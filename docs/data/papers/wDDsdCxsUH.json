{"id": "wDDsdCxsUH", "number": 15067, "cdate": 1758247389508, "mdate": 1759897331734, "content": {"title": "SocialVeil: Probing Social Intelligence of Language Agents under Communication Barriers", "abstract": "Large language models (LLMs) are increasingly evaluated in interactive environments to test their social intelligence. However, existing benchmarks usually assume idealized communication between agents, limiting our ability to diagnose whether LLMs can maintain and repair interactions under real-world conditions. To close this gap, we present SocialVeil, a social learning environment that can simulate social interaction under cognitive-difference-induced communication barriers. SocialVeil introduces three representative types of such disruption, semantic vagueness, sociocultural mismatch, and emotional interference. SocialVeil also introduces barrier-aware evaluation metrics, unresolved confusion and mutual understanding, which complement standard goal-oriented evaluation by assessing agents' capability of maintaining interaction in impaired communication. Experiments across 720 scenarios and four frontier LLMs show that barriers consistently impair performance, with mutual understanding reduced by over 45% on average, and confusion elevated by nearly 50\\%. Human evaluations validate the fidelity of these simulated barriers (ICC$\\approx$0.78, Pearson r$\\approx$0.80). We further demonstrate that adaptation strategies (Repair Instruction and Interactive learning) only have a modest effect that remains far from barrier-free performance. This work takes a step toward bringing social interaction environments closer to real-world communication, opening broader opportunities for exploring the social intelligence of LLM agents.", "tldr": "", "keywords": ["Social Interaction", "Agent", "Social intelligence", "Alignment", "Large Language Models", "Evaluation"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/103f25d2774103c0aaac1a8af3c232643e5bfe85.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces SocialEvil, a barrier-aware social interaction environment for evaluating language agents’ social intelligence under three cognitively induced communication barriers: Semantic Vagueness, Sociocultural Mismatch, and Emotional Interference. It contributes (i) a taxonomy and controllable barrier-injection scheme layered via style prompts and quantitative parameterization; (ii) barrier-aware metrics—Unresolved Confusion and Mutual Understanding—to complement goal-oriented scores; (iii) experiments on 720 scenarios adapted from SOTOPIA with four LLMs; and (iv) adaptation studies (repair instructions; interactive learning via BC+SR). Results show large degradations under barriers (e.g., ~45–58% drops on mutual understanding, large increases in confusion) and only modest gains from adaptation; human studies (κ/ICC, Pearson correlations) suggest decent fidelity/alignment of automatic metrics with human judgments."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper addresses a clear and important gap by moving beyond idealized evaluations to test social intelligence under realistic communication breakdowns \n- The framework is built on a systematic literature review, defining three barrier types (Semantic Vagueness, Sociocultural Mismatch, Emotional Interference) grounded in established social science and cognitive theories.\n- The paper thoroughly validates its contributions. Computational analysis (t-SNE) confirms the barriers create “structured” disruptions, and human evaluation shows the new metrics align strongly with human judgments.\n- The paper introduces “Unresolved Confusion” and “Mutual Understanding”, which successfully capture distinct failure modes for each barrier and reveal a trade-off between barrier-handling and goal completion.\n- The paper is well-written with clear figures and extensive appendices detailing prompts and experimental setup, supporting reproducibility."}, "weaknesses": {"value": "- The paper’s primary methodological contribution is the injection of barriers. This is described as a “style prompt $P_b$” and a “parameterization $R_b$”. However, the exact prompts and parameters used to instantiate these barriers are not provided. Appendix F details the agent and evaluator prompts, but not the crucial “Barrier Guidance” prompts (seen in Figure 2). Without these, it’s difficult to fully reproduce the barrier generation or assess its implementation. For example, how is “overuse pronouns and ellipses” practically implemented?\n\n- The “barrier agent” is fixed as GPT-4o-mini in all experiments. This introduces a potential confound. The observed effects (e.g., the performance degradation in Table 2 or the clusters in Figure 3) might not be general to the barrier type (e.g., Semantic Vagueness) but rather specific to how GPT-4o-mini manifests Semantic Vagueness. The study does not disentangle the barrier's conceptual definition from its specific implementation by a single model.\n\n- The human evaluation for identifying the correct barrier type yielded “fair” agreement (Fleiss's Kappa $\\kappa=0.38$) and accuracies between 63-67% for the three barrier types. While the authors rightly note this is common in subjective tasks and well above chance, it also suggests that the barriers, as implemented, may not be perfectly distinct to human observers, potentially overlapping in their manifestation.\n\n- The “Interactive Learning” (BC+SR) strategy is a good inclusion. However, the expert trajectories for Behavior Cloning (BC) were generated from interactions using GPT-4o as the partner agent. Using an LLM as the “expert” for navigating complex social repairs—a task the paper demonstrates LLMs struggle with—may create a low ceiling for improvement. The “modest” gains might be more an artifact of the “expert's” limited capabilities than a true reflection of the (BC+SR) method’s potential."}, "questions": {"value": "- Regarding Weakness 1: Could you please provide the exact “style prompts” ($P_b$) and “parameterizations” ($R_b$) used to inject each of the three barrier types? This seems crucial for reproducibility.\n\n- Regarding Weakness 2: Did the authors consider or run any experiments where the barrier agent model was varied (e.g., using Qwen2.5-7B as the barrier agent)? How can we be confident that the results in Table 2 are characteristic of the barriers themselves and not of GPT-4o-mini's specific failure modes?\n\n- Regarding Weakness 4: The expert trajectories for BC were sourced from GPT-4o. Do you think using human-generated expert trajectories, which might contain more sophisticated or non-obvious repair strategies, would lead to significantly better performance in the “Interactive Learning” adaptation?\n\n- Regarding Figure 5: The finding that Sociocultural Mismatch “uniquely elevate[s] Unresolved Confusion” is very interesting. Based on your qualitative analysis, could you provide an example or elaborate on the mechanism here? What does this type of interaction typically look like?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gFPC6op7UC", "forum": "wDDsdCxsUH", "replyto": "wDDsdCxsUH", "signatures": ["ICLR.cc/2026/Conference/Submission15067/Reviewer_kqS8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15067/Reviewer_kqS8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15067/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761586053091, "cdate": 1761586053091, "tmdate": 1762925389200, "mdate": 1762925389200, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SocialVeil, a benchmark designed to evaluate the social intelligence of large language model-based agents under communication barriers. The authors construct three types of barriers, including semantic vagueness, sociocultural mismatch, and emotional interference, and test several large language models. The results show that such barriers substantially reduce mutual understanding and task success."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "* The motivation for studying social intelligence in noisy or ambiguous communication settings is interesting.\n\n* The paper is clearly written and organized.\n\n* The implementation of different communication barriers is creative and could be useful for exploratory studies."}, "weaknesses": {"value": "1. The proposed benchmark is mainly constructed by manually designing prompting templates that inject vagueness, cultural mismatch, or emotional bias into conversations. There is no new model, algorithm, or principled framework. The whole approach remains at the level of prompt engineering rather than a genuine methodological advance in measuring social intelligence.\n\n2. The study does not introduce a novel metric, learning method, or theoretical insight. Most of the results simply confirm what one would expect, i.e., communication barriers reduce conversational performance. \n\n3. I am not quite persuaded that the benchmark itself is sufficiently meaningful. The scenarios are synthetic and depend entirely on prompt wording. It is unclear whether these prompts truly capture realistic sociocultural or emotional phenomena.\n \n4.  The evaluation design is too limited to support the paper’s broader claims about “probing social intelligence”. Most experiments are conducted only on plain language models, without incorporating more advanced agent architectures or reasoning strategies such as chain-of-thought prompting, reflective reasoning, or planning-based multi-agent coordination. Even though these systems were not originally designed for social simulation, they can be readily adapted to this benchmark with minor modifications. Including such evaluations would make the study far more informative, as it could reveal whether social communication barriers affect general reasoning mechanisms, dialogue consistency, or coordination strategies. In its current form, the results provide only a narrow view of model performance and cannot substantively advance understanding of social intelligence in agentic systems."}, "questions": {"value": "Please refer to the weaknesses above. In particular, I am curious: if the models were equipped with more advanced agent frameworks (for example, chain-of-thought reasoning or reflection mechanisms), how might their social intelligence behave or change under the proposed communication barriers?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "j5iZpdM22q", "forum": "wDDsdCxsUH", "replyto": "wDDsdCxsUH", "signatures": ["ICLR.cc/2026/Conference/Submission15067/Reviewer_ftGw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15067/Reviewer_ftGw"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15067/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761808436416, "cdate": 1761808436416, "tmdate": 1762925387713, "mdate": 1762925387713, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a social learning environment (SOCIALVEIL) to test LLM’s social intelligence under communication barriers such as semantic vagueness, sociocultural mismatch, and emotional interference. The authors create 720 simulated interaction episodes derived from previous work [SOTOPIA (Zhou et al., 2023)] and introduce two new barrier-aware metrics: Unresolved Confusion and Mutual Understanding, to assess the robustness of LLM agents when communication is impaired. Experiments across four models (GPT-4o-mini, Qwen2.5-7B, Qwen3-4B, and Mistral-8B) show that barriers degrade performance substantially and that adaptation methods (instructional repair and interactive learning) yield only modest gains. Human evaluations validate the reliability of the simulated barriers."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper introduces a barrier-aware social interaction environment (SOCIALVEIL) that systematically embeds realistic communication disruptions to evaluate LLM social intelligence.\n2. The paper proposes a comprehensive, automated evaluation protocol and verifies its fidelity through extensive human studies, showing strong metric alignment and reproducibility.\n3. The experiment results and analysis demonstrate that communication barriers substantially impair LLMs’ mutual understanding and relationship quality, and that current adaptation strategies only yield modest improvements—highlighting an important research gap.\n4. Overall, the paper is nicely presented and easy to follow."}, "weaknesses": {"value": "1. Evaluation: Barriers are injected with one model and GPT-4o is used as the automatic evaluator. This raises concerns about evaluator bias/overfitting to its own stylistic expectations. An ablation with multiple evaluators would strengthen claims.\n2. Dataset: Generalization beyond SOTOPIA. All scenarios are adapted from SOTOPIA; it remains unclear how well the findings transfer to other interactive corpora or human-in-the-loop settings.\n3. Dataset: Limited Data Points: 180 episodes for each barrier type\n4. Evaluation: The author claim experiments are performed on frontier models. However, GPT-4o-mini, Qwen2.5-7B, Qwen3-4B, and Mistral-8B, are evaluated. More advanced.State-of-the-art LLM such as GPT5, Gemini 2.5 Pro, Claude-4-Sonnet/Opus are not evaluated.\n5. Code: Code is not provided, there is a reproducibility risk until release."}, "questions": {"value": "See the weakness section above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7xxaCEn6Ws", "forum": "wDDsdCxsUH", "replyto": "wDDsdCxsUH", "signatures": ["ICLR.cc/2026/Conference/Submission15067/Reviewer_NjoN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15067/Reviewer_NjoN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15067/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762044303982, "cdate": 1762044303982, "tmdate": 1762925386058, "mdate": 1762925386058, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SOCIALVEIL, a novel framework and benchmark designed to evaluate the social intelligence of Large Language Model (LLM) agents under realistic communication barriers. The authors argue that existing social interaction benchmarks operate under idealized communication conditions, failing to capture the ambiguities and misalignments prevalent in real-world dialogue. SOCIALVEIL systematically injects three types of cognitively-rooted barriers—Semantic Vagueness, Sociocultural Mismatch, and Emotional Interference—into two-agent interactions. The paper presents a comprehensive evaluation protocol that includes both standard goal-oriented metrics and new barrier-aware metrics (Unresolved Confusion, Mutual Understanding). Experiments across 720 scenarios and four frontier LLMs demonstrate that these barriers significantly impair agent performance, particularly on social dimensions. The authors further show that simple adaptation strategies like repair instructions are largely ineffective, while interactive learning offers only modest gains, highlighting the challenge of achieving human-like social resilience."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "Novel  Contribution: The core idea is highly relevant and timely. Moving beyond idealized \"seamless\" interaction to study how agents handle communication breakdowns is a critical step toward more robust and socially-aware AI. The focus on structured, cognitive barriers, as opposed to simple noise, is a significant conceptual advance.\nRigorous and Well-Structured Framework: The methodology is well-designed. The barrier taxonomy is theoretically grounded in literature from pragmatics, sociolinguistics, and psychology. The two-layer implementation (style prompt + parameterization) provides a controlled yet flexible mechanism for barrier injection. The unilateral barrier design is elegant, as it isolates the source of disruption and allows for a clear evaluation of the partner agent's resilience.\nComprehensive Evaluation: The evaluation is thorough and multi-faceted. The combination of automatic metrics (covering both goals and barriers) with extensive human evaluation is a best practice. The human evaluation convincingly validates the fidelity of the simulated barriers (good ICC, above-chance identification accuracy, strong correlation with automated metrics).\nCompelling and Actionable Results: The findings are clear and impactful:\nBarriers cause significant performance degradation (~45-50% drop in mutual understanding and relationship quality).\nDifferent barriers have distinct, theoretically-aligned effects (e.g., semantic vagueness hurts mutual understanding most, emotional interference damages relationships).\nThe limited success of adaptation strategies is a sobering and important result, underscoring that social intelligence under duress is not a trivial problem solvable by simple prompting.\nHigh Reproducibility: The paper is commendable for its commitment to reproducibility, with detailed appendices covering prompts, training hyperparameters, and human evaluation protocols. The promise to release code and data is excellent."}, "weaknesses": {"value": "Statistical Reporting Could Be Enhanced: While the results are presented clearly in tables and figures, the paper would be strengthened by more formal statistical testing.\nTable 2: The reported performance drops are descriptive (averages). Statistical significance tests (e.g., paired t-tests between baseline and each barrier condition for each metric/model) would solidify the claim that barriers \"consistently impair\" performance.\nTable 3: The comparison between Base, Repair, and (BC+SR) conditions would benefit from statistical tests to confirm that the \"modest gains\" from BC+SR are statistically significant and that the difference from Repair is meaningful.\nConfidence Intervals: It is excellent that confidence intervals are provided for human evaluation (Table 4, Figure 7). It would be beneficial to also include them for the key automatic metrics in the main results (Table 2).\nClarity on Baseline and \"Barrier-Free\" Performance:\nThe \"barrier-free\" baseline is described as one of the four episode sets. It would be helpful to explicitly state its performance in the main results (Table 2) to serve as a clear reference point for the magnitude of degradation.\nThe text states mutual understanding was \"reduced by over 45% on average,\" but the baseline scores in Table 2 are already quite low for some models (e.g., Mistral's baseline Mutual Understanding is 3.54). A brief discussion on the absolute vs. relative performance drop might be useful.\nMinor Writing and Exposition Issues:\nThe transition between sections can occasionally be abrupt. For instance, the jump from the introduction of the three research questions (Sec. 3) to the first result (Sec. 4.1) could be smoother.\nSome acronyms are used before being fully defined (e.g., BC and SR are used in Table 3 before being explicitly expanded in Appendix C.1, though they are described in Sec. 3)."}, "questions": {"value": "Generalization and Scalability: The scenarios are adapted from Sotopia. To what extent do you believe the findings and the SOCIALVEIL framework generalize to other interactive benchmarks or entirely new, procedurally generated social scenarios?\nInterpretation of Adaptation Results: The results show that interactive learning improves mutual understanding but also increases confusion. What is your interpretation of this trade-off? Does the agent learn to \"navigate\" the barrier by acknowledging confusion more, without necessarily resolving it?\nBarrier Interaction: The study introduces barriers in isolation. In the real world, these barriers often co-occur (e.g., an emotional outburst causing semantic vagueness). How computationally feasible and methodologically sound would it be to study interacting or composite barriers within the SOCIALVEIL framework?\nPartner Agent's Role: The framework focuses on the partner agent's resilience. Did you observe any consistent strategies that successful partner agents used to cope with different barrier types? A brief qualitative analysis of such strategies could be a valuable addition."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JqaeayOoU2", "forum": "wDDsdCxsUH", "replyto": "wDDsdCxsUH", "signatures": ["ICLR.cc/2026/Conference/Submission15067/Reviewer_wPnq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15067/Reviewer_wPnq"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15067/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762526638114, "cdate": 1762526638114, "tmdate": 1762925384588, "mdate": 1762925384588, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}