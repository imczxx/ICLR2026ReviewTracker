{"id": "ynT6rqo4Lp", "number": 14963, "cdate": 1758246202738, "mdate": 1759897338949, "content": {"title": "Multi-Scale Diffusion-Guided Graph Learning with Power-Smoothing Random Walk Contrast for Multi-View Clustering", "abstract": "Despite the notable advances in graph-based deep multi-view clustering, existing approaches still suffer from three critical limitations:  (1) relying on static graph structures and being unable to model the global semantic relationships across views; (2) contamination from false negative samples in contrastive learning frameworks; and (3) a fundamental trade-off between cross-view consistency and view-specific discrimination. To address these issues, we introduce \\textbf{M}ulti-sc\\textbf{A}le diffusio\\textbf{N}-guided \\textbf{G}raph learning with p\\textbf{O}wer-smoothing random walk contrast (\\textbf{MANGO}) for multi-view clustering, a unified framework that combines adaptive multi-scale diffusion, random walk-driven contrastive learning, and structure-aware view consistency modeling. Specifically, the multi-scale diffusion mechanism leverages local entropy guidance to dynamically fuse similarity matrices across different diffusion steps, thereby achieving joint modeling of fine-grained local structures and overall global semantics. Additionally, we introduce a random walk-based correction strategy that explores high-probability semantic paths to filter out false negative samples, and applies a $\\beta$-power transformation to adaptively reweight contrastive targets, thereby reducing noise propagation. To further reconcile the consistency-specificity dilemma, the view consistency module enforces semantic alignment across views by sharing structural embeddings, ensuring consistent local structures while preserving heterogeneous features. Extensive experiments on 12 benchmark datasets demonstrate the superior performance of MANGO.", "tldr": "", "keywords": ["Multi-view Clustering"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/579535fe92eab727ed0e56e78670415e7ba88b81.pdf", "supplementary_material": "/attachment/c4cbc12d30e2b98af3656378b61efbb02a9d8225.zip"}, "replies": [{"content": {"summary": {"value": "This work tackles several challenges in graph-based deep multi-view clustering, such as limited representation from static graphs, the influence of false negatives in contrastive learning, and the balance between cross-view consistency and view-specific discrimination. To address these, the authors introduce MANGO, a unified framework that combines adaptive multi-scale diffusion, random walk-based contrastive learning, and structure-aware view consistency modeling, and validate its effectiveness on multiple datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe model is well-motivated and effectively leverages rich information from multi-view data by combining adaptive multi-scale diffusion, random walk-based contrastive learning, and structure-aware view consistency modeling, leading to improved clustering performance.\n2.\tThe workflow is clearly illustrated, accompanied by precise explanations.\n3.\tThe baselines used for comparison are representative, covering both deep learning-based and shallow methods."}, "weaknesses": {"value": "1. The power operation in the power-smoothing-induced contrastive learning is not described in detail, and the underlying mechanism that gives it an advantage over the standard InfoNCE loss is unclear.\n2. The relationships between different modules are not well explained and feel somewhat disjointed, for example, the connection and distinction between component A in the Graph Refinement module and the random walk-based correction mechanism.\n3. The experimental section does not provide the sources of the datasets used.\n4. The analysis of Figure 2 (t-SNE visualization) in the paper is rather superficial and lacks in-depth discussion."}, "questions": {"value": "On the Reuters dataset, the proposed method outperforms other baselines in terms of ACC and NMI, but performs significantly worse than the CVCL model in ARI. Could the authors clarify the reason for this discrepancy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "cAZg1kW3cg", "forum": "ynT6rqo4Lp", "replyto": "ynT6rqo4Lp", "signatures": ["ICLR.cc/2026/Conference/Submission14963/Reviewer_1JZN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14963/Reviewer_1JZN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14963/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761721492447, "cdate": 1761721492447, "tmdate": 1762925298308, "mdate": 1762925298308, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The manuscript introduces a MVC framework built on graph structures, aiming to address limitations in existing approaches. The framework combines three core modules: a multi-scale diffusion process guided by local entropy to integrate similarity matrices and capture both local and global semantics; a random walk–based correction mechanism that reduces the impact of false negatives via a $\\beta$-power reweighting scheme; and a structure-aware view consistency module that aligns embeddings across views while preserving view-specific features. Experiments on 12 benchmark datasets indicate that the proposed method outperforms all baseline approaches."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed method employs an interesting multi-scale diffusion mechanism to overcome the performance bottleneck caused by fixed diffusion step sizes. It dynamically fuses similarity information across different steps while considering both local structure exploration and global semantic modeling, enabling effective capture of multi-granularity structural information.\n2. The experimental section includes not only quantitative performance comparisons but also visualizations of graphs produced by different methods, offering deeper insights.\n3. The code is provided by the authors in the supplementary materials, enabling reproducibility."}, "weaknesses": {"value": "1. It is unclear how the view-aware attention mechanism mentioned in the Introduction, as part of the structure-aware cross-view contrastive learning mechanism, is implemented in the Method section. The authors should clarify this.\n2. The uniform weight matrix W appearing in Equation (5) lacks a clear definition. The authors should explicitly describe how this matrix is formulated or obtained.\n3. The graph refinement process involves T-step diffusion, but the effect of different T values on model performance is not discussed. It is also unclear whether the same T value is applied across different datasets.\n4. Several formatting issues are noted in the manuscript. In particular, some references lack page number information."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HGhUKgawnB", "forum": "ynT6rqo4Lp", "replyto": "ynT6rqo4Lp", "signatures": ["ICLR.cc/2026/Conference/Submission14963/Reviewer_oBPZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14963/Reviewer_oBPZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14963/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761723550361, "cdate": 1761723550361, "tmdate": 1762925297783, "mdate": 1762925297783, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MANGO, a deep multi-view clustering framework that integrates random walk–based contrastive learning, view consistency alignment, and adaptive diffusion to learn discriminative and robust multi-view embeddings. The authors validate the effectiveness of the proposed method through extensive experiments, including performance comparisons, ablation studies, and sensitivity analyses."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The framework effectively combines improved contrastive learning, view consistency, and adaptive diffusion in a unified architecture, providing a coherent approach to multi-view clustering, and the experimental evaluation across datasets of varying types and scales provides strong evidence for the effectiveness of the proposed method."}, "weaknesses": {"value": "1. The variables in the flowchart are not clearly labeled; many matrices and components lack explanation.\n2. Formula (6) involves a balancing parameter, but the strategy for choosing its value is not described.\n3. The manuscript claims that the multi-scale diffusion mechanism jointly models fine-grained local structures and overall global semantics; however, it is unclear whether any evidence is provided to support this claim. Further clarification or validation is needed.\n4. The description of the consistency loss (Formula 9) is unclear, making it difficult to understand.\n5. In the related work section, deep multi-view clustering methods are categorized into joint methods, alignment-based methods, and other methods, but the basis for this classification is not explained."}, "questions": {"value": "See Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "no"}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "hjqKuTeTLq", "forum": "ynT6rqo4Lp", "replyto": "ynT6rqo4Lp", "signatures": ["ICLR.cc/2026/Conference/Submission14963/Reviewer_FL2j"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14963/Reviewer_FL2j"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14963/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761726521435, "cdate": 1761726521435, "tmdate": 1762925297035, "mdate": 1762925297035, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel deep multi-view clustering framework named MANGO, which learns a discriminative multi-view embedding by integrating three key components: a random walk–modified contrastive learning module, a view consistency module, and an adaptive diffusion module. Specifically, the contrastive module dynamically adjusts the weights of negative samples to better handle complex data distributions; the view consistency module achieves deep alignment across feature spaces via a bidirectional projection mechanism; and the adaptive diffusion module captures multi-scale structural information while mitigating over-smoothing and information loss. Extensive experiments demonstrate the effectiveness of the proposed MANGO."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.The paper presents a well-structured deep multi-view clustering framework that integrates random walk–modified contrastive learning, view consistency, and adaptive diffusion modules, each complementing the others effectively.\n2.Extensive experiments conducted on 12 multi-view datasets of varying scales and types convincingly demonstrate the superiority and robustness of the proposed method.\n3.The implementation details of the experiments are presented in a detailed manner."}, "weaknesses": {"value": "1. The manuscript does not clearly explain the physical meaning of the transfer matrix $M$ in the random walk-based correction mechanism. Its connection with the similarity matrix and its role in the correction process require further clarification.\n2. The rationale behind the hybrid regularization in Equation (2) is insufficiently detailed. The authors should clarify how this regularization helps prevent overfitting and improves model generalization.\n3. The manuscript does not indicate the absence of standard deviations in Table 2, nor does it clarify whether the reported results are based on a single run or the average performance over multiple runs.\n4. The indexing of equations in the pseudocode is not consistent or properly formatted."}, "questions": {"value": "See Weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "MJVIRrvYWV", "forum": "ynT6rqo4Lp", "replyto": "ynT6rqo4Lp", "signatures": ["ICLR.cc/2026/Conference/Submission14963/Reviewer_tTks"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14963/Reviewer_tTks"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14963/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761815691051, "cdate": 1761815691051, "tmdate": 1762925296556, "mdate": 1762925296556, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}