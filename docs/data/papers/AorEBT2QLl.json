{"id": "AorEBT2QLl", "number": 7338, "cdate": 1758016896693, "mdate": 1762931002309, "content": {"title": "A Novel Graph-based Fuzzy Clustering for Deep Visual Representations", "abstract": "Clustering has long been prized for its simplicity and efficiency. However, with the\nrapid progress of large-scale self-supervised models, this landscape has shifted.\nWhile stronger representations substantially benefit clustering, jointly learning\nrepresentations and clusters on neural networks has become increasingly resourceintensive. This creates a gap: traditional clustering algorithms remain lightweight\nbut struggle with deep representations, whereas deep clustering methods are effective but computationally expensive. To bridge this gap, we propose Graph-based\nFuzzy Clustering (GFC), a novel algorithm to collaborate with foundation models\nfor direct representation clustering. GFC unifies a global fuzzy clustering objective with a local consistency constraint, enabling it to capture both global structural dependencies and local intrinsic connectivity. Furthermore, we develop a fast\noptimization program to efficiently solve the proposed multi-constrained problem. Extensive experiments across multiple benchmarks demonstrate that GFC\nnot only surpasses state-of-the-art deep clustering methods in accuracy but also\nachieves superior efficiency, offering a simple and scalable solution for modern\ndeep representations, with a notable 73.4% clustering accuracy on ImageNet-1k.", "tldr": "This paper proposes Graph-based Fuzzy Clustering (GFC), a simple scalable algorithm that collaborates with large vision models to efficiently cluster their deep representations while achieving state-of-the-art accuracy.", "keywords": ["Deep image clustering", "representation learning", "k-nearest neighbor", "fuzzy clustering"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/0bfa4c1a1222834b25ad277d336155ee272218bb.pdf", "supplementary_material": "/attachment/c58acc1414e10f2c37bead9ed99eefd8d21ade2e.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes Graph-based Fuzzy Clustering (GFC) for clustering deep visual representations extracted from foundation models. GFC unifies a global fuzzy clustering objective with a local consistency constraint by jointly optimizing a hard assignment matrix V and a soft assignment matrix P. The authors claim to achieve 73.4% clustering accuracy on ImageNet-1k, surpassing existing deep clustering methods while maintaining computational efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The core contributions: \n1) a clustering objective combining global structural dependencies and local intrinsic connectivity\n2) an efficient Lagrangian optimization algorithm with aggregation acceleration.\n3)extensive experimental validation across multiple benchmarks.\n\nStrengths：\n1）Clear problem motivation and positioning\n2）Identified the limitations of traditional clustering methods when handling deep representations\n3）The design of introducing an auxiliary hard-assignment matrix V to accelerate convergence is quite ingenious."}, "weaknesses": {"value": "1) The novelty of the method is somewhat limited and requires a clearer explanation of its fundamental differences from existing approaches, particularly PAC and Self-CSC （ Despite these advances, traditional fuzzy and graph-based methods are primarily designed for toy datasets and struggle with deep neural network outputs, facing challenges in fine-grained partitioning, parameter tuning, and algorithmic efficiency）.\n\n2)Lacks rigorous proof with complexity analysis. Although claimed to be O(nb·n), the impact of mini-batch operations on convergence speed remains unanalyzed.\n\n3)The experimental details are unclear, such as the lack of explanation for the specific procedure of “dividing the data into five overlapping blocks.”\n\n4)How should overlapping sections be handled? Does this introduce additional information leakage?\n\n5)Some symbols were not clearly explained upon their first appearance. The term “Computational Cost (Higher→Lower)” in Figure 1 is a qualitative description lacking quantitative basis."}, "questions": {"value": "1）Could you provide fair comparisons to isolate the algorithmic contribution? Specifically:\nWhat is the performance of TEMI/TAC when using DINO v3 features (same as GFC)?\nWhat is the performance of GFC when using CLIP ViT-B/16 features (same as baselines)?\nCan you provide detailed ablation studies showing where the 29% improvement over K-means comes from?\n\n2）In standard fuzzy clustering theory, m=2 is typical, while m→1 approaches hard clustering. Your choice of m=1.05 (with exponent 1/(m-1)=20) produces nearly crisp assignments. Why is m≈1 appropriate for deep representations? Have you compared results with m∈{1.5, 2.0, 3.0}? Does this choice essentially reduce GFC to hard clustering?\n\n3） You introduce V alongside soft assignment matrix P, claiming V accelerates convergence and improves stability. However, no ablation study validates this claim. Can you provide experimental results comparing GFC with and without V? How is the update frequency of V controlled relative to P? Is V necessary for the method to work, or merely a computational acceleration trick?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aEDCxXRkf0", "forum": "AorEBT2QLl", "replyto": "AorEBT2QLl", "signatures": ["ICLR.cc/2026/Conference/Submission7338/Reviewer_siZB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7338/Reviewer_siZB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7338/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760759467759, "cdate": 1760759467759, "tmdate": 1762919459779, "mdate": 1762919459779, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "MPeU7qgXSO", "forum": "AorEBT2QLl", "replyto": "AorEBT2QLl", "signatures": ["ICLR.cc/2026/Conference/Submission7338/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7338/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762930717981, "cdate": 1762930717981, "tmdate": 1762930717981, "mdate": 1762930717981, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses two long-standing bottlenecks in graph-based fuzzy clustering—high time complexity and cumbersome regularization parameter tuning—which severely limit practical applications in large-scale or real-time scenarios . Its core insight of \"subset-to-fullset\" transformation is highly innovative: by constructing a similarity graph between the full dataset and a landmark subset, it reduces the membership learning of all data points to clustering representative landmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Combines a fuzzy clustering objective based on cluster co-occurrence probabilities with a Laplacian-based local constraint.\nIntroduces a ‌hard assignment matrix‌ as an auxiliary variable to accelerate convergence and proposes an ‌aggregation acceleration strategy‌ that reduces time complexity to linear.\nCompatible with large-scale foundation models (SimCLR, CLIP, DINO v3) and scalable to datasets like ImageNet."}, "weaknesses": {"value": "The paper does not clarify the landmark subset construction strategy, which is critical to algorithm performance:​\nHow to determine landmark quantity? Is it adaptive to dataset scale or cluster density?​\nWould random vs. k-means-selected landmarks affect result stability? For example, biased landmarks might distort the similarity graph for imbalanced data.​\nAblation studies on landmark parameters (size, sampling method) would strengthen methodological rigor.​\nLimited Comparison to State-of-the-Art Methods"}, "questions": {"value": "Why does the first termsin formulas (4) and (6) do not appear‌ in the simplified objective function in formula (10).\nThe objective function of GFC should be clearly defined and its underlying meaning or intuition should be explicitly explained.\nI suspect that the reported visual representation performance may primarily stem from existing self-supervised learning methods (e.g.,SimCLR,DINOv3), rather than the proposed technique itself. The authors should clarify the source of performance gains."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "UXItLKi31e", "forum": "AorEBT2QLl", "replyto": "AorEBT2QLl", "signatures": ["ICLR.cc/2026/Conference/Submission7338/Reviewer_Xoz8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7338/Reviewer_Xoz8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7338/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761706846583, "cdate": 1761706846583, "tmdate": 1762919458791, "mdate": 1762919458791, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "To address the trade-off between clustering accuracy and speed, this paper proposes a graph-based fuzzy clustering method that collaborates with the foundation models to achieve direct clustering on deep representation. Aiming at the difficulty of clustering deep representations, a clustering model with an objective function based on cluster co-occurrence probability and local clustering constraints is proposed. A Lagrangian optimization algorithm and an acceleration scheme are developed to effectively solve the proposed model. This algorithm ensures faster convergence speed, enhances the scalability of the clustering model, and makes it highly suitable for large-scale data."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The research motivation is clear, the proposed method demonstrates effectiveness, and the paper structure is complete. Additionally, the authors have conducted extensive experiments to verify the effectiveness of the proposed method."}, "weaknesses": {"value": "The content of this paper is not inherently difficult, but its readability is poor. Significant effort is required to understand and infer the meanings of symbols, especially those related to vectors. There are errors in several formulas throughout the paper. The design motivation for each step is unclear, particularly the derivation transition from Eq. 3 to Eq. 4.\n\nIn the related work, the authors’ introduction to graph-based clustering is not comprehensive enough. While spectral clustering is indeed a common graph-based clustering method, other approaches, such as subspace clustering and deep graph clustering, which also fall into the category of graph-based clustering, are not adequately covered."}, "questions": {"value": "1. The definition and explanation of symbols are ambiguous, which greatly increases the difficulty of reading and understanding. Specific issues are as follows: \n- There are two doubts about Eq. 1: first, the author does not clarify the meaning of vector $p$, and it is inferred to be a row vector based on the context; second, if treated as a row vector, the product of a column vector and a row vector is a matrix rather than a scalar. Is there an error here? If not, please the author provide a clear explanation. \n- The description of the derivation process for Eq. 5 is incorrect: according to the operation description of \"Right Multiply\", the conclusion $P=\\Delta^{-1}WP$ cannot be derived. \n- There is a consistency issue between Eq. 10 and the definition of matrix H, and at least one of them is incorrect; Eq. 38 in the appendix also has the same problem.\n\n2. In addition, the author needs to supplement or correct the following contents:\n- It is recommended to supplement the convergence proof of the method from a theoretical perspective.\n- Table 4 presents the average results of 5 runs, but it does not report the standard deviation simultaneously like Tables 2 and 3, lacking support for result stability; moreover, no statistical significance test has been conducted on all experimental results, making it impossible to fully prove the superiority of the method's performance.\n- Table 6 in the Appendix uses the same evaluation indicators as those in the main text, but there are inconsistencies in the presentation form and decimal places of the specific values, which affect the comparability of the results.\n- Since this paper focuses on a fast and effective clustering algorithm, it is recommended to move the experimental results related to execution time from the Appendix into the main text to better support the core research goal.\n3. Typos:\n- \"yiels\" in Line 107 is suspected to be an error, and it should be \"yields\".\n- In Line 133, in the last constraint condition of the probability matrix $P$, the expressions $\\sum_{i=1}^{n}$ and $i=1,\\cdots,n$ are suspected of being redundant, and the author needs to confirm this.\n- In Line 956, the description of the value range of k is incomplete and should be supplemented in the form of a set."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4LYtoLeyBP", "forum": "AorEBT2QLl", "replyto": "AorEBT2QLl", "signatures": ["ICLR.cc/2026/Conference/Submission7338/Reviewer_oRh4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7338/Reviewer_oRh4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7338/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761721074025, "cdate": 1761721074025, "tmdate": 1762919458162, "mdate": 1762919458162, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a graph-based fuzzy clustering method that aims to improve community detection and semi-supervised learning on graphs. The key idea is to integrate fuzzy membership learning with graph spectral embedding, allowing nodes to belong partially to multiple communities. The proposed model introduces a Fuzzy Graph Laplacian (FGL), which adaptively reweights edges based on membership uncertainty, and a Mutual Information Regularizer that enhances separation between clusters. The method is evaluated on several benchmark datasets (Cora, Citeseer, PubMed, Amazon, and DBLP) for node clustering and classification tasks. Results show consistent gains over strong baselines such as spectral clustering, GCN, and DGI, especially when labels are sparse."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is clear about its motivation with sufficient significance and quality.\n- Community structures in real-world graphs are often overlapping and uncertain; addressing this via fuzzy membership learning is timely and meaningful.\n\n- The combination of fuzzy logic and spectral embedding is coherent, and the proposed FGL elegantly connects uncertainty estimation with graph topology.\n\n- The method achieves competitive or superior performance on multiple graph benchmarks, with particularly strong results in low-label regimes.\n\n- The fuzzy membership matrix provides intuitive insight into ambiguous nodes or overlapping clusters.\n\n- The optimization objective is clearly stated and derived, with proofs of convergence and parameter stability."}, "weaknesses": {"value": "- While integrating fuzzy clustering and spectral methods is well executed, the conceptual innovation is somewhat incremental. The paper feels more like a refined synthesis of existing ideas than a fundamentally new direction.\n\n- The effect of key hyperparameters (fuzzifier m, regularization strength, number of clusters) is not explored in depth.\n\n- The intuition behind the mutual information regularizer could be explained more clearly, particularly how it avoids over-smoothing or trivial membership assignments.\n\n- It would be useful to include comparisons with more recent graph contrastive learning models or probabilistic community detection baselines."}, "questions": {"value": "- How does the computational cost of your method scale with graph size compared to GCN or DGI?\n\n- Could the fuzzy membership be incorporated into a neural encoder (e.g., as a layer in a GNN) to improve scalability?\n\n- How sensitive is the model to the fuzzifier parameter m?\n\n- Does the method handle directed or weighted graphs without modification?\n\n- Could the approach extend to dynamic graphs where communities evolve over time?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "81abZQSv4g", "forum": "AorEBT2QLl", "replyto": "AorEBT2QLl", "signatures": ["ICLR.cc/2026/Conference/Submission7338/Reviewer_2T1Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7338/Reviewer_2T1Q"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7338/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995675805, "cdate": 1761995675805, "tmdate": 1762919457349, "mdate": 1762919457349, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}