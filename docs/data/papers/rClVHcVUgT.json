{"id": "rClVHcVUgT", "number": 16372, "cdate": 1758263849161, "mdate": 1759897245022, "content": {"title": "PATEin: A Privacy-Preserving Framework for Knowledge Integration via Adaptive Teacher Selection in C-LLMs", "abstract": "In-context learning (ICL) enables task adaptation without modifying model parameters, making it well-suited for commercial large language models (C-LLMs) with closed-source constraints. However, ICL prompts often contain sensitive information, raising significant privacy concerns. Most existing privacy-preserving methods for ICL require access to model parameters, making them incompatible with C-LLMs. Recent methods based on teacher ensembles with differentially private aggregation have shown promise but face two fundamental challenges: ensemble inconsistency and limited knowledge integration. We propose PATEin, a novel privacy-preserving knowledge transfer framework that dynamically selects the optimal individual teacher model for labeling, thereby mitigating the loss of individual knowledge. Furthermore, it introduces a supervised teacher strategy that selectively incorporates high-consistency voting, effectively integrating individual and ensemble knowledge. Experiments on various C-LLMs (e.g., GPT-3.5-turbo, GPT-4o-mini, Claude-3.5-haiku, DeepSeek-v3) demonstrate that PATEin significantly improves labeling accuracy, reduces computational overhead, and consistently outperforms existing baseline methods.", "tldr": "", "keywords": ["Commercial large language models (C-LLMs)，In-context learning（ICL），Privacy-Preserving，Private aggregation of teacher ensembles (PATE)，Knowledge integration"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2394347738cb06a589bd89155a4d482c6d0b9101.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents PATEin, a privacy-preserving knowledge transfer framework for commercial large language models (C-LLMs), extending the PATE (Private Aggregation of Teacher Ensembles) paradigm. Unlike previous ensemble-based approaches (e.g., PromptPATE), PATEin addresses two major challenges—ensemble inconsistency and loss of individual teacher knowledge—by introducing adaptive teacher selection and a supervised high-consistency voting mechanism. The framework combines individual and ensemble-level knowledge via similarity-based teacher matching and dynamic aggregation, while preserving differential privacy through a Confident-GNMax mechanism. Experiments on multiple datasets (AGNews, SST-2, DBPedia, TREC) and commercial LLMs (GPT-3.5, GPT-4o-mini, Claude-3.5, DeepSeek-v3) demonstrate that PATEin improves labeling accuracy and cost-efficiency under equivalent privacy guarantees."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.The paper clearly identifies the limitations of ensemble-only methods in privacy-preserving in-context learning and proposes an elegant adaptive teacher selection strategy that preserves both individual and collective knowledge.\n2.Experiments cover multiple datasets and commercial LLMs, demonstrating robustness and practical applicability. The inclusion of ablation studies (teacher count, voting threshold) provides useful insights into hyperparameter sensitivity.\n3.The written is well-organized, with logical progression from problem definition to algorithmic design and empirical validation. Figures and tables are informative and support the main claims."}, "weaknesses": {"value": "1.The paper claims that adaptive teacher selection mitigates ensemble inconsistency, but the mechanism lacks formal analysis. No theoretical results (e.g., bounds on privacy–utility trade-off or optimality of teacher selection) are provided.\n2.The teacher selection relies on cosine similarity between embeddings (Doc2Vec and text-embedding-3-small), but this approach may not capture deeper task semantics or label-level consistency.\n3.While the paper mentions the use of the Confident-GNMax mechanism and claims (ε, δ)-DP compliance, the derivation is deferred to the appendix without concrete parameter values or sensitivity analysis.\n4.Although the threshold and teacher count are analyzed, other key factors—such as the influence of noise scale (σ), ensemble size diversity, or supervision strength—are unexplored.\n5.The paper emphasizes labeling quality but gives little detail on how student models benefit in downstream fine-tuning or real-world applications beyond token cost."}, "questions": {"value": "The paper selects the “optimal” individual teacher model based on cosine similarity between embeddings (Doc2Vec and text-embedding-3-small).However, it remains unclear why text similarity correlates with labeling accuracy.Could the authors provide quantitative evidence (e.g., correlation between similarity and correctness rate) or compare against random teacher selection?\n\n\nThe paper mentions the Confident-GNMax mechanism to ensure (ε,δ)(\\varepsilon, \\delta)(ε,δ)-DP but does not report concrete privacy parameters or the chosen noise scale σ\\sigmaσ.How are these parameters determined, and how do they affect the privacy–utility trade-off?A more explicit description of the privacy accounting process would help evaluate the strength of the privacy guarantees.\n\n\nFigure 4 qualitatively shows complementarity between individual and ensemble teachers, but it is unclear how much this integration contributes to the final performance.Could the authors add an ablation study comparing three variants: (1) individual-only, (2) ensemble-only, and (3) hybrid (PATEin)?\n\n\nCurrent experiments focus mainly on text classification with small to medium C-LLMs.Can PATEin scale to larger models (e.g., 14B+) or to complex reasoning and dialogue tasks?Any preliminary results or discussion would help clarify the framework’s applicability to broader LLM scenarios."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "79l6p4J1pe", "forum": "rClVHcVUgT", "replyto": "rClVHcVUgT", "signatures": ["ICLR.cc/2026/Conference/Submission16372/Reviewer_cCM9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16372/Reviewer_cCM9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16372/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761311507095, "cdate": 1761311507095, "tmdate": 1762926497767, "mdate": 1762926497767, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies privacy-preserving in-context learning. It proposes PATEin, a framework that combines teacher selection and selective ensemble voting to improve labeling accuracy and reduce query cost under claimed differential privacy guarantees."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The motivation is clear.\n- The code and datasets are released."}, "weaknesses": {"value": "- The privacy analysis of PATEin is incorrect. PATEin first selects the “most similar” teacher based on comparisons between public inputs and each teacher’s private training data, but this selection process is not differentially private, i.e., changing one private record could change which teacher is chosen. Then, when the top two teachers agree, PATEin outputs that label directly without adding noise, which completely violates differential privacy because the output depends deterministically on private data. Therefore, the experimental comparison between PATEin and PromptPATE is not meaningful.\n\n- The novelty of PATEin is limited. The paper works in the same problem setting as PromptPATE. The only new elements are teacher selection and selective ensemble voting. These are incremental extensions to PromptPATE.\n\n- The problem formulation is not clear. I recommend adding a Problem Formulation section. This section should clearly define in-context learning, threat model, and differential privacy formulation.\n\n- Experiments are limited to simple text classification benchmarks. These benchmarks are too limited for evaluating modern LLM methods. Prior work [1] on privacy-preserving in-context learning includes more complex tasks like summarization and question answering.\n\n[1] Wu, Tong, et al. \"Privacy-Preserving In-Context Learning for Large Language Models.\" The Twelfth International Conference on Learning Representations.\n\n- The paper lacks ablation studies on different embedding models and noise levels. There is no comparison between using only individual, only ensemble, or combined knowledge."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ikYvRtSezJ", "forum": "rClVHcVUgT", "replyto": "rClVHcVUgT", "signatures": ["ICLR.cc/2026/Conference/Submission16372/Reviewer_T6Ln"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16372/Reviewer_T6Ln"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16372/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761457215941, "cdate": 1761457215941, "tmdate": 1762926497038, "mdate": 1762926497038, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes PATEin, a variant of the PromptPATE framework that integrates Private Aggregation of Teacher Ensembles (PATE) into an in-context learning (ICL) setting for closed-source commercial LLMs.\nInstead of using all teachers in an ensemble, the method selects a subset of relevant teachers, based on text similarity between the query and each teacher’s example data, to reduce computational cost and improve label quality.\nThe authors claim this improves ensemble consistency and integrates individual teacher knowledge while maintaining privacy through Gaussian noise aggregation.\n\nWhile the topic of private label aggregation in C-LLMs is timely and relevant, the novelty is limited, as the proposed “adaptive teacher selection” essentially amounts to pre-filtering which teachers vote in PATE, using standard text-similarity metrics.\nThe work lacks a clear privacy analysis of the selection step and overstates its conceptual contribution.\nPresentation is somewhat confusing, with the abstract and introduction suggesting a new “knowledge integration framework” rather than a PATE variant with heuristic teacher filtering."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The direction of combining PATE and in-context learning is important and continues a promising research line (PromptPATE, Duan et al. 2023).\n\nAddressing the high cost of multiple LLM API calls is practically relevant; exploring teacher pre-selection for efficiency is reasonable.\n\nThe paper includes experimental evaluation on multiple C-LLMs (GPT-3.5, GPT-4o-mini, Claude-3.5-Haiku, DeepSeek-v3)."}, "weaknesses": {"value": "### Limited Novelty and Conceptual Depth\n\nThe method retains the same overall PATE structure: partition data, generate teacher prompts, vote with added Gaussian noise, and aggregate.\nThe new component, a similarity-based filtering of teachers, is a heuristic efficiency improvement, not a conceptual extension of PATE.\n\nThe privacy guarantees remain those of PATE, and the overall privacy protection still depends on the support size (number of participating teachers) and the maximum agreement among them.\n\n### Lack of Clarity about Privacy Implications\n\nThe abstract (lines 20–21) claims “dynamic selection of the optimal individual teacher model”—but such selection of one or very few relevant teachers is counter to privacy. Selective querying itself could leak information about which teachers are similar to a query.\n\nThe paper does not discuss how this adaptive selection interacts with the differential-privacy accounting.\n\nStatements like “selects the optimal teacher model for labeling” may give a misleading impression that privacy is preserved automatically, when in fact the selection must be handled carefully to avoid additional leakage.\n\n### Overstatement of Contribution\n\nThe claim (lines 107–110) that this is “the first privacy-preserving knowledge integration framework tailored to C-LLM settings” is an oversell. The actual novelty is only in compute efficiency not utility for privacy.\nThe proposed “integration of ensemble and individual knowledge” is effectively conditional voting based on teacher confidence.\n\n### Presentation and Readability\n\nIt takes several pages to understand what the actual algorithmic change is.\nThe introduction repeatedly discusses “knowledge integration” and “ensemble consistency” before stating that the novelty is teacher pre-filtering based on text similarity. That the only potential gain is compute effciency (not accuracy for privacy). Heavy terminology such as “supervised teacher strategy” and “optimal individual teacher model\" distracts.  A use of a single best-match teacher model, as implied in this sentence,  is highly NOT privacy preserving and this leaves the reader pondering.\n\nSome empirical sections (Figs. 2–4) are difficult to interpret and could be summarized more compactly.\n\n### Technical Oversights\n\nThe argument in lines 196–200 incorrectly suggests that PATE requires a majority agreement for the noisy argmax to function.\nIn fact, differential privacy mechanisms (e.g., DP selection or GNMax) do not rely on majority consensus; the probability of selection depends on the noise scale.\n\nThere is no formal privacy accounting for the similarity-based filtering or dynamic teacher selection. Coceptually it can be viewed as part of the voting, but this requires some care.\n\n## Overall Assessment\n\nThe paper explores a potentially useful engineering variation on PromptPATE (for classification tasks) but lacks sufficient novelty or theoretical analysis to constitute a research advance worthy of ICLR standards."}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CLMYbS1GJR", "forum": "rClVHcVUgT", "replyto": "rClVHcVUgT", "signatures": ["ICLR.cc/2026/Conference/Submission16372/Reviewer_kEPk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16372/Reviewer_kEPk"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16372/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761958047669, "cdate": 1761958047669, "tmdate": 1762926495418, "mdate": 1762926495418, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper targets privacy-preserving knowledge transfer for commercial large language models with inaccessible parameters, addressing the high cost and ensemble inconsistency of existing PATE methods. The authors propose PATEin, an adaptive framework that first queries the top two teachers identified by embedding similarity. If these two teachers agree, their label is used, avoiding a costly full ensemble query. If they disagree, the system falls back to a standard, differentially private ensemble aggregation. Experiments show PATEin outperforms baselines like PromptPATE in labeling accuracy across multiple C-LLMs and datasets, while significantly reducing API token cost (up to 22x), thus making private transfer more practical."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well-structured. The abstract and introduction clearly state the problem, challenges, and solution. This setting has practical value as it aims to use adaptive queries to reduce the API cost in using PromptPATE with closed LLMs."}, "weaknesses": {"value": "1.  The method relies on embedding similarity to find the optimal teachers. As a result, the robustness and effectiveness of the proposed method heavily rely on the selection of the embedding model.\n2. PATEin requires building a similarity matrix between all teachers and all public data, which is potentially computationally expensive. I encourage the authors to be upfront about this potential bottleneck."}, "questions": {"value": "1. The effect of cost saving depends on the fallback rate. How does this rate vary across datasets?\n2. Table 4 seems to suggest a very high fallback rate under an adversarial teacher. Does this suggest the adaptive query method is not robust?\n3. How scalable is the teacher selection step to even larger public datasets?\n4. Could the distribution shift between public and private data influence the teacher fallback?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pGOorih08t", "forum": "rClVHcVUgT", "replyto": "rClVHcVUgT", "signatures": ["ICLR.cc/2026/Conference/Submission16372/Reviewer_b2Lr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16372/Reviewer_b2Lr"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16372/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971901689, "cdate": 1761971901689, "tmdate": 1762926494059, "mdate": 1762926494059, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}