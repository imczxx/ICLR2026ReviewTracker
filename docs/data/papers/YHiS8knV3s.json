{"id": "YHiS8knV3s", "number": 9840, "cdate": 1758143253625, "mdate": 1759897692554, "content": {"title": "Discovery of Diverse and Realistic Financial Tail-Risk Using Generative Flow Networks", "abstract": "Accurate modeling of rare high-impact financial events is essential for robust risk management, but existing methods face notable challenges. Sampling-based techniques like Sequential Markov Chain Monte Carlo generate diverse scenarios but often lack focus on specific high-risk outcomes, leading to inefficient exploration. In contrast, Deep Reinforcement Learning methods optimize sequential decision-making effectively but tend to converge on a narrow set of high-reward scenarios, limiting diversity. To address these shortcomings, we propose using Generative Flow Networks (GFlowNets), which naturally learn to sample according to a predefined reward distribution. Our approach systematically generates diverse and realistic tail-risk scenarios by explicitly defining rewards that prioritize high-risk, impactful financial scenarios. Experiments on real-world financial data show that our GFlowNet-based method significantly enhances scenario diversity and realism, effectively capturing the complex nonlinear dependencies typical of financial markets. These findings demonstrate the potential of GFlowNets as a robust framework for financial risk modeling, offering actionable insights into rare but critical market events.", "tldr": "We apply GFlowNets to the exploration of large continuous state spaces, demonstrating our approach's capabilities by discovering financial risk scenarios.", "keywords": ["GFlowNets", "risk analysis"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4a7dd23439c2271be85dd49bdefbaf4a4363b2e7.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces GRID, a method based on Generative Flow Networks (GFlowNets), for discovering diverse and realistic financial tail-risk scenarios. The authors present this as a sequential decision-making problem where a GFlowNet policy is trained to sample trajectories of macroeconomic variables. The sampling process is guided by a reward signal provided by a pre-trained ‚ÄúOracle‚Äù model, which aims to sample trajectories in proportion to their predicted risk, specifically large negative S&P 500 returns. The paper claims that this approach offers a superior trade-off between scenario diversity and risk-severity discovery compared to standard Reinforcement Learning (RL) or MCMC baselines.\n\n\nSoundness\nThe central claims of the paper are not adequately supported by the evidence, and the research methodology appears to be unsound. The paper's effectiveness depends substantially on the quality of the Oracle-provided reward signal. However, the paper's own evidence (Table 2) reports negative R¬≤ values for the Oracle, indicating its predictions are worse than a trivial mean-baseline. This makes it difficult to validate the value of the reward signal, making subsequent experimental results uninterpretable. Furthermore, using two different Oracles for training and testing is a non-standard approach that complicates the comparison.\n\nPresentation\nThe paper is generally well-written, but the presentation of the core methodology is confusing and omits important information. The experimental setup involving two different Oracles is not convincingly justified, and the performance metrics for the main (test-time) Oracle are not presented. This makes it difficult for the reader to validate the experiment and assess the reliability of the results.\n\nContribution\nWhile the idea of applying GFlowNets to risk discovery is novel and well-motivated, the paper's execution does not provide a sound or convincing validation. Due to fundamental issues in the experimental setup, particularly the unvalidated reward signal and the non-standard train/test mismatch, the evidence presented is insufficient to substantiate the claimed contributions. The results are difficult to interpret and as seen in the Q90 metric, do not show a clear or consistent advantage over the baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "‚Ä¢\tSignificant Problem: The paper addresses a highly significant and challenging problem: the discovery of diverse, high-impact tail risks, which is a known limitation of standard financial modeling.\n‚Ä¢\tNovel Problem Formulation: The conceptual framing of risk discovery as a reward-proportional sampling problem (via GFlowNets) rather than a reward-maximization problem (via standard RL) is a strong theoretical fit for the domain and represents a promising research direction."}, "weaknesses": {"value": "1.\tProblematic Setup: Questionable Reward Signal. The paper's entire methodology depends on the Oracle's quality, as the authors state: \"its effectiveness depends on oracle quality. (Line 481)\" However, the performance reported for the training Oracle in Table 2 includes R¬≤ values of -0.4762 and -0.8638. A negative R¬≤ value, by definition means the model's predictions are worse than a trivial baseline like naive mean. This suggests that the reward signal could be uncorrelated with the real-world outcome it claims to represent and potentially training the agents to optimize noise.\n2.\tConfusing Two-Oracle Methodology. The authors state they use a simple MLP Oracle for training and a different ensemble Oracle for testing (evaluation). This is not standard practice and introduces problems:\no\tTrain/Test Skew: It is likely to introduce a distributional shift in the objective function itself. The agent is optimized to find scenarios that exploit one reward model (the MLP) and then evaluated on its ability to find scenarios that score well on a different reward model (the ensemble).\no\tUninterpretable Results: This makes the results in Table 3 uninterpretable. We do not know if GRID's performance is due to its superior risk-finding ability or its incidental ability to generalize from the training MLP Oracle to the (unknown) ensemble, better than the RL baselines.\no\tNotable Omission: The paper provides no performance metrics (R¬≤, RMSE, MAE) for the test-time ensemble Oracle. Without validating the actual reward function used for evaluation, the results are unverifiable.\n3.\tEmpirical Results Do Not Demonstrate Clear Superiority.\no\tEven if (charitably) ignoring the confusing Oracle, the data in Table 3 does not show a clear win for GRID. The paper's core claim is to find tail-risk, but on the Q90 (extreme tail) metric, RL baselines outperform GRID in 2 of 3 scenarios (REINFORCE in 2002, SAC in 2008). While GRID does show strong performance on median reward and diversity (in 2008 & 2021), it fails to consistently win on the primary metric of extreme tail-risk (Q90) and this significantly weakens its central claims.\n4.\tUndersupported Methodological Claims. The paper proposes novel technical components (e.g., the dynamic mixture model) with claims that they \"improve trajectory diversity\" but lacks ablation studies or empirical evidence to further support these design choices."}, "questions": {"value": "1.\tCould the authors please elaborate on the negative R¬≤ values in Table 2? Given that this metric indicates the model is worse than a mean predictor, how can this Oracle be considered a valid source of \"realistic\" reward signals for training?\n2.\tCould the authors provide a stronger justification for the train/test Oracle mismatch? Could they also please provide the full performance metrics (R¬≤, RMSE, MAE) for the ensemble Oracle that was used for the main evaluation in Tables 3 & 4?\n3.\tHow do the authors justify their narrative of superiority in tail-risk discovery with the empirical results in Table 3, which show that RL baselines (REINFORCE and SAC) found higher-reward tail-risk scenarios (Q90) in two of the three evaluated periods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RPvJGSOqgq", "forum": "YHiS8knV3s", "replyto": "YHiS8knV3s", "signatures": ["ICLR.cc/2026/Conference/Submission9840/Reviewer_jQia"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9840/Reviewer_jQia"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9840/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761832043199, "cdate": 1761832043199, "tmdate": 1762921317983, "mdate": 1762921317983, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General comment to reviewers regarding R2 performance"}, "comment": {"value": "We thank all reviewers for their thoughtful feedback regarding Oracle R¬≤ performance. Multiple reviewers raised concerns about negative R¬≤ values and questioned how GFlowNets trained on \"unreliable\" rewards could discover realistic scenarios. We address these fundamental concerns below.\n\n**Understanding R¬≤ in Financial Prediction Context**\nOur Oracle achieves R¬≤ values of -0.48, 0.09, and -0.86 across the three crises (Table 2). While negative R¬≤ indicates predictions worse than a constant mean baseline on held-out data, this metric must be interpreted in context. Financial market prediction, particularly for 12-month S&P 500 returns during crisis periods, is fundamentally challenging due to nonlinearity, regime changes, and the inherent unpredictability of tail events. Our Oracle's MAE values (2.92-12.81) demonstrate meaningful signal despite limited variance explanation. \n\nMore importantly, R¬≤ measures unconditional variance explanation and is not necessarily indicative of a model's utility. In Hou et al. (2013) [1], the authors prove theoretically that in rational models, R¬≤ is independent of how much information is incorporated into predictions: ‚Äúthe return R¬≤ is independent of the amount of information available‚Äù. Moreover, low R2 values are common in relevant academic literature. Studies published in top tier journals in the fields of finance and asset pricing report R2 values similar to ours, and sometimes even lower [2].\n\n**Imperfect Oracles: Core GFlowNet Design Principle**\nThe reviewers' concerns do not take into account a major aspect of GFlowNet methodology. GFlowNets were explicitly designed to operate with imperfect reward proxies. This is not a limitation of our work - it is the central motivation for using GFlowNets.\n\nAs stated in the GFlowNet Foundations paper (Bengio et al.,[3]): \"In contexts where a cheap proxy for the true reward function exists, GFlowNets have been used to surface samples under which to query the proxy before more expensive evaluation under the true reward function. In these settings, the diversity of samples generated by GFlowNets can be used for robustness to proxy misspecification\".‚Äã\n\nIn  [4], the authors explicitly note that GFlowNets are valuable \"especially in scenarios of very large candidate spaces where we have access to cheap but inaccurate measurements or too expensive but accurate measurements\". This directly describes our financial forecasting setting.‚Äã\n\nThe original NeurIPS 2021 paper introducing GFlowNets [5] states: \"Diversity of the generated candidates is particularly important when the oracle is itself uncertain, e.g., it may consist of cellular assays which is a cheap proxy\". Furthermore, the paper demonstrates \"the ability to capture the modes, even in the absence of the true oracle\". \n\nThe work of [6] explicitly addresses imperfect oracles: \"Diverse candidates capturing the modes of the imperfect oracle improve the likelihood of discovering a candidate that can satisfy all (or many) evaluation criteria\"\n\n**Why GFlowNets Succeed Where RL Fails**\nUnlike reinforcement learning methods that maximize expected reward and thus over-exploit Oracle predictions, GFlowNets sample proportionally to reward. This fundamental difference is critical: RL agents trained on noisy oracles converge to exploit spurious high-reward modes, while GFlowNets maintain broad exploration that discovers scenarios the Oracle may undervalue. This is precisely why our REINFORCE and SAC baselines, despite using the identical Oracle, achieve lower median performance and collapse to narrow solution sets (Figure 2, Table 3).\n\nWe updated our submission to better explain these important points.\n\n[1] Hou, Kewei, Lin Peng, and Wei Xiong. Is R-squared a measure of market inefficiency?. 2013.\n\n2] Kelly, Bryan, and Seth Pruitt. Market expectations in the cross‚Äêsection of present values. The Journal of Finance, 2013\n\n[3] Bengio, Yoshua, et al. \"Gflownet foundations.\" JMLR, 2023\n\n[4] Jain, Moksh, et al. \"Gflownets for ai-driven scientific discovery.\" Digital Discovery, 2023\n\n[5] Bengio, Emmanuel, et al. \"Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation.\" NeuRIPS, 2021\n\n[6] Jain, Moksh, et al. \"Biological sequence design with gflownets.\" ICML, 2022."}}, "id": "FjVC8h0Q54", "forum": "YHiS8knV3s", "replyto": "YHiS8knV3s", "signatures": ["ICLR.cc/2026/Conference/Submission9840/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9840/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9840/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763632950972, "cdate": 1763632950972, "tmdate": 1763637530129, "mdate": 1763637530129, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes GRID, a generative flow networks (GFlowNets)-based method to discover diverse macro-financial tail-risk scenarios. GRID samples trajectories by predicting specific parametric distributions for each macro-variable. Training utilizes trajectory balance so that scenarios are sampled proportional to an oracle-defined terminal reward. The experiments on three crisis periods report good diversity-quality tradeoffs vs SMCMC and RL baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear problem framing: Tail-risk discovery with explicit reward shaping toward adverse outcomes, not just one worst case.\n\n2. GFlowNet fit: proportional-to-reward sampling naturally encourages multi-modal coverage.\n\n3. Continuous-state design: Nice engineering to let different variables use specific distributions.\n\n4. Evaluation and analysis: Basic risk management metrics, trajectory and terminalstate distance metrics are reported, and the comparison result achieves a good balance between generation quality and diversity."}, "weaknesses": {"value": "1. Oracle dependence: Heavy dependence on an oracle model whose out-of-sample ùëÖ2 is negative on two of the three crisis windows; this weakens the claim that discovered scenarios are financially risky rather than artefacts of the predictor.\n\n2. Realism checks are light: The paper does impose per-step bound to retain plausibility, but this is still weaker than evaluating or checking stylized facts and cross-variable co-movement that ‚Äúrealistic‚Äù in the title would suggest.\n\n3. Reward inconsistency: Table 3 states rewards are clipped at 100, but later figures show > 100. It is unclear at which stage clipping is applied and whether all methods use the same rule. The oracle‚Äôs predicted negative return exceeding 100 also raised some concerns.\n\n4. Evaluation metrics are narrow: Since the paper is explicitly positioned for stress/scenario analysis, reporting more tail coverage metric like CVaR and tail frequency of generated paths would strengthen the results and aligned with standard risk practice.\n\n5. Editorial and notation issues/confusions: Some typos remain, e.g. ‚Äúmeasure he financial losses‚Äù in line 355; The figure 3 in the appendix has a zero score for normalized diversity score for the third subplot."}, "questions": {"value": "1. With negative ùëÖ2 on two crises, why trust the oracle‚Äôs sign/magnitude for tail rewards?\n\n2. How to evaluate the ‚Äúrealistic‚Äù of the generated path? Can you show that GRID meet the basic variable dynamics (e.g. VIX‚Üë S&P‚Üì) in generated trajectories?\n\n3. In 4.1, the paper claims the initial state ‚Äúbegins at a specified macroeconomic state‚Äù. Please clarify the determination of the specified state.\n\n4. Please clarify Eq. (5). If using a unimodal proxy for mixtures, why this specific variance form?\n\n5. Why rank-select top-K for SMCMC but sample for GRID/RL?\n\n6. How sensitive are results to the per-step change bounds? Can you provide ablations like looser/tighter bounds or bounds derived from crisis windows?\n\n7. Claiming: Given small variable set and monthly granularity, what exactly is meant by ‚Äúfirst to apply GFlowNets to large continuous state spaces‚Äù."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "kHNxZpv3n6", "forum": "YHiS8knV3s", "replyto": "YHiS8knV3s", "signatures": ["ICLR.cc/2026/Conference/Submission9840/Reviewer_PPUF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9840/Reviewer_PPUF"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9840/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761921641519, "cdate": 1761921641519, "tmdate": 1762921317624, "mdate": 1762921317624, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper describes a method to generate diverse samples for risk management in finance applications. The method is based on well-studied GFlowNet."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper is written reasonably well, it's easy to follow. \n2. The proposed method may have other potential applications to other broad areas."}, "weaknesses": {"value": "1. The proposed method is based on a GFlowNet: the level of novelty is limited.\n2. Better exposition of the financial market application would benefit broader audience"}, "questions": {"value": "1. Perhaps it's obvious to the authors, but many readers of ICLR may not fully understand the key issues in the financial market applications. A brief description of the variables involved would be a big plus.\n2. The authors didn't explain how important the performance of the *oracle* model is.  Based on Tab 2, if the oracle model fails to capture the three extreme events, how would the GRID perform? \n3. Again related to the oracle model, what is the rationale of having MLP and model ensembles in the training and testing phase? Should an ablation study be conducted?\n4. Tab 3, it's hard to comprehend GFlowNet does well, when it underperforms SMCMC by 100% for 2021 event! \n5. Same argument can be made for Table 4\n6. Figure 2, what is the desirable behavior? \n7. Since the goal is to sample extremely rare events, should $Q99$ be used instead of $Q90$ (line 422)? I would argue that even $Q99$ may not reflect the extremely rare events."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "QfPTwxieiK", "forum": "YHiS8knV3s", "replyto": "YHiS8knV3s", "signatures": ["ICLR.cc/2026/Conference/Submission9840/Reviewer_627W"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9840/Reviewer_627W"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9840/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761951583907, "cdate": 1761951583907, "tmdate": 1762921317338, "mdate": 1762921317338, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces GRID, a GFlowNet-based method for discovering diverse and realistic financial tail-risk scenarios. Unlike sampling methods (SMCMC) that explore broadly but inefficiently, or deep RL methods (REINFORCE, SAC) that converge to narrow high-reward modes, GFlowNets learn to sample trajectories proportionally to their risk rewards, naturally balancing diversity and impact. The key innovation is successfully applying GFlowNets to large continuous state spaces by using flexible, feature-specific distribution families (Gaussian mixtures, Beta distributions) for modeling macroeconomic variables. Experiments on three major financial crises (2002, 2008, 2021) show GRID generates more diverse high-risk scenarios than baselines, achieving top median rewards in 2/3 cases and superior 90th-percentile performance. The method enables effective stress testing by systematically discovering multiple plausible pathways to market crashes, rather than just finding the single worst-case scenario."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper redefines financial tail-risk discovery as a proportional sampling problem rather than an optimization problem, which is a conceptual innovation. Technically, it is the first to successfully apply GFlowNets to large-scale continuous state spaces, breaking through the previous limitation to discrete domains only. Particularly clever is the design of using heterogeneous distribution families for different environmental variables (Beta for VIX, Gaussian mixtures for interest rates). This feature-aware modeling is unprecedented in the GFlowNet literature and provides new insights for multi-variable modeling in scientific domains.\n\n2. The experimental design is excellent: testing on three real financial crises with strict temporal splits ensuring no data leakage (Oracle trained only on pre-crisis data). Baseline selection covers classical probabilistic methods (SMCMC) and modern deep RL (REINFORCE, SAC). The dual evaluation framework‚Äîreward metrics (median, Q90) and diversity metrics (DTW trajectory distance, terminal-state Euclidean distance)‚Äîprovides a comprehensive perspective. The normalized diversity score (Equation 9) reveals that SAC's apparent diversity actually stems from instability rather than true exploration. Using an ensemble Oracle (4 models) during testing while training with a single MLP effectively prevents overfitting. Each method undergoes 30 independent runs with 6,000 trajectories total, demonstrating strong statistical robustness.\n\n3. Addresses a critical practical problem: tail-risk events cause enormous losses (2008 GFC exceeded $10 trillion), yet traditional VaR models systematically underestimate their probability. The multimodal distribution shown in Figure 2c perfectly illustrates the value of diversity: multiple distinct pathways can lead to market crashes (liquidity crisis vs. inflation shock), and risk management requires stress testing against all pathways. The method's output of 200 diverse crisis trajectories can be directly used for portfolio stress testing and hedging strategy development."}, "weaknesses": {"value": "The most serious weakness of this paper is its strong dependence on Oracle model quality, while Oracle itself performs poorly. Table 2 shows alarming Oracle performance across three scenarios: 2002 ($R^2 = -0.4762$, a negative value means worse than predicting the mean), 2008 ($R^2 = 0.0942$, almost no predictive power), and 2021 ($R^2 = -0.8638$, severe failure). This creates a fatal circular reasoning problem: if the Oracle cannot accurately predict market crashes, how can a GFlowNet trained on Oracle rewards possibly discover realistic tail-risk scenarios? The reward function $R(s_T) = \\max(0, -\\mathcal{O}(s_T))$ becomes meaningless when $\\mathcal{O}(s_T)$ is unreliable, and the entire sampling distribution $P_F(x) \\propto R(x)$ is essentially learning from incorrect targets. The paper claims to generate \"realistic\" scenarios but provides no validation against actual historical crisis trajectories or ground truth. The high-reward distributions may simply be overfitting to the Oracle's erroneous predictions rather than capturing genuine financial risk patterns."}, "questions": {"value": "This is very good work. I believe your experimental results are credible, and I think this paper is recommended to be accepted. However, if I still cannot obtain the experimental code to reproduce the results by myself during the rebuttal phase, I may have to consider lowering the score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "kcZ84NZkh9", "forum": "YHiS8knV3s", "replyto": "YHiS8knV3s", "signatures": ["ICLR.cc/2026/Conference/Submission9840/Reviewer_iZtM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9840/Reviewer_iZtM"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9840/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995697360, "cdate": 1761995697360, "tmdate": 1762921316904, "mdate": 1762921316904, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}