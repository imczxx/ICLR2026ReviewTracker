{"id": "qYVa1obqTZ", "number": 3825, "cdate": 1757538113575, "mdate": 1759898068124, "content": {"title": "Neural Modular Physics for Elastic Simulation", "abstract": "Learning-based methods have made significant progress in physics simulation, typically approximating dynamics with a monolithic end-to-end optimized neural network. Although these models offer an effective way to simulation, they may lose essential features compared to traditional numerical simulators, such as physical interpretability and reliability. Drawing inspiration from classical simulators that operate in a modular fashion, this paper presents Neural Modular Physics (NMP) for elastic simulation, which combines the approximation capacity of neural networks with the physical reliability of traditional simulators. Beyond the previous monolithic learning paradigm, NMP enables direct supervision of intermediate quantities and physical constraints by decomposing elastic dynamics into physically meaningful neural modules connected through intermediate physical quantities. With a specialized architecture and training strategy, our method transforms the numerical computation flow into a modular neural simulator, achieving improved physical consistency and generalizability. Experimentally, NMP demonstrates superior generalization to unseen initial conditions and resolutions, stable long-horizon simulation, better preservation of physical properties compared to other neural simulators, and greater feasibility in scenarios with unknown underlying dynamics than traditional simulators.", "tldr": "This paper presents Neural Modular Physics, a thorough modular framework for elastic simulation, enabling better generalization and stable long-horizon simulation.", "keywords": ["Neural Simulation", "Neural Modular Networks", "Elastic Dynamics", "learned simulation"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1abe3390be3b3dcaff19fd3f6632731c05189a5a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper Neural Modular Physics for Elastic Simulation , introduces a fully modular neural simulator for elastic dynamics. This represents a new direction relative to the monolithic, end-to-end neural simulation paradigms (NO, GNN) and hybrid simulators that replace partial components demonstrated through a complete modular neural architecture that mirrors traditional finite element method (FEM) computation flows. The approach enables direct supervision of intermediate physical quantities and interchangeable traditional-numerical and neural components, which is a novel result in the neural simulation literature. The contribution of this paper lies more in systematic integration and training methodology (the two-stage modular physics training) than in the individual components.\nGiven the surge of interest in physics-informed ML, differentiable simulation, and scientific machine learning. The paper addresses a key pain point of neural simulators—lack of interpretability and physical soundness—making it relevant to computational physics and graphics communities as well. The papers focus on elastic simulation is narrower than universal PDE solvers, but serves as an excellent proof-of-concept domain."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Concept: \nThe paper provides a fairly new approach to learning-based, physically interpretable simulation approach that modularizes elastic dynamics into neural subcomponents aligned with traditional numerical solvers. The idea of decomposing physics simulation into learnable yet interpretable modules, supervised via intermediate physical quantities, represents a meaningful conceptual and architectural advance.\nWhile the idea of combining neural networks with modular solvers has appeared before the innovation lies more in systematic integration and training methodology (the two-stage modular physics training) than in the individual components.\n2. Practicality/Application:  \nWhen combining neural networks with physics-based modular solvers, one of the hardest problems is ensuring boundary condition consistency between modules that are partly data-driven and partly physically constrained. In hybrid or modular networks, each subnetwork (e.g., constitutive law, integrator) may implicitly assume slightly different boundary behavior, leading to inconsistencies at their interfaces — this is known as a boundary-condition coupling error.  The NMP framework proposes to address this through architectural and Training level strategies.  The Neural Integration Module preserves the same interface as an implicit FEM integrator but replaces the internal update terms with a neural network. After the neural update, boundary condition enforcement and collision handling are explicitly re-applied.  \nHence, NMP preserves:\nDirichlet BCs \nNeumann BCs\nContact constraints\nThis design ensures neural predictions remain compatible with traditional BC enforcement — solving the “boundary leakage” problem found in prior hybrids\n3. Results: Published results show improved performance over top baselines as well as improved stability (reduced collapse) \n4. Generalizability: is demonstrated against unseen initial conditions and higher mesh resolutions. \n5. Evidence: The SPOT and BOB experiments are specifically designed to test BC handling\nSPOT: multiple fixed boundary points (head and tail)\nBOB: fixed vertices (head) and free elastic regions"}, "weaknesses": {"value": "1. Practicality/Application:  solution process and validation\nComputational cost and scalability are not discussed (e.g., time vs. FEM or other neural simulators). This is a critical metric to be evaluated.\nLack of error analysis: No discussion on failure modes or interpretability visualization for intermediate variables.  This is also critical for real world applications on elastic body problems. \n2. Results: are limited to non real world elastici body  FEM problems  \n3. Generalizability: is limited to elastic solids only. Extensions to fluids or multi-physics are not shown and this gap is acknowledged by the authors.  \n4. Evidence and support: the following weaknesses exist:\nNo ablations on module architecture: How sensitive is performance to neural constitutive/integration model complexity?\nLimited physics validation metrics: Energy conservation, stress-strain correlation, or physical invariants could further substantiate realism.\n\nWriting clarity:\nline 121 -\"dynamics on top of analytical dynamics to account for unmodeled\" ... is an incomplete sentence\nline 135: \"In this paper, we notice the internal modularity\". ... please fix\nline 141: \"As aforementioned,\" --> as mentioned earlier ?\nline 160 : \"derives two disentangled modules\" --> two decoupled ?\nline 182: \"with vertice position\" --> vertex position ?\nline 329: Transolver (?). --> what is the \"? \" provide citation, Wu ?"}, "questions": {"value": "Please address the following practical issues \n1. Discuss time to converge relative to traditional solvers on a real world engineering problem if possible\n2. discuss error analysis and boundary condition matching\n 3. provide more evidence on physics validation metrics: Energy conservation, stress-strain correlation, or physical invariants could further substantiate realism."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Qe15gl9g84", "forum": "qYVa1obqTZ", "replyto": "qYVa1obqTZ", "signatures": ["ICLR.cc/2026/Conference/Submission3825/Reviewer_b4yZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3825/Reviewer_b4yZ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3825/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761766648026, "cdate": 1761766648026, "tmdate": 1762917052570, "mdate": 1762917052570, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a hybrid-physics architecture and training method that achieves better physical consistency and generalizability than traditional simulators and neural models for elastic physics rollout. The modular design for elastic physics is inspired by the FEM method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The experiments provide good empirical evidence that their NMF model has better long term rollout performance for both seen and unseen scenarios in comparison to the baselines.\n- Their NMF model allows the addition of soft physics constraints in a fairly straightforward way.\n- The paper provides a thorough explanation of their modular model design and reasoning."}, "weaknesses": {"value": "- The architecture is specialized for elastic physics, which will not generalize to other equations and setttings. However, I acknowledge the idea of replacing components of a simulator with neural modules is an interesting idea.\n- The paper proposes a way to replace parts of an FEM method with neural networks, but this is not straightforward to apply to other types of solver schemes such as finite difference methods and spectral methods.\n- The strain-displacement matrix is required a priori to use the NMF model."}, "questions": {"value": "- Do you plan to release the code for your model training and simulations?\n- What are the costs in terms of flops and time of the NMF model inference vs the simulator used to generate ground truth trajectories?\n- Since the neural constitutive model requires the $B_e$ matrix and $V_e$ values to work, do you provide these in your test scenarios to the model? Is the $B_e$ term easy to derive in some way or should it also be learned?\n- How do you determine when to stop the separate training phase for each module? Do you train for a fixed number of steps or use some other condition for stopping?\n- You use a regularization constant of 0.1 for the volume loss term you add during joint training. How did you select this value? What happens if you increase it to make the physical constraint stronger? Does the overall trajectory become more physically plausible or does your model fail to learn due to the difficulty of satisfying this constraint?\n- There are few typos I noticed in the paper that can be corrected:\n  - Line 121: \"Examples include learned data-driven discretization stencils (Bar-Sinai et al., 2019) and learned residual\ndynamics on top of analytical dynamics to account for unmodeled (Yin et al., 2021).\" Maybe you want to write unmodeled dynamics?\n  - Line 211: \"Still start from classical FEM.\" Rewrite this to be a more clear introductory sentence.\n  - Line 424: \"With out the elaborative physical-aligned architecture and specialized training strategy in NMP, we cannot release the unique benefits of modularization.\" I think you mean to write \"we cannot realize\" instead of \"we cannot release\"."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "o4vAX1vFNg", "forum": "qYVa1obqTZ", "replyto": "qYVa1obqTZ", "signatures": ["ICLR.cc/2026/Conference/Submission3825/Reviewer_ZLNW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3825/Reviewer_ZLNW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3825/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926034192, "cdate": 1761926034192, "tmdate": 1762917052277, "mdate": 1762917052277, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper propose an neural simulator framework for elastic simulation. The framework follows closely the traditional FEM simulation pipeline, with two modules replaced by neural networks: per-element Piola–Kirchhoff stress tensors computation and per-vertex velocity increment computation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The overall presentation is clear."}, "weaknesses": {"value": "- The framework seems just a replication of some groundtruth FEM simulation method. In separate trainings for each module, it seems that the groundtruth constitutive model law and the groundtruth time integration are both available. The two groundtruth pieces are basically all you need to implement the whole simulation in the traditional way. I am concerned about the motivation of the method: if you need to implement the whole traditional pipeline to get groundtruth, why bother replacing modules with neural networks? Are there any applications beyond replication?\n\n- The framework seems not applicable on real data. The assumption of known per-vertex internal forces is not practical in reality.\n\n- The framework seems to only work for interactions between single objects and a fixed environment. \n    - The contact information, especially the offset of the ground plane, is stored in time integration network. Updated ground plane offset may not work. \n    - And I don't think the neural time integration can work for multiple objects. The neural modeling of time integration is not aware of other objects."}, "questions": {"value": "- How to make sure when F is a rigid transformation, the stress is zero? A unit test may need to make sure the simulation can maintain its rest shape forever if there is no external force."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "7PyFV7ev33", "forum": "qYVa1obqTZ", "replyto": "qYVa1obqTZ", "signatures": ["ICLR.cc/2026/Conference/Submission3825/Reviewer_BcK5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3825/Reviewer_BcK5"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3825/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762132280137, "cdate": 1762132280137, "tmdate": 1762917052039, "mdate": 1762917052039, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes to use data-driven methods to replace the traditional solvers in the elastic simulation. The experiments show the effectiveness of the proposed method, leading to low errors and stable long-horizon stability. The experiments also show the proposed method is better for unseen conditions or inputs. Another contribution is that since the proposed method supervises the intermediate variables, it means the proposed method can use physics knowledge as contraints."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is easy to follow and well organized.\n2. This paper evaluates their method from multiple aspects: 1. Comparison with neural operator based baselines. 2.  Joint training versus separate training. 3. Comparison with physics simulator. 4. Inference by combining with traditional simulators. 5. Comparison with no direct physical constraint included."}, "weaknesses": {"value": "1. The biggest weakness is that the proposed method is just substituting the immediate two steps that are done by traditional methods with data-driven methods. Thus, novelty is the biggest issue to me. Besides, the neural constitutive step is following the existing paper.\n2. Another contribution claimed by the authors is the separate training plus joint training. From what I understand, this training method was also proposed in the existing work to solve the “collapse” issue, which is also not new.\n3. For the experiments, the authors compare it with purely data-driven methods. However, their method uses physics. I don’t think the experiments are good enough for showing the advantages of their methods. For example, they should compare with the traditional methods and we can see the gap when physics is used for both methods.\n4. It will be good to see the advantages/disadvantages of the methods including baselines in terms of inference time.\n5. The method is only tested on the specific problem, which means the scope is limited."}, "questions": {"value": "1. For strengthening the experiments, do the authors think the baselines can augment with physics knowledge?\n2. What is the error for predicting just one step forward for each method?\n3. For baselines, have you tried non-autoregressive prediction, e.g., directly predicting all the following 100 steps."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5BjNXlFUkg", "forum": "qYVa1obqTZ", "replyto": "qYVa1obqTZ", "signatures": ["ICLR.cc/2026/Conference/Submission3825/Reviewer_7hFZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3825/Reviewer_7hFZ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3825/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762185224077, "cdate": 1762185224077, "tmdate": 1762917051548, "mdate": 1762917051548, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}