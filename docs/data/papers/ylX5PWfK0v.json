{"id": "ylX5PWfK0v", "number": 11616, "cdate": 1758202519580, "mdate": 1763716009587, "content": {"title": "Incorporating Expert Priors into Bayesian Optimization via Dynamic Mean Decay", "abstract": "Bayesian optimization (BO) is a powerful approach for black-box optimization, and in many real-world problems, domain experts possess valuable prior knowledge about promising regions of the search space. However, existing prior-informed BO methods are often overly complex, tied to specific acquisition functions, or highly sensitive to inaccurate priors. We propose DynMeanBO, a simple and general framework that incorporates expert priors into the Gaussian process mean function with a dynamic decay mechanism. This design allows BO to exploit expert knowledge in the early stages while gradually reverting to standard BO behavior, ensuring robustness against misleading priors while retaining the exploratory behavior of standard BO. DynMeanBO is broadly compatible with acquisition functions, introduces negligible computational cost, and comes with convergence guarantees under Expected Improvement and Upper Confidence Bound. Experiments on synthetic benchmarks and hyperparameter optimization tasks show that DynMeanBO accelerates convergence with informative priors and remains robust under biased ones.", "tldr": "We introduce DynMeanBO, a simple and general BO framework that dynamically incorporates expert priors, ensuring both faster convergence and robustness to inaccurate knowledge.", "keywords": ["Bayesian optimization", "Gaussian processes", "Expert prior knowledge", "Hyperparameter optimization"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7f50150174ff0a9296262702888f6e4638b0538a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces Dynamic Mean Bayesian Optimization (DynMeanBO) that incorporates expert priors into the Gaussian process mean function with a dynamic decay mechanism. Expert priors are modeled as probability distributions over the likely location of the global optimum. The dynamic decay mechanism is introduced to handle potential bias from bad priors. This approach is lightweight, compatible with arbitrary acquisition functions (AFs). Theoretical analysis provides convergence guarantees: DynMeanBO-EI and DynMeanBO-UCB. Experiments evaluate DynMeanBO on synthetic functions and hyperparameter optimization (HPO) tasks, using \"good\" and \"bad\" Gaussian priors. The proposed method accelerates convergence with informative priors, remains robust to misleading ones, and outperforms baselines like πBO and ColaBO."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper addresses a practical gap in prior-informed BO by integrating priors directly into the GP mean function in a principled way, rather than heuristically modifying AFs or kernels. The dynamic decay is a clever, simple mechanism that balances exploitation of priors early on with robustness later.\n2. The paper provides solid convergence proof for EI and UCB, extending standard results to the dynamic mean setting.\n3. The writing is clear. Figures are helpful, and appendices are referenced for details."}, "weaknesses": {"value": "1. The proposed method relies exclusively on GPs, which may not extend easily to other surrogates like random forests or neural networks used in modern BO.\n2. Parameters like the decay rate, scaling/shift, and initial points could be sensitive, but tuning guidance is minimal. In bad prior cases, if decay is too slow, bias might persist. Thus, empirical ablation would help."}, "questions": {"value": "Please see the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YXwJnGQmp8", "forum": "ylX5PWfK0v", "replyto": "ylX5PWfK0v", "signatures": ["ICLR.cc/2026/Conference/Submission11616/Reviewer_xfoY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11616/Reviewer_xfoY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11616/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761789807634, "cdate": 1761789807634, "tmdate": 1762922688832, "mdate": 1762922688832, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors claim to contribute:\n- A lightweight framework to incorporate expert priors into the GP mean function and decay it toward standard BO behavior, so that the resulting method can take advantage of a good prior but be robust to a bad one\n- Convergence guarantees under EI and UCB acquisitions\n- DynMeanBO performs comparably to existing methods that use a prior in good/bad prior case, but is much more computationally efficient because it only uses the prior in the GP mean function."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- Paper is well-organized and the main ideas and contributions concisely laid out. The background is thorough. The related works is thorough and motivates their method well. The method is simple and articulated clearly. \n- DynMeanBO is substantially faster than MCpi (~10x?), and a little bit faster than PiBO. It would be good to know exactly how much faster it is than each method (perhaps write in the text or caption).\n- DynMeanBO seems roughly comparable to PiBO and MCpi, though those methods seem to perform a little better in general, but is more computationally efficient (Fig. 4). It might be more informative to fix the total computation time to some budget, and then show regret for the more expensive methods, which may be able to take many fewer queries, with compute time as the x-axis. It seems generally better than PiBO and MCpi when a bad prior is given (Fig. 6). I’d also be curious to see what happens when a really bad prior is given (e.g., strong and in a place pretty far from the optimum) — does DynMeanBO still recover, or does it perform much worse than using regular BO?"}, "weaknesses": {"value": "- The prior is only incorporated into the GP mean function, though it seems desirable that it affect the covariance matrix too. It seems previous works have tried this and so far found it computationally expensive or unstable, though.\n- The method seems relatively simple, which is not necessarily a bad thing, but I’m unsure if it constitutes a substantive contribution to the BO community.\n- The regret results are not super impressive, though the method is much faster to run. It seems like this would be useful in certain BO cases, but it’s not totally clear to me how important this kind of work is, since BO typically deals with cases where querying the objective function is pretty expensive such that it’s often not a huge deal if it takes a while to choose the next point to evaluate. Some more discussion of the relative time for DynMeanBO vs. acquisition costs in real-world BO settings, compared to ColaBO/PiBO vs. acquisition costs would help elucidate the real-world relevance and applicability of this method.\n- Fig.2: It’s pretty difficult to read the graphs because they’re so small. Maybe a log scale should be used for the y-axis. There primarily seems to be a performance improvement at early iterations, which makes sense because the prior just starts in the good region. However, on none of these problems is this gain held in later iterations.\n- The method seems highly dependent on choosing a prior decay schedule, which should to some extent express how good the prior is expected to be anyway. It seems like it might be easier to just choose a weaker (more dispersed) prior instead. I can appreciate that they’ve chosen an exponential decay with only one hyperparam, $\\lambda$, which seems to work reasonably well in the cases tested.\n- I’m unsure how meaningful the theoretical results are in that they seem to rely on the fact that the mean will revert to having effectively no prior influence eventually, which seems like a trivial statement—if I do something for a finite number of iterations and then revert to a BO procedure that already has convergence guarantees, it’s unsurprising that this method also converges. That being said, I didn’t read the details super closely.\n\nMy recommendation would be weak accept--I think the paper and experiments are really nicely executed, but I'm unsure if the methodological contribution and results matter enough. I'm not super well-versed in the BO + priors subfield though.\n\n*Some general feedback:*\n\nPlease make figure legends larger so they’re easier to read (e.g., Fig. 1). Also typo in Fig.1 — “Samples *form* prior” —> from. Some of the figures are generally too small / too many plots; please print out your paper and scale stuff so it’s readable in print.\nBased on the algorithm description, I wouldn’t expect the runtime to be that much different from not using a prior, so I don’t think it’s that important to put this as Figure 3 — maybe a later figure, or supplemental? Figure 5 is more informative, maybe these two can be combined? It also might be helpful to make one big plot instead of many little plots, where the x-axis is the different problems, and each method is plotted as a line with error bars."}, "questions": {"value": "I’d be curious to see what happens when a really bad prior is given (e.g., strong and in a place pretty far from the optimum) — does DynMeanBO still recover, or does it perform much worse than using regular BO?\nWhat are the compute time factors for DynMeanBO vs. PiBO, ColaBO respectively? 10x faster? 2x faster? Specify for both good and bad prior experiments if they’re different. Also, some more discussion of the relative time for DynMeanBO vs. acquisition costs in real-world BO settings, compared to ColaBO/PiBO vs. acquisition costs would help elucidate the real-world relevance and applicability of this method."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "r6oRUAdwmX", "forum": "ylX5PWfK0v", "replyto": "ylX5PWfK0v", "signatures": ["ICLR.cc/2026/Conference/Submission11616/Reviewer_udxX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11616/Reviewer_udxX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11616/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761802242052, "cdate": 1761802242052, "tmdate": 1762922688448, "mdate": 1762922688448, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces DynMeanBO, a Bayesian optimization framework that incorporates expert prior knowledge into a GP mean function and gradually reduces that influence over time using an exponential decay factor. This dynamic mean decay allows the optimizer to exploit useful expert beliefs early on but prevents long-term bias from incorrect priors, making the method computationally light, acquisition-function agnostic, and preserving standard convergence guarantees. Empirical results across synthetic functions and hyperparameter tuning tasks show that DynMeanBO matches or outperforms prior-informed BO methods while being more robust and nearly as fast as standard BO."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tIntegrating prior distributions into the GP mean with a decaying coefficient is conceptually straightforward and compatible with arbitrary acquisition functions. It avoids the complexity of prior-specific acquisition designs.\n2.\tBy decaying the influence of the expert mean, the method can recover from misleading prior beliefs. Theoretical analysis establishes that DynMeanBO does not sacrifice long-term performance despite using potentially biased priors. The authors prove that under standard assumptions (e.g. the objective lies in the RKHS of the GP kernel), DynMeanBO with EI or UCB achieves the same asymptotic convergence rate and regret bounds as standard BO.\n3.\tThe approach is modular and compatible with a broad set of acquisition functions, which avoids the complexity of prior-specific acquisition designs."}, "weaknesses": {"value": "1.\tMost experiments involve low  to medium dimensional tasks and a specific set of deep-learning hyperparameter benchmarks; it remains unclear how DynMeanBO performs in very high-dimensional or multi-fidelity scenarios, or on domains where priors are scarce.\n2.\tThe paper did not provide detailed analysis on how sensitive the method is to mismatched prior modes or variances, which would help practitioners understand risk when experts provide only coarse or biased priors.\n3.\tAlthough mixtures of Gaussians are considered, the framework implicitly assumes that expert priors can be parameterized easily and effectively, which may not hold in many real-world domains.\n4.\tDynMeanBO introduces new tuning parameters (for the prior mean and its decay) that are set heuristically and not thoroughly examined. The GP mean uses a scaled version of the expert’s prior distribution $m_{\\text{prior}}(x) = A,\\pi(x) + B$, but the paper fixes $A=1$ and $B=0$ “for simplicity” without discussing how these might affect results. Likewise, the decay schedule $\\gamma_n=\\exp(-\\lambda (n-N_0))$ uses a fixed rate $\\lambda=1$ in all experiments, and 40% of initial samples are drawn from the prior (a fixed ratio). There is no ablation study or guidance on choosing these hyperparameters. This raises questions: e.g. if $\\lambda$ is too small (slow decay), a bad prior might mislead longer, whereas if too large, a good prior’s benefit might vanish prematurely. The robustness and performance of DynMeanBO could be sensitive to these settings, but the paper provides only a single fixed configuration. Without exploring different decay rates or prior weightings, it’s unclear how one would tune DynMeanBO in practice when the reliability of the expert prior is unknown."}, "questions": {"value": "1. How sensitive is DynMeanBO’s performance to the choice of decay rate $\\lambda$ and the number of initial prior-guided points $N_0$? The experiments fixed $\\lambda=1$ and used a 40% prior-based initialization without ablation. Would a slower or faster decay significantly change the outcomes?\n2. Beyond the specific “bad prior” tested (a single offset Gaussian), are there other failure modes to be aware of? For example, what if the expert prior is not just slightly off in location but completely adversarial (e.g. concentrated in a region of very low function value)? In such extreme cases, does the hybrid initialization (mixing Sobol points) and decay suffice to guarantee recovery, or could there be situations where DynMeanBO still performs worse than standard BO for a while? A related point is that how does observation noise affect the trust in the prior? If the objective evaluations are noisy, one might need more iterations to “override” a misleading prior."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "O7ZLW2gjB5", "forum": "ylX5PWfK0v", "replyto": "ylX5PWfK0v", "signatures": ["ICLR.cc/2026/Conference/Submission11616/Reviewer_ZGXS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11616/Reviewer_ZGXS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11616/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978324829, "cdate": 1761978324829, "tmdate": 1762922688137, "mdate": 1762922688137, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}