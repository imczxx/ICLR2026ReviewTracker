{"id": "nhJK05OQne", "number": 1194, "cdate": 1756862913547, "mdate": 1763734728164, "content": {"title": "Functional Shrinkage for Input Optimization", "abstract": "Input optimization is a major methodology in deep learning that has been widely applied in adversarial attacks, neural network verification, and deep reinforcement learning. An important topic is how to inject a perturbation with a limited budget to the crucial part of a network, in order to avoid unstable optimization paths or meaningless outcomes. In this work, we formulate a network as a functional of activation functions, and propose a functional shrinkage method to extract the principal component of the network. Then the residual component can be vulnerable to perturbations, which is exploited for perturbation injection. Experimental results show that the proposed method achieves state-of-the-art performance in several input optimization tasks. It provides a new insight into the structural decomposition and weakness exploitation of neural networks.", "tldr": "We propose a functional shrinkage method for input optimization.", "keywords": ["Functional shrinkage", "activation map", "input optimization"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4c75bab7ed18b4bb12ed08320cff2b73cc3673b1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The manuscript proposes a functional shrinkage method (FSIO) that decomposes a neural network into a principal component containing the main structural information and dominant signals, and a residual component that includes outlier-sensitive information and noise, enabling adversarial attacks and input optimization. The method is proven to be sound through theoretical analysis and theorems. Comparative experimental results demonstrate that FSIO outperforms other methods with smaller perturbation budgets and is effective in capturing the vulnerable parts of neural networks, injecting perturbations into these parts. This provides new insight into the structural decomposition and weakness exploitation of neural networks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The manuscript proposes a functional shrinkage method to extract the principal component of the network and inject perturbations into the residual component, providing a new insight into the structural decomposition and weaknesses of neural networks. Compared to other methods, it demonstrates superior performance.\n\n2. The paper is easy to follow, with clear logical analysis and comprehensive theorem proofs. The consistency of the theoretical results is supported by comparative experimental validation.\n\n3. The convergence proof and optimization model provides a guarantee for the soundness of the manuscript."}, "weaknesses": {"value": "1. Based on the experimental results, the choice of activation function and the decomposition of activation patterns seem to have a significant impact on the method presented in the manuscript. Although the authors have considered activation functions such as ReLU, sigmoid, and softplus, FSIO's performance may not be optimal for certain types of activation functions.\n\n2. FSIO injects perturbations into the residual component; however, this residual component may not fully cover all critical regions, which could result in missing some key attack targets."}, "questions": {"value": "1. Could the shrinkage function be replaced by another form that retains these properties?\n\n2. In the comparative experiments on \"adversarial attacks on image classification,\" \"adversarial attacks on neural policies,\" and \"input optimization for deep reinforcement learning,\" the functional shrinkage method (FSIO) demonstrates strong performance. Could the authors analyze under what conditions the proposed method might fail or exhibit suboptimal performance?\n\n3. In the comparative experiments for input optimization in deep reinforcement learning, why were DDPG and TD3 chosen as the algorithms for the reinforcement learning part? How would FSIO perform if applied to input optimization using PPO or DQN algorithms instead?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "oNxeHKXO6B", "forum": "nhJK05OQne", "replyto": "nhJK05OQne", "signatures": ["ICLR.cc/2026/Conference/Submission1194/Reviewer_i7HY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1194/Reviewer_i7HY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1194/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761735118468, "cdate": 1761735118468, "tmdate": 1762915703164, "mdate": 1762915703164, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes FSIO (Functional Shrinkage for Input Optimization), a framework that formulates a neural network as a functional of its activation functions and applies a form of functional shrinkage to decompose it into principal and residual components. The authors claim that this decomposition enables more effective perturbation injection for input optimization tasks. The paper evaluates FSIO across three different domains: adversarial attacks on image classification, adversarial attacks on neural policies, and input optimization for deep reinforcement learning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper presents an ambitious and comprehensive framework that aims to unify multiple areas (e.g., adversarial attacks, neural verification, and reinforcement learning) under a single umbrella of input optimization. Typically, these approaches receive much recognition as they can lead to “cross-fertilization” between distinct areas.\n\n- The theoretical formulation is mathematically rich, with detailed proofs and derivations for the proposed functional shrinkage process.\n\n- The experimental evaluation covers a diverse set of application domains (vision and RL) and activation types (ReLU, Softplus, Sigmoid), which shows the authors’ effort to generalize their method beyond a single context."}, "weaknesses": {"value": "**Lack of clarity and direction.**\nA major weakness of the paper lies in its presentation and clarity. The manuscript devotes substantial space to mathematical formalism and proofs, but it does not provide an intuitive explanation of what the proposed method aims to achieve, why it matters, or how it connects to real-world optimization or robustness problems. The introduction and methodology sections are dense and abstract, with limited motivation for key design choices. As a result, it is difficult for a reader, even one familiar with adversarial machine learning, to grasp the central intuition behind FSIO and its intended contributions.\nThe paper indeed gives strong emphasis on formal derivations but provides little conceptual grounding. It introduces several functional operators and assumptions without explaining the rationale or the high-level mechanism that makes their FSIO approach beneficial for input optimization. In essence, the proofs dominate the exposition, while the link between these theoretical elements and the final algorithmic or empirical performance is underdeveloped. Consequently, it remains unclear why this approach should outperform existing optimization schemes or how it connects to known principles in, for example, adversarial robustness (as it is one of the tasks implemented).\n\n**Weak experimental setup.**  The experimental section employs outdated or weak adversarial baselines [AttackBench]. Attacks such as FGSM and C&W are used, but modern strong baselines like APGD or AutoAttack are absent. Moreover, it is not clear how many iterations of PGD are being run, as a few iterations are insufficient for convergence and can bias results toward faster but weaker optimization schemes. The experiments also do not consider adversarially trained or robust models, which are now standard in attack evaluations. As a result, it is unclear whether the proposed FSIO method truly provides improvements beyond exploiting non-robust models or suboptimal attack configurations.\n\nAttackBench Evaluating Gradient-based Attacks for Adversarial Examples, AAAI 2025.\n\n\n\n**Lack of background and contextualization** The paper lacks sufficient technical and conceptual background for readers who are not already experts across all three subfields (adversarial robustness, DRL, and neural verification). It treats input optimization as a general umbrella that wishes to capture all of them, but does not clearly define how these tasks relate or why they should share a unified framework. The related work section also lacks a systematic discussion of prior works going in a similar direction, making it difficult to place the contribution in context. As a result, the paper’s relevance and impact remain unclear.\n\n\n**Unclear figures** Figure 1, which should convey the main intuition of the decomposition, is too generic and clear; consequently, it fails to clarify the purpose or structure of FSIO. The visualizations do not make it clear how the “principal” components relate to the underlying network function or why the decomposition is meaningful.\n**Minor issues.** Figure 2 also suffers from poor visual design: its use of bright, non-colorblind-friendly colors makes it difficult to interpret, and the intended message is unclear.\n\n\n**Actionable points.**  Provide a few intuitive explanations or motivating examples at the purpose of providing a clearer connection between the theoretical framework and the practical algorithm. Reduce the abstract formalism and strengthen intuitive exposition. Related to the adversarial attack part, please improve experimental rigor by including stronger baselines (e.g., APGD, AutoAttack). Furthermore, improve the graphical aspect for Figures 1 and 2 using color palettes that are accessible to colorblind readers.\nThe paper would benefit from providing more intuitive explanations and motivating examples to better connect the theoretical framework to the practical algorithm. The current exposition is overly abstract, and strengthening the intuitive narrative would help readers understand the motivation and practical implications of the proposed approach. Regarding the adversarial attack experiments, the authors should improve empirical rigor by including stronger, more standardized baselines (e.g., APGD and AutoAttack), and ensuring fair comparisons under converged settings. Furthermore, improve the graphical presentation of Figures 1 and 2 using color palettes accessible to colorblind readers. Lastly, the background section should be revisited and expanded to better explain what “input optimization” entails in each application domain (e.g., adversarial attacks, reinforcement learning) and to clarify how these domains are conceptually related within the proposed framework."}, "questions": {"value": "How sensitive is FSIO to hyperparameters such as the shrinkage factor?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BOkjzVMcOz", "forum": "nhJK05OQne", "replyto": "nhJK05OQne", "signatures": ["ICLR.cc/2026/Conference/Submission1194/Reviewer_r3KP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1194/Reviewer_r3KP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1194/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761741255982, "cdate": 1761741255982, "tmdate": 1762915703021, "mdate": 1762915703021, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses input optimization, a key methodology in deep learning, by proposing an approach to inject perturbations into critical parts of neural networks under limited budgets. The authors formulate a network as a functional of activation functions and define a mathematical object called the activation map, which transforms discrete activation values into continuous functional representations. \nThrough singular value decomposition on the activation map within a Hilbert space, the method decomposes it into a linear combination of orthogonal components. The proposed Functional Shrinkage algorithm selectively retains important components while shrinking less significant ones. Finally, the residual components obtained through shrinkage are exploited to construct the optimization objective for effective input manipulation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Strength 1: The introduction and related work sections are well-presented and easy to follow.\n\nStrength 2: The proposal of the method is supported by rigorous mathematics."}, "weaknesses": {"value": "Weakness 1: This paper lacks an analysis of computational costs.\n\nWeakness 2: Although the method proposed in the paper has a mathematical proof, the reason why terms with small singular values are regarded as fragile points still requires further explanation, and more convincing illustrations are also needed.\n\nWeakness 3: The threshold setting in Functional Shrinkage algorithm is crucial because it determines which components will be set to zero. However, the paper does not experimentally explore the changes resulting from adjusting the threshold."}, "questions": {"value": "Question 1: If the target is replaced with a larger and more complex neural network, can the Functional Shrinkage algorithm still achieve good results?\n\nQuestion 2: Since this algorithm targets vulnerable parts of neural networks, why not reduce the perturbation budgets in experiments to see what effect it has?\n\nQuestion 3: It remains difficult to understand why the paper formulates a network as a functional of activation functions. Is it only to bring computations into the Hilbert space?\n\nQuestion 4: Why is only λ₁ used to control the strengths of the activation-descent regularization and the residual regularization, instead of using different hyperparameters?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sF2KlB3WVz", "forum": "nhJK05OQne", "replyto": "nhJK05OQne", "signatures": ["ICLR.cc/2026/Conference/Submission1194/Reviewer_VBk4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1194/Reviewer_VBk4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1194/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761975642430, "cdate": 1761975642430, "tmdate": 1762915702870, "mdate": 1762915702870, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}