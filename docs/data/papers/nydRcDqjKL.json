{"id": "nydRcDqjKL", "number": 9400, "cdate": 1758121219476, "mdate": 1762948279007, "content": {"title": "UML-CoT: Structured Reasoning and Planning with Unified Modeling Language for Robotic Room Cleaning", "abstract": "Chain-of-Thought (CoT) prompting improves reasoning in large language models (LLMs), but its reliance on unstructured text limits interpretability and executability in embodied tasks. Prior work has explored structured CoTs using scene or logic graphs, yet these remain fundamentally limited: they model only low-order relations, lack constructs like inheritance or behavioral abstraction, and provide no standardized semantics for sequential or conditional planning. We propose UML-CoT, a structured reasoning and planning framework that leverages Unified Modeling Language (UML) to generate symbolic CoTs and executable action plans. UML class diagrams capture compositional object semantics, while activity diagrams model procedural control flow. Our three-stage training pipeline combines supervised fine-tuning with Guided Reinforced Plan Optimization (GRPO), including reward learning from answer-only data. We evaluate UML-CoT on MRoom-30k, a new benchmark of cluttered room-cleaning scenarios. UML-CoT outperforms unstructured CoTs in interpretability, planning coherence, and execution success, highlighting UML as a more expressive and actionable structured reasoning formalism.", "tldr": "", "keywords": ["Structured Reasoning", "Chain-of-Thought", "UML Diagrams", "Room Cleaning"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/0833bb878933429b48dcceba90d88420169d056c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "# Summary\n## What is the problem solved? Is it a known problem?\n\nThe problem that is being tackled in this work is plan generation for the robotics room cleaning task, but the restriction to robotics room cleaning can be alleviated and one can say the paper deals with plan generation in hierarchically represented domains. \n\n## How is it solved in the literature and how is the current approach different?\n\nThe authors propose to use UML to describe both the planning problem and the hierarchical solution. This is not a common approach to planning problems, but it was tried in the past, with the work dating back about 20 years, e.g., [1,2,3]. To the best of my knowledge, the line of research was abandoned, possibly in favor of other, more convenient formalisms that allow capturing hierarchies and partial solutions, such as HTN planning [4,5]. I would encourage the authors to look at HDDL, which seems to allow capturing the aspects of the planning problems they explore in this work.\n\n[1] Tiago Stegun Vaquero et. al., ICAPS 2005, The itSIMPLE tool for Modeling Planning Domains \n[2] Tiago Stegun Vaquero et. al., ICAPS 2006, On the Use of UML.P for Modeling a Real Application as a Planning Problem\n[3] Tiago Stegun Vaquero et. al., ICAPS 2007, itSIMPLE2.0: An Integrated Tool for Designing Planning Domains\n[4] Erol et al., AAAI 1994, HTN planning: complexity and expressivity\n[5] Holler et al., AAAI 2020, HDDL: An Extension to PDDL for Expressing Hierarchical Planning Problems\n\n\n# Significance\n\nThe problem of automated plan generation is one of the major problems autonomous agents are tasked with. The currect solution proposed might not be adopted by the community, probably due to the same reasons the similar solution that was proposed 20 years ago was not adopted - it is quite complicated and even small errors in the captured/learned model can render the solution invalid. Also, the previously proposed solution proposed UML as a representation language, while proposing transformations into PDDL or petri nets, for which solvers are readily available. Here, the authors propose language models to do the solving, aided by SFT.\n\n# Soundness\n\nThere is no theory presented in the paper.\n\n# Novelty\n\nAs mentioned before, the novelty is somewhat limited. \n\n# Scholarship\n\nThe previous work on modeling with UML or on hierarchical planning are not mentioned (see some representative papers above). HTN planning is an area of active research for the past 45+ years, with thousands of papers, workshop series and competitions dedicated to the topic. \n \n# Clarity\n\nThe paper is rather well written, with the ideas clearly described.\n\n# Evaluation and Reproducibility\n\nThe experiments are performed on the MRoom-30k dataset, in distribution only, using the 80/10/10 split. The evaluation is performed based on semantic similarity using a language model. It is unclear therefore how the approach performs (as the evaluation is imprecise) and whether it generalized out of distribution (not tested).\n\nThe baselines are rather weak, CoT/ToT/GoT. The ToT/GoT in addition to being extremely inefficient (hundreds of calls to the language model to solve each task) were recently also shown to exhibit severe performance degradation when moving out of the distribution of the instances the model was initially trained on (see Table 1 bottom part in [6]). Still, even compared to these weak baselines the performance of the proposed approach is essentially the same. Ablations show that without finetuning the performance is very low, so the finetuning is crucial to the success of the approach. It is not clear therefore whether the finetuned model doesn't just memorize the \"correct\" (according to semantic similarity evaluation metric) answers.\n\n[6] Katz et al., Arxiv 2025, Seemingly Simple Planning Problems are Computationally Challenging: The Countdown Game"}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is nicely written\n2. The problem is clearly described (albeit not formally defined)\n3. The approach is presented with visual aids, diagrams and UML example problem and solution description"}, "weaknesses": {"value": "1. The paper on planning ignores the relevant planning literature (well, any planning literature).\n2. There is no motivation for why UML would be a good formalism to use with language models.\n3. There is no formal definition of what the problem is (what is the input, what is considered to be a solution).\n4. The authors do not provide a sound validator for their task, rendering the experiments uninformative.\n5. The experiments do not investigate out of distribution performance.\n6. The experiments do not compare to strong baselines (e.g., HTN planners)."}, "questions": {"value": "1. Can all aspects of your problem be captured by HTN planning and in particular by HDDL? If not, what aspects cannot be captured?\n2. How do you ensure that the UML problem description generated is correct?\n3. How would you validate generated solutions? The semantic similarity does not answer whether the produced output is an actual plan."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jyUAWqI63l", "forum": "nydRcDqjKL", "replyto": "nydRcDqjKL", "signatures": ["ICLR.cc/2026/Conference/Submission9400/Reviewer_xG9S"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9400/Reviewer_xG9S"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9400/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760756210285, "cdate": 1760756210285, "tmdate": 1762921007826, "mdate": 1762921007826, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "BmSDOv0DGH", "forum": "nydRcDqjKL", "replyto": "nydRcDqjKL", "signatures": ["ICLR.cc/2026/Conference/Submission9400/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9400/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762948277558, "cdate": 1762948277558, "tmdate": 1762948277558, "mdate": 1762948277558, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes UML-CoT, representing symbolic reasoning as UML class diagrams and executable plans as UML activity diagrams, trained with a three-stage pipeline: SFT on UML traces, RL fine-tuning using final-plan rewards via GRPO, and GRPO on answer-only data.​\nA new MRoom-30k dataset of messy rooms is constructed with final plans generated by GPT-4o and a 1k subset with CoT from DeepSeek-R1, and evaluation relies on a semantic-similarity reward using all-MiniLM-L12-v2 over partitioned plan sections with greedy matching, plus a format reward for tag correctness.​ Experiments report that fully UML-based reasoning and plans, especially with the extra RL stage, improve similarity, recall, and F1 over text CoT, Tree-of-Thoughts, and Graph-of-Thoughts on a 1k test subset, with ablations showing SFT is necessary to bootstrap valid UML outputs and GRPO adds gains beyond longer SFT.​ Cross-task generalization results for cooking and painting are reported but under-specified, and there is no closed-loop execution in simulators or on hardware, leaving executability claims supported only by text similarity proxies rather than task success.​"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Novel formalism: Leveraging UML for symbolic reasoning and planning is creative and theoretically grounded in software engineering principles.\n\n2. Structured interpretability: The approach enhances transparency and debuggability compared to unstructured CoTs or scene graphs.\n\n3. Methodological rigor: The three-stage learning pipeline (SFT - RLFT - GRPO) is well-motivated and demonstrates incremental gains.\n\n4. Empirical evaluation: Results are consistent across multiple baselines (Tree/Graph of Thoughts) and show measurable improvements in semantic similarity and recall.\n\n5. Dataset contribution: The introduction of MRoom-30k for messy room reasoning fills a niche gap in embodied AI benchmarks."}, "weaknesses": {"value": "1. Rewards are computed only from the final plan with an embedding similarity and a format bonus, providing no direct supervision for intermediate class-diagram quality and inviting reward hacking or spurious similarity rather than faithful stepwise reasoning and grounding.\n\n2. The accuracy metric depends on all-MiniLM-L12-v2 cosine similarity and a bespoke partitioning and greedy matching procedure, but there is no human preference or simulator/hardware execution study to show that higher similarity truly correlates with cleaning success or safety.\n\n3. Cross-task generalization lacks a clear protocol: training data, zero-shot versus fine-tuned settings, annotation sources, schema alignment, and overlap controls are missing, which makes the cooking and painting results in Table 2 hard to interpret causally.\n\n4. The paper does not benchmark on established embodied household datasets such as ALFRED, TEACh, or Habitat Rearrangement, which provide standard execution-based metrics and would substantiate claims about planning quality and generality in interactive settings.\n\n5. The case for UML versus typed JSON schemas or DSL-based plans, function-calling tool APIs, or PDDL is purely conceptual without controlled ablations comparing these structured alternatives on identical backbones and metrics. (The paper lacks clear comparison to simpler structured prompts (e.g., JSON or DSL-based plans....) that might offer similar interpretability with less formal complexity.)\n\n6. There is no hybrid grounding pipeline leveraging scene graph extraction to populate UML class diagrams from perception, weakening claims about improved world modeling and verifiability in visual scenes.\n\n (Minor weakness)\n\n7. Dataset labels are largely LLM-generated (GPT-4o and DeepSeek-R1), and evaluation converts textual outputs to UML via GPT-4o, which risks label noise, conversion bias, and metric circularity disconnected from actual robotic success.\n\n8. Claims of “executable plans” are not backed by execution in ALFRED, TEACh, Habitat (ReplicaCAD/HSSD), or real robots such as TidyBot-like settings, which would give stronger external validity for executability beyond similarity scores.\n\n9. UML modeling introduces heavy symbolic overhead; it’s unclear how the approach scales to dynamic or continuous control tasks."}, "questions": {"value": "1. How exactly is cross-task generalization configured: are cooking and painting strictly zero-shot from room-cleaning training, or is any adaptation performed, and what are the data sources, schemas, and overlap controls for those domains ?\n\n2. Can you provide controlled ablations comparing UML activity/class diagrams to a typed JSON schema with control-flow operators, a function-calling interface, and a PDDL pipeline on the same training/evaluation setup to substantiate the choice of UML ?\n\n3. What mechanisms ensure the class diagrams are accurate and consistent with the activity diagrams if the reward only scores the final plan, and do you compute any structural validity or cross-diagram consistency constraints beyond format checking ?\n\n4. Why not ground UML via a perception-first pipeline that extracts a scene graph and lifts it into UML programmatically to reduce hallucination and improve consistency, and how would that compare to direct UML generation? YOur intution.\n\n5. (optional) Can you validate the similarity metric with human ratings and execution-based metrics in ALFRED or TEACh to demonstrate that higher similarity corresponds to higher success rates and better path efficiency in embodied tasks ?\n\n6. If the ultimate goal is rearrangement/cleanup, why not include benchmarks on Habitat Rearrangement (with ReplicaCAD/HSSD scenes) to measure object-goal success and state deltas under physics, and explain any interface incompatibilities if omitted ?\n\n7. How sensitive are results to the predefined partitions (“Main Messy Areas,” “Priority,” “Steps”), and are these partitions domain-neutral enough to evaluate cooking/painting without bias or misalignment ? IN case I missed this in paper, please point it out."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0GaMO98X1i", "forum": "nydRcDqjKL", "replyto": "nydRcDqjKL", "signatures": ["ICLR.cc/2026/Conference/Submission9400/Reviewer_o6Xi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9400/Reviewer_o6Xi"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9400/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761491258169, "cdate": 1761491258169, "tmdate": 1762921007397, "mdate": 1762921007397, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a structured reasoning framework that models both reasoning and planning as UML diagrams. Using a custom GPT-4o-annotated dataset (MRoom-30k), the authors train the model through supervised fine-tuning on a small CoT subset and two stages of GRPO reinforcement learning. The method aims to enhance structure adherence and interpretability, showing improved results over textual reasoning baselines."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The topic is engaging and the research direction of structured and embodied reasoning is practical.\n\n- The formulation of reasoning as the generation of UML diagrams is an interesting attempt."}, "weaknesses": {"value": "- The proposed method primarily targets the room-cleaning domain, raising concerns about its generalizability. In Table 2, the Cooking and Painting tasks are reported without clarifying the source. Moreover, all experiments are conducted solely on a custom dataset (MRoom-30k). It would strengthen the work to include evaluations on public benchmarks.\n\n- The quality of the custom dataset is uncertain, as ground-truth plans are generated by GPT-4o without verification. Given that the labels are in symbolic representations, executing the generated plans with an external simulator (see PlanBench [1]) could help validate their correctness.\n\n- The learning signal design raises concerns. Only about 1k samples contain CoT annotations for SFT, which may be insufficient. During RL fine-tuning, rewards derived from graph alignment can be unreliable due to the inherent difficulty of matching predicted and reference graphs. Furthermore, the rationale for separating CoT RL training (Stage 2) from plan-level RL training (Stage 3) is unclear.\n\n- The reasoning baselines are limited. Comparisons should include VLM agents that ground reasoning to perception and actions, such as ProgPrompt [2], OpenVLA [3], and Open-X Embodiment [4].\n\n- The novelty appears limited, focusing mainly on dataset construction and prompt-format modifications.\n\n- Code and data are not provided for review.\n\n## Reference:\n[1] Valmeekam, Karthik, et al. \"Planbench: An extensible benchmark for evaluating large language models on planning and reasoning about change.\" Advances in Neural Information Processing Systems 36 (2023): 38975-38987.\n\n[2] Singh, Ishika, et al. \"Progprompt: Generating situated robot task plans using large language models.\" arXiv preprint arXiv:2209.11302 (2022).\n\n[3] Kim, Moo Jin, et al. \"Openvla: An open-source vision-language-action model.\" arXiv preprint arXiv:2406.09246 (2024).\n\n[4] O’Neill, Abby, et al. \"Open x-embodiment: Robotic learning datasets and rt-x models: Open x-embodiment collaboration 0.\" 2024 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2024."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hELodzwrA2", "forum": "nydRcDqjKL", "replyto": "nydRcDqjKL", "signatures": ["ICLR.cc/2026/Conference/Submission9400/Reviewer_rR63"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9400/Reviewer_rR63"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9400/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761943540250, "cdate": 1761943540250, "tmdate": 1762921007002, "mdate": 1762921007002, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces UML-CoT, a new structured chain-of-thought (CoT) framework that improves multimodal reasoning and planning for embodied robotic room-cleaning tasks. Traditional CoT prompting uses free-form natural language, which lacks explicit structure and can be ambiguous, hard to interpret, or inconsistent. In this paper, the proposed UML-CoT uses Unified Modeling Language (UML) to explicitly represent reasoning and planning. Specifically, UML Class Diagrams encode objects, attributes, relationships (inheritance, aggregation), and serve as symbolic Chain-of-Thought. Besides, UML Activity Diagrams represent executable plans and support sequencing, branching, loops. Together, they yield a more interpretable and executable reasoning pipeline. Across multiple evaluation settings, UML-CoT demonstrates higher plan correctness, more coherent sequential steps and improved interpretability."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Stronger Structure than Text-based CoT. Traditional free-form Chain-of-Thought is ambiguous, hard to verify and difficult to execute. In contrast, UML-CoT provides a standardized symbolic representation by using UML class diagrams (reasoning) and UML activity diagrams (planning), which enables consistent, interpretable, and modular CoT.\n\n2. Better Expressiveness than Graph-based Methods. Prior structured CoTs (scene/logic graphs) lack inheritance, aggregation and behavioral abstraction. However, UML overcomes these issues by natively supporting object hierarchies, attributes + relationships and conditional / sequential / iterative flows. The proposed method provides more expressive symbolic modeling and planning.\n\n3. New Dataset MRoom-30k. The paper develops a large, diverse messy-room dataset, which contains 30k+ real messy indoor images, cleaning plans and 1k reasoning traces. It enables controlled evaluation of structured reasoning."}, "weaknesses": {"value": "Authors claim that the proposed method is domain-adaptable. However, all the evaluations are in a single domain of robotic room cleaning. The domain-adaptable capability of the proposed method is not evaluated comprehensively or convincingly enough.\n \n1. The major concern of this work is its domain-adaptable capability. The agent model is pre-trained with a fixed dataset on room cleaning, and the training of UML generation is also limited to the room cleaning domain. The UML has its own language restrictions and is not flexible enough to easily adapt to changes of domains. Authors demonstrate the cross-task generalizability of the proposed method in the experiments. However, it is still about transferring to different tasks in the same domain, not related to domain-adaptability. The discussion is short and experiments are not comprehensive enough. So, the evaluation of domain-adaptability is not convincing enough.\n\n2. Another weakness of the proposed method is that, as an agent model, its computation power and resources are limited in the real-world applications. If the model is too large or its fine-tuning is too expensive, it cannot be applicable to agentic applications. A small model for building the agent is preferred. It is better to avoid fine-tuning in adapting to changes of environment or working domain. However, the authors did not discuss these issues in the paper.\n\n3. The training pipeline is complex and expensive. Three-stage training includes SFT, RLFT and GRPO. This pipeline is long and computationally intensive, which makes the reproducibility more difficult. Besides, the details of the training part are introduced comprehensively enough, and choices of important hyperparameters are also missing, which cannot make the performance of the proposed method convincing enough.\n\n4. The baselines in the experiments are also limited. As an embodied AI paper, the baselines should include symbolic task planners (PDDL-based) and RL-based navigation methods. Its advantages over state-of-the-art planning methods are not clear."}, "questions": {"value": "1. In the construction of the dataset, most images are annotated with cleaning plans generated by GPT-4o. However, it is widely known that GPT models can hallucinate and produce wrong plans which may violate some domain constraints. Wrong plans in the training data can make the agent work wrongly in the deployment. How does the proposed method address this issue?\n\n2. In the RL training part, the accuracy reward is only the semantic similarity between generated and ground-truth plan. But semantic similarity may not accurately reflect the correctness of the generated plan. Sometimes, the generated plan may be semantically similar as the ground-truth result, but incorrect essentially. How does the proposed framework resolve this situation?\n\n3. In the RL training part, the format rewards encourage the model to generate both <think> and <answer> tags. But both tags are required for the agent to work correctly based on UML. So, encouraging reward may not be strong enough to make sure the trained agent works properly. Why not penalize the model if any of these tags are missing?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "o1GywWUyqm", "forum": "nydRcDqjKL", "replyto": "nydRcDqjKL", "signatures": ["ICLR.cc/2026/Conference/Submission9400/Reviewer_u88V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9400/Reviewer_u88V"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9400/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762032029772, "cdate": 1762032029772, "tmdate": 1762921006649, "mdate": 1762921006649, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}