{"id": "NylOrth5EH", "number": 17855, "cdate": 1758281277540, "mdate": 1759897149898, "content": {"title": "Degree-Conscious Spiking Graph for Cross-Domain Adaptation", "abstract": "Spiking Graph Networks (SGNs) have demonstrated significant potential in graph classification by emulating brain-inspired neural dynamics to achieve energy-efficient computation. However, existing SGNs are generally constrained to in-distribution scenarios and struggle with distribution shifts. In this paper, we first propose the domain adaptation problem in SGNs, and introduce a novel framework named Degree-Consicious Spiking Graph for Cross-Domain Adaptation (DeSGraDA). DeSGraDA enhances generalization across domains with three key components. First, we introduce the degree-conscious spiking representation module by adapting spike thresholds based on node degrees, enabling more expressive and structure-aware signal encoding. Then, we perform temporal distribution alignment by adversarially matching membrane potentials between domains, ensuring effective performance under domain shift while preserving energy efficiency. Additionally, we extract consistent predictions across two spaces to create reliable pseudo-labels, effectively leveraging unlabeled data to enhance graph classification performance. Furthermore, we establish the first generalization bound for SGDA, providing theoretical insights into its adaptation performance. Extensive experiments on benchmark datasets validate that DeSGraDA consistently outperforms state-of-the-art methods in both classification accuracy and energy efficiency.", "tldr": "", "keywords": ["Spiking Graph Networks", "Domain Adaptation", "Generalization Bound"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fd064941778d4f78166894acf2050a53decd68b3.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates the problem of domain adaptation in spiking graph networks, an issue that has not been sufficiently explored in the existing literature. The authors propose the DeSGraDA framework, which extends spiking graph networks (SGNs) through three key mechanisms: degree-based spike encoding, adversarial training in membrane potential space for temporal distribution alignment, and a pseudo-label distillation mechanism based on prediction consistency. The method is supported theoretically by a generalization error bound derived for the SGN domain adaptation (SGDA) scenario. Experiments on multiple benchmark datasets demonstrate that DeSGraDA outperforms various baseline methods in both classification performance and energy efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper introduces domain adaptation into spiking graph networks, aligning the distributions of source and target domains, which demonstrates strong novelty. \n\n2. To address key challenges in SGNs—such as node degree bias, temporal dynamic distribution discrepancies, and missing labels in the target domain—the paper proposes the DeSGraDA framework, comprising three modules: degree-aware spiking, temporal adversarial alignment, and pseudo-label distillation. The design is logically coherent and the technical approach is well-justified.\n\n3. The paper not only provides theoretical analysis such as a generalization error upper bound, but also conducts experiments on multiple datasets. The ablation studies and comparative results effectively support the method's effectiveness and superiority."}, "weaknesses": {"value": "1. The pseudo-label distillation module clusters target samples and assigns pseudo-labels based on shallow graph features, but the criteria for assessing the reliability of the clustering are not clearly defined.\n\n2. The trade-off between the additional computational overhead introduced by domain adaptation and the resulting performance improvement is not discussed.\n\n3. Some terminology is inconsistent (e.g., \"degree-conscious\" vs. \"degree-aware\")."}, "questions": {"value": "1. In the degree-aware spiking representation module, the authors adaptively set the spiking thresholds based on node degrees to achieve more balanced information propagation across the graph. However, a similar adaptive threshold mechanism was also proposed in SpikeNet (2023). What are the essential differences and advantages of the proposed method compared to prior work, in terms of mechanism design, theoretical motivation, or practical performance.\n\n2. In the temporal distribution alignment module, does the adversarial discriminator operate on all historical membrane potentials, or on a final feature vector obtained by aggregating membrane potentials across multiple time steps?\n\n3. In pseudo-label distillation, what is the rationale for selecting the number of clusters C? Are there alternative clustering and label assignment strategies that could be used?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "A214kKNjRW", "forum": "NylOrth5EH", "replyto": "NylOrth5EH", "signatures": ["ICLR.cc/2026/Conference/Submission17855/Reviewer_TxSC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17855/Reviewer_TxSC"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17855/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761918626020, "cdate": 1761918626020, "tmdate": 1762927686088, "mdate": 1762927686088, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces spiking graph domain adaptation (SGDA) and proposes DeSGraDA, a framework for graph classification under distribution shift. The method has three modules: (1) degree‑conscious spiking representation, which adapts neuron firing thresholds per node degree to balance firing across high/low‑degree nodes; (2) temporal distribution alignment, which summarizes membrane‑potential sequences with self‑attention and aligns source/target via an adversarial discriminator; and (3) pseudo‑label distillation. Experiments on SEED/BCI EEG, PROTEINS/DD proteins, and COX2/BZR chemistry datasets report improvements over graph and spiking baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Thorough experimental verification. Performance was thoroughly experimentally verified on various datasets.\n- Theoretical support. They provide the generalization bound for SGDA."}, "weaknesses": {"value": "- Limited novelty. DeSGDA comprises three components: node degree-aware personalized spiking representation, adversarial feature distribution alignment, and pseudo-label distillation. However, the second (domain alignment) and the third (pseudo labeling) components are well-known techniques in domain adaptation. Thus, their contribution is limited.\n- Concerns about effectiveness. The overall experimental improvements are marginal.\n- Unclear motivation. Additional explanation is needed for why domain adaptation should be solved with spiking neural networks.\n- Lack of experimental verification of theoretical analysis (theorems)\n- Overhead analysis. There is no analysis about the overhead caused by the proposed approach."}, "questions": {"value": "Please refer to Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fCe7eJVDbv", "forum": "NylOrth5EH", "replyto": "NylOrth5EH", "signatures": ["ICLR.cc/2026/Conference/Submission17855/Reviewer_5EVp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17855/Reviewer_5EVp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17855/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761932734727, "cdate": 1761932734727, "tmdate": 1762953394123, "mdate": 1762953394123, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method for improving the domain adaptation of spiking GNN.\nStarting from adaptively adjusting the threshold, temporal aggregation and pseudo-label generation are used together to enhance the accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Degree is a central information in graph. Using this is a rational choice\n- Experimental comparison is made for a number of baselines\n- Meaningful improvements."}, "weaknesses": {"value": "**Narrow scope**\n- Domain adaptation + spiking NN seems to have a narrow scope, and its practicality should be better motivated.\n\n**Unclear platform**\n- The reviewer is not sure whether this work is being proposed as 1) a better alternative for existing algorithms (that typically run on GPUs), 2) a method that would run on spiking (neuromorphic) hardware, or 3) a hybrid platform that uses neuromorphic+traditional digital hardware, 4) or something else. I was thinking of 2) at first, but the way the authors are making their comparison in Table 1 and 2 seems to be implying 1) or 3). If 1) or 3) is the case, I believe the comparison of the training/inference time and energy on those platforms should be made.\n\n**Feasibility**\n- The proposed method requires an adaptive threshold for each neuron, which could be hard to maintain. This issue is related with the platform one. I don't think neuromorphic hardware would have enough memory to store that much data.\n- Use of the attention operation is proposed, and I am not sure if that falls into a spiking network. An attention operation involves a lot of (fp) multiplication and accumulation without any activation function. It's been shown in multiple areas that adding attention could improve performance, but for SNNs, adding attention does not seem to be directly feasible unless the target platform is GPU or a hybrid one.\n\n**Potentially unfair setup** \n- In comparison, the GNN model architecture and methods seem to be mixed, which makes it difficult to assess a fair comparison. \n\n- What model is used for the proposed method? Eq(1) indicates that there is a learnable weight for each edge in the graph for each layer? I have not seen such setting, and for sure it would be a huge number of learnable weights compared to traditional GNNs such as GCN or GIN. Moreover, such a setting would only be only possible if all vertices are edges are known at training time, making it difficult for the work to be applied to graph classification.\n\n- I am concerned about the energy comparison made in section 5.4. I don't get how the complicated design of this work would function on simple hardware such as ROLLS. I believe it would be very difficult to run a simple GNN in a spiking form, but including the dynamic threshold and attention operation would be yet another level. If such a dramatic energy saving were to be claimed, please discuss how the algorithm would run on a neuromorphic device, and provide details, including those of the GPU-based counterpart."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9O9CNhdJZe", "forum": "NylOrth5EH", "replyto": "NylOrth5EH", "signatures": ["ICLR.cc/2026/Conference/Submission17855/Reviewer_ZjWB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17855/Reviewer_ZjWB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17855/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761999735456, "cdate": 1761999735456, "tmdate": 1762927685295, "mdate": 1762927685295, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DeSGraDA, a novel framework designed to address distribution shifts in Spiking Graph Networks (SGNs). DeSGraDA introduces a degree-conscious spiking representation with adaptive node thresholds, temporal distribution alignment via adversarial membrane potential matching, and pseudo-label distillation for reliable target supervision. The paper also provides a theoretical generalization bound for SGDA. Extensive experiments on multiple benchmark datasets demonstrate that DeSGraDA consistently surpasses state-of-the-art baselines in both classification accuracy and energy efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- This paper formally defines and proposes a novel framework for addressing SGDA, and introduces a biologically inspired degree-conscious mechanism that bridges the gap between spiking neural networks and graph learning.\n- The proposed framework integrates three complementary modules: degree-conscious spiking representation, temporal distribution alignment, and pseudo-label distillation, supported by a derived generalization bound. This combination ensures both theoretical rigor and practical robustness.\n- Extensive evaluations across multiple benchmark datasets demonstrate consistent improvements in both classification accuracy and energy efficiency. The results convincingly validate the model’s effectiveness and highlight its potential for low-power, real-world applications."}, "weaknesses": {"value": "- The discussion of related work should include more recent DA methods or frameworks, such as [1,2], to better position this study within the current research landscape.\n- In Section 4.3, the paper introduces a clustering-based approach for pseudo-label generation but does not specify which clustering algorithm is used or how DeSGraDA identifies the dominant pseudo-labels within each cluster.\n- In Section 5.3, the ablation study appears incomplete, as it only evaluates the impact of removing individual components. It would be more comprehensive to also include results for removing two or three components simultaneously.\n\n[1] Smoothness really matters: A simple yet effective approach for unsupervised graph domain adaptation. AAAI. 2025.\n[2] Rethinking Graph Domain Adaptation: A Spectral Contrastive Perspective. ECML. 2025."}, "questions": {"value": "- Can the proposed framework be applied to source-free domain adaptation scenarios? \n- How does the presence of noise in the target domain affect the performance and robustness of the proposed framework?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "EbTpNyH9ij", "forum": "NylOrth5EH", "replyto": "NylOrth5EH", "signatures": ["ICLR.cc/2026/Conference/Submission17855/Reviewer_sLij"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17855/Reviewer_sLij"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17855/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762093707972, "cdate": 1762093707972, "tmdate": 1762927684158, "mdate": 1762927684158, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}