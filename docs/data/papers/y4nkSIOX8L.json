{"id": "y4nkSIOX8L", "number": 19087, "cdate": 1758293486381, "mdate": 1759897061398, "content": {"title": "GaitSnippet: Gait Recognition Beyond Unordered Sets and Ordered Sequences", "abstract": "Recent advancements in gait recognition have significantly enhanced performance by treating silhouettes as either an unordered set or an ordered sequence. However, both set-based and sequence-based approaches exhibit notable limitations. Specifically, set-based methods tend to overlook short-range temporal context for individual frames, while sequence-based methods struggle to capture long-range temporal dependencies effectively. To address these challenges, we draw inspiration from human identification and propose a new perspective that conceptualizes human gait as a composition of individualized actions. Each action is represented by a series of frames, randomly selected from a continuous segment of the sequence, which we term a snippet. Fundamentally, the collection of snippets for a given sequence enables the incorporation of multi-scale temporal context, facilitating more comprehensive gait feature learning. Moreover, we introduce a non-trivial solution for snippet-based gait recognition, focusing on Snippet Sampling and Snippet Modeling as key components. Extensive experiments on four widely-used gait datasets validate the effectiveness of our proposed approach and, more importantly, highlight the potential of gait snippets. For instance, our method achieves the rank-1 accuracy of 77.5% on Gait3D and 81.7% on GREW using a 2D convolution-based backbone.", "tldr": "We propose a novel perspective that conceptualizes human gait as a composition of snippets, allowing for the integration of both short-range and long-range temporal context, thereby facilitating more comprehensive gait feature learning.", "keywords": ["Gait Recognition", "Snippets Sampling", "Snippet Modeling"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2eb6d1df827126be02b4d42a4c730d17b170ba4a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a snippet-based gait recognition method aiming to resolve the drawbacks of current mainstream methods, i.e., set-based and sequence-based methods. Specifically, this paper proposes to represent a gait sequence as a combination of individualized snippets which contain several randomly selected frames from a continuous segment of the sequence. The randomly selected neighboring frames make the utilization of local context information better than that of set-based methods, while the randomly selection itself relax the constraint on continuity in sequence-based methods which is difficult to be satisfied in practical situation. Furthermore, this paper proposes rational approaches to snippet sampling and snippet modeling. Through extensive experiments, the effectiveness of this method is demonstrated."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe paper is well-written and easy to follow. Most relevant details are described with enough depth providing the reader with enough information to properly grasp the overall idea and the rationale behind the choice of the implemented components. The implementation details seem to be enough to replicate the proposed solution. \n2.\tThe approach seems quite simple, yet it shows interesting performance.\n3.\tThe proposed approach seems can be applied on top of many other gait recognition methods."}, "weaknesses": {"value": "See the Questions below."}, "questions": {"value": "1. From my perspective, the main distinction between GaitSnippet and other multiscale temporal modeling methods lies in its integration of set-based and sequence-based approaches. Although the experimental results demonstrate its effectiveness, my concern is why such a combination is necessary, given that many prior studies have already shown the superiority of sequence-based methods over set-based ones.\n\n2. What would the performance be if a sequence-based modeling approach were also applied within each snippet?\n\n3. The authors propose to model a gait sequence as a composition of individual actions, each represented by an equal-length segment. Would it be more reasonable to represent each action with segments of variable length instead?\n\n4. Sampling with replacement is applied to both segment and frame selection. Could this strategy potentially lead to a loss of temporal information?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "aqrrpM9lDj", "forum": "y4nkSIOX8L", "replyto": "y4nkSIOX8L", "signatures": ["ICLR.cc/2026/Conference/Submission19087/Reviewer_yKZm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19087/Reviewer_yKZm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19087/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760621891055, "cdate": 1760621891055, "tmdate": 1762931110982, "mdate": 1762931110982, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the gait recogntion. Authors introduced a new representation of the gait, snipplet, instead of using the current set or sequence representation. Authors argue that with the new representation, it can both capture both local difference in temporal representation as well as the global shape and pose related difference. Authors also introduces specific snipplet modeling for it and build the gait snipplet model. Authors have compared this method with various of different baselines and show promising performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "+ The paper is well motivated and easy to follow. The introduced gait snipplet is able to combine both the sequential information as well as the set-level unordered information for understanding.\n\n+ Authors have provided pretty useful information in Table 3 for different sampling policy for both set, sequence and snipplet. It is interesting to see that the snipplet is able to yield the best performance across three modalities.\n\n+ Authors also compared the gait snipplet on multiple dataset, which they show best results compared with the other methods listed in the paper."}, "weaknesses": {"value": "- Some of the latest results are not included in the paper, e.g., in [1], authors showed a 77.6/70.3 for R1 and mAP on Gait3D, while gait snipplet shows 77.5 and 69.4. Numbers on GREW is also 85.8/92.6 for R1 and R5 on [1] while it is 81.7/90.9. [1] is introducing a skeleton map for gait recognition, which is also a similar new representation that can be compared with snipplet, and frankly speaking, I think the snipplet idea can also be used on the skeleton map. It would be interesting for authors to apply the idea on [1] both for comparison with the latest state-of-the-art method as well as showing the generalization ability for the introduced method.\n\n[1] Skeletongait: Gait recognition using skeleton maps"}, "questions": {"value": "In addition to comparison with some other representations that yields the best performance, it would be great if authors are able to provide time cost and resource analysis that is required for training for at least one of the dataset, such as GREW."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SrI93jHOZ7", "forum": "y4nkSIOX8L", "replyto": "y4nkSIOX8L", "signatures": ["ICLR.cc/2026/Conference/Submission19087/Reviewer_P9Zy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19087/Reviewer_P9Zy"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19087/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761600646448, "cdate": 1761600646448, "tmdate": 1762931110028, "mdate": 1762931110028, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the gait recogntion. Authors introduced a new representation of the gait, snipplet, instead of using the current set or sequence representation. Authors argue that with the new representation, it can both capture both local difference in temporal representation as well as the global shape and pose related difference. Authors also introduces specific snipplet modeling for it and build the gait snipplet model. Authors have compared this method with various of different baselines and show promising performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "+ The paper is well motivated and easy to follow. The introduced gait snipplet is able to combine both the sequential information as well as the set-level unordered information for understanding.\n\n+ Authors have provided pretty useful information in Table 3 for different sampling policy for both set, sequence and snipplet. It is interesting to see that the snipplet is able to yield the best performance across three modalities.\n\n+ Authors also compared the gait snipplet on multiple dataset, which they show best results compared with the other methods listed in the paper."}, "weaknesses": {"value": "- Some of the latest results are not included in the paper, e.g., in [1], authors showed a 77.6/70.3 for R1 and mAP on Gait3D, while gait snipplet shows 77.5 and 69.4. Numbers on GREW is also 85.8/92.6 for R1 and R5 on [1] while it is 81.7/90.9. [1] is introducing a skeleton map for gait recognition, which is also a similar new representation that can be compared with snipplet, and frankly speaking, I think the snipplet idea can also be used on the skeleton map. It would be interesting for authors to apply the idea on [1] both for comparison with the latest state-of-the-art method as well as showing the generalization ability for the introduced method.\n\n[1] Skeletongait: Gait recognition using skeleton maps"}, "questions": {"value": "In addition to comparison with some other representations that yields the best performance, it would be great if authors are able to provide time cost and resource analysis that is required for training for at least one of the dataset, such as GREW."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "SrI93jHOZ7", "forum": "y4nkSIOX8L", "replyto": "y4nkSIOX8L", "signatures": ["ICLR.cc/2026/Conference/Submission19087/Reviewer_P9Zy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19087/Reviewer_P9Zy"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19087/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761600646448, "cdate": 1761600646448, "tmdate": 1763610323903, "mdate": 1763610323903, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents GaitSnippet, a framework for silhouette-based gait recognition that bridges the gap between unordered set-based and ordered sequence-based approaches. The provided motivation is that traditional set-based models excel at computational efficiency but neglect short-range temporal cues, while sequence-based models capture temporal continuity at the expense of scalability and long-range dependencies. The authors reconceptualize gait as a collection of “snippets” and design a snippet-based pipeline encompassing Snippet Sampling, Snippet Modeling, and Snippet-Level Supervision for gait recognition. Experiments on four public datasets demonstrate consistent performance improvements, achieving state-of-the-art accuracy while maintaining efficiency comparable to 2D models and outperforming more complex 3D backbones."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1) The paper introduces a seemingly new paradigm that redefines how temporal context is encoded in gait recognition. By treating gait as a composition of snippets rather than full sequences or unordered sets, the method unifies short- and long-range temporal modeling.\n\nS2) The pipeline is coherently structured—sampling, modeling, and supervision are all systematically justified and experimentally validated. \n\nS3) The experiments are extensive, spanning multiple datasets and including ablation studies on all major design elements (sampling hyperparameters, snippet block components, supervision weights). The performance gains over both 2D and 3D baselines are convincing and consistent.\n\nS4) The proposed approach achieves better accuracy than heavier 3D models while maintaining a lower computational cost, making it attractive for deployment in real-world gait recognition systems where efficiency is critical."}, "weaknesses": {"value": "O1) While snippets are conceptually appealing, the paper provides limited theoretical justification for why random snippets generalize better than full sequences or unordered sets. The argument about mimicking human perception (recognition from partial cycles) is plausible but not formalized or empirically isolated. It remains unclear whether the improvement stems from better regularization, temporal diversity, or implicit data augmentation.\n\nO2) Although the results are strong, the paper reads as primarily an engineering contribution. There is little analysis of why snippet-level modeling yields gains—e.g., visualization of learned temporal attention, error distribution over gait conditions, or qualitative comparisons of temporal coherence. Such insights would bolster understanding of the snippet paradigm’s internal dynamics.\n\nO3) The architecture largely extends existing 2D residual frameworks by inserting pooling-based temporal operations. The core novelty thus lies more in data organization than in model architecture. \n\nO4) While technically detailed, the paper is verbose and occasionally repetitive (e.g., reiterating motivations for snippets across sections). Also a reader may struggle to identify the primary technical novelty amidst extensive procedural detail.\n\nO5) All experiments are silhouette-based. The paper does not explore how the snippet paradigm could extend to multimodal inputs (e.g., skeletons, RGB) or varying frame rates, which would be important for demonstrating broader impact. Moreover, robustness to occlusion, viewpoint shifts, or missing frames—scenarios where snippet sampling could be advantageous—are not analyzed."}, "questions": {"value": "Please address Weaknesses O1-O4."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7isOupXJ6i", "forum": "y4nkSIOX8L", "replyto": "y4nkSIOX8L", "signatures": ["ICLR.cc/2026/Conference/Submission19087/Reviewer_6tkX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19087/Reviewer_6tkX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19087/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762023545017, "cdate": 1762023545017, "tmdate": 1762931109450, "mdate": 1762931109450, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a novel snippet-based gait recognition method designed to overcome the limitations of traditional approaches: specifically, the lack of long-range modeling in sequence-based methods and the poor short-range temporal context in set-based methods. The core innovation lies in the sampling strategy, which divides the full gait sequence into $M$ equal-length sub-sequences (snippets), from which $N$ frames are uniformly sampled per snippet. For modeling this input, the method introduces intra-snippet and cross-snippet modules, which primarily adopt the structure of set-based methods, allowing for a fully 2D network architecture. Although the concept of snippet-based modeling is inspired by techniques from action recognition, its application in the gait domain yields a model that is both straightforward and efficient."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed method achieves improvements in both retrieval performance and inference speed.\n2. This paper introduces a simple approach to periodic modeling in gait recognition, which only requires an average estimation of frame length to guide snippet sampling. This is practical for gait recognition;\n3. Detailed experiments demonstrate the effectiveness of the sampling strategy and modeling design."}, "weaknesses": {"value": "1. Regarding the framework design, the approach appears incremental and lacks clear differentiation from previous methods. The snippet sampling essentially extends uniform sampling, while the modeling constrains the receptive field through various blocks.\n2. Unlike TSN, which targets general video understanding, gait data exhibits inherent periodicity. Is there any analysis examining how this characteristic influences the snippet design?\n3. Is the 32-frame setting standard in gait recognition tasks, such as among other SOTA methods in Table 1? What is the length of one complete sequence during inference? How is L_1 determined at inference time?"}, "questions": {"value": "Please refer to Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed.", "Yes, Discrimination / bias / fairness concerns", "Yes, Privacy, security and safety", "Yes, Legal compliance (e.g., GDPR, copyright, terms of use, web crawling policies)", "Yes, Potentially harmful insights, methodologies and applications", "Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)", "Yes, Research integrity issues (e.g., plagiarism, dual submission)", "Yes, Unprofessional behaviors (e.g., unprofessional exchange between authors and reviewers)", "Yes, Other reasons (please specify below)"]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fbaHmZpNYm", "forum": "y4nkSIOX8L", "replyto": "y4nkSIOX8L", "signatures": ["ICLR.cc/2026/Conference/Submission19087/Reviewer_fFgr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19087/Reviewer_fFgr"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19087/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762347291106, "cdate": 1762347291106, "tmdate": 1762931108868, "mdate": 1762931108868, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}