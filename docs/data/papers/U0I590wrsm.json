{"id": "U0I590wrsm", "number": 13622, "cdate": 1758219958371, "mdate": 1763721359784, "content": {"title": "Towards Active Synthetic Data Generation for Finetuning Language Models", "abstract": "A common and effective means for improving language model capabilities involves finetuning a “student” language model’s parameters on generations from a more proficient “teacher” model. Termed “synthetic data”, these generations are often produced before any student finetuning, but some work has considered generating new synthetic samples as training progresses. This paper studies and advocates for the latter case, where data are generated in an iterative, closed-loop fashion that is guided by the current state of the student model. For a fixed budget of generated samples, or a budget in terms of compute spent querying a teacher, we show that this curation of finetuning data affords improved student performance over static generation. Further, while there have been several LLM-specific methods proposed that operate in this regime, we find that simple, inexpensive selection criteria from the active learning literature tend to be most performant. We validate these claims across four mathematical and logical reasoning datasets using four different small language models.", "tldr": "Generating synthetic data conditioned on the student model enables more data efficient supervised finetuning.", "keywords": ["Synthetic data generation", "active learning", "language models", "supervised finetuning"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1380d5a0b69f1cd2dca94efd1ba301033bd25b60.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper studies an iterative approach to synthetic data generation for fine-tuning small language models (SLMs). Instead of generating a large static dataset from a teacher model at once, the authors propose a closed-loop scheme where the student model’s current state guides which examples are selected for further data generation by the teacher.\nThe work benchmarks several existing data selection strategies from active learning—uncertainty sampling (high-loss), reward-based scoring, LLM-as-a-judge, and BADGE diversity selection—and claims that simple heuristics like high-loss sampling outperform more expensive LLM-judge–based methods. Experiments are conducted on four reasoning datasets (GSM8K, Math1–3, ProntoQA, Game of 24) using various small instruction-tuned models. Results suggest that simple heuristics such as high-loss selection outperform more complex and expensive methods like LLM-as-a-judge, offering improved data efficiency under a fixed compute budget."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "•\tThe authors provide a solid benchmark showing that simple, inexpensive heuristics (e.g., high-loss selection) can outperform more complex LLM-as-a-judge strategies.\n•\tThe work provides practical guidance for synthetic data generation under constrained compute budgets, which can be valuable for practitioners training SLMs.\n•\tThe paper is clearly written and easy to reproduce.\n•\tIt contributes to the empirical understanding of how different data-selection heuristics impact fine-tuning performance and efficiency."}, "weaknesses": {"value": "•\tLimited novelty: The core idea—iterative, student-aware synthetic data generation—has been explored in multiple prior works. This paper mainly repackages it under the active learning perspective.\n•\tLack of theoretical or conceptual insight: The paper does not explain why the compared heuristics differ or what properties (difficulty, diversity, informativeness) they capture.\n•\tMarginal performance gains: Improvements are small or inconsistent. For GSM8K and ProntoQA, performance remains below or comparable to prior SFT results; only one dataset (Game of 24) shows notable gains.\n•\tScope limitation: All experiments are conducted on small 7–8B models; scalability to larger models or broader domains is untested.\n•\tPotential bias amplification: Since selection is based on student performance, the loop can reinforce sampling bias (e.g., favoring easy samples), which the paper neither analyzes nor mitigates.\n•\tUnclear takeaway: The results show minor absolute improvements, so the main claimed advantage, data efficiency, needs stronger quantitative justification."}, "questions": {"value": "1.\tHow do you ensure that the iterative selection process does not bias the dataset, e.g., easier questions?\n2.\tWhy does the performance of your proposed method have such a better performance, even better than the teacher model, on the Game of 24 dataset? \n3.\tHow would the method behave with a larger teacher model?\n4.\tIn your comparison, you do not control the SFT dataset size. Will that cause unfair comparison among different methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2ndv0NO3rd", "forum": "U0I590wrsm", "replyto": "U0I590wrsm", "signatures": ["ICLR.cc/2026/Conference/Submission13622/Reviewer_3RBg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13622/Reviewer_3RBg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13622/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761673857481, "cdate": 1761673857481, "tmdate": 1762924201783, "mdate": 1762924201783, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Global Response to Reviewers (1/2)"}, "comment": {"value": "We express our gratitude to the Chairs and the Reviewers for spending time reviewing our paper and providing constructive feedback. We are grateful to the Reviewers for recognizing firstly the importance of (1) the practical conclusion that **simple, inexpensive selection heuristics—particularly high-loss prioritization—often outperform more complex and resource-intensive LLM-as-a-judge scoring methods (hUid, R7W1, 3RBg)**, (2) the **clarity and rigor of the experimental framework**, including learning curves, pairwise win-rate matrices, and a unified setup for iterative synthetic data generation (hUid, R7W1), (3) the **breadth and depth of empirical evaluation**, spanning four reasoning datasets, four SLMs, multiple scoring algorithms, multiple seeds and extensive comparisons and ablations (hUid, R7W1), and (4) the **practical relevance of the guidance provided for data-efficient training**, especially under compute-constrained settings, which supports practitioners (R7W1, 3RBg). We are also grateful for constructive critical comments, which helped us to improve the paper!\n\n# Active Synthetic Data Generation (R7W1, 3RBg)\n\nWe agree with the reviewers R7W1 and 3RBg that iterative, student-aware synthetic data generation of questions and answers ($\\hat{z} = (\\hat{x}, \\hat{y})$) for SFT is not a novel contribution of our work. We do not claim to introduce these ideas either and we attribute it to prior work (LLM2LLM [1] and Lion [2]). Our contribution is to provide the first unbiased and rigorous benchmark of selection strategies in this setting, where we draw upon the active learning literature.\n\nPrior work does not disentangle the effect of data selection from synthetic data generation: LLM2LLM compares incorrect prioritization to using the ground-truth dataset, and Lion compares to a separate synthetic dataset (Vicuna), making it unclear whether gains are due to the selection strategy or the synthetic generation process. In contrast, we compare a range of selection methods directly against random sampling/static selection under identical training budgets, allowing performance improvements to be attributed to a selection strategy.\n\n[1] Lee, Nicholas, et al. \"Llm2llm: Boosting llms with novel iterative data enhancement.\" Findings of the Association for Computational Linguistics: ACL 2024. 2024.\n\n[2] Jiang, Yuxin, et al. \"Lion: Adversarial distillation of proprietary large language models.\" arXiv preprint arXiv:2305.12870 (2023).\n\n# Paper updates\n\nAll paper updates are highlighted in orange in the updated manuscript on Openreview.\n\n## Additional conceptual insights (R7W1, 3RBg)\n\nWe have added two new analyses in Section 5.4.3 to better understand the dynamics of synthetic data generation:\n1. First, we show that the synthetic data produced by the teacher statistically resembles the data selected by the student: although individual samples may be rephrased, simplified, or made more complex, with added chain-of-thought, there is a strong correlation at the dataset level, but only a weak correlation per data point. This indicates that synthetic generation preserves global scorer selection biases: if the selected data has a high loss then the synthetic data also has a high loss. \n2. Second, we study the effects on the student and we observe that when the student prioritizes “difficult” data, the teacher also generates data that is difficult for the student. Specifically, prioritizing high-loss or low-reward samples yields synthetic data that produces lower accuracies than random sampling, demonstrating that the teacher generates harder data that ultimately enables greater learning and improved generalization.\n\nBoth of these observations explain why selecting data prior to synthetic data generation results in data that has similar properties to our selected data and therefore leads to enhanced student capabilities upon finetuning. Therefore this is more efficient than pruning the synthetic dataset after synthetic data generation.\n\n## Significant gains in data efficiency (3RBg, R7W1)\n\nRather than comparing percentage accuracy differences in the learning curves, we measure the percentage difference in the amount of student data random sampling requires for equal performance with the best active synthetic data generation methods along the x-axis. This more clearly highlights the substantial performance gains from active selection; random selection requires from 33% to 100% more data than the best active selection methods. These results are now included in Appendix C.3."}}, "id": "cZXssZhidf", "forum": "U0I590wrsm", "replyto": "U0I590wrsm", "signatures": ["ICLR.cc/2026/Conference/Submission13622/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13622/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13622/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763721741897, "cdate": 1763721741897, "tmdate": 1763724073770, "mdate": 1763724073770, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies how to make synthetic data generation for small language model (SLM) finetuning more data-efficient. Instead of static, one-shot generation from a teacher LLM, it proposes an iterative and student-aware approach: at each round, the student model is used to score or select informative examples from a seed set, which then guide new synthetic question–answer pairs generated by the teacher. The student is then finetuned on the accumulated synthetic data. The authors systematically compare several selection criteria—such as student loss, reward score, LLM-as-a-judge, and BADGE—and find that simple active learning strategies (e.g., selecting high-loss samples) outperform complex LLM-based scoring under the same compute budget. Experiments on four reasoning datasets (GSM8K, Math1–3, ProntoQA, and Game of 24) demonstrate strong data efficiency and even near-SOTA SFT performance with an order of magnitude less training data."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- The paper provides a clear and unified experimental framework for iterative synthetic data generation, grounding the idea in active learning principles.\n- Empirical results are extensive: four datasets, four SLMs, multiple scoring algorithms, and comparisons to static generation.\n- The conclusion—that simple, low-cost criteria (e.g., high student loss) outperform expensive LLM-as-a-judge scoring—is practical and well-supported.\n- The ablation on selection design choices (argmax vs. sampling, using prediction vs. ground truth) is detailed and informative.\n- The method achieves impressive data efficiency, matching or exceeding prior SFT performance with far fewer examples."}, "weaknesses": {"value": "- Conceptually, the idea of iterative, student-guided data generation is not entirely new. Prior works such as [1,2,3] (especially 1) have explored similar active distillation loops where the student model guides data selection or teacher queries. However, the present paper does not cite or discuss these connections, nor does it clarify what is fundamentally new beyond applying classic active learning heuristics in this context.\n- The method, while empirically solid, lacks deeper theoretical or conceptual insight into why the high-loss criterion works best—most explanations remain empirical.\n- The study focuses solely on SFT; it would be valuable to test whether the same iterative synthetic data idea scales to RLHF or continual training.\n- Some experiments (e.g., Math1–3) show relatively small margins over static generation, suggesting the benefit may vary with domain or data diversity.\n- The paper does not analyze the diversity or potential overfitting of the generated datasets across iterations.\n\n[1] ELAD: Explanation-Guided Large Language Models Active Distillation. In Findings of the Association for Computational Linguistics: ACL 2024, pages 4463–4475, Bangkok, Thailand. Association for Computational Linguistics.\n\n[2] Evolving knowledge distillation with large language models and active learning. arXiv preprint arXiv:2403.06414.\n\n[3] Active large language model-based knowledge distillation for session-based recommendation. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 39, No. 11, pp. 11607-11615)."}, "questions": {"value": "- How does the proposed iterative generation compare quantitatively with recent active distillation frameworks (e.g., ELAD or Evolving KD) under similar budgets?\n- Could the authors clarify whether the benefit primarily comes from better data selection or progressive curriculum effects from student feedback?\n- How robust is the approach when the teacher’s generation quality degrades (e.g., smaller or domain-specific teachers)?\n- Would the same active selection principles extend to reinforcement-based finetuning or continual pretraining?\n- Could the authors release intermediate synthetic datasets to verify the claimed data-efficiency curves and reproducibility?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "egUHfinc1L", "forum": "U0I590wrsm", "replyto": "U0I590wrsm", "signatures": ["ICLR.cc/2026/Conference/Submission13622/Reviewer_R7W1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13622/Reviewer_R7W1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13622/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761963886431, "cdate": 1761963886431, "tmdate": 1762924201515, "mdate": 1762924201515, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces an iterative, closed-loop method for Active Synthetic Data Generation (ASDG) to finetune Small Language Models (SLMs) using a Teacher LLM. The process leverages the Student's current performance (loss and predictions) to actively select seed prompts for generating new, highly informative synthetic data. The authors formally benchmark various data selection heuristics (including loss, reward, LLM-as-a-judge, and BADGE) across four reasoning datasets and four SLMs. The main finding is that iterative generation is significantly more data-efficient than static generation, and the simple heuristic of prioritizing samples with the highest student loss is the most effective and performant, often achieving competitive results with much larger, statically generated SFT datasets."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The conclusion that simple data selection methods, such as prioritizing hard samples with high loss, often outperform complicated and expensive LLM-as-a-judge based methods is a useful result for practitioners, suggesting that resource-intensive scoring is not always necessary.\n\nThe use of learning curves and the pairwise win-rate matrix (Figure 4) provides a structured comparative analysis focused on the core concept of data efficiency.\n\nAnalysis is thorough, covering four distinct reasoning datasets (GSM8k, Math1-3, ProntoQA, Game of 24) and four different student SLMs (Mistral 7B, Llama 3 8B, Qwen 7B, Qwen 2.5 7B)."}, "weaknesses": {"value": "The paper claims to provide a \"benchmark study for iterative synthetic data generation\" but fails to run a head-to-head comparison against the actual selection methods proposed by the most relevant prior works, specifically LLM2LLM (Lee et al., 2024) and the full LION (Jiang et al., 2023c) strategy. The critical \"incorrect student answers\" criterion from LLM2LLM is relegated to the appendix (C.1) despite being a highly competitive baseline in a truly active synthetic data setting.\n\nLimitations in Experimental Scale and Baseline Selection Validity: 1) The paper focuses on a small, fixed training budget (1k samples per iteration, max total 10k for GSM8k/Math1-3). This scale is extremely small for finetuning modern SLMs, especially when compared to the multi-hundred thousand to multi-million sample sizes used by SOTA baselines in Table 1. While the relative performance of the selection methods within this small budget is clear, can the absolute efficiency claims scaling up with data? 2) Static Generation (Random Sampling) is Too Weak: This is the weakest possible baseline. A more competitive baseline would be a fixed synthetic dataset filtered using some non-active metric (e.g., high reward score, or high diversity selection applied once). The superiority of any student-aware curriculum over pure random sampling is expected, so the magnitude of this win is not fully persuasive.\n\nInsufficient Discussion of Computational Budget and Trade-offs The paper frames the work around a \"fixed data generation budget\" (L14). However, the budget analysis is incomplete. 1) Teacher Output Cost is Missing: The current analysis (Figure 5) only uses Input Tokens as a proxy for compute. Since the primary cost for Chain-of-Thought (CoT) generation is the Teacher's Output Tokens, omitting this cost makes the true teacher compute comparison incomplete. 2) Student Cost is Ignored: The iterative loop requires the student to make predictions and compute gradients on the entire seed set $D_{0}$ at every iteration. This computational overhead on the student's side grows with the seed set size and the number of iterations ($|D_0| \\times T$), and should be explicitly discussed in the efficiency trade-off analysis."}, "questions": {"value": "The authors state they have access to the ground-truth label $y$ but find that using the loss from the model's own generation $\\mathcal{L}(z_i, \\theta)$ (\"uncertainty\") is more effective than the true loss $\\mathcal{L}(z_i, y)$. This counter-intuitive finding is not explored beyond a single sentence. Why is using the model's own (potentially incorrect) generation as the target label better than using the verified ground truth label? This requires deeper analysis.\n\nWhy BADGE Implementation? The critical decision to use generated sequences instead of ground-truth targets for BADGE's gradient representations (L243-245) lacks sufficient justification, similar to the loss/uncertainty choice."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8FM7rYGLzC", "forum": "U0I590wrsm", "replyto": "U0I590wrsm", "signatures": ["ICLR.cc/2026/Conference/Submission13622/Reviewer_hUid"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13622/Reviewer_hUid"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13622/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762242230880, "cdate": 1762242230880, "tmdate": 1762924201184, "mdate": 1762924201184, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}