{"id": "46AQ4qaWqQ", "number": 15893, "cdate": 1758256713822, "mdate": 1759897274813, "content": {"title": "SynthWorlds: Controlled Parallel Worlds for Disentangling Reasoning and Knowledge in Language Models", "abstract": "Evaluating the reasoning ability of language models (LMs) is complicated by their extensive parametric world knowledge, where benchmark performance often reflects factual recall rather than genuine reasoning. Existing datasets and approaches (e.g., temporal filtering, paraphrasing, adversarial substitution) cannot cleanly separate the two. We present SynthWorlds, a framework that disentangles task reasoning complexity from factual knowledge. In SynthWorlds, we construct parallel corpora representing two worlds with identical interconnected structure: a real-mapped world, where models may exploit parametric knowledge, and a synthetic-mapped world, where such knowledge is meaningless. On top of these corpora, we design two mirrored tasks as case studies: multi-hop question answering and page navigation, which maintain equal reasoning difficulty across worlds. Experiments in parametric-only (e.g., closed-book QA) and knowledge-augmented (e.g., retrieval-augmented) LM settings reveal a persistent *knowledge advantage gap*, defined as the performance boost models gain from memorized parametric world knowledge. Knowledge acquisition and integration mechanisms reduce but do not eliminate this gap, highlighting opportunities for system improvements. Fully automatic and scalable, SynthWorlds provides a controlled environment for evaluating LMs in ways that were previously challenging, enabling precise and testable comparisons of reasoning and memorization.", "tldr": "We introduce a framework and benchmark to disentangle task reasoning from parametric knowledge in LLMs.", "keywords": ["LLM Reasoning", "Agents", "Controlled Evaluation", "RAG"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8411e2a9d0b5e23e2d353abe9c6c90ad0a0f9d5e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates the real capability of reasoning of LLMs when isolating parametric knowledge. They design a simulated world from the Wiki so that both simulated world and real world share the same degree of difficulty. After that, they conduct detailed experiments and analyze the effect of reasoning and knowledge."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- This paper provides a detailed construction pipeline for a simulated world from the real world, including entity selection, question construction, and human annotation.\n- This paper rigorously analyzes the effect of reasoning disentangled from parametric knowledge, using commonsense/multi-hop QA and page navigation."}, "weaknesses": {"value": "- All the experiments are based on closed-source models. Some open-sourced models should be included, e.g., DeepSeek-V3.1 and K2, and various model sizes should be considered for generability, e.g., Qwen3 series."}, "questions": {"value": "- For page navigation, is the content simulated or from the real world? I wonder if you could report the difference between the minimum steps needed to reach the final page and the steps LLMs take to reach the final page to see whether there is a potential shortcut.\n- Could you explain why the F1-Score of Multi-hop QA of SM is higher in reading comprehension, since it is counterfactual (maybe) and should not be higher than RM.\n- Coule you train an embedding model from scratch using you real-world corpora and simulated-world corpora separately to ablate the effect of LLM retrievals since they are constructed from the same source?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Xkyktw4gBL", "forum": "46AQ4qaWqQ", "replyto": "46AQ4qaWqQ", "signatures": ["ICLR.cc/2026/Conference/Submission15893/Reviewer_Ra5g"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15893/Reviewer_Ra5g"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15893/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760586403863, "cdate": 1760586403863, "tmdate": 1762926108815, "mdate": 1762926108815, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "SynthWorlds proposes a fully automatic, scalable framework to disentangle language-model reasoning from memorized factual knowledge by constructing parallel corpora and tasks in two mirrored worlds—real-mapped (RM) and synth-mapped (SM)—and measuring a knowledge advantage (KA) gap, i.e., the performance difference between RM and SM conditions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper offers a novel and well-motivated formulation of disentangling reasoning from memorized factual knowledge by constructing paired “real-mapped” and “synth-mapped” worlds with matched structure, and by introducing a formal knowledge-advantage metric to quantify the contribution of parametric knowledge.\n2. The data-generation pipeline is fully automated; difficulty is explicitly controlled; the evaluations span parallel multi-hop QA and page navigation tasks; and the comparisons cover closed-book, single-step RAG, and iterative reasoning–retrieval (IRCoT + RAG) across multiple models with appropriate metrics, yielding credible, interpretable results."}, "weaknesses": {"value": "1. Conclusions are based on two property models; it is unclear how KA scales with capacity or how post-training techniques affect KA.\n2. The corpus and questions derived largely from one source (Wikidata) may yield relation distributions and writing style that favor certain generalization paths, which may disrupt the evaluation.\n3. Although the benchmark proposed in the paper can quantify KA, the quantification results do not seem surprising. Moreover, it is not yet shown that improvements on SynthWorlds translate to gains on standard web or scientific tasks."}, "questions": {"value": "1. Do the findings persist across model sizes within a family? Please discuss whether scaling reduces the gap via better retrieval or stronger reasoning.\n2. Can you include at least one additional domain (e.g., biomedical/software) and report the results?\n3. What are the dominant RM vs. SM failure modes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VXV6bkbI5m", "forum": "46AQ4qaWqQ", "replyto": "46AQ4qaWqQ", "signatures": ["ICLR.cc/2026/Conference/Submission15893/Reviewer_HETT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15893/Reviewer_HETT"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15893/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760840985009, "cdate": 1760840985009, "tmdate": 1762926108246, "mdate": 1762926108246, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "SYNTHWORLDS introduces a novel framework to disentangle reasoning from factual knowledge in language models by constructing parallel corpora: a real-mapped world with familiar entities and a synthetic-mapped world with renamed entities, preserving identical reasoning structures while obscuring parametric knowledge. Through case studies on multi-hop question answering and page navigation, experiments reveal a persistent knowledge advantage gap, where LMs like GPT-5-mini and Gemini-2.0-Flash perform better in RM settings even with retrieval augmentation, highlighting reliance on memorized knowledge. This scalable, automated approach enables controlled evaluation, offering datasets and tasks that facilitate precise analysis of reasoning abilities, with contributions including a generation pipeline, public corpora, and empirical insights into LM limitations in novel environments."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- SYNTHWORLDS uniquely separates reasoning complexity from parametric knowledge through parallel corpora.\n- The framework is fully automatic and scalable, leveraging knowledge graphs (e.g., Wikidata) to generate large, interconnected corpora without manual curation."}, "weaknesses": {"value": "- This paper proposes the challenges in distinguishing reasoning from reciting for controlled evaluation. However, we don't know whether the paper really solve this problem. I mean, if your scores can precisely reflect the real reasoning abilities of LLMs, then you should observe a correlation between human preference (e.g. LM Arena Rankings on Reasoning) and your scores.\n- This paper mentions two kinds previous approaches on controlled evaluation: (1) curation of “clean” evaluation sets and (2) synthetic\ndataset generation, but the authors did not compare their method with these methods in experiments. I know you may argue you did not know how to measure the effectiveness of evaluation methodologies on controlled evaluation. You may refer to this work's settings for comparison experiments [1].\n- Typo: Line 102: \" (§5).Across\" has no space between \")\" and \"Across\".\n\n\n[1]  Establishing Trustworthy LLM Evaluation via Shortcut Neuron Analysis. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3809–3822, Vienna, Austria. Association for Computational Linguistics."}, "questions": {"value": "- The paper defines the Knowledge Advantage Gap as a core metric. To what extent can this metric be generalized to other domains beyond the structured knowledge of Wikidata (e.g., mathematical reasoning or code generation)?\n- If the framework and its generated datasets become widely adopted, what prevents future LMs from being trained on generations of SYNTHWORLDS-style corpora?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1voqYtYD0o", "forum": "46AQ4qaWqQ", "replyto": "46AQ4qaWqQ", "signatures": ["ICLR.cc/2026/Conference/Submission15893/Reviewer_2dyf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15893/Reviewer_2dyf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15893/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760929964009, "cdate": 1760929964009, "tmdate": 1762926107774, "mdate": 1762926107774, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces SynthWorlds, a framework to create multi-hop questions and page navigation benchmarks from a knowledge graph e.g. WikiData and assess an LM’s memorized factual knowledge. SynthWorlds builds two parallel corpora on a knowledge graph, one with real-world entities and another with synthetically generated ones, to keep reasoning complexity identical while removing factual familiarity that an LM could utilize in the real-world setting. The paper measures the “knowledge advantage gap” i.e. the LM’s parametric knowledge memorized in its weights, demonstrating this in frontier LLMs like GPT-5-mini and Gemini-2.0-Flash. Even in RAG-based approaches, this gap can exist."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The introduction is extremely well-written, just exquisite writing. I especially liked lines 59 through 76.\n2. For synthetic multi-hop QA data generation to evaluate LMs, the paper presents the right next step by building synthetic datasets on top of the real-world Wikipedia knowledge graph that captures the complex interconnectedness and messiness. I think this paper is exciting for the field of multi-hop reasoning evaluation.\n3. SynthWorlds contains a set of reasoning motifs, e.g., constraints and joins, that are not just logical compositions. This makes the questions more realistic; however, the question difficulty is unclear. I guess this is a tradeoff: in contrast to PhantomWiki that had logical compositions only, the question difficulty (reasoning steps) was simply the sum of the number of hops."}, "weaknesses": {"value": "1. The authors heavily talk about determining knowledge gaps as the main contribution, but mention task reasoning difficulty in contribution 1 and Sec 3 line 205 as a main contribution. It is clear how SynthWorlds is evaluating knowledge gaps, but not clear at all how to determine task reasoning difficulty. It would be good to discuss this, since it's a main contribution of the work.\n2. A major limitation is that SynthWorlds requires a knowledge graph to exist for a document corpus (Wikidata graph in the case of Wikipedia). I would be curious about what the authors think could work when we only have access to Wikipedia but not Wikidata.\n3. Because the questions and documents from the graph G_facts are LM generated, there is no clear way to automatically verify full correctness. And what if the questions contain parametric knowledge from the LM generating the questions? There is discussion in App B.2 about human validation; however, I'm interested in automatic validation techniques or correct-by-design question/document generation.\n4. Since the SM is created once, future LLMs would memorize it once uploaded to the internet. Is there a clear pipeline for creating synthetic worlds from scratch and any knowledge graph? Several synthetic benchmarks create knowledge graphs from scratch (although not as realistic as WikiData), and LLM memorization is not helpful by design, e.g., PhantomWiki and GSM-Infinite."}, "questions": {"value": "1. Why not generate multiple SMs for a given RM? And take the average performance with stderr?\n2. Line 194: The augmented case is unclear. What do the authors mean by \"providing the model with external knowledge acquisition and integration strategies\"? Does baseline just mean CoT prompting with a few CoT examples, and augmented mean RAG prompting? If so, it would be better to just say that.\n3. Line 194: What is \"near random\"? Since these questions are open-ended QA and not multiple-choice, shouldn't P_S^base be near 0? i.e., the LM can't answer those questions at all in the baseline setting?\n4. Line 202: The example of \"rivers remain river-like...\" does not improve clarity. Is there a better concrete example?\n5. Figure 4: I'm confused why the Recall@5 for RM and SM (blue and orange) are not about the same. This is measuring the fraction of times the correct document was retrieved from the corpus, right? Since this is offloaded to an embedding-based retriever, why is the recall higher for RM over SM?\n6. How are the authors calculating error bars in Fig 4, 5, etc.?\n7. Are questions in page navigation baselines also formed using reasoning motifs? Then in Figure 5 it would make sense to club results by reasoning motifs, like in Figure 4. See the other comment about improving Figure 5 axes.\n\n### Typos and editorial suggestions\n1. Line 65: It would be useful to add citations for synthetic data generation that use existing content directly and template-based evaluation. This would parallel the previous example with ToolQA and Zhang et al., Mirzadeh et al. work.\n2. Line 89: \"Surface-form-consistent transformations\" is an uncommon term in the literature, so it would be best to paraphrase this in layman's terms, or define it explicitly here.\n3. Figure 5: Instead of breaking up the plots by expected random walk distance, it would be good to do a line plot, with success rate on the y-axis, expected random walk distance on the x-axis, a blue line for RM and orange for SM. Then you could have 2 plots per model, one for Links and another for Cont+Links. It makes more sense to demonstrate success as a function of difficulty. The current plot highlights Links vs. Cont+Links more, which I don't think is the main point that the authors are driving home. The plot would be similar to that of PhantomWiki (Gong et al.)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "43BuTmCynl", "forum": "46AQ4qaWqQ", "replyto": "46AQ4qaWqQ", "signatures": ["ICLR.cc/2026/Conference/Submission15893/Reviewer_raJh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15893/Reviewer_raJh"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15893/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761936207269, "cdate": 1761936207269, "tmdate": 1762926107349, "mdate": 1762926107349, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}