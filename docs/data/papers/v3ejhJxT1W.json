{"id": "v3ejhJxT1W", "number": 19313, "cdate": 1758295329285, "mdate": 1759897046114, "content": {"title": "Splat the Net: Radiance Fields with Splattable Neural Primitives", "abstract": "Radiance fields have emerged as a predominant representation for modeling 3D scene appearance. Neural formulations such as Neural Radiance Fields provide high expressivity but require costly ray marching for rendering, whereas primitive-based methods such as 3D Gaussian Splatting offer real-time efficiency through splatting, yet at the expense of representational power. Inspired by advances in both these directions, we introduce splattable neural primitives, a new volumetric representation that reconciles the expressivity of neural models with the efficiency of primitive-based splatting. Each primitive encodes a bounded neural density field parameterized by a shallow neural network. Our formulation admits an exact analytical solution for line integrals, enabling efficient computation of perspectively accurate splatting kernels. As a result, our representation supports integration along view rays without the need for costly ray marching. The primitives flexibly adapt to scene geometry and, being larger than prior analytic primitives, reduce the number required per scene. On novel-view synthesis benchmarks, our approach matches the quality and speed of 3D Gaussian Splatting while using 10x fewer primitives and 6x fewer parameters. These advantages arise directly from the representation itself, without reliance on complex control or adaptation frameworks.", "tldr": "", "keywords": ["neural rendering", "radiance field representation", "3DGS", "NeRF"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fb94b7aa231f87d1d7786c38865ca68afe00681c.pdf", "supplementary_material": "/attachment/fcdb687caeae23715617f1ed8f8582b7bae62bd5.pdf"}, "replies": [{"content": {"summary": {"value": "The paper proposes Splat the Net, a unified representation that integrates the expressivity of neural radiance fields with the real-time rendering efficiency of splatting-based approaches. Each primitive in the proposed framework defines a bounded neural density field represented by a shallow sinusoidal network, for which the authors derive a closed-form solution to line integrals along view rays.\nThis analytic construction practically allows accurate, differentiable rendering without ray marching. The approach achieves state-of-the-art visual quality on multiple benchmarks, such as NeRF Synthetic, Mip-NeRF360, and Tanks & Temples, while requiring an order of magnitude fewer primitives and parameters than 3D Gaussian Splatting."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed framework is novel and well-explored. By introducing neural primitives that can be analytically integrated and splatted, the authors effectively bridge two traditionally separate families of radiance field models.\n2. The resulting design reconciles neural expressivity with analytic efficiency, achieving a favorable trade-off between compactness, rendering quality, and runtime.\n3. The paper provides extensive experiments across synthetic and real benchmarks, complemented by ablations and visual comparisons that clearly support the claims."}, "weaknesses": {"value": "1. The reliance on per-primitive neural parameters may constrain the method’s scalability and practicality, particularly in memory-limited environments.\n2. While the experimental results are comprehensive, the paper could be further strengthened by a brief discussion of scenarios where the proposed neural primitives may be less effective, which would help clarify the scope and robustness of the approach."}, "questions": {"value": "Given that training is more computationally demanding than purely analytic splatting, are there potential strategies—such as improved initialization, parameter sharing, or adaptive optimization—that could help accelerate convergence?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mHX7e0eFVW", "forum": "v3ejhJxT1W", "replyto": "v3ejhJxT1W", "signatures": ["ICLR.cc/2026/Conference/Submission19313/Reviewer_awhh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19313/Reviewer_awhh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19313/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761295691271, "cdate": 1761295691271, "tmdate": 1762931261741, "mdate": 1762931261741, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Common Questions"}, "comment": {"value": "We thank all reviewers for their thoughtful comments and feedback. We will include all elaborations, analyses, and ablation studies discussed in this rebuttal in the final version of the paper. We first address the common questions raised by multiple reviewers, and then respond to the individual questions from each reviewer separately.\n# **Extension to Large-Scale Scenes** \nWe agree that supporting very large-scale environments is an interesting aspect of scene representations. However, our focus in this work is on the core representational aspects and designing such a representation rather than on the engineering challenges associated with scaling to very large scenes, which we instead evaluate on standard datasets of the field. As the reviewers are aware, recent scene representations such as NeRF and 3DGS likewise addressed such settings only in later follow-up works [1,2], which have since developed into an active research direction of their own.\n\nAt the same time, we believe that our novel scene representation offers several characteristics that make it well-suited for scaling up. Requiring an order of magnitude fewer primitives and achieving a corresponding sixfold reduction in memory compared to 3DGS–while still maintaining over 100 FPS on challenging real scenes and without any dedicated control or compression mechanisms–makes splattable neural primitives a promising basis for future work in this direction. Since the number of primitives typically scales roughly linearly with scene size, starting from a representation that is already significantly more compact directly facilitates scaling to much larger environments. Moreover, our primitive-based representation can directly benefit from ongoing research on scaling up 3DGS, for example, through hierarchical structures.\n\n[1]Grid-guided Neural Radiance Fields for Large Urban Scenes\n\n[2]CityGaussian: Real-time High-quality Large-Scale Scene Rendering with Gaussians\n\n# **Optimization Challenges & Complexity** \nWhile the total number of parameters in our representation is significantly lower than in established 3DGS (Ours-92 MB vs 3DGS-734 MB), the optimization dynamics of our neural primitives differ and typically require more training iterations to converge. Nevertheless, we do not consider the optimization to be more complex than in 3DGS (based on real scene evaluation experiments). In fact, our approach relies on **fewer** stabilizing control mechanisms and requires tuning **fewer** hyperparameters–for instance, it does not rely on heuristic opacity resetting at regular intervals like 3DGS does. It remains an interesting and important future research direction to investigate methods for accelerating convergence and improving the optimization process of neural primitives.\n# **Failure Modes** \nWhile we occasionally observe minor difficulties of our representation in accurately fitting certain scene elements, we did not identify any discernible failure modes. These effects are not specific to particular shapes or scenes but tend to correlate with overall scene complexity. We will incorporate a more detailed discussion in a revised version of the paper to help readers better assess the challenging scenarios for our representation. \n# **Ablation Study**  \n## *Network Width*\nWe analyze the effect of network width (number of neurons N and frequency w0) on all MipNeRF360 scenes. To facilitate a meaningful comparison, we resume training from a pretrained checkpoint and disable the densification process. This setup eliminates the influence of the number of primitives.\nWe report PSNR values and memory footprint in the following table:\n|N|Memory(MB)|w0=1|w0=10|w0=30|w0=50|\n|:-:|:-:|:-:|:-:|:-:|:-:|\n|4|73|26.35|27.29|27.33|27.12|\n|8|92|26.32|27.42|27.54|27.41|\n|16|129|26.19|27.46|27.62|27.55|\n\nWe see that increasing the frequency​ improves PSNR up to w0=30. At w0=30, the PSNR gain from increasing N from 4 to 8 is larger than the gain from increasing N from 8 to 16. However, the memory cost from 8 to 16 is significantly higher (37MB) compared to the cost from 4 to 8 (19MB). Therefore, we set w0=30 and N=8 as our final configuration.\n## *Initialization*\nWe appreciate the reviewer's suggestion for training robustness under different initialization strategies. However, we note that some of the suggested strategies (noisy/sparse seeds, or purely random placements/shapes) are not typically encountered in practice. For real scene evaluation, our initialization is the result of SfM (a point cloud), similar to other 3DGS-based methods. Regarding the NeRF Synthetic dataset, in the unlimited budget setting, we agree that mesh-based initialization, as employed in the limited budget setting for expressivity analysis, introduces ambiguities. We have now re-run the experiments with random initialization and observed that it performs the same (PSNR: ours 33.36 vs 3DGS 33.32). Hence, ours is not sensitive to initialization (ours achieves 33.40 PSNR with mesh-based initialization)."}}, "id": "lhmTiPQRbu", "forum": "v3ejhJxT1W", "replyto": "v3ejhJxT1W", "signatures": ["ICLR.cc/2026/Conference/Submission19313/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19313/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19313/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763682730321, "cdate": 1763682730321, "tmdate": 1763682730321, "mdate": 1763682730321, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes splattable neural primitives: volumetric, ellipsoid-bounded primitives whose density is represented by a shallow neural network with periodic activation. A key technical claim is a closed-form antiderivative for line integrals through the neural density, which yields a perspectively accurate splatting kernel and thus avoids ray marching while retaining neural expressivity. Empirically, on synthetic and real novel-view synthesis benchmarks, the method targets the quality/speed of 3D Gaussian Splatting (3DGS) while using ~10× fewer primitives and ~6× fewer parameters, attributing the gains to the representation itself rather than to heavy control frameworks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "This paper introduces a neural primitive whose volumetric density is learned via a one-hidden-layer MLP, yet remains analytically integrable along rays. This bridges the perceived “neural vs. primitive” dichotomy and is, to my knowledge, a first in making the primitive itself neural while still splatting.\nThe analytical formulation is clearly spelled out (ray–ellipsoid intersection, anti-derivative, front-to-back alpha compositing), and the implementation details include population control (split/duplicate/prune via weight-gradient magnitudes) and geometric regularization to avoid degenerate ellipsoids.\nAblations probe network width/frequency and the effect of regularization; comparisons to an alternative neural integration strategy (AutoInt) clarify multi-view consistency benefits."}, "weaknesses": {"value": "1. While the representation is new, final image quality/speed sometimes appears comparable to strong modern 3DGS variants that incorporate compression/regularization/adaptive control (e.g., BetaGS, T-3DGS, structured/linear kernels), some of which achieve very low memory or high FPS. A more direct, apples-to-apples model-size / memory / bandwidth comparison to these compression-oriented pipelines would clarify the net practical advantage. (Table 2 partially covers this, but a focused compression study would help.)\n2. Adding per-primitive neural components (albeit shallow) complicates implementation relative to purely analytic Gaussians, which map naturally to existing graphics pipelines and hardware rasterization paths. This may limit industrial adoption unless the benefits (fewer primitives, comparable speed) translate into easier deployment (e.g., on mobile/embedded) than a tuned Gaussian pipeline. A short discussion of engine integration, batching, and runtime kernels would strengthen practical significance. (Authors do note PyTorch/CUDA implementation.)\n3. On the synthetic dataset, initializing primitive positions from resampled ground-truth meshes risks leaking geometry and may overstate robustness; a stronger setting would evaluate multiple non-oracle inits (sparse SfM points, random, noisy depth). The paper acknowledges slow convergence vs. Gaussians and extends training, which heightens the importance of init robustness.\n4. It may be worth to consider augmenting each primitive with a small learnable feature vector as additional input to the MLP to further boost expressivity under fixed primitive counts; this could bridge to richer local modulation without exploding primitive numbers."}, "questions": {"value": "How robust is training to different initializations (e.g., sparse SfM points, noisy/sparse seeds, or purely random placements/shapes)? Can you report quantitative results (PSNR/SSIM/LPIPS, convergence rate) and qualitative failure modes across several inits on both synthetic and real scenes? (This would mitigate concerns about mesh-based seeding.)\nThe authors extend training to 100k iterations due to slower convergence. Can you share wall-clock training time comparisons and memory bandwidth/throughput metrics vs. 3DGS?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Wt9PdDaH2g", "forum": "v3ejhJxT1W", "replyto": "v3ejhJxT1W", "signatures": ["ICLR.cc/2026/Conference/Submission19313/Reviewer_ByAG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19313/Reviewer_ByAG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19313/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761709889387, "cdate": 1761709889387, "tmdate": 1762931261366, "mdate": 1762931261366, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces splattable neural primitives, a hybrid radiance field representation designed to unify the expressivity of neural radiance fields with the efficiency of splatting-based rendering. Each primitive is represented as an ellipsoid-bounded neural density field, parameterized by a shallow sinusoidal network that admits a closed-form integral along view rays. This analytical formulation eliminates the need for expensive ray marching while retaining multi-view consistency. Experiments on both synthetic and real-world datasets demonstrate that the proposed approach achieves comparable or superior performance to 3D Gaussian Splatting (3DGS), requiring ten times fewer primitives and fewer parameters overall."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed formulation is conceptually sound and well motivated. Representing volumetric primitives as shallow neural fields bounded by ellipsoids provides an elegant way to connect neural and analytic splatting methods under a single theoretical framework.\n\n2. The analytical derivation of the antiderivative for the density field is mathematically consistent and efficiently implemented, offering a clear path to rendering without ray marching.\n\n3. Experimental results indicate that the proposed neural primitives maintain strong image quality under strict memory constraints, remaining both compact and efficient."}, "weaknesses": {"value": "1. The overall training process is more complex, requiring more iterations and careful convergence control due to the optimization of numerous small neural modules.\n\n2. While the ablation studies illustrate the role of model parameters, a more detailed analysis of trade-offs between expressivity, convergence, and stability would have strengthened the paper’s argument.\n\n3. The impact of network width or frequency choices on quality and efficiency remains underexplored in the ablation section."}, "questions": {"value": "1. How does performance vary with different configurations of network width and frequency? \n\n2. The scalability of the method for very large scenes is insufficiently discussed, how does runtime and memory usage scale with the number of primitives in such scenes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "98WvRK62Y1", "forum": "v3ejhJxT1W", "replyto": "v3ejhJxT1W", "signatures": ["ICLR.cc/2026/Conference/Submission19313/Reviewer_FKH4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19313/Reviewer_FKH4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19313/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761744794784, "cdate": 1761744794784, "tmdate": 1762931260107, "mdate": 1762931260107, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces \"splattable neural primitives,\" a novel radiance field representation that combines the expressivity of neural networks with the rendering efficiency of primitive-based splatting. Each primitive is an ellipsoid-bounded volume with a shallow neural network defining its density field, enabling exact analytical integration along view rays. The method achieves real-time rendering performance comparable to 3D Gaussian Splatting (3DGS) while using significantly fewer primitives (10×) and parameters (6×), demonstrating strong results on synthetic and real-world novel-view synthesis benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Novel Representation: The proposal of fundamentally neural primitives with closed-form ray integration is a conceptually clean and innovative contribution. It successfully bridges the gap between expressive neural fields and efficient splatting-based rendering, a notable advance in the field.\n2. Empirical Efficiency: The method demonstrates compelling practical benefits, matching 3DGS's quality and speed while drastically reducing primitive and parameter counts. This efficiency is directly attributed to the representation's inherent expressivity, not external control mechanisms."}, "weaknesses": {"value": "1. Optimization Challenges: The paper acknowledges slower convergence and difficulties in optimizing millions of neural primitives due to a complex loss landscape. This suggests the method may be less robust or more sensitive to training configurations compared to established baselines like 3DGS.\n2. Limited Ablation on Real Scenes: While toy examples (e.g., Snowflake, Leaf) effectively showcase expressivity, the ablation studies on network width and regularization lack depth for complex real-world scenes. The claimed expressivity advantage is not fully quantified or visually demonstrated on challenging benchmarks."}, "questions": {"value": "1. Scalability & Robustness: Given the optimization difficulties mentioned, how does the method scale to extremely large, unbounded outdoor scenes? Are there specific types of scenes or geometries where the neural primitives consistently fail or underperform?\n2. Integration Cost: The paper emphasizes \"exact\" and \"efficient\" integration. What is the precise computational overhead of evaluating the analytical anti-derivative compared to a single 3D Gaussian splatting kernel? A breakdown of rendering time (integration vs. blending) would clarify the practical trade-offs."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "ZcsIikAtaI", "forum": "v3ejhJxT1W", "replyto": "v3ejhJxT1W", "signatures": ["ICLR.cc/2026/Conference/Submission19313/Reviewer_4maN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19313/Reviewer_4maN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19313/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761913347441, "cdate": 1761913347441, "tmdate": 1762931259688, "mdate": 1762931259688, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}