{"id": "fdp7klHmnn", "number": 2525, "cdate": 1757133577609, "mdate": 1759898142992, "content": {"title": "Robust Learning of Diffusion Models with Extremely Noisy Conditions", "abstract": "Conditional diffusion models have the generative controllability by incorporating external conditions. However, their performance significantly degrades with noisy conditions, such as corrupted labels in the image generation or unreliable observations or states in the control policy generation. This paper introduces a robust learning framework to address extremely noisy conditions in conditional diffusion models. We empirically demonstrate that existing noise-robust methods fail when the noise level is high. \nTo overcome this, we propose learning pseudo conditions as surrogates for clean conditions and refining pseudo ones progressively via the technique of temporal ensembling. Additionally, we develop a Reverse-time Diffusion Condition (RDC) technique, which diffuses pseudo conditions to reinforce the \\textit{memorization effect} and further facilitate the refinement of the pseudo conditions. \nExperimentally, our approach achieves state-of-the-art performance across a range of noise levels on both class-conditional image generation and visuomotor policy generation tasks.", "tldr": "", "keywords": ["diffusion models", "noisy conditions", "generation controllability"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b088d813489b30dc2f32fcdfc873ddd539b79548.pdf", "supplementary_material": "/attachment/b719ad5a0926451c7cc41e61eb83b8aac0f80976.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces a robust learning framework for conditional diffusion models under extremely noisy conditions, such as corrupted labels or unreliable observations. The authors identify that existing noise-robust methods fail when noise levels are high, and propose two key innovations:\n\nPseudo Conditions (PC): A surrogate for clean conditions, initialized from noisy ones and progressively refined using temporal ensembling and early stopping to avoid overfitting.\n\nReverse-time Diffusion Condition (RDC): A technique that applies the diffusion process to pseudo conditions in reverse, enhancing memorization and stabilizing training under noise.\n\nThe method is evaluated on class-conditional image generation (CIFAR-10/100) and visuomotor policy generation (Push-T), achieving state-of-the-art performance across various noise levels. Ablation studies confirm the effectiveness of both PC and RDC components."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper introduces a genuinely new role for diffusion dynamics: instead of diffusing only the image, it diffuses the condition itself in reverse time (RDC). This is not a minor tweak; it reframes the noisy-label problem as a joint denoising task in both pixel and label space and gives the diffusion model a self-contained way to “hallucinate then refine” its own conditioning signal.\n\nThe combination of (i) learning a pseudo-condition, (ii) updating it via temporal ensembling, and (iii) injecting it back through an RDC augmentation has not appeared before in the diffusion literature. Even individually, these ideas are creatively re-purposed from semi-supervised learning, mean-teacher methods, and score-based generative models.\n\nThe work removes a key limitation of prior label-noise diffusion papers (TDSM, RCGAN, etc.)—the need to estimate an explicit noise-transition matrix—and still works when 80 % of the labels are adversarially corrupted.\n\nThe method is model-agnostic: any conditional diffusion backbone (U-Net, DiT, etc.) can slot in the lightweight prediction head and RDC loss. This makes the barrier to adoption low for practitioners who already have diffusion pipelines.\n\n It opens a new research direction—self-correcting conditional diffusion—that could extend to text-to-image (noisy captions), reinforcement learning (noisy rewards), or audio (transcript errors)."}, "weaknesses": {"value": "The paper motivates RDC by analogy to “data augmentation with Gaussian noise” and by an intuitive SDE reversal, but it never proves that the reverse-time diffusion of the condition actually improves the denoising error or the posterior p(clean-label | noisy-label).\n\n\nTraining freezes the pseudo-label at 25 k (CIFAR-10) or 30 k (CIFAR-100) iterations—numbers taken from a grid search on clean validation data. In real noisy-data scenarios we do not have clean validation labels."}, "questions": {"value": "Refer to Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "872lKJyjSu", "forum": "fdp7klHmnn", "replyto": "fdp7klHmnn", "signatures": ["ICLR.cc/2026/Conference/Submission2525/Reviewer_FovT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2525/Reviewer_FovT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2525/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761808045747, "cdate": 1761808045747, "tmdate": 1762916267876, "mdate": 1762916267876, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "## Review of “ROBUST LEARNING OF DIFFUSION MODELS WITH EXTREMELY NOISY CONDITIONS”\n\n### Summary\nThe paper studies conditional diffusion models when the conditioning signal (labels for class-conditional image generation, visual observations for visuomotor policy generation) is extremely noisy. The authors argue existing robustness methods fail at high noise rates and propose two ideas:\n1. **Pseudo condition (PC):** learn a per-sample latent “pseudo condition” \\(\\hat y\\) using a lightweight prediction head and temporal ensembling, then gradually replace the noisy condition \\(\\tilde y\\) with \\(\\hat y\\).\n2. **Reverse-time Diffusion Condition (RDC):** inject noise into \\(\\hat y\\) via a reverse-time SDE so that the model must learn to generate conditioned on progressively denoised pseudo conditions.\n\nThey claim state-of-the-art performance on CIFAR-10/100 with up to 80% label noise and on a visuomotor policy learning benchmark with distorted camera inputs."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper targets a setting that is undeniably important: conditional diffusion models trained with highly corrupted conditioning signals, including 60–80% incorrect class labels on CIFAR-style datasets and visual inputs with heavy distortion in visuomotor tasks. Even if the proposed solutions need more clarity, the problem itself is real and underexplored at the level of “extremely noisy conditions,” rather than just mild label noise. The paper does a good job motivating why this matters for reliability and safety."}, "weaknesses": {"value": "### Major Concerns\n\n#### 1. Conceptual clarity / internal consistency\nThe core story of the paper is: (i) noisy conditions \\(\\tilde y\\) entangle clusters, (ii) we “repair” them by learning pseudo conditions \\(\\hat y\\), (iii) we further stabilize training using RDC. But the paper never really gives a coherent probabilistic view of what \\(\\hat y\\) is supposed to represent.\n\n- This is just classic self-training / bootstrapping on noisy labels with EMA. There is no guarantee provided about to where the \\(\\hat y\\) converges rather than to whichever early bias the model latches onto. \n\n- The authors appeal to “memorization effect” and “early stopping” but give no principled stopping rule, no theoretical identifiability, and no robustness analysis under heavy class imbalance or systematic (non-symmetric) corruption. This is hand-wavy.\n\n- Later, \\(\\hat y\\) becomes part of an SDE and is diffused in reverse time (Sec. 3.1.2). But now \\(\\hat y_t\\) is treated almost like a continuous signal you can inject noise into, including for discrete labels. The paper never reconciles these two roles: is \\(\\hat y\\) a discrete class label, a continuous embedding, or a generic latent code? The text casually mixes these cases, e.g. in label-conditioning vs. visuomotor conditioning, and the math assumes a continuous vector with gradients \\(\\nabla_{\\hat y} \\log p_t(\\hat y)\\). This looks mathematically incompatible with the categorical-label case that motivates most of the “extremely noisy label” narrative.\n\n- The RDC SDE in Eq. (8) is introduced with forward / reverse SDEs copied from diffusion literature, but the derivation is not convincing. The paper defines boundary conditions \\( \\hat y_0 \\sim \\mathcal{N}(\\mu,\\sigma) \\), \\( \\hat y_T = \\hat y \\), then writes down dynamics that allegedly realize a “reverse-time diffusion condition.” However:\n  - There is no demonstration that these dynamics actually produce a tractable marginal \\(p_t(\\hat y)\\) consistent with those boundary conditions.\n  - There is no training algorithm that simulates these SDEs in practice in a numerically well-defined way beyond saying “we estimate \\(\\hat y_\\phi\\) using numerical methods.” This is extremely vague.\n\nIn short: the paper sells RDC as a principled diffusion-in-condition-space, but the derivation looks more like informal noise injection / augmentation of the conditioning vector. The gap between the math and the actual implementation is huge and currently not bridged.\n\n#### 2. Method description is incomplete / borderline non-reproducible\nSeveral critical training details are missing or contradictory:\n\n- **How exactly is \\(\\hat y\\) updated?**  \n  The algorithmic description for pseudo condition learning (Eq. (6)–(7), Algorithm 1) is ambiguous:\n  - Eq. (6) optimizes \\(\\| \\hat y_\\phi - \\tilde y \\|^2\\). But if \\(\\tilde y\\) is extremely noisy, regressing toward it just propagates noise. Why should this denoise anything, instead of *fitting the noise faster*? The only answer given is “memorization effect” / “temporal ensembling” / “early stopping,” but the paper does not specify (a) the EMA momentum \\(\\alpha\\), (b) when to stop, or (c) how sensitive results are to those choices.  \n  - Algorithm 1 line 7 says `yt ← (1−λ)yt + λ ŷϕ`. This quietly introduces a new \\(\\lambda\\) and mutates \\(y_t\\) in-place, but \\(\\lambda\\) is never defined, nor is it connected to \\(\\alpha\\) in Eq. (7). This raises reproducibility and even correctness concerns.\n\n- **When is the condition encoder trained and frozen?**  \n  For image-based conditions (visuomotor setting), the paper says: initialize \\(\\hat y\\) with encoder output \\(\\tilde y = e_\\gamma(\\text{image})\\); run early stopping to refine \\(\\hat y\\); later continue training the encoder to match \\(\\hat y\\) (Sec. 3.2). \n  This implies a bilevel schedule (first fix \\(e_\\gamma\\), tune \\(\\hat y\\); then fix \\(\\hat y\\), tune \\(e_\\gamma\\)). But:\n  - There is no precise schedule (epochs? steps? loss plateaus? validation metric?).\n  - There is no ablation isolating whether this two-phase procedure, *not* RDC, is what actually gives the reported visuomotor gains.\n\n- **Sampling / guidance**  \n  The method claims to “switch” classifier-free guidance from \\(\\tilde y\\) to \\(\\hat y\\) in Eq. (5). But at sampling time you don’t have ground-truth clean labels or clean observations — you either have the noisy condition \\(\\tilde y\\) (test-time corruption) or nothing. The paper doesn’t say how \\(\\hat y\\) is obtained at inference. Do we run the prediction head \\(q_\\phi\\) online to predict a denoised condition at test time? Do we rely on a refined encoder \\(e_\\gamma\\)? This is crucial for deployment, especially in the robotics/control setting, and it’s missing.\n\nOverall, too many essential knobs are “empirically determined,” “estimated numerically,” or “updated via early stopping,” without concrete, reproducible definitions. For ICLR-level work, that’s not acceptable.\n\n#### 3. Weak/unclear baselines and metrics\nThe empirical claims are not convincingly supported.\n\n- **Label-noise baselines.**  \n  The paper mostly compares against EDM (Karras et al., 2022) and TDSM (Na et al., 2024). But robustness to label noise has an extensive literature: MentorNet, Co-teaching, DivideMix, early-learning regularization, transition-matrix estimation, etc. Many of those works explicitly address extreme label noise and could be adapted to conditional generative models or to the conditional encoder. The paper cites some of them in Related Work but does not actually implement competitive versions (e.g. using DivideMix-style clean/noisy split on the condition head, or robust loss on the condition head rather than plain \\(\\ell_2\\)). So “SOTA” is overstated.\n\n- **Metric choice for controllability.**  \n  In Figure 1(b), controllability is measured as top-1 accuracy of a pretrained CIFAR-10 classifier on generated samples.   \n  This is fragile: if the classifier itself struggles under heavy corruption or distribution shift, the “controllability” score will be noisy. No calibration is provided. Also, top-1 accuracy on generated samples says nothing about sample diversity or mode-collapse. You *could* cheat controllability by collapsing to a single prototypical “dog” image per class. The paper does include FID/IS/Density/Coverage in Table 1, but does not analyze mode collapse explicitly in the high-noise regime (60–80%), which is exactly where they claim superiority.\n\n- **CIFAR-100 @ 60–80% noise.**  \n  The paper shows very large claimed gains when noise is extremely high and TDSM “collapses,” and then takes that as evidence of novelty. But TDSM is originally designed for label noise via transition matrices and might simply be mis-implemented for 100-way classification under 80% corruption, which is an extremely adversarial setting. There is no sanity check like: what is the oracle upper bound if you just train on clean labels for a small clean subset? What if you partially relabel with a small trusted clean set? Without that, “SOTA” here mostly means “our baseline impl of TDSM crashes so we win.”\n\n- **Visuomotor / robotics experiments.**  \n  The robotics evaluation is (i) one environment (Push-T), (ii) one type of corruption (camera distortion with fixed probability), and (iii) one metric (IoU/TAC).\n  This is extremely narrow. There’s no evaluation of closed-loop robustness under *unseen* distortions, lighting changes, occlusions, or partial sensor dropout — which is exactly the kind of real-world brittleness the introduction uses to motivate safety (“autonomous driving,” “surgery,” etc.). The leap from “slightly distorted tabletop pushing in simulation” to “hazardous failures in autonomous driving and surgery” is not justified.\n\nIn short: the experiments are tailored to showcase the authors’ method, but they do not seriously test robustness, and they omit strong alternative baselines.\n\n#### 4. Mathematical rigor of RDC\nRDC is pitched as a key novelty, but right now it reads like ad hoc noise augmentation with diffusion-flavored notation:\n\n- Eq. (8) writes forward and reverse SDEs for \\(\\hat y\\), but there is no derivation that these correspond to an ELBO-style bound, or that optimizing Eq. (10) is consistent with score matching in \\(\\hat y\\)-space. The connection to Kingma & Gao (2023) is waved at but not actually developed.\n\n- Eq. (9) defines \\(\\hat y_\\phi\\) as an integral of the learned score function over \\(t\\). But then the paper immediately says “we directly optimize \\(\\|\\hat y_\\phi - \\tilde y\\|^2\\)” instead of training the score network in \\(\\hat y\\)-space in a principled way. This looks self-contradictory: either RDC gives you a principled score-matching view, or you’re just using it as data augmentation for a regression head.\n\n- The ablation in Table 3 is used to argue RDC “fixes” the degradation caused by naïve pseudo conditions. But that table is only on CIFAR-10 40% noise, and it is extremely underspecified: hyperparameters, stopping rules, and sampling details are not given. So it’s impossible to tell whether RDC itself is doing anything fundamental, or whether the improvement is due to other training heuristics that were added alongside it (e.g., different EMA schedule or guidance scaling).\n\nGiven how much of the claimed novelty rests on RDC, this level of vagueness is a serious issue."}, "questions": {"value": "Do we really need the REVERSE-TIME DIFFUSION CONDITION? is that possible to define a manual schedule to anneal the noise level of the \\hat y. I think here the author lacks enough discussion about the intuition/motivation of the introducing of such a techinique."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "uwaHCN69VZ", "forum": "fdp7klHmnn", "replyto": "fdp7klHmnn", "signatures": ["ICLR.cc/2026/Conference/Submission2525/Reviewer_oTa3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2525/Reviewer_oTa3"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2525/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761835000553, "cdate": 1761835000553, "tmdate": 1762916267569, "mdate": 1762916267569, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a training framework for conditional diffusion models designed to handle highly noisy conditioning inputs. The method combines two key components: Pseudo Condition and Reverse-time Diffusion Condition. The Pseudo Condition is produced by a lightweight prediction head that processes the UNet encoder’s output, serving as a surrogate for the clean condition and mitigating the impact of noise in the original input. Meanwhile, the Reverse-time Diffusion Condition employs a reverse SDE to generate a denoised estimate of the input condition. By integrating PC and RDC, the proposed approach effectively approximates clean conditioning signals, leading to improved performance across tasks such as label-conditioned image generation and image-conditioned visuomotor policy learning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper is clearly written and well-structured, making it easy to follow. The overall presentation is coherent, and Algorithm 1 effectively clarifies the proposed method. Most of the experiments generally support the authors’ claims, with the 2D toy experiments providing particularly intuitive and convincing evidence."}, "weaknesses": {"value": "The main concern with this paper lies in the experimental design and the limited exploration of key design choices.\n\nIn the image-conditioned visuomotor policy generation experiments, the “noisy” images are generated using only two specific distortion types. While these distortions can be regarded as forms of noise, they do not capture more general or practically relevant noise sources—such as typical camera noise or Gaussian noise. Incorporating experiments with these more realistic noise types would strengthen the method’s robustness and practical deployability in real-world scenarios.\n\nMoreover, the experiments are confined to the UNet architecture, leaving the generalization of the proposed approach to other diffusion model backbones—particularly Transformer-based architectures—unclear. The experiments in Section 4.2 are also limited to class-label–conditioned image generation with demonstrations. Extending the evaluation to other conditioning modalities, such as line sketches (as referenced in [1]), would further demonstrate the versatility of the proposed method.\n\n[1] Zhang, L., Rao, A., & Agrawala, M. (2023). Adding conditional control to text-to-image diffusion models. In Proceedings of the IEEE/CVF international conference on computer vision (pp. 3836-3847).\n\nMinor:\n\nThe caption of Table 2 does not appear to correspond correctly to the content of the table."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4XYS7AM9Lw", "forum": "fdp7klHmnn", "replyto": "fdp7klHmnn", "signatures": ["ICLR.cc/2026/Conference/Submission2525/Reviewer_pT6p"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2525/Reviewer_pT6p"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2525/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761987190034, "cdate": 1761987190034, "tmdate": 1762916266798, "mdate": 1762916266798, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a robust learning framework that helps conditional diffusion models train more effectively and efficiently under extremely noisy conditions. Building upon the theory of the *memorization effect* [1], the paper introduces *pseudo-conditions*, which gradually replace the original noisy conditions with clean conditions generated by the model itself through a *temporal ensembling* module. It further proposes *Reverse-time Diffusion Conditioning (RDC)*, which applies a reverse-time diffusion process to the pseudo-conditions as a form of conditional augmentation, enhancing the memorization effect and stabilizing training. Extensive experiments on CIFAR-10/100 and Push-T datasets demonstrate that the proposed method outperforms existing baselines (e.g., TDSM) under high noise levels.\n\n[1] S. Liu, et al. Early-learning regularization prevents memorization of noisy labels. NeurIPS 2020"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "-  The paper introduces a novel robust learning approach that optimizes the conditions during training, treating noisy conditions as denoising targets for data augmentation. The method achieves significant performance gains, especially in faster convergence, showing clear benefits during the early stages of training.\n-  The proposed method is lightweight and easy to integrate into existing diffusion models, making it valuable for training on large-scale, low-quality datasets.\n-  The paper is well-structured, with clear organization, well-designed experiments, and detailed implementation information."}, "weaknesses": {"value": "*   The frequent use of early stopping reduces the generalizability of the approach, suggesting that the theoretical foundation is still incomplete. The authors are encouraged to analyze the causes of overfitting and provide theoretical explanations and improvement strategies.\n*   The comparison baselines are relatively limited; including more baselines would make the results more convincing.\n*   The theoretical support for RDC is insufficient. Although the ablation study shows that RDC is critical to performance, further theoretical analysis and more detailed ablations are needed to clarify its contribution."}, "questions": {"value": "- Can this method be extended to high-dimensional conditions, such as high-resolution images? In such cases, is it easy to recover pseudo-conditions from the diffusion model?\n- Could you provide more textual description of Figure 2 to help readers better understand the connection between the data and your argument? Is the mention of \"Figure 2(b)\" in line 229 of the text a typo?\n- Could you add a textual description of temporal ensembling? Although it originates from [1], as one of the new modules in the paper, and considering its early introduction, a brief explanation of its principles would help readers with limited background better understand your work and intentions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "M0Cw5LZNwX", "forum": "fdp7klHmnn", "replyto": "fdp7klHmnn", "signatures": ["ICLR.cc/2026/Conference/Submission2525/Reviewer_hdc3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2525/Reviewer_hdc3"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2525/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990172705, "cdate": 1761990172705, "tmdate": 1762916266383, "mdate": 1762916266383, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}