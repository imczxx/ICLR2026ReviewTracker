{"id": "3ZhFjE6yp1", "number": 17488, "cdate": 1758276618936, "mdate": 1759897172083, "content": {"title": "Cold Start in the Dark: Efficient and Practical Model Extraction of GNNs", "abstract": "The deployment of Graph Neural Networks (GNNs) on MLaaS platforms makes them vulnerable to Model Extraction Attacks (MEAs), where an adversary queries a proprietary model's API to reconstruct a high-fidelity surrogate. However, the practicality of current methods is limited by unrealistic assumptions, such as access to detailed soft-label probabilities, large initial seed datasets, or permissive query budgets. To address this gap, this work introduces MIME, a framework designed for the more stringent and realistic \"Cold Start in the Dark'' problem, where an adversary operates with no initial labels and only hard-label feedback under a tight budget. MIME resolves the critical cold start challenge using unsupervised pre-training to establish a strong structural baseline from the topology alone. This bootstraps a query-efficient active learning loop that strategically balances node uncertainty and diversity, ensuring robustness through adaptive graph regularization. Extensive experiments show that MIME achieves strong performance on both model accuracy and fidelity. The findings demonstrate a practical and stealthy attack vector, exposing a concrete security risk to production GNNs by succeeding under realistic adversarial constraints.", "tldr": "We introduce MIME, an attack that efficiently extracts GNN models under realistic, low-information \"cold start\" conditions by using unsupervised learning to bootstrap a query-efficient active learning strategy.", "keywords": ["Model Extraction", "Graph Neural Networks", "Active Learning", "Self-Supervised Learning", "Black-Box Attacks"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a461ed0d42a6c8abde4c8e897d6b68ac881d26d3.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This manuscript introduces a practical framework MIME for conducting MEAs on GNNs deployed through MLaaS platforms. MIME targets the “Cold Start in the Dark” scenario, where an adversary has no initial labeled data and receives only hard-label feedback under a limited query budget. The framework employs unsupervised pre-training to derive structural representations from graph topology, establishing a foundation for an efficient active learning process that strategically balances node uncertainty and diversity. To enhance stability, MIME incorporates adaptive graph regularization, ensuring robust surrogate model reconstruction. Experimental results show that MIME achieves high accuracy and fidelity with strong query efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The manuscript introduces the *“Cold Start in the Dark”* setting, a realistic and stringent scenario of GNN model extraction in which the adversary lacks labeled data, receives only hard-label feedback, and operates under a tight query budget. This establishes a significant conceptual contribution and provides a benchmark for evaluating practical model extraction attacks.\n- The proposed MIME framework integrates unsupervised pre-training, sequential uncertainty–diversity filtering, adaptive Laplacian regularization, and self-training into a unified pipeline. Each component is carefully designed to address a specific challenge: initialization, efficient querying, stability, and post-budget refinement. The overall methodology is coherent, systematic, and technically sound.\n- Extensive experiments are conducted on five benchmark datasets, including Coauthor-CS, Coauthor-Physics, Amazon-Computer, Amazon-Photo, and Cora-Full. MIME is compared against representative baselines such as Random, AGE, CEGA, and Realistic Attack. The results consistently demonstrate MIME’s superior performance in both accuracy and fidelity, especially under strict query budgets, indicating strong query efficiency and robustness."}, "weaknesses": {"value": "- The proposed MIME framework primarily combines existing techniques such as unsupervised pre-training, uncertainty-based sampling, and graph regularization without introducing a fundamentally new algorithmic idea or theoretical contribution. The innovation is largely incremental and integrative rather than original.\n- Although MIME successfully illustrates a realistic and effective attack, the paper provides limited discussion on potential defense strategies or detection mechanisms. Expanding this aspect would help bridge the findings with practical mitigation approaches.\n- All experiments are performed in transductive node classification settings. The work does not empirically investigate inductive, dynamic, or heterogeneous graph scenarios, which limits the generalizability of the proposed framework.\n- The methodology section is mathematically detailed, which strengthens rigor but may reduce accessibility for readers unfamiliar with graph-based active learning or extraction attacks. A clearer illustration of the query selection process and algorithmic intuition could improve clarity.\n- The study focuses on empirical validation without providing formal theoretical analysis, such as convergence guarantees or robustness bounds. Incorporating such analysis would enhance the academic depth and rigor of the contribution."}, "questions": {"value": "Please refer to the ```weaknesses``` section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "S9K30jytYr", "forum": "3ZhFjE6yp1", "replyto": "3ZhFjE6yp1", "signatures": ["ICLR.cc/2026/Conference/Submission17488/Reviewer_sy2a"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17488/Reviewer_sy2a"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17488/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761641394680, "cdate": 1761641394680, "tmdate": 1762927368714, "mdate": 1762927368714, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a more realistic GNN attack scenario, termed “COLD START IN THE DARK.” Building on this, it introduces MIME, a three-phase method: DGI for cold start, multi-round active-learning loops to select the most valuable nodes, and final fine-tuning to obtain the leaked model. The motivation is strong and the pipeline is clearly presented; however, the method has many components and the justification is unconvincing. The experimental evaluation is also incomplete."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper introduces a more realistic attack setting for GNNs and proposes a powerful method, MIME, to address it. The writing is clear."}, "weaknesses": {"value": "Major:\n\n* The paper presents many methodological details in the main text (which is good) but gives little explanation of *why* these design choices were made. There are no theoretical guarantees, nor convincing intuitive justifications. For example, in Eqs. (4), (7), (10), and (12), each quantity is defined as a weighted combination of two components, yet it is unclear why each component is necessary and what role it plays.\n\n* The experimental section is weak:\n\n  * The method introduces many hyperparameters (up to 16 per Tables 3 and 4), yet the experiments use only five similar datasets. Based on prior experience, these five datasets are highly homophilous and simple GCNs already perform well. This raises overfitting concerns. It is unknown whether the chosen hyperparameters would hold on more diverse datasets.\n\n  * I agree a method need not always be SOTA. However, in Table 1 on AmzP and AmcC at low attack budgets, the method underperforms Random and REALISTIC by more than 10%. Please provide a reasonable explanation. This also appears inconsistent with the claim of “Impressive Efficiency at Low Budgets” and the emphasized cold-start advantage.\n\n  * Experiments were run with a single fixed random seed, which makes the reported means and standard deviations statistically meaningless.\n\n  * The time complexity seems high. The pipeline has three phases, and Phase 2 includes many GNN training runs. Please compare wall-clock cost with baselines, and discuss whether this cost is acceptable for larger datasets.\n\n* I suggest a brief discussion on how existing defenses could be strengthened to resist MIME. This would improve completeness.\n\nMinor:\n\n* “Proposition 1” scarcely qualifies as a proposition; it is at best a remark.\n* Line 191: “Eq” and “equation” are redundant."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SZPV8Jobw1", "forum": "3ZhFjE6yp1", "replyto": "3ZhFjE6yp1", "signatures": ["ICLR.cc/2026/Conference/Submission17488/Reviewer_qjVj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17488/Reviewer_qjVj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17488/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761663736892, "cdate": 1761663736892, "tmdate": 1762927368329, "mdate": 1762927368329, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work investigates the subject of Model Extraction attacks, which consists of stealing a proprietary model by leveraging only query access, and specifically they focus on the field of Graph Neural Networks (GNNs). The authors propose MIME, which is a framework designed for realistic setting for this specific context of attacks. The proposed framework is based on the adversary operating without any initial labels and only hard-label feedbacks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The general problem that is considered is very interesting. Additionally the proposed setting, without labeled data and only hard-label feedback seems to be more realistic in my opinion. \n- The overall mathematical definition is clear and valuable to better understand the direction.\n- The solution involving unsupervised pre-training (using the Infomax) and active learning is innovative and interesting. \n- The experimental setting showcase the worth of the method. Specifically I liked the ablation studies provided in Table 2 and Table 6 - showcasing the importance of each component within the proposed method."}, "weaknesses": {"value": "I believe that the paper proposes some good elements enhancing the realistic aspect of GNN extraction attacks by introducing constrained and practical setting. Nonetheless, a number of elements are still lacking in the manuscript, and I summarize these elements within the following points:\n- The proposed bi-level optimization problem is clearly interesting, nonetheless, after Proposition 1, I was expecting some theoretical elements or guarantees to better motivate the usage of the proposed MIME.\n- A number of baselines are missing, for instance specific attacks for graph-data [1] or general adaptation of the general black-box methods such as Knockoff Nets. \n- The manuscript seems to be lacking a discussion of the complexity of the overall method, and specifically compared to other baselines. \n    - This is also related to some missing larger dataset evaluation such as the OGB family. \n- I couldn’t find specific details on the considered baselines and if they are actually using hard-label or no-seed constraints as the proposed method. \n\n\n—\n\n[1] Unveiling the Secrets without Data: Can Graph Neural Networks Be Exploited through Data-Free Model Extraction Attacks? - USENIX 2024.\n\n[2] Knockoff Nets: Stealing Functionality of Black-Box Models. - CVPR 2019."}, "questions": {"value": "- Would it be possible to extend the study to larger graphs such as OGB-Arxiv? \n- This previous question is also related to the question of the complexity of the method. While you have provided some elements in Figure 3 regarding the “computational savings” of each component, a systematic and complete time or complexity analysis is missing. \n- Could you provide additional details regarding the considered setting for the other baselines? And specifically addressing the question of comparison fairness in this case. \n- In the conclusion, the authors claim: “This finding proves that defenses must evolve beyond simple query monitoring.” - And from the experimental setting, I couldn’t find any comparison to any defense method and therefore wondering where does this statement come from? and can you then experimentally back it up?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "WWnqBopfzq", "forum": "3ZhFjE6yp1", "replyto": "3ZhFjE6yp1", "signatures": ["ICLR.cc/2026/Conference/Submission17488/Reviewer_bTmV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17488/Reviewer_bTmV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17488/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923462887, "cdate": 1761923462887, "tmdate": 1762927367864, "mdate": 1762927367864, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes MIME (Minimal Information Model Extraction), a framework for extracting GNN models under realistic constraints: no initial labels, hard-label feedback only, tight query budgets, and limited data access. MIME uses unsupervised pre-training (DGI) for cold start initialization, followed by an active learning loop with uncertainty-diversity filtering, and finishes with self-training."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Well-motivated problem formulation.\n2. Empirical results show the effectiveness of the attack.\n3. Overall, the paper is well-written."}, "weaknesses": {"value": "1. Transductive setting limits applicability.\n2. Formal analysis of convergence guarantees is missing.\n3. Limited GNN architectural diversity.\n4. Limited dataset evaluation."}, "questions": {"value": "1. How will this attack work for inductive settings?\n2. How do you ensure fair comparison with the other baselines?\n3. How effective is this attack when the surrogate and the victim models are different?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "G4oJ6hzBy5", "forum": "3ZhFjE6yp1", "replyto": "3ZhFjE6yp1", "signatures": ["ICLR.cc/2026/Conference/Submission17488/Reviewer_Lje6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17488/Reviewer_Lje6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17488/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982044333, "cdate": 1761982044333, "tmdate": 1762927367494, "mdate": 1762927367494, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}