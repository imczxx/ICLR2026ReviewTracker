{"id": "QVzb9c3VCy", "number": 7254, "cdate": 1758013247187, "mdate": 1759897863558, "content": {"title": "Enhancing Object Discovery for Unsupervised Instance Segmentation and Object Detection", "abstract": "We propose Cut-Once-and-LEaRn (COLER), a simple approach for unsupervised instance segmentation and object detection. COLER first uses our developed CutOnce to generate coarse pseudo labels, then enables the detector to learn\nfrom these masks. CutOnce applies Normalized Cut only\nonce and does not rely on any clustering methods, but it\ncan generate multiple object masks in an image. We have\ndesigned several novel yet simple modules that not only allow CutOnce to fully leverage the object discovery capabilities of self-supervised models, but also free it from reliance\non mask post-processing. During training, COLER achieves\nstrong performance without requiring specially designed loss\nfunctions for pseudo labels, and its performance is further improved through self-training. COLER is a zero-shot unsupervised model that outperforms previous state-of-the-art methods on multiple benchmarks. We believe our method can help\nadvance the field of unsupervised object localization.", "tldr": "We propose a novel and simple method to enhance object discovery in self-supervised models, enabling efficient multi-instance segmentation from a single image.", "keywords": ["unsupervised learning", "object discovery", "pseudo labeling", "zero-shot learning", "normalized cut"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3e65cde8fe847acf037caa53ec2a04fd69b28a37.pdf", "supplementary_material": "/attachment/dc474b6af5dff0193d88e0507aa1667fccd89bdd.zip"}, "replies": [{"content": {"summary": {"value": "Building on existing methods (as the authors themselves note) this paper presents a method for unsupervised object discovery. The method is based on normalized cuts of the graph Laplacian calculated using pre-trained image features (DINO, in this case). The main contributions of the proposed method is a boundary enhancing procedure based on the difference the second eigevector and a boundary vector obtained by calculating the distance between each feature and its neighbours. In practice this is a form of contrast enhancement (typical in image processing). The resulting boundary enhanced map provides cleaner and more detailed segments. Two other post-processing steps are proposed (rank based filtering which gets rids of noisy areas and self-training). Some variatns of the model use a CRF to further refine results. The main advantgage of the method is that it produces several object proposal while still needing to perform the Ncut once.\nThe mehod is evaluated on several image segmentation datasets and is shown to improve results."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper proposes some nice engineering solutions to problems faced by segmentation methods. Results are mildly better than proposed baselines and the method seems to be cheaper to run (as discussed in the paper).\nThe experiments are extensive enough with some ablation studies and a nice limitations section."}, "weaknesses": {"value": "My main concern regarding this paper is its significance. Now, I am not an expert in the field, but to me this seems like a series of ad-hoc improvements to existing methods. I don't claim this is not important, or that the results are invalid - but I do feel that as a scientific paper I would expect to learn something new when reading. I do not feel that this paper, beyond the obvious technical contributions, have taught me anything.\n\nFurthermore, even taking into account the scope of the paper I feel the experimental results, while fine, are underwhelming and improvements are minimal. \n\nI am also wondering why the second round of self-training hurts performance on almost all benchmarks? can the authors elaborate?\n\nOne last remark - while the presentation of the paper is fine and it is readable, I found the use of SSM as abbreviation for a \"self supervised model\" extremely confusing (as SSM usually refers to state-space models)."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SrHWBfNcO1", "forum": "QVzb9c3VCy", "replyto": "QVzb9c3VCy", "signatures": ["ICLR.cc/2026/Conference/Submission7254/Reviewer_HFo2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7254/Reviewer_HFo2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761324413353, "cdate": 1761324413353, "tmdate": 1762919388429, "mdate": 1762919388429, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the unsupervised instance segmentation task. \nIt first proposes the CutOnce module to generate pseudo labels. More specifically, CutOnce first performs N-Cut on pretrained self-supervised features, followed by boundary augmentation and ranking. \nThen, the COLER module uses pseudo-labels generated from CutOnce to train the object detector."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The presentation of this paper is clear. \nWriting logic is easy to follow, and illustrations are helpful for understanding."}, "weaknesses": {"value": "1. The proposed method cannot fundamentally solve the issues mentioned in the paper (i.e. more accurate multi-object segmentation): \n- As long as pseudo-labels are directly generated by N-Cut self-supervised features and the SSL features do not reveal real objectness, heuristic tricks like boundary processing, connected-component analysis can only receive incremental improvement, but not fundamentally solve the problem.\n\n2. The designs of some modules are not well justified:\n- First 2 modules in CutOnce are designed for \"enhancing the distinction between foreground and background\" as claimed in line 183.\n- If the design only serves for foreground-background contrast, it is not enough for the goal to \"enable NCut algorithm to discover multiple objects rather than focusing on a single one\" as mentioned in line 179.\n\n3. The contribution of this paper to the relevant field is minor:\n- It follows the practice of CutLER and CuVELR, only introducing some tricks for processing self-supervised features.\n- Compared with baselines, the performance gain is marginal.\n\n4. Some important related works are not discussed and compared:\n- unMORE: Unsupervised Multi-Object Segmentation via Center-Boundary Reasoning (icml25)\n\n5. Some experiment settings are problematic:\n- Pretraining datasets are not consistent for different methods (some on IN train, others on IN val).\n- CuVLER are not given self-training.\n- AR metrics are not calculated from the final detection evaluation."}, "questions": {"value": "1. Fundamentally, why is Boundary Augmentation helpful for multi-object segmentation? \n- Why \"the saliency of more objects is enhanced\"? From equation (5), what you are doing is more like an averaging operation within the neighborhood. For the visualization in Figure 1, can you normalize the heatmap before and after the boundary augmentation to facilitate a more direct comparison?\n- Will it give a similar effect as the proposed module if one simply applies mask erosion onto the original binary mask in order to make  \"Nearby objects are less likely to be considered as a single entity\"?\n\n2. Does the \"boundary\" mentioned in the Boundary Augmentation module refer to the boundary of objects? Or just the boundary of the foreground? If two objects are tightly adjacent to each other (i.e., there are no background pixels between them), can they be segmented into two?\n\n3. For \"Ranking-Based Instance Filter\", why use feature sum as the sorting criterion? What does the feature sum value represent?\n\n4. In Table 3, why are CuVLER and COLER pretrained on the ImageNet validation set instead of the training set? It is important to align all settings to make the experimental results comparable. \n\n5. In Table 3, why not provide CuVLER with self-training while all other methods are doing so? In addition, the original CuVLER paper also uses self-training and yields better AP50 (23.5) than you provide in Table 3 (23.0).\n\n6. Table 3 should also include AR. \n\n7. It is claimed that COLER may detect instances that are not annotated in Ground Truth, consider evaluating on COCO* mentioned in unMORE (https://arxiv.org/abs/2506.01778).\n\n8. Given that pseudo-labels generated from CutOnce are obviously worse than VoteCut as suggested in Table 2, why do detectors trained on CutOnce yield better performance than those trained on VoteCut as suggested in Table 3?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "3a3hkh0z92", "forum": "QVzb9c3VCy", "replyto": "QVzb9c3VCy", "signatures": ["ICLR.cc/2026/Conference/Submission7254/Reviewer_okBi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7254/Reviewer_okBi"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761572914561, "cdate": 1761572914561, "tmdate": 1762919388027, "mdate": 1762919388027, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes COLER (Cut-Once-and-LEaRn) for unsupervised, zero-shot instance segmentation and object detection. The pipeline has two stages: 1. CutOnce (train-free pseudo-mask generator). It applies Normalized Cut (NCut) only once on DINO-ViT features, then adds three simple modules to (a) adapt similarity with density-tuned temperature (b) sharpen and separate instances via a boundary-augmentation transform on the NCut eigenvector, and (c) select foreground components using a ranked connected-component filter. Unlike TokenCut/MaskCut/VoteCut families that use recursive cuts or clustering, CutOnce claims multi-instance discovery from a single NCut pass. 2. LEaRn (detector training): it trains a class-agnostic Cascade Mask R-CNN solely on CutOnce masks and improves quality via one self-training round, deliberately avoiding bespoke pseudo-label losses."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The method is technically sound and implementation-oriented: the density-tuned similarity (adaptive temperature), boundary-augmented eigenvector, and rank-based component selection are specified mathematically and ablated individually and cumulatively.\n\n- The pipeline figure and intermediate visualizations (raw/“boundary”/difference eigenvectors, component maps) explain why single-pass NCut can still separate multiple instances. And, the writing is direct; notation for the three modules is compact and consistent.\n\n- Single-pass NCut → multi-instance with three lightweight modules is a clear conceptual departure from recursive partition (MaskCut/CutLER) and clustering/voting (VoteCut/CuVLER). The design removes the need to guess cluster counts and avoids recursive error accumulation.\n\n- Comparisons are made to strong open baselines: CutLER (MaskCut+detector+self-train) and CuVLER (VoteCut+detector+soft loss), showing COLER is competitive while being simpler and faster at the pseudo-mask stage."}, "weaknesses": {"value": "- The three modules—adaptive temperature on cosine affinities, boundary emphasizing via neighborhood differencing, and rank filtering—are spectral pre/post-processing heuristics layered on a classical NCut pipeline (no new learning principle or theory). In contrast, DiffCut offers a more substantive change of backbone (diffusion UNet features) *and* a recursive NCut with granularity control; DiffNCut explores differentiability for end-to-end learning. The paper’s “SOTA” claim should be carefully bounded by setting/task\n\n- Even with boundary augmentation, one eigenvector is a coarse partition; multi-object scenes with strong co-occurrence/overlap can remain merged. This is exactly what recursive strategies (MaskCut/CutLER; DiffCut) were built to address. The paper acknowledges multi-object limits; quantitative stress-tests on dense scenes (LVIS/Objects365) against recursive/voting approaches would sharpen the picture.\n\n- The paper compares with CutLER/CuVLER, but omits direct head-to-head on DiffCut under an instance-level protocol (even a proxy comparison would help). Also, some CuVLER strengths (multi-SSL diversity, mask scoring) are not ablated against COLER’s single-backbone design.\n\n- There is an appealing spectral intuition, but no theoretical insight into why the boundary augmentation (subtract neighborhood mean absolute difference) and density temperature scaling improve the eigenvector’s separability or component stability."}, "questions": {"value": "- Why one eigenvector? Provide analysis on when the second smallest eigenvector is sufficient for multi-instance separation. An experiment using multi-eigenvector embeddings (top-k eigvecs with mean-shift or connected components) as a control could clarify the tradeoff versus your boundary augmentation. \n\n- How about high-res inputs? Could you please show scaling experiments (e.g., 640², 1024²)? Does single-pass NCut remain stable and fast?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ysTUbIExxN", "forum": "QVzb9c3VCy", "replyto": "QVzb9c3VCy", "signatures": ["ICLR.cc/2026/Conference/Submission7254/Reviewer_efiD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7254/Reviewer_efiD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761841236341, "cdate": 1761841236341, "tmdate": 1762919387298, "mdate": 1762919387298, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on unsupervised instance segmentation and object detection. The authors introduce a pipeline that first generates pseudo labels using a self-supervised model, which are then used to train a standard detector. They propose several novel techniques during the pseudo label generation phase to ensure higher quality, validating the pipeline's strong performance across various datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The presentation is clear and logical, effectively demonstrating the overall pipeline design with well-structured experiments. \n\n2. The experimental results demonstrate strong performance, achieving favorable metrics when compared directly against the established baseline methods, suggesting the efficacy and competitive advantage of the proposed approach."}, "weaknesses": {"value": "1. The overall pipeline lacks significant novelty, bearing a strong resemblance to existing unsupervised methods. Although the authors introduce several techniques to enhance pseudo label quality, the specific mechanisms—such as the methods used to refine the pseudo segmentation map and the filtering strategies—do not demonstrate a substantial departure from classical computer vision approaches.\n\n2. The performance improvements achieved by the proposed method are marginal when compared to the existing state-of-the-art or baselines.\n\n3. As the authors suggest, the method appears to heavily rely on the underlying self-supervised model. The reported gains achieved by simply switching or upgrading the self-supervised model are notably larger than the improvements resulting from the carefully designed pseudo-label strategies."}, "questions": {"value": "See **Weakness**."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "N42YtxWisC", "forum": "QVzb9c3VCy", "replyto": "QVzb9c3VCy", "signatures": ["ICLR.cc/2026/Conference/Submission7254/Reviewer_dVFE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7254/Reviewer_dVFE"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989334815, "cdate": 1761989334815, "tmdate": 1762919386853, "mdate": 1762919386853, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}