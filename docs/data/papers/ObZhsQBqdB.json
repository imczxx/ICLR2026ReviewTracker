{"id": "ObZhsQBqdB", "number": 5052, "cdate": 1757839350412, "mdate": 1759897997801, "content": {"title": "MaskOpt: A Large-Scale Mask Optimization Dataset to Advance AI in Integrated Circuit Manufacturing", "abstract": "As integrated circuit (IC) dimensions shrink below the lithographic wavelength, optical lithography faces growing challenges from diffraction and process variability. Model-based optical proximity correction (OPC) and inverse lithography technique (ILT) remain indispensable but computationally expensive, requiring repeated simulations that limit scalability. Although deep learning has been applied to mask optimization, existing datasets often rely on synthetic layouts, disregard standard-cell hierarchy, and neglect the surrounding contexts around the mask optimization targets, thereby constraining their applicability to practical mask optimization. To advance deep learning for cell- and context-aware mask optimization, we present MaskOpt, a large-scale benchmark dataset constructed from real IC designs at the 45$\\mathrm{nm}$ node. MaskOpt includes 104,714 metal-layer tiles and 121,952 via-layer tiles. Each tile is clipped at a standard-cell placement to preserve cell information, exploiting repeated logic gate occurrences. Different context window sizes are supported in MaskOpt to capture the influence of neighboring shapes from optical proximity effects. We evaluate state-of-the-art deep learning models for IC mask optimization to build up benchmarks, and the evaluation results expose distinct trade-offs across baseline models. Further context size analysis and input ablation studies confirm the importance of both surrounding geometries and cell-aware inputs in achieving accurate mask generation.", "tldr": "", "keywords": ["Mask Optimization", "Optical Lithography", "Integrated Circuits", "Deep Learning"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c329150ddf7baa415ced942130c80f1f0ac30c42.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents a benchmark dataset containing 104714 metal-layer tiles and 121952 via-layer tiles using five designs from the OenROAD flow for IC mask optimization. It focuses on generating the mask at a cell level and provides results on model-based OPC and ILT tasks to highlight the importance of cellaware and context-aware inputs."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear presentation. This paper clearly introduces the background of optical lithography and other concepts.\n2. The provided dataset contains much more data compared to the previous benchmark dataset. And it is closer to a real application without using synthetic tiles.\n3. This benchmark enables cell-based hierarchical OPC, which provides more information for mask optimization."}, "weaknesses": {"value": "1. This paper doesn’t clearly explain the advantages and weaknesses of modelbased OPC and ILT. Experimental results show some optimization preferences (e.g., methods belonging to model-based OPC tend to optimize the L2 metric, while methods from ILT show greater improvement in EPE), but these are not clearly explained.\n2. Fewer baseline methods are included for comparison. The experiment only adopts four baseline methods. For OPC mask prediction, Neural-ILT and CFNO are adaptable but not included for comparison.\n3. The mask ground truths are generated using OpenILT platform, and all baseline methods are trained to minimize the loss between model outputs and mask ground truths. The square L2 error between the printed wafer images using mask ground truths and the targeted layout image should be provided as an oracle result."}, "questions": {"value": "1. What are the differences in advantages and weaknesses between modelbased OPC and ILT methods?\n2. Can more methods be added to the experimental comparison and analyzed in more detail?\n3. Can the mask ground truths generated in this paper produce the closest result to the target layout images? Is minimizing the error with mask ground truths the optimal optimization objective?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "o35HlBgk0i", "forum": "ObZhsQBqdB", "replyto": "ObZhsQBqdB", "signatures": ["ICLR.cc/2026/Conference/Submission5052/Reviewer_wh2C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5052/Reviewer_wh2C"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5052/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761393536268, "cdate": 1761393536268, "tmdate": 1762917846634, "mdate": 1762917846634, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed a lithography benchmark targeting OPC and ILT (pixelated mask optimization). The overall contribution includes larger-scale real design synthesized under NanGATE45 PDK and standard cell-based clips. Its interesting to see efforts contribute to the AI for computational lithography. But I do have concerns about the practicality and impacts of such benchmark compared to prior works. Please see my detailed comments below."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "-Benchmarks include real chip designs synthesized on open source PDK. Especially, metal layers are more close to true design patterns compared to the previous LithoBench, where metal layer designs are mostly synthetic data. \n\n-Multiple ML solutions are evaluated on the newly introduced benchmark. \n\n-The amount of data is significantly larger than existing benchmarks, potentially benefits ML-based solutions."}, "weaknesses": {"value": "I do have several concerns and comments on the benchmark.\n1. Author mentioned the clipping is based on standard cells (plus different sizes of surrounding context), I don't know the motivation to do that: a. STC patterns are usually quite limited, for each technology node, there are typically larger hundreds or 1K STCs. based on this, I really doubt the diversity and coverage of the benchmark. b. If the clips are with lots of similar patterns with different surrounding contexts, this will only pose significantly challenge on ML training. c. The clip has 512x512 nm core region on 1024x1024 tile. However, as far as I know, there are many STCs in NanGate45 that have much larger size than 1024x1024. In this sense, the benchmark does not show advantage over LithoBench. \n\n2. Again for the tile size, its too small for practical usage. In industry practical, the tile size should be at least 8um X 8um or even larger. Models supporting such small clips are typically useless. Even for lithobench, the clip size is already 2umX 2um. \n\n3. In computationaly lithography or precisely ILT, ML methods/genAI methods only serve as add-on for traditional solver because one need to go through at least few iterations of numerical solver for refinement check. However, the experiments does not show any SOTA numerical ILT results like: MultiILT [Sun+, DAC'23], DiffOPC [Chen+, ICCAD24], CurvyILT [Yang+, ISPD'25]\n\n4. By looking at the benchmark details, for example in Fig. 6, some of the patterns are intentionally cut into clips, resulting in patterns cut into half, yielding even much smaller CD than the layer rules. Thus I would say some of the data points do not make any sense."}, "questions": {"value": "Please refer to the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "h6g81o57d7", "forum": "ObZhsQBqdB", "replyto": "ObZhsQBqdB", "signatures": ["ICLR.cc/2026/Conference/Submission5052/Reviewer_D1GT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5052/Reviewer_D1GT"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5052/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761620746115, "cdate": 1761620746115, "tmdate": 1762917845113, "mdate": 1762917845113, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces MaskOpt, a new dataset for learning-based mask optimization in optical lithography. \nThe dataset is built from “five real IC designs at the 45nm technology node,” and contains 104,714 metal-layer tiles and 121,952 via-layer tiles. For each tile, the authors provide (1) a clipped layout “core” region aligned with a standard-cell placement, (2) optional extended spatial context around that core (0–128 nm), (3) the associated standard-cell tag, and (4) ground-truth model-based OPC and ILT masks generated using OpenILT. The task is: given layout + context + cell tag, predict either the OPC-style or ILT-style corrected mask.\nThey benchmark several published deep-learning baselines (GAN-OPC, DAMO, Neural-ILT, CFNO) and evaluate them.\nThe main claims are: (1) MaskOpt is more realistic than prior datasets such as LithoBench because it preserves standard-cell hierarchy and surrounding context; (2) including standard-cell identity and local context improves mask prediction; and (3) different baseline models expose different trade-offs between fidelity and manufacturability."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The motivation is clear. Mask optimization is indeed a core bottleneck in modern lithography because it requires repeated forward lithography simulation and careful process-window optimization.\n\n2. The dataset is not just random image crops: tiles are explicitly aligned with standard-cell placements."}, "weaknesses": {"value": "1. The contribution is incremental and the novelty is overstated. The core claimed contribution is “a large-scale dataset for mask optimization that captures cell hierarchy and context.”\nBut LithoBench already provides >100k labeled via tiles plus tens of thousands of metal-layer tiles, including both target and optimized masks.\nRelative to that, MaskOpt differs mainly in (1) how the clips are cropped with different margins, (2) adding a per-sample \"cell tag\" channel\", which is more like a incremental variant of LithoBench rather than a new benchmark.\nBesides, all evaluation toolkits are provided by OpenILT and open-sourced model, which further limits the contribution.\n\n2. The benchmark evaluation methodology assumes mask quality is best assessed from a tile's core region after simulating a larger window with an added margin. \nThis standard trick minimizes boundary artifacts in the core. The paper claims larger margins inherently improve fidelity by providing more context. \nHowever, this is misleading and cannot actually scale to production, as the usable margin is physically limited in manufacturing, and the \"center-is-better\" bias does not scale to larger or full-chip layouts with cut-off contexts. \nThus, the reported gains are partly an artifact of the windowed simulation, overstating the model's practical performance in full-chip mask synthesis. \n\n2. The paper repeatedly describes the source designs as “five real IC designs at the 45nm node.” In reality, these are designs implemented using the fully open-source OpenROAD flow and the public Nangate45 library, not proprietary cutting-edge designs.\nOpenROAD + Nangate45 is great for research, but it is far from manufacturing signoff at 45 nm.\n\n3. The cell tag is injected as a one-hot channel broadcast to 1024×1024 and concatenated with the image. \nThat means the model can trivially memorize a per-cell lookup table for mask style, which is the opposite of generalization. \nThe authors do not evaluate generalization to unseen cells, unseen designs, or process drifts.\n\n4. The OpenILT provides several ILT algorithm, and the author didn't tell which ILT solutions they used."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Jn5exZ23Lk", "forum": "ObZhsQBqdB", "replyto": "ObZhsQBqdB", "signatures": ["ICLR.cc/2026/Conference/Submission5052/Reviewer_pGry"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5052/Reviewer_pGry"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5052/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761810676695, "cdate": 1761810676695, "tmdate": 1762917844438, "mdate": 1762917844438, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}