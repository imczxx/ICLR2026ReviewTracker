{"id": "Xo0uuCThYG", "number": 1113, "cdate": 1756842527427, "mdate": 1759898227378, "content": {"title": "The Emergence of Complex Behavior in Large-Scale Ecological Environments", "abstract": "We explore how physical scale and population size shape the emergence of complex behaviors in open-ended ecological environments.  In our setting, agents are unsupervised and have no explicit rewards or learning objectives but instead evolve over time according to life, death, and reproduction rules.  As they act, they also shape their environment and the population around them in an ongoing dynamic ecology.  Our goal is not to optimize a single high-performance policy, but instead to examine how behaviors emerge and evolve across large populations due to natural competition and environmental pressures.  In an effort to discover how complex behaviors naturally emerge, we conduct experiments in large-scale worlds that reach populations of more than 60,000 individual agents, each with their own evolved neural network policy.  We identify various emergent behaviors such as long-range resource extraction, vision-based foraging, and predation that arise under competitive and survival pressures.  We examine the relationship between sensing, environmental scale, and the emergence of these behaviors, finding that some appear only in large environments and populations, and that larger scales generally increase stability and consistency in these settings.  While there is a rich history of research in evolutionary settings, our scaling results provide promising new directions to explore ecology as an instrument of machine learning in an era of abundant computational resources.", "tldr": "We explore how environmental scale and sensing the emergence complex behaviors in open-ended evolutionary settings.", "keywords": ["Population dynamics", "Adaptive agents", "Synthetic environment", "implicit rewards"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c5d57c853fedb6a43429acdbf3c7b5e58f8362ad.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors introduce a large-scale platform for open-ended intelligent agent simulations. In these simulations, large numbers of agents, with their actions decided based on randomly initialized neural networks, can collect resources with which to survive, navigate their environment, attack and kill other agents, reproduce, and, should they run out of health, die. Evolution of the agents is facilitated by the reproduction action, where, assuming an agent has enough resources, it may produce a copy of itself with a small perturbation of the neural network weights, thus creating a simple random search evolution. As a state description, the agents can have access to internal sensors, describing their health, age, and resources, as well as external information, including a compass and local vision. The authors then experiment with allowing the agents access to some or all of this information and different actions, in particular, whether or not the agents can kill, to determine how the populations evolve over time and whether certain information leads to more common policies. They find, for example:\n\n- Agents without a compass appear to die out quickly in environments where land is not surrounded by water. This is due to the land-based agents not finding water, thus dying, and the water-based agents not realizing how to get onto land and collect food before heading back to the water. Given a compass, the agents can learn to \"mine\" for resources.\n- Agents with vision are less likely to kill, but more efficient. Killing in this world involves the agents in front of the attacking agent dying. Therefore, agents with vision are typically better at it. \n\nOverall, the paper is an interesting exploration of emergent policy, although the largest contribution is likely to be the development of the JAX-based environment in which one can run these simulations."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "The strengths of the paper come in its comprehensive and clear discussion of results and the introduction of a tool that will likely benefit other research efforts. The authors clearly state the arguments behind the behaviors that emerge in their simulations in a way that is easy to understand and of general interest. Further, the development of a JAX-based package to perform further experiments is likely to be of great use to the research community."}, "weaknesses": {"value": "While the paper is well-written and of interest, several weaknesses need to be addressed. \n\n- The experiments in the paper are very limited and likely within the scope of other, similar studies. Therefore, the main result of the paper appears to be the development of the JAX package. To that end, though, there is very limited information provided about the simulation package and its performance. Scaling tests, discussions on GPU deployment, software architecture, and future directions are all absent in a paper where this appears to be a very significant result and contribution to the community.\n- The handling of statistics is not very strong. The authors mention that in larger simulations, some of the emergent strategies are more stable. This is likely to be self-averaging of the system with a larger sample size. However, that also means that the smaller simulations were not repeated enough (four times according to the methods) to be fairly compared to the larger ones. A simple solution would be to show the scaling as a function of simulation size to identify saturation and then only present results in the larger runs. \n- The argument surrounding non-determinism due to GPU operations could be better explained. Is it a type-casting issue related to the 16-bit weights?\n- The absence of captions in Figures 5 and 6, initially assumed to be an oversight, appears now more to be a means of not going over the page limit for the conference submission."}, "questions": {"value": "The following questions came up when reading over the paper.\n\n- Is the vision given to the agents 360 degrees? If so, would it make more sense to only provide limited vision in a cone?\n- How are fights decided? From an initial reading, it appears that whoever attacks first wins. It could be interesting to have probabilistic or health-based criteria. How easily can this be implemented and tested in the new framework?\n- Further to the previous question, would it make sense to include growth in the agents, perhaps by increasing HP?\n- The authors mentioned the color of the agent is changeable. Can the authors elaborate on this point? It doesn't appear to be mentioned further in the work.\n- The biggest question that arose was the possibility of guiding the evolution. Simple, random evolution is very limited. How could the authors see including certain drives of the agents, e.g., a desire to live and reproduce, perhaps using limited reinforcement learning algortihms to have a more guided search. Are these different kinds of update strategies simple in the new, JAX-based framework?"}, "flag_for_ethics_review": {"value": ["Yes, Unprofessional behaviors (e.g., unprofessional exchange between authors and reviewers)"]}, "details_of_ethics_concerns": {"value": "The authors appear to have removed captions to meet the page limit. While minor, it could be seen as a breach of ethics."}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "oSQZP0f5Df", "forum": "Xo0uuCThYG", "replyto": "Xo0uuCThYG", "signatures": ["ICLR.cc/2026/Conference/Submission1113/Reviewer_J3YU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1113/Reviewer_J3YU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1113/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761234560977, "cdate": 1761234560977, "tmdate": 1762915682652, "mdate": 1762915682652, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper examined how environmental scale and population size influence the emergence of complex behaviors in open-ended ecological environments. In this setting, agents have no explicit rewards or learning objectives but evolve over time through life, death, and reproduction rules while continuously shaping their surroundings and populations. The study focuses not on optimizing a single policy but on observing how diverse behaviors, such as long-range resource gathering, vision-based foraging, and predation, emerge from natural competition and environmental pressures. Experiments in large-scale worlds with over 60,000 agents show that some behaviors appear only at larger scales and that increasing scale generally improves the stability and consistency of ecological dynamics."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This study clearly shows the originality of the objective-free ecological formulation that couples population dynamics (life/death/reproduction) with partially observable sensing, positioned as a tool to probe emergent behavior at scale. Methodologically, a scalable JAX simulator that supports large maps/populations, explicit resource flows, and controlled sensor ablations, enabling systematic tests of scale and sensing. In the experiments, consistent evidence that compass enables reliable long-range resource trips and vision improves foraging/predation efficiency, with larger worlds reducing variance and increasing stability."}, "weaknesses": {"value": "First, the work relies on mutation-only neuroevolution with memory-less MLPs, but it does not make clear what form of representation or adaptation is actually learned. Second, the paper does not position itself against diversity- and curriculum-driven open-ended learning frameworks, leaving unclear whether the contribution extends or primarily scales existing ideas. Third, the main behavioral effects are intuitive, and because map area and initial population are scaled together, the source of the observed stability (environmental scale vs. population size) remains confounded. For details, see the following questions."}, "questions": {"value": "1. The paper adopts mutation-only neuroevolution with memory-less MLP policies, without any gradient-based optimization or explicit learning objective. Could the authors clarify what kind of representation or adaptation process actually occurs under this setup? For example, how do policy parameters or sensory mappings evolve over time, and can this be interpreted as a form of learning in any representational sense?\n\n2. How does this study relate to unreferenced diversity- and curriculum-driven open-ended learning prior work such as Novelty Search [a], MAP-Elites [b], and POET [c]? A clearer positioning or comparative discussion could help readers understand whether this work extends or merely scales up existing ideas.\n\n\n3. The results mainly show that a compass leads to navigation and vision improves foraging and predation efficiency, which are intuitively expected outcomes. Beyond the stability that appears at larger scales, what new behavioral or algorithmic insight does this work reveal that was not already known from prior open-ended evolution frameworks?\n\n4. In the scaling experiments, both map area and initial population size increase together.\nCould the authors disentangle these two effects (environmental scale vs. population size)?\nIt may remain unclear which factor actually drives the emergence and stability of complex behaviors.\n\n5. Figures 5 and 6 currently have the “Caption.” only. Please add proper captions.\n\nReferences\n[a] Lehman and Stanley. Abandoning objectives: Evolution through the search for novelty alone.\nEvolutionary Computation 19(2), 2011.\n[b] Cully et al. Robots that can adapt like animals. Nature 521(7553), 2015. \n[c] Wang, Rui, Joel Lehman, Jeff Clune, and Kenneth O. Stanley. POET: Paired Open-Ended Trailblazer.\nGECCO 2019."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FjTmZGDlzw", "forum": "Xo0uuCThYG", "replyto": "Xo0uuCThYG", "signatures": ["ICLR.cc/2026/Conference/Submission1113/Reviewer_P43N"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1113/Reviewer_P43N"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1113/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761812055069, "cdate": 1761812055069, "tmdate": 1762915682492, "mdate": 1762915682492, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a large-scale ecological simulation in which tens of thousands of neural agents live, eat, reproduce, and die without any explicit reward or predefined objective. Each agent’s behavior is governed by a small feedforward neural network whose weights are inherited and randomly mutated during reproduction, forming a purely evolutionary learning process. By systematically scaling the ecological environment—world size, terrain, population, and sensor richness—the authors show that increasingly complex behaviors (such as long-distance resource collection, navigation, and vision-based predation) emerge reliably only at large scales. The work argues that ecological scale can serve as a new axis of capability emergence, much like model scale in modern deep learning. This paper is novel and inspiring, presenting an large-scale ecological simulation that explores how complex behaviors can emerge from simple evolutionary rules without any explicit reward. That said, the work is still more exploratory than analytical—its claims about emergence rely mainly on qualitative observation, and the mechanisms behind the behaviors are not deeply quantified or explained."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Fresh perspective on open-ended learning. The paper reframes “intelligence without reward” as a scalable ecological process. The analogy between ecological and model scaling is elegant and offers a new lens on emergence in machine learning.\n\n2. The authors manage to simulate up to 60 000 agents in a large heterogeneous world with realistic resource flow, physics, and reproduction—all efficiently implemented in JAX. \n\n3. Convincing qualitative behaviors. Emergent patterns—migratory resource transport, coordinated foraging, predation—appear genuinely spontaneous. The controlled scaling studies (terrain, sensory modalities, map size) clearly show that these behaviors depend on environmental complexity.\n\n4. Interdisciplinary impact. The work bridges artificial life, multi-agent systems, and open-ended evolution."}, "weaknesses": {"value": "1. Lack of quantitative behavioral metrics. Claims about “emergence” are supported mainly by qualitative observation. There are no explicit metrics for behavioral diversity, complexity, or ecological stability.\n\n2. Minimal evolutionary mechanism. The use of pure mutation without crossover or explicit selection limits interpretability of the evolutionary dynamics. It’s unclear whether complexity arises from environment pressure alone or random drift.\n\n3. Missing ablations and baselines. The paper would be stronger if it included smaller-scale or simplified control experiments to isolate the effect of each design choice (e.g., mutation variance, resource rules, sensory range).\n\n4. Compute intensity and reproducibility. Running such large worlds likely requires significant hardware. The paper does not discuss runtime or resource requirements, which may hinder reproducibility."}, "questions": {"value": "1. Can you provide a quantitative measure (even heuristic) for behavioral diversity or ecological balance over time?\n\n2. How sensitive are the observed behaviors to mutation rate or neural network size?\n\n3. Are there global population caps or only local resource constraints?\n\n\n\n4. Have you considered hybrid models that combine within-lifetime learning (e.g., gradient updates) with across-generation evolution?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4yUp5mTemM", "forum": "Xo0uuCThYG", "replyto": "Xo0uuCThYG", "signatures": ["ICLR.cc/2026/Conference/Submission1113/Reviewer_NFvD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1113/Reviewer_NFvD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1113/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761898102450, "cdate": 1761898102450, "tmdate": 1762915682350, "mdate": 1762915682350, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper seeks to understand how complex behaviors can emerge through large-scale ecological environments with agents (on the order of 10,000s) interact with each other and the dynamic and changing environment. The paper describes how the environment and agents work, and discusses what happens during the evolution of the agents with different environment settings."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- The paper introduces a jax based environment which is easy to scale on a GPU/multi-GPU setup to enable faster data generation for studying emergence.\n- Environment looks like something that can be easily visualized which is a great for developers/researchers in the future."}, "weaknesses": {"value": "- Overall I feel this paper lacks significantly novelty. Perhaps one novelty is that this is a large-scale environment with 60,000 agents with some interesting game rules (although they seem similar to neural MMO e.g. foraging). Another concern is that the majority of this paper is spent 1. explaining the game and rules followed by 2. analyzing what happens if you evolve all these different (memoryless) agents and what behaviors emerge. There is not much discussion around how these results would teach us anything new about how complex behaviors emerge as a result of scale. As a result this work seems otherwise very similar to the hide and seek open AI work or neural MMO itself.\n- A large concern is that the agents are all memoryless, which appears to be a significant drawback when comparing to e.g. neural MMO which uses RNN based agents. Memory is a fundamental part of human behavior and not having this capability as a baseline or approach in the environment would limit the possibilities of the proposed environment.\n- Figure 5 missing caption"}, "questions": {"value": "- It is interesting that RL is not considered and only population evolution operations are performed by adding noise to parent descended weights. What is the reasoning behind this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QFzGRbX1sd", "forum": "Xo0uuCThYG", "replyto": "Xo0uuCThYG", "signatures": ["ICLR.cc/2026/Conference/Submission1113/Reviewer_ssLs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1113/Reviewer_ssLs"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1113/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761938021604, "cdate": 1761938021604, "tmdate": 1762915682210, "mdate": 1762915682210, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper uses a new JAX-based simulation environment the authors developed to allow rapid evaluation of large grid worlds, where they conduct experiments with populations of more than 60,000 individual agents, each with their own evolved neural network policy. They report on their experiments. \n\nTheir stated aim is \"to examine how behaviors emerge and evolve across large populations due to natural competition and environmental pressures.\" They observe some behaviours they refer to as emergent, that arise more commonly with scale. They do not however discuss if similar behaviors have or have not been observed in previous simulations in the literature. The computing framework they develop to enable their simulations is not positioned as their central contribution, and the design is not discussed in detail nor compared to that of other simulations, but it's possible that some novelty of their work lies partly in that HPC contribution."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The authors developed a new simulation environment to allow rapid evaluation of large grid worlds, where they conduct experiments with populations of more than 60,000 individual agents, each with their own evolved neural network policy. They observe some behaviours they refer to as emergent, that arise more commonly with scale. Specifically these are: the ability of agents to travel long distances inland in order to find resources (and in fact to go back and forth to water, a behaviour they call \"mining\") and the ability to use vision sensors to effectively locate free resources or prey on other agents. \n\nThe topic in ecology and study of emergence in collections of agents is very nice and interesting.\n\nThe effort to set up a platform where such large-scale studies can be carried out is a strength. It would be good to see more information about how the computational design in this paper advances state of the art."}, "weaknesses": {"value": "Contextualization with respect to other work is insufficient. \n\nIn particular, there is no information in the experimental results discussion about how such observations compare to ones in related work. This would be important if this paper is meant as a contribution on the (computational) ecology side, but it's also crucual in order to assess the strength of their simulation, e.g. it allows them to remedy specific weaknesses in previous work. The Related Work section near the start of the paper, which does list extensive related literature, also doesn't position the authors' contribution with respect to those other works, it simply lists them. Perhaps the largest contribution of the paper is on the high-performance computing side, i.e. the new JAX-based design they propose. That HPC work is however not stated as the paper's focus and there are few details of that design. \n\nThere are also presentation issues, and instances where rigor is lacking:\n\nRe Section 3.1: \n- it sounds like in an EG each agent has full knowledge of the id’s of other living agents, since this information is  encoded in s_t… is that really what you assume? it’s quite different from more evolutionary settings.. Michael Levin for example emphasizes the role of information transfer in self-organization (via bioelectiricity). \n- Line 164 has sloppy wording: do you mean \"it maps for each player, a state-action pair (s_t, a_t) to a distribution…\"\n- Definition of Gamma: this should be spelled out more clearly.. \\Gamma(s_t) is a list of agents alive at time t and for each of them the\nidentify of their parents.\n- In which case, why do you nead G_t? isn’t this information included in \\Gamma(s_t)?\n\nRe Section 3.2:\nRigor of this section is important to understand the paper, and for any comparison with learning paradigms like RL or genetic algorithms but it's too informally worded.\n- line 174: the notation s_t = {s^m_t, s^a_t} suggests ignorance of the mathematical meaning of these symbols and also goes against convention to call a state space by an upper case letter, instead this is some hybrid between trying to say what each state is, and discussing state space. It seems you’re saying that each s_t = (s_t^m, s_t^a)--notice the parentheses not curly brackets--in which case the state space is S_t = S_t^m x S_t^a. Or maybe the intent is something else. It should be rigorously stated.                                                           \n - line 185ff, make clear which factors of S_t^m are changing with time and which are unchanging.\n- line 199ff, how much  memory does each agent have? what else governs agents? you need a section for agents\n- throughout this section, there are many assumptions.. how would changing these affect the outcome? no ablation analysis was done.."}, "questions": {"value": "What would the authors say is their central contribution and how does it advance state of the art, i.e. what exactly does it do *better than comparable* other approaches or past work?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lD6gRAbaCC", "forum": "Xo0uuCThYG", "replyto": "Xo0uuCThYG", "signatures": ["ICLR.cc/2026/Conference/Submission1113/Reviewer_hMQJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1113/Reviewer_hMQJ"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission1113/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762812990423, "cdate": 1762812990423, "tmdate": 1762915682030, "mdate": 1762915682030, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}