{"id": "rBUUtTPiEO", "number": 4709, "cdate": 1757751678980, "mdate": 1759898018604, "content": {"title": "Antagonistic Evolution for LLM Tool Use", "abstract": "Tool use has emerged as a pivotal mechanism for enhancing Large Language Models (LLMs), allowing them to interact with external tools to solve complex tasks and access knowledge beyond their static pre-trained parameters. However, most existing studies rely on advanced LLMs to improve tool-use capabilities via data synthesis, often resulting in suboptimal data quality or mismatched task difficulty, thereby limiting model performance. To address these limitations, we propose a novel antagonistic evolution framework for tool-use tasks, involving a query-generation model and a tool-use model updated in an adversarial manner. The query-generation model is optimized to produce increasingly challenging and high-quality queries, which the tool-use model then learns to solve. This adversarial process is iteratively executed, enabling both models to co-evolve and progressively enhance the tool-use capabilities. Experiments on three comprehensive tool-use benchmarks demonstrate evolving performance improvements, validating the effectiveness of our approach.", "tldr": "", "keywords": ["Large Language Model", "Tool Learning", "Adversarial Evolution"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/20801ec820c8764c0465a3dbd0e392fe3962ce8f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes an antagonistic evolution framework to train tool-use LLMs. The method iteratively optimizes the query-generation model that creates more complex queries, and the tool-use model that solves queries. Experiments on BFCL-live, APIBank, and ACEBench show performance improvements over baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper tackles an important problem. Improving the tool-use ability of LLMs in a data-efficient and self-improving manner is highly relevant to current LLM research.\n2. The co-evolution framework is an interesting and potentially effective idea. The design of alternating updates between query generation and tool-use training is conceptually reasonable.\n3. The paper is overall clear and well written, easy to follow."}, "weaknesses": {"value": "1. Although the paper claims to draw inspiration from GANs, the proposed antagonistic evolution does not involve an explicit adversarial optimization or equilibrium-seeking process.  There is no discussion of Nash equilibrium or convergence properties, and the algorithmic stability remains unclear.\n2. The connection and distinction from curriculum learning, self-play, and self-evolution paradigms are not thoroughly discussed. The paper should clarify how the proposed method differs conceptually and technically from prior approaches.\n3. Limited experiments:\n* The experiments only use Qwen2.5-7B-Instruct as the base model, which limits generality.\n* The baselines are mostly generic tool-learning models, but do not include methods like curriculum-learning or self-play-based methods for comparison.\n* The discussion of results is insufficient. For instance, in Table 1, the proposed method underperforms several baselines under the “BFCL-live Parallel” setting, but this discrepancy is under explained."}, "questions": {"value": "In Equation (2), the goal is to update the tool-use model. However, the current formulation maximizes the conditional probability of q̃ given A, rather than A given q̃. Is this correct？"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WHwZshsSFK", "forum": "rBUUtTPiEO", "replyto": "rBUUtTPiEO", "signatures": ["ICLR.cc/2026/Conference/Submission4709/Reviewer_8C5p"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4709/Reviewer_8C5p"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760692887697, "cdate": 1760692887697, "tmdate": 1762917527920, "mdate": 1762917527920, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes AETool, an antagonistic evolution framework to enhance the tool-use capability of large language models (LLMs). The key idea is to co-train a query-generation model and a tool-use model in an adversarial manner.. Extensive experiments across three benchmarks (BFCL, API-Bank, and ACEBench) demonstrate consistent performance gains over baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Comprehensive Experiments. The paper evaluates on multiple public tool-use benchmarks.\n2. Continuous Improvement. The results convincingly show that the model benefits from iterative training."}, "weaknesses": {"value": "1. Overstated novelty. The paper claims to introduce the first adversarial evolution method for tool-use tasks. However, similar self-challenging or self-play paradigms have been explored in related agentic settings (e.g., [1–2]). These works are not cited or discussed, leaving unclear how AETool fundamentally differs from prior approaches.\n2. Unfair comparisons. Many baselines are open-source models that differ in both backbones and training datasets. Consequently, it is difficult to determine whether the reported improvement originates from AETool itself, rather than from differences in model architecture or data scale.\n3. Weak baseline selection. The only fair baseline is the vanilla SFT method, which is too weak to establish strong empirical evidence. The comparison omits recent reinforcement learning–based and self-challenging methods (e.g., [1–4]), limiting the strength of the empirical claims.\n5. Lack of detailed analysis of the query model. The query model update appears to be the paper’s primary innovation relative to prior work [1]; therefore, its role warrants careful analysis, which is currently missing. Specifically, I have the following concerns:\n\t- Empirical issue: Figure 4 shows that removing the query-model update leads to only marginal degradation in later epochs and even performs better in early stages. This raises doubts about whether updating the query model is truly necessary.   \n\t- Methodological issue: The paper trains the query model to generate harder queries based on the tool model’s confidence scores, but such confidence signals may be unreliable. Consequently, the distinction between “easy” and “hard” queries could be noisy, making it unclear whether the query model genuinely learns to generate more challenging queries.\n\t- Missing analysis: A more detailed investigation of the query model’s evolution and the actual difficulty growth of generated queries is needed to validate the claimed mechanism.\n\n\n[1] Y. Zhou et al., Self-Challenging Language Model Agents\n\n[2] P. Li et al., Iterative Tool Usage Exploration for Multimodal Agents via Step-wise Preference Tuning\n\n[3] C. Qian et al., ToolRL: Reward is All Tool Learning Needs\n\n[4] S. Zhang et al., Nemotron-Research-Tool-N1: Tool-Using Language Models with Reinforced Reasoning"}, "questions": {"value": "1. How sensitive is the performance to the temperature and the number of generated queries k in each iteration?\n2. Does the adversarial process always converge to improvement, or can it degrade due to somehow unexpected queries?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6QC4V7kNOf", "forum": "rBUUtTPiEO", "replyto": "rBUUtTPiEO", "signatures": ["ICLR.cc/2026/Conference/Submission4709/Reviewer_QBxT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4709/Reviewer_QBxT"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761049102659, "cdate": 1761049102659, "tmdate": 1762917527670, "mdate": 1762917527670, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes AETool, an antagonistic co-evolution training scheme for tool use: a query-generation model iteratively rewrites the same solution into harder, higher-quality queries while a tool-use model learns to solve them; the authors report gains over similarly sized baselines and direct SFT on three mainstream tool-use benchmarks—BFCL, APIBank, and ACEBench."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Bringing antagonistic difficulty ramping into tool-use training is commendable; compared with the traditional pipeline that mass synthesizes data with a strong model and then SFTs it, this paper emphasizes self-generated samples aligned to the trained model’s competence frontier, which is a well-motivated direction consistent with recent self-play advances"}, "weaknesses": {"value": "1. Lack of theoretical analysis. First, this paper does not specify conditions under which antagonistic co-evolution avoids mode collapse and yields stable improvements. A minimal stylized objective plus stability conditions would help, such as self-play formulations with Nash-style guarantees. Secondly, there is no robustness analysis for the adversarially generated data: tool-using agents are known to be brittle under prompt-injection/perturbation and environment shifts, so a robustness section is needed. Thirdly, the method assumes the tool model’s confidence is a reliable proxy for difficulty, but LLM confidence is often miscalibrated.\n---\n2. Related work may be incomplete. This paper should more systematically compare with prior adversarial/self-evolution or self-generated data approaches for tool use and alignment."}, "questions": {"value": "APIBank Level-3 exists and is widely regarded as a key tier for integrated multi-tool/multi-turn planning; please clarify why it was not evaluated or include a Level-3 assessment to strengthen completeness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ODLAUwHpEx", "forum": "rBUUtTPiEO", "replyto": "rBUUtTPiEO", "signatures": ["ICLR.cc/2026/Conference/Submission4709/Reviewer_m3db"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4709/Reviewer_m3db"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761201955553, "cdate": 1761201955553, "tmdate": 1762917527430, "mdate": 1762917527430, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes AETool, a novel antagonistic evolution framework for improving LLM tool-use capabilities through co-evolution of a query-generation model and a tool-use model. Unlike most self-evolution approaches that rely on a single model, AETool introduces an adversarial training loop with data mutation to iteratively generate more challenging yet solvable queries. The method achieves state-of-the-art results across three major tool-use benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.Most prior self-evolving approaches rely on a single model to generate and learn from its own data. In contrast, AETool explicitly decouples roles into a query-generation model and a tool-use model, enabling more controlled and adaptive difficulty progression.  \n2.The proposed system integrates four key components: query generation, tool use, adversarial co-evolution, and data mutation into a cohesive and iterative pipeline that enables continuous mutual improvement.  \n3.AETool consistently achieves state-of-the-art results on three established tool-use benchmarks, demonstrating both effectiveness and generalization."}, "weaknesses": {"value": "1.Each iteration requires running two models, multiple sampling passes, and a data mutation step, leading to significantly higher training costs than standard supervised fine-tuning (SFT). The paper lacks key efficiency metrics (e.g., training time, GPU hours, or inference latency), making it difficult to assess practical deployability.  \n2.While the method is described as antagonistic or GAN-inspired, it could alternatively be interpreted as a form of multi-agent collaborative training. The paper does not clearly differentiate its approach from existing multi-agent frameworks or justify why the adversarial perspective is more appropriate.  \n3.The warmup phase for the query-generation model depends on high-quality ground-truth queries from the original dataset. If the initial data is noisy or low-quality, the entire evolution process may start from a poor initialization. The robustness of the method under such conditions is not analyzed."}, "questions": {"value": "Please see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "I0PS97uKRO", "forum": "rBUUtTPiEO", "replyto": "rBUUtTPiEO", "signatures": ["ICLR.cc/2026/Conference/Submission4709/Reviewer_6D4F"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4709/Reviewer_6D4F"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990512672, "cdate": 1761990512672, "tmdate": 1762917526655, "mdate": 1762917526655, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}