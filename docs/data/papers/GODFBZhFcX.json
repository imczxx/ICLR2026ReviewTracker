{"id": "GODFBZhFcX", "number": 11587, "cdate": 1758202190453, "mdate": 1759897565995, "content": {"title": "From Assumptions to Actions: Turning LLM Reasoning into Uncertainty-Aware Planning for Embodied Agents", "abstract": "Embodied agents operating in multi-agent, partially observable, and decentralized environments must plan and act despite pervasive uncertainty about hidden objects and collaborators' intentions. Recent advances in applying Large Language Models (LLMs) to embodied agents have addressed many long-standing challenges, such as high-level goal decomposition and online adaptation. Yet, uncertainty is still primarily mitigated through frequent inter-agent communication. This incurs substantial token and time costs, and can disrupt established workflows, when human partners are involved. We introduce PCE, a Planner-Composer-Evaluator framework that converts the fragmented assumptions latent in LLM reasoning traces into a structured decision tree. Internal nodes encode environment assumptions and leaves map to actions; each path is then scored by scenario likelihood, goal-directed gain, and execution cost to guide rational action selection without heavy communication. Across two challenging multi-agent benchmarks (C-WAH and TDW-MAT) and three diverse LLM backbones, PCE consistently outperforms communication-centric baselines in success rate and task efficiency while showing comparable token usage. Ablations show that merely enlarging model capacity or reasoning depth yields only limited gains, whereas PCE amplifies the benefits of scaling beyond what parameter growth alone can achieve. A user study further demonstrates that PCE produces communication patterns that human partners perceive as more efficient and trustworthy. Together, these results establish a principled route for turning latent LLM assumptions into reliable strategies for uncertainty-aware planning.", "tldr": "", "keywords": ["multi-agent system", "large language model", "human-agent cooperation"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/260c01f22bd783cc07468633fc14032ec54fe02e.pdf", "supplementary_material": "/attachment/e8de2375355aad7b2777fa46a6d39384c8a05baf.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes **PCE (Planner–Composer–Evaluator)**, a modular framework that enhances LLM agents’ ability to plan and act in multi-agent embodied environments. The **Planner** generates potential next steps, the **Composer** extracts hypotheses from plans and structures them into a decision tree, and the **Evaluator** assesses candidate actions based on expected gain and cost of paths on the decision tree. The system aims to make LLM agents more consistent and efficient by explicitly modeling future actions and uncertainty. Experiments conducted on two benchmarks, C-WAH and TDW-MAT, across multiple backbone LLMs demonstrate improvements in task success rate with decreased communication. Furthermore, human studies on PCE show that the system is more helpful and efficient."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The **motivation for PCE is clear and well-grounded**. By designing the planning module to explicitly model upcoming steps and their corresponding confidence scores, analogous to a world model, the approach enables LLM agents to act more consistently and **avoid redundant or unproductive communications**, leading to more efficient collaboration.\n- Across both C-WAH and TDW-MAT benchmarks, **PCE consistently achieves faster goal completion and higher success rates** under all three backbone LLMs (GPT-4o mini, GPT-OSS:20B, and Gemma3:4B). This demonstrates the strong performance of PCE. Meanwhile, smaller communication times make PCE more efficient when cooperating with humans.\n- The authors systematically evaluate the necessity of each component and provide clear explanations of their functionalities. This detailed analysis and transparent modular design make the system **relatively easy to reproduce and adapt** to other tasks or environments."}, "weaknesses": {"value": "- The designs of the planner, composer, and evaluator in the planning module essentially prompt LLMs to perform planning, extraction, and evaluation. Meanwhile, the evaluation metric is the score output by an LLM judge. Given that LLM scores are not very accurate, it may be challenging to accurately measure the system's stability.\n- As in Tables 1 and 2, regarding the token usage metric, the result is not significant. This makes me think about whether the system is sending too many tokens at one time in the communication channel, or if the system has a higher latency in planning for the next step.\n- Typos:\n    - In the composer part of Fig 1., “assumtion” should be “assumption”."}, "questions": {"value": "- Regarding Weakness 1, can the authors analyze the accuracy of the LLM-generated scores? It is important to understand their stability.\n- Regarding Weakness 2, for the metrics, does the **Usage** metric measure only communication tokens or all tokens generated within the system? If it’s the former, could the authors also compare the total generated tokens with the baselines? I believe this would be a good proxy for both the latency and cost of the designed system.\n- From Table 3, we observe an interesting phenomenon: removing the **planner** dramatically increases the number of communication rounds (from 1.70 to 9.52), whereas removing the **composer** decreases them. Could the authors explain why this happens?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "knPdlXy85J", "forum": "GODFBZhFcX", "replyto": "GODFBZhFcX", "signatures": ["ICLR.cc/2026/Conference/Submission11587/Reviewer_yuvs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11587/Reviewer_yuvs"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11587/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761429142512, "cdate": 1761429142512, "tmdate": 1762922671164, "mdate": 1762922671164, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response (1/2)"}, "comment": {"value": "We sincerely thank all reviewers for their thoughtful evaluation and constructive feedback. We are actively addressing all concerns raised by the reviewers to strengthen the manuscript.\n\nIn this rebuttal, we first outline the key strengths recognized by the reviewers, followed by a summary of the major issues identified and the corresponding new experiments and revisions we have completed.  We are currently incorporating these results into the manuscript and will upload the revised paper along with detailed individual responses shortly\n\nWe appreciate the following strengths highlighted across the reviews:\n\n- **Significance of Formulated Problem, Originality and Clarity of Proposed Method:** Reviewers commended the core idea of extracting and structuring latent assumptions from LLM reasoning traces (FyaB S1, yuvs S1), addressing communication-heavy problems (FyaB S2, Sbnl S1, yuvs S1), Clear framework design (FyaB S3, yuvs S3), and introducing an uncertainty handling mechanism to this field (5pEK S1).\n- **Strong Empirical Performance and Valuable User Study:** The consistent performance gains on C-WAH and TDW-MAT benchmarks across diverse LLM backbones (GPT-4o mini, GPT-OSS, Gemma3), along with the significant reduction in communication overhead, were recognized as strong evidence of the framework's effectiveness (5pEK S1,2, FyaB S4, SbnL S3, yuvs S2). The inclusion of user studies validating that PCE produces more efficient and trustworthy collaboration patterns with human partners was highly praised (FyaB S4, SbnL S2, yuvs S2).\n- **Reproducibility and broad applicability:** The detailed analysis and modular design of the system make it easy to reproduce and adapt to other tasks (yuvs S3). Consistent improvements across GPT-4o mini, GPT-OSS:20B, and Gemma3:4B suggest broad applicability (Snbl S3).\n\nBelow, we summarize the key issues identified by the reviewers.\n\n**1. Component Reliability and Validation**\n\nMultiple reviewers raised concerns regarding the \"reliability and accuracy of the core modules (Composer and Evaluator)\" given their reliance on LLMs.\n\n- **FyaB(Q1) & SbnL(Q3):** Questioned the Composer's ability to correctly extract assumptions, handle vague traces, and avoid hallucinations.\n- **yuvs(Q1):** Raised concerns about the accuracy and stability of the scores generated by the LLM-based Evaluator.\n\n**Our Response & New Experiments:**\n\n- **Quantitative Expert Evaluation (Composer):** We conducted a blind cross-evaluation with four domain experts to assess the Composer's trees against human expert outputs. Results show that the Composer achieves near-human performance in Extraction Accuracy (6.27/7.0) and Generation Appropriateness (6.39/7.0).\n- **Human-AI Correlation Study (Evaluator):** We analyzed the alignment between Evaluator scores and human expert judgments. Experimental results showed that the difference in evaluation scores between the Evaluator and the expert was minimal.\n\n**2. Baselines and Differentiation**\n\nReviewers requested clearer positioning against existing methods and \"comparisons with stronger or more relevant baselines.\"\n\n- **5pEK(Q2):** Suggested comparing with distance-based MCTS methods to validate tree-based planning efficiency.\n- **SbnL(W1,W2):** Asked for clearer differentiation from communication-centric frameworks like ProAgent, CoELA, and REVECA.\n\n**Our Response & New Experiments:**\n\n- **New Baseline (MHP):** We incorporated the MCTS-based Hierarchical Planner (MHP) ****as a baseline. Results show PCE significantly outperforms MHP (42.76 vs. 64.90 steps), demonstrating the value of semantic reasoning over pure distance optimization.\n- **Clarified Positioning:** We are revising the Related Work section to detail the distinction that unlike baseline models, which treat communication as an essential protocol or search mechanism, PCE treats it as an optional means for handling uncertainty."}}, "id": "kzC2OG3sXr", "forum": "GODFBZhFcX", "replyto": "GODFBZhFcX", "signatures": ["ICLR.cc/2026/Conference/Submission11587/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11587/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11587/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763717858857, "cdate": 1763717858857, "tmdate": 1763717858857, "mdate": 1763717858857, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes PCE (Planner-Composer-Evaluator), a framework for uncertainty-aware planning in LLM-based embodied agents. The key idea is to extract implicit assumptions from LLM reasoning traces and structure them into a decision tree, enabling effective multi-agent coordination without heavy communication. However, the technical contribution is limited and differentiation from similar work is unclear."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The paper effectively identifies the communication overhead problem.\n- User study results showing that PCE produces more efficient communication patterns demonstrate practical value.\n- Consistent improvements across GPT-4o mini, GPT-OSS:20B, and Gemma3:4B suggest broad applicability."}, "weaknesses": {"value": "- The distinction between the proposed methodology and existing multi-agent task planning techniques remains unclear. In particular, the paper needs to articulate clear differences from approaches like ProAgent, CoELA, REVECA, and CaPo, which also perform tasks through multi-agent communication.\n- Furthermore, while the main contributions are presented as the Planner-Composer-Evaluator structure and the decision tree-based techniques in the Composer and Evaluator, these appear to be applications of existing methods rather than novel contributions.\n- In the experimental section, the performance degradation when removing the Composer appears minimal. This raises questions: if the Planner-Evaluator structure alone achieves higher performance than baselines that utilize collaborative agents, what accounts for this superiority? The analysis lacks clarity on why performance exceeds baselines even without the Composer, and where specifically the Composer contributes to performance improvements. Such analysis should be included to better understand the contribution of each component."}, "questions": {"value": "- What is the recovery method when assumptions at decision tree nodes are incorrect?\n- How does PCE perform in environments where communication is completely blocked?\n- How do you evaluate and ensure the quality of assumption extraction?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "B8NECspTNS", "forum": "GODFBZhFcX", "replyto": "GODFBZhFcX", "signatures": ["ICLR.cc/2026/Conference/Submission11587/Reviewer_SbnL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11587/Reviewer_SbnL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11587/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761612819444, "cdate": 1761612819444, "tmdate": 1762922670610, "mdate": 1762922670610, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper identifies a key challenge for LLM-based embodied agents in partially observable, multi-agent settings: the heavy reliance on inter-agent communication to resolve uncertainty, which incurs significant token, time, and human workflow costs.\n\nTo address this, the authors propose PCE, a Planner-Composer-Evaluator framework. The core idea is to leverage the implicit, fragmented assumptions that LLMs generate in their reasoning traces.\n\n- The **Planner** produces an initial action and its reasoning trace.\n\n- The **Composer** extracts these latent assumptions and structures them into an explicit decision tree (a \"scenario tree\"). Internal nodes represent assumptions (with True/False branches), and leaves represent the final action to be taken under that scenario.\n\n- The **Evaluator** scores each root-to-leaf path (scenario) based on its estimated likelihood (L(S)), conditional gain (G(a)), and execution cost (C(a)) .\n\nThis allows the agent to make a rational, uncertainty-aware choice—including whether to communicate or take a physical action—by selecting the action from the scenario with the highest final utility score, U(S,a)=E[gain]−λC(a). Experiments on two multi-agent benchmarks (C-WAH and TDW-MAT) with three different LLM backbones show that PCE outperforms communication-centric baselines in success rate and efficiency. A user study also suggests that PCE's communication patterns are perceived by humans as more efficient and trustworthy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **Originality and Significance**: The paper's core contribution is novel and insightful. Instead of simply using an LLM's reasoning trace (like Chain-of-Thought), the PCE framework performs meta-reasoning on the trace itself. The idea of \"turning LLM reasoning into... planning\"  by extracting, structuring, and formally evaluating latent assumptions is a clever way to operationalize the implicit knowledge within LLMs for decision-making under uncertainty.\n\n- **Problem Formulation**: The work addresses a well-defined and critical problem. As LLM agents become more capable, their reliance on frequent communication becomes a bottleneck, especially when humans are in the loop. This paper offers a principled alternative to naive, communication-heavy strategies.\n\n- **Methodological Clarity**: The proposed PCE framework is modular, logical, and well-explained. The three-stage pipeline is intuitive, and the Evaluator's scoring function provides a principled mechanism for balancing scenario likelihood, potential gain, and the distinct costs of physical vs. communicative actions.\n\n- **Thorough Empirical Evaluation**: The experimental validation is a significant strength.\n\n  * __Generality__: The method is tested on three diverse LLM backbones (including commercial and open-source models) across two challenging benchmarks , consistently outperforming four representative baselines.\n\n  * __Ablation Studies__: The ablations are comprehensive. The component analysis (Table 3) successfully demonstrates that each part of the PCE pipeline is necessary for good performance .\n\n   * __Scaling Analysis__: The \"LLM Scaling\" study (Figure 3) provides compelling evidence that the performance gains are attributable to the PCE framework itself, not just to using a larger model. It shows that while scaling models (e.g., Gemma3 4B → 27B) improves a \"Planner only\" baseline, PCE reaps greater benefits, widening the performance gap .\n\n   * __User Study__: The inclusion of a user study  is commendable. It directly validates the paper's central hypothesis: that reducing communication intelligently leads to a human-agent collaboration that is not only more efficient but also perceived as more trustworthy and useful."}, "weaknesses": {"value": "- **Scalability of the \"Multi-Agent\" Claim**: The experiments are exclusively conducted in two-agent settings. While technically \"multi-agent,\" this does not sufficiently support the paper's broader claims of solving uncertainty in \"multi-agent... environments\". The complexity of tracking collaborator intentions and partial observations scales combinatorially with the number of agents. It is unclear how the Composer's decision tree and the Evaluator's scoring would handle branching on assumptions about n−1 other agents without becoming intractable.\n\n- **The Composer**: The entire framework's effectiveness hinges on the Composer module. This module is tasked with complex, non-trivial reasoning steps: (1) semantically identifying the most critical uncertainties from a free-text reasoning trace , (2) ranking them by abstract criteria like \"influence\" , and (3) proposing new atomic assumptions from scratch when needed. The paper states this is approximated using \"LLMs' commonsense reasoning\"  and provides a prompt (Figure 9), but this sweeps a massive amount of complexity under the rug. The paper offers no analysis of the Composer's reliability. If the Composer fails to extract the key assumption or hallucinates an irrelevant new one, the entire decision tree is built on a faulty foundation, and the Evaluator's \"principled\" scoring becomes meaningless. The ablation in Table 3 only shows that no Composer is bad, not that the current Composer is robust.\n\n\n- **Potentially Overstated Scaling Claims**: In the scaling ablation (Figure 3), the performance improvement (i.e., the slope of the line) for \"Planner only\" appears quite similar to that of \"PCE.\" For example, in Figure 3(b), both methods see a drop of ~9-10 steps when moving from \"Low\" to \"High\" reasoning. The paper's claim that PCE \"amplifies the benefits of scaling\"  seems slightly overstated; the data suggests the benefit of the PCE framework is largely additive—PCE starts at a better baseline, and that baseline advantage is maintained or slightly widened as the model scales.\n\n\n- **Missing Related Work**: The related work section  focuses primarily on communication-centric methods (like ProAgent, CoELA, etc.). However, it seems to overlook other recent lines of work on long-horizon LLM planning in partially observable environments that do not rely on heavy communication. For example, [1].\n\n[1] Nayak, Siddharth, et al. \"LLaMAR: Long-Horizon Planning for Multi-Agent Robots in Partially Observable Environments.\" arXiv preprint arXiv:2407.10031 (2024)."}, "questions": {"value": "- **On the Composer's Reliability (W2)**: The Composer's ability to correctly identify assumptions and generate new ones is critical. How robust is this process? What happens if the Planner's reasoning trace is vague or does not contain an obvious, extractable assumption? Is there any quantitative analysis of the Composer's \"hit rate\" for identifying the correct critical uncertainty?\n\n- **On Scalability (W1)**: Could you elaborate on how you expect the PCE framework, particularly the Composer's tree generation, to scale to n>2 agents? Would the tree depth D=3  be sufficient to model the compounded uncertainties from multiple collaborators?\n\n- **Clarification of Figure 2**: The visualization in Figure 2(c) is slightly confusing. It highlights a path corresponding to nodes 1(False) → 5(False) → 4 as the \"best scenario.\" To clarify: at the time of decision-making, the truth values of the assumptions are unknown. Does this highlighted path simply represent the leaf node (action [gocheck] cabinet) that received the highest utility score U from the Evaluator, and the path shown is the scenario (i.e., the set of assumptions) under which that action is optimal?\n\n- **Clarification of the Communication Mechanism**: The user study strongly supports that PCE's communication is more efficient. To confirm my understanding: is communication reduced simply because the [send_message] action is treated as just another potential leaf in the decision tree, which must then \"win\" the U(S,a) competition against all physical actions? This seems to be the implicit gating mechanism, and it's elegant, but I want to ensure I'm not missing a more explicit component. If that is the case, its best to explicitly mention it in the paper."}, "flag_for_ethics_review": {"value": ["Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MJvrjbXMeE", "forum": "GODFBZhFcX", "replyto": "GODFBZhFcX", "signatures": ["ICLR.cc/2026/Conference/Submission11587/Reviewer_FyaB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11587/Reviewer_FyaB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11587/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761663818378, "cdate": 1761663818378, "tmdate": 1762922670131, "mdate": 1762922670131, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes PCE (Planner–Composer–Evaluator) for embodied decision making. PCE is a modular framework that turns implicit assumptions inside an LLM’s reasoning trace into a structured decision-tree for uncertainty-aware planning in partially observable multi-agent environments. Experiments (including human evaluations) on C-WAH and TDW-MAT show that PCE consistently outperforms communication-centric baselines  across three LLMs. This work also provides ablation and user studies."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. It is interesting to introduce an uncertainty-handling mechanism to this field. PCE explicitly extracts and evaluates the LLM’s latent assumptions and plan with structured decision-tree.\n2. The experimental results show strong gains in success rate and step efficiency on two benchmarks, with comparable computational cost. It is also good to include human evaluations.\n3. The ablations on reasoning and different LLMs also show the consistency of performance gain."}, "weaknesses": {"value": "1. It is unclear how the hyperparameters were chosen. The authors set D = 3, alpha = 1, beta = 1, lambda = 1, Kaction = 10, Kmessage= 3 empirically, but no according further explaination or ablation is provided.  \n2. The related work section should discuss tree-search-based methods (e.g., CoTS) more clearly.  The authors need to clearly articulate how their method differs conceptually and why PCE is needed beyond existing tree reasoning or search frameworks.\n3. The paper would benefit from more case studies or qualitative analyses to illustrate how PCE behaves in different uncertainty scenarios and to provide deeper insight into its decision-making process."}, "questions": {"value": "See weaknesses, and\n\n1. Why is the Usage of PCE lower than CoELA? According to my understanding, PCE’s three modules all require LLM inference, which should make the total cost higher than CoELA, which only infers twice. Please clarify this discrepancy.  \n2. How about using MCTS based on distance as a comparison or baseline? It might provide a stronger reference for tree-based planning efficiency.\n\nI am willing to change my score if the concerns are addressed"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Dcjt0SpM6Q", "forum": "GODFBZhFcX", "replyto": "GODFBZhFcX", "signatures": ["ICLR.cc/2026/Conference/Submission11587/Reviewer_5pEK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11587/Reviewer_5pEK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11587/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959580063, "cdate": 1761959580063, "tmdate": 1762922669590, "mdate": 1762922669590, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}