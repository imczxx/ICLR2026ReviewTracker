{"id": "kTFz6YJlQ8", "number": 20524, "cdate": 1758307074336, "mdate": 1759896973552, "content": {"title": "Extracting Rule-based Descriptions of Attention Features in Transformers", "abstract": "Mechanistic interpretability strives to explain model behavior in terms of bottom-up primitives. The leading paradigm is to express hidden states as a sparse linear combination of basis vectors, called features. However, this only identifies which text sequences (exemplars) activate which features; the actual interpretation of features usually requires subjective and time-consuming inspection of these exemplars. This paper advocates for a different solution: rule-based descriptions that match token patterns in the input and correspondingly increase or decrease the likelihood of specific output tokens. Specifically, we extract rule-based descriptions of SAE features trained on the outputs of attention layers. While prior work treats the attention layers as an opaque box, we describe how it may naturally be expressed in terms of interactions between input and output features, of which we study three types: (1) skip-gram rules of the form \"[Canadian city] . . . speaks $\\rightarrow$ English\", (2) absence rules of the form \"[Montreal]... speaks $\\not\\rightarrow$ English,\" and (3) counting rules that toggle only when the count of a word exceeds a certain value or the count of another word. Absence and counting rules are not readily discovered by inspection of exemplars, where manual and automatic descriptions often identify misleading or incomplete explanations. We then describe a simple approach to extract these types of rules automatically from a transformer, and apply it to GPT-2 small. We find that a majority of features may be described well with around 100 skip-gram rules, though absence rules (2) are abundant even as early as the first layer (in over a fourth of features). We also isolate a few examples of counting rules (3). This paper lays the groundwork for future research into rule-based descriptions of features by defining them, showing how they may be extracted, and providing a preliminary taxonomy of some of the behaviors they represent.", "tldr": "", "keywords": ["transformers", "interpretability", "rule extraction"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8632605ddaf2e0d28f71b028b4536ef9445a8a0d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper provides a mechanistic interpretability technique for transformers that takes into account the attention mechanism by analyzing the ways in which feature vectors of a sparse autoencoder (SAE) interact within the attention mechanism to promote or discourage certain outputs. This allows a practitioner to identify three kinds of rule embedded in a transformer: (1) skip-gram rules that promote an output based on the presence of a skip bigram, (2) absence rules, which are like (1) but discourage an output, and (3) counting rules, which are like a competition between rules of the form (1) and (2). The authors provide two ways of ranking query-key interactions in order to prune low-ranking ones: a weight-based one and a gradient-based one. They test their method on GPT-2 small. They evaluate their automatically extracted skip-gram rules on the binary task of predicting whether a feature is active for a given prefix, achieving F1 scores of about 70-80%. They also identify skip-grams that have distractor features which make them act like absence rules."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper is generally well-written and does a good job of contextualizing itself with respect to prior work. Section 3.1 does a good job of presenting the main idea of the paper, which appears to be an original and significant extension of mechanistic interpretability to the attention mechanism. The authors test multiple ranking strategies for pruning."}, "weaknesses": {"value": "1. The method is limited in its expressivity; the types of rule extracted are quite simple, and it does not appear to be straightforward to extend it to take into account other parts of the transformer architecture besides the attention mechanism, such as the feedforward layers. However, this may not be a very serious issue, as mechanistic interpretability methods typically rely on these simplifications, and 3.1 does a good job of justifying the types of rules they study.\n1. I'm not sure how to interpret the significance of the results in Fig 3, because there is no baseline. Is 80% F1 good or bad?\n1. There don't seem to be any results on counting rules, despite their prominence in the exposition of the paper. This aspect of the paper is incomplete.\n1. GPT-2 is pretty old; it would be nice to see this method evaluated on more than one LLM, including a newer one.\n1. Although I found some parts of the paper, like 3.1, to be quite clear and helpful, other parts are hard to follow. In particular, I'm a bit lost as to exactly how the experiments and evaluation in Section 4 work. For the binary classification task, what are you using as the ground-truth labels?"}, "questions": {"value": "1. Eq (2): Why are the last two steps identical?\n1. Fig 5: There seems to be an off-by-one lag after \"If\" in the feature activations, and there's something strange going on with \"Both.\" What's going on there?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "79YVs9K4EG", "forum": "kTFz6YJlQ8", "replyto": "kTFz6YJlQ8", "signatures": ["ICLR.cc/2026/Conference/Submission20524/Reviewer_ytiW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20524/Reviewer_ytiW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20524/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761688487455, "cdate": 1761688487455, "tmdate": 1762933945224, "mdate": 1762933945224, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method to interpret attention-layer Sparse Autoencoder (SAE) features by extracting symbolic, human-readable rules. The paper focus on skip-grams, absence rules, and counting rules. This approach differs from current methods to interpret SAEs, which are mainly focused on observing the activation of a SAE feature in tokens of the training corpus and using autointerp methods to give meaning to them. The paper introduces $\\mathcal{S}(j)$ to quantify interactions between input-output features (OV circuit) and $\\mathcal{A}(j, k)$ to quantify the interaction between a pair $(j, k)$ of input features (QK circuit). Applying this method to GPT-2 small, the authors show that simple skip-gram rules can approximate many features with reasonable fidelity and that absence rules are common"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper proposes a new method to interpret SAEs features. It differs from previous work especially in the treatment of the QK features, trying to analyze feature interactions that contributes to the attention pattern formation.\n- The method is capable of finding interesting set of features that it may be hard to do with autointerp."}, "weaknesses": {"value": "1. Some of the claims relies on weak evidence:\n    - The evidence for counting rules is a single qualitative example (Figure 7).\n    - In the absence rules analysis, the counterfactual validation (Fig 6c) is limited to only the first attention layer.\n2. The entire evaluation is limited to one model, GPT-2 small. It is not clear if this methodology will apply to larger models.\n3. The method for ranking rules relies on heuristics, like picking the \"top 100\" features to reduce the search space. These choices are not well-justified, and it is not guaranteed that they are generalizable to other models.\n4. The F1-score evaluation is hard to interpret. It's run on a simplified dataset (top 100 activations vs. 100 zero-activations). The paper itself notes in the appendix that this setup favors recall, so it's hard to tell if an F1-score of ~0.75 is actually good."}, "questions": {"value": "1. Can you provide quantitative evidence (e.g., F1 scores, prevalence) for counting rules?\n2. Why was the validation for absence rules limited to Layer 1? Is this experiment intractable on higher layers?\n3. For the gradient-based ranking, did you consider using more robust attribution methods like Integrated Gradients (IG) instead of simple gradients?\n4. I found the notation is a bit confusing.\n    - In Section 3.1, the sum with $i \\leq t$ and $j=1$ to $n$ is confusing. Using a double sum would make it easier to read (one sum is related to the tokens, while another one is related to the $n$ SAE features), or using $1 \\leq j \\leq n$ instead of $j=1$, removing the $n$ from the top of the summation.\n    - In Section 3.2, in the “Ranking query-key rules” paragraph, it is said that you first pick the 100 key features $j$ with highest value of $\\mathcal{S}(j)$, then for each of these key features $j$, you pick the 100 query features maximizing $\\mathcal{A}(j, k)$. In my understanding, for $\\mathcal{A}(j, k)$, $j$ is a query feature, while $k$ is a key feature. Shouldn’t be the case that you pick the 100 query features maxizing  $\\mathcal{A}(k, j)$ instead?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bmsUNlWyr1", "forum": "kTFz6YJlQ8", "replyto": "kTFz6YJlQ8", "signatures": ["ICLR.cc/2026/Conference/Submission20524/Reviewer_DttW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20524/Reviewer_DttW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20524/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761873542387, "cdate": 1761873542387, "tmdate": 1762933944411, "mdate": 1762933944411, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper describes an approach to find symbolic templates (aka rules) which activate specific patterns in the attention heads of transformer based language model. The idea builds on the sparse-autoencoder features, and uses them to identify three types of rules: n-grams, absence rules and counting rules in the GPT-2 model. The rules found are illustrated with examples, as well as evaluated quantitatively."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The paper falls within the mechanistic interpretability tradition and builds on the work of Kissane et al 2024 with sparse autoencoders. The suggested method for finding rules goes beyond manual exemplar inspection and is thus able to find rules which are hard to identify manually\n- While the details of the methodology are somewhat obscure in places the general approach seems reasonable and sound.\n- The results may be of some interest given the amount of attention to mechanistic interpretability."}, "weaknesses": {"value": "- The main contribution is the procedure for finding rules: while it's an improvement over manual examplar examination, it is still based on quite strong priors and hard-coded search patterns and assumptions.\n- The advertised symbolic and interpretable nature of the found rules only really applies to the bottom transformer layer where inputs can be directly linked to input tokens. In layers above, the interpretation of the features and rules becomes increasingly murky.\n- The presentation relies heavily on detailed familiarity with previous work and is thus very hard to follow as a self-contained paper. \n- The focus is exclusively on single attention heads, while transformers have many other components which impact the computations. Thus the scope is very narrow."}, "questions": {"value": "- How are feature activations and direct feature attributions related, and why are you presenting both in your results?\n- How should I think about interpreting these rules in layers > 1 of the transformer, where inputs are no longer tokens?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "IU239JZkg2", "forum": "kTFz6YJlQ8", "replyto": "kTFz6YJlQ8", "signatures": ["ICLR.cc/2026/Conference/Submission20524/Reviewer_7pMq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20524/Reviewer_7pMq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20524/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761929681871, "cdate": 1761929681871, "tmdate": 1762933943819, "mdate": 1762933943819, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies attention-head interpretability at the level of SAE features. To this end. the authors train sparse autoencoders on attention head outputs of GPT-2 small (using an existing setup on open web text (OWT) and then aim to identify attention-output features by extracting rule-like patterns from attention’s query–key (QK) and value (OV). To this end they 1) collect a feature-specific dataset from 50k OWT sequences (positives = top activations of g, negatives = non-activations) for each attention-output feature they identified, and 2) rank candidate (query-feature, key-feature) pairs either by a weight score (\\text{QK}\\times \\text{OV}) or by a gradient mask score. From the top pairs they induce three rule types:\nstudy three types: \n\t(1) skip-gram rules of the form “[Canadian city] . . . speaks → English”,\n\t(2) absence rules of the form “[Montreal] . . . speaks ̸→ English,” and \n\t(3) counting rules that toggle only when the count of a word exceeds a certain value or the count of another word.\nThey use GPT-2 small and show that many early-layer features can be approximated by less than 100 rules, that distractor rules are common, and that count-sensitive rules already show up in low layers."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper looks at feature level for behaviors, such as skip-gram patterns, that are frequently studied in circuit analysis, providing an interesting view from the SAE lens, making the analysis better scalable.\n- It identifies the discovered rules on a broad set of sequences, indicating robustness of these features. \n- It focuses on a clearly defined set of rules that can be sensibly studied."}, "weaknesses": {"value": "- The evaluation, while on a broad set of samples is qualitatively limited to binary activations; \n- The paper does not compare to traditional circuit analysis approaches, which could analyse the same patterns, showing how much they overlap.\n- Similarly, there are no ablations on other methods beyond SAEs\n- While the paper evaluates how often the patterns are present in the collected data, it would be interesting to see how they are present in real-world tasks. \n- The approach uses a single, small model and the open web text corpus, so generalizability on to larger/different models and also corpora is limited here."}, "questions": {"value": "How would the rule extracting method perform on circuit heads (such as induction, name-mover, IOI-style)?\nHow sensitive are your results to model size and data selection to train the SAE?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xTRQEZBWcn", "forum": "kTFz6YJlQ8", "replyto": "kTFz6YJlQ8", "signatures": ["ICLR.cc/2026/Conference/Submission20524/Reviewer_hiA6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20524/Reviewer_hiA6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20524/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994937664, "cdate": 1761994937664, "tmdate": 1762933943331, "mdate": 1762933943331, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}