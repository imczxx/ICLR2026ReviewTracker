{"id": "c8CZWLy4T4", "number": 8358, "cdate": 1758079825217, "mdate": 1759897789727, "content": {"title": "Beyond RAG vs. Long-Context: Learning Distraction-Aware Retrieval for Efficient Knowledge Grounding", "abstract": "Retrieval-Augmented Generation (RAG) is a framework for grounding Large Language Models (LLMs) in external, up-to-date information. However, recent advancements in context window size allow LLMs to process inputs of up to 128K tokens or more, offering an alternative strategy: supplying the full document context directly to the model, rather than relying on RAG to retrieve a subset of contexts. Nevertheless, this emerging alternative strategy has notable limitations: (i) it is token-inefficient to handle large and potentially redundant contexts; (ii) it exacerbates the “lost in the middle” phenomenon; and (iii) under limited model capacity, it amplifies distraction, ultimately degrading LLM output quality. In this paper, we propose LDAR (Learning Distraction-Aware Retrieval), an adaptive retriever that learns to retrieve contexts in a way that mitigates interference from distracting passages, thereby achieving significantly higher performance with reduced token usage compared to long-context approaches. Extensive experiments across diverse LLM architectures and six knowledge-intensive benchmarks demonstrate the effectiveness and robustness of our approach, highlighting the importance of balancing the trade-off between information coverage and distraction.", "tldr": "We propose a learning-based retrieval strategy framework that adaptively balances information coverage and distraction in accordance with the capacity of the LLM.", "keywords": ["Retrieval-Augmented Generation", "Language Models", "Long-Context"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ac65855c567848c67053a4686b0c3d6df1a4f694.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper address the distracting issue caused by RAG. They propose a method called LDAR which learns a lightweight retriever that learns to select passages to minimize potential interference from distracting passage. Their retriver operates on the cosine similarity distribution and selects a dynamic set of passages from a contiguous quantile interval to balance coverage and distraction. For example, if the risk of having distraction is higher, retrieves passages from a narrow quantile interval, minimizing the risk of having distraction. The retriever is trained with the reward signal of whether the downstream LLM gives a correct answer using the retrieved passages. Their expeirments on various benchmarks show significantly better results than the baseline methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The motivation of this paper is solid, learning to balance coverage and distraction for RAG is an important question.\n2. The proposed method is lightweight by only finetuning a retriever model.\n3. The experimental setups are comprehensive, the zero-shot experiment is persuasive and the performance is good."}, "weaknesses": {"value": "1. An analysis of the proposed method is needed. For example, it would be interesting to compare with a baseline that learns to rerank the retrieved passages alone with the same optimization objective.\n2. The interpretability of the addressed distaction issue is limited. It would be interesting to see how the proposed retriever balance coverage and distraction, some case studies would be helpful."}, "questions": {"value": "1. what is the passages ratios compared with the initial top-N because LDAR quantile cutting step.\n2. For more capable or larger LLMs, is the quantile cutting still useful compare with using long-context."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "w3IxamLgCU", "forum": "c8CZWLy4T4", "replyto": "c8CZWLy4T4", "signatures": ["ICLR.cc/2026/Conference/Submission8358/Reviewer_VnKc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8358/Reviewer_VnKc"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8358/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761673116974, "cdate": 1761673116974, "tmdate": 1762920273008, "mdate": 1762920273008, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents LDAR(Learning Distraction-Aware Retrieval), a method for adaptive retrieval that compellingly addresses the performance-cost tradeoff between RAG and full long-context. The core contribution which involves identifying the problem of LLMs getting incorrect results given both gold passage and distraction passage, and a lightweight, band-based retriever that is sound and justified well againts the \"distraction problem\"(Figure 3 , Section 4.1). The experimental evaluation is thorough, demonstrating LDAR's effectiveness and adaptability across a wide range of modern LLMs and challenging tasks. However, the method's design, which feeds raw similarity scores to a Transformer , raises significant concerns about overfitting to task-specific patterns, a limitation the authors themselves acknowledge. This casts doubt on the true generalizability claimed in the zero-shot experiments (see Section 5.5 ). Other key weaknesses include lack of ablation studies and justification for key architectural choices the complete omission of the method's training cost."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "## Originality\nThe paper's primary originality lies in its precise and insightful problem formulation. It moves beyond the simplistic \"RAG vs. Long-Context\" debate to investigate why RAG systems fail. The core insight, clearly demonstrated in Section 3 and Figure 2, is that performance degradation is not just from irrelevant passages but that even a set of exclusively gold passages can collectively confuse an LLM and lead to incorrect answers. Identifying this \"distraction\" effect, even among relevant documents, is a novel and important contribution.\n\nThe proposed solution, LDAR, is also original. Instead of relying on complex textual rerankers or fine-tuning the LLM, it introduces a lightweight, \"score-only\" adaptive retriever. The \"band-based\" retrieval strategy (Section 4.1) is a creative mechanism to make the reinforcement learning problem tractable, cleverly reducing the search space from a complex combinatorial problem (as in Bernoulli sampling) to a low-dimensional, continuous one.\n\n## Quality\nThe empirical quality of this work is a major strength. The authors validate LDAR with a thorough and rigorous experimental setup (Section 5).\n\n1. Comprehensive Benchmarking: The method is tested across a diverse and modern set of both open-source (Llama-3.1, Qwen-2.5, Mistral-Nemo) and closed-source (GPT-4o, Gemini-2.5) models, demonstrating broad applicability.\n\n2. Challenging Tasks: The evaluation spans six knowledge-intensive benchmarks, including the difficult LaRA tasks (Location, Reasoning, Comparison) and HELMET's long-context adaptations of HotpotQA and NQ.\n\n3. Strong Results: The results in Table 1 are compelling. LDAR consistently achieves a superior performance-to-cost ratio, significantly outperforming the full long-context (LC) baseline in overall accuracy while using substantially fewer tokens (often achieving ~2x token efficiency).\n\n4. Well-Justified Method: The core design choice of \"band-based\" retrieval is well-justified empirically by the comparison in Figure 3, which clearly shows it finds a more stable and effective trade-off than the Bernoulli-based alternative.\n\n## Clarity\nThe paper is exceptionally well-written, organized, and easy to follow, earning a top score for presentation. The authors use visualizations effectively to build a clear and logical narrative.\n\n## Significance\nThis paper addresses a highly significant and practical problem for the LLM community. As context windows expand to 1M tokens, the question of how to best utilize this vast context for optimal cost-performance is of paramount importance. This work provides a practical and effective solution that moves \"beyond\" the binary choice of RAG vs. full context."}, "weaknesses": {"value": "## Serious Concerns Regarding Generalization and Overfitting\n- The model's score-only policy may overfit similarity-shape statistics of a corpus. LDAR uses only the cosine-similarity distribution (no text), and explicitly restricts access to textual content for scalability. While elegant, this design risks learning corpus-specific distributional quirks rather than semantic robustness, limiting the proposed method's contribution.\n\n- Zero-shot section (Sec. 5.5) lacks mechanism analysis. Authors transfer LaRA-trained policies to HELMET (HotpotQA/NQ) and report modest gains, but do not explain why a Comparison-trained policy improves HotpotQA or why a Location-trained policy improves NQ. Given that different tasks have vastly different retrieval needs, this positive result may be a coincidence.\n\n- The \"score-only\" architecture is also vulnerable to overfitting to the statistical properties of the passage database (e.g., LaRA's mix of novels and finance reports). The paper provides no evidence that a policy learned on this database distribution would generalize to a database with a different profile (e.g., social media, legal documents). The test on HELMET's Wikipedia database (Section 5.5) is not a sufficient stress test and lacks a deep analysis of the distribution shift.\n\n## Missing Ablation Studies for Key Architectural Choices\n- The paper employs a Transformer Encoder to process the sequence of similarity scores. This is a non-trivial architectural choice, implying that the relationships between scores are important. However, this is not justified with a baseline, such as a simpler Multi-Layer Perceptron (MLP), to prove this complexity is necessary.\n- The model uses \"Periodic Embedding\" to encode the raw scalar similarity scores. This is a specific and non-obvious design choice. The paper provides no justification or ablation study comparing this to simpler, standard alternatives (such as learnable embedding with truncation of sorted scores).\n\n## Omission of Training Cost and Practicality\n- The paper's central claim is improved inference efficiency (i.e., lower token usage). However, it provides no information whatsoever about the training cost. The RL training loop, as formulated in Eq. (3), requires a forward pass of the (potentially massive) pretrained LLM $F_{\\psi}$ to obtain the reward signal $r_{\\psi}$ for every gradient step. This suggests the training process may be prohibitively expensive.\n- The paper provides no data on the number of LLM calls required for convergence or the total wall-clock training time. This omission makes it impossible to assess the method's practical viability or cost-benefit trade-off."}, "questions": {"value": "Please list up and carefuly describe any questins and suggestions for the authors.Think ofthe things where a response from the author can change youropinion, clarify a confusion or address a limitation. This is important for a productive rebuttal and discussion phase with the authors.\n\n- Can you extend Sec. 5.5 with broader zero-shot tests? Add more tasks (train/test task cross-matrix) and more corpus database.\n- Have you done any ablation on the necessity of choosing transformers as the backbone of the retriever?\n- Could you provide a clear training cost-benifit analysis?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zt7b9e7ga6", "forum": "c8CZWLy4T4", "replyto": "c8CZWLy4T4", "signatures": ["ICLR.cc/2026/Conference/Submission8358/Reviewer_brC4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8358/Reviewer_brC4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8358/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761803799913, "cdate": 1761803799913, "tmdate": 1762920272513, "mdate": 1762920272513, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper Beyond RAG vs. Long-Context: Learning Distraction-Aware Retrieval for Grounding LLMs studies the trade-off between retrieval-augmented generation (RAG), which may miss relevant information, and long-context models, which can include too much irrelevant content. It introduces LDAR (Learning Distraction-Aware Retrieval), a lightweight retrieval method that adaptively selects a contiguous range of passages from the ranked candidates based only on their similarity scores, achieving a balance between information coverage and distraction. LDAR uses a small transformer trained with policy gradients to predict how wide the retrieval range should be for each query, optimizing task performance according to the LLM’s context capacity. Experiments on multiple benchmarks and models show that LDAR achieves higher accuracy than both RAG and long-context approaches while using fewer tokens. The main contributions are a learning-based distraction-aware retrieval framework, the banded retrieval design that improves stability and generalization, and extensive validation demonstrating efficient grounding for LLMs."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1) The paper proposes a dynamic interval (band) method to select high-quality context from a passage sequence sorted by cosine similarity.\n\n2) The motivation section analyzes in depth how different retrieval strategies, when applied over a cosine-sorted list, affect answer correctness, and it systematically frames the problem of adaptively balancing recall versus distraction.\n\n3) The evaluation covers a reasonably broad set of settings on four LaRA tasks (location/reasoning/comparison/hallucination) and the long-context variants of HotpotQA/NQ from HELMET."}, "weaknesses": {"value": "1) The analysis experiments for the method itself are not sufficient (see Questions).\n\n2) The method appears sensitive to LLM size, which affects cross-model generalization and thus reduces transferability and robustness across heterogeneous systems.\n\n3) There is a lack of concrete case studies: results are mainly aggregate metrics and curves, without step-by-step comparisons on representative examples."}, "questions": {"value": "1) Do different retrievers induce different cosine-similarity distributions, and would this shift the behavior/performance of the adaptive retriever?\n\n2) Using only accuracy as the reward seems limited. Since the token usage ratio is also reported, can the optimization include a cost term (e.g., inference/compute budget)?\n\n3) In the visualization of retrieval intervals (Fig. 6), most learned bands overlap with the top-k region. For bands outside the top-k, can you provide concrete examples to intuitively explain why passages outside the top interval are selected/beneficial (or why the top interval is insufficient)?\n\n4) Is selecting a continuous interval (band) inherently reasonable? Does it implicitly assume that high-quality passages are locally clustered in the cosine-sorted order? If possible, please add a fixed-length sliding-window experiment: slide a window of length (w) over the cosine-sorted sequence, evaluate accuracy for each window as the retrieved set, examine whether stable peak regions exist, and compare their alignment with the LDAR-learned band."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5nCT1ebQci", "forum": "c8CZWLy4T4", "replyto": "c8CZWLy4T4", "signatures": ["ICLR.cc/2026/Conference/Submission8358/Reviewer_771K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8358/Reviewer_771K"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8358/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966954696, "cdate": 1761966954696, "tmdate": 1762920272022, "mdate": 1762920272022, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work investigates the noisy information in the context of RAG, and introduces LDAR (learning distraction-aware retrieval) that learns to select passages to minimize interference from distracting passages. The training framework invites the target LLM in-loop to refine the retrieval model. The approach shows effective on the LaRA benchmark compared with several baseline settings on Llama 3.1 8B, Llama 3.2 3B, Qwen 2.5 7B, Qwen 3 4B, Mistral-Nemo-12B, GPT-4o, GPT-4o-mini, Gemini-2.5-pro, and Gemini-2.5-flash. Some interesting findings are shown, including the more capable models (e.g., GPT-4o and Gemini 2.5) perform well on the long-context setting."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* This work is well-motivated and easy to follow.\n\n* The proposed method can improve the performances for a range of LLMs. \n\n* The proposed method, which does not require the internal information such as attention values of the target LLM, is model-agnostic and can be applied with any LLMs including the closed ones such as GPT and Gemini."}, "weaknesses": {"value": "* This work should be compared with other reranking methods, which are important related work to address. However, in the current manuscript, none of the reranking methods such as RankRAG is mentioned and compared. \n\n* The experimental setting of the baseline methods is not comprehensive. The number of passages in RAG, LC, BMG, and Adaptive-k are not clear. Number of passages greatly impact the end performance. Without an analysis on the passage size, the contribution of the proposed method is hard to clarify. \n\n* The proposed method adds computation cost during inference. An analysis of the runtime could be added."}, "questions": {"value": "* What is the basic retrieval model (Top-k) in the experiments? \n\n* What is the exact long-context setting in the experiments? The entire dataset or top-k with a very large k?\n\n* From Table 2, LC looks powerful when the LLMs are capable. LC can be speed up with prompt cache (Cache-Augmented Generation). Could you compare the method with CAG in terms of accuracy and efficiency?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "QU7GvrcYqU", "forum": "c8CZWLy4T4", "replyto": "c8CZWLy4T4", "signatures": ["ICLR.cc/2026/Conference/Submission8358/Reviewer_8eo8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8358/Reviewer_8eo8"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8358/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761967835942, "cdate": 1761967835942, "tmdate": 1762920271676, "mdate": 1762920271676, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}