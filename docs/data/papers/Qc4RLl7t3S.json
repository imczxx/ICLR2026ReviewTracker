{"id": "Qc4RLl7t3S", "number": 20794, "cdate": 1758310315118, "mdate": 1759896958387, "content": {"title": "On the Mechanism and Dynamics of Modular Addition: Fourier Features, Lottery Ticket, and Grokking", "abstract": "We present a comprehensive analysis of how two-layer neural networks learn features to solve the modular addition task.\nOur work provides a full mechanistic interpretation of the learned model and a theoretical explanation of its training dynamics.\nFirst, we empirically show that trained networks learn a sparse Fourier representation; each neuron's parameters form a trigonometric pattern corresponding to a single frequency.\nWe identify two key structural properties: phase alignment, where a neuron's output phase is twice its input phase, and model symmetry, where phases are uniformly distributed among neurons sharing the same frequency, particularly when overparametrized.\nWe prove that these properties allow the network to collectively approximate an indicator function on the correct logic for the modular addition task.\nWhile individual neurons produce noisy signals, the phase symmetry enables a majority-voting scheme that cancels out noise, allowing the network to robustly identify the correct sum.\nWe then explain how these features are learned through a \"lottery ticket mechanism\".\nAn analysis of the gradient flow reveals that frequencies compete within each neuron during training.\nThe winning frequency that ultimately dominates is predictably determined by its initial magnitude and phase misalignment.\nFinally, we use these insights to demystify grokking, characterizing it as a three-stage process involving memorization followed by two generalization phases driven by feature sparsification.", "tldr": "We demystify the feature learning and training dynamics of the gradient-based training on modular addition task.", "keywords": ["mechanistic interpretation", "training dynamics", "modular addition", "feature learning"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/163eeff9adb23ef40004cf70db53b4331b5266f7.pdf", "supplementary_material": ""}, "replies": [{"content": {"title": {"value": "Reviews unavailable"}, "comment": {"value": "Dear Area Chair,\n\nMany thanks for your efforts in coordinating the review process. We’re writing to check on the availability of the reviews for Submission 20794. They don’t appear in the system yet on our side.\nCould you advise on the expected timeline or any steps we should take?\n\nAuthors of Submission 20794"}}, "id": "xP93YTgluV", "forum": "Qc4RLl7t3S", "replyto": "Qc4RLl7t3S", "signatures": ["ICLR.cc/2026/Conference/Submission20794/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20794/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20794/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762959293702, "cdate": 1762959293702, "tmdate": 1762978026300, "mdate": 1762978026300, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper provides a comprehensive mechanistic and theoretical explanation of how two-layer neural networks learn to perform modular addition and how this process explains grokking.  \nUsing both empirical analysis and formal dynamical proofs, the authors show that during training, each neuron converges to a single-frequency Fourier feature of the form\n\n$$\n\\theta_m[j] = \\alpha_m \\cos(\\omega_{\\phi(m)} j + \\phi_m), \\quad\n\\xi_m[j] = \\beta_m \\cos(\\omega_{\\phi(m)} j + \\psi_m),\n$$\n\nwhere the output phase satisfies a phase-alignment relation\n\n$$\n\\psi_m \\approx 2\\phi_m.\n$$\n\nAcross neurons, phases become uniformly distributed within each frequency group, forming a phase-symmetric ensemble.  \nThe network’s collective behavior can then be interpreted as a majority-voting Fourier circuit that robustly implements the indicator function\n\n$$\n1[(x+y)\\bmod p = j].\n$$\n\nOn the dynamics side, the authors identify a “lottery ticket” mechanism in Fourier space:  \ndifferent frequencies compete within each neuron, and the one with the largest initial magnitude and smallest phase misalignment wins.  \nThis explains the emergence of single-frequency neurons and provides a predictive theory of feature selection.  \n\nFinally, the paper analyzes grokking as a three-stage process:\n1. Memorization phase dominated by loss minimization  \n2. First generalization phase where weight decay sparsifies frequencies and sharpens alignment  \n3. Second generalization phase where weight decay refines the clean Fourier solution  \n\nTogether, these results offer a unified, end-to-end account of how gradient descent discovers structured Fourier representations and transitions from memorization to generalization."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- Comprehensive mechanistic theory.  \n  This is the most complete explanation so far of modular-addition learning and grokking in shallow networks, connecting empirical phenomena (phase alignment, sparsification) to provable training dynamics.\n\n- Elegant empirical–theoretical correspondence.  \n  Observations 1–6 are each mirrored by formal results (Proposition 4.2, Theorem 5.2, 5.3). The analytical use of quadratic activations is a well-justified simplification that retains the core dynamics observed with ReLU.\n\n- Novel “Fourier lottery ticket” insight.  \n  The finding that feature emergence is governed by initial magnitude and phase misalignment provides a simple, predictive explanation of why single-frequency neurons reliably appear.\n\n- Interpretability of grokking.  \n  The proposed three-stage timeline, validated with metrics like phase alignment and frequency sparsity, makes grokking a measurable and interpretable process.\n\n- Clarity and rigor.  \n  The exposition is unusually clear for such a technical topic, combining intuitive figures with formal statements."}, "weaknesses": {"value": "- Restricted architectural scope.  \n  All analyses use two-layer MLPs with one-hot or learned embeddings; while ideal for interpretability, it remains unclear whether the same Fourier-alignment and frequency-competition mechanisms appear in deeper or attention-based models.\n\n- Empirical validation of the voting mechanism.  \n  Proposition 4.2 predicts that uniform phase diversity cancels noise via majority voting; an ablation that breaks phase uniformity could directly confirm this mechanism.\n\n- Connection to pretrained LLMs not explored.  \n  The paper convincingly explains why Fourier features emerge in modular tasks, but stops short of relating this to real LLMs—where similar sinusoidal and Fourier-like number encodings have already been observed."}, "questions": {"value": "1. Connection to Fourier features in large models.  \n   Recent work (arXiv:2502.09741) shows that when numbers are initialized with Fourier features, large pretrained LLMs can learn addition almost instantly, and that existing LLM embeddings already exhibit Fourier structure.  \n   Can the authors interpret this observation through their phase-alignment dynamics—i.e., are Transformers implicitly performing the same “frequency lottery” at scale?\n\n2. Scaling of grokking time.  \n   Theoretical results (Theorem 5.3) relate convergence time to initialization scale \n   $\n   \\kappa_{\\text{init}}\n   $\n   and modulus \n   $\n   p.\n   $\n   Can this be turned into a quantitative scaling law predicting grokking delay?  \n   Moreover, can this framework explain the observation from arXiv:2502.09741 that when the magnitude is large for some Fourier component, the model skips the grokking phase and learns addition with less data?\n\n3. Quantifying required neurons.  \n   Can the authors estimate the minimum number of neurons \n   $\n   M\n   $\n   required to achieve \n   $\n   100\\\\%\n   $\n   test accuracy as a function of \n   $\n   p?\n   $\n  \n\n4. Beyond addition.  \n   Would similar Fourier competition and alignment appear in modular multiplication or other? Extending analysis to those tasks could generalize the theory beyond addition."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lrA69h7Bb2", "forum": "Qc4RLl7t3S", "replyto": "Qc4RLl7t3S", "signatures": ["ICLR.cc/2026/Conference/Submission20794/Reviewer_W5pE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20794/Reviewer_W5pE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20794/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761614030921, "cdate": 1761614030921, "tmdate": 1762999995487, "mdate": 1762999995487, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper analyses the phenomenon of delayed generalisation (grokking) on the modulo arithmetic task mod(a+b)23. The work corroborates other findings that, during the grokking process, the two-layer MLP learns Fourier transforms to complete the solution. The paper suggests that grokking occurs in three distinct phases: Memorisation, where the model learns 'common data', then Generalisation Phase 1, where the model begins to minimise loss on 'rare examples' and then finally Generalisation Phase 2, where increased generalisation is governed only by the weight decay term.  Through theoretical and empirical analysis, the authors argue that it is possible to predict the final frequency domain of neurons based on their initial parameterisation via an analysis of Fourier components aligning with their observation of the Lottery Ticket Mechanism. The authors also provide a mechanistic insight into the trained model and identify a majority voting mechanism that cancels out noise and facilitates generalisation. Finally, there is an analysis of how gradient-based training facilitates the representation of features from a training dynamics perspective."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper adds interesting observations about the grokking phenomena in the context of the mod(a+b)23 task, which provide a nice insight into grokking on this dataset.  \n2. The combination of extensive theoretical results and supporting empirical results strengthens the paper's findings; however, some of the observations provided by the paper are corroborations of previous findings rather than novel insights (see weaknesses below). \n3. The notion of the majority voting scheme is an interesting insight; it would be nice to see if, in other grokking tasks, such a dynamic is used to improve generalisation. \n4. Predicting the final frequency of a neuron from its initialisation via magnitude and phase misalignment is a neat finding; it would be good to see these findings extended to other modulo arithmetic tasks to demonstrate their generality."}, "weaknesses": {"value": "1. **Lottery Ticket Mechanism**:  In the paper, observation 6 is positioned as a novel observation; however, prior work, namely [1], [2] explicitly mentions the role of internal structure at initialisation, via the Lottery Ticket Hypothesis (LTH) [3], being a primary factor in grokking. Furthermore, [2] even goes on to show that particular 'grokking tickets' reduce the time for generalisation to occur. I think that the 'Lottery Ticket Mechanism' you observe should be positioned as corroborating other findings in the literature, rather than being a novel insight of this paper's analysis. \n\n2. **Fourier Features** Could the authors describe why/if they believe this perspective to be novel? Given that previous literature describing the dynamics of grokking via mechanistic interpretability [1] has shown that neural networks leverage discrete Fourier transforms and trigonometric identities to perform the addition necessary in modular arithmetic tasks. \n\n3. **Narrowness of analysis on mod(a+b) 23 Task**: The grokking task that is analysed in this paper is somewhat non-standard compared to other grokking studies [1] [2], for example, the original paper [4]  that introduces grokking conducts experiments on the mod(a+b)97 task. Is there a rationale behind examining mod(a+b)23? In the mod(a+b)23 case, as shown by Figure 3, there is a slight delay in generalisation; however, this is not as extreme as in the mod(a+b)97 case. Can you show that part of your analysis holds in other modular arithmetic tasks, or are these findings limited to this particular dataset?\n\n4. **Importance of Weight Decay in Grokking**: The three phases of grokking suggested in this paper (Memorisation, Generalisation 1 and Generalisation 2) place a large weighting on the weight decay term in enabling generalisation. While [5] does support this narrative, more recent literature [6] has shown that weight decay is not a causal factor in generalising on algorithmic tasks, as they can mitigate or induce grokking entirely without modifying weight decay.  Additionally, [7] has also shown that grokking can be mitigated and that this mitigation is not solely reliant on the weight decay factor.  In light of these existing results, do you feel that you phases of grokking adequately describe the dynamics of grokking, or that they rely on factors that may correlate with generalisation, but are not causal factors for it?\n\n5. **Common vs Rare Training Examples**: The statements regarding common vs rare training examples resemble conjecture; the idea of common examples where 'symmetric pairs' are memorised is not fully quantified in the paper, nor are 'rare' examples properly explained. To empirically justify statements about 'common' and 'rare' training examples, the authors should conduct an ablation study where the model is trained only on so-called 'rare' examples. This should, under the arguments in the paper, eliminate the memorisation phase and reduce the time to generalise on the test data.\n\n6. **Even-order polynomials and Activation Swapping**: In Appendix Table 1, the activation swapping is shown replacing the RelU function with polynomials, preserving accuracy when the exponent is even and losing accuracy when the exponent is odd. However, there is no even representation of even and odd exponents in this table. Can you add the results for the exponents 5, 7 and 9 to represent odd exponents fully? \n\n7. **Prediction of final frequency**: The paper makes the bold statement that a neuron's final frequency can be predicted entirely from its initial magnitude and frequency alignment. Can the authors please provide an empirical analysis of how many neuron frequencies at the end of training are correctly predicted from this evaluation? \n\n8x. **Lack of clear takeaways**: The paper offers many observations of grokking dynamics; however, it is unclear what the general takeaways of the work should be, given that some of the observations are not entirely novel. The authors should explicitly highlight how their work provides new understandings of grokking that can generalise outside of their specific experimental setup. The paper would benefit from focusing less on the quantity of observations and instead on the clarity of insights. Could the authors please provide a conclusion section to this effect? \n\nReferences:\n[1] Nanda, N., Chan, L., Lieberum, T., Smith, J. and Steinhardt, J., 2023. Progress measures for grokking via mechanistic interpretability. arXiv preprint arXiv:2301.05217.\n\n[2] Furuta, H., Minegishi, G., Iwasawa, Y. and Matsuo, Y., 2024. Towards empirical interpretation of internal circuits and properties in grokked transformers on modular polynomials. Transactions on Machine Learning Research.https://openreview.net/forum?id=MzSf70uXJO.  \n\n[3] Frankle, J. and Carbin, M., 2018. The lottery ticket hypothesis: Finding sparse, trainable neural networks. arXiv preprint arXiv:1803.03635.\n\n[4] Power, A., Burda, Y., Edwards, H., Babuschkin, I. and Misra, V., 2022. Grokking: Generalisation beyond overfitting on small algorithmic datasets. arXiv preprint arXiv:2201.02177.\n\n[5] Liu, Z., Michaud, E.J. and Tegmark, M., 2022. Omnigrok: Grokking beyond algorithmic data. arXiv preprint arXiv:2210.01117.\n\n[6] Kumar, T., Bordelon, B., Gershman, S.J. and Pehlevan, C., 2023, September. Grokking as the transition from lazy to rich training dynamics. In The twelfth international conference on learning representations.\n\n[7] Mason-Williams, G. and Mason-Williams, I., Decomposed Learning: An Avenue for Mitigating Grokking. In ICML 2025 Workshop on Methods and Opportunities at Small Scale."}, "questions": {"value": "See weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fAicXJcOCy", "forum": "Qc4RLl7t3S", "replyto": "Qc4RLl7t3S", "signatures": ["ICLR.cc/2026/Conference/Submission20794/Reviewer_vTtu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20794/Reviewer_vTtu"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20794/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761821293596, "cdate": 1761821293596, "tmdate": 1762999995492, "mdate": 1762999995492, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper explores a one-hot encoded modular addition task $(a+b) mod 23$ with a 2-layer fully connected neural network with a hidden size of 512. With this network, they explore 3 questions, encompassing mechanistic interpretability, training dynamics, and grokking. They explore these questions from the parameters perspective, empirically finding that a neuron's parameters form a trigonometric pattern, and identify a set of properties: phase-alignment, model symmetry, majority-voting scheme, and a lottery ticket mechanism."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The paper explores an interesting set of questions. \n\nHighlights potentially interesting findings. \n\nWork around activation functions is intriguing."}, "weaknesses": {"value": "The paper introduces the conceptions `phase alignment, where a neuron’s output phase is twice its input phase, and phase symmetry, where phases are uniformly distributed among neurons sharing the same frequency.` however, before this introduction, the term `phase` is not concretely defined in this context, which makes this section hard to parse.  \n\nThe paper states on line `136` that `We begin with the most striking observation: a global trigonometric pattern in parameters that consistently emerges across all training runs with random initialization.` however, no empirical evidence is provided to support this claim.\n\nOn line `148` it states `In Figure 7b, we zoom in on the learned parameters of the first five neurons`; however Figure 7b looks at 3 Neurons; how are these neurons selected? In addition, how many neurons have this pattern? How often was this pattern observed over multiple runs? Line `150-151` goes on to state `The plots show that these parameters are well approximated by cosine curves, shifted by phases φm, ψm, and scaled by magnitudes αm, βm.` however, only 1.9% of the total neurons are represented in Figure 7a, and only 0.5859375% for Figure 7b. Although these neurons may be represented this way, how are the other neurons represented? This is especially important to show when the following text reads `this suggests that the trained neural network learns to solve modular addition by embedding a trigonometric structure into its parameters`. The paper then uses this finding to build the rest of the paper. In addition, I was unable to reproduce the main findings in the paper, i.e., that **all** the networks' input and output parameters formed a `trigonometric structure` and found neurons that did not form a `trigonometric structure` which suggests the `trigonometric structure` is not a requirement for the model to learn this task. \n\nThe paper only explores $(a+b) mod 23$, which limits the generality of the findings. Additional modular tasks should be explored to further support the findings, such as subtraction, division, and multiplication. Given that the paper explores modular arithmetic in a non-standard setup, where the input data is one-hot encoded. It is unclear how the findings will generalize to larger networks, more practical problems, or networks that use embedding layers.\n\nThe paper ends abruptly with no concluding section and does not provide clear takeaways nor relates the findings back to the current literature."}, "questions": {"value": "Please see weakness and more concretely: \n\nWhy is only p=23 explored in a network with a hidden width of 512 explored? Do these results hold when using a range of $p$ values, i.e $29, 31, 37, 41,.., 83, 89, 97$ and hidden widths of $32, 64, 128, 256$? \n\nCan you explore  additional modular arithmetic tasks such as subtraction, division, and multiplication? This would help improve the generality of the findings. To also help substantiate claims around phase alignment,  model symmetry, and the lottery ticket mechanism can this be explored in the case of CIFAR 10 and CIFAR 100 [1].\n\nA lot of the work is then based on the finding that the problem is solved by `embedding a trigonometric structure into its parameters`. Given the model is significantly overparameterized, can you explore and report what happens when the first (input) layer is frozen (completely random) during training (with all data)? \n\n[1] Krizhevsky, A. and Hinton, G., 2009. Learning multiple layers of features from tiny images."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DQ9z8F8X3q", "forum": "Qc4RLl7t3S", "replyto": "Qc4RLl7t3S", "signatures": ["ICLR.cc/2026/Conference/Submission20794/Reviewer_xW8s"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20794/Reviewer_xW8s"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20794/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761854258317, "cdate": 1761854258317, "tmdate": 1762999995514, "mdate": 1762999995514, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies 1 hidden layer, one hot encoded networks and seeks to describe the learned solution mechanistically and explain how the training dynamics result in that solution being learned."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- This work addresses a question that the field currently considers to be of high importance: why do deep neural networks learn the features they learn on modular addition?"}, "weaknesses": {"value": "*I am concerned with the paper overclaiming its novelty, particularly with respect to their claimed mechanistic interpretation*. \n\nThis paper claims multiple results are novel, but I know some were done by other published papers. Furthermore, some results claimed as novel are in disagreement with results from other published papers.  \n\nThus, there are significant issues with this paper: \n\n1. At least five prior works of high relevance aren't cited, which leads to 2. \n\n2. There are **multiple claims of novelty that aren't novel**, i.e. other published work has already achieved the result:\nClaimed novelty 1. \"While individual neurons produce noisy signals, the phase symmetry enables a majority-voting scheme that cancels out noise, allowing the network to robustly identify the correct sum.\"\nClaimed novelty 2. \"We prove that these properties allow the network to collectively approximate an indicator function on the correct logic for the modular addition task.\" \n\nClaimed novelties 1 and 2 are already known and aren't novel. They were detailed by [1], which provided a mathematical model for how networks get the correct answer, using the uniform phase assumption to cancel out noise (claimed novelty 1) to prove the correct logit becomes \"dirac\" (i.e. an indicator, novelty 2). I believe that Gromov's work on this topic (which is cited by this paper) also used random phase cancellation to prove the correct logit would be like a dirac indicator, but I am more familiar with [1] which I know did this.\n\nAlso, claims 1 and 2 disagree with empirical and theoretical results in [2], which shows that in 2-layer networks the logits are **not an indicator on the correct output logit**. [2] gives both empirical evidence and a theoretical proof that on average, O(log(n)) different frequencies are learned, and the size of the margins as a function of frequencies that are learned is O(log(n)). Thus, in multilayer networks, the margins are not an indicator.\n\n3. a lack of scope (the authors only study 1 hidden layer networks, though this is unclear from a first reading of their paper, which claims they study 2 layer networks, which can't be the case due to it being already established and proven that networks with >= 2 hidden layers learn O(log(n)) frequencies to solve this task [2]. 1 layer networks learn *all* (p-1)/2 frequencies (Morwani et al.), while multi-layer networks have been observed to learn substantially fewer (Nanda et al., Chughtai et al., [2]), and the gradient dynamics explaining why this happens are considered an open problem. Only studying 1 hidden layer networks makes their results fail to generalize to multilayer networks, and can't explain the aforementioned open problem. \n\n4. False claims are made, for example, on line 99, the authors state either one hot encoded inputs or a trainable embedding matrix can be used, but switching from one hot encodings to a trainable embedding causes the network to learn O(log(n)) frequencies [2], and not the n-1/2 frequencies result of Morwani et al., were trainable embeddings to be used, observation 3 and definition 4.1 both become false.\n\nLess significant, but still issues:\n\n5. This paper claims a \"full\" mechanistic understanding of models trained on modular addition, and presents 6 empirical observations, but lacks convincing empirical evidence supporting the mechanistic interpretation and observations. Some of this empirical evidence is relegated to the appendix (but should be adjacent to the observations and in the main paper). The experiments remain unconvincing due to reasons like: experiments not over multiple random seeds, some experiments seem to require training on the entire dataset (what do the plots in the first section look like when using standard ML train test splits?), lack of quantitative statistical / causal testing supporting observations 1-6.\n\n6. This paper spends a significant amount of space claiming the aforementioned \"full\" mechanistic understanding (claims 1 and 2). This space should instead be used to incorporate convincing experimental evidence supporting what's necessary for the main result of the paper: their claims about how training dynamics unfold. \n\n7. This work does not have a related work section, as it's located in the appendix. Furthermore, this work incorrectly claims a \"complete\" discussion of related work, while missing citations to at least 5 other works ([1,2,3,4,5]). The authors state: \"A complete discussion on related works is deferred to A.2 due to space limit.\"\n\n8. There is no limitations section or conclusion; the last section is titled \"TRAINING DYNAMICS FOR FEATURE EMERGENCE\".\n\nIn summary, this paper makes multiple claims of novelty where the result is already well known and established. Of particular note, is the claim of a \"full\" mechanistic understanding, but [1,3], and especially [2] all together provide a more complete understanding than what is presented in this paper. **I believe this paper is not ready for publication at this time and needs a rewrite and restructuring beyond the scope of what can occur during reviews.** \n\nThat said, **there are open problems remaining related to the gradient training dynamics on modular addition**: if their claim for the training dynamics holds up robustly under quantitative analyses with depth, over many random seeds, then their work would be the first paper (to my knowledge) to resolve *how* networks learn the features on modular addition. [5] is an uncited paper that attempted to explain the gradient dynamics on modular addition and was (to my knowledge) only accepted at a workshop. It used lotka-volterra ODEs to attempt their arguments. \n\nA successful paper on the gradient dynamics is worthy of publication, without needing to claim novel mechanistic interpretations.\n\n[1] Grokking modular polynomials https://arxiv.org/pdf/2406.03495\n\n[2] Uncovering a Universal Abstract Algorithm for Modular Addition in Neural Networks\n https://arxiv.org/abs/2505.18266\n\n[3] Towards a unified and verified understanding of group-operation networks https://arxiv.org/abs/2410.07476\n\n[4] Modular addition without black-boxes: Compressing explanations of MLPs that compute numerical integration https://arxiv.org/abs/2412.03773\n\n[5] Survival of the Fittest Representation: A Case Study with Modular Addition https://openreview.net/forum?id=2WfiYQlZDa"}, "questions": {"value": "Q1. Is my understanding correct that you trained networks with one hot encoded inputs and 1 hidden layer, i.e. the same networks trained by Morwani et al.?\n\nQ2: How is this different from the Survival of the fittest work, which also uses ODEs (Lotka Volterra) [5]?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "RbfuWM87he", "forum": "Qc4RLl7t3S", "replyto": "Qc4RLl7t3S", "signatures": ["ICLR.cc/2026/Conference/Submission20794/Reviewer_Ykz3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20794/Reviewer_Ykz3"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20794/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988165931, "cdate": 1761988165931, "tmdate": 1762999995234, "mdate": 1762999995234, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}