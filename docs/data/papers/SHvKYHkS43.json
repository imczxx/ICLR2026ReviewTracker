{"id": "SHvKYHkS43", "number": 20847, "cdate": 1758310870260, "mdate": 1759896955843, "content": {"title": "Q-STRONG: Quantum-Statistical Robustness with Noise-Guarded Dynamics for Learning", "abstract": "State-of-the-art learners remain fragile under heavy-tailed noise, adversarial perturbations, and—on NISQ devices—intrinsic stochasticity. We present \\emph{Q-STRONG}, a quantum–statistical framework that couples (i) robust M–estimation, (ii) quantile–scheduled gradient clipping, and (iii) gap–adaptive randomized smoothing. Inputs are encoded as quantum states; a task-aligned Hamiltonian yields a representation whose spectral gap acts as a stability signal. During training, bounded-influence losses and per-sample clipping suppress rare gradient spikes. At inference, we certify predictions with instance-adaptive noise $\\sigma(x)=\\kappa\\,\\Delta(x)^{-\\beta}$, producing larger $\\ell_2$ radii where the representation is stable.\n\nWe prove non-asymptotic guarantees: convergence of clipped SGD to first-order stationarity for weakly smooth robust objectives; a stability-based generalization bound with an \\emph{effective} Lipschitz constant lowered by clipping and robustification; gap-adaptive extensions of randomized-smoothing certificates; and parameter-noise resilience that scales inversely with the gap. Empirically, Q-STRONG achieves a favorable accuracy–robustness frontier on MNIST and CIFAR-10 with label noise and common corruptions, and on synthetic manifolds stressing intrinsic dimension and outliers. Ablations isolate the roles of each component. The approach is hardware-agnostic (classical or NISQ), plug-compatible with standard models, and adds minimal overhead. Q-STRONG thus offers a practical, theoretically grounded route to certified, noise-resilient learning.", "tldr": "Q-STRONG unifies robust M-estimation, quantile-clipped optimization, and gap-adaptive randomized smoothing in a quantum-state framework to deliver certified, noise-resilient learning on MNIST/CIFAR.", "keywords": ["Quantum machine learning", "Robust M-estimation", "Dynamic gradient clipping", "Randomized smoothing", "Certified robustness", "Noise resilience", "Spectral gap", "Quantum state embeddings", "Adversarial robustness", "NISQ hardware"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/59a92d2cdf824dda0ed7bd7d2848d2090a366e4c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors propose a robustness framework that encodes inputs as unit-norm complex quantum states and uses the Hamiltonian spectral gap as a stability signal for training and certification. It combines robust M-estimation with gradient clipping, and introduces gap-adaptive randomized smoothing for larger certified $\\ell_2$ certificates. The paper proves convergence of clipped SGD, tighter generalization for the method, and a certification theorem that inherits the guarantee of Cohen et. al with the gap-dependent noise. The quantum aspect is, to my reading, primarily the state-space formalism.  Experiments on MNIST/CIFAR-10 show improved certificates with similar accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "-- The paper combines robust M-estimation, adaptive gradient clipping, and randomized smoothing and gives proofs of convergence, stability, and certification\n\n-- The idea of linking the randomized-smoothing noise to a quantum spectral gap seems to be an original connection (though I am not an expert)\n\n-- Empirically the method achieves larger certified $\\ell_2$ robustness without accuracy loss, supporting the theory claims"}, "weaknesses": {"value": "-- The paper is a bit of a mess in its current sate. For example lines 234 - 241 I think are intended to be a tex algorithm, but the authors messed up the latex. The leading [t] [1] suggests this.\n\n-- On line 125, I think you meant $\\Delta_\\theta(x) = \\lambda_1(x) - \\lambda_2(x)$. This should be fixed.\n\n-- I find the paper hard to read. It reads like a bunch of standalone passages. \n\n-- The experiments are rather limited overall. There are limited comparisons to stronger certified robustness methods.\n\n-- The quantum and robust statistics connection is not clearly spelled out. I believe this needs a dedicated section.\n\nFor these reasons, I opt to reject the paper in its current state. Though I am open to changing my score if the authors can correct these points."}, "questions": {"value": "-- Can you compare to newer certified training methods e.g. AdvSmooth [1] and TRADES [2]?\n\n-- Could the spectral gap be replaced by a regular stability proxy such as Jacobian singular values?\n\n-- In what sense is this framework quantum-statistical if implemented entirely on classical hardware? In general I believe the quantum connection needs to be spelled out more\n\n[1] https://arxiv.org/pdf/1906.04584\n[2] https://arxiv.org/pdf/1901.08573"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nwUF1dQFnS", "forum": "SHvKYHkS43", "replyto": "SHvKYHkS43", "signatures": ["ICLR.cc/2026/Conference/Submission20847/Reviewer_PuYh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20847/Reviewer_PuYh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20847/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761154132447, "cdate": 1761154132447, "tmdate": 1762999993962, "mdate": 1762999993962, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Q-Strong, a framework that combines randomized smoothing, robust M-estimation, and gradient clipping. The authors investigate the convergence and robustness of the framework and evaluate it on the MNIST and CIFAR datasets."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed framework combines state-of-the-art techniques, and the empirical performances are promising.\n\n- The framework comes with non-asymptotic guarantees"}, "weaknesses": {"value": "- The paper is a combination of existing techniques already employed in the literature. While this is not necessarily a weakness, I miss seeing what the main non-incremental contributions of the paper are compared to the literature. For instance, it is not clear if the theoretical framework is simply a straightforward consequence of existing results.\n\n- In my opinion, the empirical evaluation should be improved. In fact, if the goal of the paper is to propose a method that improves the tradeoff robustness/accuracy, then this should be compared with state-of-the-art techniques and possibly on more datasets."}, "questions": {"value": "- What are the main technical contributions in the theoretical analysis? \n\n- Have you compared the proposed tool with state-of-the-art techniques for adversarial training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6EeRDyQ6TK", "forum": "SHvKYHkS43", "replyto": "SHvKYHkS43", "signatures": ["ICLR.cc/2026/Conference/Submission20847/Reviewer_tebY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20847/Reviewer_tebY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20847/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761774128890, "cdate": 1761774128890, "tmdate": 1762999993735, "mdate": 1762999993735, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a quantum–statistical framework designed to enhance robustness against heavy-tailed noise, adversarial perturbations, and intrinsic stochasticity. In particular, the framework, Q-STRONG, is proposed for near-term quantum processors (NISQ devices). The approach integrates three key components: (i) robust M-estimation, (ii) quantile-scheduled gradient clipping (DynClip), and (iii) gap-adaptive randomized smoothing. Inputs are encoded as quantum states, and the spectral gap of a task-aligned Hamiltonian serves as a stability signal to guide adaptive noise injection and certification."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The mathematical analysis is rigorous and technically sound. The non-asymptotic convergence guarantees for clipped SGD under weakly smooth robust objectives, as well as the stability-based generalization bound, are well presented and theoretically meaningful. The integration of the spectral gap as a stability indicator is a novel approach. The connection between quantum representations and robustness is an appealing direction. The derivations for bounded-influence losses (e.g., Huber) and dynamic clipping are particularly interesting and appear consistent with the theoretical claims."}, "weaknesses": {"value": "The major concern is the empirical validation, which is currently insufficient to support the broad theoretical claims. The experiments are primarily limited to MNIST, with only minimal results reported on other datasets. Although the authors mention experiments on CIFAR-10, I could not find any corresponding results in the paper.\n\nGiven the ambitious theoretical framework and the claim of hardware-agnostic applicability (classical or quantum), evaluations on more diverse benchmarks, such as Fashion-MNIST, SVHN, and CIFAR, are essential. Such experiments would help demonstrate the generality of the proposed method and bridge the gap between the theoretical assumptions (e.g., Lipschitz smoothness, bounded spectral gaps) and observed empirical behavior."}, "questions": {"value": "Refer to Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "3FAV7qRIxw", "forum": "SHvKYHkS43", "replyto": "SHvKYHkS43", "signatures": ["ICLR.cc/2026/Conference/Submission20847/Reviewer_sDXU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20847/Reviewer_sDXU"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20847/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761983966472, "cdate": 1761983966472, "tmdate": 1762999994162, "mdate": 1762999994162, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The submission proposes Q STRONG, a framework that combines three ideas (1) Robust M estimation, (2) Quantile‑scheduled gradient clipping, and. (3) Gap adaptive randomized smoothing at inference. Empirically, the paper reports ablations on MNIST and CIFAR 10 (with label noise and CIFAR-10-C) comparing CE, Huber, DynClip, and Dyn+Smooth, with Dyn+Smooth improving certified radii at modest accuracy cost."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe paper’s idea is novel and is practically motivated. It presents a tidy framework where robust losses (bounded influence), quantile‑based clipping, and randomized smoothing reinforce each other and are all modulated by a single, interpretable quantity (the spectral gap).\n\n2.\tIt has ablation studies to shows the effectiveness of DynClip and Dyn+Smooth. The direction is promising for practitioners for certified robustness."}, "weaknesses": {"value": "1.\tThe construction of the error Hamiltonian Hθ(x) (how it depends on θ and x), the precise procedure to estimate Δ(x), and the statistical concentration of this estimator are not specified with enough operational detail to reproduce results.\n\n2.\tCIFAR 10(+C) results are described but not fully shown; the paper would be stronger with complete tables/plots for CIFAR 10 and severity sweeps on CIFAR 10 C, plus variance across seeds. Also it is suggested to show results on more complex tasks.\n\n3.\tComparisons to stronger robustness baselines (e.g., adversarially trained smoothed models, label noise robust methods) are missing."}, "questions": {"value": "1.\tWhat exact Hamiltonian do you use in experiments? How is it parameterized, how often is Δ(x) estimated, and what is the computational cost relative to forward/backward? Please include an algorithmic box with pseudocode.\n\n2.\tThe text mentions mean certified radius 0.666 for MNIST, while Tables 1–2 show 0.30–0.41. Which is correct? Also, why do the tables say Digits10 rather than MNIST?\n\n3.\tCould you add comparisons to stronger robustness baselines (e.g., adversarially trained smoothed classifiers) and a sensitivity study over the quantile α schedule, k, and beta?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "A4JlqK0yMj", "forum": "SHvKYHkS43", "replyto": "SHvKYHkS43", "signatures": ["ICLR.cc/2026/Conference/Submission20847/Reviewer_gTbd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20847/Reviewer_gTbd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20847/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990349171, "cdate": 1761990349171, "tmdate": 1762936341463, "mdate": 1762936341463, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}