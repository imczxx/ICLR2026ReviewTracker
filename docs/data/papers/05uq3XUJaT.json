{"id": "05uq3XUJaT", "number": 3367, "cdate": 1757411444566, "mdate": 1763361432756, "content": {"title": "Fine-tuning large language models for text ranking with listwise constraints", "abstract": "With the rapid adoption of large language models (LLMs) across diverse applications, retrieval augmentation has become a key factor for improving downstream performance. Recent advances show that LLM-based retrieval can substantially enhance ranking quality. In this work, we present a novel LLM-based retrieval framework optimized along three complementary dimensions: (1) a customized attention-based fusion of hidden-layer representations, (2) a dedicated multi-layer perceptron (MLP) module for enriched feature transformation, and (3) a new list-wise learning objective, ListRank loss, to capture fine-grained relevance order. Experimental results demonstrate that our model achieves state-of-the-art performance. The model is publicly available for download on HuggingFace.", "tldr": "We propose a method to improve the fine-tuning performance of text ranking models by leveraging feature fusion, incorporating customized MLP modules, and optimizing with a listwise loss.", "keywords": ["Feature fusion", "listwise", "LLM", "rank"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/438531bfdc6d7eff6df3c9f4faf576cb9faa1f30.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a listwise fine-tuning method for LLM-based text reranking. The method improves three limitations of existing LLM rankers (single-token compression, shallow scoring heads, and pairwise objectives)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Despite operating at 4B parameters, ListRank outperforms or matches 7B–13B rerankers (RankLLaMA, RankGPT), demonstrating accuracy-efficiency trade-off potential. \n- The proposed list-wise training approach shows improvement based on the point-wise trained rerank models."}, "weaknesses": {"value": "- The motivation for the architectural improvement is unclear. The authors need to further explain the limitations of single-token summarization. In addition, as I understand it, the introduced attention pooling and MLP essentially still produce a single-token summarization in the end. As shown in the ablation study, the performance gains brought by attention pooling and the MLP are also quite limited.\n- The evaluation is conducted only on DL19 and DL20. The authors should evaluate on more benchmarks, such as BEIR.\n- The authors need to provide more justification regarding the fairness and statistical significance of the comparisons. I noticed that the experimental setups for different models in Table 1 are not consistent.\n- The novelty is limited. List-wise training has already been extensively studied in prior work. The baselines used in this paper are relatively weak; the authors should compare against more recent list-wise works [1,2,3].\n\n[1] Reddy et al., FIRST: Faster Improved Listwise Reranking with Single Token Decoding, 2024, EMNLP\n\n[2] Liu et al., Sliding Windows Are Not the End: Exploring Full Ranking with Long-Context Large Language Models, 2025, ACL\n\n[3] Liu et al., Leveraging Passage Embeddings for Efficient Listwise Reranking with Large Language Models, 2025, WWW\n\n- The writing quality needs improvement — many citations are directly glued to the text without proper formatting."}, "questions": {"value": "- The explanation of the figure in the text is somewhat confusing. How exactly is a smoother convergence curve observed after adding attention pooling and the MLP?\n- Why are point-wise and list-wise data mixed during training, and to what extent is the improvement simply due to using more training data compared to the baselines?\n- Have the author compared against other list-wise methods such as ListNet?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DvaKUEhgPp", "forum": "05uq3XUJaT", "replyto": "05uq3XUJaT", "signatures": ["ICLR.cc/2026/Conference/Submission3367/Reviewer_ytSp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3367/Reviewer_ytSp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3367/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761724719109, "cdate": 1761724719109, "tmdate": 1762916690154, "mdate": 1762916690154, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "ZEel6wh69o", "forum": "05uq3XUJaT", "replyto": "05uq3XUJaT", "signatures": ["ICLR.cc/2026/Conference/Submission3367/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3367/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763361431844, "cdate": 1763361431844, "tmdate": 1763361431844, "mdate": 1763361431844, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents ListRank to address limitations in existing reranking approaches. The method includes three extra modules compared to the Qwen3-Reranker-4B backbone: (1) attention pooling, (2) a gated MLP, and (3) ListRank Loss. The model is trained on a RankGPT-refined subset of the MS MARCO passage ranking dataset. Experimental results show that ListRank achieves comparable performance on MS MARCO dev, TREC DL19, and DL20 benchmarks with a 4B model. Ablation studies confirm that each component contributes to performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper demonstrates each component's contribution with quantifiable improvements.\n\n2. Comparable performance on standard benchmarks (MS MARCO, TREC DL19/DL20) with improved parameter efficiency.\n\n3. Comprehensive analysis includes convergence behavior and input length effects."}, "weaknesses": {"value": "This paper suffers from significant structural and organizational issues that require major revision. The novelty is limited, as both the gated MLP and listwise ranking losses are well-established methods in the literature. Additionally, the paper contains too many logical inconsistencies and typo errors throughout. Specific issues include:\n\n1. Introduction Section Structure\n\nThe introduction reads more like a related work section, containing to many background without clearly describing the paper's motivation, solution, and contributions.\n\nI suggest the authors restructure this section as follows:\nSplit the introduction into separate \"Introduction\" and \"Related Work\" sections\nStart the introduction with the problem statement and key contributions\nMove the historical survey (lines 24-51) to the Related Work section\n\n2. Section 2.1 (Preliminaries) - Technical Writing Issues\n\nLine 75: \"assigns each candidate D_i a real-valued relevance score, s_i, and sorts the candidates...\" → The notation s_i should be introduced here.\n\nLine 76: \"Collecting scores over the candidate list yields s = [s1, s2, . . . , sk], which induces a permutation by sorting in descending order\" lacks a proper verb structure. Suggested revision: \"Collecting scores over the candidate list yields s = [s1, s2, . . . , sk], which induces a permutation when sorted in descending order.\"\n\nLine 86: \"(pointwise formulation)\" and \"(listwise formulation)\" should reference actual mathematical formulations rather than being mere textual labels. Consider providing brief formula definitions or removing these parentheticals if they are not formally defined.\n\nLines 87-88: This content is redundant with lines 80-84 and should be removed or consolidated.\n\n3. Section 2.2 (Base Model) - Citation Format\n\nLine 107: \"query–document pair (Section 2.1)\" should use \\ref{sec:preliminaries} instead of manual section numbering for proper LaTeX cross-referencing.\n\n4. Section 2.4 (Multi-Layer Perceptron) - Content Focus Issues\nOverly verbose general MLP description: The MLP description is too generic and well-known. Given that Transformers already contain MLP layers in each block, this extended justification is unnecessary and should be significantly condensed.\n\nMisaligned emphasis: This section should focus on the gated structure innovation rather than rehashing basic MLP concepts. The gated mechanism (up-projection + gate-projection with element-wise multiplication) is the key contribution and deserves more emphasis.\nNotation inconsistency: The formula for h_out should use superscript notation (h^{out}) to maintain consistency with Section 2.5.\n\n5. Section 2.5 (ListRank Loss) - Structural Issues\n\nLines 249-250 misplaced: The sentence \"Based on the Attention Pool, MLP optimization, and ListRank loss proposed in this work, we construct a new model, which we refer to as ListRank\" should appear to the beginning of Section 2 or immediately after Section 2.1 as an overview, not at the end of the loss description.\n\nLines 251-252 redundancy: These lines repeat information already conveyed and should be removed or merged with the previous paragraph.\n\nSections 3 and 4 also contain typographical errors and require careful revision."}, "questions": {"value": "1. In Figure 2 (Training loss convergence curves), I noticed that Base+Attention Pool exhibits a loss spike between steps 65,000-70,000, and Base+Attention Pool+MLP shows another spike between steps 60,000-70,000. What do you think causes these spikes?\n\n2. Regarding Section 3.2 (EXPERIMENTAL SETUP), could you clarify how the random negatives are sampled during data construction?\n\n3. The results show that adding ListRank Loss on top of Attention Pool + Gated MLP yields approximately 8% improvement. What performance would we see if we trained Base + ListRank Loss directly, without the attention pooling and MLP modules?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tqvEbUa5Yi", "forum": "05uq3XUJaT", "replyto": "05uq3XUJaT", "signatures": ["ICLR.cc/2026/Conference/Submission3367/Reviewer_5Vsk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3367/Reviewer_5Vsk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3367/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761869293162, "cdate": 1761869293162, "tmdate": 1762916689924, "mdate": 1762916689924, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ListRank, a new framework designed for large language model (LLM)-based text retrieval and reranking tasks. The main contribution lies in addressing limitations of current LLM-based reranking approaches through three key innovations: A customized attention-based fusion of token-level representations. A multi-layer perceptron (MLP) module for enhanced feature transformation. A ListRank loss designed to model listwise ordering, thereby improving the fine-grained relevance order of candidate documents in a ranking task. The experimental results on MS MARCO and TREC datasets show that ListRank outperforms existing state-of-the-art reranking models in terms of mean reciprocal rank (MRR) and normalized discounted cumulative gain (nDCG) at 10."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The combination of attention pooling, MLP for feature transformation, and a listwise loss function (ListRank) represents a novel approach in the context of LLM-based text reranking. \n\n2. The paper presents a detailed and well-structured approach to a complex problem in retrieval. The proposed ListRank loss is a creative contribution, addressing the underutilization of global ordering in most existing reranking methods.\n\n3. The presentation of the method is clear, with well-defined steps outlined in the methodology section. The ablation study provides a strong demonstration of the contribution of each component, which adds to the clarity of the paper’s argument."}, "weaknesses": {"value": "1. The paper presents the ListRank loss in a practical context but lacks a deep theoretical justification for why the method should be superior to existing pairwise or pointwise methods. More rigorous analysis of the listwise nature of the problem and how exactly ListRank capitalizes on this could strengthen the argument.\n\n2. The experiments, while thorough, seem primarily focused on empirical validation without enough exploration into the why behind the observed performance improvements. For instance, why does ListRank perform better in long-text retrieval, and what exactly about the MLP and attention fusion modules leads to better results? A deeper analysis would have added significant value.\n\n3.  The use of MS MARCO as a training dataset is well-established but also well-trodden. The paper could have explored other more challenging or domain-specific datasets to better illustrate the broader applicability of the method. Furthermore, it's unclear if the ListRank approach could generalize to domains outside of traditional information retrieval."}, "questions": {"value": "1. The paper mentions that ListRank outperforms existing models in terms of retrieval metrics like nDCG. How does ListRank handle cases where candidate documents in the top-k list are of significantly different lengths? Could performance degrade with extremely long documents or highly diverse types of content?\n\n2. The authors claim that ListRank’s attention pooling module resolves the hallucination problem in long-text scenarios. Can the authors provide a more detailed explanation of how ListRank mitigates hallucinations better than existing models? Is there a theoretical framework behind this, or is it purely experimental?\n\n3. Could the authors elaborate more on the scalability of ListRank when applied to extremely large datasets or when fine-tuning large language models on a distributed setup? What specific challenges arise in such cases, and how does the model handle them?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2ZQqLSLjjV", "forum": "05uq3XUJaT", "replyto": "05uq3XUJaT", "signatures": ["ICLR.cc/2026/Conference/Submission3367/Reviewer_t7gj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3367/Reviewer_t7gj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3367/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761894657738, "cdate": 1761894657738, "tmdate": 1762916689748, "mdate": 1762916689748, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}