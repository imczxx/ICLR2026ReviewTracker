{"id": "b1ITgc4J4M", "number": 22077, "cdate": 1758325665651, "mdate": 1759896887758, "content": {"title": "Residual Feature Integration is Sufficient to Prevent Negative Transfer", "abstract": "Transfer learning has become a central paradigm in modern machine learning, yet it suffers from the long-standing problem of negative transfer, where leveraging source representations can harm rather than help performance on the target task. Although empirical remedies have been proposed, there remains little theoretical understanding of how to reliably avoid negative transfer. In this article, we investigate a simple yet remarkably effective strategy: augmenting frozen, pretrained source-side features with a trainable target-side encoder that adapts target features to capture residual signals overlooked by models pretrained on the source data. We show this residual feature integration strategy is sufficient to provably prevent negative transfer, by establishing rigorous theoretical guarantees that it never performs worse than training from scratch on the target data, and that the convergence rate can transition seamlessly from nonparametric to near-parametric when source representations are informative. To our knowledge, this is the first theoretical work that ensures protection against negative transfer. We carry out extensive numerical experiments across image, text and tabular benchmarks, and empirically verify that the method consistently safeguards performance under distribution shift, label noise, semantic perturbation, and class imbalance. Our study thus advances the theory of safe transfer learning, and provides a principled approach that is simple, robust, architecture-agnostic, and broadly applicable.", "tldr": "We prove that residual feature integration is sufficient to eliminate negative transfer in deep transfer learning, providing the first general theoretical guarantee with supporting empirical validation.", "keywords": ["deep transfer learning theory", "negative transfer", "provable safe transfer mechanism"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/af729dcd671f1b2efe8dbf2057480755d37baf97.pdf", "supplementary_material": "/attachment/817efa91b7cea809852e2f9a6c4ec2093a78e823.zip"}, "replies": [{"content": {"summary": {"value": "This paper studies transfer learning and proposes a residual feature integration method to mitigate negative transfer. The authors also introduce an upper bound for the generalization error under a nonparametric regression setup. However, the theoretical contribution is somewhat limited, and the empirical comparisons lack depth in several aspects."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.The paper identifies a simple, intuitive, and model-agnostic method (ReFine) to address the persistent problem of negative transfer. The strategy of augmenting a frozen pre-trained feature extractor with a trainable residual encoder is straightforward to implement and integrates easily into existing transfer learning pipelines.\n2.The work provides a rigorous theoretical analysis demonstrating that ReFine provably prevents negative transfer. \n3.The method is evaluated across a wide range of settings, including image, text, and tabular data. Experiments cover natural distribution shifts and challenging stress tests (e.g., high label noise, semantic perturbation, class imbalance), consistently showing that ReFine mitigates performance degradation where other methods fail."}, "weaknesses": {"value": "1.While the theoretical analysis is rigorous, the core architecture—a linear combination of a pre-trained feature map and a ReLU network—is structurally similar to models previously analyzed in the deep learning theory literature. The resulting generalization bounds, though well-derived, may not represent a significant conceptual advance over existing approximation theories for neural networks.\n2.The selection of baseline methods lacks contemporary relevance. Compared approaches like DANN and LoRA are established but not state-of-the-art. The empirical evaluation would be more compelling if it included more recent and influential transfer learning strategies, providing a clearer view of the method's current competitive standing.\n3.The paper does not provide a detailed comparison of the number of trainable parameters across all methods. This omission makes it difficult to assess the true efficiency of ReFine and to perform a fair comparison with parameter-efficient fine-tuning baselines like Adapter and LoRA.\n4.The multi-source transfer experiments are evaluated against only two simple baselines (NoTrans and a Naive concatenation). This setup is not sufficient to demonstrate a clear advantage, as it lacks comparison with dedicated and potentially stronger multi-source transfer learning algorithms."}, "questions": {"value": "1. The proposed model, \\hat{g}(x)=v⊤frep(x)+uh(x) can be viewed as a ReLU network directly according to the descriptions on P5 . The approximation analysis for such architectures has been extensively studied in prior works, and the theoretical guarantees provided here do not appear to deviate significantly from existing results.\n2.The baseline methods selected for comparison—such as DANN and LoRA—are relatively outdated. Several influential and more recent transfer learning strategies are not included, which limits the relevance and comprehensiveness of the experimental evaluation.\n3. A detailed comparison of the number of parameters across different methods is missing. This makes it difficult to assess the efficiency of the proposed approach relative to existing alternatives.\n4. In the multi-source transfer experiments, only two simple baselines (NoTrans and Naive) are used. This is insufficient to demonstrate the advantages of the proposed method in multi-source settings, where more competitive or state-of-the-art approaches should be considered."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YPhlwxtWh1", "forum": "b1ITgc4J4M", "replyto": "b1ITgc4J4M", "signatures": ["ICLR.cc/2026/Conference/Submission22077/Reviewer_cD6H"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22077/Reviewer_cD6H"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22077/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761055856882, "cdate": 1761055856882, "tmdate": 1762942056387, "mdate": 1762942056387, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a transfer learning method called REFINE for mitigating the phenomenon of negative transfer. Specifically, the authors employ an additional term in addition to composing a linear probe based on the learned representation from the source domain. They provide several experiments to demonstrate the effectiveness of the proposed method. Moreover, a upper bound of excess risk regarding fine-tuning is also offered by this study."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. This study is well-written and easy to follow. The motivation behind their method is reasonable.\n2. They conducted comprehensive transfer learning experiments to demonstrate the effectiveness of their method in transfer learning scenarios, which are sound.\n3. Meanwhile, the theoretical results obtained by this work are rigorous."}, "weaknesses": {"value": "1. The core idea of this paper is similar to that of the following papers. Both add extra terms to model the potential differences between the source and target tasks that are not successfully captured by the learned representation, in addition to the linear probe on the learned encoder. I sincerely suggest that the authors discuss the differences between their work and these studies in the related works section.\n\n[1] Transfer learning with affine model transformation. Advances in Neural Information Processing Systems, 36, 17296-17329.\n\n[2] Deep transfer learning: Model framework and error analysis. arXiv preprint arXiv:2410.09383.\n\n2. Some of the presented accuracy results seem a little bit weird. For example, the results transferring from CIFAR100 to CIFAR10 are lower than expected. Based on my experience, it should be around 80%, rather than the figure given in the paper (around 40%). The reason for this phenomenon seems to be that they only adopt 10,000 as the pretraining size. I don't understand the rationale behind such a design. Can the authors elaborate on that? This raises a concern about whether the conclusion still holds under sufficient pretraining.\n\n3. The experiments conducted in this study are all focused on small-scale datasets. But I am totally okay with that, given that they have a solid theoretical guarantee."}, "questions": {"value": "The authors claimed that they desire to learn $h$ and $w$ such that \n$$\n\\mathcal{R}\\_{\\mathbb{P}^t}(w \\circ (f\\_{rep}, h)) \\leq \\min\\\\{\\mathcal{R}\\_{\\mathbb{P}^t}(w_{ft} \\circ f_{rep}), \\mathcal{R}\\_{\\mathbb{P}^t}(g\\_{sc})\\\\}\n$$\nI wonder did authors demonstrate this holds for ERM $(\\hat{w}, \\hat{h})$ at somewhere of this paper? Or this is just a desire? If this can be justified, what kind of requirements are necessary for the risk $\\mathcal{L}$?\n\n**Summary of review:** I think this is a solid paper overall, considering its comprehensive and sound experiments as well as the theoretical guarantees provided. However, the originality of the idea is not clear, along with some experimental concerns mentioned above. Therefore, I would like to set my initial rating at 4. If author successfully resolve my concerns, I will be pleasure to raise my rating."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KKJi2zib71", "forum": "b1ITgc4J4M", "replyto": "b1ITgc4J4M", "signatures": ["ICLR.cc/2026/Conference/Submission22077/Reviewer_fQBT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22077/Reviewer_fQBT"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22077/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761211995071, "cdate": 1761211995071, "tmdate": 1762942056095, "mdate": 1762942056095, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a transfer learning algorithm designed to prevent negative transfer. If the source model provides useful information, the algorithm leverages it; otherwise, its performance does not fall below that of training solely on the target data. It assumes the existence of a pretrained source model $f_{\\text{rep}}$. A residual trainable network $h$ is then added, and a linear trainable model $w$ is applied on top of the concatenated representation  $(f_{\\text{rep}}(x), h(x))$."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper derives an error bound for the proposed algorithm, comparing its error to that of the ground truth regression function. Furthermore, the authors conduct numerical experiments demonstrating that their approach is not affected by negative transfer."}, "weaknesses": {"value": "1. The paper claims that its approach avoids negative transfer and that Equation (1) holds for their method, stating that the error of the proposed approach is less than the minimum of the errors obtained by using only target data and by training on top of the source model $f_{\\text{rep}}$. However, the theorem they provide does not justify this claim. In fact, Theorem 4.1 only establishes a rate guarantee relative to $f^*$, not an inequality comparing $\\hat{g}$—the algorithm’s output—with $\\min \\\\{\\text{only target}, w \\circ f_{\\text{rep}}\\\\}$. In particular, Theorem 1 does not imply this claim. Therefore, the main claim of the paper remains unproven.\n\n2. A major difficulty with the algorithm lies in tuning the hyperparameter $\\rho$, yet the paper provides no method for adaptively selecting this parameter."}, "questions": {"value": "What is the practical justification for the assumption that $||v^*||\\leq 1$ ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QEx1zv9D3n", "forum": "b1ITgc4J4M", "replyto": "b1ITgc4J4M", "signatures": ["ICLR.cc/2026/Conference/Submission22077/Reviewer_PRLw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22077/Reviewer_PRLw"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22077/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761520729507, "cdate": 1761520729507, "tmdate": 1762942055856, "mdate": 1762942055856, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors identify residual connections as a powerful mechanism for provably avoiding negative transfer, and based on this insight, propose a simple yet effective method termed Residual Feature Integration (REFINE). Theoretically, the authors formally justify this simple yet remarkably effective approach through a rigorous analysis. Empirically, the authors conduct extensive experiments across image, text, and tabular benchmarks, and demonstrate that REFINE consistently mitigates negative transfer under diverse scenarios, including distribution shifts, label noise, semantic perturbations, class imbalance, and multi-source transfer settings."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The manuscript is well written, logically structured, and easy to follow.\n- The authors provide theoretical analysis.\n- According to the empirical evaluations, the proposed simple approach achieves good performance across image, text, and tabular benchmarks, and under challenging conditions such as distribution shift, label noise, semantic perturbation, and class imbalance."}, "weaknesses": {"value": "- The current setting is restricted to supervised fine-tuning. The proposed method requires access to labeled target-domain/task data, which is a relatively strong assumption even in conventional transfer learning [1]. Could the authors provide insights into whether the method would still work under unsupervised domain adaptation (UDA) [1] (does not require target-domain labels) or source-free domain adaptation (SFDA) settings [2-3] (does not require access to either the source data or target-domain labels)? Empirical validation or theoretical discussion in such scenarios would substantially enhance the generality of the method.\n- The manuscript does not investigate how the performance varies with different amounts of target-domain data used for transferring.\n- This manuscript lacks clarification of model architectures and size. The specific architectures of the CNN and Transformer models used in experiments are not clearly described. This makes it difficult to assess how architectural design and parameterization influence the effectiveness of the proposed method. \n- For intentional and extreme negative transfer, such as non-transfer learning [4-6] (where the goal is to enforce strong negative transfer for model intellectual property protection), will the proposed method can still work? It would be insightful if the authors could discuss or empirically investigate the applicability or limitations of the method in such settings.\n\n[1] Unsupervised domain adaptation by backpropagation. ICML 15\\\n[2] Do We Really Need to Access the Source Data? Source Hypothesis Transfer for Unsupervised Domain Adaptation. ICML 20\\\n[3] A Comprehensive Survey on Source-free Domain Adaptation. TPAMI 23\\\n[4] Non-Transferable Learning: A New Approach for Model Ownership Verification and Applicability Authorization. ICLR 22\\\n[5] Your Transferability Barrier is Fragile: Free-Lunch for Transferring the Non-Transferable Learning. CVPR 24\\\n[6] Toward Robust Non-Transferable Learning: A Survey and Benchmark. IJCAI 25"}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QSANKsnJNM", "forum": "b1ITgc4J4M", "replyto": "b1ITgc4J4M", "signatures": ["ICLR.cc/2026/Conference/Submission22077/Reviewer_VFA3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22077/Reviewer_VFA3"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22077/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931704670, "cdate": 1761931704670, "tmdate": 1762942055654, "mdate": 1762942055654, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}