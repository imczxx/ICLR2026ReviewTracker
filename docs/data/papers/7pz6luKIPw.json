{"id": "7pz6luKIPw", "number": 8998, "cdate": 1758106584686, "mdate": 1759897749012, "content": {"title": "ChildEval: How Large language models meet children’s personalities", "abstract": "The remarkable success of Large Language Models (LLMs) has revolutionized LLM-based chatbots for personalized tasks beyond generic dialogues. Personalization involves customizing LLMs to generate text responses based on user preferences. One promising endeavor is to enable personalized interactions for children's caretakers while also promoting development and learning. However, dedicated research is required to determine whether LLMs can effectively deliver personalized responses based on children's preferences, as their interactions differ from those of adults. We introduce ChildEval, a benchmark to evaluate LLMs' capacity to infer, interpret, and follow child-centered preferences in a long-context conversational setting. Our benchmark comprises of 29K synthesized children's (ages 3-6) persona profiles, which are related to their preferences in both explicit and implicit manners. Implicit preferences are integrated inside dialogues consisting of 6 to 10 turns. The preferences cover 5 top-level and 14 sub-level topics that involve children's daily lives and development. We further propose child-centric preferences to systematically evaluate the performance of open-source LLMs. Experimental results demonstrate the impact of various personalized representations on LLM responses and indicate that fine-tuning on this dataset may enhance performance.", "tldr": "", "keywords": ["LLM-based chatbots", "children's personalities", "personalized dialogue generation", "children's caregiver"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/78b3061076c03ddbc6acf6fd7306f3f76f9a994c.pdf", "supplementary_material": "/attachment/b5d1d22f25e9f21cd56be8ab8832ed28b372d48c.zip"}, "replies": [{"content": {"summary": {"value": "The authors introduce ChildEval - an evaluation benchmark for LLMs to rate their response from the perspective of children (3-6 years old).\nThey build a synthetic dataset of child-eval conversations + metrics to evaluate how well a LLM responds to a child.\nThose metrics are based on custom prompts - showing a QWEN model the history, LLM_response and asking to give yes/no related to the criterion to evaluate.\n\nUsing this dataset and metrics, they evaluate 5 state of the art open-weight LLMs to see how good they are at responding to children. They show that LLMs struggle to keep their response consistent with child preferences after long and implicit conversations.They show that finetuning those LLMs on ChildEval improves evaluation performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Strengths:\n- The paper introduces a synthetic dataset that looks soundly constructed for child-LLM dialogue, which can be reused by other researchers focusing on child LLM interaction. This is a novel domain that hasn't been explored.\n- The paper introduces evals for child-LLM interaction - which is great for a new field and can be used as a benchmark for following papers."}, "weaknesses": {"value": "- It is not clear in this paper how LORA finetuning was done to improve performance : there is no mention of train/test splits and it is unclear if LORA fine-tuning was done on the same data that is used for evaluations.\n- The paper constructs personas and preferences as separate but some of the preferences are actually already included in personas. This make the finding \"preference consistency increases when adding persona to the prompt\" weaker.\n- The 4 evals that are introduced are based on a prompt + response for QWEN - and numbers are then taken as ground truth for model comparison. It would be good to validate the stability of those metrics by comparing metric stability across different judge models.\n- There is no correlation between the 4 metrics that are introduced and any real data/real human preference. The dataset is from synthetic data and the evals are from a synthetic Judge."}, "questions": {"value": "What was the methodology used for LORA fine-tuning (training data, evaluation data)?\nHow strongly do the introduced metrics correlate with actual human preference?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CjdwLWKtwK", "forum": "7pz6luKIPw", "replyto": "7pz6luKIPw", "signatures": ["ICLR.cc/2026/Conference/Submission8998/Reviewer_meKb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8998/Reviewer_meKb"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8998/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761400307036, "cdate": 1761400307036, "tmdate": 1762920726822, "mdate": 1762920726822, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ChildEval, a benchmark to evaluate how well Large Language Models can understand and respond to children's (ages 3-6) preferences in conversational settings. The benchmark comprises 29K synthetically generated children's persona profiles created through a three-step pipeline: 1) Persona Generation: Used Qwen2.5-72B to generate diverse child personas through iterative generation-and-refinement, with FAISS-based filtering to remove semantically similar profiles; 2) Preference Generation: Created 46K preferences from personas and sampled topics, expressed as first-person statements that can be revealed either explicitly or implicitly; 3) Dialogue Construction: Generated child-LLM conversations that naturally embed implicit preferences using prompt-based generation.\n\nThe benchmark introduces fine-grained child-centric metrics beyond standard Preference Consistency (PC): \n- Emotional Adaptation (EA): Sensitivity to children's emotions\n- Interaction Scaffolding (IS): Guiding participation with questions/hints\n- Developmental Appropriateness (DA): Age-appropriate language and complexity\n- Engagement (EG): Creating lively, interesting interactions\n\nExperiments evaluated 5 state-of-the-art open-source LLMs (Qwen2.5-3B, Qwen3-4B, LLaMA3.1-8B, DeepSeek-R1, Mistral-7B). Results showed LLMs struggle with long-term personalization and implicit preference inference. Both LoRA and PSM fine-tuning methods significantly improve performance over base models on both preference consistency and child-oriented evaluation."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The work studies an important research direction: formulating child-LLM interaction as a personalization problem, addressing an important and underexplored application area with significant societal impact, and offers essential resources:\n- The first large-scale benchmark with child-specific evaluation dimensions (46K preferences across 14 developmental topics)\n- Novel child-centric evaluation framework beyond generic preference consistency: Emotional Adaptation (EA), Interaction Scaffolding (IS), Developmental Appropriateness (DA), and Engagement (EG)\n- Comprehensive problem formulation distinguishing explicit vs. implicit preferences in long-context multi-session dialogues.\n- Experimental analysis across 5 state-of-the-art LLMs and 3 adaptation strategies (prompting, LoRA, PSM), revealing that: LLMs struggle significantly with implicit preference inference and long-term personalization."}, "weaknesses": {"value": "The benchmark does not provide sufficient details on data quality verification or comprehensive evaluation validation. Here are the key limitations:\n\nDataset quality:\n- The training and evaluation set are entirely generated by Qwen2.5-72B with no validation against actual child-LLM conversations. It is unclear if generated dialogues match authentic child speech/text patterns (word omissions, semantic errors).\n- No user studies with actual children or domain experts to verify realistic scenarios.\n- The dataset might contain model-specific biases given it is entirely generated by Qwen2.5-72B, then evaluated using Qwen2.5-72B-Instruct, which might explain why Qwen3-4B-instruct outperform DeepSeek-R1 in Table 2.\n\nEvaluation Validation:\n- No human evaluation to validate LLM-as-judge approach. The LLM-judge prompt for EA and DA does not provide the evaluation guideline for different age (e.g., 3 year-old vs 6 year-old).\n- All metrics evaluated by Qwen2.5-72B-Instruct - single model bias\n- No error analysis on evaluation - unclear how often the evaluator makes mistakes"}, "questions": {"value": "- What are the data quality filters applied other than  FAISS-based similarity filtering? What types of errors were caught during data cleaning?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aBLglUxECL", "forum": "7pz6luKIPw", "replyto": "7pz6luKIPw", "signatures": ["ICLR.cc/2026/Conference/Submission8998/Reviewer_9AiT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8998/Reviewer_9AiT"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8998/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761515621609, "cdate": 1761515621609, "tmdate": 1762920726371, "mdate": 1762920726371, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The study proposes ChildEval to evaluate LLMs' personalization capability toward preschool children (ages 3-6). The benchmark features 29K synthetic child persona profiles, with both explicit and implicit preferences embedded within 6 to 10-turn dialogues. The evaluation protocol goes beyond traditional Preference Consistency (PC), introducing child-specific metrics: Emotional Adaptation (EA), Interaction Scaffolding (IS), Developmental Appropriateness (DA), and Engagement (EG)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses LLM interaction and personalization for children, a critical and underexplored area given LLMs' increasing role as a core medium for human-computer interaction."}, "weaknesses": {"value": "- Neglect of Safety and Mental Health (Core Concern): The paper focuses too narrowly on preference matching and completely omits the crucial dimensions of LLM security, risk mitigation, and the ability to guide children toward healthy mental development. This is considered a more essential scenario and an unacceptable omission in any LLM-child interaction assessment.\n\n- Flawed Personality Modeling: The methodology relies on generating personas via LLM-created \"explicit static persona descriptions.\" This approach lacks discussion on what \"child personality\" truly is, risking significant \"personality bias\" and failing to capture the implicit, dynamic, and complex nature of a child's true personality.\n\n- Data Reliability and Ethical Issues: The data is entirely model-driven/synthetic with no human participation. This raises serious doubts about the reliability and validity of the fabricated personalities, questioning whether they reflect the true distribution of human/child personalities.\n\n- Lack of Interdisciplinary Rigor: The work is perceived as irresponsibly applying a general-purpose personality modeling framework to a sensitive child scenario without sufficient consideration of social, psychological, or educational complexities. This purely technical approach is viewed as lacking practical meaning and failing to align with the ultimate goal of ensuring LLMs serve a child's healthy growth."}, "questions": {"value": "1. Why does the smaller Qwen3-4B model significantly outperform much larger models like DeepSeek-R1 in Table 2? This conclusion violates the general trend observed in the scaling law. What is the authors' explanation for this anomalous phenomenon?\n\n2.  Why are the results for DeepSeek-R1 in Figure 2 only presented up to 10 dialogue turns, while other models (such as Qwen3-4B and Llama2-7B) are evaluated over longer contexts (e.g., 20 turns)?"}, "flag_for_ethics_review": {"value": ["Yes, Discrimination / bias / fairness concerns"]}, "details_of_ethics_concerns": {"value": "The exclusive reliance on LLMs to synthesize child persona data without human validation poses a critical ethical risk. Given the sensitivity and complexity of child personalities, the model-generated data is highly likely to contain significant bias and inaccurate stereotypes, lacking necessary psychological rigor. Evaluating or training models on this biased data can lead to misleading or harmful 'personalized' interactions, potentially impeding a child's healthy cognitive and emotional development. This approach compromises the benchmark’s credibility and violates safety standards for research involving vulnerable populations."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "l60p1AtruB", "forum": "7pz6luKIPw", "replyto": "7pz6luKIPw", "signatures": ["ICLR.cc/2026/Conference/Submission8998/Reviewer_M6CE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8998/Reviewer_M6CE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8998/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927135023, "cdate": 1761927135023, "tmdate": 1762920725968, "mdate": 1762920725968, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new benchmark called ChildEval, designed to assess the ability of large language models (LLMs) to understand, reason, and follow children's preferences in long-context conversations. The authors note that existing personalized research primarily focuses on adults, while children exhibit significantly different interaction patterns and needs, lacking corresponding evaluation metrics. To address this gap, ChildEval incorporates 29,000 synthetic child personas, each associated with explicit and implicit preferences in daily life and developmental contexts.\n\nBeyond the dataset itself, this work proposes a fine-grained evaluation protocol tailored for children. It introduces four new child-oriented assessment dimensions alongside the traditional “Preference Consistency (PC)”: Emotional Adaptation (EA), Interaction Scaffolding (IS), Developmental Appropriateness (DA), and Engagement (EG). .\n\nIn the experimental section, the authors evaluated multiple open-source LLMs, verifying the impact of different personalization representation methods (such as incorporating personas into prompts) on model performance. They demonstrated that fine-tuning on ChildEval enhances models' ability to personalize for children. Experimental results reveal challenges existing LLMs face in handling children's implicit preferences and long dialogue histories, emphasizing the importance of comprehensive evaluation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- ChildEval is thoughtfully designed. It not only incorporates children's basic profiles but also distinguishes between explicit and implicit preferences, with the latter posing greater demands on the model's reasoning capabilities. By inserting irrelevant dialogues into conversation histories to simulate long-context scenarios, the evaluation becomes more realistic and challenging.\n- One of the key contributions of this paper is the introduction of four new evaluation dimensions tailored for children: EA, IS, DA, and EG. These dimensions go beyond merely assessing whether responses align with children's preferences, instead evaluating LLM responses across multiple dimensions—interaction quality, emotional support, educational value, and fun—all of which are crucial for child users. This evaluation framework provides a valuable foundation for future research in this area."}, "weaknesses": {"value": "- The entire ChildEval benchmark (including child profiles and dialogues) was generated by LLM. Although the authors employed methods like deduplication to ensure diversity, synthetic data may not fully capture the complexity, creativity, and unpredictability of authentic child language. Biases inherent in the generative model itself may also be introduced into the dataset. The paper's description of the “self-verification” process is insufficiently clear, lacking human validation steps to ensure the quality and authenticity of the generated data. This represents a major limitation of the work.\n- The paper employs LLM to evaluate four dimensions of child-oriented content. While “LLM-as-a-judge” is a prevalent evaluation approach today, its reliability remains under investigation. Conducting human evaluations on a small subset of data and calculating consistency with LLM assessments would significantly enhance the credibility of evaluation results."}, "questions": {"value": "- Could you provide more details about the “self-verification” mechanism during dialogue generation? When constructing the dataset, was any form of manual sampling evaluation or qualitative analysis conducted to validate the authenticity and quality of the generated child profiles and dialogues—particularly those used to infer implicit preferences?\n- When using LLM as an evaluator, have you considered or conducted any small-scale human evaluations to validate the accuracy of the LLM's judgments? How do you perceive and address potential biases that may arise from using an LLM to evaluate other LLMs?\n- Experimental results indicate that the LoRA method generally outperforms your proposed PSM in preference consistency. Could you elaborate further on potential scenarios or aspects where PSM might hold advantages over LoRA? For instance, does it exhibit particular strengths in computational efficiency, deployment convenience, or interpretability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TAJS1IGQ36", "forum": "7pz6luKIPw", "replyto": "7pz6luKIPw", "signatures": ["ICLR.cc/2026/Conference/Submission8998/Reviewer_pEdu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8998/Reviewer_pEdu"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8998/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761981030016, "cdate": 1761981030016, "tmdate": 1762920725644, "mdate": 1762920725644, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ChildEval, a novel benchmark designed to evaluate how well LLMs can personalize interactions for children (ages 3-6) by inferring and following their preferences in --possibly long-- conversational settings. The benchmark includes 29K persona profiles, each paired with 6-10 turn dialogues (check Q1 for clarification), covering 5 top-level and 14 sub-level topics related to children's daily lives and development (art, cognitive development, nutrition, language, social-emotional development), in both Chinese and English. The authors propose a comprehensive evaluation framework covering Preference Consistency (Alignment score) and more child-oriented metrics (e.g., Appropriateness). Finally, the authors benchmarked four well-known models (Qwen, LLaMA, DeepSeek, Mistral) on the proposed dataset using three strategies: prompting, LoRA fine-tuning, and a novel architecture called Persona Steer Module. The authors find that the performance of LLMs degrades as irrelevant dialogue turns increase. Adding persona information helps consistency, and fine-tuning the model improves performance with different trade-offs (LoRA vs. proposed approach)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Comprehensive benchmark and with 29K diverse persona profiles and realistic scenarios and diverse topics, and bilingual.\n- Novel evaluation framework, with 4 new child-specific dimensions (EA, IS, DA, EG)\n- Comprehensive evaluation with many SOTA LLMs, different evaluation strategies (prompting, LoRA, Persona Steer Module), long-context evaluation (up to 21K tokens) and several ablation and error analysis."}, "weaknesses": {"value": "- All personas and dialogues are LLM-generated, and there is no verification that synthetic data reflects actual child behavior.\nAuthenticity concerns: May not capture true child communication patterns (e.g., word omissions, semantic errors mentioned but not evidenced)\n- Lack of human evaluation to verify the quality of the proposed evaluation framework and metric. \n\nMinor\n- No comparison with frontier models ( GPT-4, Claude, or Gemini), even on a subset would have being an interesting analysis."}, "questions": {"value": "Q1: how many actual dialogues and turns have being generated?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vq5wEomuAj", "forum": "7pz6luKIPw", "replyto": "7pz6luKIPw", "signatures": ["ICLR.cc/2026/Conference/Submission8998/Reviewer_v1hT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8998/Reviewer_v1hT"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission8998/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762019342992, "cdate": 1762019342992, "tmdate": 1762920724615, "mdate": 1762920724615, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}