{"id": "I5Qgn23qAz", "number": 8175, "cdate": 1758072520073, "mdate": 1759897801783, "content": {"title": "Robust Domain Generalization under Divergent Marginal and Conditional Distributions", "abstract": "Domain generalization (DG) aims to learn predictive models that can generalize to unseen domains.\nMost existing DG approaches focus on learning domain-invariant representations under the assumption of conditional distribution shift (i.e., they primarily address changes in $P(X|Y)$ while assuming the label marginal $P(Y)$ remains stable). \nHowever, real-world data seldom satisfy this assumption.\nMultiple domains often differ in more complex ways, where both the label distribution $P(Y)$ and the conditional distribution $P(X|Y)$ vary simultaneously.\nIn this work, we propose a new framework for robust domain generalization under divergent marginal and conditional distributions. \nWe introduce a novel risk bound for unseen domains by explicitly decomposing the joint distribution into marginal and conditional components and characterizing risk gaps arising from both sources of divergence. \nTo operationalize this bound, we design a meta-learning procedure that minimizes and validates the proposed risk bound across seen domains, ensuring strong generalization to unseen ones. \nEmpirical evaluations demonstrate that our method achieves state-of-the-art performance not only on conventional DG benchmarks but also in challenging Multi-Domain Long-Tailed Recognition (MDLT) settings where both marginal and conditional shifts are pronounced.", "tldr": "Robust DG under concurrent prior and feature shifts. Based on theoretical analysis, we introduce RC-Align, a meta-learning framework that leverages DA loss. We achieved SOTA on both standard DG and MDLT settings.", "keywords": ["Domain Generalization", "Multi-Domain Long-Tailed Learning", "Prior Shift", "Feature Shift", "Meta-Learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0341646692b350792cf1a81855a5bed7fe52f2ab.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper studies domain generalization under a compound shift in both $P(Y)$ and $P(Z|Y)$. A risk bound is provided, which decomposes the generalization gap into 2 parts: a prior shift term consisting of class distribution weighted risks, and a feature shift term consisting of Wasserstein distances between class-conditional feature distributions. Building on this, the paper proposes RC-Align, a meta-learning method that regularizes on a domain-class distribution alignment loss. Experiments on standard DG and MDLT benchmarks show strong average and worst-domain performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* This paper conducts a solid theoretical analysis of the domain generalization error. The decomposition into prior and feature shift terms is intuitive and insightful. The algorithm design is also closely connected with these theoretical impressions.\n* Experimental results show decent performance improvement on both standard DG and MDLT benchmarks."}, "weaknesses": {"value": "* From my current understanding, the current theoretical framework cannot guarantee generalization on an arbitrary target domain. In Theorem 3, the performance depends on the Wasserstein distance between the target data distribution and its best approximation via interpolation between source domains. Hence, it only guarantees generalization under the condition that the target domain is an interpolation of source domains, which is known to be well-resolved by ERM. The cases where the target domain is an extrapolation cannot be handled by the current results. Also, the idea of building generalization bounds via controlling the inter-domain feature distribution alignment is not new.\n* The current hyperparameter selection scheme does not follow the DomainBed standard, which requires a sweep among a predefined joint distribution of all hyperparameters. The learning rate for RC-Align is fixed to 5e-5 as stated, which differs from the standard settings and may result in unfair comparison.\n* The meta-learning scheme and the DA loss design are both borrowed from existing works. The methodological contribution is thus somewhat limited to a combination of existing methods. Also, the meta-learning scheme may introduce a significant computational burden compared to other baselines. This weakness is already acknowledged by the authors, which is good. However, there is no running time/memory comparison provided in the current version, so it is unclear whether the performance improvement is worthwhile with increased computational costs."}, "questions": {"value": "* According to Theorem 3, it seems that it suffices to minimize the empirical risk $R_{D_i}$ on each source domain to achieve generalization, since the second term is intractable under the DG setting. I don't see a clear motivation for why we need additional upper bounds for $R_{D_i}$ in Theorems 1-2, since it can be directly optimized via ERM. Can the authors further explain this point?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Rca6J5YDIM", "forum": "I5Qgn23qAz", "replyto": "I5Qgn23qAz", "signatures": ["ICLR.cc/2026/Conference/Submission8175/Reviewer_Fem2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8175/Reviewer_Fem2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8175/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761078404253, "cdate": 1761078404253, "tmdate": 1762920136372, "mdate": 1762920136372, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenging problem of domain generalisation under compound distribution shifts, where both the marginal label distribution and the conditional feature distribution differ across domains. The authors first derive a new theoretical upper bound, then prove that the practical Domain-Class Distribution Alignment loss can upper-bound the Wasserstein distance term in this bound, enabling a tractable optimisation objective. They propose RC-Align, a meta-learning framework that minimises this composite risk bound through a combination of cross-entropy and DA losses within a leave-one-domain-out training protocol."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper introduces a principled and interpretable risk decomposition that explicitly separates the effects of prior and feature distribution shifts. Empirically verify the correlation between DA loss and generalisation gap, and conduct ablations to show the complementary effects of the DA loss, meta-learning, and Manifold Mixup."}, "weaknesses": {"value": "1. The generalization under concurrent marginal and conditional distribution shifts has been extensively studied in prior works (e.g., Hu et al., 2020; Tan et al., 2024), suggesting that this might not be a critical gap. However, this does not detract from the systemic and insightful theoretical framework presented by the authors.\n\n2. A primary theoretical concern is that the PL condition represents a strong assumption regarding the non-convex loss landscapes inherent to deep neural networks (as acknowledged by the authors in the Appendix). This analysis should therefore be perceived as offering descriptive insights into the algorithm's dynamics within an idealised context, rather than providing stringent guarantees.\n\n3. The DA loss is optimised by comparing feature distances between similar and dissimilar classes, whereas the Wasserstein distance evaluates differences in global distributions. The introduction of intermediate quantities and constants in the proof could render the bound relatively loose. This may reduce the theoretical robustness of the assertion that minimising the DA loss directly equates to minimising feature distribution mismatch.\n\n4.  The analysis presented in Fig. 1 shows a strong correlation between DA loss and the generalisation gap. However, additional ablation studies isolating DA lossâ€™s causal impact on robustness would further substantiate the claim, as potential confounding variables might be present.\n\n5. Table 2 does not include the DomainNet results as presented in Table 3, leading to potential inconsistency in the results representation. Including these results would enhance the comprehensiveness of the analysis."}, "questions": {"value": "1.While the generalization under concurrent marginal and conditional distribution shifts has been explored in previous works, emphasize how your theoretical framework offers a unique perspective or addresses gaps that these studies have not fully tackled.\n\n2. Discuss the implications of the PL condition as a strong assumption in your analysis. Discuss any potential limitations and how these insights can still advance understanding in the field.\n\n3. In regards to optimizing the DA loss, provide further clarification on the role of intermediate quantities and constants in your proof. \n\n4. In response to the suggestion for additional ablation studies in Fig. 1, propose any current or future experiments that could better isolate the causal impact of DA loss on robustness. \n\n5. Explain the discrepancy in the results between Table 2 and Table 3. If available, provide the missing DomainNet results in Table 2."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DYo9IIubRc", "forum": "I5Qgn23qAz", "replyto": "I5Qgn23qAz", "signatures": ["ICLR.cc/2026/Conference/Submission8175/Reviewer_Eovd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8175/Reviewer_Eovd"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8175/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761878232926, "cdate": 1761878232926, "tmdate": 1762920135950, "mdate": 1762920135950, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses domain generalization (DG) under compound distribution shifts where both the marginal label distribution P(Y) and conditional distribution P(X|Y) vary across domains. The authors propose RC-Align, a meta-learning framework grounded in a novel theoretical upper bound that explicitly decomposes generalization risk into prior shift and feature shift components. The method uses a Domain-Class Distribution Alignment (DA) loss combined with cross-entropy in a MAML-style meta-learning procedure. Experiments on standard DG benchmarks and Multi-Domain Long-Tailed Recognition (MDLT) settings demonstrate state-of-the-art performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper provides a clean theoretical decomposition of domain generalization risk into interpretable components (prior shift and feature shift).\n2. Good performance on standard DG and MDLT benchmarks."}, "weaknesses": {"value": "1. While the decomposition is useful, the individual components (domain alignment, meta-learning for DG) are well-established. The main contribution is combining them with theoretical justification, but the theoretical tools (Wasserstein distance bounds, InfoNCE decomposition) are standard.\n\n2. The definition of $\\pi$ in Theorem 1 is missing.\n\n3. Although the theory motivates minimizing Wasserstein feature distance, the implemented DA loss is a heuristic contrastive loss that aligns features with class centroids. The connection between this loss and the Wasserstein bound is qualitative, not quantitative. The actual training objective may not truly minimize the theoretical upper bound."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0ERkvkosjK", "forum": "I5Qgn23qAz", "replyto": "I5Qgn23qAz", "signatures": ["ICLR.cc/2026/Conference/Submission8175/Reviewer_RSKH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8175/Reviewer_RSKH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8175/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972011810, "cdate": 1761972011810, "tmdate": 1762920135040, "mdate": 1762920135040, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}