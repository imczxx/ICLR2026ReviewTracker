{"id": "p6YqLhrdhJ", "number": 12411, "cdate": 1758207621086, "mdate": 1759897511542, "content": {"title": "CountsDiff: A diffusion model on the natural numbers for generation and imputation of count-based data", "abstract": "Diffusion models have excelled at generative tasks for both continuous and token-based domains, but their application to discrete ordinal data remains underdeveloped. We present \\emph{CountsDiff}, a diffusion framework designed to natively model distributions on the natural numbers. CountsDiff builds on the Blackout diffusion framework by simplifying its formulation through a direct parameterization in terms of a survival probability schedule and an explicit loss weighting. This introduces flexibility through design parameters with direct analogues in existing diffusion modeling frameworks.\nBeyond this reparameterization, CountsDiff introduces features from modern diffusion models, previously absent in counts-based domains, including continuous-time training, classifier-free guidance, and churn/remasking reverse dynamics that allow non-monotone reverse trajectories. \nWe propose an initial instantiation of CountsDiff and validate it on natural image datasets (CIFAR-10, CelebA), demonstrating that the framework scales to complex, high-dimensional data domains. We then highlight biological count assays as a natural use case, evaluating CountsDiff on single-cell RNA-seq imputation in a fetal cell and heart cell atlas. Remarkably, we find that even this simple instantiation matches or surpasses the performance of a state-of-the-art discrete generative model and leading RNA-seq imputation methods, while leaving substantial headroom for further gains through optimized design choices in future work.", "tldr": "Diffusion Model for natural numbers, application on images and scRNA-seq imputation.", "keywords": ["generative models", "diffusion models", "data imputation", "computational genomics", "discrete diffusion", "blackout diffusion", "birth death processes"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/59f6a78fb71698cb7ee6fccf4bbe73b326561954.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces **CountsDiff**, a diffusion framework whose state space is the set of natural numbers. The forward process is a continuous-time pure-death birth–death process parameterized by a _survival_ schedule p(t)p(t)p(t); the reverse process is generalized to allow **attrition** (deaths) during sampling, enabling non-monotone trajectories akin to remasking/churn. The objective is a weighted NLL with a principled time weighting; the authors also add predictor-free guidance and propose randomized rounding to avoid small-count collapse. Experiments cover (i) toy sparse counts, (ii) CIFAR-10/CelebA generation, and (iii) scRNA-seq **imputation** (fetal and heart cell atlases), where CountsDiff is competitive with discrete diffusion (ReMDM/D3PM) and specialized imputation baselines."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- *Well written easy and structured:* The forward process and binomial marginals/conditionals are derived cleanly with an intuitive p(t)p(t)p(t) parameterization; the link to Gaussian schedules (via matched SNR) is useful for design transfer."}, "weaknesses": {"value": "- *Novelty*: CountsDiff’s core forward process is a reparameterized pure-death process; the main novelty is the _design space framing_ (survival schedule + weights) and the **attrition** reverse sampler. This is solid but somewhat incremental relative to Blackout diffusion and continuous-time discrete denoising models.\n- *Empirical results:* While the aim isn’t SOTA on CIFAR-10/CelebA, reported FIDs are modest and sometimes worse under cosine schedule without tuning; training steps for CelebA are halved due to compute, weakening claims there."}, "questions": {"value": "- Gaussian diffusion on the toy dataset seems to be unexpectedly bad given that the authors were \"unable to match the performance ..., even by varying model capacity\". Can the authors provide some more details on the setting? And what was used for dequantization (i.e. unfiorm dequnatization, bitwise channel encodings,...)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "6UvCbFluvJ", "forum": "p6YqLhrdhJ", "replyto": "p6YqLhrdhJ", "signatures": ["ICLR.cc/2026/Conference/Submission12411/Reviewer_Mgjp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12411/Reviewer_Mgjp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12411/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761917322860, "cdate": 1761917322860, "tmdate": 1762923306066, "mdate": 1762923306066, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors develop a continuous-time diffusion framework (CountsDiff) that is suited for modeling natural numbers (count data). Specifically, the proposed framework extends a prior model, Blackout diffusion, by introducing features adapted from modern continuous diffusion models, such as continuous-time training, classifier-free guidance, and non-monotone reverse dynamics (attrition). The authors validate the framework on natural images and RNA sequences, showing it can match or outperform a SOTA discrete generative model ."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The formulation of a pure death process as the forward corruption process and a generalized birth-death process (attrition) as the reverse sampling process provides an elegant and principled way of modeling distributions on the natural numbers.\n\n2. The proposed framework successfully bridges the gap between modern Gaussian-based continuous diffusion models and discrete diffusion models in count-based domains, specifically by translating and incorporating powerful techniques such as continuous-time training, classifier-free guidance, and non-monotone reverse dynamics. This greatly unlocks the modeling potential of diffusion models for count data."}, "weaknesses": {"value": "1. The experiments are relatively weak and somewhat unconvincing. Despite all the technical innovations, the experimental results of CountDiff do not fully demonstrate its advantages. For example:\n\n   i. On natural images, there are no other baselines except for the variants of CountDiff itself. It is difficult to tell how well the proposed method performs without a direct comparison to other methods under the same setting (*e.g.*, same model architecture and training steps).\n\n   ii. In Table 1, it seems that to achieve good sampling results (FID and IS), both guidance $\\gamma$ and attrition schedule $\\eta_{\\text{rescale}}$ have to be tuned. It would be helpful to include ablation results showing the individual effect by just changing one of them.\n\n2. The paper fails to mention some highly-relevant prior work [1]. Upon a quick research, it appears that Chen et al. (2023) [1] developed a similar discrete-time forward and backward processes that are suited for modeling count data, which the authors termed binomial thinning and Poisson thickening processes respectively. In [1], an identical loss function was introduced to train the model. However, it does not explicitly acknowledge nor discuss the established foundation laid by this prior work.\n\n[1] Chen, Tianqi, and Mingyuan Zhou. \"Learning to jump: Thinning and thickening latent counts for generative modeling.\" International Conference on Machine Learning. PMLR, 2023."}, "questions": {"value": "1. Although the paper formulates CountDiff as a continuous-time diffusion framework for count data. It is unclear what the additional benefits are to adopt the continuous-time training. Unlike the Gaussian diffusion, to my understanding, CountDiff still have to go through a fixed number sampling steps as described by Algorithm 2. Consequently, the major drawback of slow sampling remains unresolved in this new framework.\n\n2. Can the CountDiff be adapted for modeling non-negative continuous data like [1]? In [1], a trick named the Poisson-based data randomization is introduced to handle both natural numbers and non-negative real values.\n\n3. The main quantitative comparison (Table 1) reports the best FID and IS for different combinations of guidance ($\\gamma$) and attrition ($\\eta_{\\text{rescale}}$). Could the authors clarify how to determine a good combination of the two hyperparameters in practice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AoEWCyUn7N", "forum": "p6YqLhrdhJ", "replyto": "p6YqLhrdhJ", "signatures": ["ICLR.cc/2026/Conference/Submission12411/Reviewer_A2oq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12411/Reviewer_A2oq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12411/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962418512, "cdate": 1761962418512, "tmdate": 1762923305613, "mdate": 1762923305613, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a discrete diffusion model that builds off of Blackout diffusion with a reparameterization of the forward process, which enables the large toolkit from Gaussian diffusion (for reals) to be applied in the natural number case. The corresponding denoising process (with generalization over birth-death processes), guidance, and rounding procedures are worked out. On simulated counts, discrete diffusion methods easily capture the data distribution where Gaussian diffusion fails. On CIFAR10, countsdiff produces competitive qualitative and quantitative results. Finally, the authors test the method on imputation for transcriptomics data."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "I will contextualize both my positive and critical comments by acknowledging that I’m not very well versed in the details of existing discrete diffusion methods, and so may not be able to judge the conceptual advances (or the lack thereof) of the current work:\n\n- the paper tackles an important problem in developing diffusion models more appropriate for discrete data with an elegant and more general framework building off of existing works.\n- the results are solid, and while not overwhelmingly superior than existing methods, provide some interesting insights on the method, such as the effect of attrition scale on blurring and the newly incorporated noise schedules\n- the paper is overall clearly written with concise language, and clearly motivates the problem being tackled relative to existing solutions"}, "weaknesses": {"value": "- While the framework developed here is elegant, it’s ultimately unclear to me how well it performs compared to existing approaches without the additional proposed generalization. See questions for specific comments. To be clear, I’m not saying that this work is inferior or uninteresting because it does not beat the SOTA on those benchmarks, but that it’s unclear to me as a relatively naive reader what the value of the proposed generalization is aside from conceptual elegance (which I appreciate)"}, "questions": {"value": "- It’s great that the method was validated on simulated data, but it’s somewhat expected to outperform a Gaussian model and that’s not really the interesting comparison here. Are there some synthetic experiments (e.g., with higher dimensional toy data) one can come up with that better emphasize the benefits of the generalization compared to existing discrete diffusion methods?\n\n- Similarly, while qualitative results on CIFAR10 look fine and show the value of guidance, attrition, and a cosine p-schedule, it’s unclear to me how they compare quantitively to existing methods (esp. in Table 1). This may be solved, for example, by simply noting that one of the previous methods (e.g. Blackout) is equivalent to which noise schedule.\n\n- On the RNA seq data as well, the current method is comparable but not clearly superior to existing methods, in particular remasking diffusion. The authors reason why some metrics are less meaningful. But as a non-domain expert, a more explicit demonstration of these points (e.g., via a downstream task) may help the authors’ case."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "r5Ff8zfldd", "forum": "p6YqLhrdhJ", "replyto": "p6YqLhrdhJ", "signatures": ["ICLR.cc/2026/Conference/Submission12411/Reviewer_Pqn8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12411/Reviewer_Pqn8"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12411/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762024682967, "cdate": 1762024682967, "tmdate": 1762923304965, "mdate": 1762923304965, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents CountsDiff, a diffusion framework designed to model distributions on the natural numbers. It builds upon the Blackout Diffusion framework, simplifying its formulation through a direct parameterization in terms of a survival probability schedule and an explicit loss weighting."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Introduces a diffusion framework designed to handle discrete ordinal data using birth/death processes.\n\n- The survival-probability-based parameterization provides a potentially simpler formulation than prior discrete diffusion frameworks.\n\n- The method could be useful for applications such as modeling scRNA-seq data, where count-valued distributions naturally arise."}, "weaknesses": {"value": "- The motivation for applying the method to natural image datasets is unclear and misaligned with the model’s intended domain.\n\n- The novelty relative to existing discrete diffusion models (e.g., Santos et al., 2023) appears limited.\n\n- The presentation and related work discussion are difficult to follow and lack clear differentiation from prior methods."}, "questions": {"value": "I do not understand why CountsDiff is applied to natural image datasets (CIFAR-10, CelebA). Existing Gaussian diffusion models already perform very well, and there is no comparison with these established methods on image datasets. The DDPM paper by Ho et al. (2020) achieved an FID score of 3.17, which is much better than the results reported in Table 1. \n\nThe scRNA-seq data seem to make much more sense for this framework, and the authors also mainly emphasize related work on scRNA-seq in Section 6. Therefore, I think the paper should be significantly revised to make this emphasis much clearer, so that the audience can better understand the main contribution. Moreover, the related work section is unclear—for example, the authors mention that methods such as Forest-Diffusion can also be adapted to the scRNA-seq task, but it is not explained what the limitations of that method are or what advantages the proposed approach offers. In addition, Forest-Diffusion is not included as a baseline in the numerical results.\n\nThe presentation of the proposed method and its novelty compared to existing work such as Santos et al. (2023) are also unclear. It seems that the main difference from Santos et al. (2023) is that this work considers a general schedule p(t), whereas Santos et al. (2023) focuses on the special case of a fixed p(t)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "BAuyKwW7bQ", "forum": "p6YqLhrdhJ", "replyto": "p6YqLhrdhJ", "signatures": ["ICLR.cc/2026/Conference/Submission12411/Reviewer_Dd4F"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12411/Reviewer_Dd4F"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12411/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762058685097, "cdate": 1762058685097, "tmdate": 1762923304602, "mdate": 1762923304602, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}