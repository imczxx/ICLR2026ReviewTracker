{"id": "alEx0sm74l", "number": 14108, "cdate": 1758228593130, "mdate": 1759897389542, "content": {"title": "Compositional Neuro-Symbolic Concepts in Neural Activities", "abstract": "We explore whether human neural responses exhibit compositional structure via NEURONA, a modular neuro-symbolic framework for grounding compositional concepts in neural activity. Leveraging image- and video-based fMRI question-answering datasets, NEURONA learns to map interacting concepts from visual input to patterns of fMRI signals, explicitly modeling their relational structure through hierarchical predicate-argument dependencies. We demonstrate that incorporating these structural priors improves both decoding accuracy and generalization to unseen visual stimuli. Our findings provide support that relational meaning is better explained by guided co-activation across multiple regions, and highlight neuro-symbolic frameworks as promising tools for decoding compositional concepts from neural activity.", "tldr": "A neuro-symbolic framework for grounding compositional concepts in fMRI responses", "keywords": ["concept grounding", "neural decoding", "neuro-symbolic systems"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7a3a2f116c41660624a63d385b00bda203e536da.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The MS introduces a neuro-symbolic fMRI-QA framework that links unary (objects) and relational (predicates) concepts to brain-region embeddings. They show that argument-guided learning of the predicates (i.e., conditioning on subject/object) improves decoding, especially for action/position queries. This is an interesting result indicating the system is role-sensitive and is learning from brain data something like event representations rather than argument-agnostic predicate maps. \n\nNote: I assess the work mainly for its **value in advancing understanding of brain data and brain-research methods**, rather than for engineering improvements in QA performance from fMRI decoders."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The system learns in a way that understands event semantics, i.e., decoding what is the subject doing to the object.  in fact, while the framing of the work is in terms of learning relational concepts, but I think it's equally fair to say they are learning event semantics, which are driven by relations applied to objects, and the objective is to learn the general semantics. \n2. The findings implicitly supports the neurobiological position *against* searching for a general (neurobiological) concept-brain-location in a context independent way, but conditionalizing it on the subject/predicate. This has a major implication for theories that aim to identify brain regions for 'verb meaning' independent of context\n3. The neuro-symbolic decomposition is clear and the MS is readable beyond the neuro-symbolic community."}, "weaknesses": {"value": "* There is a main limitation for using the results to inform brain studies, grounded in the use of *Atlases*: using an atlas as the feature basis can (*i*) induce correlations among features because of spatial smoothing and parcellation choices (e.g., 2 brain areas might encode the image in the same way introducing collinearity among features), and (*ii*) allocate variance to parcels that are not informative with respect to the task domain, which limits interpretability and statistical sensitivity. \nTo my thinking, a better, domain-aligned approach is to start from image-by-voxel data and apply PCA (or other dimensionality reduction; e.g., dictionary learning) prior to training. This would match the feature space to the dataset, perhaps increase precision, and certainly provide more information on distributed brain networks relevant to the concepts. Currently, interpretation is forced to be in the Atlas domain, which is not a state of art basis for brain representations."}, "questions": {"value": "I was wondering if the predicate representation in the unguided setting contains decodable information about the object arguments. If that is the case, it would hint that the predicate embedding/code binds to specific objects."}, "flag_for_ethics_review": {"value": ["Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "details_of_ethics_concerns": {"value": "The study decodes brain representations form single participants and can, in principle, read out information about novel contents from new participants. This risk however is generic to brain decoding. Here, the datasets are public and not especially sensitive, which mitigates immediate concerns. \n\nStill, a brief ethics statement specific to the architecture would help, to clarify intended use, potential of abuse if used to construct single-person fingerprinting based on the data, and indicating considerations to guard against malicious use, e.g., mapping the features learned per participant to sensitive data."}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "K0JxdB7d1d", "forum": "alEx0sm74l", "replyto": "alEx0sm74l", "signatures": ["ICLR.cc/2026/Conference/Submission14108/Reviewer_U1Ce"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14108/Reviewer_U1Ce"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14108/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761912795787, "cdate": 1761912795787, "tmdate": 1762924579233, "mdate": 1762924579233, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a neuro-symbolic framework for compositional concept grounding and reasoning using fMRI data. The model aims to decode not only object-level but also relational representations from regional brain activity. The authors evaluate NEURONA on 2 visual fMRI dataset, showing improved decoding and question-answering performance compared to previous fMRI decoding methods (SDRecon, BrainCap, UMBRAE). The work further analyzes the impact of multi-region grounding and relational reasoning through ablation studies.\n\nOverall, the paper is conceptually interesting and methodologically competent, but the empirical depth is relatively limited in statistical validation and subject generalization, and the interpretive link between symbolic composition and neural mechanisms could be made more rigorous. . Additional analyses are highly encouraged."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well motivated to tackle the puzzle of interpretable concept grounding in neural data, with an emphasis on compositional structure.\n2. The results are consistent across two datasets and multiple concept types.\n3. The ablation analyses meaningfully test hypotheses about region-level grounding and compositional generalization.\n4. It positions neuro-symbolic modeling as a promising route to study structured neural semantics beyond pixel-level reconstruction."}, "weaknesses": {"value": "1.The results in Tables 1–2 are trained and tested on one subject per dataset, which limits generalizability. Multi-subject or cross-subject validation is essential for neuroscientific conclusions.\n2. Grounding is restricted to coarse atlas parcels; voxel-level analyses would strengthen claims about spatial specificity of “modular concepts.”\n3. Results in table 1 and 2 are using models trained from one subject in each dataset\n4. It remains unclear how much each region or network contributes to concept decoding; e.g., whether “multi-region grounding” corresponds to interpretable brain modules.\n5. While means ± SD are reported, formal statistical tests are absent, so robustness to inter-individual variability is uncertain.\n6. Without ground-truth region–concept pairs, “consistent” grounding might reflect network-level co-activation rather than explicit compositional structure.\n7. Qualitative examples are interesting but could be complemented by quantitative measures (e.g., concept-wise accuracy)\n8. Writing is generally clear, though sections 3–5 are dense and occasionally repeat prior claims; discussion could better delineate cognitive vs. computational interpretations."}, "questions": {"value": "1. Have you tried cross-subject evaluations?\n2. In the multi-region grounding setup, is there any redundancy or competition between regions (e.g., correlated activations leading to similar grounding weights)?\n3. How consistent are the learned concept groundings across subjects — do similar regions emerge for the same concept?\n4. Do claims of compositional grounding align with theories of hierarchical organization of the brain?\n5. How might this framework extend to other domains (e.g., motor planning)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "B1hF1uKZFn", "forum": "alEx0sm74l", "replyto": "alEx0sm74l", "signatures": ["ICLR.cc/2026/Conference/Submission14108/Reviewer_FGNG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14108/Reviewer_FGNG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14108/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761932156024, "cdate": 1761932156024, "tmdate": 1762924578715, "mdate": 1762924578715, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes NEURONA, a neuro-symbolic framework for grounding compositional concepts in neural activity using fMRI data. The approach extends Logic-Enhanced Foundation Model (Hsu et al. 2023) to fMRI-based question answering, testing different hypotheses about how concepts are grounded in brain regions through hierarchical predicate-argument dependencies. The authors demonstrate improved decoding accuracy on constructed fMRI-QA datasets derived from BOLD5000 and CNeuroMod, showing particular gains on compositional queries involving actions and spatial relationships.\n\nThe version of the paper as of now should be rejected because (1) the central claims about discovering compositional organization in the brain are not well supported by the evidence, (2) the experimental design conflates task performance improvements with evidence of neural representational structure, (3) the \"grounding\" methodology does not actually demonstrate meaningful concept-to-brain mappings, and (4) key claims about compositionality lack proper validation through decomposability or systematic structural tests. The technical framework represents a potentially valuable contribution to neural decoding, but the interpretive claims about brain organization require much stronger evidence than currently provided."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Despite fundamental issues, the paper has notable technical strengths:\n\n1. A well-defined evaluator logic for creating conjunctions that could help in better decoding. \n2. Strong empirical performance: 47% relative improvement over baselines is substantial, and the generalization to unseen compositional queries is genuinely impressive evidence that the learned representations support novel combinations.\n3. Cross-dataset validation: Testing on both image and video datasets with consistent results strengthens the technical contribution."}, "weaknesses": {"value": "1. The Core Interpretive Problem:\n\nThe paper's fundamental flaw is the interpretive leap from 'symbolic structure improves neural decoding' to 'relational meaning in the brain emerges from structured activations guided by hierarchical predicate-argument structure.' The authors consistently conflate improved task performance with evidence of compositional neural mechanisms, but these are different claims requiring different types of evidence.\nThe 'grounding' results are classification logits indicating which brain regions are statistically useful for predicting concept labels—not neural representations in a meaningfully neuroscientific sense. Classification weights in multivariate neuroimaging do not reflect the underlying neural patterns or information content; they indicate statistical utility for discrimination, not representational structure (see Haufe et al. 2014 NeuroImage). True neural representations involve patterns of activity across voxels that can be decoded, analyzed geometrically, and related to cognitive processes. Furthermore, the authors mischaracterize the prior literature on concept grounding. The foundational studies cited (Huth et al., Mitchell et al., Palatucci et al.) use forward encoding models that predict brain activity from semantic features, allowing legitimate claims about neural encoding. The paper should better distinguish its claims from prior work on concept grounding and be more precise about what type of evidence would support compositional neural organization vs. improved decoding.\nThe distinction between functional and representational compositionality should be made explicit early in the paper. The current presentation conflates these concepts (e.g., see Lake & Baroni 2018 ICML)\n\n2. Experimental Design Issues:\n\nThe datasets retrofit compositional reasoning onto passive viewing data without evidence that participants were performing compositional operations. BOLD5000 participants simply viewed images—they were not actively reasoning about spatial relationships or compositional structure. The \"ground truth\" comes from automated scene graph parsing, not actual participant cognition. This creates a fundamental disconnect between the experimental setup and claims about compositional cognition in the brain. The danger is that improved decoding may simply reflect visual feature correlations rather than compositional neural processes - without evidence that participants engaged compositional reasoning, there's no basis for compositional interpretations of the neural patterns.\nWithout participants actively performing compositional reasoning during scanning, there is no basis for claiming that improved decoding of these post-hoc questions reflects compositional neural organization. The authors need to demonstrate that participants were actually engaging compositional processes, not just that symbolic priors help classify brain signals.\n\nThe dataset construction follows machine learning conventions (scene graphs → QA tasks) which is appropriate for developing better reasoning systems. However, this methodology is insufficient for claims about brain organization. Without experimental evidence that participants engaged compositional reasoning during scanning, improved decoding of post-hoc compositional questions cannot support claims about compositional neural mechanisms. The authors are applying machine learning validation criteria (task performance) to neuroscientific claims (brain organization) without the experimental controls required for the latter.\nBoth the issues 1 and 2 could be addressed if voxel/region-wise encoding models (akin to Huth et al.) could be constructed for the concepts from the scene graph parsing and the predicted responses corresponding to the concepts from the model can be treated as grounding/representations and the rest of methodology could be applied (transformation into unary and binary embedding space and executor logic).\n\n3. Missing Evidence for Compositionality:\n\nWhile the paper implements compositional operations in its executor, it does not demonstrate compositional neural representations. Key missing evidence includes:\n\n3.1 Decomposability: True neuro-symbolic compositional systems (tensor products, vector symbolic architectures) maintain constituent structure that can be systematically recovered through inverse operations. In contrast, the executor combines groundings through non-invertible operations that destroy constituent information. There is no principled way to recover individual concept groundings from the final compositional output, demonstrating that the system implements functional composition without compositional representation. I consider the evaluator logic is a good conjunction recipe but not sure about neuro-symbolic composition though given lack of invertibility. And given that it resembles conjunctive representations, I wasn’t surprised that H5 showed greatest evidence.\n\n3.2 Systematic decomposition: While the authors demonstrate generalization to novel combinations by ensuring disjoint train/test sets, they lack fine-grained analysis of systematic recombination patterns. True compositionality requires systematic relationships between constituents and compounds across all concept types - for example, if the system learns holding(person, bat) and beside(person, tree), it should systematically handle holding(person, tree) and beside(person, bat) with predictable performance relationships. The paper shows aggregate performance on unseen combinations but doesn't analyze whether learned representations support the algebraic manipulation of concepts that characterizes genuine compositional systems. While dataset constraints may limit the extent to which systematic recombination tests are feasible, the authors don't report what subset of such analyses their data could support or acknowledge these limitations when making compositionality claims. Without demonstrating systematic performance patterns across specific recombination types (argument swapping, predicate transfer, role systematicity), the generalization results, while impressive, don't constitute strong evidence for compositional representation.\n\n4. Methodological Concerns:\n\nThe consistency metric (how often concepts ground to same regions) is presented as validation, but high consistency could simply reflect stable solutions to the classification task rather than meaningful neural organization (similar to the Haufe et al. critique above). Without independent validation against known neuroscience or comparison to null models with random concept assignments, these results cannot support claims about brain organization."}, "questions": {"value": "1.\tCan the authors implement encoding models built from the parsed concepts and use them as grounding/representations?\n2.\tIf strong claims about neurosymbolic representations are to be made: Can fine-grained systematicity tests be done? Is it possible for the evaluator to be inverted to make the output decomposable after binding?\n3.\tCan better null models be used (with random concept assignments)?\n4.\tIf your answer is no to points 1 and 2, can the focus be changed to methodological contribution and decoding improvements rather than strong claims about brain organization?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "v8eDhKAjqV", "forum": "alEx0sm74l", "replyto": "alEx0sm74l", "signatures": ["ICLR.cc/2026/Conference/Submission14108/Reviewer_RD4u"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14108/Reviewer_RD4u"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14108/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761947208161, "cdate": 1761947208161, "tmdate": 1762924578095, "mdate": 1762924578095, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes NEURONA, a neuro-symbolic framework for decoding compositional concepts from fMRI by parsing each visual stimulus into a symbolic expression (e.g., predicate–argument relations) and grounding its unary and relational concepts to candidate neural entities derived from cortical parcellations. The authors focused on using QA accuracy as the proxy for concept groundings capabilities. The proposed approach extends LEFT to fMRI-QA so that weak supervision from question-answer pairs can train disentangled concept groundings and an end-to-end executor that composes those groundings to answer queries. The authors conduct experiments to show that the proposed method improves accuracy and generalizes to unseen compositions on BOLD5000-QA and CNeuroMod-QA."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "I am not familiar with tasks with fMRI, but to the best of my knowledge the framework is new in bringing predicate–argument guidance into an fMRI-QA decoder and testing it via five alternatives within one executor.\n\nThe overall evaluation setup looks correct to me: the compositional split is appropriate; train and test use disjoint entity–relation pairs, so it measures true generalization. The ablations are clean and isolate the source of gains: unguided multi-region grounding adds little over a single region, while subject/object guidance and full guidance help most, especially for actions and spatial queries. Results are robust and strong across multiple cortical atlases. The qualitative maps are sensible and aid interpretation. \n\nOverall I think the paper is overall clearly written and the ideas are intuitive to understand despite my unfamiliarities with fMRI-related tasks."}, "weaknesses": {"value": "The primary concern is the novelty about the proposed approach. \n\nThe proposed method assembles known pieces: a LEFT-style executor, VLM-derived scene graphs, and standard cortical parcellations. The main new element is predicate–argument guidance and the within-executor hypothesis family that tests it. I acknolwedge that these are thoughtful design choices, but they are not a new model class or theory. That said, the paper still adds value: it gives a clean empirical test of the idea, uses a compositional split that rules out memorization, and offers consistency and cross-atlas checks that others can reuse. \n\nIn short, the work is incremental in mechanism yet still useful in evidence and evaluation protocol for the research commnuity."}, "questions": {"value": "Since fillers ultimately come from token sequences, I am wondering have the authors thought about how robust are role actions to multi-token fillers or subword boundary changes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "fUCjUWqejJ", "forum": "alEx0sm74l", "replyto": "alEx0sm74l", "signatures": ["ICLR.cc/2026/Conference/Submission14108/Reviewer_fNVL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14108/Reviewer_fNVL"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14108/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761953207495, "cdate": 1761953207495, "tmdate": 1762924577633, "mdate": 1762924577633, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}