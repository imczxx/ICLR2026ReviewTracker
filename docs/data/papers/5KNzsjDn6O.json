{"id": "5KNzsjDn6O", "number": 16528, "cdate": 1758265608312, "mdate": 1759897234963, "content": {"title": "DART: Difficulty-Adaptive Reasoning Truncation for Efficient Large Language Models", "abstract": "Adaptive reasoning is essential for aligning the computational effort of large language models (LLMs) with the intrinsic difficulty of problems. Current chain-of-thought methods boost reasoning ability but indiscriminately generate long explanations, leading to evident inefficiency. However, existing reinforcement learning approaches to adaptive thinking remain unstable and heavily reward-dependent. Here we propose DART, a supervised Difficulty-Adaptive Reasoning Truncation framework that adjusts thinking length according to problem difficulty. By distilling concise reasoning patterns from stronger models, interpolating them into a continuum of reasoning styles, and curating optimal training data that balances correctness and compactness, DART learns when to ''stop thinking''. Across multiple mathematical benchmarks, experimental results demonstrate its remarkable efficiency while preserving or improving accuracy, achieving a significant 81.2% reasoning truncation (DeepSeek-R1-Distill-Qwen-7B on GSM8K dataset) with 5.33x computational acceleration. DART provides a stable and general paradigm for efficient reasoning, advancing the development of adaptive intelligence in LLMs.", "tldr": "", "keywords": ["Adaptive Reasoning", "Difficulty-Aware", "Efficient LLM"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a54d175c427f8c15f17c0fcac6102027b6760d2f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The main idea is to propose the DART framework, which implements Difficulty-Adaptive Truncation through a complete SFT framework, enabling the model to answer simple questions quickly and think more deeply about complex problems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The authors empirically identify and formalize the sigmoid-shaped relationship between reasoning length and accuracy, which provides a theoretical motivation for adaptive truncation. This insight contributes a valuable quantitative characterization of the “optimal reasoning length” phenomenon, offering a foundation for subsequent research on reasoning efficiency.\n2. Unlike RL-based methods, which are notoriously sensitive to reward shaping and initialization, DART achieves adaptive reasoning entirely through supervised fine-tuning. This yields greater training stability, reproducibility, and easier integration with existing LLM infrastructure, an important practical advantage for scaling and deployment."}, "weaknesses": {"value": "1. The proposed framework distills reasoning chains and subsequently selects the shortest correct CoT as the sole supervision signal. While this efficiently reduces token redundancy, it inevitably drives the model toward a single canonical reasoning pattern. This may suppress the natural diversity of reasoning trajectories that could otherwise contribute to robustness and creativity. In tasks requiring exploratory or multi-path reasoning, such as open-domain problem-solving or commonsense inference, this rigid supervision could cause premature convergence toward a single logic template, thereby missing potentially valuable intermediate reasoning paths.\n2. The interpolation fusion between base and distilled models relies on empirically chosen coefficients (α), which are sampled discretely between 0 and 1. However, the choice of step size and distribution lacks theoretical justification or formal analysis of convergence properties. The paper demonstrates smooth behavior empirically, but does not establish why linear parameter interpolation should produce semantically coherent intermediate reasoning styles. This makes the fusion spectrum somewhat heuristic and architecture-dependent, weakening claims of theoretical robustness or generalizability beyond the tested model families.\n3. The adaptive data curation pipeline requires an explicit correctness signal for filtering valid CoTs. This assumption restricts the method to closed-form reasoning tasks with well-defined answers. Consequently, DART cannot be directly extended to open-ended tasks, such as dialogue, writing, or scientific hypothesis generation. The framework would thus benefit from a broader definition of “reasoning sufficiency” that does not rely solely on exact-match evaluation.\n4. Since the framework rewards shorter reasoning when correct, there exists a bias toward brevity even when longer reasoning might improve interpretability or error recovery. Without a mechanism to penalize premature truncation, the adaptive model may occasionally terminate too early on out-of-distribution or higher-complexity problems, leading to subtle accuracy degradation or reasoning incompleteness."}, "questions": {"value": "See the Weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "w57Nig0SfU", "forum": "5KNzsjDn6O", "replyto": "5KNzsjDn6O", "signatures": ["ICLR.cc/2026/Conference/Submission16528/Reviewer_pyBf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16528/Reviewer_pyBf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16528/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761908640452, "cdate": 1761908640452, "tmdate": 1762926614514, "mdate": 1762926614514, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents DART, a method for efficient reasoning for LLMs. It introduces a strategy to curate concise data with varying reasoning lengths for problems of different difficulty levels. Specifically, DART distills short reasoning chains from stronger teacher models, then fuses the long/short-reasoning models to create a continuum of reasoning styles (different lengths), and automatically selects the shortest correct reasoning chain for each problem to build an adaptive training dataset. The final model is then finetuned on this curated data to learn when to stop thinking based on problem complexity. The evaluation across various model sizes demonstrates its effectiveness in compressing generation length by up to 81.2% while maintaining or improving reasoning accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The written is straightforward and easy to understand.\n\nThe paper proposes an angle to train efficient LRM basing on different difficulty level.\n\nThe experiments show that the method has some improvements on different models with reduced generation length."}, "weaknesses": {"value": "It is not very clear what's the advantage of using the extrapolation to generate different lengths of response regarding different difficulty levels. I understand that the extrapolation could help to control the length of the generation, which can be further used to select and include the data used for the final training. It is not clear how this extrapolation based data generation method work compared with using the prompt based method to generate different lengths of response. \n\nLack of experimental results. The main idea for this paper is to curate different length of CoT data based on different question difficulty level, and the author noted that methods like tokenskip didn’t consider such difficulties. A most natural baseline to be included is to compare the results with those static methods like tokenskip/lightthinker, which is currently lacking. Another question is why the baselines compared are different on different base models. Only DeepSeek-R1-Distill-Qwen-7B contains the results for other SFT based baselines? It is not clear how the current data curation protocol works without further evaluation on other models compared with other mechanisms. \n\nlightthinker:Thinking Step-by-Step Compression\n\n\nTokenskip Controllable Chain-of-Thought Compression in LLMs"}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "L4KPGtHA52", "forum": "5KNzsjDn6O", "replyto": "5KNzsjDn6O", "signatures": ["ICLR.cc/2026/Conference/Submission16528/Reviewer_WVeW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16528/Reviewer_WVeW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16528/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761933431278, "cdate": 1761933431278, "tmdate": 1762926613780, "mdate": 1762926613780, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a supervised difficulty-adaptive reasoning truncation framework that enables LLM to adjusts thinking length according to problem difficulty dynamiclly. By distilling concise reasoning patterns from stronger models, interpolating them into a continuum of reasoning styles, and curating optimal training data, that balances correctness and compactness, DART learns to alleviate overthinking problem in LRM."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper addresses an important problem, improving reasoning efficiency for large language models\n- The four-step framework (DISTILLING SHORT COTS, interpolation, CREATING A MODEL SPECTRUM, CURATING TRAINING DATA, adaptive training) is clearly structured and easy to follow.\n- The experiments cover several standard mathematical reasoning benchmarks and include analyses on certain hyperparameters, such as fusion coefficients and sampling density"}, "weaknesses": {"value": "- Limited novelty. The idea of adaptive, difficulty-aware reasoning is not new, and prior work, such as CoT-Valve, has already explored similar strategies for interpolating model weights and curating adaptive data based on correctness.\n- The method appears less effective on DeepSeek-R1-Distill-Qwen-7B. On benchmarks such as GSM8K, MATH-500, and OLYMPAID, the generated token length is reduced, but the accuracy also drops.\n- The short-CoT data generated from DeepSeek-R1-Distill-Qwen-7B is important to the framework, yet the paper provides little analysis of its quality or length comparison. Conceptually, the method relies on the same model to generate compressed reasoning traces and subsequently distills itself on this data, but the rationale for why such a self-distillation loop should be effective is unclear. Including a comparison with existing token-compression methods, such as Selective Context used in TokenSkip, would help clarify the discussion.\n\n[1] CoT-Valve: Length-Compressible Chain-of-Thought Tuning\n\n[2] Compressing context to enhance inference efficiency of large language models.\n\n[3] TokenSkip: Controllable Chain-of-Thought Compression in LLMs"}, "questions": {"value": "- Could the authors clarify how the proposed framework differs from prior adaptive reasoning methods such as CoT-Valve?\n- For experiments on DeepSeek-R1-Distill-Qwen-7B, token usage decreases, but accuracy also drops. Could this degradation be caused by generating the short-CoT data using the same model?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gJve9shGPq", "forum": "5KNzsjDn6O", "replyto": "5KNzsjDn6O", "signatures": ["ICLR.cc/2026/Conference/Submission16528/Reviewer_DU6L"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16528/Reviewer_DU6L"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16528/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761987407067, "cdate": 1761987407067, "tmdate": 1762926613399, "mdate": 1762926613399, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the issue that chain-of-thought (CoT) reasoning often produces unnecessarily long reasoning traces, regardless of the intrinsic difficulty of a problem. To address this problem, the paper proposes DART, a framework that trains a model on optimal reasoning chains collected through a pipeline. Specifically, a base model generates long reasoning chains, while a teacher model converts them into shorter chains. Model fusion is then applied to interpolate between these two models, creating a continuum of models capable of producing intermediate-length reasoning chains. Finally, a training set is constructed from the shortest correct reasoning chains, which is used to train the final model for more efficient reasoning."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper focuses on an important problem—the inefficiency of CoT. The proposed framework is presented as modular and is conceptually sound."}, "weaknesses": {"value": "-\tClarity issues. Some parts of the methodology are not clearly explained. For example, it is unclear how the distillation teacher model shortens long reasoning chains and how this process affects the quality of the reasoning paths. Additionally, the paper does not discuss how the quality of the generated reasoning chains is controlled or verified.\n-\tLimited novelty. The proposed method essentially involves collecting question-answer pairs with varying reasoning lengths and using this dataset to train a model. While practical, the technical novelty is fairly limited.\n-\tComputational cost. Using a base model, a teacher model, and creating a continuum of models to obtain reasoning chains of varying lengths appears computationally expensive. It would be useful to consider whether a single model could produce different reasoning lengths using prompting or other steering techniques.\n-\tPerformance drop. While the method reduces the number of output tokens, performance drops on several datasets, suggesting that shorter reasoning chains may not always preserve reasoning quality.\n-\tAlthough the approach is described as difficulty-aware, the final trained model does not explicitly identify the difficulty of a given input or adapt the reasoning process accordingly.\n-\tLimited evaluation. The evaluation is restricted to mathematical reasoning tasks, which limits the generalizability of the findings."}, "questions": {"value": "-\tWould the framework generalize to reasoning tasks beyond mathematics?\n-\tWould it be possible to use a single model to produce reasoning chains of different lengths using prompting or other steering techniques?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PkX1dvzoQp", "forum": "5KNzsjDn6O", "replyto": "5KNzsjDn6O", "signatures": ["ICLR.cc/2026/Conference/Submission16528/Reviewer_dE18"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16528/Reviewer_dE18"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16528/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762238834664, "cdate": 1762238834664, "tmdate": 1762926613065, "mdate": 1762926613065, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}