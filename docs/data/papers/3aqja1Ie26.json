{"id": "3aqja1Ie26", "number": 9270, "cdate": 1758116836407, "mdate": 1759897734287, "content": {"title": "Learning Medium-Sensitivity Functions: A Case Study on QR Code Decoding", "abstract": "The hardness of learning a function that attains a target task relates to its input-sensitivity. For example, image classification tasks are input-insensitive as minor corruptions should not affect the classification results, whereas arithmetic and symbolic computation, the learning of which has been recently attracting interest, are highly input-sensitive as each input variable connects to the computation results. \nThis study investigates the learning functions of medium sensitivity through learning-based Quick Response (QR) code decoding, which has both sensitivity to the change of plain texts and insensitivity to the bit flips. \nOur experiments reveal that Transformers can robustly decode QR codes, even beyond the theoretical error-correction limit, while remaining sensitive to single‑character changes in plain texts. We demonstrate that the robust decoding ability is derived from the regularity of natural language words. Transformers trained on English-based datasets learn to exploit it. Interestingly, this generalizes to words in different languages and to random alphabetical strings. To our knowledge, this study provides the first case study of learning medium-sensitivity functions and also suggests potential applications of learning-based QR code decoding that boost classical methods in combination.", "tldr": "Transformer learning ability of mid-sensitivity functions, particularly QR-code decoding, is examined.", "keywords": ["Input-Sensitivity", "Transformer", "QR Code", "QR Code Decoding"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d4874b68844c816ff7380bd0b51689e9c3ea6739.pdf", "supplementary_material": "/attachment/38843396acb0c5dece2ca8288883fea022ce9ec4.zip"}, "replies": [{"content": {"summary": {"value": "The paper studies how Transformers perform on QR code decoding. The authors first train a model to identify the mask pattern and then use a Transformer to decode the QR data. They find that Transformers remain robust under bit-flip noise even without using error-correction codes, achieving performance beyond the theoretical limit. The authors suggest that this robustness comes from the model’s ability to capture language structures, as shown by the variation in decoding success across different languages. This implies that Transformers may correct some intentional misspellings in QR codes."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper explores an interesting and relatively unexplored task. The authors evaluate the model’s performance across different mask patterns and provide an insightful analysis of why Transformers can surpass classical decoding algorithms and even exceed theoretical performance limits."}, "weaknesses": {"value": "The task is interesting, but I am concerned about the level of difficulty. Since Reed–Solomon doesn’t modify the original URL codewords, a Transformer is effectively learning to ignore irrelevant components (function patterns, err correction words) and to map 8-bit codewords back to characters. Its apparent error-correction ability comes from modeling language structure rather than true parity-based correction."}, "questions": {"value": "(1) What's the architecture/size of the mask-classification model?\n(2) Is a 12-layer Transformer unnecessarily large for retrieving a short URL, which typically consists of only a few words or tokens? A smaller or shallower model might achieve similar performance with far less computational cost."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xtuN8oJ0C3", "forum": "3aqja1Ie26", "replyto": "3aqja1Ie26", "signatures": ["ICLR.cc/2026/Conference/Submission9270/Reviewer_pS7C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9270/Reviewer_pS7C"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9270/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761862898171, "cdate": 1761862898171, "tmdate": 1762920917485, "mdate": 1762920917485, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a case study on learning medium-sensitivity functions through the task of QR code decoding. The authors construct several URL datasets and employ a standard Transformer architecture and training strategy. Experimental results show that Transformer-based QR code decoding achieves a high success rate, demonstrates robustness to various levels of corruption, and generalizes beyond English-rich data to other languages. This study provides insights into the potential of learning-based approaches for medium-sensitivity tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well written and easy to follow. The motivation for studying medium-sensitivity functions is clearly articulated.\n\n2. The ablation study is comprehensive, covering different mask patterns and corruption types, including flip and burst errors."}, "weaknesses": {"value": "1. While QR code decoding is an interesting example and the ablation studies are detailed, the overall scope of the paper is narrow. It is unclear how the findings can be generalized to a broader set of medium-sensitivity tasks.\n\n2. The evaluation is limited. The impact of model architecture is not explored, and the test set consists of only 1,000 samples, compared to 500,000 training samples. Increasing the diversity and size of the test set would help validate the generality of the results."}, "questions": {"value": "1. Is it possible to use a hybrid input order? For example, Table 1 shows the effects of row and column ordering. Could a combined strategy, such as block-wise or diagonal ordering, be beneficial? Could the performance differences be attributed to positional embeddings?\n\n2. It is notable that a learning-based method can achieve high success rates in QR code decoding. Are there other real-world applications of medium-sensitivity functions where such methods could be applied? Can the learned model generalize to these other tasks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "P206sExF7J", "forum": "3aqja1Ie26", "replyto": "3aqja1Ie26", "signatures": ["ICLR.cc/2026/Conference/Submission9270/Reviewer_qpnk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9270/Reviewer_qpnk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9270/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761939072705, "cdate": 1761939072705, "tmdate": 1762920917119, "mdate": 1762920917119, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This submission is about using transformers to decode QR codes. The overall takeaway is that the models learn to do this extremely well.\n\nThe work is pitched as the first study into learning what the authors term *medium-sensitivity* functions. This does not seem to be formally defined, but they compare with parity learning (high sensitivity) and image classification (which they call low sensitivity)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The experiments seem interesting and I expect this work will be turned into a solid contribution in the future."}, "weaknesses": {"value": "The authors have missed key prior work. I found a blog post [1] and Github repo [2] on learning neural networks to decode QR codes specifically. \n\nI am not an expert, but there appears to be decades of work on using neural networks to decode error-correcting codes [3,4] and more recent work that includes training [5,6].\n\nIt seems that a major revision is required.\n\n[1] [https://medium.com/@andrewromanenco/decoding-qr-codes-using-neural-networks-272f9e8ba635](https://medium.com/@andrewromanenco/decoding-qr-codes-using-neural-networks-272f9e8ba635)\n\n[2] [https://github.com/Brainydaps/AI-QR-Code-Decoder](https://github.com/Brainydaps/AI-QR-Code-Decoder)\n\n[3] Yuan, Jing, and C. S. Chen. \"Neural net decoders for some block codes.\" IEE Proceedings I (Communications, Speech and Vision) 137.5 (1990): 309-314.\n\n[4] Yuan, Jing, V. K. Bhargava, and Q. Wang. \"An error correcting neural network.\" Conference Proceeding IEEE Pacific Rim Conference on Communications, Computers and Signal Processing. IEEE, 1989.\n\n[5] Beery, Yair, David Burshtein, and Eliya Nachmani. \"Deep learning decoding of error correcting codes.\" U.S. Patent Application No. 15/996,542.\n\n[6] Choukroun, Yoni, and Lior Wolf. \"Error correction code transformer.\" Advances in Neural Information Processing Systems 35 (2022): 38695-38705."}, "questions": {"value": "Can you give a mathematical definition of \"medium-sensitivity function\"?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MEgScvw3cG", "forum": "3aqja1Ie26", "replyto": "3aqja1Ie26", "signatures": ["ICLR.cc/2026/Conference/Submission9270/Reviewer_v7oJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9270/Reviewer_v7oJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9270/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762112114109, "cdate": 1762112114109, "tmdate": 1762920916793, "mdate": 1762920916793, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a rigorous empirical and theoretical study of learning medium-sensitivity functions through Transformer-based QR code decoding. It formalizes QR decoding as an intermediate sensitivity task—sensitive to text changes but robust to bit-level noise—and derives a novel analytical model for the Reed–Solomon success rate under corruption. Experiments demonstrate that Transformers not only exceed the theoretical error-correction limits but also generalize across languages and random strings, exploiting statistical regularities of natural words. \nThis work bridges sensitivity theory and deep learning, revealing how attention models perform hybrid symbolic–robust computations."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- Introduces a novel conceptual framework of medium-sensitivity learning, formalizing an intermediate regime between robustness and semantic invariance in neural models.\n\n- Provides a theoretically grounded link between Transformer behavior and Reed–Solomon coding limits, extending information-theoretic analysis to neural error correction.\n\n- Presents quantitative evidence that Transformers can exceed classical decoding thresholds, revealing emergent redundancy exploitation beyond explicit code design.\n\n- Demonstrates broad empirical validity across synthetic and linguistic datasets, supporting both the theoretical model and its generalization to real-world settings."}, "weaknesses": {"value": "- The theory assumes idealized noise and independence, which may not reflect real Transformer behavior.\n\n- Experiments are limited in scale and domain, so generalization beyond controlled settings is unclear.\n\n- Computational cost and scalability are not discussed, leaving practical applicability uncertain."}, "questions": {"value": "1. How does your medium-sensitivity framework connect to known notions of robustness or Lipschitz continuity, and can it be quantified by model capacity or gradients?\n\n2. How does the mathematical formulation of medium-sensitivity generalize beyond the discrete symbol space—can the same definitions and bounds be extended to continuous vector spaces where distance and corruption are not count-based?\n\n3. Can your Reed–Solomon analysis handle non-linear or data-dependent noise, and how would that change the theoretical limits?\n\n4. What kinds of failure cases did you observe, and what do they reveal about the limits of medium-sensitivity learning?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1TyKRtcXUH", "forum": "3aqja1Ie26", "replyto": "3aqja1Ie26", "signatures": ["ICLR.cc/2026/Conference/Submission9270/Reviewer_eM4m"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9270/Reviewer_eM4m"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9270/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762339096269, "cdate": 1762339096269, "tmdate": 1762920916170, "mdate": 1762920916170, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}