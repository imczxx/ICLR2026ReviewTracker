{"id": "J9VRPrhwjM", "number": 21239, "cdate": 1758315288350, "mdate": 1759896932698, "content": {"title": "SteelNet: Multimodal Representation Learning for Industrial Process Optimization", "abstract": "Steel rolling mills must continuously monitor various sensors like vibration probes, thermocouples, and flow meters to ensure safe operations and maintain product quality. However, the harsh industrial condition sometimes lead to sensor failures, unclear signals, and incomplete data. Traditional monitoring systems often struggle in these environments, makes it challenging to detect early signs of problems and predict failures. To this end, we propose SteelNet: A Multimodal Representation Learning Framework designed for robust learning from various industrial sensor data. SteelNet incorporates the cross-modal alignment and modality dropout strategies that enable consistent representation learning even when modalities are partially missing. The core problem being solved is improving equipment availability and optimizing process parameters. This framework allows for the early detection of critical events by combining information from multiple sensors, and effectively handling missing or data, which are common in industrial environments. By improving the reliability of anomaly detection and predictive insights, SteelNet not only strengthens fault tolerance but it also support better decision making in the process optimization. Although developed for steel rolling mills, it's applicability extends to real-world scenarios and other industry setups.", "tldr": "", "keywords": ["Multimodal Representation Learning", "Cross-Modal Alignment", "Steel Rolling Mills", "Deep Learning", "Casual Inference"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/941f48bca38a5f22438f3984454eb05d2c8576b9.pdf", "supplementary_material": "/attachment/9402892e9da3bc2b5e907cbf9c3819490d2d3e7a.zip"}, "replies": [{"content": {"summary": {"value": "This study proposes SteelNet, a multimodal learning framework that jointly uses images and sensor data to predict defect types and analyze their underlying causes on steel surfaces. Specifically, SteelNet integrates an image encoder and a sensor encoder, where a classification head predicts defect types and an attribution network effectively identifies the contributions of multiple sensors. Moreover, the framework uses modality dropout and incorporates physics-informed constraints to address the modality-absence problem in steel manufacturing processes. Experimental results demonstrate that SteelNet achieves robust performance and provides interpretable insights into the causal relationships between sensors and defects."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1) The proposed framework extends multimodal modeling to the steel domain for defect detection and its interpretability, which are crucial in steel manufacturing.\n2) This study defines and addresses the modality-absence problem, which has not been considered in previous research. To tackle this issue, the study uses dropout and effectively simulates missing modalities.\n3) To demonstrate the effectiveness of SteelNet, this study generated simulation data that were designed to reflect real-world conditions, including sensor-absence scenarios where certain sensors were not recorded or became unavailable."}, "weaknesses": {"value": "[Method]\n1) This method does not meet the standards for publication at a top-tier AI conference. While the attempt to integrate multimodal representation learning with causal interpretability is conceptually sound, the proposed components such as the parameter encoder, multi-task prediction heads, and the attribution loss with sparsity regularization rely on widely used techniques from existing studies. Moreover, the physics-informed constraint is formulated as a simple supervised learning framework rather than offering a novel algorithmic innovation.\n2) The description of the method section is insufficient and requires more detailed explanation. For example, definitions of the attribute loss and the sparsity loss are missing.\n\n[Experiments & Results]\n1) The proposed method is not compared with existing studies. Although it achieves relatively high accuracy, it is difficult to determine whether the model truly outperforms prior approaches without comparative evaluation.\n2) The paper does not include experiments on real-world data. Although these limitations are clearly stated, it is difficult to validate real-world applicability using solely generated dataset. Moreover, the comparison between real and simulated data mentioned in Appendix relies only on a few statistical indicators, making it somewhat weak. The authors should either (1) add experiments based on real data, or (2) provide stronger evidence that the simulated data is indistinguishable from real data.\n3) The explanations for each figure and table in results are insufficient. For example, there is no detailed analysis or discussion related to Figure 3, and Figure 4 does not specify which defect class it represents. Providing clearer and more detailed explanations for each figure and table would greatly improve the readers’ understanding of the paper."}, "questions": {"value": "1) Why did the proposed method use the predicted values from a separately trained ResNet model as intensity labels instead of using the actual intensity values? Using model-predicted values as labels seems inefficient and may introduce additional sources of error. A more detailed explanation of this design choice is needed.\n2) Why was the proposed method validated using an equally sampled dataset rather than the original data distribution? In real-world scenarios, the proportions of different defect types are typically imbalanced. Such uniform sampling may hinder a realistic comparison with actual industrial conditions. Therefore, it is recommended to also include experimental results based on the original class distribution."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IK29IG39FS", "forum": "J9VRPrhwjM", "replyto": "J9VRPrhwjM", "signatures": ["ICLR.cc/2026/Conference/Submission21239/Reviewer_Mdjv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21239/Reviewer_Mdjv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21239/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761198489409, "cdate": 1761198489409, "tmdate": 1762941650974, "mdate": 1762941650974, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SteelNet, a multimodal representation learning framework aimed at improving industrial process optimization， specifically in steel rolling mills. It integrates cross-modal alignment and a modality-dropout strategy to learn robust representations from heterogeneous sensor data (e.g., vibration, temperature, pressure). The model also incorporates a parameter attribution mechanism for causal interpretation of process variables and their relation to defects. The authors construct a synthetic multimodal dataset by extending the Severstal Steel Defect Detection dataset with simulated process parameters to evaluate the framework’s performance under missing modalities."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. SteelNet addresses real-world challenges in industrial environments such as missing sensor data, noise, and cross-modal inconsistencies, which enhances its industrial applicability.\n\n2. The framework integrates multiple components (cross-modal alignment, self-attention, causal attribution) and demonstrates solid performance with clear ablation and robustness studies."}, "weaknesses": {"value": "1. The paper mainly applies existing multimodal learning ideas (cross-modal fusion, modality dropout, attention, attribution) to an industrial context. It does not introduce a fundamentally new algorithmic contribution, which fails to meet ICLR’s originality and theoretical novelty standards.\n\n2. Evaluation is conducted only on a synthetically augmented version of a single dataset, without evidence on broader industrial or real sensor datasets, limiting the generalizability.\n\n3. Some plots (e.g., architecture overview and confusion matrices) are too rough or visually cluttered, lacking publication-level polish expected for ICLR."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "u5lKVCEQCk", "forum": "J9VRPrhwjM", "replyto": "J9VRPrhwjM", "signatures": ["ICLR.cc/2026/Conference/Submission21239/Reviewer_KXx5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21239/Reviewer_KXx5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21239/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761769106804, "cdate": 1761769106804, "tmdate": 1762941650715, "mdate": 1762941650715, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces SteelNet, a multimodal representation learning approach designed for defect detection in steel rolling mills.\nThe method integrates multiple data sources and aims to identify the variables that contribute most to defect occurrence.\nTo achieve this, it employs a synthetic parameter generation process intended to reproduce known domain-specific cause–effect relationships and environmental correlations."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The paper is overall well-written and easy to follow.\n- The synthetic parameter generation mechanism is conceptually interesting, as it attempts to encode domain knowledge and known physical correlations into the learning process.\n- The integration of multimodal data and the focus on explainability (via variable contribution analysis) are valuable contributions to industrial AI and fault diagnosis applications."}, "weaknesses": {"value": "- The experimental validation is limited to a single dataset, making it difficult to assess the generality and broader applicability of the proposed method.\n- Although the authors claim robustness to missing data and early detection of critical events, no quantitative study or sensitivity analysis is presented to substantiate these claims.\n- Some methodological choices, such as disregarding temporal dependencies and class imbalance, raise concerns about the validity of the reported results. Other aspects also seem ad hoc or insufficiently detailed (e.g., empirically determined weights)."}, "questions": {"value": "1) Are the empirically determined weights fixed, or are they updated during training or fine-tuning?\n2) Table 1 reports performance metrics, but it is unclear whether these values refer to a specific defect class or represent averages across all classes. Could the authors clarify this?\n3) How robust is the model to missing data or corrupted modalities?\n4) What is the timeliness or early-warning performance of the model in detecting faults?\n5) How representative is the dataset used? If class distributions differ from real-world conditions, how might this affect the model’s deployment validity?\n6) Given that this type of process is inherently sequential, how effective is the proposed approach without modeling temporal dependencies? Is there any evaluation of the model’s ability to detect faults early, i.e., before failure events occur?\n7) The authors claim that the approach applies to other industrial settings. What aspects are specifically tailored to steel rolling mills, and what components are generalizable? Dataset characteristics, domain-specific feature engineering, or architectural design?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "SbqhBa71gY", "forum": "J9VRPrhwjM", "replyto": "J9VRPrhwjM", "signatures": ["ICLR.cc/2026/Conference/Submission21239/Reviewer_ow7r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21239/Reviewer_ow7r"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21239/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761906583654, "cdate": 1761906583654, "tmdate": 1762941650430, "mdate": 1762941650430, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SteelNet, a multimodal representation-learning framework for steel-mill monitoring that aims to stay robust when sensors fail and to surface actionable parameter-level attributions for defects. It pairs a new (partly synthetic) multimodal dataset with a model that uses a parameter encoder, self-attention, physics-informed constraints, modality dropout, and multi-task heads for defect class and “intensity” prediction, plus an attribution head to highlight root-cause variables."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. Integration of industrial requirements with AI design:\nThe paper effectively connects real industrial problems with AI methods. Instead of building a generic model, it designs the system to handle real issues in steel manufacturing, such as missing sensor data, few labeled samples, and the need for clear explanations of defect causes. This focus on practical challenges makes the work more useful and relevant for industry applications, not just academic research.\n\n2. Systematic ablation study:\nThe authors conduct an ablation analysis that clearly disentangles the effect of each model component — self-attention, modality-dropout, attribution loss, and physics constraints. \n\n3. Acknowledgment and discussion of limitations:\nThe paper clearly states its main limitations — including the use of synthetic data, simplified treatment of time, and absence of real factory deployment. This honest discussion shows that the authors understand the boundaries of their work and helps readers see what still needs to be tested in real conditions."}, "weaknesses": {"value": "1. Figures: low readability and polish (plus a minor mistake): \nSeveral plots are hard to read (small fonts, low contrast, dense legends) and look inconsistent across sections (e.g., architecture/importance figs; robustness and appendix plots). Clearer typography, consistent palettes, and vector graphics would help. Also fix the caption typo “it’s mask” → “its mask” in Fig. 6.\n\n2. System/algorithm description feels sketch-level rather than fully academic:\nWhile Fig. 2 and “Algorithm 1” give a high-level view, key pieces remain under-specified—especially the exact fusion with the image modality and the formal definition of the physics constraint (it appears as a black-box term PhysicsConstraint(z)). Please spell out the fusion pathway, units/normalization, and the constraint’s closed form (including any coefficients) so others can replicate precisely.\n\n3. Heavy reliance on synthetic parameters and static samples limits external validity:\nThe paper itself notes that process parameters are synthetically generated, time dynamics are omitted, and there is no validation on real sensor data. This makes generalization to real plants uncertain. A small real-sensor/time-series study (even a pilot) would strengthen the claims.\n\n4. Claims not fully supported as contributions:\nThe paper states it targets equipment availability and improves operational decision-making, but the experiments do not measure uptime/availability or control benefits; as written, that should not be counted as a demonstrated contribution. Also, the defect-intensity scoring (ResNet-34 trained on masks) is a useful dataset step, but not methodically novel—please frame it as dataset preparation rather than a core algorithmic contribution."}, "questions": {"value": "Q1. Figures / readability:\nCould you regenerate all figures with vector graphics, larger fonts, clear axis units, consistent color palettes, and readable legends—especially Figs. 5–9? (Also, please fix the caption typo “it’s mask” → “its mask” in Fig. 6.) \n\nQ2. Method clarity: fusion + physics constraint:\nHow exactly are image features fused with process-parameter embeddings, and what is the closed-form definition (with coefficients) of the physics-constraint term used in training? The ablation refers to “w/o Physics Constraints” but the constraint itself isn’t fully specified.\n\nQ3. Data realism and leakage control:\nGiven the reliance on synthetic parameters and static samples, can you provide any validation on real sensor time-series—or, at minimum, describe safeguards against leakage between the intensity model and the parameter generation pipeline? \n\nQ4. Baselines and statistical rigor:\nBeyond ablations, will you add head-to-head baselines (e.g., strong tabular models and established missing-modality methods), report mean±std over multiple seeds, and clarify the sensor-dropout protocol (failure sampling pattern, seeds, confidence intervals)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "twa2TWlkl4", "forum": "J9VRPrhwjM", "replyto": "J9VRPrhwjM", "signatures": ["ICLR.cc/2026/Conference/Submission21239/Reviewer_hZkH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21239/Reviewer_hZkH"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21239/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986604915, "cdate": 1761986604915, "tmdate": 1762941650127, "mdate": 1762941650127, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}