{"id": "NIA4qmseAd", "number": 8191, "cdate": 1758073119595, "mdate": 1759897800869, "content": {"title": "A Generative Framework for Causal Estimation via Importance-Weighted Diffusion Distillation", "abstract": "Estimating individualized treatment effects from observational data is a central challenge in causal inference, largely due to covariate imbalance and confounding bias from non-randomized treatment assignment. While inverse probability weighting (IPW) is a well-established solution to this problem, its integration into modern deep learning frameworks remains limited. In this work, we propose Importance-Weighted Diffusion Distillation (IWDD), a novel generative framework that combines the pretraining of diffusion models with importance-weighted score distillation to enable accurate and fast causal estimation—including potential outcome prediction and treatment effect estimation. We demonstrate how IPW can be naturally incorporated into the distillation of pretrained diffusion models, and further introduce a randomization-based adjustment that eliminates the need to compute IPW explicitly—thereby simplifying computation and, more importantly, provably reducing the variance of gradient estimates.  Empirical results show that IWDD achieves state-of-the-art out-of-sample prediction performance, with the highest win rates compared to other baselines, significantly improving causal estimation and supporting the development of individualized treatment strategies.", "tldr": "", "keywords": ["Causal Inference", "Diffusion Distillation", "Diffusion Model"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/575d817e4bcf5049f893499acde5c822e0117029.pdf", "supplementary_material": "/attachment/67100650791ef33984725641f2a6221d76ef427e.zip"}, "replies": [{"content": {"summary": {"value": "The authors proposed Importance-Weighted Diffusion Distillation (IWDD), a two stage framework for estimating causal effect in the binary treatment setting. In the first stage, a conditional diffusion model is trained to learn P(Y|Z,X) and also serves as the teacher network. In the second stage, a distillation process is conducted by introducing a fake score network together with the teacher network to guide the training of a one-step generator. Although it is not an end-to-end framework, the method IWDD overcomes some key limitations in previous works, such as DiffPO, where a propensity score model is not required by considering the imbalance through sampling in an implicit way. The theoretical analysis and empirical results look promising."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe two-stage method is pretty straight forward and written in a clear way.\n2.\tIncorporating the randomized control and considering sample weight in an implicit way by a simple sampling process seems a novel contribution.\n3.\tThe empirical evaluation is pretty compelling by comparing to quite a few solid baselines across several different simulation datasets. \n4.\tThe theoretical results are technically sound, especially the compared of different variance estimator and also the empirical risk."}, "weaknesses": {"value": "1.\tThe current work only handle binary treatment setting, which is quite limited since complex treatments, such as continuous or categorical are pretty common in real datasets.\n2.\tAlthough unconfoundedness is a standard assumption but still quite strong. How unmeasured confounders can impact the the performance of IWDD is not discussed. E.g., will the proposed method be more robust to unmeasured confounder compared to other baselines?\n3.\tThe first stage of training a conditional diffusion model may be computational extensive. This could also be a potential barrier for real applications.\n4.\tThe proposed method did not consider the high-dimensionality case of X. If simply concatenating X and Z for conditioning, the high-dimensional X may dominant the information since Z is just one-dimensional. \n5.\tSome important baselines that also use generative AI are missed. E.g., GANITE, CausalEGM based on GAN, and CEVAE based on VAE. Especially considering CausalEGM is a quite recent method and seems to outperform existing baselines, it should be compared and benchmarked."}, "questions": {"value": "1.\tCould the authors provide the performance drop when introducing unmeasured confounder for different methods? The effect of the unmeasured confounder can be adjusted to different levels\n2.\tThe author should also include the missed baselines, such as GANITE, CausalEGM, and CEVAE for a more comprehensive comparison.\n3.\tThe scalability of the proposed method IWDD should be rigorously tested by varying the sample size.\n4.\tThe author stated that Fisher divergence is better than KL divengence, any intuition for this empirical conclusion?\n5.\tHow the method is sensitive to the dimension of X?\n6.\tThe author claims that one-step generator largely improves efficiency. Then the running time and computational cost at different stages should be benchmarked.\n7.\tWhy causalforest is only shown in Table 2 not Table 1? The performance of causalforest is much worse than other baselines is dubious as it is not consistent from the results in other papers."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "x3Azthbdqk", "forum": "NIA4qmseAd", "replyto": "NIA4qmseAd", "signatures": ["ICLR.cc/2026/Conference/Submission8191/Reviewer_BX17"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8191/Reviewer_BX17"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8191/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761000857312, "cdate": 1761000857312, "tmdate": 1762920148642, "mdate": 1762920148642, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new framework for causal effect estimation with diffusion models. For that, the authors develop Importance-Weighted Diffusion Distillation (IWDD), which first pretrains diffusion models and then performs balancing of the covariate distributions of the treated and untreated groups by importance sampling, as an alternative to IPW loss adjustment. The authors then perform experiments on different datasets and benchmark their method against related baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- Adapting diffusion models for causal effect estimation is an interesting research idea, allowing for going beyond pure point estimation of CATEs but also allowing for estimating the conditional potential outcomes distribution, which then can be used to estimate different causal quantities.\n- Large parts of the paper are well written, and the flow of the paper is easy to follow.\n- The authors provide code for the reproducibility of their results."}, "weaknesses": {"value": "**The contribution/novelty and practicality of the method seem rather limited.**\n- The idea of using diffusion models for potential outcomes estimation while tackling distribution shift/treatment selection bias is not new and has already been explored e.g. by DiffPO. Thus, the major contribution of this paper is avoiding using the IPW term and instead performing importance weighting via sampling. The applied adaptations and performed experiments are also limited and could be improved clearly (see points below).\n- One major motivation of their applied weighing via sampling is avoiding IPW weighing the loss term which is stated to be problematic because of (i) the need for estimating the propensity score and (ii) avoiding unstable optimization in case of extreme propensity score weights/overlap violations. However, both points do not seem to be solved better by their proposed framework. For (i), instead of estimating the propensity score (a rather “simple” task, i.e. training a calibrated binary classification model), their method requires a pretrained diffusion model and a fake score network which seems to be a computationally more expensive and also from the estimation side way more complex problem, making the intuition unclear why this should be a better approach. For (ii), as the authors state, IPW can apply simple clipping/trimming with the cost of losing the orthogonal properties of the loss but likely increasing finite sample estimation performance. However, the method of the authors requires also evaluating the pretrained diffusion and fake score network for sampled combinations of (x,z) in regions that were never observed during training, which intuitively should also lead to degraded performance. Here, I think the provided variance analysis is not really useful for showing benefits of their method because it does not take into account the variance for estimating p(y|x,z) and evaluating it in these low overlap regions, which is the main problem of their method here.\n\n**The experimental setup is unclear and raises serious concerns.**\n - Figure 2 seems to have no clear meaning. The paper does conditional potential outcomes distribution estimation, what is the purpose of showing a marginal distribution shift of y between training and test domain?\n- Figure 3 is unclear. The true distributions of potential outcomes in orange should a) at least be the same within each column (why are they different?) and b) should be the same for Y(0) for both in-sample and out of sample (and for Y(1) the same). (I guess in sample and out of sample refers to training and test domain.) This is because the plot implies the distribution of _potential_ (not just observed) outcomes are plotted, and there is no distribution shift in x between training and test data. Did the authors plot the distribution of observed outcomes instead? If not, it is unclear to me why the trained model should perform well for predicting Y(1) in-sample but bad for Y(1) out of sample since there is no distribution shift in x. So I guess for in-sample, the authors actually show P(Y|Z=0) and P(Y|Z=1)  following the observational distribution instead.\n- Overall and importantly, if the treatment assignment is fully deterministic here (no overlap for any x), both potential outcomes for any x are never identifiable at all so showing results here is actually just stating that for some randomly selected DGP one method is better than the other because of some inductive bias. This is not useful for causal inference method validation.\n- The comparison to the baselines seems strange. In Tables 1 and 2, how can DiffPO have notable percentage win rates but incredibly high average error rates? This might be an indicator for some model failure for individual datasets and thus improper hyperparameter tuning. Also the link provided in l.269 trying to show the incorrect implementation of DiffPO does not work properly and does not show what is stated by the authors."}, "questions": {"value": "- In Fig. 2, the paper does conditional potential outcomes distribution estimation, what is the purpose of showing a marginal distribution shift of y between training and test domain?\n- In Fig 3., the true distributions of potential outcomes in orange should a) at least be the same within each column, why are they different?\n- In Fig. 3, did the authors plot the distribution of observed outcomes instead of potential outcomes for in sample data?\n- In Tables 1 and 2, how can DiffPO have notable percentage win rates but incredibly high average error rates?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RIbSbW2oyT", "forum": "NIA4qmseAd", "replyto": "NIA4qmseAd", "signatures": ["ICLR.cc/2026/Conference/Submission8191/Reviewer_uGJs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8191/Reviewer_uGJs"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8191/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761776260256, "cdate": 1761776260256, "tmdate": 1762920148251, "mdate": 1762920148251, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a two-stage framework, which first pretrains a covariate- and treatment-conditional diffusion model on observational data, then incorporates inverse probability weighting (IPW) into the distillation process to adjust for confounding. The method shows theoretical variance reduction and results on empirical datasets. The paper shows good empirical performance on causal learning challenge datasets in ACIC."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- The idea to use deep learning techniques such as diffusion and distillation on IPW is innovative, which arguably hasn't been done before \n- The paper shows details of how diffusion and distillation are built into the algorithm, and shows the rationale \n- The paper shows good results on the increasingly popular ACIC datasets"}, "weaknesses": {"value": "- The diffusion/distillation them algorithms are popular algorithms, while it's uncertain how much impact the algorithm has, because it's only applied on the dealing of confounding factors, or IPW \n- The paper may be missing key ablation studies, e.g., IPW itself uses one-layer regression, which itself is a shallow ML technique. What if we use an MLP or other deeper models without diffusion or distillation? Ablation to see the contribution to see each technique will be helpful to boost the paper's impact. \n- The results could use comparisons with other techniques, SOTA (combining IPW and DL), and against IPW, also in other datasets other than ACIC. ACIC has multiple datasets, but the comparison with other techniques could be seen on other older datasets."}, "questions": {"value": "- Could you add more ablation studies on how diffusion and distillation each contribute to the good results \n- Other than diffusion and distillation being popular applications in deep learning, are they the only techniques that could add to performance increase? e.g. p(y | x, z) could be estimated many different ways, with DL, graphical models\n- More comparison and analysis on public datasets, with previous methods, e.g., DragonNet, would be helpful."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Y9pKoh9jMc", "forum": "NIA4qmseAd", "replyto": "NIA4qmseAd", "signatures": ["ICLR.cc/2026/Conference/Submission8191/Reviewer_QBWv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8191/Reviewer_QBWv"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8191/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762031736873, "cdate": 1762031736873, "tmdate": 1762920147813, "mdate": 1762920147813, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a new generative framework for modelling potential outcome distributions, namely, Importance-Weighted Diffusion Distillation (IWDD). The proposed method uses a pre-trained diffusion model to distill its predictions onto a different generative model. Furthermore, during the distillation process, the authors suggested a randomization-based adjustment that serves as a substitute for the inverse probability weighting (IPW). The paper also formulates theoretical guarantees for when the suggested distillation should improve over the baseline diffusion model.  Finally, the authors evaluate their IWDD empirically based on the standard causal ML benchmarks."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The proposed idea is original. Also, the paper has a clear structure."}, "weaknesses": {"value": "The method relies on the core idea that we can substitute the IPWs with the randomization-based adjustment (i.e., shuffling the covariates and treatment assignment). Yet, by doing so, we cannot use the observed outcomes from the original dataset (as they originate from P(X, Z, Y) and not from P(X)P(Z)P(Y|X, Z)). The paper also does not clearly explain what sample is being used for the distillation, so I assume the pre-trained diffusion model was used to sample from both of the potential outcomes, P(Y|X, Z). If this is indeed the case, the theoretical insights in Sec. 3.3 are obsolete: There, the authors assume that the target model $G_\\Theta$ minimizes the risk wrt. data from the RCT (=P(X)P(Z)P(Y|X, Z)). Yet, in reality (as far as I understood), the ground-truth P(Y|X, Z) is substituted with another diffusion model.  I encourage the authors to clarify these important details.\n\nTherefore, I question the sanity of the proposed method: To the best of my knowledge, there is no direct way to omit the inverse propensity weights (other than trimming/truncation/retargeting of the loss) if we want to use the observational data and want to incorporate the propensity score into the loss.    Furthermore, in my opinion, the paper has limited novelty (e.g., in comparison with Diff-PO [1]), and the main method is simply the implementation of a two-stage covariate-adjusted learner with diffusion models.    \n\nI also found several minor mistakes:\n- Line 195. $\\lambda(\\sigma)$ was not defined.\n- I double-checked the code from [1], and the propensity scores were trimmed to at least 0.33 in DiffPO (https://github.com/yccm/DiffPO/blob/15a6b675236736a95a3adfdf1711390893b8fd96/src/main_model.py#L150). Also, the link that the authors provided in line 269 is not active anymore.\n\nReferences:\n- [1] Yuchen Ma, Valentyn Melnychuk, Jonas Schweisthal, and Stefan Feuerriegel. DiffPO: A causal diffusion model for learning distributions of potential outcomes. In The Thirty-eighth Annual Conference on Neural Information Processing Systems, 2024. URL https://openreview.net/forum?id=merJ77Jipt."}, "questions": {"value": "- Why were CATE/CAPOs benchmarks chosen if the main task is the estimation of the potential outcomes distributions? I would expect the benchmarks to center around evaluating different distributional distances (e.g., Wasserstein distance). Also, many generative baselines for potential outcomes are missing (e.g., [1, 2]).\n- How are the hyperparameters of the main method and other baselines tuned? I haven’t found any details on that in the Appendix and the provided code.\n\nReferences:\n- [1] Yoon, Jinsung, James Jordon, and Mihaela Van Der Schaar. \"GANITE: Estimation of individualized treatment effects using generative adversarial nets.\" International conference on learning representations. 2018.\n- [2] Vanderschueren, Toon, Jeroen Berrevoets, and Wouter Verbeke. \"NOFLITE: Learning to predict individual treatment effect distributions.\" Transactions on Machine Learning Research (2023)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vgSLE05hav", "forum": "NIA4qmseAd", "replyto": "NIA4qmseAd", "signatures": ["ICLR.cc/2026/Conference/Submission8191/Reviewer_3g5t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8191/Reviewer_3g5t"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8191/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762145788157, "cdate": 1762145788157, "tmdate": 1762920147309, "mdate": 1762920147309, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}