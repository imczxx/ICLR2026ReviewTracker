{"id": "PXDFTeIqMd", "number": 2802, "cdate": 1757254413017, "mdate": 1759898126463, "content": {"title": "TAMMs:~Change Understanding and Forecasting in Satellite Image Time Series with a Temporal-Aware Multimodal Model", "abstract": "Temporal Change Description (TCD) and Future Satellite Image Forecasting (FSIF) are critical, yet historically disjointed tasks in Satellite Image Time Series (SITS) analysis. Both are fundamentally limited by the common challenge of modeling long-range temporal dynamics. To explore how to improve the performance of methods on both tasks simultaneously by enhancing long-range temporal understanding capabilities, we introduce \\textbf{TAMMs}, the first unified framework designed to jointly perform TCD and FSIF within a single MLLM-diffusion architecture. TAMMs introduces two key innovations: Temporal Adaptation Modules (\\textbf{TAM}) enhance frozen MLLM's ability to comprehend long-range dynamics, and Semantic-Fused Control Injection (\\textbf{SFCI}) mechanism translates this change understanding into fine-grained generative control. This synergistic design makes the understanding from the TCD task to directly inform and improve the consistency of the FSIF task. Extensive experiments demonstrate TAMMs significantly outperforms state-of-the-art specialist baselines on both tasks.", "tldr": "We introduce TAMMs, a unified framework which provides a single solution to both describe historical changes and forecast future scenes, significantly outperforming prior methods on both tasks.", "keywords": ["Remote Sensing", "Satellite Image Time Series", "Temporal Reasoning", "Generative models", "Change-aware Generation", "Multimodal Large Language Models"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/934497995bc729534ea89259ccaa024551c9988b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents TAMMs, the first unified framework that jointly performs temporal change description (TCD) and future satellite image forecasting (FSIF) by enhancing long-range temporal understanding. It introduces lightweight Temporal Adaptation Modules (PTE and CTP) to awaken a frozen MLLM’s ability to reason over sparse, long-term satellite image time series, producing a semantic feature Mt. The novel Semantic-Fused Control Injection (SFCI) mechanism then translates Mt into multi-scale, spatially-aware control signals to guide a frozen diffusion U-Net, ensuring patch-level temporal consistency in generated future images. Additionally, a new metric, Temporal Consistency Score (TCS), is proposed to quantify the plausibility of predicted changes against historical dynamics. Extensive experiments demonstrate that TAMMs significantly outperforms state-of-the-art specialized baselines on both tasks, with particularly large gains in TCS, validating the closed-loop paradigm of “understanding why changes occur to forecast what will happen."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "TAMMs pioneers a single, frozen-backbone framework that couples satellite change captioning with future image synthesis, leveraging lightweight adapters to awaken long-range temporal reasoning and fine-grained diffusion control; it handles sparse, multi-year sequences, introduces the TCS metric to quantify temporal plausibility, and achieves comprehensive SOTA results with minimal trainable parameters."}, "weaknesses": {"value": "1. the paper presentation need to be improved.\nFor example, TAMMs is designed through different modules like PTE, CTP, SFCI, however there are no corresponding label in figure 2, making it not convenient for readers to understand.\nIn addition, the descriptive labels are automatically generated by Qwen2.5-VL model, why in figure 2 it is ChatGPT icon?\n\n\n2. The ablation study is not sufficient.\nThe choice of MLLM backbone(why DeepSeek-VL2) is not clear, as well as the choice of Stable Diffusion\nIn addition, in table2 Ablation on Temporal Adaptation (for Change Description), w/o PTE achieves sota and authors should provide corresponing analysis"}, "questions": {"value": "1.It is reasonable to encode time_diff into the input sequence, but why make it a learnable token, I do not think it is to“inject explicit temporal awareness” but implicit instead. The author should provide some persuasive ablation studies here.\n\n2.In figure 5, apart from TAMMs generate the most detailed description, it is obvious that the description length of TAMMs is much longer than that of other models，  making it appear to be an unfair comparison, which is worth noting"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lUhr4o9gCc", "forum": "PXDFTeIqMd", "replyto": "PXDFTeIqMd", "signatures": ["ICLR.cc/2026/Conference/Submission2802/Reviewer_72WA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2802/Reviewer_72WA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2802/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761364864948, "cdate": 1761364864948, "tmdate": 1762916383093, "mdate": 1762916383093, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a framework called **TAMMs**, designed for temporal change description and future image forecasting in satellite image time series. The method builds upon a frozen MLLM and a diffusion-based generator, introducing two auxiliary modules — **Temporal Adaptation Module (TAM)** and **Semantic-Fused Control Injection (SFCI)** — to enable temporal awareness and semantic guidance without large-scale fine-tuning. The TAM module enhances the MLLM’s temporal reasoning through Physical Time Encoding (PTE) and Contextual Temporal Prompting (CTP), while the SFCI module maps the MLLM’s semantic outputs into multi-scale control signals to guide the diffusion generation process. The paper further proposes a new metric, **Temporal Consistency Score (TCS)**, to quantify the consistency between predicted changes and historical dynamics. Experiments conducted on the fMoW (training) and Google Earth (testing) datasets demonstrate that the proposed approach outperforms several existing baselines on both temporal description and image forecasting tasks."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper provides a unified framework for satellite image time-series modeling, integrating semantic understanding and future prediction into a single closed-loop process.\n2. The proposed TAM and SFCI modules are logically designed to enable temporal encoding and generative control while keeping the pretrained MLLM and diffusion models frozen.\n3. The introduction of the TCS metric offers a way to quantify spatial consistency between predicted and historical changes, addressing the limitation of conventional image quality metrics in temporal evaluation."}, "weaknesses": {"value": "1. The study focuses narrowly on satellite image forecasting and does not explore the applicability of the proposed framework to other domains, limiting its generality.\n2. The proposed approach appears primarily as an engineering implementation based on pretrained LLMs and diffusion models, with limited introduction of new theoretical mechanisms or modeling principles; thus, its novelty is modest.\n3. The overall architecture is complex but lacks a clear explanation of the core ideas and hierarchical relationships among key components. The importance, dependency, and training connections of different modules are not well clarified. The paper allocates substantial space to implementation details and equations but does not adequately explain the design rationale or training phase distinctions. For example, while the appendix mentions multi-stage training, the main figures do not distinguish which components are frozen or trainable across different stages, which makes the workflow difficult to interpret.\n4. Other issues: The title in the PDF and the OpenReview submission are inconsistent and should be unified; Equation (6) is missing a pair of braces."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7ARme1tmj9", "forum": "PXDFTeIqMd", "replyto": "PXDFTeIqMd", "signatures": ["ICLR.cc/2026/Conference/Submission2802/Reviewer_kXkZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2802/Reviewer_kXkZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2802/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761755200575, "cdate": 1761755200575, "tmdate": 1762916382912, "mdate": 1762916382912, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents TAMMs, a unified framework for jointly performing Temporal Change Description (TCD) and Future Satellite Image Forecasting (FSIF) within a single MLLM-diffusion architecture. It introduces two main components: Temporal Adaptation Modules (TAM), which enhance the model’s ability to capture long-range temporal dynamics, and Semantic-Fused Control Injection (SFCI), which transfers temporal understanding into precise generative control. This integration allows insights from TCD to directly improve FSIF consistency and performance across both tasks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Synergistic training for change detection together with future generation is an interesting idea for enhancing the reasoning capabilities of MLLM in the satellite image domain.\n- Temporal Consistency Score (TCS) adds value as a metric specifically desgned for application on SITS.\n- Performance results are strong in Table 1.\n- Ablation study is performed on proposed modules."}, "weaknesses": {"value": "- Some examples of the data used for training (satellite images together with generated captions) should be presented, possibly in supp. material.\n- writing could be improved, some non exhaustive examples for use of language include:\n   - l.38 \"because fails\"\n   - l.39-41 \"the absence of a unified framework of temporal-aware multimodal model for satellite image change understanding and forecasting named TAMMs\"\n   - l.42 \"How can model reason\"\n- similarly \"Satellite Image Time Series (SITS)\" appears in several places in text, one should be ok then use abbreviation"}, "questions": {"value": "- As far as i understand captions generated via Qwen 2.5 VL are treated as ground truths for training. Can you explain why the trained model outperforms Qwen 2.5?\n- in l.199 can you explain what is meant via \"specific time interval\", what is the input to the small MLP?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wDVclJxfOj", "forum": "PXDFTeIqMd", "replyto": "PXDFTeIqMd", "signatures": ["ICLR.cc/2026/Conference/Submission2802/Reviewer_7xU9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2802/Reviewer_7xU9"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2802/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931316825, "cdate": 1761931316825, "tmdate": 1762916382797, "mdate": 1762916382797, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes TAMMs, a unified framework that connects TCD with FSIF. The approach freezes a multimodal LLM and introduces TAM for long-range temporal reasoning, and injects these semantics into a frozen diffusion U-Net via SFCI to guide fine-grained generation. A new metric, TCS, evaluates whether predicted changes align spatially and in area with historical change. Extensive experiments on a large fMoW training corpus and long-horizon Google Earth sequences show strong TCD performance and notable gains on TCS, with ablations supporting the contributions.\nStrengths"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Timely problem and clear unification, bridging understanding to forecasting in a single, parameter-efficient pipeline for remote-sensing time series.\n\n2. Well-motivated architecture: TAM adds lightweight temporal conditioning without full fine-tuning; SFCI combines structural and semantic control for diffusion, yielding an intuitive, modular design."}, "weaknesses": {"value": "1. On FSIF, some standard metrics are only competitive rather than strictly superior to strong generative baselines. A brief discussion and supplemental visuals would help reconcile this with the TCS gains.\n\n2. Prompt robustness is missing: TAM relies on Contextual Temporal Prompting (CTP), but there is no analysis of robustness to prompt phrasing/length/templates; please add prompt ablations.\n\n3. Test-time generalization is not demonstrated. Evaluation hinges on a curated set of 150 long-horizon Google Earth sequences; please provide cross-dataset (e.g., Sentinel-2/Landsat) or leave-region/season-out tests."}, "questions": {"value": "1. How sensitive is TCS to the underlying change detector, its thresholds, and hyperparameters (e.g., σ, β)? Any correlation with human rankings?\n\n2. Could you clarify cases where SSIM/PSNR lag slightly behind certain baselines—are there domain/normalization or texture–sharpness trade-offs?\n\n3. How do you handle geometric reprojection (CRS/EPSG), the resampling kernel, and radiometric normalization across time?\n\n4. What is the exact mask post-processing (e.g., thresholding, morphology) before centroid and area computation?\n\n5. Could you compare TCS against temporal FID/KID variants or other spatial-consistency metrics to validate complementary signal?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "WROYyLpePf", "forum": "PXDFTeIqMd", "replyto": "PXDFTeIqMd", "signatures": ["ICLR.cc/2026/Conference/Submission2802/Reviewer_zohA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2802/Reviewer_zohA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2802/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959315430, "cdate": 1761959315430, "tmdate": 1762916382663, "mdate": 1762916382663, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}