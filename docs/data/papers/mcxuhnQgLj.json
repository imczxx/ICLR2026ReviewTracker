{"id": "mcxuhnQgLj", "number": 15625, "cdate": 1758253324909, "mdate": 1763746968856, "content": {"title": "Autonomy-Aware Clustering: When Local Decisions Supersede Global Prescriptions", "abstract": "Clustering arises in a wide range of problem formulations, yet most existing approaches assume that the entities under clustering are passive and strictly conform to their assigned groups. In reality, entities often exhibit local autonomy, overriding prescribed associations in ways not fully captured by feature representations. Such autonomy can substantially reshape clustering outcomes—altering cluster compositions, geometry, and cardinality—with significant downstream effects on inference and decision-making. We introduce autonomy-aware clustering, a reinforcement (RL) learning framework that learns and accounts for the influence of local autonomy without requiring prior knowledge of its form. Our approach integrates RL with a deterministic annealing (DA) procedure, where, to determine underlying clusters, DA naturally promotes exploration in early stages of annealing and transitions to exploitation later. We also show that the annealing procedure exhibits phase transitions that enable design of efficient annealing schedules. To further enhance adaptability, we propose the Adaptive Distance Estimation Network (ADEN), a transformer-based attention model that learns dependencies between entities and cluster representatives within the RL loop, accommodates variable-sized inputs and outputs, and enables knowledge transfer across diverse problem instances. Empirical results show that our framework closely aligns with underlying data dynamics: even without explicit autonomy models, it achieves solutions close to the ground truth (gap $\\sim$3–4\\%), whereas ignoring autonomy leads to substantially larger gaps ($\\sim$35–40\\%).", "tldr": "We introduce autonomy-aware clustering, a reinforcement-based method that models latent data autonomy—where points may override prescribed assignments—altering cluster structure.", "keywords": ["Clustering", "Local Autonomy", "Facility Location", "Reinforcement Learning", "Deep Learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8cdc12005712efe7dcb781f72ec68f5697a79aaf.pdf", "supplementary_material": "/attachment/c2e01057e26082379cbc13d929e57140a89e13b0.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents the idea of autonomy-aware clustering to tackle real-world scenarios where entities deviate from the prescribed cluster assignments. By integrating reinforcement learning with deterministic annealing, the proposed method captures these autonomy effects, leading to satisfactory clustering results on the London Traffic dataset."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper proposes the entity autonomy problem in the existing passive clustering frameworks, which seems to be a practical research direction.\n2. The proposed method is theoretically grounded, with detailed mathematical derivations and proofs."}, "weaknesses": {"value": "1. In Fig. 1, it is not clear how such autonomy would occur in existing clustering methods. For example, for the given data, the classic K-means algorithm would not achieve such degraded results as illustrated in Figures c and d. I feel that a more intuitive example and explanation would help the readers to understand that the proposed autonomy problem is realistic and commonly encountered.\n2. How could the proposed Adaptive Distance Estimation Network estimate the behavior of instances? In the fully supervised case, how can such estimations reflect real autonomy rather than random guesses? According to the experiments, the methods with or without prior autonomy knowledge only have a performance gap of 3-4%, which is a bit surprising. \n3. In fact, such a result may indicate that the dataset used for evaluation is not representative and complicated enough. It is not convincing whether the method could generalize to other scenarios, such as social networks and recommender systems, especially considering the hyperparameters required.\n4. In Eq. P1, $\\rho(i)$ is not explained."}, "questions": {"value": "My major concerns lie in two aspects: i) more examples and discussions are needed to prove that such an autonomy problem widely exists in real-world applications; ii) it is a bit unreasonable that the model could produce results close to ground truth even without any priors on the entity autonomy. In other words, one could change the \"ground truth\" and the model would produce the same but \"much worse\" results. These concerns need to be addressed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jNblbuzfch", "forum": "mcxuhnQgLj", "replyto": "mcxuhnQgLj", "signatures": ["ICLR.cc/2026/Conference/Submission15625/Reviewer_ggqe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15625/Reviewer_ggqe"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15625/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761036909836, "cdate": 1761036909836, "tmdate": 1762925891400, "mdate": 1762925891400, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces the novel concept of Autonomy-Aware Clustering, addressing the critical limitation in traditional clustering where entities are assumed passive and strictly conform to assignments. In reality, entities exhibit local autonomy ($p(k|j,i)$), probabilistically overriding prescribed cluster memberships, which can significantly alter cluster centers and composition. The framework tackles this challenge in two stages. First, for the case where autonomy models are known, it adapts Deterministic Annealing (DA), leveraging its advantages in handling non-convexity and initialization sensitivity. Second, for the practical, unknown-autonomy case, it formulates the problem as a unit-horizon Markov Decision Process (MDP) and proposes a Reinforcement Learning (RL) framework to jointly learn the assignment policy and cluster representatives. A key component is the Adaptive Distance Estimation Network (ADEN), a Transformer-based attention model used within the RL loop for model-free learning of dependencies. Empirical results demonstrate that the autonomy-aware framework produces effective results."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The most notable originality lies in the formal definition and robust solution for autonomy-aware clustering, explicitly accounting for stochastic entity behavior conditional on the policy. The quality is high due to the integrated methodological approach, which uses the strong theoretical basis of Deterministic Annealing (DA) and augments it with a practical Reinforcement Learning (RL) framework incorporating a Transformer-based ADEN for model-free learning. The work's significance is demonstrated by compelling results showing the method is highly accurate and, interestingly, can sometimes use the RL exploration to achieve up to a 10% improvement over the explicitly known-model solution by escaping local minima. The paper's clarity is excellent, making the sophisticated methodology accessible."}, "weaknesses": {"value": "The framework's primary reliance on the DA formulation limits its direct generality to resource allocation or other clustering problems that can be represented by a distance to a cluster representative, excluding non-centroid-based clustering methods. The implementation of the ADEN to estimate the average cost within the RL loop may introduce complexity and potential instability in training that is not fully analyzed, compared to simpler clustering cost functions. While the empirical results are strong, the paper lacks a direct comparison of the ADEN/RL method against modern deep clustering baselines (e.g., autoencoder-based clustering) on the same dataset, making it difficult to isolate the contribution of the autonomy modeling aspect from the benefits of using a deep Transformer model generally."}, "questions": {"value": "What is the practical stability and computational overhead of training the Transformer-based ADEN within the RL loop, especially for large $K$ clusters or very high-dimensional data, and did the authors observe sensitivity to ADEN initialization or hyperparameter choices? Is there a theoretical path to extend this framework to non-centroid-based clustering methods, such as those relying on density or connectivity, given the current formulation's dependence on cluster representatives $y_j$? Is the reported 10% performance gain over the known-model solution an isolated case, or can the authors provide statistics on how often the learning-based approach effectively escapes local minima across a broader range of problem instances?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6tSUBQnk8s", "forum": "mcxuhnQgLj", "replyto": "mcxuhnQgLj", "signatures": ["ICLR.cc/2026/Conference/Submission15625/Reviewer_mjED"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15625/Reviewer_mjED"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15625/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761473698903, "cdate": 1761473698903, "tmdate": 1762925890662, "mdate": 1762925890662, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces autonomy-aware clustering, a new formulation of the clustering problem that explicitly accounts for cases where individual entities may override their prescribed cluster assignments. For example, sensors sending data to a non-assigned base station or users acting outside expected preference groups. The authors formalize this idea by introducing a local autonomy model  that captures the probability of an entity originally assigned to cluster jj actually joining cluster kk. They first extend Deterministic Annealing clustering to this setting when the autonomy model is known, and then develop a reinforcement-learning-based approach (with a Transformer-based Adaptive Distance Estimation Network, ADEN) to learn the autonomy dynamics when unknown. Experiments on synthetic data and a decentralized sensing application (UAV placement over traffic sensors) show that the proposed method achieves near-optimal solutions even without explicit autonomy models, outperforming baselines that ignore autonomy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The paper raises a genuinely interesting and underexplored issue — that entities in clustering may act autonomously rather than passively following their assigned clusters. This perspective is both conceptually fresh and practically relevant, especially for systems with distributed agents (sensors, users, robots, etc.).\n    \n* Casting clustering with unknown autonomy as a one-step MDP is a clever move, allowing the use of RL techniques without explicit autonomy models.\n    \n* The synthetic and real-world experiments convincingly show that ignoring autonomy leads to significant degradation in performance, while the proposed model maintains small optimality gaps.\n\n* The paper manages to combine analytical results (e.g., β-annealing behavior) with practical deep-learning components (ADEN) in a coherent framework."}, "weaknesses": {"value": "- While the framing is fresh, it remains unclear how far this differs from existing probabilistic or soft-clustering models (e.g., mixture models, stochastic EM, or clustering with noisy assignments). In those methods, points also have probabilistic memberships, which may implicitly capture similar uncertainty. The paper could better clarify how “local autonomy” goes beyond mere stochasticity in assignments.\n    \n- The autonomy term is elegant mathematically but may be hard to interpret or estimate in real data. If autonomy stems from unobserved confounders, does the model risk overfitting to noise rather than uncovering meaningful autonomy?\n    \n- In many practical domains, deviations from assigned clusters could also be viewed as data noise, mislabeling, or temporary network failures, phenomena often handled by preprocessing rather than by modifying the clustering objective. The paper could better articulate when modelling autonomy is essential rather than optional.\n    \n* The RL + transformer-based approach (ADEN) seems quite heavy relative to the conceptual simplicity of the problem. The added learning complexity may limit adoption in standard clustering pipelines."}, "questions": {"value": "1. How does this framework differ fundamentally from soft or probabilistic clustering methods (e.g., GMMs, fuzzy c-means) that already allow stochastic assignments?  \n    What does the autonomy layer model that those do not?\n    \n2. In practice, how can one tell whether observed deviations reflect genuine _autonomy_ versus noisy or corrupted data?  \n    \n3. Does the method require retraining for every new dataset, or can the learned ADEN generalise across settings with similar autonomy patterns?\n    \n4. How sensitive is the method to the choice of annealing schedule or β-step size?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rJsMQwEzUF", "forum": "mcxuhnQgLj", "replyto": "mcxuhnQgLj", "signatures": ["ICLR.cc/2026/Conference/Submission15625/Reviewer_no6m"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15625/Reviewer_no6m"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15625/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761908513804, "cdate": 1761908513804, "tmdate": 1762925890190, "mdate": 1762925890190, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "## Summary\n\nThe paper presents autonomy-aware clustering, which allows entities (data points) to probabilistically deviate from their assigned clusters according to a probability distribution. \nIt extends Maximum Entropy Principle–based Deterministic Annealing (MEP-DA) by local autonomy distributions into the objective function. When the autonomy distribution is known, the authors provide analytical update rules and analyze convergence behavior. When it is unknown, they propose a neural network (ADEN) to estimate average costs through supervised learning, alternating between model training and cluster updates until an annealing threshold is reached.  The authors evaluate their method on synthetic and real-world traffic data. The results indicate that accounting for local autonomy improves clustering performance compared to ignoring it.\n\n## Contribution\n\nWhile I have reservations about whether local autonomy is a good model for decentralized sensing, I acknowledge that it could be an interesting problem to study. The theoretical contribution seems solid, albeit incremental."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- Local entity autonomy could be an interesting problem, and decentralized sensing is a plausible scenario.\n- The theoretical contribution seems solid, albeit incremental."}, "weaknesses": {"value": "## Soundness\n\nThe paper makes several unsubstantiated claims and has major methodological flaws:\n\n- The authors do not justify why local autonomy is a better model for decentralized sensing than other approaches.\n- The authors claim to use Reinforcement Learning but this is not justified, in my opinion (see detailed discussion below).\n- The MDP the authors claim to solve is never formalized.\n- The experimental setup has major flaws: the problems are contrived and artificial, the baselines are not clearly defined.\n- Some numerical results are missing (e.g., UDT19 dataset) and the empirical evaluation has major flaws. How can an algorithm achieve \"10% improvement over ground truth\"?\n- The claim \"These gaps can be further reduced through standard hyperparameter tuning and extended training\" is not supported by any evidence.\n- The problem formulation is presented as major contribution, but it is a straightforward extension of MEP-DA.\n\n## Presentation\n\nThe presentation is poor and needs significant improvement:\n\n- The writing is convoluted and hard to follow. The paper is full of jargon and undefined terms (e.g., \"entity\").\n- The figures/tables are low quality and hard to read.\n- The related work section is weak and does not contextualize the work well. Yes, other works do not use local autonomy, but how do they methodologically differ from this work? Why is local autonomy a better model?\n- The conclusion is completely missing.\n- Limitations are completely missing.\n\nI want to discuss the Reinforcement Learning aspect in more detail, as it is a major red flag for me. From my understanding, the first loop in Algorithm 2 performs the following steps:\n\n1. Assign new distances to all data points based on the current cluster centroids.\n2. Sample assignments using the currently learned soft assignment distribution $\\pi_\\theta$.\n3. Observe actual assignment outcomes using the autonomy distribution and update empirical costs.\n4. Update an exponential moving average of the costs.\n5. Update the neural network parameters $\\theta$ using supervised learning to minimize the squared error between the predicted costs and the empirical costs.\n\nThis is not Reinforcement Learning. It does not use an MDP formulation. There is no action space, state space, transition dynamics, or reward function. There is also no temporal component: While the training loop is run repeatedly, there is no temporal difference learning despite the claim of a \"straightforward Q-learning–style stochastic iterative update\". Instead, Algorithm 2 is supervised learning with an alternating optimization scheme. The authors should clarify this, or correct my misunderstanding by formally defining the MDP they are solving and the Bellman equation they are using."}, "questions": {"value": "- Why would I model the decentralized sensing problem with local autonomy instead of modeling interference/noise directly?  \n- Can the authors clarify why Algorithm 2 is using Reinforcement Learning?  \n- What MDP is Algorithm 2 solving? The authors should be able to formalize the action space, state space, transition dynamics, and reward function.  \n- What baseline is used in the results? MEP-DA w/o the local autonomy distribution?\n- In the results, the paper claims that \"Notably, when $\\kappa=0.1$ , $T = 0.1$, ADEN matches the performance of the model-based baseline (ground truth), and for $\\kappa=0.5$, T = 0.1 it achieves approximately a 10% improvement over the ground truth, despite the absence of an explicit autonomy model\".  \n  - What is the model-based baseline (ground truth)? Algorithm 1 with the true autonomy distribution?  \n  - How is it possible to outperform the ground truth?\n- Where are the numerical results for the UDT19 dataset?  \n- What are limitations of the proposed method? When would I use it over other methods and vice versa?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SYjS9iLsZV", "forum": "mcxuhnQgLj", "replyto": "mcxuhnQgLj", "signatures": ["ICLR.cc/2026/Conference/Submission15625/Reviewer_2opo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15625/Reviewer_2opo"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15625/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761925656110, "cdate": 1761925656110, "tmdate": 1762925889621, "mdate": 1762925889621, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}