{"id": "PDYQuxyAYI", "number": 17545, "cdate": 1758277381211, "mdate": 1759897168112, "content": {"title": "FedFFT: Taming Client Drift in Federated SAM via Spectral Perturbation Filtering", "abstract": "Federated Learning (FL) enables decentralized training without data sharing, but suffers from statistical heterogeneity across clients, leading to client drift, poor generalization, and sharp minima compared to centralized training. Sharpness-Aware Minimization (SAM) has emerged as a promising approach to improve generalization, yet its application in federated learning still suffers from divergence problems, since perturbations are computed locally and reflect client-specific loss geometries. To better understand this issue, we provide analysis from a new perspective, the frequency domain, for SAM perturbations in federated settings, revealing that inter-client perturbation inconsistencies are predominantly concentrated in the low-frequency spectrum. Motivated by this insight, we propose Federated learning with Frequency-domain Filtering of SAM perturbations (FedFFT). It is a lightweight and plug-and-play method that filters out low-frequency components of SAM perturbations without requiring additional communication, thereby suppressing inconsistent components in client updates while preserving consistent learning signals. Extensive experiments across multiple benchmarks and diverse backbones demonstrate that FedFFT consistently outperforms SAM-based FL methods, particularly under severe non-IID distributions. These results highlight the effectiveness, scalability, and general applicability of our frequency-domain perspective for sharpness-aware federated optimization.", "tldr": "", "keywords": ["federated learning", "Sharpness-Aware Minimization"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b3ca1b7cd9e7e3bbae8a911386f8d3c7e22750af.pdf", "supplementary_material": "/attachment/525f3039c99c7f1c9af474bca37a13acb92f0a63.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposed a novel frequency-domain perspective and a lightweight filtering method, namely FedFFT, to solve divergent perturbations in sharpness-aware federated learning (FL). Extensive experiments validate that FedFFT outperforms SOTA methods. However, I have some concerns as follows: 1) The theoretical analysis is missing, including convergence and generalization analysis; 2) A \nclipping method for perturbation tensor should be added as one of the baselines in the experiments; 3) I think that the computation complexity of the proposed method is large. The authors should add theoretical analysis and experiments to evaluate the proposed method from this aspect."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper proposed a novel frequency-domain perspective and a lightweight filtering method, namely FedFFT, to solve divergent perturbations in sharpness-aware federated learning (FL). Extensive experiments validate that FedFFT outperforms SOTA methods. Overall, this paper is well-written and the proposed method outperforms SOTA baselines."}, "weaknesses": {"value": "I have some concerns as follows: 1) The theoretical analysis is missing, including convergence and generalization analysis; 2) A \nclipping method for perturbation tensor should be added as one of the baselines in the experiments; 3) I think that the computation complexity of the proposed method is large. The authors should add theoretical analysis and experiments to evaluate the proposed method from this aspect."}, "questions": {"value": "My questions are shown as follows: \n1) The theoretical analysis is missing, including convergence and generalization analysis; \n2) A clipping method for perturbation tensor should be added as one of the baselines in the experiments; \n3) I think that the computation complexity of the proposed method is large. The authors should add theoretical analysis and experiments to evaluate the proposed method from this aspect."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JhsACSFS1H", "forum": "PDYQuxyAYI", "replyto": "PDYQuxyAYI", "signatures": ["ICLR.cc/2026/Conference/Submission17545/Reviewer_53SX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17545/Reviewer_53SX"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17545/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762078668233, "cdate": 1762078668233, "tmdate": 1762927417731, "mdate": 1762927417731, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper analyzes the instability of Sharpness-Aware Minimization (SAM) in federated learning under non-IID data and proposes FedFFT, which filters out the low-frequency components of SAM perturbations via Fourier transform to reduce cross-client inconsistency. The authors claim that (1) client drift in SAM mainly manifests in low-frequency spectral components, and (2) removing these components improves generalization and convergence. Experiments on CIFAR-10/100 and Tiny-ImageNet show performance gains over FedSAM and other SAM-based FL baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The motivation is intuitive: analyzing perturbations in frequency space is an interesting angle.\n- FedFFT is simple to implement and adds no communication overhead, making it practically deployable.\n- The method is compatible with multiple SAM variants and FL optimizers."}, "weaknesses": {"value": "- The core idea—removing low-frequency components to suppress bias while retaining high-frequency “invariant” signals—has already been widely explored in Fourier-based domain generalization and robustness literature (e.g., “A Fourier-Based Framework for Domain Generalization.”). This paper effectively transfers the same frequency-filtering trick from input space to perturbation space, without introducing a new optimization principle. The contribution feels more like an engineering adaptation.\n- The proposed filtering is a hard high-pass truncation with fixed ratio r, with no adaptive, learnable, or theoretically justified mechanism. Other gradient/perturbation smoothing strategies (e.g., norm projection, momentum regularization, proximal updates) are not compared, making it unclear whether FFT is uniquely effective or simply one of many workable heuristics.\n- All experiments are conducted on only three small-scale vision datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet) in simulated FL settings. There is no evaluation on larger, real-world, multi-modal, or cross-institution datasets. Given that the paper repeatedly claims the method is “plug-and-play” and “optimizer-agnostic,” the empirical evidence does not sufficiently support this level of generality."}, "questions": {"value": "- Why is FFT the correct basis rather than other orthogonal transforms or learned spectral projections?\n- Would the method still work if applied to gradients instead of SAM perturbations? \n- How does the method behave in personalization FL settings, where client-specific signals are desirable?\n- Have you tested FedFFT on a larger-scale dataset such as ImageNet-1k or a real FL benchmark (e.g., FEMNIST, MIMIC-III)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tZDIVkp3oJ", "forum": "PDYQuxyAYI", "replyto": "PDYQuxyAYI", "signatures": ["ICLR.cc/2026/Conference/Submission17545/Reviewer_ME7W"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17545/Reviewer_ME7W"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17545/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762092138273, "cdate": 1762092138273, "tmdate": 1762927417283, "mdate": 1762927417283, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper aims to solve the inconsistency of perturbations added by clients in Federated Learning Sharpness-Aware Minimization (FLSAM) problem. Transforming to the frequency domain, authors observe that inconsistency mainly lies in low-frequency parts of the perturbation signals, while high-frequency parts are relatively homogeneous. Based the observation, FedFFT is proposed, where the inconsistent low-frequency noises are filtered by a high-pass filter to mitigate the effect of non-iid data. Simulations results are provided, with comparison to different baselines, to illustrate the performance of the algorithm."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The idea of analyzing perturbation inconsistency is novel and inspiring, which I believe is transferrable to other aspects when facing data heterogeneity in FL."}, "weaknesses": {"value": "1. I am concerned about whether the proposed algorithm can be generally applied to other tasks, e.g., language or audio tasks. In other words, I wonder if inconsistency always lies in the low-frequency parts. Here is an example where I suspect inconsistency may lies in the high-frequency parts. Consider each client maintains an audio dataset, where each data sample is a piece of music performance consisting of a main melody and an accompaniment. Assume that the accompaniments in all clients’ data are similar (for example, all are cello accompaniments with the same frequency), while the main melodies may be played by different instruments such as violin, piano, or flute. In this case, inconsistency lies in high-frequency rather than low-frequency, as cello provides similar low-frequency parts for all clients. Could you explain how the proposed method can be generalized to this task?\n\n2. Another concern is about its computational efficiency. As FFT and inverse FFT are applied to each layer's output, the computation overhead might be an issue for large-scaled models. Could you quantify the computation of the method and how does it compare to other baselines?"}, "questions": {"value": "See Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HzxwHA78we", "forum": "PDYQuxyAYI", "replyto": "PDYQuxyAYI", "signatures": ["ICLR.cc/2026/Conference/Submission17545/Reviewer_vymE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17545/Reviewer_vymE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17545/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762219110605, "cdate": 1762219110605, "tmdate": 1762927416927, "mdate": 1762927416927, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces FedFFT, a simple and communication-free method to mitigate client drift in Sharpness-Aware Minimization (SAM)–based federated learning. The key idea is to analyze SAM perturbations in the frequency domain, showing that inter-client inconsistencies concentrate in low-frequency components. Building on this insight, the authors propose to apply a high-pass filter to locally computed SAM perturbations, removing low-frequency (client-specific) components while preserving high-frequency (task-consistent) ones. The resulting method integrates seamlessly with standard FL optimizers such as FedAvg, FedDyn, and SCAFFOLD, and achieves consistent improvements in accuracy, convergence speed, and communication efficiency across multiple datasets."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "I really enjoyed reading this paper. Although I am not an expert in federated learning, I found it to be a well-executed and clearly presented study. The main strength lies in the simplicity and clarity of the core idea—examining SAM perturbations through a frequency-domain perspective and proposing a straightforward filtering approach. The idea is conceptually clean and easy to understand, allowing the paper to communicate its motivation and method effectively. The presentation is clear and well-structured, and the authors support their claims with a range of empirical evaluations, which, while not exhaustive, provide reasonable evidence for the method’s potential. Overall, the work stands out for its conceptual neatness and clear exposition."}, "weaknesses": {"value": "While I liked the study and found the idea interesting, I do have some reservations. I am not an expert in empirical studies nor in federated learning, so I would be somewhat skeptical unless other reviewers can validate that the empirical components are well executed and robust.\n\nIn particular, I have the following concerns: First, the theoretical justification for the frequency-domain perspective is missing—the link between low-frequency components of SAM perturbations and client-specific biases is purely empirical and not formally established. Second, the meaning of frequency in parameter space is ambiguous; applying FFT to flattened weights lacks a clear interpretation tied to model structure. Third, the evaluation scope is narrow, focusing on vision datasets with synthetic Dirichlet heterogeneity, and does not test more realistic or diverse FL settings. Fourth, simpler baselines (such as random filtering or gradient smoothing) are not explored, making it hard to isolate the benefit of spectral filtering. Finally, the paper lacks any convergence or stability analysis, which would be important for understanding the method’s optimization behavior.\n\nI also have a few minor quibbles about the presentation. The authors claim to provide an analysis in the frequency domain (Intro contribution bold-faced point 1, line 77, and also abstract), but this “analysis” is entirely empirical and observational as far as I can see (Figure 1)—it was not clear a priori in the intro that this part is observational as well. Moreover, in Figure 1 and throughout the paper, the description of how the Dirichlet parameter $\\alpha$ quantifies client heterogeneity is missing; this is a central experimental factor and should be explicitly defined. The evaluation across architectures also feels limited, especially since the FFT is applied directly to parameter tensors—raising the question of how such filtering interacts with different architectures. Finally, the paper would benefit from providing at least a tentative theoretical explanation or hypothesis for why filtering in the frequency domain makes sense and under what kinds of data or model heterogeneity the method is expected to help—or potentially fail."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "4tSd24leDo", "forum": "PDYQuxyAYI", "replyto": "PDYQuxyAYI", "signatures": ["ICLR.cc/2026/Conference/Submission17545/Reviewer_DkAu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17545/Reviewer_DkAu"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17545/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762237775613, "cdate": 1762237775613, "tmdate": 1762927416336, "mdate": 1762927416336, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new method from the perspective of frequency domain to address the client drift problem, built upon the SAM perturbation. The proposed FedFFT method is motivated by the observation that client disagreement is predominantly a low-frequency phenomenon. Therefore, this paper proposes to filter perturbations in low frequency end and utilize the filtered perturbation for SAM updates. The effectiveness of the proposed algorithm is evaluated on various tasks and compared with benchmark methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed method is effective and the effectiveness is supported by simulation results. \n2. The new perspective also provides new insights to solve the client drift issue. \n3. The presentation and organization of the paper is good with easy to follow structure. The comparison of the proposed method with SOTA is sufficient."}, "weaknesses": {"value": "1. Lacks of theoretical analysis to support the effectiveness of the proposed method, which is critical. \n2. The added computation burden resulted from rFFT and inverse rFFT is not discussed, which I assume would be high. In that way, balancing accuracy and computation needs to be considered. \n3. The Tiny-imageNet does not have good accuracy on the selected models. Is that suitable to still use these models?\n4. Some formatting and polish suggestions: a) Line 156: $w_t\\rightarrow w^t$, Line 158: $w_{t+1} \\rightarrow w^{t+1}$. b) Line 558: inconsistent citation format, i,e., did not use full name of authors. c) Appendix C.4 wrong figure title, all used \"TinuImageNet\". d) Line 845\" \"Compare\"-> \"compare\". e) Line 917, \"As shown in Table 8\""}, "questions": {"value": "1. How is the perturbation radius is selected? In your experiment, you set the value to be 0.1. If you change the value, would the performance of your algorithm be affected?\n2. Do you have the learning curves of Cifar 10 and Cifar 100, similar as you presented in Figure 6.\n3. What is the computation complexity comparison of FFT based methods and solely SAM-based methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "PChtkY0W5T", "forum": "PDYQuxyAYI", "replyto": "PDYQuxyAYI", "signatures": ["ICLR.cc/2026/Conference/Submission17545/Reviewer_XV7M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17545/Reviewer_XV7M"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission17545/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762406364375, "cdate": 1762406364375, "tmdate": 1762927415931, "mdate": 1762927415931, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}