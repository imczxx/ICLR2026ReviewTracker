{"id": "Rt9SeEAMWv", "number": 2679, "cdate": 1757194875194, "mdate": 1763756602046, "content": {"title": "Stability, Complexity and Data-Dependent Worst-Case Generalization Bounds", "abstract": "Providing generalization guarantees for stochastic optimization algorithms remains a key challenge in learning theory.\nRecently, numerous works demonstrated the impact of the geometric properties of optimization trajectories on generalization performance. \nThese works propose worst-case generalization bounds in terms of various notions of intrinsic dimension and/or topological complexity, which were found to empirically correlate with the generalization error.\nHowever, most of these approaches involve intractable mutual information terms, which limit a full understanding of the bounds.\nIn contrast, some authors built on algorithmic stability to obtain worst-case bounds involving geometric quantities of a combinatorial nature, which are impractical to compute.\nIn this paper, we address these limitations by combining empirically relevant complexity measures with a framework that avoids intractable quantities.\nTo this end, we introduce the concept of \\emph{random set stability}, tailored for the data-dependent random sets produced by stochastic optimization algorithms. \nWithin this framework, we show that the worst-case generalization error can be bounded in terms of (i) the random set stability parameter and (ii) an empirically relevant, data- and algorithm-dependent complexity measure of the corresponding random set.\nMoreover, our framework improves existing topological generalization bounds by recovering previous complexity notions without relying on mutual information terms.\nThrough a series of experiments in practically relevant settings, we validate our theory by evaluating the tightness and of our bounds and the interplay between topological complexity and stability.", "tldr": "We introduce a novel framework for deriving data- and algorithm-dependent worst-case generalization bounds. As a result, our approach yields fully computable topological generalization bounds.", "keywords": ["learning theory", "topological generalization", "algorithmic stability"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f358697c210656d56c07c9205196ea3a00d515a1.pdf", "supplementary_material": "/attachment/6fdcad9ce424bc6da7d919e0d74d3f8fb9ddcdb2.zip"}, "replies": [{"content": {"summary": {"value": "This paper focuses on worst-case generalization on the weight trajectory/data-dependent set. The paper identifies that existing worst-case bounds have the following problems: They involve intractable information-theoretic or combinatorial nature quantities that are hard to compute, or they ignore the randomness of the algorithms.\nThis paper then develops random-set stability that considers algorithmic randomness and proves worst-case generalization gap can be bounded together by the stability and Rademacher complexity or fractal-based complexities. Empirical results show that the bounds are non-vacuous in many cases and successfully predict the interplay between the stability and fractal-based complexities."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- This paper reveals valuable problems in existing works of worst-case generalization, and thereby is well motivated. This problem is interested not only for worst-case bounds, but also in other topics, eg, generalization bounds using mutual information.  \n- This paper provides novel stability-based worst-case bounds with tractable quantities. The bounds not only recover several classic bounds, but also can be used with recent fractal-based complexities.\n- In experiments, the bounds are non-vacuous in many cases. \n- The paper is well written and clear to follow."}, "weaknesses": {"value": "1. The auto-satisfaction of local Lipschitzness in Line 315 seems incorrect because the Lipschitzness is not local wrt $z$. For example, for loss $\\\\ell(w, z) = \\\\|w - z\\\\|\\_2^2$ and some unbounded $\\\\mathcal{Z} \\\\subseteq \\\\mathbb{R}^d$, then one would have infinite $L_{S, U}$. More practically, one may have very large $L_{S, U}$ thanks to some samples $z$ (eg, $z$ that is out of distribution so that the trained weights drastically disagree on them, as in domain generalization scenes). \n 2. The paper has provided comprehensive discussion on existing works in trajectory-worst-case generalization bounds and reveals the problem of them. However, beyond these works, mutual-information-based bounds have also tried to solve similar problems of having unbounded IT quantities, which are not cited and discussed in this paper. For example, see [1,2,3] listed below. They essentially inject virtual random (which is also emphasized in this paper) noise and transform unbounded MI terms into bounded and easy-to-estimate MI terms (similar to stability in some sense) and robustness against the noises (similar to complexity and local Lipschitzness). Their drawbacks at least include reliance on local approximation, and assumptions or reliances on testing loss robustness which requires extra samples (like $\\tilde{S}$ to estimate Rademacher complexity).\n 3. One motivation of the paper is that algorithmic randomness is \"paramount to deriving stability-based bounds\". However, what specific benefits randomness brings are fully buried in the proof instead of being explained in the main text. \n     - I skimmed the proof of Lemma 3.4, where it seems that $U$ does not play important role. Indeed, if one sets $U$ to constant to remove randomness, the proof of course still goes well. It seems the improvement of Lemma 3.4 (eg, the form of empirically relevant Rad + stability) over existing bounds mainly come from some detailed technical improvement instead of exploitation of randomness $U$ (please correct me if wrong). \n     - Nevertheless, it seems that randomness $U$ indeed plays important role in reducing $\\beta_n$: If randomness is not used, then one has to incorporate randomness by seeing training algorithm instances with seed $U$ (like partial application) as fixed algorithms with different (Foster-style) stability $\\beta_{n, U}$, and taking expectation over $U$ (sth like $\\\\mathbb{E}\\_{U} \\\\mathbb{E}[G_S(\\\\mathcal{A}\\_U(S))] \\\\le \\\\mathbb{E}\\_{U}[\\\\dots]$). Then one has to take maximum of $\\beta_{n, U}$ over $U$, where some bad $U$ brings extreme looseness. In contrast, with this paper's random-set stability, one essentially replaces this maximum with expectation, which significantly down-weights those bad $U$s.\n 4. In experiments, the uniform stability is estimated by taking empirical maximum over hundreds of samples, which is obviously negatively biased. \n 5. The motivation and goal of \"interplay\" experiments are not quite clear to me. Is it validating the theoretical prediction that generalization is approximately proportionate to the complexity with the random-set stability as the factor that decreases as the training set increases? But from Table 1, learning rate, which is altered in the interplay experiments, can drastically change stability, and we should not expect a stable proportionate relation at all.\n 6. Minor typos:\n     - Lines 035,059,083,167,169,189...: one should use `\\citep{}` for these citations\n     - Line 866: \"index et\" -> \"index set\"?\n     - Line 877: \"$\\omega(S_1, S_2)$\" -> \"$\\omega(\\mathcal{W}_{S_1}, S_2)$\"?\n     - A lot of missing $U$ in the proof of Lemma 3.4?\n\n\n\n### References\n\n[1] Gergely Neu, Gintare Karolina Dziugaite, Mahdi Haghifam, and Daniel M. Roy. Information-theoretic generalization bounds for Stochastic Gradient Descent. In Proceedings of Thirty Fourth Conference on Learning Theory, pp. 3526–3545. PMLR, 2021.\n\n[2] Ziqiao Wang and Yongyi Mao. On the generalization of models trained with SGD: Information-theoretic bounds and implications. In International Conference on Learning Representations. ICLR, 2022.\n\n[3] Ze Peng, Jian Zhang, Yisen Wang, Lei Qi, Yinghuan Shi, and Yang Gao. Leveraging Flatness to Improve Information-Theoretic Generalization Bounds for SGD. In International Conference on Learning Representations. ICLR, 2025."}, "questions": {"value": "- Aside from uniform stability that considers the upperbound of hypothesis/loss change, there has been on-average stability that replaces $\\sup$ with expectation (eg, [4]), which is usually tighter and easier to estimate. Is it possible to integrate this on-average form into the random-set stability. Will that improve both tightness and estimation (related to my Weakness 4)?\n\n\n\n\n### References\n\n[4] Yunwen Lei and Yiming Ying. Fine-grained analysis of stability and generalization for stochastic gradient descent. In International Conference on Machine Learning, pp. 5809–5819, 2020."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hTGSh0WFlW", "forum": "Rt9SeEAMWv", "replyto": "Rt9SeEAMWv", "signatures": ["ICLR.cc/2026/Conference/Submission2679/Reviewer_PcQB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2679/Reviewer_PcQB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2679/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761853766732, "cdate": 1761853766732, "tmdate": 1762916329973, "mdate": 1762916329973, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work introduces an interesting class of generalization bounds based on “random set stability”, which is tied to the stability across the parameter trajectory of the algorithm. The aim of these bounds is to bound the worst-case generalization gap across a given window of the trajectory. Crucially, this bound is, unlike information-theoretic relatives, rather straightforward to compute. The authors conclude with experiments on Vision Transformers and GraphSage."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is clearly structured and articulated.\n2. The ability to numerically evaluate these bounds presents a clear advantage over Mutual Information based relatives."}, "weaknesses": {"value": "1. Unless one employs early stopping, the trajectory window at the end of training (assuming near convergence in parameter space) should be essentially a single point, plus tiny fluctuations. I believe that this might lead the presented bounds to be overtly optimistic in near-convergence training settings which is an important and prevalent setting in machine learning. This seems to be consistent to what is written around line 428.\n2. In deep learning, Lipschitz constants are typically very large (roughly exponential in the depth). This might further subtract from the achievable accuracy of the presented generalization bounds.\n3. I appreciate the inclusion of experiments. However, the results left me a bit confused. It is claimed (and seems to be experimentally supported) that a magnitude scale $\\approx \\beta_n^{-1/3}$ is a sound choice. This suggests that the bounds in Thm. 4.4 should become better as $n$ increases. However it seems that the bounds in fact become worse for larger sample size (e.g. Pearson correlation $0.28$ for GraphSage with n=10k). Could you please give me your thoughts on this?"}, "questions": {"value": "- See weaknesses\n- l. 125: unclear what is z_{i,j}"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GN3xeRLhYS", "forum": "Rt9SeEAMWv", "replyto": "Rt9SeEAMWv", "signatures": ["ICLR.cc/2026/Conference/Submission2679/Reviewer_aoKU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2679/Reviewer_aoKU"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2679/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989921108, "cdate": 1761989921108, "tmdate": 1762916329812, "mdate": 1762916329812, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces random set stability, a notion tailored for data-dependent, stochastic hypothesis sets like optimization trajectories. The authors derive an expected worst-case generalization bound that combines this stability parameter (beta_n) with a Rademacher complexity term. This term is computed on the observed random set Cal W_{S,U} using an auxiliary, independent sample. The central claim is that this framework provides computable, trajectory-based bounds without relying on the intractable mutual information (MI) terms that are common in related topological and fractal-based analyses."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "This paper studies an important and fundamental problem in generalization theory."}, "weaknesses": {"value": "The main weakness of the paper is the writing: it is very dense and the authors don't spend time in giving intuitions etc. Lets consider introduction. The summary of contribution involves discussion on beta_n without precisely defining it. Another example is Definition 3.1, what is G_S'(w)? the definitions need to be self-contained! Lemma 3.2 talks about trajectory-stability. IT hasn't defined clearly. How one can understand the statements?\n\nIn this version of the paper, it is very difficult to judge the contribution of this paper.\n\n\nThe other drawback is that this paper mentions that mutual information based bounds are difficult to estimate. For many optimization algorithms, we have results that implies mutual information terms in the bounds can be upper-bounded by simple quantities. For example, look at the following papers:\n\nNegrea, Jeffrey, et al. \"Information-theoretic generalization bounds for SGLD via data-dependent estimates.\" Advances in Neural Information Processing Systems 32 (2019).\n\nNeu, Gergely, et al. \"Information-theoretic generalization bounds for stochastic gradient descent.\" Conference on Learning Theory. PMLR, 2021."}, "questions": {"value": "I have two technical clarification questions. \n(1) In Lemma 3.4 you assume ~S_J is independent of S, but in the symmetrization step (and later discussion) it seems you need ~S_J to be independent of the random set W_{S,U}, which depends on both S and the algorithmic randomness U. Should the assumption be ~S_J ⟂ (S,U)? If not, how do you justify symmetrization when the index class is random and data-dependent? \n\n(2) In the projected-SGD corollary, the text summarizes the stability as O(T²/n), but the displayed expression appears to scale like (∑_t η_t)(∑_s η_s L²)/n; how does this reconcile with classical uniform-stability rates O((∑_t η_t)/n)? Could you clarify the precise assumptions (Lipschitz/smoothness/convexity), step-size regime, and whether there’s a typo in the exponents/summary rate?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "adRsXPVW15", "forum": "Rt9SeEAMWv", "replyto": "Rt9SeEAMWv", "signatures": ["ICLR.cc/2026/Conference/Submission2679/Reviewer_vF2R"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2679/Reviewer_vF2R"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2679/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762208129414, "cdate": 1762208129414, "tmdate": 1762916329670, "mdate": 1762916329670, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new theoretical framework to explain generalization in deep learning by analyzing the entire training trajectory. To avoid often uncomputable \"information-theoretic\" (IT) terms found in previous work the authors introduce \"random set stability\", a measure of how much the worst-case loss along the whole trajectory changes when training data is changed. They show that common algorithms (such as projected SGD) are stable, and then they derive a generalization bound that combines this random set stability parameter and a Rademacher complexity term, recovering some previous bounds as special cases. They claim this offers the first fully computable bound and validate the approach empirically on ViT and GraphSAGE, showing correlations between their bound's components and actual generalization gaps."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Novel stability framework that unifies point-wise points and uniform convergence bounds (by interpolating $J$)\n* Computable components"}, "weaknesses": {"value": "* Bound has convergence rate of $O(n^{−1/3})$ rather than the usual $O(n^{−1/2})$\n* The empirical validation relies on a seemingly very optimistic estimate of the $\\beta_n$ parameter\n* Empirical results seem to suggest a bound > 1 on a 0-1 loss"}, "questions": {"value": "I am afraid I am by no means an expert in this field so my review will have pretty low confidence, but I would love it if the authors could clarify the following:\n\n* Having a slower convergence rate seems like a really big downside. Can the authors please justify why they think this is an acceptable trade-off just to get rid of the information-theoretic terms in the bounds?\n* Is the estimation procedure of $\\beta_n$ defensible? Assumption 3.1 says that the stability parameter must hold for _any_ value $z \\in \\mathcal{Z}$, but algorithm 1 simply calculates the maximum over 1000 samples drawn from the training distribution (half seen, half unseen). This seems like a very optimistic estimate. What about points that fall outside of the training distribution? And is 1000 points really enough to estimate this supremum given the high dimensionality of the data? Would it be better to do some sort of hill climbing/optimization to find points for which the difference is large? My concern is that if this estimate is an under-estimate, than all the empirical results will seem much tighter than they actually are, right?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "V20hONLfJg", "forum": "Rt9SeEAMWv", "replyto": "Rt9SeEAMWv", "signatures": ["ICLR.cc/2026/Conference/Submission2679/Reviewer_UhsB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2679/Reviewer_UhsB"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2679/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762277952702, "cdate": 1762277952702, "tmdate": 1762916329442, "mdate": 1762916329442, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of deriving practical worst-case generalization bounds for stochastic optimization algorithms. It introduces random set stability, a novel framework tailored to data-dependent random sets (e.g., optimization trajectories), avoiding intractable mutual information terms in prior works. The framework bounds generalization error via the stability parameter and Rademacher complexity, recovering classical bounds and yielding computable topological bounds."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper introduces the novel concept of random set stability, creatively integrates algorithmic stability with a data-dependent random set framework, successfully avoids intractable mutual information terms in existing methods, and offers a fresh approach to deriving generalization bounds.\n2. Through rigorous mathematical deductions, this paper completes theorem proofs and the recovery of classical bounds, while conducting systematic experiments on real datasets using ViT and GraphSage models to validate the effectiveness and tightness of the proposed bounds.\n3. This paper provides the first fully computable topological/fractal generalization bounds free of mutual information terms, addresses the core limitation of previous related studies where complexity measures were hard to implement, and advances the application of learning theory in practical algorithms."}, "weaknesses": {"value": "1. This paper only provides expected generalization bounds instead of high-probability bounds, which limits the reliability of the framework in practical scenarios where probabilistic guarantees with strict confidence levels are needed.\n2. Estimating the stability parameter requires replacing part of the training samples and retraining, leading to high computational costs in large-sample scenarios without proposing efficient optimization schemes."}, "questions": {"value": "1. Could you please explain the advantage of your defined random set stability in detail compared with others? What if you change $\\omega'$ in Assumption 3.1 into $\\omega(\\mathcal{W}_{S',U},S')$?\n2. Is there any possibility of deriving high-probability generalization bounds?\n3. Have you explored any efficient estimation methods for the stability parameter $\\beta_n$ that avoid complete retraining after sample replacement?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XVCMAMCUiF", "forum": "Rt9SeEAMWv", "replyto": "Rt9SeEAMWv", "signatures": ["ICLR.cc/2026/Conference/Submission2679/Reviewer_3wS4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2679/Reviewer_3wS4"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission2679/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762769177300, "cdate": 1762769177300, "tmdate": 1762916329311, "mdate": 1762916329311, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}