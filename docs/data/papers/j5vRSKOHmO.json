{"id": "j5vRSKOHmO", "number": 12463, "cdate": 1758207992617, "mdate": 1763605675617, "content": {"title": "Multiple Streams of Knowledge Retrieval: Enriching and Recalling in Transformers", "abstract": "When an LLM learns a new fact during finetuning (e.g., new movie releases, updated celebrity gossip, etc.), where does this information go? Are entities enriched with relation information, or do models recall information just-in-time before a prediction? Are ``all of the above'' true with LLMs implementing multiple redundant heuristics? Existing localization approaches (e.g., activation patching) are ill-suited for this analysis because they usually replace parts of the residual stream, thus overriding previous information.\nTo fill this gap, we propose dynamic weight grafting, a technique that selectively grafts weights from a finetuned model onto a pretrained model. Using this technique, we show two separate pathways for retrieving finetuned relation information: 1) \"enriching\" the residual stream with relation information while processing the tokens that correspond to an entity (e.g., \"Zendaya\" in \"Zendaya co-starred with John David Washington\") and 2) \"recalling\" this information at the final token position before generating a target fact. In some cases, models need information from both of these pathways to correctly generate finetuned facts while, in other cases, either the \"enrichment\" or \"recall\" pathway alone is sufficient. We localize the \"recall'' pathway to model components---finding that \"recall\" occurs via both task-specific attention mechanisms and an entity-specific extraction step in the feedforward networks of the final layers before the target prediction. By targeting model components and parameters, as opposed to just activations, we are able to understand the mechanisms by which finetuned knowledge is retrieved during generation.", "tldr": "We propose dynamic weight grafting (grafting parameters from a finetuned to a pretrained model) to localize behavior to model components", "keywords": ["mechanistic interpretability"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/100371317f5686d3dc9d344c3dfc1191954906d3.pdf", "supplementary_material": "/attachment/beeac7592474ffcad87d28907a46c67995d8dfba.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces dynamic weight grafting, a technique to localize fine-tuned knowledge retrieval mechanisms in LLMs. Unlike activation patching (which replaces activations and destroys previous computations), dynamic weight grafting selectively swaps weights from finetuned models into pretrained models at specific layers, components, and token positions. The authors identify two retrieval pathways: (1) \"enrichment\" at entity tokens and (2) \"recall\" at the final token position. Key findings: both pathways together nearly recover full fine-tuning performance and grafting everything except these pathways yields near-zero accuracy. Recall operates through task-specific attention at entities/final token and relation-specific FFNs in final layers. Experiments use Llama3, Pythia, GPT2-XL, Gemma on synthetic relation completion datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Addresses previous method gap: activation patching conflates which components compute vs. pass through information, weight grafting isolates true mechanisms. Conducted ablations demonstrate both pathways are sufficient along with complement grafting to back the claims. Consistent results across multiple models Llama3/Gemma (strong recall) and GPT2-XL/Pythia (weaker recall, stronger enrichment). Granularity is impressive, localizes recall to ATTN O matrices + FFNs with task-specific attention, more precise than prior feedforward/attention papers. Importantly tests training task-specific vs. relation-specific models."}, "weaknesses": {"value": "Synthetic data limitation, may not reflect true complexity in other natural language prompts. Only relation completion is tested. I wonder if the findings extend to other tasks like reasoning or open-ended generation?\n\nA few of the final conclusions were already known."}, "questions": {"value": "How do results change with other types of prompts (e.g., Wikipedia text)? Are pathways applicable to paraphrasing beyond templates?\nWhat happens with real factual data where models have partial pre-existing knowledge (compared to fully synthetic facts)?\nCan the authors explicitly highlight the findings of their work that were already known and the ones that were novel?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ps3E9gldQo", "forum": "j5vRSKOHmO", "replyto": "j5vRSKOHmO", "signatures": ["ICLR.cc/2026/Conference/Submission12463/Reviewer_6duy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12463/Reviewer_6duy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12463/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761857784145, "cdate": 1761857784145, "tmdate": 1762923344052, "mdate": 1762923344052, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes \"dynamic weight grafting,\" a novel interpretability method that intervenes on model parameters (weights) instead of activations, avoiding the limitations of activation patching. Using this method, the authors investigate knowledge retrieval from SFT. They find that new knowledge is retrieved via two primary, localized pathways: an \"Enrichment\" (E) path at the entity's tokens and a \"Recall\" (R) path at the final token. Experiments establish these pathways as both necessary and sufficient. The paper further uses component grafting to localize the \"R\" pathway to specific attention mechanisms, O-matrices, and FFNs."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "**Novel and Sound Methodology**: The core contribution, \"dynamic weight grafting,\" is a clever and valuable addition to the interpretability toolkit. It correctly identifies a key flaw in standard activation patching (conflating information computation with information passing) and proposes a more precise causal intervention by swapping the mechanisms (weights) themselves.\n\n**Clear, Rigorous Findings**: The identification of the 'E' and 'R' pathways is a clear and compelling finding. The authors were rigorous in their analysis, using complement experiments ((FE+LT)^C) to establish both the sufficiency and necessity of these pathways.\n\n**Deep Mechanistic Localization**: The paper doesn't stop at the token level. The component grafting experiments in Section 3.3 are particularly strong, using the \"reversal curse\" setup to dissect the \"R\" pathway into its constituent parts (task-specific attention vs. relation-specific FFN/O-matrix). This provides a granular, plausible mechanism for how recall functions."}, "weaknesses": {"value": "## Experimental Concerns\n\n1. **Unexplained Model-Specific Strategies**: A significant concern is the inconsistent behavior across models, which the paper notes but fails to adequately explain. In Figure 2, the performance of LT (Last Token) versus FE^C (which includes LT) shows large, unexplained disparities in models like GPT2-XL. More importantly, the paper notes that models like Gemma/Llama favor a strong 'R' path, while GPT2-XL/Pythia favor an 'E' path. For an interpretability paper, why these divergent strategies emerge is as important as the fact that they do. The paper's attempt to correlate this with architecture (e.g., RoPE) is unsatisfying, as the groupings are inconsistent (Pythia has RoPE but groups with GPT-2). A more concrete hypothesis and-ideally-a simple experiment to test it are needed. The current explanation feels arbitrary.\n\n2. **Limited Scope (Synthetic SFT Data)**: The reliance exclusively on synthetic, templated SFT data severely limits the generality of the findings. Are these 'E' and 'R' pathways a general mechanism for knowledge retrieval, or are they an artifact of this specific, narrow, templated SFT setting? One could argue that the model is simply overfitting to the template, learning to \"plug in\" information at the entity (E) or \"look up\" the answer at the end (R). Maybe it can include even a preliminary discussion or experiment using dynamic weight grafting to explore pre-trained knowledge (e.g., on LAMA probes), to contrast it with these SFT-induced mechanisms.\n\n3. **Weakness of Top-5 Accuracy Metric**: The choice of Top-5 accuracy as the primary metric is questionable and potentially misleading. The authors' defense of this metric (citing \"uncertainty\" in Appendix A.2) is directly contradicted by their own data in Appendix C.9.2. An example for a Gemma 'LT' graft shows the target \"Uta\" with a probability of 0.008, while the incorrect token \"John\" has a probability of 0.901. This is not \"uncertainty\"; this is high-confidence error. This metric choice masks the important nuance of how a mechanism fails (e.g., by confidently predicting the wrong thing). Using a more sensitive metric like logit difference (on the correct token) or mean target rank (as shown in C.1.2) as the primary metric in the main text would be far more rigorous and convincing.\n\n## Writing and Clarity Concerns\n\n1. **Undefined Terms**: The core concepts of \"enrich\" (E) and \"recall\" (R) are introduced abruptly in Section 3.1 as if they are experimental conclusions. The paper fails to provide a clear, a priori definition of what information flow processes these terms are hypothesized to represent. What does it mean for a token to be \"enriched\"? This makes the results section difficult to follow, as the reader is learning the definitions from the experimental results themselves.\n\n2. **Bloated and Repetitive Result Presentation**: The presentation of results in the main text and appendix is highly repetitive and buries the key insights. The appendix is inundated with dozens of charts (e.g., Fig 6, 7, 10, 11, 12) that all show the exact same experiment on different models or datasets, reinforcing the same basic point. The true insight—that different model architectures have different E/R preferences—is lost in this flood of redundant figures."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "awImhaSJmi", "forum": "j5vRSKOHmO", "replyto": "j5vRSKOHmO", "signatures": ["ICLR.cc/2026/Conference/Submission12463/Reviewer_qgGX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12463/Reviewer_qgGX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12463/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761893870695, "cdate": 1761893870695, "tmdate": 1762923343760, "mdate": 1762923343760, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Dynamic Weight Grafting to localize how SFT-injected relational knowledge is retrieved from LLMs at inference time. Instead of activation patching, DWG swaps parameters of a fine-tuned model into a pre-trained model selectively by token position or component during generation. The authors construct synthetic relation datasets to train on GPT-2-XL, Pythia-2.8B, Llama-3, Gemma-1.1. The authors identify two retrieval pathways: (i) enrichment at the first-entity tokens and (ii) recall at the last token before prediction. Either pathway can partially recover SFT performance; FE+LT recovers near-SFT, while grafting the complement drops to pre-trained level. Component grafting further pins recall to task-specific attention at FE/LT and relation-specific O-projection + FFN in late layers."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper proposes an innovative way to probe how relational knowledge is retrieved from parameters without directly overriding residual stream, like activation patching.\n- Datasets and experiments are tightly controlled, yielding strong, clean and strong evidence that enrichment at the first token and recall at the last token jointly recover fine-tuning performance.\n- Component grafting reveals insights for how late-layer O-projection + FFN at the final token and task-specific attention at the first token are necessary for retrieval and recall.\n- Overall, the writing is very clear. The experiments and ablations are well designed and easy to reproduce."}, "weaknesses": {"value": "- It is not clear if similar mechanism can generalize to real-world data and if the findings still hold as model size scales.\n- The study is conducted on one-hop relational task; findings for position and component grafting may not transfer to multi-hop settings. The claims should be tempered accordingly to the scope of the task."}, "questions": {"value": "1. How sensitive are conclusions or findings to evaluation choices? Was any human auditing performed to check robustness?\n2. In Table 1, the QA appears synthetically phrased to mirror the headline. Do the findings persist under lexically diverse or paraphrased question formulations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MfWXGjJmeB", "forum": "j5vRSKOHmO", "replyto": "j5vRSKOHmO", "signatures": ["ICLR.cc/2026/Conference/Submission12463/Reviewer_Yvnw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12463/Reviewer_Yvnw"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12463/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761956346791, "cdate": 1761956346791, "tmdate": 1762923343399, "mdate": 1762923343399, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Dynamic Weight Grafting (DWG), a new method for studying how fine-tuned knowledge is retrieved in Transformer-based LLMs. Unlike activation patching, DWG swaps model weights rather than activations, allowing analysis of mechanisms without overwriting upstream computations. Using this method, the authors identify two distinct retrieval pathways for fine-tuned facts:\n\n- Enrichment Pathway: Relation information is integrated while processing entity tokens.\n\n- Recall Pathway: The model retrieves stored information at the final token before prediction.\n\nExperiments across several LLMs (Llama3, GPT-2 XL, Gemma, Pythia) show that both pathways together nearly recover fine-tuning performance, and either can sometimes suffice independently. The recall mechanism is localized to attention and feedforward layers in later Transformer blocks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Novel methodology: DWG is an original and potentially useful interpretability technique that avoids the destructive limitations of activation patching.\n- Comprehensive experiments: Multiple models and datasets are tested, showing consistency of findings.\n- Clear conceptual framing: The paper offers an intuitive distinction between “enrichment” and “recall” processes in LLM memory retrieval.\n- Potential for broader application: The approach could generalize to other interpretability or knowledge editing analyses."}, "weaknesses": {"value": "- Synthetic and simplistic setting: The experiments rely heavily on artificial datasets (e.g., fake movies and actors), which limits external validity.\n- Limited theoretical insight: The method identifies where retrieval occurs but not why or how specific mechanisms encode relations.\n- Insufficient analysis of failures: Cases where grafting fails (e.g., certain models or directions) are mentioned but not deeply analyzed."}, "questions": {"value": "Please see the weaknesses part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "iUDjHWhS18", "forum": "j5vRSKOHmO", "replyto": "j5vRSKOHmO", "signatures": ["ICLR.cc/2026/Conference/Submission12463/Reviewer_Mt2g"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12463/Reviewer_Mt2g"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12463/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762001286737, "cdate": 1762001286737, "tmdate": 1762923343118, "mdate": 1762923343118, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}