{"id": "ShEDWasmDG", "number": 5401, "cdate": 1757907405228, "mdate": 1763719031421, "content": {"title": "HARP: Hallucination Detection via Reasoning Subspace Projection", "abstract": "Hallucinations in Large Language Models (LLMs) pose a major barrier to their reliable use in critical decision-making. Although existing hallucination detection methods have improved accuracy, they still struggle with disentangling semantic and reasoning information and maintaining robustness. To address these challenges, we propose HARP (Hallucination detection via reasoning subspace projection), a novel hallucination detection framework. HARP establishes that the hidden state space of LLMs can be decomposed into a direct sum of a semantic subspace and a reasoning subspace, where the former encodes linguistic expression and the latter captures internal reasoning processes. Moreover, we demonstrate that the Unembedding layer can disentangle these subspaces, and by applying Singular Value Decomposition (SVD) to its parameters, the basis vectors spanning the semantic and reasoning subspaces are obtained.\nFinally, HARP projects hidden states onto the basis vectors of the reasoning subspace, and the resulting projections are then used as input features for hallucination detection in LLMs. By using these projections, HARP reduces the dimension of the feature to approximately 5% of the original, filters out most noise, and achieves enhanced robustness. Experiments across multiple datasets show that HARP achieves state-of-the-art hallucination detection performance; in particular, it achieves an AUROC of 92.8% on TriviaQA, outperforming the previous best method by 7.5%.", "tldr": "", "keywords": ["Hallucination detection", "Subspace", "Projection", "SVD"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b46ae45a37a23d20e2153474a50211b3222cb2f9.pdf", "supplementary_material": "/attachment/93b788e483fff82fa2d8d0c2527fefc1b32c682b.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces HARP, a novel framework for detecting hallucinations in Large Language Models (LLMs). The central claim is that the final hidden state space of an LLM can be decomposed into a direct sum of two orthogonal subspaces: a \"semantic subspace\" and a \"reasoning subspace.\" The authors posit that the model's unembedding layer parameter matrix, W_unemb, inherently separates these two spaces. By applying Singular Value Decomposition (SVD) to W_unemb, the authors identify the basis vectors for these subspaces. Specifically, right singular vectors corresponding to large singular values are proposed to span the semantic subspace, while those corresponding to near-zero singular values are claimed to span the reasoning subspace.\nThe proposed method, HARP, projects the final hidden states onto this identified \"reasoning subspace\" to generate low-dimensional features. These features are then fed into a two-layer MLP classifier to produce a token-level hallucination score. The final hallucination score for a given response is the maximum score across all its tokens. The authors conduct experiments on several open-domain QA datasets (NQ Open, TruthfulQA, TriviaQA, TyDiQA) using Qwen-2.5-7B and LLaMA-3.1-8B models, reporting state-of-the-art performance in terms of AUROC."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Novelty of Approach: The core idea of leveraging the spectral properties of the unembedding matrix to derive features for a downstream task is novel and interesting. It moves beyond standard probing or output-based consistency checks by attempting to ground the detection mechanism in the model's internal structure, which is a commendable direction for mechanistic interpretability.\n2. Simplicity and Efficiency: The proposed method is technically straightforward and computationally efficient. It relies on a one-time SVD pre-computation and a simple projection, avoiding costly iterative sampling or complex architectural modifications. If validated and efficient at scale, this would represent a practical and scalable approach for hallucination detection.\n3. Strong Empirical Results on Tested Benchmarks: The paper presents compelling empirical results, consistently outperforming several established baselines across multiple datasets and two different model architectures. The reported gains, such as a 7.5% AUROC improvement on TriviaQA, are significant and suggest that the extracted features are indeed highly informative for hallucination detection in the tested settings."}, "weaknesses": {"value": "The paper suffers from fundamental weaknesses in its theoretical grounding and argumentation.\n1. Unsupported Foundational Premise: The cornerstone of this work—the decomposition of the hidden state space into orthogonal \"semantic\" and \"reasoning\" subspaces—is presented as a discovery but is, in fact, an unsubstantiated assertion.\n  ○ The paper transitions from a high-level cognitive analogy directly to a formal mathematical claim (Eq. 3) without providing any theoretical justification, empirical evidence from prior work, or logical deduction. Statements like \"we establish that the hidden state space ... can be decomposed\" are misleading; the property is not established, but is postulated.\n  ○ The properties defined in Eq. 5 and Eq. 6 are the very definitions the authors introduce. The subsequent claim \"Based on the properties...\" is a form of circular reasoning. The validity of the entire framework rests on this unproven assumption, making the subsequent technical development an exercise built on a fragile foundation.\n2. Misleading Terminology and Lack of Conceptual Rigor: The choice to label the near-null space of W_unemb as the \"reasoning subspace\" is highly speculative and lacks evidence.\n  ○ The authors provide no causal or correlational evidence linking this subspace specifically to what is commonly understood as \"reasoning\" (e.g., chain-of-thoughs, self-reflection, etc.). An alternative, and perhaps more plausible, hypothesis is that this subspace captures any information orthogonal to the final token prediction, which could include contextual noise, computational artifacts, or simply redundant features.\n  ○ Attaching the loaded term \"reasoning\" to this mathematically-derived space overstates the paper's findings and risks misdirecting future research. A more scientifically cautious term, such as \"output-orthogonal subspace,\" would be more appropriate.\n3. Arbitrary Formulation and Disconnected Sections: The mathematical modeling in Section 3.1, which defines hallucination via a similarity function sim and threshold λ, is both arbitrary and disconnected from the main technical contribution of the paper. This section does not inform the subsequent SVD-based methodology and its inclusion suggests a lack of a coherent, unified theoretical framework.\n4. Limited Experimental Scope and Unaddressed Scalability Concerns: The empirical evaluation, while strong on its specific benchmarks, is narrow and fails to address critical questions about the method's applicability to larger, state-of-the-art models.\n  ○ The experiments are confined to 7B/8B parameter models. It is unclear if the observed spectral properties of W_unemb and the effectiveness of HARP will generalize to much larger models (e.g., 70B+), where hallucination behaviors may differ.\n  ○ The paper does not discuss the computational feasibility of performing a full SVD on the unembedding matrix of a model with a very large vocabulary and hidden dimension (e.g., >128k vocabulary, >8192 hidden dim). This is a critical practical consideration for the method's scalability.\n  ○ Given the fact that Mixture-of-Experts (MOE) framework becomes status-quo choice in open-sourced and proprietary model developement, the experiment design does not reflect that its claim is applicable to a wide range of LLM design choices. The proposed method fails to generalize its impact in the mainstream research."}, "questions": {"value": "To be more confident in my assessment, I would like the authors to address the following:\n1. Can you provide any theoretical justification or cite prior work that supports the claim that the hidden state space naturally decomposes into orthogonal semantic and reasoning components, and that the unembedding layer acts as the separator? Beyond the analogy, what is the mechanistic basis for this hypothesis?\n2. How do you defend the specific label \"reasoning subspace\"? Have you conducted any analysis to show that activity in this subspace correlates with explicit reasoning steps (e.g., in chain-of-thought prompting, mathematical problems, or logical puzzles) and is not just capturing other forms of non-semantic information?\n3. Could you elaborate on the computational cost of applying SVD to the unembedding matrices of much larger models, such as those with vocabulary sizes exceeding 100,000 and hidden dimensions exceeding 8,192? Is the proposed method practical for state-of-the-art foundation models?\n4. Why should the community believe that findings on 7B/8B models are representative of hallucination phenomena in significantly larger models? Have you considered any experiments or analysis to suggest this generalization holds?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pVFnGAcDXI", "forum": "ShEDWasmDG", "replyto": "ShEDWasmDG", "signatures": ["ICLR.cc/2026/Conference/Submission5401/Reviewer_Vnht"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5401/Reviewer_Vnht"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5401/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761929228323, "cdate": 1761929228323, "tmdate": 1762918038884, "mdate": 1762918038884, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes HARP (Hallucination Detection via Reasoning Subspace Projection), a framework for detecting hallucinations in Large Language Models (LLMs)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Comprehensive Experimental Validation: The experiments cover diverse datasets (open-domain QA, reading comprehension) and models.\n\n2. Novel Theoretical Insight: The paper introduces a meaningful decomposition of the LLM hidden state space into semantic and reasoning subspaces."}, "weaknesses": {"value": "1. Limited Generalization to Larger Models: The experiments only use medium-sized LLMs (Qwen-2.5-7B-Instruct, LLaMA-3.1-8B). It remains unclear whether HARP can maintain its performance on larger-scale models (e.g., 70B or 175B parameters), as the structure of hidden state spaces and the role of the Unembedding layer may change with model scale.\n\n2. Ambiguity in Reasoning Subspace Interpretation: While the paper defines the reasoning subspace as capturing internal reasoning processes, it lacks a more concrete, interpretable validation (e.g., linking specific components of the reasoning subspace to specific reasoning steps). This makes it difficult to fully confirm that the projected features truly reflect \"reasoning\" rather than other irrelevant hidden state information.\n\n3. Sensitivity to SVD Parameter Selection: The paper sets the semantic subspace dimension k=d×95%, based on singular value distribution, but it does not thoroughly explore how different k values (e.g., 90%, 98%) affect detection performance across diverse datasets and models. This may limit the adaptability of HARP to different LLM architectures.\n\n4. Lack of Comparison with Recent Advanced Methods: The baseline methods include relatively early works (e.g., Perplexity from 2023) but lack comparisons with the latest hallucination detection methods (post-2024) that also focus on model internal states. This makes it hard to fully position HARP’s competitiveness in the current state of the art.\n\n5. Practical Deployment Challenges: Although HARP reduces feature dimensions, it still requires accessing the hidden states of LLMs—a requirement that may not be feasible for closed-source LLMs (e.g., GPT-4, Claude 3). The paper does not discuss solutions for such scenarios, limiting its practical application scope."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UXjKYwBjJr", "forum": "ShEDWasmDG", "replyto": "ShEDWasmDG", "signatures": ["ICLR.cc/2026/Conference/Submission5401/Reviewer_NZ6Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5401/Reviewer_NZ6Q"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5401/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761947504725, "cdate": 1761947504725, "tmdate": 1762918038635, "mdate": 1762918038635, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents HARP (HAllucination detection via Reasoning subspace Projection), a framework for hallucination detection that mathematically decomposes the hidden state space into semantic and reasoning subspaces. The approach employs SVD on the Unembedding layer to derive basis vectors representing these subspaces, enabling hidden states to be projected onto the reasoning subspace, which then serves as the input to a hallucination detector. HARP achieves substantial feature compression (to about 5% of the original dimensionality) while isolating reasoning-related signals crucial for identifying hallucinations. Experiments across multiple datasets (NQ Open, TruthfulQA, TriviaQA, TyDiQA) and models show state-of-the-art AUROC performance, surpassing existing approaches and baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Research Innovation: The paper offers a novel perspective by interpreting LLM hallucinations through the decomposition of the hidden state space into semantic and reasoning subspaces. This conceptual framing provides new insight into the underlying mechanisms of hallucination generation.\n2. Computational Efficiency: By projecting hidden states onto the reasoning subspace, the method effectively compresses feature dimensionality to about 5% of the original space, significantly improving both computational efficiency and robustness.\n3. Methodological Effectiveness: As shown in Table 1, HARP achieves substantially higher AUROC scores than competing baselines across four QA datasets and two LLMs. The results demonstrate strong consistency and robustness across different data domains and model architectures. The paper also conducts comprehensive ablation studies and analyses to support its conclusions.\n4. Clarity of Presentation: The methodology is clearly described and easy to follow."}, "weaknesses": {"value": "1. Overreliance on SVD and orthogonality assumptions. HARP relies heavily on the assumption that the hidden representations can be effectively decomposed via SVD into orthogonal semantic and reasoning subspaces. In practice, neural network weight matrices rarely yield strictly zero singular values, and the orthogonality assumption may not strictly hold. Although Section 4.3 mitigates this issue using an approximate low-rank solution, the reliability of this decomposition requires more rigorous empirical validation and theoretical justification.\n2. Limited experimental scope and insufficient diversity. The current experiments are primarily conducted on QA datasets, which may not fully reflect the generalization ability of HARP. It would strengthen the paper to evaluate the method on a broader range of tasks—particularly those involving more complex logical reasoning (e.g., mathematical reasoning datasets) and non-QA settings. Moreover, experiments on additional model architectures and scales are necessary, since the compatibility of some methods may vary with model size and vocabulary distribution. Including additional evaluation metrics such as ECE or F1 would also provide richer insights. Finally, the paper does not clarify whether results are averaged over multiple runs or report variance, which raises concerns about the robustness and statistical significance of the findings.\n3. Lack of analysis on overconfidence and hallucination dynamics. LLMs are known to exhibit overconfidence, particularly on datasets with high accuracy. It would be valuable to analyze how HARP behaves under such conditions—e.g., comparing hallucination patterns and performance changes across models and datasets with varying accuracy levels. A differential analysis between correct and incorrect responses could also offer deeper insight into how HARP mitigates hallucinations."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "lQ22ojvUI8", "forum": "ShEDWasmDG", "replyto": "ShEDWasmDG", "signatures": ["ICLR.cc/2026/Conference/Submission5401/Reviewer_EBLo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5401/Reviewer_EBLo"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5401/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761967621145, "cdate": 1761967621145, "tmdate": 1762918038365, "mdate": 1762918038365, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces HARP, a novel framework for hallucination detection in LLMs. The core hypothesis is that an LLM's hidden state space can be decomposed into a \"semantic subspace\" and a \"reasoning subspace\". The authors propose to identify these subspaces by applying SVD to the unembedding matrix. They define the \"reasoning subspace\" as the one spanned by the basis vectors corresponding to the smallest singular values. The method then projects the final-layer hidden states onto this low-dimensional \"reasoning subspace\" and uses these projections as features to train a simple MLP classifier for hallucination detection. \n\nThe paper reports state-of-the-art results on several QA datasets, suggesting high accuracy and efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The core idea of separating semantic and reasoning information by analyzing the unembedding matrix is novel and insightful.\n\nThe reported experimental results show a significant improvement over existing baselines, which is impressive."}, "weaknesses": {"value": "The evaluation is confined to simplistic tasks that are misaligned with modern, critical LLM use cases.\n\nThe paper's entire empirical validation rests on short-form, factual question-answering datasets like NQ Open, TruthfulQA, and TriviaQA. While HARP demonstrates strong performance, these tasks are arguably \"solved\" problems for state-of-the-art LLMs and do not represent the true frontier of the current hallucination challenge. If this paper were submitted two years ago, its contribution would be significant, but the field has rapidly advanced. The critical applications where robust hallucination detection is most needed today are in:\n\n- Long-form generation (e.g., summarization, report writing)\n\n- Complex reasoning (e.g., multi-step math or logic problems)\n\n- Agentic workflows (e.g., software development and tool use)\n\n- ......\n\nIn these complex scenarios, hallucinations manifest as subtle logical fallacies, fabricated evidence, inconsistent reasoning steps, or non-existent API calls—not just the simple factual errors tested in this paper (e.g., \"The capital... is Shanghai!\").\n\n\nThe core assumption of HARP is that a \"reasoning subspace\" can be isolated and used for detection. However, the paper provides no evidence that this method can capture these more complex, structural, and procedural forms of hallucination. It is highly unclear whether the proposed technique can generalize beyond the simple, factual-recall domain to address the far more difficult and relevant problems facing LLMs today.\n\n----\n\nThe paper appears to be missing a critical and directly relevant baseline: Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models.\n\nThis work is highly relevant as it proposes a method for hallucination detection that also leverages the model's internal states. Specifically, the authors of that paper develop a Classifier that receives the contextualized embeddings of each token during the LLM’s inference process. It then outputs a probability indicating the probability of hallucination in the LLM’s output.\n\nGiven the strong methodological overlap (i.e., using internal representations/embeddings during inference for classification), this paper should be considered a key baseline.\n\nI strongly recommend that the authors:\n\n- Discuss this paper in the related work section.\n\n- Include it as a baseline in the experimental comparison and discuss how the current submission's performance and methodology differ.\n\n\n\n\nI am open to increasing my score if the authors address these points."}, "questions": {"value": "Please refer to the previous section"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "g19twhkcl1", "forum": "ShEDWasmDG", "replyto": "ShEDWasmDG", "signatures": ["ICLR.cc/2026/Conference/Submission5401/Reviewer_VdiQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5401/Reviewer_VdiQ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5401/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994323331, "cdate": 1761994323331, "tmdate": 1762918038052, "mdate": 1762918038052, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}