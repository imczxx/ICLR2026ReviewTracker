{"id": "fDC5WeLeqh", "number": 17046, "cdate": 1758271530415, "mdate": 1759897202178, "content": {"title": "AWM: Accurate Weight-Matrix Fingerprint for Large Language Models", "abstract": "Protecting the intellectual property of large language models (LLMs) is crucial, given the substantial resources required for their training. Consequently, there is an urgent need for both model owners and third parties to determine whether a suspect LLM is trained from scratch or derived from an existing base model. However, the intensive post-training processes that models typically undergo‚Äîsuch as supervised fine-tuning, extensive continued pretraining, reinforcement learning, multi-modal extension, pruning, and upcycling‚Äîpose significant challenges to reliable identification. In this work, we propose a training-free fingerprinting method based on weight matrices. We leverage the Linear Assignment Problem (LAP) and an unbiased Centered Kernel Alignment (CKA) similarity to neutralize the effects of parameter manipulations, yielding a highly robust and high-fidelity similarity metric. On a comprehensive testbed of 60 positive and 90 negative model pairs, our method demonstrates exceptional robustness against all six aforementioned post-training categories while exhibiting a near-zero risk of false positives. By achieving perfect scores on all classification metrics, our approach establishes a strong basis for reliable model lineage verification. Moreover, the entire computation completes within 30s on an NVIDIA 3090 GPU.", "tldr": "", "keywords": ["fingerprint", "large language models", "intellectual property"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8ff664151c797f096b35b633376b3e5689c6157c.pdf", "supplementary_material": "/attachment/08aa8746993df0f067b6046ded1856b830767cfd.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose AWM, a method based on centered kernel alignment to fingerprint and compare LLMs. It is more accurate than competing methods such as HuRef and REEF on a large set of different LLMs of different families. However, it requires knowledge of all the weights of the LLMs to be compared."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- Empirically the new proposed algorithm is quite strong, improving upon previous methods such as HuRef and REEF in distinguishing between related and unrelated LLMs on a fairly large set of LLMs tested.  \n\n- The algorithm works directly with weight matrices and only uses centered kernel alignment computation and the Hungarian algorithm for finding permutations, and is therefore very efficient. \n\n- The authors give a detailed list of potential weight manipulations on different parts of the transformer architecture by an attacker in Section 4 and explain how this guides the design of their algorithm."}, "weaknesses": {"value": "- This fingerprinting method requires access to the weights of the models to be compared, which isn't always possible unless both models are open-sourced. This limits the applicability of the method compared to other fingerprinting approaches. \n\n- In Section 4 the authors discuss how an attacker might manipulate the weights to evade detection. However, these manipulations are never evaluated against the algorithm in the experiments. This creates a gap in the argument of the paper."}, "questions": {"value": "- Have the authors consider how to apply their method to other forms of manipulations/infringement such as model distillation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dAjUDapyZj", "forum": "fDC5WeLeqh", "replyto": "fDC5WeLeqh", "signatures": ["ICLR.cc/2026/Conference/Submission17046/Reviewer_Wyog"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17046/Reviewer_Wyog"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17046/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761748306877, "cdate": 1761748306877, "tmdate": 1762927060258, "mdate": 1762927060258, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes AWM, a training-free, white-box fingerprint for LLMs that combines LAP-based layer matching with an unbiased CKA similarity to measure model lineage directly from weights. The experimental suite spans six common post-training transformations (SFT, continued pretraining, RL-based alignment, multimodal extension, pruning, and MoE upcycling) over 60 positive and 90 negative pairs. The method is computationally efficient (single-GPU, sub-minute per pair) and requires no instrumenting or watermarking of the target model."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.The method is minimalist and targeted, focusing on embeddings and Q/K, which makes LAP+linear CKA implementation straightforward and efficient (single-GPU, sub-minute).\n2.Dynamic layer assignment via LAP addresses the weakness of fixed layer-to-layer comparisons and tolerates moderate architectural edits.\n3.It requires no data collection, retraining, or watermark insertion, so it does not degrade model quality and is easy to operationalize.\n4.Empirically, the approach cleanly separates derived from independent models (AUC=1.0, TPR@1%FPR=100%), implying near-zero false-positive risk."}, "weaknesses": {"value": "1.The pipeline relies on overlaps in token embeddings and Q/K weights; if the suspect model re-trains the tokenizer or heavily replaces early blocks, the LAP matching can become unstable and |Z| may drop.\n2.In cases of knowledge distillation, AWM will likely fail because cross-model weights exhibit near-zero statistical correlation despite functional similarity. Notably, recent alleged infringement incidents (e.g., API-based distillation claims) fall into this category.\n3.Although LAP provides some structural elasticity, it presupposes roughly comparable sets of alignable matrices. If the suspect model adds/removes many layers or alters layer roles, matching can break or produce erroneous alignments. While permutation invariance should not affect CKA in principle, aggressive layer reordering can still mislead the LAP stage and degrade end-to-end performance.\n4.Since the method is simple and single, the attacker can try to perform some lossless transformation on the AWM model to reduce the CKA similarity but maintain the model output. This is not difficult to achieve.\n5.The approach evaluates one-to-one similarity and does not address models fused from multiple sources (e.g., model ùê∂ partly derived from ùê¥ and ùêµ).\n6.The only comparison methods are HuRef and REEF. Why are there no comparisons with baselines used in REEF, such as PCS and ICS?\n7.The related work section recommends adding some black box-based methods. Currently, piracy through APIs is also very common."}, "questions": {"value": "1.The first step of the method relies on a shared vocabulary. How should we handle cases where the suspect model retrains or replaces its tokenizer/vocabulary?\n2.Does the author have any insights on piracy cases involving knowledge distillation? Could lightweight black-box probes be combined with AWM to first flag potential distillation cases?\n3.When the architecture undergoes significant depth/width changes, cross-layer sharing, or reordering of blocks, can you constrain the LAP with structural priors to prevent misalignment?\n4.Since the method is very simple, it becomes easier to attack. How can this issue be addressed?\n5.Have you considered approaches for mixed-origin cases, for example, solving multiple partial LAPs and reporting a mixed (or mixture) score?\n6.Release an evaluation sheet (model names/versions, checkpoints, tokenizer specs, training corpus tags), and precise CKA/LAP implementation details (module selection, sampling of parameter blocks, normalization, kernel choices).\n7.It is recommended to add some comparison methods and, if possible, add explicit ablation experiments"}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety"]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JeN6zkJCcJ", "forum": "fDC5WeLeqh", "replyto": "fDC5WeLeqh", "signatures": ["ICLR.cc/2026/Conference/Submission17046/Reviewer_z54L"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17046/Reviewer_z54L"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17046/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761803064281, "cdate": 1761803064281, "tmdate": 1762927059083, "mdate": 1762927059083, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a method for LLM intellectual property (IP) protection, aiming to overcome the vulnerabilities of current fingerprinting schemes, which are often not robust against intensive post-training and malicious weight manipulations. The authors introduce AWM (Accurate Weight-Matrix Fingerprint), a novel, training-free, intrinsic weight-based fingerprinting scheme designed to be highly robust to such modifications. The method's core mechanism leverages the Linear Assignment Problem (LAP) and an unbiased Centered Kernel Alignment (CKA) similarity metric. This process first extracts permutation and signature transformations from the word embedding matrices via LAP , and then uses the CKA-based metric to robustly compare the Q and K matrices across layers, a design intended to neutralize the effects of parameter manipulations like orthogonal transformations. Experimental results demonstrate that AWM achieves perfect classification scores and shows exceptional robustness."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The idea of this paper is novel.\n- This paper presents promising results.\n- This paper provides a comprehensive theoretical analysis."}, "weaknesses": {"value": "- Dependency on Word Embeddings: The method relies heavily on the word embedding matrix. An attacker could potentially defeat the detection by freezing all other layers and only replacing or retraining the embedding layer, which may cause the method to fail.\n\n- Limited Detection Scope: The method's scope is restricted to $W_Q$ and $W_K$ matrices. An attacker could steal other components (e.g., implanting stolen FFN blocks into an MoE model). This form of partial theft would likely go undetected.\n\n- Other suggestions for improving the writing:\n  - The theoretical analysis in Section 4 is somewhat confusing.  It may be better for the authors to first introduce the basic ideas and conclusions at the beginning of the section to improve readability.\n\n  - The Related Work section on fingerprinting is limited, focusing mostly on traditional classification models and only two LLM fingerprinting papers. It may be better for the authors to conduct a more exhaustive survey to enrich this section."}, "questions": {"value": "Please refer to the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PvYafkurIP", "forum": "fDC5WeLeqh", "replyto": "fDC5WeLeqh", "signatures": ["ICLR.cc/2026/Conference/Submission17046/Reviewer_fYwn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17046/Reviewer_fYwn"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17046/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761804898534, "cdate": 1761804898534, "tmdate": 1762927058588, "mdate": 1762927058588, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a mechanism to \"fingerprint\" an LLM. This is to find out if an LLM is trained from scratch or is a finetuned/derived version of a different LLM. The paper evaluates their methods on multiple models, different post training techniques and they achieve perfect scores in all classification metrics."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The computation completes within 30 seconds on a single NVIDIA 3090 GPU.\n\nThe method does not require any additional training and does not impact the LLM's performance (as other watermarking approaches)\n\nThe evaluation is very comprehensive across multiple llama models and multiple offspring variations where models are post trained with sft, continued pretraining, RL. \n\nThey also present a false positive evaluation with 90 known to be unrelated pairs, where they show other approach like REEF shows significant false positives mostly for models that use same training data sources."}, "weaknesses": {"value": "Maybe lack of experiments with larger models and other model architectures like MoE."}, "questions": {"value": "Any thoughts on how this will work with MoE models?\n\nAny thoughts on how this will work if the post training is done with LoRA methods and or adding new layers of randomly initialized parameters."}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety"]}, "details_of_ethics_concerns": {"value": "Perhaps the results of privacy and IP concerns for some of the model pairs should be  look up thoroughly, even if the paper claimed them to be as false positives from other methods (see Fig 2)."}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "du6gkwq06p", "forum": "fDC5WeLeqh", "replyto": "fDC5WeLeqh", "signatures": ["ICLR.cc/2026/Conference/Submission17046/Reviewer_tHGT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17046/Reviewer_tHGT"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17046/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761922145182, "cdate": 1761922145182, "tmdate": 1762927058042, "mdate": 1762927058042, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}