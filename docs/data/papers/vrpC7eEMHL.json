{"id": "vrpC7eEMHL", "number": 16167, "cdate": 1758260889572, "mdate": 1759897257217, "content": {"title": "Conformal Language Generation with Collaborative Ranking and Dynamic Thresholds", "abstract": "Large language models (LLMs) face significant challenges in providing reliable uncertainty quantification for language generation. We introduce a novel conformal prediction framework specifically designed to enhance this reliability through Collaborative Ranking and Dynamic Thresholds. Our method innovatively departs from traditional metrics by harnessing advanced LLM capabilities for comparative judgment, allowing it to rank candidate responses and form a robust, rank-based nonconformity score. This approach enables the construction of prediction sets with rigorous statistical guarantees that inherently adapt to diverse input difficulties and prompt complexities. Extensive experiments across varied question-answering domains consistently demonstrate significant improvements in conditional coverage, delivering precisely calibrated LLM outputs demanding extended reasoning and factual accuracy. We have provided code with implementation details in the repository below: https://anonymous.4open.science/r/512499.", "tldr": "", "keywords": ["Conformal prediction", "large language model", "conditional validity"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7dce3192602d6e807c069e205231ca09d7dd4f96.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Proposes to use one LLM to generate multiple responses and another LLM to rank responese by quality/factuality to construct conformal prediction sets. Experiments are conducted on MedicalQA, Natural Questions, FactScore, and MATH datasets shows better conditional coverate over conformal baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "* Rank based conformality score to model LLM factuality with adaptive calibration threshold for question difficulty is interesting."}, "weaknesses": {"value": "* Lack of technical novelty beyond applying existing components e.g. conformal prediction, LLM self-ranking, adaptive thresholding. Little insight of broader interest beyond existing work.\n* Ranking score is heuristic and no formal treatment is provided to show exchangeability under ranking\n* Superficial evaluation and lacking ablation experiments regarding model size, datasets, tasks, and ranking schemes\n* Overuse of pseudo-academic phrasing and LLM-generated writing degrades clear presentation \n* Factual correctness via entailment” is ungrounded—entailment models are unreliable, especially across domains like medical QA or math.\n* No qualitative human evaluation to verify factuality\n* Links to \"dual-process theory\" and \"speculative decoding\" are tenuous"}, "questions": {"value": "* What is the computational cost of generating and ranking many responses per question? How does it compare to standard conformal methods\n* How is \"ranking factual correctness\" defined and operationalized? \n* What models and prompts were used for ranking?\n* How is exchangeability preserved under ranking with LLM heuristics?\n* What if the LLM generator and ranker are the same?\n* How is the proposed method different from Zhou 2026? \n*"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "quC0L0YMtn", "forum": "vrpC7eEMHL", "replyto": "vrpC7eEMHL", "signatures": ["ICLR.cc/2026/Conference/Submission16167/Reviewer_yo8P"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16167/Reviewer_yo8P"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16167/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761355904135, "cdate": 1761355904135, "tmdate": 1762926330803, "mdate": 1762926330803, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes RankConf and AdaptiveRankConf, novel conformal prediction frameworks that use collaborative ranking between LLMs to provide factuality guarantees for language generation. The key innovation is generating K candidate responses from a lower-tier LLM, having a higher-tier LLM rank them by quality, and using rank-based nonconformity scores with conformal prediction to filter responses with distribution-free coverage guarantees."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Unlike prior work using log-probabilities or token-level scores, this paper cleverly exploits LLMs' comparative judgment capabilities through ranking, which is conceptually appealing and better aligned with how humans assess quality.\n\n2. Theorem 4.1 provides clear marginal coverage guarantees (P[correctness] ≥ 1-α), and the proof is straightforward and valid.\n\n3. Figure 1 shows AdaptiveRankConf maintains near-ideal coverage across difficulty levels, significantly outperforming SplitConf on hard questions (Level 3).\n\n4. Tests on 4 datasets (MedicalQA, NQ, FactScore, MATH) with multiple model combinations and ablations on K and temperature.\n\n5. AdaptiveRankConf achieves 38.56% retention on MedicalQA vs 30.24% for SplitConf while maintaining coverage."}, "weaknesses": {"value": "1. Paper claims to be \"practical\" but provides no wall-clock time comparisons, API cost estimates, or latency analysis despite requiring 50× API calls per query.\n\n2. 50× calls to lower-tier model + 1× call to higher-tier model makes total cost >> single-model baselines, undermining practical applicability.\n\n3. Paper claims cost savings but provides no evidence ranking is cheaper than generation.\n\n4. If higher-tier model misjudges factuality during ranking, entire framework fails, but this is not analyzed.\n\n5. No correlation with human rankings, no analysis of ranking errors, no comparison across model pairs.\n\n6. Table 4 shows CovGap varies 6× across model combinations (0.011 to 0.066) but no explanation of when/why this occurs."}, "questions": {"value": "1. What is the actual cost-benefit analysis? Provide concrete numbers:\n\n2. Why not use the higher-tier model directly for generation? If it can judge factuality well enough to rank, why introduce the lower-tier model at all? The cost savings argument needs quantitative support.\n\n3. How sensitive is the method to K? Figure/table showing coverage, set size, and **cost** as K varies from 5 to 100.\n\n4. Does this work beyond QA? Demonstrate on at least one non-QA task (e.g., summarization, code generation, creative writing).\n\n5. How were features chosen? What happens with different feature sets? Is there a principled way to select features?\n\n6. What happens if you artificially degrade ranking quality (e.g., by using a weaker ranker)? How does coverage degrade?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IZG11966Jj", "forum": "vrpC7eEMHL", "replyto": "vrpC7eEMHL", "signatures": ["ICLR.cc/2026/Conference/Submission16167/Reviewer_F4W8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16167/Reviewer_F4W8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16167/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761523501915, "cdate": 1761523501915, "tmdate": 1762926329908, "mdate": 1762926329908, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel approach to uncertainty quantification through Collaborative Ranking and Dynamic Thresholds. The goal is to improve factual accuracy and reliability in LLM outputs, particularly for complex, high-stakes tasks such as healthcare and education. The authors present a rank-based conformal prediction framework called RankConf, which leverages a lower-version LLM to generate candidate responses and a higher-version LLM to rank those responses based on their factual correctness. This method ensures that the final output is factually correct with high probability, addressing shortcomings of traditional probabilistic metrics."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The approach uses a ranking system based on LLM capabilities to rank candidate answers, forming a robust, rank-based nonconformity score to generate prediction sets with statistical guarantees.\n\n2.  By adjusting thresholds based on question difficulty, the paper achieves enhanced conditional validity, making the method more robust across a range of input difficulties.\n\n3. The method introduces dynamic thresholds that adapt to input complexity, ensuring more accurate responses for simple queries and applying stricter filtering for complex or challenging queries."}, "weaknesses": {"value": "1.The method relies heavily on the quality of the ranking mechanism between the low- and high-version models. If the gap between the two models' capabilities is not large enough, the ranking may fail to effectively distinguish between factually correct and incorrect responses. This could result in misranked candidates and affect the overall factuality of the generated outputs.\n\n2.Introducing a multi-tier ranking system, where responses are ranked not just by two models but through multiple models of varying capabilities, might improve the reliability of the ranking process. Additionally, more detailed experiments could be performed to understand the sensitivity of the method to the ranking model's performance.\n\n3. In domains requiring multi-step reasoning or abstract problem-solving, the proposed method might not consistently maintain factual correctness, as it mainly relies on factual entailment and simpler input features.\n\n4. The paper could explore efficiency optimizations, such as early stopping mechanisms during candidate generation or using lighter-weight models for ranking tasks. Additionally, investigating the possibility of reducing the number of candidate generations based on the complexity of the input could help strike a better balance between quality and computational cost."}, "questions": {"value": "1. How does the model handle scenarios where the factual correctness of a response is context-dependent rather than just a matter of entailment? For example, if the input prompt requires reasoning over multiple steps or integrating knowledge from multiple domains, would the rank-based conformal prediction still provide reliable factuality guarantees? This could be a limitation if the ranking mechanism does not account for such complex reasoning chains.\n\n2. What is the potential impact of dataset bias on the effectiveness of the ranking mechanism and the non-conformity scores? If the calibration dataset has inherent biases or imbalances in difficulty levels across queries, could this lead to suboptimal performance in certain real-world scenarios, especially in tasks that involve minority or edge cases? How might the framework adapt to mitigate this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HTubBeTn2J", "forum": "vrpC7eEMHL", "replyto": "vrpC7eEMHL", "signatures": ["ICLR.cc/2026/Conference/Submission16167/Reviewer_znDo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16167/Reviewer_znDo"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16167/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761743661006, "cdate": 1761743661006, "tmdate": 1762926329193, "mdate": 1762926329193, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces RankConf and AdaptiveRankConf, two conformal prediction methods for reliable language model generation. A smaller LLM generates candidate answers, while a stronger LLM ranks them by factual quality; responses below a calibrated rank threshold form the final prediction set. The adaptive version adjusts thresholds based on input difficulty for better conditional coverage. Experiments on datasets including MedicalQA, Natural Questions, FactScore, and MATH show that the proposed methods achieve similar or slightly better overall coverage than prior conformal factuality methods"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Addresses an important problem \n- The method accounts for input difficulty, which is specifically important in factual qa.\n- Experiments cover several diverse QA datasets\n- Proposed method shows consistent coverage across datasets."}, "weaknesses": {"value": "- Throughout the main paper, the authors state that ranking is at the response level. However, the prompts and the sample outputs provided in the appendix (tables 7-8) convey the other way - that a response is decomposed into claims first, then the claims are ranked, and lower ranks are combined etc. If the proposal actually runs at the claim level, how is it different from CondSplitConf?\n\n- Experimental results show that AdaptiveRankConf coverage is very close to CondSplitConf. However, it introduces significantly more computation due to sampling many generations (experiments vary between 10-100). With superior computational requirements and very close coverage levels, CondSplitConf seems to be a better option. \n\n- I don't see the necessity of defining S and M functions. Doesn't y* ⇒ M(S(y)) mean the same as y* ⇒ y, since we only do atomic claim decomposition and merge the claims without any intermediate process?\n\nMinor: space and dot are missing in lines 423 and 431."}, "questions": {"value": "Each generation is labeled as correct or incorrect at the passage level. However, many generations may contain both correct and incorrect claims. I wonder what combining a response level and a subclaim level method would lead to."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fHgSvDPWkU", "forum": "vrpC7eEMHL", "replyto": "vrpC7eEMHL", "signatures": ["ICLR.cc/2026/Conference/Submission16167/Reviewer_9aKN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16167/Reviewer_9aKN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16167/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972132550, "cdate": 1761972132550, "tmdate": 1762926328712, "mdate": 1762926328712, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}