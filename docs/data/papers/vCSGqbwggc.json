{"id": "vCSGqbwggc", "number": 11118, "cdate": 1758189708652, "mdate": 1759897607330, "content": {"title": "EduVerse: A User-Defined Multi-Agent Simulation Space for Education Scenario", "abstract": "Reproducing cognitive development, group interaction, and long-term evolution in virtual classrooms remains a core challenge for educational AI, as real classrooms integrate open-ended cognition, dynamic social interaction, affective factors, and multi-session development rarely captured together. Existing approaches mostly focus on short-term or single-agent settings, limiting systematic study of classroom complexity and cross-task reuse.\nWe present \\textbf{EduVerse}, the first \\emph{user-defined} multi-agent simulation space that supports environment, agent, and session customization. A distinctive human-in-the-loop interface further allows real users to join the space. Built on a layered \\textbf{CIE} (\\textbf{C}ognition–\\textbf{I}nteraction–\\textbf{E}volution) architecture, EduVerse ensures individual consistency, authentic interaction, and longitudinal adaptation in cognition, emotion, and behavior—reproducing realistic classroom dynamics with seamless human–agent integration.\nWe validate EduVerse in middle-school Chinese classes across three text genres, environments, and multiple sessions. Results show: \\textbf{(i) Instructional alignment}: simulated IRF rates ($0.28$--$0.64$) closely match real classrooms ($0.37$--$0.49$), indicating pedagogical realism; \\textbf{(ii) Group interaction and role differentiation}: network density ($0.27$–$0.40$) with about one-third of peer links realized, while human–agent tasks indicate a balance between individual variability and instructional stability; \\textbf{(iii) Cross-session evolution}: the positive transition rate $R^{+}$ increase by 11.7\\% on average, capturing longitudinal shifts in behavior, emotion, and cognition and revealing structured learning trajectories.\nOverall, EduVerse balances realism, reproducibility, and interpretability, providing a scalable platform for educational AI. The system will be open-sourced to foster cross-disciplinary research.", "tldr": "", "keywords": ["AI4Education; Large Language Models; Educational AI"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/faa3909142d439bc4566b07f5083bd839c35b8c4.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes an LLM-based multi-agent simulation designed for educational settings. Specifically, they try to capture the dynamics of cognitive development and classroom interactions over time."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "- Educational psychology theories back up the design of the simulation components\n- The simulation captures a lot of factors that go into classroom dynamics, such as seating arrangements, varying personalities, emotions, etc.\n- They performed rigorous experiments validating different aspects of the model. \n- The results are quite promising. The interaction dynamics resemble behaviors observed in real classroom settings."}, "weaknesses": {"value": "- Not sure if the authors can claim to be the first multi-agent simulation space for education since I found some existing papers that use multi-agent simulations in the education domain [a, b], aside from those already cited in the more comprehensive related works in the appendix. Granted that they are doing different things, \"multi-agent simulation space for education\" is broad enough to encompass their works as well.\n\n[a] Xu, S., Wen, H. N., Pan, H., Dominguez, D., Hu, D., & Zhang, X. (2025, April). Classroom Simulacra: Building Contextual Student Generative Agents in Online Education for Learning Behavioral Simulation. In Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems (pp. 1-26).\n\n[b] Arana, J. M., Carandang, K. A. M., Casin, E. R., Alis, C., Tan, D. S., Legara, E. F., & Monterola, C. (2025, July). Foundations of PEERS: Assessing LLM Role Performance in Educational Simulations. In ACL 2025 Student Research Workshop.\n\n- Evaluations on the temporal dynamics / trajectories are a bit weak in my opinion. They are not backed up by any data but only rather vague statements like \"clear individual differences\", \"sustained positive affect\", etc. \n\n- The memory management and knowledge progression is also not quite clear. The authors mention that they are adjusted based on behavioral signals such as bloom level and response type. However, there does not seem to be very convincing validation of this design."}, "questions": {"value": "- Regarding the temporal dynamics experiments, it is not quite clear what we expect the curves to be. What is a valid trajectory and what is not? Does any curve that exhibit positive transitions / shifts valid? How well does this match reality?\n- How do you manage the memory? How do you decide what gets stored and what gets forgotten? How well does this match realistic human student memory recall?\n- How are the emotions being probed? Is it just through direct prompting, or do you also ask the agents to answer some kind of questionnaire similar to what we would give a human participant?\n- Out of curiosity, are you able to capture problematic student behaviors? It would be very interesting to simulate interventions or management strategies for them."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "toI4VdW9yG", "forum": "vCSGqbwggc", "replyto": "vCSGqbwggc", "signatures": ["ICLR.cc/2026/Conference/Submission11118/Reviewer_LQGY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11118/Reviewer_LQGY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11118/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761812755773, "cdate": 1761812755773, "tmdate": 1762922292673, "mdate": 1762922292673, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents EduVerse, a user-defined multi-agent simulation framework for educational scenarios. It introduces a Cognition–Interaction–Evolution (CIE) architecture to simulate realistic classroom dynamics among virtual students and teachers. EduVerse enables customization of agents, environments, and interactions, while supporting human-in-the-loop participation. The authors evaluate the system through simulated and real classroom experiments in Chinese language teaching, showing that EduVerse can reproduce authentic teaching dynamics and capture long-term learning evolution. The platform demonstrates promising potential for educational research, intelligent tutoring, and social learning analysis."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Solid theoretical foundation – The CIE framework is conceptually well-motivated and systematically designed, combining cognitive modeling, social interaction, and evolution mechanisms.\n\nRich and diverse experiments – The authors conduct multiple experiments across different educational aspects (cognitive alignment, group interaction, long-term evolution), providing strong empirical support."}, "weaknesses": {"value": "Unclear system details – The description of the system’s user interface and real-user interaction mechanism (how students and teachers use EduVerse) is vague and underdeveloped.\n\nLimited explanation of real-world experiments – Although the paper claims real classroom validation, the implementation details of these experiments (e.g., how data were collected, how participants interacted) are not clearly stated..\n\nScalability and generalization – The experiments are confined to a specific subject (Chinese language classes), and the system’s adaptability to other domains remains untested."}, "questions": {"value": "Questions:\n1. What does \"IRF\" mean? This abbreviation appears in abstract without providing any full name before.\n2. For the LLM, you mentioned that you use \"InternVL\" and \"GPT-4\" (In line 216-219), do you fine-tuning the LLMs via education data to get better results?\n3. You mention that \"EduVerse provides a human-in-the-loop interface that admits real students or teachers alongside virtual agents\" (Line 281-282), how can students and teachers in the real world interact with the system? Does the user interface (UI) is something like the UI of ChatGPT?\n4. Do the names appear in the experiment part like \"Zhang Jie\", \"Liu Li\" are the names of your simulated student agent or real student name in the real world?\n5. Do you have more information about experiments conducted in real world classrooms? It seems that all the experiments in the experiment part are conducted in simulators.\n\nSuggestions:\n1. As the author provide so much appendix, I recommend add a table of contents before appendix part.\n\nTypos:\n1. In Fig1, ②: Mr. Zhuvividly => Mr. Zhu vividly\n2. In Fig1, circle a: Cognition Engin => Cognition Engine"}, "flag_for_ethics_review": {"value": ["Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "details_of_ethics_concerns": {"value": "The paper should explicitly report ethical approval and detailed procedures for user experiments to meet HCI and educational research standards (e.g., IRB review, informed consent, participant demographics, and data handling)."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yhWUtSc2al", "forum": "vCSGqbwggc", "replyto": "vCSGqbwggc", "signatures": ["ICLR.cc/2026/Conference/Submission11118/Reviewer_Zq4a"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11118/Reviewer_Zq4a"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11118/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761843349125, "cdate": 1761843349125, "tmdate": 1762922292332, "mdate": 1762922292332, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a framework, EduVerse, for user-defined multi-agent simulation in the context of AI in education. The authors deployed  EduVerse in middle school Chinese language classes with diverse educational  tasks, rich emotional expression, and complex interaction structures. The authors also conducted empirical experiment with existing frameworks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- Timely topic focusing on the AI in education and LLM \n- In-depth analysis of related work \n- The proposed framework  combines the cognitive, interactive, and  evolutionary dynamics of developmental agents in the context of AI in education\n- Deployed in classrooms showcases the practical impact\n- Human-in-the-loop interface allows real teachers and students  to enabling simulation, causal testing, and validation"}, "weaknesses": {"value": "For designing an intelligent tutoring system, it is crucial to take into account the subject domain. For example, students cognitive, help seeking behavior, and peer discussion vary widely across math vs writing an essay in literature vs introductory programming. \n\nThe prior work by other researchers cited by the authors are also domain specific. Would the authors say how to incorporate the framework for a specific subject domain with different question difficulties and knowledge base?"}, "questions": {"value": "Please see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "hjoWUL4MzR", "forum": "vCSGqbwggc", "replyto": "vCSGqbwggc", "signatures": ["ICLR.cc/2026/Conference/Submission11118/Reviewer_2hzb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11118/Reviewer_2hzb"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11118/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761932210426, "cdate": 1761932210426, "tmdate": 1762922291882, "mdate": 1762922291882, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce EduVerse, a “user‑defined multi‑agent simulation space” for virtual classrooms built around a Cognition–Interaction–Evolution (CIE) architecture layered over a Perception–Cognition–Action loop. Users can customize the seat graph/layouts, teacher/student agents,, and sessions (multi‑lesson trajectories). A human‑in‑the‑loop interface lets real users join a simulated class. Figure 1 lays out the three components, user‑defined environment, CIE agent modeling, and interaction/evolution experiments. \nThe authors’ core claim is the simulated instructional realism of a typical classroom (measured by IRF rates)."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "I think this is a very interesting idea with a good approach but I have alot of reservations about the claims made by the authors.\n\nFocusing on the positives, I think the work done itself is good. There are plenty of good uses for a simulator of this type, especially ones that involve a human in the loop. \n\nI do like the modular CIE breakdown, the explicit teacher pacing controller, and that the tasks are already implemented. The range of evaluation criteria is good, even if I have some concerns about them. IRF alignment, B/E/C distributions, small‑graph network summaries, ablations, human–agent tasks, and a cross‑session measure. \n\nMy favorite part is probably the CIE-based agent modeling. I think there’s alot of potential in the ideas that the authors outlined here with how the process of teacher-led group discussion can play out."}, "weaknesses": {"value": "While there’s alot to like about this paper, I think there are some pretty severe issues with the main claim:\n\n- The authors position EduVerse as the “first” user‑defined multi‑agent classroom simulator. But they even acknowledge other pre-existing multi-agent class room simulators in their own related work, and other general agent set ups (ie, AgentVerse) that already support role‑based, IRF‑style interactions. \n\n- The Abstract and Table 1 frame IRF rates as “close” to real classes, but Table A4 shows sizeable divergences (e.g., Argumentative Essay, Lecture: 0.639 vs. 0.417 real). ESPECIALLY with a signal as noisy as teacher-led discussion in classes, I feel like it's hard to take any purely quantitative analyses at face value without some kind of qualitative evidence to back it up. \n- There’s a lack of details about how many classes/schools were used as the comparison baseline and, again, who annotated the logs who could provide qualitative evidence as backup. \n- The system labels its own cognition (Bloom) and emotion during the Monitor step, then reuses these labels for evaluation (BEC distributions). If im not misunderstanding, this is basically just the model asking itself if it's correct, which doesnt seem super reliable.\n- The authors  fine‑tune VLM backbones (InternVL/LLaVA/Qwen‑VL/MiniCPM) for text‑only style, trained on ~6k utterances. Why VLMs for text style control? The authors also report InternVL “achieved the highest scenario‑grounded performance,” but the metric and protocol aren’t shown. \n- Not a huge negative but a heads up, for Figure 1, the middle section has “Cognition Engin” instead of “Cognition Engine”"}, "questions": {"value": "- Did the authors inspect the generated EduVerse logs vs the conversation logs of a real classroom?\n- Were all experiments/baselines drawn from the same classroom or different classrooms?\n- What was the motivation for using VLM backbones for what seems, to me, a largely text-based scenario?"}, "flag_for_ethics_review": {"value": ["Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "details_of_ethics_concerns": {"value": "I might have missed it but my concern is primarily with the participants in the 'Chinese language middle school classrooms'. I don't believe the authors mentioned any IRB or consent process for collecting data from these students? I'm not sure if this is a significant issue but I figured I should flag it to be safe."}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gyNNBsvRcy", "forum": "vCSGqbwggc", "replyto": "vCSGqbwggc", "signatures": ["ICLR.cc/2026/Conference/Submission11118/Reviewer_pnJm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11118/Reviewer_pnJm"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11118/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979878434, "cdate": 1761979878434, "tmdate": 1762922291326, "mdate": 1762922291326, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper focuses on reproducing realistic classroom dynamics. To achieve this, the authors present EduVerse, a novel user-defined multi-agent simulation platform that introduces a Cognition–Interaction–Evolution (CIE) architecture. This architecture models the long-term cognitive, emotional, and behavioral development of virtual agents within customizable classroom environments."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Human–Agent Interaction provides valuable insights through experimental studies."}, "weaknesses": {"value": "- The work attempts to address multiple aspects, including individual modeling, role-differentiated social interaction, and longitudinal instructional adaptation. But does not clearly explain them.\n\n- The evaluation is vague.\n  - Please include the key metrics in the main paper instead of the appendix. This would improve both readers’ understanding and reviewers’ efficiency.\n  - Table 1 does not show how the simulation aligns with real classroom data. For example, IRF_rate on Lyrical Prose (0.336 vs. 0.486) contradicts the claim of only minor genre-specific variations.\n  - Figure 5 lacks a clear caption about the ablation study, making it difficult to follow the analysis and interpret the bar chart.\n  - Much of the analysis focuses on individual cases, while the main focus should be at the class level.\n\n- The work is limited to Chinese language classes. Cross-domain or cross-linguistic experiments would strengthen the generalization of this work.\n\n- Figure 4 is too small and hard to review."}, "questions": {"value": "Please see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2diRbeavPa", "forum": "vCSGqbwggc", "replyto": "vCSGqbwggc", "signatures": ["ICLR.cc/2026/Conference/Submission11118/Reviewer_jPWs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11118/Reviewer_jPWs"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission11118/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762146021072, "cdate": 1762146021072, "tmdate": 1762922290842, "mdate": 1762922290842, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}