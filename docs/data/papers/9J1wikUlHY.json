{"id": "9J1wikUlHY", "number": 9905, "cdate": 1758147995362, "mdate": 1759897687795, "content": {"title": "Beyond BFI: The CSI for Enhanced Reliability and Validity in Evaluating LLM Personality Traits", "abstract": "As large language models (LLMs) increasingly function as human-like assistants exhibiting human-like personality traits, understanding their behavioral characteristics becomes essential for responsible AI development.\nHowever, existing evaluation efforts, which often adapt human psychological assessments such as the Big Five Inventory (BFI), face two significant limitations. First, these approaches often lack reliability, as minor prompt variations can lead to inconsistent test results. Second, the theoretical foundations of these tools, rooted in human studies, are misaligned with the computational nature of LLMs, thereby limiting their validity in predicting real-world model behavior.\nTo address these limitations, we introduce the Core Sentiment Inventory (CSI), a novel personality trait evaluation instrument designed from the ground up and specifically tailored to the unique characteristics of LLMs. CSI covers both English and Chinese, that implicitly evaluates models' personality traits, providing insightful psychological portraits of LLMs. Extensive experiments demonstrate that: (1) CSI effectively captures nuanced behavioral patterns, revealing significant behavioral variations in LLMs across different languages and contexts; (2) Compared to current evaluation tools, CSI significantly improves reliability, yielding more consistent and robust results; and (3) The correlation between CSI scores and LLMs' real-world outputs exceeds 0.85, demonstrating its strong validity in predicting LLM behavior.", "tldr": "We propose the CSI, a novel evaluation method that assesses personality traits in LLMs with greater reliability and stronger predictive validity than prior human-centered methods.", "keywords": ["personality trait;evaluation;LLMs;psychometrics"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ed95f79126ffed4684b6a6c2b1aa07ef872c526c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper attempts to address the limitations of using human psychometric assessments, such as the Big Five Inventory (BFI), to evaluate the personality traits of Large Language Models (LLMs). To solve this, the paper introduces the Core Sentiment Inventory (CSI), a new evaluation instrument designed specifically for LLMs. Inspired by the Implicit Association Test (IAT), the CSI measures an LLM's implicit stance by asking it to associate a large inventory of 5,000 stimulus words with one of two evaluative poles: \"comedy\" (positive) or \"tragedy\" (negative). These associations are aggregated into three scores: Optimism (O_score), Pessimism (P_score), and Neutrality (N_score). The authors claim that, through extensive experiments, the CSI demonstrates significantly higher reliability and stronger predictive validity compared to the BFI."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "* Important Research Direction: The paper tackles an interesting and increasingly important area of research: the study of LLM behaviors and the challenge of characterizing their personality-like traits.\n* Clear Motivation: The authors' goal of creating a more robust, reliable, and valid evaluation system is promising. The paper identifies some known limitations in directly applying human-centric psychological tests like the BFI to non-human-like AI systems, such as model reluctance and prompt sensitivity."}, "weaknesses": {"value": "* Lack of Psychometric Underpinning: The paper's central argument rests on discarding the BFI, but it fails to provide a psychometrically sound alternative. Earlier works selected the BFI not arbitrarily, but because it is a widely adopted and validated framework in human studies, believed to characterize actual, stable behavioral differences. The authors propose replacing this with a new three-dimensional O/P/N (Optimism/Pessimism/Neutrality) framework without sufficient theoretical or psychometric justification. This new framework feels arbitrary and it is not demonstrated why these dimensions are a valid, stable, or comprehensive way to characterize an LLM's behavioral tendencies.\n* Non-Neutral Stimuli: The methodology's validity hinges on using neutral stimuli to probe a model's \"implicit\" stance. However, this claim is not convincing. A review of the authors' own examples in Table 2 reveals many chosen words are not neutral. For instance, the Top 5000 English words include \"heal\" and \"bullying.\" This use of emotionally-related stimuli fundamentally renders the test results unconvincing as a measure of implicit personality.\n* Interpretation of LLM Behavior (Instruction-Following vs. Inherent Traits): The paper seems to confuse what it is measuring. LLMs are, at their core, instruction-following systems whose behaviors can be significantly altered by system prompts and training.\n* Consistency is Personality?: The paper claims high consistency as a strength. However, this is more likely a measure of the model's ability to consistently follow the simple instructions of the IAT-like task, not a measure of a stable, \"inherent\" trait.\n* \"Reluctancy\" as a Feature, Not a Bug: The paper frames \"model reluctance\" (e.g., refusing to answer BFI questions with \"As an AI, I do not have... beliefs\") as a failure of the BFI. An alternative and more likely interpretation is that this reluctance is the model's inherent behavior, reflecting its alignment and safety training. The fact that the BFI triggers these guardrails may indicate it is probing targeted questions that reveal the LLM's core programming. The CSI, by design, seems to bypass this, and its \"near-zero reluctance\" may simply mean it is measuring a more superficial, less meaningful behavior."}, "questions": {"value": "1. How do the authors justify their new method from a psychometric standpoint? Why should these be considered a valid or superior framework to the Big Five for characterizing model behavior, rather than an arbitrary, ungrounded classification?\n2. Given that the stimulus set contains emotionally related words like \"bully\" and \"heal\", how does this align with the principle of avoiding explicit emotional words? How can the test results be considered a valid measure of \"personality\" rather than just a measure of common-sense association or alignment?\n3. How can the authors distinguish between measuring a stable, inherent \"personality trait\" and measuring a model's \"ability to follow instructions\" consistently? Could the high consistency of CSI simply be an artifact of a simpler, more direct task?\n4. The paper frames model reluctance as a failure of BFI. Could it not be argued that this reluctance is the model's 'inherent' behavior (i.e., its alignment)? Does designing a test (CSI) that avoids reluctance simply mean the test is measuring a more superficial, less meaningful behavior?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "JZcW82jiaj", "forum": "9J1wikUlHY", "replyto": "9J1wikUlHY", "signatures": ["ICLR.cc/2026/Conference/Submission9905/Reviewer_R6L3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9905/Reviewer_R6L3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9905/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761635585338, "cdate": 1761635585338, "tmdate": 1762921363386, "mdate": 1762921363386, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a novel personality benchmark Core Sentiment Inventory (CSI) designed specifically for LLMs. The authors find that CSI captures behavioral nuances and variations between LLMs. They claim that CSI is more reliable than extant evaluation tools and that the high correlation between scores and outputs indicates strong validity for predicting LLM behavior."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "This study identifies important short-comings with the llm personality assessment literature and argues for more reliable and valid evaluation tools."}, "weaknesses": {"value": "The experimental design does not support the claim of reliability and validity of the CSI measure. For reliability, the authors test only two model types and they do not vary the prompts. If they conducted multiple trials, they do not report the repeated measures scores. For validity, they use the CSI words are seeds for generating stories, that are then evaluated for presence of the words used as seeds. This is plainly circular and does not prove that CSI is a valid measure of sentiment.\nThe main issue with using word associations as a proxy for personality assessment as some psychometric evaluations for human populations, is the unchecked assumption that the LLMs have stable internal representations. This assumption underlies the belief that words have unconscious associations and can be indicative of stable personality traits. Unfortunately, both of these claims remain to be proven. Thus, the soundness of word associations tasks for llm evaluations is questionable.\nA quick inspection of the terms associated with comedy, tragedy, and neutrality show that they vary from model to model (Table 18, P25). With many of the same terms occurring in across the categories. This strongly undermines the construct validity. It is questionable from a face validity standpoint as well, what is the valence of \"I\" ???"}, "questions": {"value": "P3L142 \"First, it alleviates test fatigue, a common issue in human-centric scales (e.g., 44 items in BFI, 100 in EPQ-R; see Table 1). With 5,000 items per language, CSI supports a broader and more inductive evaluation. Second, drawing on the implementation of the Implicit Association Test (Bai et al., 2025) on LLMs, CSI uses implicit assessment rather than direct self-report, which reduces refusal rates. Finally, CSI demonstrates stronger predictive validity, showing higher correlations between its scores and the sentiment of model-generated outputs\"\n\n=> How are these statements supported by your experimental design? Prima facie, I don't understand how a 5,000 item questionnaire would reduce test fatigue compared to a 44 item questionnaire. And if we're talking about LLMs, what does test fatigue have to do with anything? How do 5,000 items entail a broader and more inductive evaluation? The traits of optimism and pessimism are fewer and less behaviorally salient than neuroticism, openness, conscientiousness, extroversion, and agreeableness. That is to say, there is abundant empirical evidence linking these traits to other behavioral measures. Whereas the Big-5 have been shown to be stable traits, optimism and pessimism are affects that is they are transient and situational.\n\nP7L364 \"Second, we observe notable discrepancies in sentiment stance across languages. For example, GPT-4o shows minimal differences between English and Chinese, whereas LLaMA-3.1-70B displays a substantial divergence, with pessimism being dominant in Chinese (P_score of 0.47) compared to English (P_score of 0.30). This suggests that model behavior varies significantly across language\nscenarios, a phenomenon that deserves deeper exploration.\"\n\n=> Were tests of significance conducted? How do we know the means are significantly different?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KwAt6Tcmbu", "forum": "9J1wikUlHY", "replyto": "9J1wikUlHY", "signatures": ["ICLR.cc/2026/Conference/Submission9905/Reviewer_XoYK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9905/Reviewer_XoYK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9905/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761944026016, "cdate": 1761944026016, "tmdate": 1762921363127, "mdate": 1762921363127, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper claims that BFI scores for LLMs are not stable and provides an alternative. The author critisise BFI methodology for \"based on human-centered psychological theories\" yet propose a new methodologe that is also \"inspired\" but a human centered work. At the same time the authors constantly mention \"personality traits\" as if LLMs do have personality."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper is rather well written, is in a relevant field and does address an important issue."}, "weaknesses": {"value": "The subject of the reseach is not motivated convincingly. For example, human BFI scores also fluctuate (and this is well documented), and the level of fluctuations show in the opening figure is on par with human fluctuations. The methodology that authors propose, in my opinion, does not have any other nature that would make it more suitable for the computer systems per se. It is also not clear to which the proposed scoring mechanism would be beneficial for behaviour prediction that authors mention several times in the introduction."}, "questions": {"value": "Here are some further works that could be informative for the scope of the work:\n\nSorokovikova A, Rezagholi S, Fedorova N, Yamshchikov IP. LLMs Simulate Big5 Personality Traits: Further Evidence. InProceedings of the 1st Workshop on Personalization of Generative AI Systems (PERSONALIZE 2024) 2024 Mar (pp. 83-87).\n\nPan X, Gao D, Xie Y, Chen Y, Wei Z, Li Y, Ding B, Wen JR, Zhou J. Very large-scale multi-agent simulation in agentscope. arXiv preprint arXiv:2407.17789. 2024 Jul 25.\n\nDong W, Zhao Y, Sun Z, Liu Y, Peng Z, Zheng J, Zhang Z, Zhang Z, Wu J, Wang R, Xu S. Humanizing llms: A survey of psychological measurements with tools, datasets, and human-agent applications. arXiv preprint arXiv:2505.00049. 2025 Apr 30.\n\nTshimula JM, Nkashama DJ, Muabila JT, Galekwa RM, Kanda H, Dialufuma MV, Didier MM, Kalonji K, Mundele S, Lenye PK, Basele TW. Psychological Profiling in Cybersecurity: A Look at LLMs and Psycholinguistic Features. InInternational Conference on Web Information Systems Engineering 2024 Dec 2 (pp. 378-393). Singapore: Springer Nature Singapore."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GFiC5AXDn0", "forum": "9J1wikUlHY", "replyto": "9J1wikUlHY", "signatures": ["ICLR.cc/2026/Conference/Submission9905/Reviewer_EDnX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9905/Reviewer_EDnX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9905/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762022107137, "cdate": 1762022107137, "tmdate": 1762921362741, "mdate": 1762921362741, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}