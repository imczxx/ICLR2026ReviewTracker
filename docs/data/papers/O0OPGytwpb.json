{"id": "O0OPGytwpb", "number": 19309, "cdate": 1758295277489, "mdate": 1759897046331, "content": {"title": "On-the-Fly Data Augmentation via Gradient-Guided and Sample-Aware Influence Estimation", "abstract": "Data augmentation has been widely employed to improve the generalization of deep neural networks. Most existing methods apply fixed or random transformations.\nHowever, we find that sample difficulty evolves along with the model's generalization capabilities in dynamic training environments.\nAs a result, applying uniform or stochastic augmentations, without accounting for such dynamics, can lead to a mismatch between augmented data and the model's evolving training needs, ultimately degrading training effectiveness.\nTo address this, we introduce SADA, a Sample-Aware Dynamic Augmentation that performs on-the-fly adjustment of augmentation strengths based on each sample's evolving influence on model optimization.\nSpecifically, we estimate each sample’s influence by projecting its gradient onto the accumulated model update direction and computing the temporal variance within a local training window.\nSamples with low variance, indicating stable and consistent influence, are augmented more strongly to emphasize diversity, while unstable samples receive milder transformations to preserve semantic fidelity and stabilize learning.\nOur method is lightweight, which does not require auxiliary models or policy tuning. It can be seamlessly integrated into existing training pipelines as a plug-and-play module.\nExperiments across various benchmark datasets and model architectures show consistent improvements of SADA, including +7.3% on fine-grained tasks and +4.3% on long-tailed datasets, highlighting the method's effectiveness and practicality.\nCode will be made publicly available soon.", "tldr": "", "keywords": ["Data augmentation", "adaptive data augmentation"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fc066f8c68618ef9bcf66d0439c7ed79551b7e81.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a dynamic automatic data augmentation technique that adjusts the strength of various image transformations---both geometric and color-based---based on the difficulty of individual samples. The sampling strategy evolves during training using a combination of exponential moving average (EMA) and a sliding window mechanism. The authors conduct a fairly thorough comparison with existing automatic data augmentation methods, which are typically static. The code is not provided at submission time.\n\nDisclaimer: I previously reviewed this paper for NeurIPS, where it was rejected. Except for a few added references, this submission is essentially identical to the original. None of the reviewers’ concerns appear to have been addressed, so I have not made any changes to my original review."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The empirical results appear promising. The idea of adapting data augmentation dynamically during training, rather than relying on a fixed strategy, is both intuitive and worth exploring further.\n\nThe paper provides a broad empirical comparison with other augmentation strategies."}, "weaknesses": {"value": "1) The most significant concern is the lack of proper discussion regarding EntAugment (Yang et al. 2024b), a closely related prior work that also proposes a dynamic per-sample augmentation strategy during training:\n   - Despite its clear relevance, EntAugment is not described properly in the submission.\n   - All baseline numbers are copy-pasted from EntAugment without proper credit, rather than obtained in the context of this submission.\n   - Performance metrics from EntAugment, which are comparable to those of the proposed method, are not included in the result tables. This omission is problematic (unless there is a good reason not to include them, but I cannot find any).\n\n2) There are inconsistencies in the reported results compared to the literature, likely due to the lack of a standardized evaluation protocol:\n  - For example, TrivialAugment reports 98.2 on CIFAR-10/SS and 84.3 on CIFAR100-WRN in published results, higher than the numbers reported in this submission.\n  - Many baseline methods (e.g., DATA, TA, AA) rely on architectures like ShakeShake-26 and WRN-28-10. It’s unclear why this paper uses different variants (e.g., SS-32, WRN-50-2), making direct comparison difficult.\n\n3) Given these discrepancies, the absence of publicly available code at the time of submission is a notable drawback.\n\n4) The complexity analysis is misleading. The method introduces an additional factor L in computational cost, yet the paper presents the overall complexity O(NKL) as effectively O(N), downplaying the actual overhead.\n\n5) Minor clarity issues are present. For instance, Figure 1 refers to “inverse sampling difficulty,” a term that has not been defined at that point in the paper, making it hard to interpret"}, "questions": {"value": "I found the lack of comparison/discussion with EntAugment very problematic on many aspects described above. Unless a convincing explanation is given, I will vote for a reject."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "vQeuBGRCUE", "forum": "O0OPGytwpb", "replyto": "O0OPGytwpb", "signatures": ["ICLR.cc/2026/Conference/Submission19309/Reviewer_j34f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19309/Reviewer_j34f"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19309/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761036507483, "cdate": 1761036507483, "tmdate": 1762931258559, "mdate": 1762931258559, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a dynamic automatic data augmentation technique that adjusts the strength of various image transformations---both geometric and color-based---based on the difficulty of individual samples. The sampling strategy evolves during training using a combination of exponential moving average (EMA) and a sliding window mechanism. The authors conduct a fairly thorough comparison with existing automatic data augmentation methods, which are typically static. The code is not provided at submission time.\n\nDisclaimer: I previously reviewed this paper for NeurIPS, where it was rejected. There were extensive discussions and numerous experiments/comparisons (a total of 11 tables!) presented in the NeurIPS rebuttal, following comments from all reviewers. Aside from the inclusion of an additional baseline, these comparisons and most discussions were not taken into account tin the ICLR submission, which I found very disappointing."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The empirical results appear promising. The idea of adapting data augmentation dynamically during training, rather than relying on a fixed strategy, is both intuitive and worth exploring further.\n\nThe paper provides a broad empirical comparison with other augmentation strategies.\n\nThe paper provides a theoretical insight in Appendix B."}, "weaknesses": {"value": "1) The most significant concern is the lack of proper discussion regarding EntAugment (Yang et al. 2024b), a closely related prior work that also proposes a dynamic per-sample augmentation strategy during training. Despite its clear relevance, EntAugment is not described properly in the submission.\n\n2) There are a few inconsistencies in the reported results compared to the literature, likely due to the lack of a standardized evaluation protocol in this domain. For example, TrivialAugment reports 98.2 on CIFAR-10/SS and 84.3 on CIFAR100-WRN in published results, higher than the numbers reported in this submission. \n\n3) The absence of publicly available code at the time of submission is a notable drawback.\n\n4) The complexity analysis is misleading. The method introduces an additional factor L in computational cost, yet the paper presents the overall complexity O(NKL) as effectively O(N), downplaying the actual overhead.\n\n5) Minor clarity issues are present. For instance, Figure 1 refers to “inverse sampling difficulty,” a term that has not been defined at that point in the paper, making it hard to interpret"}, "questions": {"value": "I found the lack of comparison/discussion with EntAugment very problematic on many aspects described above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "vQeuBGRCUE", "forum": "O0OPGytwpb", "replyto": "O0OPGytwpb", "signatures": ["ICLR.cc/2026/Conference/Submission19309/Reviewer_j34f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19309/Reviewer_j34f"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19309/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761036507483, "cdate": 1761036507483, "tmdate": 1763061818523, "mdate": 1763061818523, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a sample-aware data augmentation strategy that dynamically adjusts the augmentation strength for each sample. This adjustment is based on estimating a sample's influence by projecting its gradient onto the model update direction. Specifically, the method applies stronger augmentation to samples exhibiting low variance and weaker augmentation to those considered unstable. This augmentation process is performed on-the-fly, and experimental results demonstrate its efficacy across various classification tasks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The core idea of dynamically adjusting augmentation strength based on gradient information is both logical and potentially powerful.\n- The work includes a comprehensive set of experiments on classification tasks, covering various settings such as closed-set and open-set, and different k-shot scenarios."}, "weaknesses": {"value": "- The paper does not sufficiently detail the computational overhead. Since the gradient must be calculated at every optimization step to determine the augmentation strength, a clear analysis of the computational complexity and the resulting wall-clock time overhead during training is necessary.\n- The experimental results show varying degrees of advantage: a noticeable gap on Tiny-ImageNet, a moderate improvement on CIFAR-10, and almost similar test accuracy for ImageNet-1k (Table 7). Given the potential training time overhead, the marginal benefit on large-scale datasets like ImageNet-1k is not sufficiently advantageous to justify the added complexity.\n- The method's performance appears to be highly sensitive to the choice of hyperparameters, specifically the window size and decay factor. Although the optimal window size shows a consistent decreasing trend, the optimal decay factor does not exhibit a clear tendency, which raises concerns regarding the robustness of the method. This suggests a user might need to perform an extensive grid search for the decay factor whenever the experimental setting (e.g., training data, classifier architecture) is changed."}, "questions": {"value": "- Given the variety of augmentations (e.g., geometric, color), is the same decay factor applied universally across all categories of augmentation, or are different decay factors employed for different augmentation categories?\n- Would the proposed sample-aware augmentation strategy offer benefits when applied to image generation tasks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xh8ufemLdj", "forum": "O0OPGytwpb", "replyto": "O0OPGytwpb", "signatures": ["ICLR.cc/2026/Conference/Submission19309/Reviewer_gLX1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19309/Reviewer_gLX1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19309/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761894686475, "cdate": 1761894686475, "tmdate": 1762931257975, "mdate": 1762931257975, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SADA, a plug-and-play augmentation scheme that adapts per-sample augmentation strength on the fly using training-dynamics signals. At each step, the method first estimates a sample’s influence by projecting its gradient onto the accumulated model-update direction, and then measures stability as the temporal variance of this influence over a short window (EMA-smoothed). Stable (low-variance) samples receive stronger augmentations; unstable (high-variance) samples receive milder ones to preserve semantics. The influence is made efficient via a first-order loss-difference approximation. A bound is sketched that links SADA to reduced generalization complexity via a per-sample sensitivity term. Experiments on CIFAR-10/100, Tiny-ImageNet, ImageNet-1k, several fine-grained datasets, and long-tailed benchmarks report consistent gains and favorable accuracy-cost tradeoff."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper proposes an intuitive yet effective data augmentation approach that adapts per-sample augmentation strength on the fly. The methods takes sample variance into consideration via gradient projection, and avoids intense per-sample computation via a series of approximation, making it practical in a wide range of classification tasks.\n\n2. The proposed method shows consistent performance improvement in extensive experimental settings. The method outperforms other methods on CIFAR-10/100, Tiny-ImageNet, and is competitive on ImageNet-1k. The method also achieves improvements on transfer-learning, fine-grained and long-tail datasets."}, "weaknesses": {"value": "1. The proposed method introduces a principled approach for sample-aware augmentation. However, in each step a random augmentation operation is selected. Different image transformation process can impact the sample at different levels, which may interfere with the delicately designed augmentation strength.\n\n2. The method introduced hyper parameters like window size and decay factor. Their values seem to be set based on experimental guidance, which probably need to be tuned individually for different tasks (standard, transfer or long-tail classification) and datasets."}, "questions": {"value": "1. How does the method perform with controlled randomness for image transformation operations? Or is the random selection of operations an important factor in the approach?\n\n2. How does the method affect the training dynamics? In particular, would the sample difficulty score in Figure 1 be distributed more evenly at the latter stage of training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mLqhTLNp2b", "forum": "O0OPGytwpb", "replyto": "O0OPGytwpb", "signatures": ["ICLR.cc/2026/Conference/Submission19309/Reviewer_WfCB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19309/Reviewer_WfCB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19309/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761895382676, "cdate": 1761895382676, "tmdate": 1762931257514, "mdate": 1762931257514, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}