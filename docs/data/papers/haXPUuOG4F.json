{"id": "haXPUuOG4F", "number": 17902, "cdate": 1758281821477, "mdate": 1759897146741, "content": {"title": "Instance Data Condensation for Image Super Resolution", "abstract": "Deep learning based image Super-Resolution (ISR) relies on large training datasets to optimize model generalization; this requires substantial computational and storage resources during training. While dataset condensation has shown potential in improving data efficiency and privacy for high-level computer vision tasks, it has not yet been fully exploited for ISR. In this paper, we propose a novel Instance Data Condensation (IDC) framework specifically for ISR, which achieves instance-level data condensation through Random Local Fourier Feature Extraction and Multi-level Feature Distribution Matching. This aims to optimize feature distributions at both global and local levels and obtain high-quality synthesized training content with fine detail. This framework has been utilized to condense the most commonly used training dataset for ISR, DIV2K, with a 10\\% condensation rate. The resulting synthetic dataset offers comparable or (in certain cases) even superior performance compared to the original full dataset and excellent training stability when used to train various popular ISR models. To the best of our knowledge, this is the first time that a condensed/synthetic dataset (with a 10\\% data volume) has demonstrated such performance. The associated code and synthetic dataset are available here.", "tldr": "", "keywords": ["Dataset Distillation", "Image Super Resolution"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d74d9bf577153560de4fd72cae4b6d088da70a25.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces Instance Data Condensation (IDC), a novel framework tailored for image super-resolution (ISR). The method introduces two main components: Random Local Fourier Feature Extraction, which preserves high-frequency local details crucial for ISR, and Multi-level Feature Distribution Matching, which aligns feature distributions at both instance and group levels to maintain diversity and fidelity in the synthesized data. Experiments conducted on the DIV2K dataset with a 10% condensation rate show that the synthetic dataset achieves comparable or even superior performance to the full dataset when training state-of-the-art ISR models such as EDSR, SwinIR, and MambaIRv2. The work represents the first successful application of dataset condensation to low-level vision, demonstrating efficient data compression without loss of model quality or training stability."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "This paper proposes a new data condensation framework, Instance Data Condensation, to the best of my knowledge, is the first to apply the concept of dataset condensation to image super-resolution (ISR). While numerous condensation methods have been explored in high-level vision tasks such as classification, detection, and segmentation, similar attempts have not been made for low-level vision problems. Therefore, the proposed method shows a degree of novelty and exploratory value in extending data condensation to the SR domain."}, "weaknesses": {"value": "1. The paper’s presentation is quite poor, making it difficult to follow the main ideas. The Related Work and Methodology sections are intermixed, with prior studies and the proposed approach discussed together without clear separation. This confuses the reader and obscures the novelty of the work.\n2. Beyond presentation issues, the paper also suffers from conceptual ambiguity in several analyses. For example, in the discussion of Figure 1 (left), the authors claim that the DCSR method suffers from a bias toward complex textures, yet the selected “snow mountain” region actually corresponds to a structured area rather than a purely textured one. Moreover, the figure does not convincingly show that the proposed IDC method avoids such bias. Similarly, the claim that transforming features into the Fourier domain leads “to a more informative representation” (line 259) is unsubstantiated and conceptually weak—Fourier transformation changes the representation domain but does not inherently increase information content. These unclear or overstated interpretations undermine the analytical rigor of the paper and should be supported by clearer quantitative evidence or theoretical reasoning.\n3. Another concern arises from the ablation study (Table 2). The results for variants V5–V7 show larger performance drops compared with V4, even though each variant removes different components of the proposed framework (e.g., Unfolding, Local Feature, or Instance/Group Losses). This trend appears inconsistent with the claim that these components are beneficial, since removing them does not lead to clearly distinguishable or interpretable degradations."}, "questions": {"value": "The paper claims that using a 10% condensed dataset significantly improves training efficiency. However, no quantitative evidence is provided. Could the authors clarify how the training time, number of iterations, and computational cost compare between training on the condensed dataset and the full (“Whole”) dataset?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9b0h7qPjrX", "forum": "haXPUuOG4F", "replyto": "haXPUuOG4F", "signatures": ["ICLR.cc/2026/Conference/Submission17902/Reviewer_AS8f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17902/Reviewer_AS8f"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17902/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962117516, "cdate": 1761962117516, "tmdate": 1762927723479, "mdate": 1762927723479, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel framework termed Instance Data Condensation (IDC) for image super-resolution. IDC addresses the challenge of reducing training data volume while maintaining or even enhancing model performance. The framework leverages Random Local Fourier Features (RLFF) and Multilevel Feature Distribution Matching to condense training datasets at the instance level, eliminating the need for class labels common in high-level vision tasks. Extensive experiments and ablation studies validate the effectiveness and robustness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper is well-motivated and easy to follow.\n2. The proposed framework achieves better performance with only 10% synthetic crops."}, "weaknesses": {"value": "1. The condensation process is computationally intensive.\n2. Although the instance-level paradigm is promising, its effectiveness across diverse tasks remains to be validated.\n3. The scalability of the IDC framework across datasets of different volumes lacks empirical validation."}, "questions": {"value": "1. Does the IDC data distillation method affect the generalization performance of super-resolution models? Please provide relevant experimental results to illustrate.\n2. What is the memory footprint of RLFF?  \n3. When the condensation ratio falls below 10%, is any modal collapse observed? Or is the model overfitting?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UmxyGd6sb5", "forum": "haXPUuOG4F", "replyto": "haXPUuOG4F", "signatures": ["ICLR.cc/2026/Conference/Submission17902/Reviewer_vLAv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17902/Reviewer_vLAv"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17902/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976248706, "cdate": 1761976248706, "tmdate": 1762927723158, "mdate": 1762927723158, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new dataset condensation framework for image super-resolution, by designing a Multi-level Feature Distribution Matching approach and Random Local Fourier Features. The conducted experiments show that the condensed datasets give promising performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation is clear. This paper shows a new dataset condensation method for image super-resolution.\n2. The writing of this paper is fluent, and the content is easy to follow.\n3. The designs of the two approaches make sense to some degree.\n4. The conducted ablation experiments are detailed and well-designed."}, "weaknesses": {"value": "1. More large-scale datasets should be condensed to show the promising performance of the proposed method. The related datasets in the paper are DIV2K and Flickr2K, which are not very large in real scenarios. I believe that the value of condensation is more evident on large-scale datasets than in experiments with specific case studies.\n2. The performance improvement is not very obvious, as shown in Table 1, and the condensation burden comparison should be provided to give more analysis.\n3. Can you give some theoretical analysis or insights about your designs, such as random local Fourier features?\n4. Can this method extend to other low-level missions, such as deblur and denoise? Please give some discussions."}, "questions": {"value": "Please refer to \"Weaknesses\"."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cSMCxcX8Zc", "forum": "haXPUuOG4F", "replyto": "haXPUuOG4F", "signatures": ["ICLR.cc/2026/Conference/Submission17902/Reviewer_p8PL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17902/Reviewer_p8PL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17902/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762184050887, "cdate": 1762184050887, "tmdate": 1762927721494, "mdate": 1762927721494, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}