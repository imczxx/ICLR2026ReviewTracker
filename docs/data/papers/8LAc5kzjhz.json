{"id": "8LAc5kzjhz", "number": 6276, "cdate": 1757963765901, "mdate": 1759897925324, "content": {"title": "Spatial CAPTCHA: Generatively Benchmarking Spatial Reasoning for Human-Machine Differentiation", "abstract": "Online services rely on CAPTCHAs as a first line of defense against automated abuse, yet recent advances in multi-modal large language models (MLLMs) have eroded the effectiveness of conventional designs that focus on text recognition or 2D image understanding. To address this challenge, we present **Spatial CAPTCHA**, a novel human-verification framework that leverages fundamental differences in spatial reasoning between humans and MLLMs. Unlike existing CAPTCHAs that rely on low-level perception tasks vulnerable to modern AI, Spatial CAPTCHA generates dynamic questions requiring geometric reasoning, perspective-taking, occlusion handling, and mental rotation—skills intuitive for humans but difficult for current AI systems. The system employs a procedural generation pipeline with constraint-based difficulty control, automated correctness verification, and human-in-the-loop validation to ensure scalability, robustness, and adaptability. Evaluation on a corresponding benchmark, **Spatial-CAPTCHA-Bench**, demonstrates that humans vastly outperform 10 state-of-the-art MLLMs, with the best model achieving only 31.0\\% Pass@1 accuracy. Result comparison with Google reCAPTCHA further confirms the effectiveness of Spatial CAPTCHA as both a security mechanism and a diagnostic tool for spatial reasoning in AI.", "tldr": "Spatial CAPTCHA demonstrates that spatial reasoning remains a decisive weakness for multimodal models, enabling secure and scalable human verification.", "keywords": ["CAPTCHA", "multimodal models", "spatial reasoning", "robustness", "evaluation benchmark"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5ace0fe0a8fcc72f21a9627a65475f31cf26e6ed.pdf", "supplementary_material": "/attachment/1ad28b6fc3bc5281f7e81aea80bf532509ac1cd9.zip"}, "replies": [{"content": {"summary": {"value": "This work presents Spatial CAPTCHA, a framework designed to be robust against MLLMs that defeat current CAPTCHAs. It leverages the significant gap between human and AI spatial reasoning abilities by generating dynamic questions requiring geometric reasoning, perspective-taking, and mental rotation. Evaluation on the new Spatial-CAPTCHA-Bench demonstrates that humans vastly outperform 10 state-of-the-art MLLMs, with the best AI model achieving only 31.0% Pass@1 accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This paper introduces a new and well-founded open-source pipeline that can automatically generate large scale 3d spatial captchas based on spatial cues such as positioning, counting, etc. The performance on the benchmark shows impressive human performance (almost 100%) and decent MLLM performance (lower than all open code/data captchas). The authors also provided extensive analysis to the reliability of their benchmark and the performance of different models under each specified category."}, "weaknesses": {"value": "1. Why would open-source models perform better on spatial-captcha than on recaptcha, even though proprietary ones do the opposite? The latter discovery demonstrates how difficult spatial-captcha is, but there isn't enough explanation for the open-source models' performance.\n2. Figure 3b's graphs are all stacked together. Without a legend and enough explanation, it is difficult to make meaningful thoughts about this figure.\n3. Typos: All citations in Section 3 have wrong format (no parentheses)."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QYkOory9PG", "forum": "8LAc5kzjhz", "replyto": "8LAc5kzjhz", "signatures": ["ICLR.cc/2026/Conference/Submission6276/Reviewer_NVWJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6276/Reviewer_NVWJ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6276/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761007660771, "cdate": 1761007660771, "tmdate": 1762918584876, "mdate": 1762918584876, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Spatial CAPTCHA, a novel framework designed to differentiate humans from machines by leveraging tasks grounded in spatial reasoning—a known weakness of current Multimodal Large Language Models (MLLMs). The authors have developed a sophisticated, automated pipeline that procedurally generates a virtually endless supply of puzzles based on four fundamental human spatial abilities, such as mental rotation and perspective-taking. A key innovation is the use of formal specifications (\"manifests\") to ensure each puzzle is valid, unambiguous, and has a controllable difficulty level.\n\nTo validate their approach, the authors created Spatial-CAPTCHA-Bench, a dataset of 1,050 puzzles, and conducted a large-scale experiment comparing the performance of 10 state-of-the-art MLLMs against 60 human participants. The results reveal a stark performance gap: humans achieved approximately 90% accuracy, while the best-performing AI model only reached 31%. The study also found that MLLMs are poorly calibrated, often expressing high confidence even when providing incorrect answers, further demonstrating the effectiveness of this new CAPTCHA paradigm."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. **Novel and High-Impact Problem:** The paper addresses a timely and critical real-world problem. With conventional CAPTCHAs becoming increasingly vulnerable to AI, the proposed method of targeting a well-established weakness in MLLMs—spatial reasoning—is an insightful and promising direction for the next generation of human-verification systems.\n\n2. **Rigorous and Scalable Generation Pipeline:** A standout contribution is the procedural generation pipeline. Using formal manifests to define and control puzzle generation is an elegant solution that guarantees the validity and logical unambiguity of each CAPTCHA by design. This makes the system renderer-agnostic and capable of producing an endless supply of challenges, which is essential for a robust security tool.\n\n3. **Methodical and Cognitively Grounded Design:** The work is built on a strong theoretical foundation. Instead of designing arbitrary puzzles, the authors methodically ground their tasks in four well-researched categories of human spatial cognition. This principled, theory-first approach adds significant scientific credibility to the framework.\n\n4. **Convincing and Well-Executed Experiments:** The empirical evaluation is thorough and the results are compelling. The massive, undeniable performance gap between humans and a wide array of top-tier MLLMs provides powerful evidence for the system's effectiveness. The direct comparison to reCAPTCHA further strengthens the claim that this is a superior method for human-machine differentiation.\n\n5. **Exceptional Clarity and Presentation:** The paper is very well-written, engaging, and easy to follow. The motivation, methodology, and results are presented with a clear and logical narrative, making the paper's significant contributions highly accessible."}, "weaknesses": {"value": "The primary weakness of the paper lies in an important, unaddressed subtlety in its claim of unambiguity.\n\n**Lack of Perceptual Ambiguity Verification:** The framework's core claim is that puzzles are \"unambiguous\" because they are generated from a mathematically precise and logically sound manifest. However, this guarantee of logical unambiguity does not automatically extend to perceptual unambiguity in the final rendered 2D image. The paper does not adequately address the possibility that rendering artifacts, unfortunate camera angles, or subtle visual similarities could cause a mathematically incorrect \"distractor\" option to appear correct, or vice-versa. While the high-fidelity renderer and significant geometric differences between options mitigate this risk, the lack of a formal post-rendering check for perceptual clarity is a notable gap in the validation process."}, "questions": {"value": "The paper does an excellent job of ensuring the logical correctness and unambiguity of the puzzles via the manifest system. However, could you elaborate on how the system guarantees perceptual unambiguity after the 3D scene is rendered into a 2D image? Specifically, what prevents a situation where a mathematically incorrect distractor might, due to rendering artifacts or its specific orientation, be visually confusable with the correct answer? A discussion on this point—perhaps covering renderer fidelity, human validation studies focused on distractor clarity, or potential post-rendering programmatic checks—would significantly bolster the framework's claim of robustness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cUoQogi0D7", "forum": "8LAc5kzjhz", "replyto": "8LAc5kzjhz", "signatures": ["ICLR.cc/2026/Conference/Submission6276/Reviewer_BLj8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6276/Reviewer_BLj8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6276/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761519777947, "cdate": 1761519777947, "tmdate": 1762918584364, "mdate": 1762918584364, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Spatial Captcha presents a procedural generation pipeline for creating challenging multiple choice visual spatial reasoning captchas. The pipeline is designed to target well studied visual reasoning tasks that are easier for humans than for models. The authors evaluate some of the frontier multimodal models on the generated captchas and find that they only achieve 31% accuracy at best while humans achieve over 99% accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper is well-written and the motivation for building a more challenging captcha is clear. The authors thoroughly explain the human psychology research that led to the design of the dataset and validate that the puzzles generated are challenging for many state-of-the-art multimodal models."}, "weaknesses": {"value": "The authors motivate their work by pointing out that current CAPTCHAs are too simple for the best performing models. This is a valid concern but I am not sure if building a slightly more challenging CAPTCHA is the best way to address it. It has become clear that even if a certain type of visual reasoning task is harder for models today, it will be significantly easier for the next generation of frontier models. The authors could strengthen the paper by discussing the expected lifespan of Spatial CAPTCHA as a benchmark and how the framework could adapt to future model advances. I believe a more forward looking approach would be to embrace that as computer-use agents get more capable they will make up a majority of internet traffic and we should adopt more [forward looking mechanisms](https://blog.cloudflare.com/introducing-pay-per-crawl/).\n\nAnother concern is that the spatial CAPTCHA dataset is framed as out-of-distribution data for current models. While I agree that web data lacks these specific reasoning tasks, model developers could readily generate synthetic data targeting this distribution. The paper attributes poor model performance to architectural limitations in VLMs, but this claim would be significantly strengthened by fine-tuning experiments demonstrating that performance is low even with targeted training data."}, "questions": {"value": "1. How does a frontier system like GPT-5 with a high thinking budget perform on the Spatial CAPTCHA dataset? Does it significantly outperform the state-of-the-art VLMs evaluated in the paper?\n2. Have you tested whether fine-tuning on procedurally generated puzzles significantly improves model performance, or whether the limitation is architectural?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "lnjuzsBmtz", "forum": "8LAc5kzjhz", "replyto": "8LAc5kzjhz", "signatures": ["ICLR.cc/2026/Conference/Submission6276/Reviewer_kkRJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6276/Reviewer_kkRJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6276/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761967414465, "cdate": 1761967414465, "tmdate": 1762918583834, "mdate": 1762918583834, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}