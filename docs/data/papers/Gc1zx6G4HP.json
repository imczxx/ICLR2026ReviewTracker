{"id": "Gc1zx6G4HP", "number": 18800, "cdate": 1758290973109, "mdate": 1763516692196, "content": {"title": "Diagnosing Failure Root Causes in Platform-Orchestrated Agentic Systems: Dataset, Taxonomy, and Benchmark", "abstract": "Agentic systems consisting of multiple LLM-driven agents coordinating through tools and structured interactions, are increasingly deployed for complex reasoning and problem-solving tasks. At the same time, emerging low-code and template-based agent development platforms (e.g., Dify) enable users to rapidly build and orchestrate agentic systems, which we refer to as platform-orchestrated agentic systems. However, these systems are also fragile and it remains unclear how to systematically identify their potential failure root cause. This paper presents a study of root cause identification of these platform-orchestrated agentic systems. To support this initiative, we construct a dataset AgentFail containing 307 failure logs from ten agentic systems, each with fine-grained annotations linking failures to their root causes. We additionally utilize counterfactual reasoning-based repair strategy to ensure the reliability of the annotation. Building on the dataset, we develop a taxonomy that characterizes failure root causes and analyze their distribution across different platforms and task domains. Furthermore, we introduce a benchmark that leverages {LLMs for automatically identifying root causes, in which we also utilize }the proposed taxonomy as guidance for LLMs. Results show that the taxonomy can largely improve the performance, thereby confirming its utility. Nevertheless, the accuracy of root cause identification reaches at most 33.6\\%, which indicates that this task still remains challenging. In light of these results, we also provide actionable guidelines for building such agentic systems. In summary, this paper provides a reliable dataset of {failure root cause for } platform-orchestrated agentic systems, corresponding taxonomy and benchmark, which serves as a foundation for advancing the development of more reliable agentic systems.", "tldr": "", "keywords": ["agentic system", "taxonomy", "root cause"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/0106213e3d3728425a44a92b0da02cd36555d0b7.pdf", "supplementary_material": "/attachment/dd53fef92fdfc3810227928357b64ffe5efa18ad.zip"}, "replies": [{"content": {"summary": {"value": "This paper studies the failure mechanisms of platform-orchestrated agentic systems — systems built via low-code platforms such as Dify and Coze, where multiple LLM agents coordinate through structured workflows.\nThe authors propose AgentFail, a dataset of 307 failure logs collected from ten systems across two platforms. Each case is annotated with the root cause of failure (using a grounded-theory annotation process and verified through counterfactual repair).\nThey further introduce a three-level taxonomy (agent-level, workflow-level, and platform-level failures) and an LLM-based benchmark to automatically identify the root cause. Experiments show that providing the taxonomy improves identification accuracy from about 10% to 33%, but the task remains difficult."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. Relevance and motivation: The paper studies an emerging and practical problem: why multi-agent LLM systems built via platforms fail. With tools like Dify and Coze getting popular, understanding their fragility is indeed necessary.\n\n2. Paper writing \nThe paper is overall well-writing and easy to follow."}, "weaknesses": {"value": "1. Limited originality\nWhile the paper claims novelty, it heavily overlaps in spirit with Zhang et al., 2025d (“Which Agent Causes Task Failures and When?”) and Cemri et al., 2025 (“Why Do Multi-Agent LLM Systems Fail?”). The “root cause” concept here appears as an extension or recombination of those works, not a fundamentally new paradigm. This work seems like a stitched combination of prior benchmarks (Who&When + MAST) applied to Dify/Coze.\n\n2. Conceptual overlap and presentation\nSeveral parts (taxonomy diagrams, repair analysis) are nearly identical to those in previous works, differing only in labels or platforms. The conclusion \"failure attribution is challenging\" has already been pointed out by previous works. So I do not understand what is the real conclusion of this paper. \n \n3. Dataset scale and diversity\nAlthough the dataset has 307 failures, this is relatively small given ten systems and multiple task types. The number of distinct workflows per platform (five each) may not generalize well to other agentic frameworks (e.g., LangChain, HuggingGPT). The scope is narrow and may not support strong general claims about **\"platform-orchestrated\"** systems."}, "questions": {"value": "1. The authors should clearly articulate how this work differs from Zhang et al., 2025d (“Which Agent Causes Task Failures and When?”) and Cemri et al., 2025 (“Why Do Multi-Agent LLM Systems Fail?”).\n\n2. Taxonomy construction:\nWas the taxonomy inductively derived or guided by existing taxonomies like MAST?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "977XO7vLDp", "forum": "Gc1zx6G4HP", "replyto": "Gc1zx6G4HP", "signatures": ["ICLR.cc/2026/Conference/Submission18800/Reviewer_Y37G"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18800/Reviewer_Y37G"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18800/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923963069, "cdate": 1761923963069, "tmdate": 1763000001352, "mdate": 1763000001352, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "SH5ybXDEuE", "forum": "Gc1zx6G4HP", "replyto": "Gc1zx6G4HP", "signatures": ["ICLR.cc/2026/Conference/Submission18800/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18800/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763516691345, "cdate": 1763516691345, "tmdate": 1763516691345, "mdate": 1763516691345, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper assembles a dataset of 307 failure logs from ten multi-agent systems built on two low-code platforms, Dify and Coze. It proposes a three-level taxonomy of root causes spanning agent, workflow, and platform sources, and evaluates automatic root-cause identification by prompting off-the-shelf LLMs with or without the taxonomy."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Focus on platform-orchestrated systems is well motivated and reflects how many users build agents today. \n2. The dataset spans several workflow topologies and task families, which is a reasonable starting point for analysis."}, "weaknesses": {"value": "1. The core weakness of the paper is limited novelty relative to recent work. The contribution reads as an amalgam of prior studies. Like [1] and related attribution papers [2], it runs multi-agent systems and analyzes failure traces. Like [2], it introduces a categorization of failure patterns. It also echoes prior efforts in annotator analysis and uses off-the-shelf LLMs to diagnose logs. The annotation protocal is almost a duplicate of [1]. The high-level takeaway appears unchanged from those lines of work, and the new taxonomy feels largely isomorphic to existing ones with new labels rather than new insights.\n2. The method defines the root cause as the earliest decisive error that flips failure to success when counterfactually corrected, which is convenient but can ignore latent upstream design flaws like missing validation that merely manifested later.\n\n[1] Which agent causes task failures and when? On automated failure attribution of llm multi-agent systems\n\n[2] Why Do Multi-Agent LLM Systems Fail?"}, "questions": {"value": "1. The benchmark shows only modest gains when the taxonomy is given to the model. What additional signal or supervision would be needed to reach practitioner-useful accuracy?\n2. Can the taxonomy guide automatic repair, not just diagnosis? A short case study demonstrating end-to-end bug fixing would strengthen the practical contribution."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "B32DhBKMk7", "forum": "Gc1zx6G4HP", "replyto": "Gc1zx6G4HP", "signatures": ["ICLR.cc/2026/Conference/Submission18800/Reviewer_EPDZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18800/Reviewer_EPDZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18800/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761940608344, "cdate": 1761940608344, "tmdate": 1763000001216, "mdate": 1763000001216, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates how to identify and analyze failures in platform-orchestrated agentic systems—multi-agent setups built using low-code tools like Dify. The authors introduce AgentFail, a dataset of 307 annotated failure cases, and develop a taxonomy of root causes to guide both human and LLM-based diagnosis."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper introduces a well-structured taxonomy that categorizes different root causes of failures in agentic systems. By using counterfactual reasoning to validate annotations, the study ensures higher reliability and rigor in its dataset"}, "weaknesses": {"value": "A key weakness of this paper is that the AgentFail dataset and benchmark are not substantially different or larger than existing benchmarks on LLM-based agent failures. While it provides valuable annotations and taxonomy, the dataset’s modest size (307 logs) and similar structure to prior diagnostic benchmarks limit its novelty and scalability, making it less impactful for evaluating generalizable failure analysis across diverse agentic systems.\n\nAnother weakness is that it’s unclear whether introducing a separate classification task for root cause identification adds meaningful value beyond standard error attribution analyses."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "J5adKqkJiO", "forum": "Gc1zx6G4HP", "replyto": "Gc1zx6G4HP", "signatures": ["ICLR.cc/2026/Conference/Submission18800/Reviewer_XsZm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18800/Reviewer_XsZm"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18800/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761981477130, "cdate": 1761981477130, "tmdate": 1763000002156, "mdate": 1763000002156, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a study to diagnose the failure root causes in multi-agent systems built on low-code platforms. The authors contribute AgentFail, a dataset of 307 annotated failure logs, and a new taxonomy that classifies failures at the agent, workflow, and platform levels. While this taxonomy significantly improves the ability of LLMs to automatically find the root cause, the task remains highly challenging, with the best-performing models only achieving 33.6% accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper’s primary strength is its systematic study of failure root causes in platform-orchestrated (low-code) agentic systems. It contributes the AgentFail dataset, featuring root-cause labels tied to execution traces that are uniquely validated using a “counterfactual repair” methodology. This work establishes a concrete benchmark for automated root cause identification in this specific context, quantifying its high difficulty (33.6% max accuracy) and providing a clear baseline for future research."}, "weaknesses": {"value": "Although the authors outline a GT-inspired multi-annotator process, the taxonomy construction still reads relatively ad-hoc: the criteria for defining, merging, or splitting categories and concrete coding examples are insufficiently detailed. The core benchmark is methodologically shallow; the diagnostic “method” is simply prompting existing LLMs and lacks any novel algorithmic contribution or comparison against strong, non-LLM baselines (e.g., rule-based or supervised classifiers). This lack of depth, combined with a failure to clearly differentiate from related work on agent failure and inconsistent notation, makes the work feel more like a descriptive study than a complete technical paper."}, "questions": {"value": "1. Your repair validation (Fig 1) shows off-diagonal effects—e.g., a repair for D3 (reasoning) also fixes D1 (formatting). Doesn’t this confound the experiment and undermine the core claim that your taxonomy categories are distinct and identifiable?\n\n2. The 33.6% accuracy benchmark is difficult to interpret. To distinguish inherent task difficulty from the weakness of your prompting method, please provide two crucial baselines: (a) the performance of a simpler, non-LLM classifier (e.g., fine-tuned BERT or keyword-based), and (b) the human expert accuracy for this same task.\n\n3. The novelty claim of “why” (root cause) vs. “where” (localization) appears weak, as other cited work (e.g., Cemri et al.) also proposes root-cause taxonomies. Please articulate the specific, novel contribution of your taxonomy itself, beyond its application to low-code platforms.\n\n4. The paper’s credibility is weakened by inconsistent notation and numerous typos. For instance, Section 3.4 and Figure 1 introduce a new “D1, D2...” notation that clashes with the “F1.x” taxonomy used elsewhere. Please clarify this discrepancy and thoroughly proofread the manuscript."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LSKdOXJ9dj", "forum": "Gc1zx6G4HP", "replyto": "Gc1zx6G4HP", "signatures": ["ICLR.cc/2026/Conference/Submission18800/Reviewer_pc4Z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18800/Reviewer_pc4Z"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18800/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762544878341, "cdate": 1762544878341, "tmdate": 1763000001390, "mdate": 1763000001390, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}