{"id": "L3ETLxmb7N", "number": 7159, "cdate": 1758010025348, "mdate": 1759897869607, "content": {"title": "MoDE: Weight Denoising Towards Better LLM Performance through a Mixture of Domain Experts", "abstract": "Pruning in large language models (LLMs) is widely assumed to degrade performance, since most weights are considered essential contributors to model capacity; thus, existing methods primarily rely on training to retain accuracy. However, our empirical study challenges this view: we find that some weights behave as noise weights‚Äîdespite appearing moderately important‚Äîwhose removal can in fact improve in-domain accuracy. To this end, we first present the **DENoise** (Domain Expert weight deNoising) algorithm, which effectively removes domain-aware noise weights without requiring fine-tuning to achieve improvement; We further develop **MoDE** (Mixture of Domain Experts), which treats these in-domain optimal denoised models as experts and employs a bilevel trainable router to dynamically activate them, thereby enhancing out-of-domain generalization. Experimental results show that applying the **DENoise** algorithm yields 2‚Äì3% gains across benchmarks such as MMLU, MBPP, and GSM8K, while **MoDE** achieves an average improvement of over 1.1% against baseline models, all without introducing additional parameters or tuning overhead.", "tldr": "Pruning noise weights boosts in-domain accuracy; MoDE ensures cross-domain generalization.", "keywords": ["Mixture of Experts", "Large Language Models"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6b873b7bfcc2e7b22b7f41f376ea2d190867446b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper challenges the assumption that pruning LLMs must degrade performance, introducing the concept of \"Noise Weights\"‚Äîparameters whose removal can improve in-domain accuracy without any fine-tuning. The authors propose DENoise to identify and remove these weights to create domain-expert subnetworks, and MoDE, a Mixture-of-Domain-Experts framework that uses a trainable router to dynamically activate these experts. Experiments on LLaMA-2 and Gemma models show that DENoise yields 2-3% gains, while MoDE provides a 1.1% average improvement."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Valuable Finding: The core claim‚Äîthat pruning specific weights can improve LLM performance without retraining‚Äîis highly compelling and potentially impactful. This challenges conventional conclusion in compression.\n2. Practical Utility of DENoise: The DENoise algorithm itself is useful. It offers a plug-and-play method to achieve stable 2-3% performance gains on major benchmarks, which is highly valuable for deploying models in resource-constrained environments.\n3. Clear Motivation: The preliminary study effectively motivates the \"noise weight\" hypothesis by showing performance gains when pruning mid-to-low importance intervals."}, "weaknesses": {"value": "1. Lack of Critical Generalization and Sensitivity Experiments: The paper's analysis could be strengthened to better support the given intuition from more angles. First, to what extent does a model specialized for one domain lose its general capabilities? Second, the DENoise algorithm relies on a domain-specific dataset to find the optimal threshold. The paper provides no sensitivity analysis on how the size or diversity of this dataset affects the algorithm's effectiveness. It is unclear if DENoise overfits to small validation sets.\n2. The paper's method provides a feasible application for downstream deployment; however, it lacks a discussion of the training time (for the router) and test-time costs. A more detailed discussion would be beneficial."}, "questions": {"value": "1.  Can the DENOISE scores in Table 1 be considered the \"Oracle Router\" performance for MoDE (i.e., the theoretical performance upper bound if routing were perfect)? Given that the MoDE performance is consistently lower than this \"oracle\" baseline, it suggests the bi-level router is a bottleneck. Could you please provide metrics on the router's classification accuracy? This is essential for understanding the performance gap.\n2.  How sensitive is DENoise to the size and diversity of the validation set? An ablation study is needed on the impact of the number of samples in $D_T$ on the final performance gain. This is crucial to understand if DENoise is robust or prone to overfitting when the domain-specific validation data is small.\n3.  In Section 3.1, K-means clustering is used to define sub-domains. How was the value of K chosen? The ablation in Table 5 shows K=12 is optimal for MMLU. Does this imply that an exhaustive search for K is required for every domain? This appears to be a significant, unaddressed cost."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "BnaLdfh4Hy", "forum": "L3ETLxmb7N", "replyto": "L3ETLxmb7N", "signatures": ["ICLR.cc/2026/Conference/Submission7159/Reviewer_x9fT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7159/Reviewer_x9fT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7159/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761054559871, "cdate": 1761054559871, "tmdate": 1762919322506, "mdate": 1762919322506, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper observes that some mid-to-low \"importance\" weights behave like noise for a given domain. It argues pruning those specific weights can raise in-domain accuracy without any fine-tuning. The pruning rule is called DENoise. Reported single-model gains are about 2‚Äì3% on MMLU/MBPP/GSM8K, with a max of +6.8% in some settings. To avoid hurting out-of-domain performance, the paper treats each domain‚Äôs denoised subnet as an expert and add a bilevel trainable router that routes inputs to the best expert (MoDE: Mixture of Domain Experts). MoDE is claimed to yield an average +1.1% versus baselines across multiple LLMs."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1- Insightful observation on noise weights.\n\n2- The fact that you can convert the pruned subnets to Experts is interesting.\n\n3- DENoise results in tuning-free per-domain modest improvements, which could be helpful in (quite implausible) settings where any form of fine-tuning can't be done."}, "weaknesses": {"value": "1- The paper is mostly readable overall (intro, figures, and experiments are fine), but the method section needs to be revised. There are typos, inconsistent capitalization of MoDE, singular Expert vs. Experts. DENoise and Mode Architectures in Sections 3.1 and 3.2 are very unclear. There are missing definitions, notation drift, and steps that aren‚Äôt clearly specified.\n\n2- No additional parameters is not accurate: you must store multiple pruned copies (one per domain) plus a router.\n\n3- Router training is not tuning-free. DENoise is tuning-free, but MoDE requires training a classifier/router and domain labels. Claiming it's tuning-free is misleading.\n\n4- The gains are not significant. Average gains can be within margin of error for LLM evaluation based on different runs. The paper would benefit from confidence intervals, multiple seeds, and ablation of threshold choices. There is no study of statistical robustness.\n\n5- The router is trained on fixed pre-defined domains. That hardly is the case in practical setting and there are many domains that the queries can belong to.\n\n6- Turning pruned subnets into experts is a neat way to retain cross-domain performance that per-domain pruning would otherwise sacrifice. That said, there is no mention of or comparison to ToMoE[1] which is very similar in nature. \n\n\n[1] ToMoE: Converting Dense Large Language Models to Mixture-of-Experts through Dynamic Structural Pruning, Gao et al, 2025."}, "questions": {"value": "1- How are domains and posteriors obtained? The text says \"select the most suitable main knowledge domain $D_j$ by computing the posterior $ùëÉ(ùê∑‚à£ùëá)$ but never defines how $P(D‚à£T)$ is estimated.\n\n2- What is task embedding? The paper switches between $F$ and $\\bar{F}$ and per-sample embeddings, but doesn't specify how a task-level vector is aggregated from dataset examples (mean-pooling of token embeddings? CLS token? Which layer?)\n\n3- Typos:\n- line 75: We attempt to identify and the Noise Weight in LLM,\n- line 108: Under this framework, the critical question is to construct the expert (how?)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "EDT9IFf48Y", "forum": "L3ETLxmb7N", "replyto": "L3ETLxmb7N", "signatures": ["ICLR.cc/2026/Conference/Submission7159/Reviewer_4edp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7159/Reviewer_4edp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7159/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761601412776, "cdate": 1761601412776, "tmdate": 1762919321876, "mdate": 1762919321876, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes two methods: DENoise ‚Äì an algorithm that identifies ‚Äúnoise weights‚Äô‚Äô in attention and FFN layers and removes them to improve in-domain performance without further training. MoDE ‚Äì a ‚ÄúMixture of Domain Experts‚Äô‚Äô framework that routes inputs to denoised experts through a bilevel router. Experiments on MMLU, MBPP, GSM8K, MathQA, HumanEval, and several LLaMA- and Gemma-based models show reported accuracy gains of roughly 1‚Äì3 %. The authors interpret pruning-based improvements as evidence of ‚Äúnoise neurons‚Äô‚Äô in LLMs."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Addresses a topical issue‚Äîefficient inference and pruning in LLMs.\n\nThe idea of combining pruning with an MoE-style router is interesting conceptually.\n\nImplementation is simple to reproduce from the algorithmic description (Algorithm 1 p.5).\n\nExperiments are wide in model coverage."}, "weaknesses": {"value": "1. Conceptual and theoretical unsoundness. The core hypothesis‚Äîexistence of ‚Äúnoise weights‚Äô‚Äô whose removal improves accuracy‚Äîis speculative and unsupported. The so-called ‚ÄúFisher Information perspective‚Äô‚Äô (Eq. 2‚Äì3, p.3) is a qualitative restatement of existing pruning theory and does not prove that any concrete subset of weights is harmful. The PAC-Bayes argument is taken out of context and misapplied: removing parameters does not tighten the bound without redefining priors and posteriors. There is no formal link between their denoising procedure and the bound‚Äôs KL term. As a result, the entire theoretical motivation reads as post hoc justification rather than a derivation.\n\n2. Methodological vagueness and unrigorous design. Algorithm 1 p.5 is effectively a grid search over pruning thresholds, not a principled optimization. The ‚Äúimportance metric‚Äô‚Äô is reused from prior work (He et al., 2018) without justification for large transformer layers; scaling factors (Œ±, Œ≤) and patching (Eq. 7 p.4) are arbitrary. The ‚Äúdomain identification‚Äô‚Äô via clustering (Sec. 3.1 pp.4-5) uses K-means on embedding features but gives no quantitative validation that clusters correspond to domains or that the router labels are meaningful. The bilevel router is simply a two-layer classifier trained with cross-entropy‚Äîno gating or mixture-of-experts load balancing is present. Calling this an MoE architecture is misleading.\n\n3. Experimental design fails to support claims. Reported gains (Table 1 p.7) are within noise levels (1‚Äì2 %) and lack variance or significance tests. Many ‚Äúimprovements‚Äô‚Äô vanish under MoDE compared to DENoise (e.g., Gemma-7B shows ‚Äì0.38 % on MBPP pass@1 and ‚Äì0.11 % on pass@10). No control experiments showing whether similar gains appear under random pruning of equal sparsity. Without that, the main conclusion (‚Äúsome weights are noise‚Äù) is invalid. The authors claim tuning-free operation but evaluate different pruning ratios and select the best (Table 3 p.8), which is tuning. \n\n4. Misuse and misunderstanding of existing literature. Prior pruning works (e.g., SparseGPT, LLM-Pruner, EigenDamage) already study improvement after moderate pruning; the paper fails to reference or compare to these baselines. The supposed novelty‚Äî‚Äúidentifying noise weights‚Äô‚Äô‚Äîis merely a re-labelling of low-importance weights. The relation to Mixture-of-Experts systems (Sec. 5 p.9) is superficial; no conditional computation or sparse routing at token level is implemented.\n\n5. Missing key analyses. No ablation on different random seeds, projection dimensions, or router architectures. No evaluation of computational savings versus performance trade-off. The method‚Äôs hyperparameters (Œ∏ init, Œ¥Œ∏, k) are opaque and not motivated. The ‚Äúdenoised‚Äô‚Äô subnetworks‚Äô sparsity ratios are not reported, so efficiency claims (‚Äúwithout additional parameters or tuning overhead‚Äô‚Äô) cannot be verified. No qualitative analysis of which weights were removed or their layer distributions.\n\n6. Invalid empirical evidence for generalization. Figure 1 p.2 shows one task (MMLU Philosophy) with small ‚Äúnon-monotonic‚Äô‚Äô pruning curves and extrapolates to 57 tasks. But the paper provides no raw data for those tasks (only the claim that ‚Äúmany tasks benefit‚Äô‚Äô). Figures 4‚Äì5 pp.7‚Äì9 show boxplots and ablations that fluctuate randomly‚Äîthese do not prove systematic benefit. Hence, the core finding that pruning mid-importance weights ‚Äúenhances generalization‚Äô‚Äô is not statistically credible."}, "questions": {"value": "Can you provide statistical significance (std dev / CIs) for all reported numbers?\n\nHow does DENoise compare to random pruning at the same sparsity?\n\nWhat proportion of weights are removed? What is the resulting FLOP reduction?\n\nHow do you ensure that clustering truly separates ‚Äúdomains‚Äô‚Äô?\n\nCan MoDE run faster than the dense baseline? If not, what benefit does routing bring?\n\nPlease provide results on open-ended generation tasks; all current metrics are classification accuracies."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "no ethical concern"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NtzFJkXj2Y", "forum": "L3ETLxmb7N", "replyto": "L3ETLxmb7N", "signatures": ["ICLR.cc/2026/Conference/Submission7159/Reviewer_67E6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7159/Reviewer_67E6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7159/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761617957252, "cdate": 1761617957252, "tmdate": 1762919321327, "mdate": 1762919321327, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper challenges the conventional wisdom that pruning LLM weights invariably degrades performance. The authors introduce the concept of \"noise weights\"‚Äîparameters that may appear moderately important but whose removal can improve in-domain task accuracy. Based on this observation, the paper proposes two methods: 1. DENoise: A tuning-free algorithm to identify and remove these domain-aware noise weights, creating specialized \"expert\" subnetworks; 2. MoDE (Mixture of Domain Experts): A framework that uses these denoised experts and employs a bilevel trainable router to dynamically activate the appropriate expert for a given task, aiming to improve out-of-domain generalization. Experiments on models like LLaMA-2 and Gemma across benchmarks (MMLU, MBPP, GSM8K) show that DENoise can yield performance gains of 2-3%, and MoDE achieves an average improvement of over 1.1% without adding parameters or requiring fine-tuning.\n\nThis paper introduces a novel and interesting perspective on weight pruning, backed by positive (though not exceptional) experimental results. The core idea is intriguing. The limited performance gains and the applicability to only general domains (general knowledge vs math vs code) weaken the overall contribution. It suggests a new direction, but many questions remain to be solved."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper's novel insights are its main strength. The idea that removing specific, non-trivial weights can improve performance‚Äîrather than just preserve it‚Äîis a novel and counter-intuitive contribution to the pruning and model efficiency literature.\n\n2. The paper clearly outlines the DENoise algorithm for creating experts and the MoDE framework for routing between them. The presentation is logical and easy to follow.\n\n3. Empirical evaluations are valid. The authors validate their claims across multiple model families (LLaMA, Gemma) and standard benchmarks and also include additional ablation studies."}, "weaknesses": {"value": "1.  While the methods demonstrate consistent improvements, the reported gains are often modest.\n\n2. The approach relies on pre-defined domains and a well-aligned classifier (router) to guide the pruning. It may limit its applicability to many important problems.\n\n3. The section \"Fisher Information Perspective on Noise Weights\" is a bit overly intuitive and subjective. It does not provide informative justifications for the existence of \"noise weights.\" The connection drawn to FIM and PAC-Bayes is tenuous and feels like a post-hoc attempt to add theoretical groundings, but their connections are questionable.\n\n4. In Figure 2, y-axis shows the \"Number of Improved Tasks.\" This absolute number may be confusing without knowing the total number of tasks tested (which is stated as 57 in the text but not in the caption). The graph may consider using percentages to provide more interpretable visualizations."}, "questions": {"value": "It feels like enabling a mixture of experts within the dense model. For the classifier, general domains may not be hard to distinguish.\n\nBut how can we apply it to domains not easily definable (e.g., simple problems that can be answered directly vs. difficult problems that need intensive reasoning)?\n\nA mixture of experts could provide an end-to-end pipeline for training the experts as well as the router at the same time. How can we design something similar here?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "KZoTzDIbRB", "forum": "L3ETLxmb7N", "replyto": "L3ETLxmb7N", "signatures": ["ICLR.cc/2026/Conference/Submission7159/Reviewer_m5aZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7159/Reviewer_m5aZ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7159/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761881780061, "cdate": 1761881780061, "tmdate": 1762919320700, "mdate": 1762919320700, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}