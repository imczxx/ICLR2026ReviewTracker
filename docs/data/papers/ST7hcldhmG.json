{"id": "ST7hcldhmG", "number": 4129, "cdate": 1757607615719, "mdate": 1759898051546, "content": {"title": "3DGS IS A VERSATILE REGULATOR: MODULATING UNIVERSAL METRIC-DEPTH REPRESENTATION VIA ANCHOR-BASED GAUSSIAN-SPLATTED MULTIPLICATION", "abstract": "Recent advances in zero-shot affine-invariant depth estimation have achieved remarkable progress. However, extending relative depth to metric depth remains challenging due to the absence of reliable metric-scale guidance within existing depth foundation models. Building on this, we introduce a novel depth estimation paradigm—anchor–multiplier factorization—as an alternative to conventional approaches such as direct depth regression, depth completion, or feature-fusion methods. Our key insight is that sparse point anchors supply indispensable metric-scale cues, while relative-scale geometric structure can be stably regulated via Gaussian-splatted multiplication conditioned on image semantics. Accordingly, we implement GSD---an anchor-based Gaussian Splatting Depth Regulator for universal metric-depth restoration. We also propose the first theoretical analysis showing how anchor–multiplier factorization mitigates training divergence, and thereby improves metric restoration accuracy. Extensive experiments across diverse datasets demonstrate substantial accuracy gains over state-of-the-art baselines, highlighting the benefits of treating 3DGS not merely as a renderer, but as a versatile regulator for visual representation learning.", "tldr": "", "keywords": ["Metric Depth Representation", "Sparse Anchor", "3D Gaussian Splatting"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a6343196f710ca92db0cb58eaafc62ee5cc6901a.pdf", "supplementary_material": "/attachment/52aecfd8bb90326ac497fcedfcecf09fde2f541c.pdf"}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel metric-scale depth completion method utilizing 3D Gaussian Splatting (3DGS). Specifically, given sparse anchors (observations), the authors formulate depth completion as the problem of predicting an anchor–multiplier over the interpolated anchors, and employ 3DGS to estimate this multiplier (i.e., the 3DGS multiplier) for the task. The authors further strengthen the motivation of their approach through a theoretical proof presented in Section 3.1. When trained proposed method and competitor on Hypersim and then fine-tuned on KITTI using the same training recipe, the proposed method demonstrates comparable or superior performance to existing approaches."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper shows that the parameters of 3D Gaussian Splatting (orientation, scale, transparency, etc.) vary across scenes and can capture rich spatial textures, demonstrating that such representational power can be effectively applied to the depth completion task. Although prior works (Sec. 2.2) have explored depth estimation using 3DGS, it is interesting that this work leverages 3DGS to render a multiplier map, explicitly utilizing these properties within the proposed pipeline.\n2. The authors reformulate the depth completion task into an anchor–multiplier and interpolated-anchor framework and support this formulation with a theoretical proof motivating their design."}, "weaknesses": {"value": "1. Unclear presentation about metric-depth estimation methods (line 40 and Figure 1)\n- In Figure 1, all pipeline types are shown with sparse anchors, but several methods mentioned around line 40 do not actually require sparse anchors such as Marigold, Depth Anything V2, GeoWizard, etc. Moreover, Marigold and GeoWizard focus on affine-invariant rather than metric depth estimation. Clarifying this distinction in the presentation would improve consistency and clarity.\n\n2. Comparison made against depth regression methods rather than depth completion methods\n- In lines 74–82, the paper emphasizes the decoupling of metric scale and relative geometric structure by comparing with prior works. However, methods such as Metric3D, UniDepth, and MoGe-2 perform metric depth estimation from a single image, where metric-scale estimation modules are inherently required in the pipeline. In contrast, the proposed approach performs metric-depth completion given sparse anchors (e.g., LiDAR), where some degree of metric-scale decoupling naturally arises from the input setting itself. From this perspective, the observed decoupling may stem more from the input configuration than from the anchor–multiplier factorization itself. A clearer discussion is needed on why the proposed method achieves decoupling when compared to other sparse-anchor-based depth completion methods such as Marigold-DC, Zero-DC [a1], or etc.\n\n[a1] Hyoseok et al., \"Zero-shot Depth Completion via Test-time Alignment with Affine-invariant Depth Prior\", AAAI 2025.\n\n3. Applicability of Theorem 1 and Figure 2 under sparse-anchor conditions\n- Theorem 1 and Figure 2 are conceptually interesting. However, in realistic depth completion settings with sparse anchors, obtaining an accurate dense scalar matrix I(S) is generally infeasible. It would strengthen the paper if Figure 2 also included experiments under a sparse-anchor condition (e.g., stride 16 on Hypersim) to better examine the theoretical claims under practical sparsity.\n\n4. Experiment section\n- It would be beneficial to also report RMSE and MAE in Table 1 and Table 2. Additionally, evaluating on the VOID dataset, following the protocols of Marigold-DC, Zero-DC [a1], or OGNI-DC, could make the comparison more comprehensive.\n- While using the same dataset for all methods ensures fairness, the performance gaps appear heavily influenced by each architecture’s data-recipe characteristics. Including the original model performance reported in the official papers would make the comparison more transparent. For instance, Marigold-DC could be evaluated using its original implementation procedure instead of “one out of ten samples.” Likewise, Depth Anything V2 + Least Square originally achieves 4.4 AbsRel on NYUv2, while the reproduced version shows 12.0 AbsRel."}, "questions": {"value": "1. The training on Hypersim uses only 192×256 resolution, which seems quite low. Is there a specific reason for this choice? (Other training uses higher resolutions, e.g., line 861.)\n2. In Section 3.1, the notation of the image sample I and ground-truth depth D_gt​ as sets of pixel coordinates is confusing. It would be clearer to formally define them as functions over the pixel domain."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "This paper focuses on the depth completion task, i.e., metric-depth estimation given sparse observations (e.g., LiDAR).\nThe authors utilize publicly available datasets such as Hypersim and KITTI for training and evaluation.\nI do not identify any ethical concerns related to the proposed methodology or the datasets used in this work."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qQysstnklF", "forum": "ST7hcldhmG", "replyto": "ST7hcldhmG", "signatures": ["ICLR.cc/2026/Conference/Submission4129/Reviewer_cTeK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4129/Reviewer_cTeK"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4129/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761622555681, "cdate": 1761622555681, "tmdate": 1762917189773, "mdate": 1762917189773, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes anchor–multiplier factorization for metric depth: compute an interpolated dense initialization from sparse depth “anchors” and predict a per-pixel multiplicative map with a feed-forward 3D Gaussian Splatting renderer.  The authors claim this separates scale from structure and stabilizes training (via a variance-reduction argument). They present GSD (frozen DINOv2 + UNet + 3DGS) with a simple transform that maps normalized outputs to a metric range, and report strong results on Hypersim/KITTI and zero-shot tests against recent baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea of predicting a per-pixel multiplicative map and rendering it with 3DGS. Using 3DGS to output a 2D scale field, then applying it to an anchor-interpolated depth, is a new combination.\n\n2. The paper tries a theoretical story (gradient-variance reduction) to motivate why learning α could be easier than learning depth directly.\n\n3. The method is feed-forward at test time"}, "weaknesses": {"value": "1.  The core idea, metric depth as scale multiply relative structure, is well-known. Recent work also learns pixel-level rescale fields, eg. [1][2]. The factorization is therefore not conceptually new. The change is mostly the depth-completion setting with anchors. Thus, the contribution is limited. \n\n2. Many 3DGS-depth hybrids already exist. The distinct part here is using 3DGS to render α (not RGB/depth), which is an implementation innovation. Its novelty depends on showing clear advantages over a strong pure 2D α-head, eg, simply using a 2D UNet/Vit could plausibly learn the same thing. Unless the authors can show using 3DGS beats an equally pure 2D α-head, the effectiveness of 3DGS is not fully justified.\n\n3. The theory is under-validated. Claims about reduced gradient variance need direct measurements during training, not just descriptive statistics.\n\n4. The paper states “zero-shot on five unseen real datasets NYUv2, KITTI, ScanNet, ETH3D, DIODE,” yet elsewhere says all methods are trained on Hypersim and fine-tuned on KITTI for fairness (and separately, GSD is also trained on KITTI from scratch). How is KITTI both a zero-shot target and the fine-tuning domain?\n\n\n[1] Zhu, Ruijie, et al. \"Scaledepth: Decomposing metric depth estimation into scale prediction and relative depth estimation.\" arXiv preprint arXiv:2407.08187 (2024).\n\n[2]  Jun, Jinyoung, et al. \"Depth map decomposition for monocular depth estimation.\" European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2022."}, "questions": {"value": "1.  Was KITTI used for any training before zero-shot evaluation on KITTI in Table 2? Please state exact training sets per experiment.\n2.  If α is a 2D field, what advantage does 3DGS confer over a purely 2D α-predictor (accuracy, boundary quality, speed)? Please include a 2D UNet/Swin α-only baseline."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uqTWRp9mXO", "forum": "ST7hcldhmG", "replyto": "ST7hcldhmG", "signatures": ["ICLR.cc/2026/Conference/Submission4129/Reviewer_Eiw5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4129/Reviewer_Eiw5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4129/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761956842174, "cdate": 1761956842174, "tmdate": 1762917189417, "mdate": 1762917189417, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new pipeline for multimodal (image + sparse depth), which decouples the scale and its multiplier by the interpolated sparse depth and the multiplier map computed by 3D GS algorithm (MVSplat). \n\nThe proposed method's architecture, GSD, consists of two main modules. The Gaussian Sphere Prediction Module takes in the RGB image and the sparse depth to interpolate, and predicts the 3D Gaussian parameters (centers, covariances, opacities, and spherical harmonics). This utilizes the VIT (DINOv2) + CNN network followed by the U-Net (MVSplat) architecture. \n\nThe second part is Depth Regulation Module (DRM), which performs differentiable GS to render a dense multiplier map on the image plane, and this is multiplied by the raw Gaussian response, which has a value in [0,1]. The authors introduce a mapping function which projects the rendered multipliers. The metric depth map is produced by element-wise multiplication of the maped Gaussian response and interpolated depth.\n\nThe authors tried to show a variance reduction, where the gradient variance for the anchor-multiplier formulation is lower than the direct depth regression."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well-written.\n\nThe proposed paradigm in the paper is well-motivated - The proposed anchor-multiplier factorization method is reasonable to have, since this provides a separation between the scale and its geometry.\n\nThe proposed method is grounded in the theoretical analysis, especially in a variance reduction theorem.\n\nThe first work uses 3DGS as a regulator, which repurposes 3D GS to predict depth multipliers.\n\nThe model has been trained on Hypersim and the KITTI depth completion benchmark, and the authors conducted the zero-shot generalization experiment on NYUv2 (uniform sparse depth sampling), KITTI, ScanNet, ETH3D, DIODE."}, "weaknesses": {"value": "Reliance on the sparse metric and limited experiment on the uniformly sampled sparse anchor - In reality, the sparse depth (anchor) may come from LiDAR, Radar, SfM, or VIO system. The uniformly sampled pattern cannot represent such cases with the sensors.\n\nLimited discussion on the computational cost - even though the trainable model parameters are in total 3.8M, the inference time and its applicability to real-time applications should be discussed.\n\nLimited baselines - Not only the monocular depth estimation method, but also the depth completion method should be compared with this.  The reviewer points out that NLSPN is an outdated baseline. For example, OMNI-DC (ICCV 2025), DepthPrompt (CVPR 2024), Marigold-DC (ICCV 2025), etc."}, "questions": {"value": "1. The details in estimating 3D Gaussian Splatting parameters are not clear.\nDoes the proposed method exactly follow the MVSplat? In that case, it requires multiple images of the static scene, and that sounds like the method is not applicable, considering the training time of the 3D Gaussian splatting regression module. If so, the selection of the baselines does not sound fair. Specifically, if the model requires multi-view images to have 3D GS regression, the model should be compared with the multi-view depth estimation models such as DUST3R or VGGT (CVPR 2025).\n\n2. Computational cost and inference time.\nAlthough the authors argue that feed-forward 3DGS rendering is efficient, the paper offers a limited quantitative comparison of runtime, memory consumption against large transformer-based or diffusion-based depth models. Providing inference time (e.g., FPS) could be helpful to understand the practicality of this paper.\n\n3. A limited evaluation dataset.\nDepth completion models are often evaluated on VOID-1500, VOID-500, and VOID-150 (Wong et al., VOICED), which are the same image with different sparsity. Could the authors compare the proposed method to the updated depth completion models on VOID?\n\n4. Concatenation vs. Multiplication?\nWong et al., (VOICED) and ScaffNet already densify the sparse depth and concatenate them with the image features. What if this method directly concatenates the multiplier and scaler (even if the variance would not be minimized)? This will be helpful to clarify the contribution of the reformulation of the metric depth estimation to the anchor-multiplier setup."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "wvoOyLwPXD", "forum": "ST7hcldhmG", "replyto": "ST7hcldhmG", "signatures": ["ICLR.cc/2026/Conference/Submission4129/Reviewer_17B6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4129/Reviewer_17B6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4129/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762228559601, "cdate": 1762228559601, "tmdate": 1762917189140, "mdate": 1762917189140, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles the metric depth estimation problem through decoupling it into two parts. The first component creates a coarse metric depth map by interpolating (via a combination of linear and nearest-neighbor) a prior map of sparse anchors (e.g. sparse point clouds from depth sensors, SLAM, etc.). The second component learns to output a dense multiplier map though taking as input both the original sparse anchor map and a RGB image. The second component is made up of a combination of a frozen pre-trained ViT encoder (DINO in their experiments) + a learnable CNN encoder + an upsampling decoder as the RGB encoder, and a U-Net encoder for fusing the sparse anchor map and RGB image. The fused output is then fed into a learnable Gaussian decoder. The Gaussian decoder outputs a set of Gaussian parameters which is then rendered into the dense multiplier map. The final metric depth is then computed via element-wise multiplication of the multiplier map and the interpolated anchor map. Experiments train the model on Hypersim and KITTI depth completion, and additionally evaluated zero-shot on multiple unseen datasets. The resulting model outperforms existing methods on Hypersim, and achieves second among compared methods on KITTI completion. The model also achieves a mix of first and second place among compared methods for zero-shot evaluation on unseen datasets.."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Overall the method is an impressive engineering feat which fused together various components (large pre-trained models i.e. DINO, 3DGS rendering for learning depth) in existing literature to produce a method that achieves empirical performance comparable to current state-of-the-art.\n\n-  A central contribution of the paper is to reframe metric depth estimation via decoupling it into a learned multiplier combined with a coarsely generated (non-learnable) prior map. This is a novel way to approach the problem. However I think it can be better ablated, see Weaknesses.\n\n- Figures 1 and 3 are extremely well-designed and greatly aid the understanding of the proposed method."}, "weaknesses": {"value": "- I am strongly concerned about the theoretical section. The theory does **not** appear to conclude that the factorization approach produces more stable gradients. Rather, this conclusion is entirely based on the **assumption** that $\\kappa << \\Lambda$, i.e. a network regressing high-variance output such as metric depth will inherently have large gradient magnitude $||V||$, while a network regression multiplier map $\\alpha$ will have inherently much smaller gradient magnitude. There is no justification for this assumption, other than stating that it occurs 'under mild conditions\" (which seems to not be backed neither theory nor experiments). Assumption 3 regarding no correlation between $U$ and $V$/$W$ also appears very strong, and I do not see any attempts to justify it. Overall I think the paper might be better off without the theoretical section entirely, by motivating the factorization method with stronger empirical evidence.\n\n- The captions of tables 3-5 barely contain any information, and details in Table 3 are poorly presented. This is especially concerning given the importance of Table 3 for ablation individual components of this complex method. See more under questions.\n\n- Given that key contribution of the method is this \"learned multiplier\" component studied in Table 3, there are no experiments ablating what happens if the output representation is not the multiplier, but the metric depth itself. E.g. one can perform a simple ablation which feeds the interpolated anchor map plus the sparse anchor map into the U-Net fusion encoder, followed by the Gaussian decoder / rendering to directly produce a dense metric depth map. Are the gradients less \"stable\" empirically if this was done?\n\n- While the method's complexity is impressive, the multi-stage pipelines contained within the architecture (Hybrid ViT / CNN encoder, U-Net fusion, Gaussian decoder, differentiable 3DGS renderer) can also be viewed as a weakness. Such a system is difficult to reproduce, and does not offer much academic insights on the drawbacks of existing methods + how lessons learnt from this paper can be incorporated into other works tackling the same problem."}, "questions": {"value": "- Due to the high complexity of the proposed methods which combines several different large-scale components, I feel that Table 3 should be one of the most important evaluations in the paper. However, it seems barely elaborated on, and experimental details are omitted. How are the modules ablated? What dataset is the ablation done on? In experiments (a) and (b), what is used in place of +GS-UNet? In experiments (a)-(c), what loss is used in place of the Sobel loss? All these are important components of the method, but only given a one-sentence elaboration that simply says the method as a whole achieves the best performance. \n\n- Real world sparse prior maps, such as LiDAR, are often noisy. Given that there are no learnable components in computing the interpolated prior map, it would appear that the method would intuitively be more sensitive (less robust) to noise, especially due to the naive interpolation algorithms used. Do the authors have any insights for or against this?\n\n- Given that the results of the method parallel that of the state-of-the-art, what makes this a better or preferred method compared to existing ones? E.g. PromptDA seems to do better on KITTI completion, why would one choose GSD over PromptDA for this task?\n\n- Not a question, but a suggestion: If the authors agree that the factorized approach towards metric depth estimation is the core novelty of their work, it would be more convincing, and possibly simpler to implement, if existing methods are adapted such that they produce multiplier maps (that are multiplied with interpolated depth) instead. For instance, if the authors show that PromptDA (factorized) performs much better than vanilla PromptDA, or Marigold-DC (factorized) performs much better than vanilla Marigold-DC, the paper would be much stronger and impactful."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lCgSFoHZJn", "forum": "ST7hcldhmG", "replyto": "ST7hcldhmG", "signatures": ["ICLR.cc/2026/Conference/Submission4129/Reviewer_rCKa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4129/Reviewer_rCKa"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4129/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762238042571, "cdate": 1762238042571, "tmdate": 1762917188890, "mdate": 1762917188890, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}