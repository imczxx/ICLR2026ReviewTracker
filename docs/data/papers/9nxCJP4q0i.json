{"id": "9nxCJP4q0i", "number": 1638, "cdate": 1756900108592, "mdate": 1759898197360, "content": {"title": "Consolidating Reinforcement Learning for Multimodal Discrete Diffusion Models", "abstract": "Optimizing discrete diffusion model (DDM) with rewards remains a challenge—the non-autoregressive paradigm makes importance sampling intractable and rollout complex, puzzling reinforcement learning methods such as Group Relative Policy\nOptimization (GRPO). In this study, we introduce **MaskGRPO**, the first viable approach to enable scalable multimodal reinforcement learning in discrete diffusion with effective importance sampling and modality-specific adaptations. To this end,\nwe first clarify the theoretical foundation for DDMs, which facilitates building an importance estimator that captures valuable token fluctuation for gradient updates. We then delicately tailored the rollout method for visual sequences, which yields diverse completions and reliable optimization gradients. Upon math reasoning, coding, and visual generation benchmarks, MaskGRPO brings more stable and efficient gradient updates, leading to stronger reasoning performance and better generation quality. This study establishes MaskGRPO as a systematic policy optimization approach and the first practical way for discretized visual diffusion. Code is enclosed in the supplementary material.", "tldr": "We introduce **MaskGRPO**, the first viable approach to enable scalable multimodal reinforcement learning in discrete diffusion with effective importance sampling and modality-specific adaptations.", "keywords": ["discrete diffusion", "masked diffusion", "math reasoning", "image generation", "reinforcement learning", "GRPO"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/384ddb4427de6b8d1c298873b3de3e667a5c50ea.pdf", "supplementary_material": "/attachment/cbb9e905a0a7b0187db79e1f34e63776e49a8af4.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose maskGRPO, a GRPO-style RL method for discrete diffusion models developed and shown to work on multimodal DDMs, both text and images. To achieve this, they propose a tractable importance estimator, and an approximated surrogate for importance weighting and KL in GRPO for DDMs. The authors claim more stable and efficient updates while showing improved performance on a set of both visual and language tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is generally well written and easy to follow. The results are compelling enough and it's nice to see GRPO working on image DDMs. The formulations of the importance estimator for DDMs is also useful."}, "weaknesses": {"value": "A cornerstone of the narrative of the paper seems to revolve around compute/sample efficiency, but I did not see a detailed tokens-to-gain or wall-clock comparison against the strongest off-policy GRPO / surrogate-policy approaches, or a theoretical note explaining why the method is expected to work more efficiently in practice."}, "questions": {"value": "Can you provide either empirical or theoretical grounding in support of markGRPO being more efficient than similar methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "hWiA6Bl7n1", "forum": "9nxCJP4q0i", "replyto": "9nxCJP4q0i", "signatures": ["ICLR.cc/2026/Conference/Submission1638/Reviewer_pNLG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1638/Reviewer_pNLG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1638/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760712964569, "cdate": 1760712964569, "tmdate": 1762915838764, "mdate": 1762915838764, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes MaskGRPO, an RL framework extending GRPO to multimodal DDMs. It introduces modality specific rollout strategies with AR-like reversing for text and probabilistic emerging for vision, along with a low-variance importance estimator for stable and scalable optimization across discrete diffusion. Experiments show consistent gains in reasoning, coding, and visual generation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The problem is clearly defined — the paper directly targets the limitation of static embeddings in collaborative code completion by proposing a dynamic, incremental embedding approach.\n\n2. The overall framework is well-structured and conceptually coherent, with a clear system design.\n\n3. The method improves both language and vision generation, demonstrating strong empirical utility."}, "weaknesses": {"value": "The paper lacks discussion of training cost or comparison of resource consumption with baseline methods."}, "questions": {"value": "1. How is the mask ratio in the Rev(·, t) operator scheduled? Is it fixed or dynamically adjusted during RL training?\n\n2. How does the training cost of MaskGRPO compare with other diffusion-RL methods such as Diffu-GRPO?\n\n3. The paper introduces modality-specific rollout strategies, but it is unclear how sensitive the performance gains are to these design choices. Could the authors provide ablation or analysis showing how each component (AR-like reversing, emerging sampler) contributes to the overall gains?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rUUOpOsi6L", "forum": "9nxCJP4q0i", "replyto": "9nxCJP4q0i", "signatures": ["ICLR.cc/2026/Conference/Submission1638/Reviewer_Extk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1638/Reviewer_Extk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1638/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761844369293, "cdate": 1761844369293, "tmdate": 1762915838543, "mdate": 1762915838543, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work proposes a method adapting GRPO for multimodal discrete diffusion models, by using modality specific sampling algorithms for rollouts (semi-autoregressive for text, and random probabilistic unmasking for images), as well as modality specific remasking strategies to use for updates in the GRPO objective (autoregressive-like remasking for text and standard random remasking for images). This is done along with limiting GRPO updates to trajectories in the time interval $(\\gamma, 1)$. The modified GRPO method is used to fine-tune LLaDA for text reasoning tasks as well as MMaDA (a multimodal discrete diffusion model) for text-image alignment and aesthetic quality, where it is shown to outperform alternate RL methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. A comprehensive set of baselines are evaluated for experiments.\n2. The generated image samples in Figures 4, 7 are convincing in terms of improvement.\n3. The ablations with truncation ratio $\\gamma$ are helpful in establishing its impact (Figure 5)."}, "weaknesses": {"value": "1. The writing needs polishing and proofreading\n    - There are numerous grammatical mistakes that interfere with the clarity of presentation\n    - The citation format is incorrect (using `\\citet` rather than `\\citep` )\n    - The Emerge sampler is described unclearly in text (lines 238-247)\n\n2. The Emerge sampler (algorithm 4) doesn’t seem novel, and appears to be the same as the usual random unmasking from masked diffusion models (eg. without confidence based heuristics for unmasking). This is discussed in the original MDLM paper (Sahoo et al., 2024) as well as other early work on masked diffusion (eg. (Shi et al., 2024)). Despite this, the text appears to frame the sampler as a novel contribution (eg. line 244 ‘we refer to MDLM … and propose the … sampling strategy’ and line 247, ‘our sampler’). This should be clarified.\n\n3. A number of claims are made which require more detail or justification:\n    - The motivation for the autoregressive-like remasking invokes an observation that tokens with high entropy provide more informative signal for training, and that later tokens (in AR generation) tend to diverge more. This should be supported by some evidence from rollouts\n    - Remasking with the $\\mathrm{Rev}(\\cdot, t)$ operator is asserted to be more stable and have low-variance (line 192, and also on line 189, the estimator is asserted to be “low-discrepancy”)  (I am assuming, compared to random remasking) - but this statement should be verified explicitly.\n    - TraceRL is claimed to induce “biased estimation of sequence-level importance” - why is the method biased, compared to remasking with $\\mathrm{Rev}(\\cdot,t)$? This seems important since the introduction of a new remasking strategy is a core aspect of the method, and the straightforward thing appears to be reusing the partially masked completion obtained during rollouts.\n\n4. It would be helpful to list the time taken to achieve the reward improvement (or some proxy), since the importance weight computation in this method appears to be more computationally intensive than the mean-field approximation for token level likelihood used in diffu-GRPO \n\nI recommend for a reject, mainly due to point 2 above, which I view as critically important.\n\nJiaxin Shi, Kehang Han, Zhe Wang, Arnaud Doucet, and Michalis K Titsias. Simplified and\ngeneralized masked diffusion for discrete data. arXiv preprint arXiv:2406.04329, 2024."}, "questions": {"value": "1. For text, if tokens later on in generation (more towards the end of generation) are more useful for training, in what sense does the AR-like process assign them “higher attention”. \n    - This appears to conflict with the truncation ratio being set at $\\gamma > 0$  since it will exclude a group of tokens near the end of the (block-autoregressive) generation.\n    \n2. Is the masking rate multiplier ($\\frac1t$ for linear) used in the likelihood computation at the token-level (for instance Equation 8)? The notation in Equation (2) implies it is.\n    - If it is, is the masking rate adjusted for the alternate remasking strategies considered (namely autoregressive-like remasking)?\n\n3. The mechanism behind why smaller truncation ratios lead to training failure (for image fine-tuning) is unclear. An explanation is given in terms of samples having stronger correlations between image patches, but its unclear to me why this results in collapse."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "S5KpKWeT4o", "forum": "9nxCJP4q0i", "replyto": "9nxCJP4q0i", "signatures": ["ICLR.cc/2026/Conference/Submission1638/Reviewer_q71V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1638/Reviewer_q71V"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1638/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982799441, "cdate": 1761982799441, "tmdate": 1762915838415, "mdate": 1762915838415, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles reinforcement learning (policy-based methods such as GRPO, PPO) for discrete diffusion models (dLLMs for text generation, bidirectional discrete diffusion models for visual generation). The authors propose to improve GRPO with effective importance sampling and modality-specific adaptations to the text and visual generation domains. For text generation, it proposes a semi-autoregressive reverse masking strategy to align better with the inherent causality in reasoning tasks. For visual generation, it adopts a probability-based sampler for better visual textures. The method was shown to improve LLaDA and MMaDA on math, coding, and compositional visual generation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "+ The AR-ness introduced back to the masking scheme to improve text-based reasoning tasks looks convincing.\n+ Evaluation on several benchmarks shows promising results."}, "weaknesses": {"value": "+ The overall novelty is a bit limited. The AR-ness that could help dLLMs with reasoning tasks has been noted in previous work. While there are improvements over MaskGIT sampler for visual decoding and sampling, the latter is a relatively old method. Visual generation is evaluated only on text-to-image generation, which is not the biggest advantage of discrete diffusion models. There could be an evaluation of image editing to make the results more significant (however, recent approaches like Transfusion [1] and BAGEL [2] do explore continuous diffusion heads instead of discrete diffusion models for the visual generation part).\n+ Minor point: “3.2 ROLLOUT ADAPTION” was placed in the wrong place. Shouldn’t it be right before “Let visual tokens emerge from masks”?\n\n[1] Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model\n\n[2] Emerging Properties in Unified Multimodal Pretraining"}, "questions": {"value": "See \"weaknesses\""}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uOIh4AHpry", "forum": "9nxCJP4q0i", "replyto": "9nxCJP4q0i", "signatures": ["ICLR.cc/2026/Conference/Submission1638/Reviewer_mNG6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1638/Reviewer_mNG6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1638/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762720524171, "cdate": 1762720524171, "tmdate": 1762915838225, "mdate": 1762915838225, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}