{"id": "K6Zl3gAtMu", "number": 20684, "cdate": 1758308975526, "mdate": 1759896964025, "content": {"title": "Foliagen: Framework for Foliage Image Generation from Individual Crop Leaf Images", "abstract": "While machine learning (ML)-based crop disease classifiers mostly targeted individual leaf images, real-world applications call for disease classification on crop foliage images instead, because they usually rely on cameras mounted on unmanned aerial vehicles to capture foliage images across vast crop fields for automated disease identification. We found that known state-of-the-art (SOTA) classifiers on the only real-world soybean foliage image dataset all exhibited unsatisfactory performance, despite the dataset being modest-sized and including just two soybean disease categories (among many). Hence, it is desirable to make available large foliage image datasets with common crop disease categories for better evaluating and possibly improving SOTA crop disease classifiers on foliage images. This paper introduces a framework that generates crop foliage images utilizing available datasets of individual leaf images, termed Foliagen (short for foliage generation). A generated foliage image dataset can be arbitrarily sized, with each image emulating the natural distribution of diseased leaves with a specified disease rate. Being annotated by design, such generated datasets are valuable for (1) evaluating the SOTA classifiers when applied to practical use and (2) pre-training general SOTA classifiers, making it possible to effectively fine-tune them using any real-world foliage image dataset for improved classification performance. The Foliagen framework is exemplified by generating foliage image datasets for soybean and tomato. Our evaluation results indicate that five SOTA classifiers on generated datasets with nine disease categories achieve accuracy up to 87\\% for soybean and 86\\% for tomato under $\\gamma$ = 5\\%, and that they all exhibit less than 92\\% in classifying the real soybean foliage image dataset (with just two disease categories). Foliagen makes it possible to generate crop foliage image datasets to evaluate future disease classifiers objectively, aiming at in-field applications.", "tldr": "This paper introduces a framework, called Foliagen, to generate diseased foliage image from individual diseased images with customizable disease rate.", "keywords": ["Foliage Dataset", "Leaf Disease", "Image Classification", "Transfer Learning", "Image Generation"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d19b83baf21f860d3bf442f85c0aaa16d3548cac.pdf", "supplementary_material": "/attachment/ae6b634a1b2dbdfe79ea496172222a9ef80b85e5.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces Foliagen, a framework for synthesizing crop foliage images from single-leaf datasets by incorporating biologically-informed rules (like phyllotaxis and disease hot spots). Pre-training on this synthetic data and fine-tuning on a small real dataset significantly enhances performance, bridging a critical gap between lab-trained models and real-world UAV applications."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.  Significance and Practical Impact: The work addresses a crucial, real-world data gap (scarcity of real crop canopy images) and offers a valuable, cost-effective solution through synthetic data pre-training.\n2.  Biologically-Informed Approach and Ablation: The use of biological rules for structure and disease placement is a key feature. Crucially, experiments (Appendix A.2.1) justify the framework's necessity by showing its superiority over direct single-leaf pre-training."}, "weaknesses": {"value": "1.  Overly Simplified and Non-Generalizable Framework Diagram (Fig. 3): The main diagram is a simple linear flow that fails to illustrate core algorithmic details. More importantly, it is *Soybean-specific* (showing trifoliate synthesis) and completely omits the process for the second example crop, tomato, undermining the claim of a general \"framework.\"\n2.  Lack of Simple Synthesis Baseline Comparison: A key ablation is missing: a comparison against a much simpler baseline, such as **random copy-pasting** of leaves. Without this, it is unclear if the complex biological modeling (e.g., phyllotaxis) is truly necessary for effective transfer learning.\n3.  Ambiguity and Errors in Core Mathematical Formulation (Sec. 3.2): The formulas for leaf positioning contain two issues: (a) The golden angle definition ($\\theta_{g}=137.5^{\\circ}$) conflicts with the use of the non-standard $\\theta_{g}^{rad}$ in the cosine/sine functions, creating a unit ambiguity. (b) An \"off-by-one\" error exists in the index range $n\\in\\{1,2,...,N-1\\}$, which does not match the intended leaf count $N$.\n4.  Lack of Real-World Distribution Validation for Disease Modeling: The paper claims its disease modeling (Fig. 4) is based on real data, but only presents statistics for the *synthesized* dataset. To justify fidelity, the authors must first present an analysis of the **real-world target dataset (MH-SoyaHealth Vision)** to show that the distribution characteristics are faithfully replicated."}, "questions": {"value": "please refer to weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VvCJkCASlV", "forum": "K6Zl3gAtMu", "replyto": "K6Zl3gAtMu", "signatures": ["ICLR.cc/2026/Conference/Submission20684/Reviewer_4gCG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20684/Reviewer_4gCG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20684/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761803333315, "cdate": 1761803333315, "tmdate": 1762934067775, "mdate": 1762934067775, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper discusses a flaw in many prior literature -- where they do crop disease classification by taking close-up shots of leaf. They rather discuss how UAVs capturing foliage are more practical. They discuss the lack of datasets for foliage-based crop disease classification. The authors introduce a framework called foliagen -- where they combine leaf images from multiple existing datasets to create foliage imagery. These datasets (considered annotated) were used for downstream tasks and showed performance improvement."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "+ The paper is easy to follow\n+ The practicality of UAV foliage over leaf imagery is reasonable\n+ The proposed method seems simple (and thus attractive!) \n+ The performance improvement on the downstream tasks are encouraging"}, "weaknesses": {"value": "- I like the authors' motivation of UAV imagery being more practical. How does UAV imagery actually look like? I think even a small dataset of actual imagery would be very useful -- it would show various real-world challenges (shading, wind, etc.)\n\n- Is it merely enough to combine leaf disease images. Would diseases not show up in other parts of the plant?\n\n- I think knowing related work on generative plant disease classification/datasets would be useful. Currently, this seems to be a geometric method of combining leaves. Are there pixel-level methods?"}, "questions": {"value": "- As mentioned in the weakness, I would like to see the justification of this imagery being representative of actual imagery collected via UAVs\n\n- It would be good to see justification of absence of disease artifacts in other parts of the plant.\n\n- Is it possible to view results on additional plants available in the existing datasets. \n\n- Is there any prior work on generative plant disease classification/datasets? If so, could you contrast?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YgtfFOGPMd", "forum": "K6Zl3gAtMu", "replyto": "K6Zl3gAtMu", "signatures": ["ICLR.cc/2026/Conference/Submission20684/Reviewer_j62w"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20684/Reviewer_j62w"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20684/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762152606504, "cdate": 1762152606504, "tmdate": 1762934067421, "mdate": 1762934067421, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Foliagen, a framework for generating synthetic crop foliage datasets from existing single-leaf images. The method bridges the gap between single-leaf data and real UAV canopy imagery by simulating multi-plant scenes with realistic spatial structure and disease distribution. Foliagen builds images through a three-level process (leaf, plant, foliage) and controls disease severity by leveraging a controllable parameter.\n\nDatasets for soybean and tomato are synthesized using public leaf images (ASDID, Kaggle, PlantVillage), with leaves arranged naturally on soil backgrounds to resemble real plant growth. Five SOTA classifiers are evaluated, showing that models pretrained on Foliagen data generalize better to real canopy datasets (e.g., MH-SoyaHealthVision), especially under limited real data. The work establishes a practical benchmark for studying leaf-to-foliage generalization and developing field-ready crop disease models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "(1) The paper addresses a highly meaningful and underexplored problem: transferring disease recognition knowledge from single-leaf images to UAV-level canopy imagery. This leaf-to-foliage generalization idea is both novel and practical, as it provides a concrete pathway to bridge laboratory datasets and real field conditions. To the best of my knowledge, very few studies have systematically investigated this level shift, making Foliagen an important step toward realistic and scalable agricultural vision benchmarks.\n\n(2) The proposed Foliagen framework enables controllable and biologically inspired data generation. It introduces a hierarchical process from leaf to plant to foliage with a tunable disease ratio parameter gamma, allowing users to precisely control the severity and spatial distribution of disease symptoms. In addition, the use of spiral phyllotaxis, a natural leaf arrangement pattern following the golden angle of 137.5 degrees, makes the synthetic foliage geometrically realistic and closer to actual crop canopies. This balance between controllability and biological plausibility distinguishes Foliagen from conventional rule-based augmentation pipelines.\n\n(3) The paper demonstrates the practical value of Foliagen through transfer learning experiments. Models pretrained on the synthetic foliage data achieve higher accuracy on real UAV canopy images, even when fine-tuned with only a small fraction of real samples. This shows that the generated data effectively supports real-world applications and can reduce the reliance on costly field annotations."}, "weaknesses": {"value": "(1) The data generation process in Foliagen is primarily rule-based and does not involve any learnable modeling. While the proposed pipeline effectively demonstrates controllable canopy synthesis, incorporating modern generative methods such as GANs or diffusion models could further improve realism and variability. Even if such approaches may not always outperform rule-based designs, exploring them would offer valuable insights into the trade-off between generative plausibility and diversity.\n\n(2) The paper does not include ablation or sensitivity analysis to evaluate the contribution of each generation level. Introducing more controlled variations across the leaf, plant, and foliage stages could help quantify their individual effects and justify the design choices in Foliagen."}, "questions": {"value": "(1) It would be useful to introduce more variations at different generation levels (leaf, plant, and foliage) and analyze how these affect model performance. Such experiments could help clarify the role of each level in shaping the learned representations and validate the effectiveness of the hierarchical design.\n\n(2) A comparison with generative approaches, such as GANs or diffusion models, could be considered to assess the trade-off between controllability and realism. Such an analysis would provide deeper insight into how rule-based synthesis compares with learnable generation in modeling complex canopy structures.\n\n(3) The sensitivity of the results to the choice of disease ratio (e.g., 5% vs. 15%) should be more thoroughly analyzed, as it likely affects model training and transferability. It would also be valuable to discuss how the ratio can be set to better reflect real-world field conditions, for example, by relating it to typical disease incidence observed in UAV imagery."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xXJOKDVWXc", "forum": "K6Zl3gAtMu", "replyto": "K6Zl3gAtMu", "signatures": ["ICLR.cc/2026/Conference/Submission20684/Reviewer_fBth"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20684/Reviewer_fBth"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20684/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762359252153, "cdate": 1762359252153, "tmdate": 1762934066876, "mdate": 1762934066876, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}