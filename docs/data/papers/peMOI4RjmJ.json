{"id": "peMOI4RjmJ", "number": 23294, "cdate": 1758341872475, "mdate": 1759896822359, "content": {"title": "Unbalanced Soft-Matching Distance For Neural Representational Comparison With Partial Unit Correspondence", "abstract": "Representational similarity metrics typically force all units to be matched, making them susceptible to noise and outliers common in neural representations. We extend the soft-matching distance to a partial optimal transport setting that allows some neurons to remain unmatched, yielding rotation-sensitive but robust correspondences. This unbalanced soft-matching distance provides theoretical advantages---relaxing strict mass conservation while maintaining interpretable transport costs---and practical benefits through efficient neuron ranking in terms of cross-network alignment without costly iterative recomputation. In simulations, it preserves correct matches under outliers and reliably selects the correct model in noise-corrupted identification tasks. On fMRI data, it automatically excludes low-reliability voxels and produces voxel rankings by alignment quality that closely match computationally expensive brute-force approaches. It achieves higher alignment precision across homologous brain areas than standard soft-matching, which is forced to match all units regardless of quality. In deep networks, highly matched units exhibit similar maximally exciting images, while unmatched units show divergent patterns. This ability to partition by match quality enables focused analyses, \\emph{e.g.,} testing whether networks have privileged axes even within their most aligned subpopulations. Overall, unbalanced soft-matching provides a principled and practical method for representational comparison under partial correspondence.", "tldr": "", "keywords": ["Optimal Transport", "Neural Tuning", "Representational Similarity", "Deep Neural Networks"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7ccfa3189ecb7798996f24b532d34a9a9d8b1357.pdf", "supplementary_material": "/attachment/8722aedf0cafa5d9d2721d84de31438248e03503.pdf"}, "replies": [{"content": {"summary": {"value": "This paper proposes an extension of the soft matching distance for measuring representational alignment. The idea is to account for noisy, low-reliability units by relaxing the strict mass conservation of soft matching, thus allowing for unmatched units. The authors also provide a method for selecting the hyperparameter of the method, the optimal amount of unmatched mass. In simulation experiments, they show that their metric is able to select the better model of simulated data, while standard soft matching fails. They also test their method on real fMRI data (NSD), finding that it achieves higher ROI-matching accuracy than standard soft matching."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "- The paper addresses a relevant question that is of great interest to the community.\n- It adds a sensible extension to soft matching, creating a promising candidate for a good neural similarity measure. The proposed unbalanced soft matching is well-motivated and initial sanity checks are promising.\n- The writing is clear and logical.\n- I see no issues with quality or correctness."}, "weaknesses": {"value": "- Arguably, the fact that there are unmatched units between two systems is a difference that we might not want to ignore. Suppose there were two essentially identical candidate models to be evaluated, but one has (many) random noise units added. Unbalanced soft matching with optimally chosen s (for each model) would not find a difference between these models, correct? Standard soft matching thus has an implicit bias for simpler models, which might be desirable, but is somewhat lost by your method (unless one uses the s to decide).\n- On a similar note, the metric suffers from the fact that I can trivially achieve optimal similarity by just inflating my model: Because the metric is free to drop what it doesn't need, any sufficiently large model should eventually achieve perfect similarity (at potentially large values of s). This won't generalize to a test set, though. \n\nOverall, while there is a potential weakness of the proposed method, I do think that the paper adds a valuable proposition to the research field of representational similarity."}, "questions": {"value": "- To address the main criticism of the metric being too flexible: It might be necessary in practice to combine unbalanced soft matching with train-test split evaluations, where you choose s (and the units to be discarded) on the train split, to then compute the similarity score on the test split.\n- Will you release a reference implementation to compute unbalanced soft matching? \n- Section 4.3: How exactly does the matching of similar brain regions work? I currently understand that you select two ROIs in two subjects each, then compute a between-subject matching for all voxels of these regions, to then measure the fraction of units that were correctly mapped to the corresponding region in the other subject. Is this correct? The paper could be a bit more detailed here.\n- For voxels of fMRI readings, there sometimes are uncertainty measures of individual voxels based on estimates of SNR. If you threshold units by this uncertainty measure, i.e. exclude them if they are too unreliable, does that match against the units your algorithm excludes? How do results in table change 1 if you compute soft matching but exclude unreliable units?\n- How does $m_{reg}$ relate to $s$? Is it simply $m_{reg} = s$?\n- I was initially confused about the notation $\\mathcal{T}^{u}(N_x, N_y)$, because the $u$ is never mentioned. I now think this simply stands for \"unbalanced\", is that correct? Should this maybe be $\\mathcal{T}^{s}(N_x, N_y)$? I would have found it logical, notation-wise, to include s in the reference to the set of natural solutions, because the set is parameterized in s.\n- Figure 7 states 3 layers but I think it should say 2.\n- Grammar in lines 192, 216."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "s0r66Q7baT", "forum": "peMOI4RjmJ", "replyto": "peMOI4RjmJ", "signatures": ["ICLR.cc/2026/Conference/Submission23294/Reviewer_QEdB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23294/Reviewer_QEdB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23294/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761758103099, "cdate": 1761758103099, "tmdate": 1762942593044, "mdate": 1762942593044, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper extends soft matching for neuron to neuron alignment to a partial optimal transport setting that can leave units unmatched. It is rotation sensitive (in some cases, a desired quality) yet robust to noise and unequal population sizes. They use simulations, fMRI across NSD subject pairs, and DNN experiments to show that the method filters out low-quality units, improves cross-area precision, and closely tracks brute force ablations at far lower cost."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "In summary, I think the originality and significance of this paper are good.\n\n- I believe the paper addresses an important and timely problem. \n\n- Recasting as average matched correlation gives an interpretable score in [−1,1], which helps. \n\n- Experiments seem thorough. Simulations show recovery with outliers and correct model selection. NSD shows exclusion of low noise ceiling voxels and higher within-area precision than balanced soft matching. DNNs show matched units have similar MEIs and that alignment drops after random rotations, consistent with privileged axes."}, "weaknesses": {"value": "- Novelty relative to existing unbalanced OT and partial matching methods could be clearer. The authors cite Chapel et al. and related work, but I am not sure what is gained over the existing partial OT with dummy nodes plus a simple threshold.\n\n- My understanding is that the tuning curves are centered as unit-normalized before being used for the unbalanced soft-matching. However, there are many cases where the neuronal units have very small responses (dead neurons). This normalization scheme would blow up the activities of these dead neurons, and I think that would affect the matching result. I think the authors should address the sensitivity of UnSM to the preprocessing methods.\n\n- The clarity of the paper can be improved. Readers would appreciate a more detailed explanation of the original soft-matching algorithm at the beginning. The authors can use that opportunity to define variables more carefully. Currently, variables such as p, and q, and terminologies like \"mass\" are not defined clearly before being used. The mathematical part of the paper is currently only really readable to readers who are already familiar with the OT literature or the softmatching paper."}, "questions": {"value": "1. The variables p and q are used in line 108 without being explained or introduced. \n\n2. For choosing optimal regularization, the authors first introduce a 2D-valued function f(s)=[\\zeta(s), \\rho(s)], with a justification that looking at both quantities is necessary for balancing the transport distance and reg. strength. But then the authors proceed to ignore \\rho(s) when computing the maximal positive curvature. Why is that?\n\n3. I don’t think I understand the Figure 2 left image. What is the red box and the yellow line? If both X and Y have 100 signal neurons, then shouldn’t the matching combinations form a square submatrix of size 100x100?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "nrskwKoI3E", "forum": "peMOI4RjmJ", "replyto": "peMOI4RjmJ", "signatures": ["ICLR.cc/2026/Conference/Submission23294/Reviewer_SBuW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23294/Reviewer_SBuW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23294/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761956680336, "cdate": 1761956680336, "tmdate": 1762942592839, "mdate": 1762942592839, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Existing representational similarity metrics frequently fall into two categories: rotation-invariant methods (e.g., CKA, RSA) that measure overall geometric similarity but obscure neuron-level correspondence, or rotation-sensitive methods (e.g., standard soft-matching) that find such correspondences but are brittle, as they inherit the \"critical limitation\" of classical optimal transport (OT) by forcing a complete, one-to-one match between all units. This paper identifies the latter's inadequacy in the common scenario of comparing noisy biological data (fMRI) or functionally distinct deep neural networks (DNNs), where correspondence is inherently partial. It introduces the \"unbalanced soft-matching distance,\" a principled extension of soft-matching to a partial OT framework. This method permits a fraction of units to remain unmatched, governed by a data-driven regularization parameter selected via an L-curve heuristic. The authors demonstrate through simulations that the method is robust to spurious \"outlier\" neurons and correctly identifies models with greater signal overlap in a task where standard soft-matching fails."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The method is theoretically well-grounded, providing a principled extension of optimal transport to solve the well-documented problem of spurious alignments in noisy, partially corresponding neural data.\n2. The paper provides compelling evidence of practical utility by showing that a single $\\mathcal{O}(n^3 \\log n)$ optimization can rank unit alignment as accurately as a computationally prohibitive $\\mathcal{O}(n^4 \\log n)$ brute-force ablation.\n3. The method provides highly interpretable outputs by partitioning units into \"matched\" and \"unmatched\" subsets."}, "weaknesses": {"value": "1. The method's autonomy relies entirely on an L-curve heuristic to select the optimal matched mass, a technique the authors concede has unclear generality and is known to be unstable in non-ideal (e.g., smooth) cost-regularization landscapes.\n2. By relaxing mass conservation, the proposed method sacrifices formal metric properties, specifically the triangle inequality, limiting its use in downstream algorithms or theoretical proofs that require a true metric.\n3. The \"correlation-based ordering\" heuristic used as a fast baseline appears to be a strawman, as its catastrophic failure is predictable; a more competitive baseline, such as a greedy matching algorithm, was not included for comparison."}, "questions": {"value": "1. The method relies on a squared Euclidean distance cost (Section 2.2). How sensitive are the resulting unit partitions and alignment rankings to this choice, and have alternative cost functions (e.g., cosine distance) been investigated?\n2. How does the L-curve heuristic's second-derivative approximation perform on smooth cost-regularization curves that lack a distinct \"elbow,\" and what is the method's failure mode in such cases?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0QRXcLA2ke", "forum": "peMOI4RjmJ", "replyto": "peMOI4RjmJ", "signatures": ["ICLR.cc/2026/Conference/Submission23294/Reviewer_Ny7g"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23294/Reviewer_Ny7g"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23294/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762552752200, "cdate": 1762552752200, "tmdate": 1762942592581, "mdate": 1762942592581, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}