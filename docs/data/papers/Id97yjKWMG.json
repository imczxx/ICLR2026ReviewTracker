{"id": "Id97yjKWMG", "number": 17005, "cdate": 1758271104372, "mdate": 1759897204879, "content": {"title": "PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time", "abstract": "Large Language Model (LLM) empowered agents have recently emerged as advanced paradigms that exhibit impressive capabilities in a wide range of domains and tasks. Despite their potential, current LLM agents often adopt a one-size-fits-all approach, lacking the flexibility to respond to users’ varying needs and preferences. This limitation motivates us to develop PersonaAgent, the first personalized LLM agent framework designed to address versatile personalization tasks. Specifically, PersonaAgent integrates two complementary components: a personalized memory module that includes episodic and semantic memory mechanisms; a personalized action module that enables the agent to perform tool actions tailored to the user. At the core, the persona (defined as unique system prompt for each user) functions as an intermediary: it leverages insights from personalized memory to control agent actions, while the outcomes of these actions in turn refine the memory. Based on the framework, we propose a test-time user-preference alignment strategy that simulate the latest $n$ interactions to optimize the persona prompt, ensuring real-time user preference alignment through textual loss feedback between simulated and ground-truth responses. Experimental evaluations demonstrate that PersonaAgent significantly outperforms other baseline methods by not only personalizing the action space effectively but also scaling during test-time real-world applications. These results underscore the feasibility and potential of our approach in delivering tailored, dynamic user experiences.", "tldr": "We introduce PersonaAgent, a novel LLM-agent framework for various personalization tasks.", "keywords": ["Personalization", "Large Language Models", "LLM Agents"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/03768c840b0389f5ef3e0a346a1aedf9b1676099.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper focuses on personalized LLM agents. To address the one-size-fits-all limitations of existing approaches, it proposes PersonaAgent. The core of this framework is the persona, which acts as an intermediary between the personalized memory module (including semantic memory mechanisms) and personalized actions. Based on this framework, the paper proposes a test-time user-preference alignment strategy to optimize the persona by simulating recent interactions. Finally, the effectiveness of the proposed framework is demonstrated on the LaMP benchmark."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. Using the persona as an intermediary between memory and action is intuitive and reasonable.\n2. A complete personalized agent framework, PersonaAgent, is proposed.\n3. Experimental results demonstrate the effectiveness of the proposed strategy, and detailed ablation experiments are performed."}, "weaknesses": {"value": "1. The paper is poorly written, the method is obscure, and lacks necessary details. For example, the input to $f_{enc}$ is a tuple. How is the tuple encoded into an embedding? How does the resulting $\\mathcal{R}^u(q^*)$ work? What is the observation? How are personas and observations combined to perform personalization? What is the textual loss function? These are unclear.\n2. The motivation for the proposed module is unclear, making this paper less like a technical report.\n3. Are the baseline methods adapted to the dataset used, or do they use their generalized form? Furthermore, do they also use the tools used in this paper?\n4. There is a lack of discussion on the space and time complexity of the algorithm. Each user needs to maintain a large amount of information, and test time alignment may introduce significant inference delays."}, "questions": {"value": "Please refer to Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "08yDfUeSdT", "forum": "Id97yjKWMG", "replyto": "Id97yjKWMG", "signatures": ["ICLR.cc/2026/Conference/Submission17005/Reviewer_q71x"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17005/Reviewer_q71x"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17005/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761447142521, "cdate": 1761447142521, "tmdate": 1762927028440, "mdate": 1762927028440, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes PersonaAgent, a personalized LLM agent framework for conversational AI. PersonaAgent integrates two memory types—episodic and semantic memory—and a personalized action module, all coordinated via a dynamically optimized user persona (system prompt). The framework introduces a test-time user-preference alignment strategy that updates the persona prompt based on recent user interactions. Experiments on the LaMP benchmark demonstrate improved performance over non-personalized, workflow-based, and agentic baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* Proposes a unified memory-action framework for personalization, generalizable across tasks.\n\n* Introduces a test-time persona optimization mechanism, enabling real-time adaptation to user preferences.\n\n* Provides comprehensive experiments and ablation studies, showing the necessity of each component."}, "weaknesses": {"value": "* Evaluation relies on machine metrics (accuracy, F1, ROUGE) not fully convincing; would be better to include personalization metrics (e.g., Persona-F1, faithfulness).\n\n* The computational cost and scalability of test-time alignment are not thoroughly discussed."}, "questions": {"value": "* How does the test-time alignment impact inference latency and scalability?\n\n* How does the method perform for users with limited interaction history?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6x8gTRAStt", "forum": "Id97yjKWMG", "replyto": "Id97yjKWMG", "signatures": ["ICLR.cc/2026/Conference/Submission17005/Reviewer_acgQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17005/Reviewer_acgQ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17005/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761956963892, "cdate": 1761956963892, "tmdate": 1762927028130, "mdate": 1762927028130, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes PersonaAgent, the first personalized LLM agent framework that adapts to individual user preferences through a dynamic persona. It combines personalized memory (episodic and semantic) and action modules, with the persona acting as an intermediary that evolves via user interactions. Experiments show it outperforms baselines in personalization and scales effectively in real-world test-time settings."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tPersonaAgent is the first LLM agent framework for dynamic user-level personalization, combining episodic/semantic memory and persona-driven actions for continuous adaptation.\n2.\tThe test-time alignment method optimizes the persona via simulated interactions and textual loss, enabling real-time, scalable personalization without retraining.\n3.\tThe work rigorously validates its approach across four diverse personalization tasks, ablation studies, and scaling analyses."}, "weaknesses": {"value": "1.\tThe evaluation relies primarily on LaMP, which focuses on text classification and generation tasks that do not adequately capture instruction-following ability in real interactive dialogues—would the framework still excel other benchmarks?\n2.\tThe action module only uses Wikipedia search and personal data retrieval; given that Wikipedia search may dominate performance gains, does the personalization component (i.e., personal data retrieval alone) meaningfully contribute to the agent’s effectiveness?\n3.\tAlthough persona case studies are included, the full agent execution process is not illustrated—could a detailed step-by-step example better demonstrate how personalization operates in practice?\n4. The paper lacks runtime analysis—how long does the agent actually take to execute?"}, "questions": {"value": "See the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "KqVUFA6i5W", "forum": "Id97yjKWMG", "replyto": "Id97yjKWMG", "signatures": ["ICLR.cc/2026/Conference/Submission17005/Reviewer_dcVc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17005/Reviewer_dcVc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17005/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982014812, "cdate": 1761982014812, "tmdate": 1762927027786, "mdate": 1762927027786, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}