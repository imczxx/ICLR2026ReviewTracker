{"id": "AcTsKglDdh", "number": 21352, "cdate": 1758316537020, "mdate": 1759896926767, "content": {"title": "DataMIL: Selecting Data for Robot Imitation Learning with Datamodels", "abstract": "Recently, the robotics community has amassed ever larger and more diverse datasets to train generalist policies. However, while these policies achieve strong mean performance across a variety of tasks, they often underperform on individual, specialized tasks and require further tuning on newly acquired task-specific data. Combining task-specific data with carefully curated subsets of large prior datasets via co-training can produce better specialized policies, but selecting data naively may actually harm downstream performance. To address this, we introduce DataMIL, a data selection framework built on the datamodels paradigm that reasons about data selection in an end-to-end manner, using the policy itself to identify which data points will most improve performance. Unlike standard practices that filter data using human notions of quality (e.g., based on semantic or visual similarity), DataMIL directly optimizes data selection for task success, allowing us to select data that improves the policy while dropping data that degrade it. To avoid performing expensive rollouts in the environment during selection, we introduce a surrogate loss function on task-specific data, allowing us to use DataMIL in the real world without degrading performance. We validate our approach on 60+ simulation and real-world manipulation tasks, notably showing successful data selection from the largest open collections of robot datasets (OXE); demonstrating consistent gains in success rates over prior works. Our results underscore the importance of end-to-end, performance-aware data selection for unlocking the potential of large prior datasets in robotics.", "tldr": "We learn to estimate each data-point's effect on imitation learning performance via Datamodels; we then leverage these models to select high quality samples that maximizes downstream policy success", "keywords": ["Robot Learning", "Data Curation", "Imitation Learning"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/82e6c304571ad1e85b44780f29e82e7042b2743f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces DataMIL, a framework for selecting the most beneficial data from large, heterogeneous prior datasets to improve imitation learning for specific robotic tasks. The core problem addressed is that naively co-training with large datasets can harm performance, while heuristic-based selection methods (e.g., based on visual or semantic similarity) are often suboptimal because they don't directly consider the data's impact on the final policy's performance.\n\n\nDataMIL adapts the \"datamodels\" paradigm to robotics. It works by estimating the influence of each data point (or cluster of data points) on a policy's task success. To make this feasible for robotics, it introduces two key adaptations:\n\n\n1. A surrogate objective: Instead of using expensive real-world rollouts to measure performance during data selection, DataMIL uses the policy's validation loss on a small set of target-task data as a differentiable proxy metric.\n\n2. Efficient estimators: It explores two methods for calculating data influence scores: a comprehensive but computationally expensive Regression Estimator and a more efficient Metagradient-based Estimator suitable for large, modern policies like Octo.\n\n\nThe proposed pipeline involves clustering prior data, estimating influence scores for each cluster using the surrogate objective, selecting the top-ranked clusters, and finally co-training a policy on this selected data and the target task data. The authors validate DataMIL across 60+ simulation and real-world tasks, demonstrating superior performance over several baselines by selecting data from large datasets like MetaWorld, LIBERO-90, and the Open X-Embodiment (OXE) dataset."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- As robotic datasets like OXE and DROID grow in scale and heterogeneity, the problem of \"negative transfer\" or performance degradation from irrelevant data becomes increasingly severe. DataMIL provides a concrete solution to this important and timely challenge in the field.\n- The paper's primary strength is its shift from heuristic-based data selection to a more principled, end-to-end optimization. By directly estimating a data point's influence on policy performance (via a proxy), DataMIL moves beyond potentially misleading similarity metrics and focuses on the ultimate goal: task success. This is a significant conceptual improvement over methods that rely purely on visual, motion, or state-action similarity.\n- The paper successfully adapts a powerful idea from the broader machine learning community to the specific constraints of robotics. The introduction of a differentiable, rollout-free surrogate loss is a clever and necessary innovation that makes the datamodels framework tractable for physical systems.\n- The authors provide comprehensive validation across a wide range of settings: a large number of simulation tasks in MetaWorld (50) and LIBERO (10), and challenging real-world tasks using the massive and heterogeneous OXE dataset. The demonstrated ability to select useful data for an unseen embodiment (Tiago robot) is particularly compelling."}, "weaknesses": {"value": "- The entire method hinges on the assumption that minimizing validation loss on a small target dataset ($\\hat{\\mathcal{M}}$) is a reliable proxy for maximizing real-world success rate ($\\mathcal{M}$). The paper provides one experiment (Fig. 2) to show this correlation holds, but this is on a single task. This proxy is known to be noisy in robotics. It is plausible that for tasks involving complex contact dynamics, deceptive local minima, or sparse rewards, data that merely helps \"fit\" the target demonstrations (i.e., lower BC loss) might not be the data that promotes robust, generalizable behavior. The proxy might favor data that is visually simple or has similar action patterns, even if other data could teach a more valuable physical prior, potentially filtering out more diverse or challenging data from the prior dataset that could have been crucial for improving robustness and generalization.\n- The method introduces several critical hyperparameters that significantly impact performance, and the paper relies on empirical ablations to set them.\n1. Figure 10a shows that performance is sensitive to the percentage of data selected. There is no principled way offered to determine the optimal ratio a priori, meaning users must perform a costly sweep.\n\n2. Figure 10b demonstrates that performance varies with cluster granularity. The justification that the optimal strategy is a \"function of the dataset size\" is intuitive but not actionable without further guidance. \n\n3. The paper fixes α=0.5 based on simulation results (Fig. 10c), but this optimal ratio is likely task- and dataset-dependent. The need for these expensive, nested hyperparameter sweeps undermines the overall efficiency of the framework.\n\n- The cross-embodiment selection for the Tiago robot (Fig. 5a) is interesting, but the paper only observes that the selected data represents \"robots operating on a table top from an ego-perspective\". This is a very general description. It's unclear if DataMIL is discovering abstract skills or simply matching on coarse visual scene structure, the latter being a much weaker form of transfer."}, "questions": {"value": "While the validation loss proxy appears to work well in your experiments, its reliability is a critical assumption. Can you characterize the potential failure modes? In what specific types of robotic tasks (e.g., those with high physical variability, tasks requiring tool use where initial states are similar but require vastly different actions, or long-horizon tasks with sparse success signals) might minimizing validation loss lead to the selection of data that is detrimental to real-world task success?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gxC8JcEulo", "forum": "AcTsKglDdh", "replyto": "AcTsKglDdh", "signatures": ["ICLR.cc/2026/Conference/Submission21352/Reviewer_FrUR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21352/Reviewer_FrUR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21352/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760619057049, "cdate": 1760619057049, "tmdate": 1762941716283, "mdate": 1762941716283, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposed a data selection strategy called DataMIL for robot imitation learning problems. DataMIL is built upon prior work (datamodels) on data selection in CV and NLP problems: the regression method and the metagradient method. To tackle the intractable datamodeling objective in robot imitation learning, the paper proposed some modifications to the standard datamodels: (1) a proxy metric, (2) clustering demonstrations temporally, and (3) a strategy to prevent distribution shift. Empirically, the DataMIL achieved higher success rates on both simulated and real-world multi-task robotics benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Instead of using heuristics such as visual similarity or state–action closeness to select subsets of prior data, this paper proposed to use the performance-aware datamodels to predict scores for selecting each data, resulting in an end-to-end data selection algorithm for robotics imitation learning problem.\n\n- The proposed proxy metric prevents expensive and intractable rollouts on real-robot during data selection and also prevents repeatedly learning the same algorithms on different subsets of the prior data.\n\n- Empirically, the evaluations of the proposed methods range from both simulated and real-world robotics benchmarks and show consistent gains of DataMIL over multiple baselines."}, "weaknesses": {"value": "- Gradient-based data reweighting and data balancing for supervised learning problems has been widely studied in the literature [1, 2, 3]. The concepts of datamodels and regression based methods have been proposed in prior methods. Also, the data selection for robotics imitation learning is still a supervised learning problem. Overall, the contributions of the paper seem to be incremental.\n\n- The explanations for some strategies in Sec. 4.2 are unclear and some ablation experiments are limited. See the question part for details.\n\n- Since the paper focuses on empirical studies, including preliminary open-source code in the submission would strengthen the conclusions.\n\n[1] Ren, Mengye, Wenyuan Zeng, Bin Yang, and Raquel Urtasun. \"Learning to reweight examples for robust deep learning.\" In International conference on machine learning, pp. 4334-4343. PMLR, 2018.\n\n[2] Shu, Jun, Qi Xie, Lixuan Yi, Qian Zhao, Sanping Zhou, Zongben Xu, and Deyu Meng. \"Meta-weight-net: Learning an explicit mapping for sample weighting.\" Advances in neural information processing systems 32 (2019).\n\n[3] Wang, X., Pham, H., Michel, P., Anastasopoulos, A., Carbonell, J., & Neubig, G. (2020, November). Optimizing data usage via differentiable rewards. In International Conference on Machine Learning (pp. 9983-9995). PMLR."}, "questions": {"value": "- Fig 2: Is the target-only policy trained on a dataset with expert and sub-optimal demonstrations on the target task? I am curious about the performance of imitation learning only on target expert demonstrations. \n\n- The ablation experiments for the proxy metric $\\hat{M}$ in Sec 4.2 only limits to a single task.\n\n- The “clustering training examples” paragraph in Sec. 4.2: The description of the specific clustering methods are not clear from the texts. Is there any ablation study showing the effects and necessity of clustering training examples?\n\n- Fig 2, Fig 3, Fig 4, and Sec 5.2: Is there a direct quantitative comparison between the dataset selected by different methods? For example, if imitation learning on the target expert data can achieve almost 100% success rate, then computing the IoU score or some clustering based scores (e.g., NMI score) between these expert data and data selected by different methods would be direct comparisons.\n\n- Any ideas about how to perform data selection only on fine-tuning datasets and how to reduce the distribution shift if we cannot retain the prior dataset?\n\n- Any comments on computing the metric as in Eq.5 if the policy objective itself is not differentiable, e.g., if we were doing RL instead of IL."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "WW6Gsm9nZT", "forum": "AcTsKglDdh", "replyto": "AcTsKglDdh", "signatures": ["ICLR.cc/2026/Conference/Submission21352/Reviewer_FHqk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21352/Reviewer_FHqk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21352/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761801449653, "cdate": 1761801449653, "tmdate": 1762941715964, "mdate": 1762941715964, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the critical problem of selecting beneficial data from large, heterogeneous datasets for robot imitation learning. The authors argue that standard heuristic-based selection methods (e.g., visual or state-action similarity) are suboptimal and can even harm performance. To address this, the paper proposes DataMIL, a framework based on the 'datamodels' paradigm, which aims to predict a policy's performance based on the data it is trained on. The core contribution is a surrogate objective—the behavior cloning (BC) loss on a small set of target-task data. This surrogate avoids the need for expensive and risky real-world rollouts and is fully differentiable, enabling efficient metagradient-based estimation. The conclusion is supported by comprehensive experiments in simulation (MetaWorld, LIBERO) and on real-world hardware (OXE), demonstrating superior performance over several baselines."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- The proposed problem is critical for the robot learning community. As the field increasingly relies on scaling up data (e.g., OXE), methods for effectively curating this data to specialize in new tasks are essential.\n- The paper's core idea of using a differentiable, rollout-free surrogate metric (BC loss on target data) is novel and effective. It elegantly adapts the datamodels framework to the specific constraints of robotics.\n- The evaluation is comprehensive, spanning multiple benchmarks (MetaWorld, LIBERO, OXE), policy architectures (MLP, Octo), and strong heuristic baselines (BR, Flow, STRAP).\n- The real-world evaluation on the heterogeneous OXE dataset is a significant strong point, especially the demonstration of successful cross-embodiment data selection (for the Tiago robot), which strongly supports the claims."}, "weaknesses": {"value": "- The proposed data model incurs high computational costs, as it requires per-task estimation.\n- The method is far from \"plug-and-play,\" as it introduces numerous new hyperparameters that demand meticulous tuning, often relying on human heuristics and empirical expertise."}, "questions": {"value": "- Q1: Is there a trade-off strategy to efficiently identify the approach that yields the maximal performance improvement for the policy?\n- Q2: The authors find that the optimal clustering strategy differs between LIBERO (sub-trajectories) and OXE (full-trajectories). Could the authors provide a principled heuristic for selecting the appropriate clustering granularity based on dataset characteristics (e.g., dataset size, degree of heterogeneity, number of tasks)?\n- Q3: I'm curious about the potential impact of leveraging the identified \"negative samples\" explicitly during training, rather than only using positive examples. For instance, could a contrastive learning objective be designed to actively repel these negative examples while attracting positive ones? Intuitively, explicitly instructing the policy \"what not to learn\" might be more efficient or precise for defining the correct decision boundaries than only providing positive examples."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "u5mXBZ6T1t", "forum": "AcTsKglDdh", "replyto": "AcTsKglDdh", "signatures": ["ICLR.cc/2026/Conference/Submission21352/Reviewer_PBcc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21352/Reviewer_PBcc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21352/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996987045, "cdate": 1761996987045, "tmdate": 1762941715668, "mdate": 1762941715668, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles the challenge of improving task-specific robot imitation learning using large, diverse prior datasets that often contain helpful and harmful examples. Motivated by the limits of heuristic data filtering, which may select visually or semantically similar but suboptimal samples, the authors introduce DataMIL, a data-selection framework built on datamodels that estimates how each datapoint influences policy performance end-to-end. Their method avoids costly real-world rollouts by using a differentiable surrogate loss and meta-gradient or regression-based estimators to assign influence scores, selecting the most beneficial data while discarding harmful samples. Experiments across simulated and real manipulation tasks, including MetaWorld, LIBERO, and OXE, show consistent improvements over prior state-of-the-art retrieval and co-training baselines, particularly in heterogeneous real-world settings. The key takeaway is that performance-aware, end-to-end data attribution enables better curation of large robot datasets and significantly improves fine-tuning outcomes on new tasks."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper builds on the datamodels paradigm and adapts it thoughtfully to robotics, incorporating principled techniques like metagradients and surrogate losses to avoid expensive rollouts.\n2. The paper demonstrates consistent improvements across 60+ simulation and real-world tasks (MetaWorld, LIBERO, OXE), making the empirical evidence strong and diverse.\n3. Comparisons against multiple state-of-the-art retrieval and co-training methods, plus ablations on surrogate loss vs true success metrics, meaningfully validate the approach.\n4. Demonstrates utility in real robot settings and across embodiments, an important step toward practical general-purpose robot learning."}, "weaknesses": {"value": "1. Even with meta-gradients, building datamodels requires multiple policy trainings, making the pipeline significantly more expensive than standard fine-tuning or heuristic retrieval. This may limit usability in real-world labs without large compute.\n2. The method is evaluated primarily on one new task at a time. Broader deployment to large-scale continual or many-task adaptation scenarios remains underexplored.\n3. The core datamodel assumption is borrowed from NLP/CV; a deeper theoretical justification for robotic sequential decision-making settings would strengthen the contribution.\n4. I was deeply interested in looking at more qualitative data selection examples by DataMIL and considered baselines. While the authors provide some examples, I did not find them to be very convincing. It would be nice to see more examples along the lines of Figure 6 for Meta World. Moreover, retrieved demo examples shown for real-world tasks (Figure 8) also do not tell me much - why did DataMIL select those demos? It would be nice to include more discussion around qualitative results in the paper.\n5. While the paper compared against several retrieval methods in robotics datasets, simpler retrieval strategies, such as retrieving dataset with matching camera poses, objects being manipulated, etc., were not considered. Without such baselines, I believe it is hard to justify this method as the current best for retrieval-based learning from large-scale robotics datasets.\n\n\nOther minor issues:\n1. Caption in Figure 6 should be updated to show which task the plots are for."}, "questions": {"value": "1. Did the authors analyze the outputs of DataMIL datamodel against some of the recent heuristic-based retrieval strategies for co-training? E.g. [1] and [2] have said that matching data distributions around specific factors such as camera poses and placement arrangements helps boost policy learning. According to [3], not all factors are equally important. Do those takeaways still hold for the datamodels trained in this paper?\n2. In line 408, the authors say that they “replace the All-Data baseline with a Random baseline” due to the scale of OXE. What exactly is the issue due to the scale of OXE? Does the policy underfit the entire data? In which case, what if the policy architecture is scaled up - is retrieval still necessary?\n\n\nReferences: \n\n[1] What Matters in Learning from Large-Scale Datasets for Robot Manipulation, Saxena et al., 2025\n\n[2] Sim-and-Real Co-Training: A Simple Recipe for Vision-Based Robotic Manipulation, Maddukuri et al., 2025\n\n[3] Decomposing the Generalization Gap in Imitation Learning for Visual Robotic Manipulation, Xie et al., 2023"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6OivIXYh42", "forum": "AcTsKglDdh", "replyto": "AcTsKglDdh", "signatures": ["ICLR.cc/2026/Conference/Submission21352/Reviewer_DUws"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21352/Reviewer_DUws"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21352/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762380915727, "cdate": 1762380915727, "tmdate": 1762941715448, "mdate": 1762941715448, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}