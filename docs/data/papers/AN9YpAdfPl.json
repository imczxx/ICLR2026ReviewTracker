{"id": "AN9YpAdfPl", "number": 7944, "cdate": 1758045370193, "mdate": 1759897820612, "content": {"title": "TabImpute: Accurate and Fast Zero-Shot Missing-Data Imputation with a Pre-Trained Transformer", "abstract": "Missing data is a pervasive problem in tabular settings. Existing solutions range from simple averaging to complex generative adversarial networks, but due to each method’s large variance in performance across real-world domains and time-consuming hyperparameter tuning, no default imputation method exists. Building on TabPFN, a recent tabular foundation model for supervised learning, we propose TabImpute, a pre-trained transformer that delivers accurate and fast zero-shot imputations requiring no fitting or hyperparameter tuning at inference-time. To train and evaluate TabImpute, we introduce (i) an entry-wise featurization for tabular settings, which enables a $100\\times$ speedup over the previous TabPFN imputation method, (ii) a synthetic training data generation pipeline incorporating realistic missingness patterns, and (iii) MissBench, a comprehensive benchmark with $42$ OpenML datasets and $13$ new missingness patterns. MissBench spans domains such as medicine, finance, and engineering, showcasing TabImpute’s robust performance compared to $11$ established imputation methods.", "tldr": "We develop a pre-trained transformer called TabImpute to produce accurate and fast zero-shot imputations for tabular missing data.", "keywords": ["missing data", "matrix completion", "transformer", "tabular"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4e72131913faac05bf56c09b36accafeafa6b32f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes TabImpute, a pre-trained transformer model for zero-shot missing data imputation for tabular datasets. \nTabImpute is based on another method called TabPFN (the first version is published 2022 and the final version with extended experiments is published in nature, 2025). \nTabImpute leverages an entry-wise featurization that enables efficient and parallel imputation, overcoming major speed and scalability barriers of previous transformer-based approaches. The model is trained entirely on synthetically generated tabular data with realistic missingness patterns, including MCAR, MAR, and eleven detailed MNAR scenarios. The pipeline enables strong generalization.\n\nThe paper introduces MissBench, a benchmark suite consisting of 42 publicly available OpenML datasets and 13 missingness mechanisms spanning domains such as medicine, finance, and engineering. TabImpute is shown to outperform 11 well-established imputation methods and recent foundation models in terms of accuracy and runtime, especially for high missingness rates. The final method adaptively ensembles TabImpute with EWF-TabPFN to leverage complementary strengths, further improving accuracy.​\n\nThe entire framework, including model, training pipeline, and benchmark suite, is open-sourced. TabImpute addresses the key limitations of prior methods (slow tuning, narrow applicability) and provides a fast, accurate, and general-purpose solution for missing-value problems in modern machine learning workflows.​\n\nThe main novelties include 1) entry-wise featurization for tabular imputation, enabling parallel and scalable predictions with transformers.\n2) Synthetic data generation pipeline supporting a wide variety of missingness patterns, especially MNAR. 3) Introduction of MissBench, a comprehensive benchmark for tabular imputation. 4) Adaptive ensemble (TabImpute + EWF-TabPFN) achieving state-of-the-art zero-shot imputation accuracy across datasets and missingness scenarios. 5) Open-source release of code, models, evaluation pipeline, and benchmark."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The method works fast and does not require any extra fitting or hyperparameter tuning, making it efficient for real-world applications.​​\n2. It handles many types of missing data and still gives accurate results across different domains (results include evaluations on tabular datasets of medicine, finance, and engineering).​​\n3. TabImpute was evaluated on a large benchmark (42 real datasets with 13 missingness patterns) and performed better than 11 other known imputation methods.​​\n4. The authors shares their code and models openly, encouraging reproducibility and making it easy for others to build on or apply their work."}, "weaknesses": {"value": "1. It seems that the scalability for large tables is limited. TabImpute’s transformer architecture, combined with the new entry-wise featurization, results in a quadratic time complexity with respect to both rows and columns, effectively squaring the computational cost compared to standard attention. \nWhile the method works well for the relatively small tables in the benchmark (up to hundreds of rows and columns), it will likely struggle with larger, industry-scale datasets (thousands to millions of entries), both in terms of speed and memory.​\n\n2. All experiments and methods focus strictly on numerical tables, ignoring the reality that most tabular datasets in medicine, business, and public policy contain categorical features or a mix of types. Compared to several strong baselines (e.g., MissForest, HyperImpute), which do support mixed types, TabImpute currently cannot be used “as is” on real-world data without preprocessing or architectural changes.​\n\n3. The pre-training of TabImpute uses synthetic data generation based mainly on linear factor models, though it simulates various missingness types. Generalization to datasets whose structure (e.g., highly non-linear interactions or domain-specific distributions) differs from training priors may not be robust. The method’s performance on real, extremely complex medical or financial MNAR cases is not thoroughly validated, so claims of universal generalization remain partly unproven.​\n\n4. The ensemble step that adaptively weights TabImpute and EWF-TabPFN based on error on observed entries, while clever for accuracy, could potentially bias imputations if observed values are not representative, especially in systematic MNAR settings not covered in training.​\n\n5. The paper does not address failure modes or vulnerable cases. For instance the authros could address highly sparse matrices, blocks of missingness, or adversarially masked data where generative pre-trained models may break down.​\n\n6. While TabImpute is described as “fast” and “efficient,” there is no comprehensive analysis of wall-clock time, GPU/CPU requirements in varied environments, or deployment cost compared to industry standards, apart from per-entry runtime benchmarks. For practical adoption, these details are essential.​\n\n7. Removing the attention mask and recasting imputation as entry-wise prediction introduces new statistical dependencies. The paper claims “no data leakage,” but fails to fully analyze potential risks. For example the authors could  analyze using test data to inform train predictions.​"}, "questions": {"value": "1. Considering the quadratic complexity of both attention and entry-wise featurization, can the proposed TabImpute realistically scale to industry datasets with millions of rows or columns? What architectural or algorithmic innovations would be necessary to prevent memory and computation bottlenecks, and can you demonstrate such scaling beyond what is shown in MissBench?\n\n2. How does TabImpute perform on highly non-linear, domain-specific real-world datasets whose data distributions, interactions, or missingness patterns diverge significantly from your synthetic training priors? Can you provide evidence or theory supporting robustness to out-of-distribution missingness in places like healthcare or finance, especially when the linear factor model and MNAR pattern simulations clearly do not match real-world generative processes?\n\n3. TabImpute does not currently support categorical or mixed-type tabular data. What specific obstacles prevent extending your model to these widely-used formats, and how would your training and inference procedures need to change? Can you show that transformer-based imputation can compete with specialized classical methods (such as MissForest or HyperImpute) on mixed-type datasets without extensive feature engineering?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6okcnYAFeC", "forum": "AN9YpAdfPl", "replyto": "AN9YpAdfPl", "signatures": ["ICLR.cc/2026/Conference/Submission7944/Reviewer_V9f3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7944/Reviewer_V9f3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7944/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761646789185, "cdate": 1761646789185, "tmdate": 1762919963383, "mdate": 1762919963383, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces TabImpute, a pre-trained transformer model for zero-shot missing data imputation in tabular datasets, by extending TabPFN with entry-wise featurization (EWF). This enables parallel GPU computation of missing values, achieving major speedup over TabPFN's column-wise approach. The model is trained on 25 million synthetic datasets generated using linear factor models with diverse missingness patterns. The authors also introduce MissBench, a benchmark with 42 OpenML datasets and 13 missingness patterns. Finally, they ensemble TabImpute and a pre-trained TabPFN to introduce TabImpute+."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The entry-wise featurization cleverly recasts PFNs for cell-level imputation, enabling efficient parallel computation. \n\n2. The softmax-based reweighing scheme that dynamically adjusts missingness pattern proportions during training is principled and seems effective. Additionally, the closed-form solution for the adaptive ensembling is theoretically motivated and quite interesting.\n\n3. The clearest contribution of this work is the MissBench dataset. The diversity of 13 MNAR patterns is particularly valuable given their prevalence in real-world applications. The limited set of standard evaluation conditions is a key limitation in current imputation literature."}, "weaknesses": {"value": "1. The 13 MNAR patterns, while extensive, lack theoretical grounding. Notably, sequential missingness patterns (Seq-MNAR) are inappropriate for tabular data since columns are permutation-invariant. Such patterns only make sense for repeated measures of the same feature over time, which doesn't appear to be the case here. More critically, the paper fails to reference prior work on \"structured missingness\" [1,2], which defines missingness mechanisms orthogonal and complementary to the Rubin (1976) framework (MCAR/MAR/MNAR). Many of the paper's patterns (Block-MNAR, Panel-MNAR, Cluster-MNAR) align with existing structured missingness taxonomies but are presented without proper attribution. The authors should either: (a) adopt established structured missingness frameworks and clearly map their patterns to these taxonomies, or (b) provide stronger justification for why their patterns represent realistic real-world scenarios beyond the brief qualitative descriptions provided. This would strengthen the paper's foundation and clarify its relationship to prior work.\n\n2. The claim that TabImpute+ achieves state-of-the-art performance is inadequately supported due to missing comparisons with recent imputation methods [3,4,5]. This omission is particularly concerning because [3] and [5] are transformer-based approaches that would provide fairer architectural comparisons. Currently, all baselines are non-transformer methods (random forests, GANs, matrix factorization, etc.). The authors should include these baselines or explicitly justify their exclusion to substantiate their state-of-the-art claims.\n\n3. The results in Table 2 raise concerns about TabImpute+'s practical utility. For most individual patterns, either TabImpute or EWF-TabPFN alone achieves top performance. The \"Overall\" metric is misleadingly close since it's normalized over only these 3 methods, obscuring the fact that the ensemble provides minimal added value (also not statistically significant). More critically, TabImpute exhibits catastrophic failures on several patterns (Censoring-MNAR, Self-Masking-MNAR), while EWF-TabPFN maintains consistently reasonable performance across all patterns. For practitioners prioritizing robustness over marginal average gains, EWF-TabPFN appears to be the safer choice. \n\n4. The O(n^2m + nm^2) complexity due to entry-wise featurization is prohibitive. The authors acknowledge this but provide no concrete solutions beyond \"imputing in chunks\". This fundamentally limits its utility to real-world imputation challenges (like biobanks).\n\n\n#### References\n[1] A Complete Characterization of Structured Missingness (2023)\n\n[2] Learning from data with structured missingness (Nat. Mech. Int., 2023)\n\n[3] CACTI: Leveraging Copy Masking and Contextual Information to Improve Tabular Data Imputation (ICML 2025)\n\n[4] DiffPuter: Empowering Diffusion Models for Missing Data Imputation (ICLR 2025)\n\n[5] ReMasker: Imputing Tabular Data with Masked Autoencoding (ICLR 2024)"}, "questions": {"value": "1. SDs are provided, but no significance testing is performed. Are TabImpute+'s improvements over HyperImpute/MissForest statistically significant? Also how were the SDs calculated for the normalized score? The cross method re-normizaiation is effected by the variance of the performance of each method.\n\n2. What inductive biases allow a model trained on LFMs to work on non-linear real-world data? Is the transformer learning general imputation strategies, or is most of the performance on  non-linear settings originating from EWF-TabPFN?\n\n3. Can the authors explain why TabImpute+ underperforms on Censoring-MNAR despite training including conceptually similar patterns?\n\n4. Authors state they tried “nonlinear factor models and structural causal models (SCM) similar to the ones used in TabPFN”. However Table 5 does not include results for this? Am I missing something? could the authors make it clear which TabImpute models used SCMs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8hP3MeGvSp", "forum": "AN9YpAdfPl", "replyto": "AN9YpAdfPl", "signatures": ["ICLR.cc/2026/Conference/Submission7944/Reviewer_HSxa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7944/Reviewer_HSxa"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7944/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761858157536, "cdate": 1761858157536, "tmdate": 1762919962933, "mdate": 1762919962933, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces TabImpute, a pre-trained Transformer for zero-shot imputation in tabular data, building on TabPFN. It proposes an efficient entry-wise featurization and a synthetic data generation pipeline with realistic missingness patterns. Additionally, it presents MissBench, a benchmark spanning 42 OpenML datasets and 13 missingness scenarios across multiple domains."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The idea of leveraging Prior-Data Fitted Networks (PFNs) for imputation tasks is interesting and opens new directions in amortized inference under missing data.\n\n- The paper centers on the underexplored challenge of MNAR imputation, which is important in real-world tabular applications.\n\n- The use of in-context learning for tabular data continues a promising line of work and may inspire future extensions beyond classification."}, "weaknesses": {"value": "- The methodological contribution is minimal, as the proposed TabImpute appears to be a near-direct adaptation of TabPFN, with only slight modifications to the attention mechanism and task framing.\n\n- The related work section is overstated and omits many relevant deep generative models for tabular imputation, particularly those tailored to MNAR data (e.g., [1–3]). These should be cited and, where possible, used as baselines.\n\n- The paper lacks scientific rigor in some claims, such as criticizing TabPFN's performance on the proposed benchmark without sufficient grounded analysis or discussion of why it fails.\n\n- Key technical details are missing, especially in the Introduction. The exposition prioritizes benchmark specifications over a clear and detailed presentation of the model itself.\n\n- Experimental comparisons are limited to only a few methods and primarily on the authors' own benchmark, making it difficult to assess broader performance. While more baselines appear in Figure 1, there are no implementation details, and surprisingly poor performance is reported for some models without explanation. In fact, some claims about baseline limitations (e.g., lack of GPU support for GAIN, HyperImpute, and MIWAE) are factually incorrect and should be corrected."}, "questions": {"value": "I have no further questions except for the points mentioned above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "EEvjknprZk", "forum": "AN9YpAdfPl", "replyto": "AN9YpAdfPl", "signatures": ["ICLR.cc/2026/Conference/Submission7944/Reviewer_uvPA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7944/Reviewer_uvPA"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7944/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761934644207, "cdate": 1761934644207, "tmdate": 1762919962509, "mdate": 1762919962509, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "TabPFN which is an pretrained model for tabular data prediction. This work seeks to do the same but for imputation. They build upon TabFPN, but propose a faster featurization method with a synthetic data pipeline with different missingness patterns. They show much better performance on many metrics.\n\nFigures 1 and 2 are great, it shows its better than even MissForest, but runtime stays low. Hmm the only thing I dislike is that the y-axis on Figure 1b is log-linear which really distort the actual gap between methods.\nThe figures are really nice.\n\nIt would be great to spend a bit more time explaining the TapPFN baseline arch and data setup.\n\nEntry-wise featurization is a bit of a fancy word to say (i, j, X[i,:], X[:,j]). I'm not sure I understand. (i, j, X[i,:], X[:,j]) has shape 2+n+m and there are m x n of it, so the shape is [2+n+m,m,n]. How is it a matrix? And how is the target Xij*? Because this means the input is much bigger than the output. Can you clarify and maybe explain it a simpler way.\n\n\" We use TabPFN’s base architecture with one modification: removing the attention mask to allow training points to attend to test points. \" This seems very wrong. I don't understand how you can justify this. You can impute train data based on train+test data, there is obvious leakage of the test set. Am I missing something here? Because this seems very wrong.\n\nIts interesting that training on simpler data generation process worked better, this may be because of simplicity inductive bias.\n\nOf course sequential training is worse, it make sense. Its nice to include remarks like this in the paper.\n\nThe ensembling make sense, but can you add a bit of details. Like having a figure showing inference of your method would be great.\n\nTabImpute struggle with many missingness types. I get that TabImpute+ might be better with only the 3 types of missiness, but is it true also for TabImpute? Because it seems to struggle massively at Censoring-MNAR, Polarization-MNAR, Soft-Polarization-MNAR, Panel-MNAR, Col-MAR, Self-Masking-MNAR. In fact how to explain poor performance on Self-Masking-MNAR if its trained on that??? And what do you mean by zero-shot method, its not defined as far as I can tell. Idk why the numbers are different in Table 2, please explain.\n\nEvaluated on 42 datasets is great but they are pretty small. I assume its a limited of the TabPFN line of work since you need to attend through the whole dataset, so thats fine.\n\n\"(ii) enhancing our method to support categorical data\" What do you mean, doesn't your method super categorical data? Are you only using one-hot features?\n\n\nOverall I really like the direction, its interesting and powerful. My big concern is the inclusion of the test set in the imputation self-attention. I really dont't understand how this can be justified. And is it only applied during training or also at evaluation. We need more details on this, does it mean that test points can attend to train post, because that is clearly wrong if thats the case. Training points should be used to produce the imputation of training and test points, test points should be used to produce test point, but test points CANNOT be used to produce train points.\n\nThe only metric is this normalized RMSE, but what about other metrics. Currently it says nothing about diversity of imputations. This is actually quite important in the context of multiple imputations where Rubin showed that you need diversity to get good estimates. And diversity I assume would be affected by your random shuffling and whatnot at inference, it would be good to see. Its okay if there is no diversity, then it become a better MissForest, but we need to know if its diverse or not because Multiple Imputation folks will not use it if its not diverse. I recommend using some of the metrics in Table 3 of https://arxiv.org/abs/2309.09968.\n\nThere are many things that are justified without numbers, it would be great to see an ablation, this would explain why use only the 3 missing patterns instead of all patterns and the removal of the attention mask. Actually, I see that there is some ablation in the appendix, but its missing the removal of the attention mask and it would be great to have more context and explanation about the ablation results.\n\nRight now, I cannot give a good score giving my concern on the self-attention mask, but if its resolved (maybe I understood wrong?), the score would go up. And if the paper was improved a bit (more metrics, especially with diversity in mind, maybe some inference time figure, some cleanup of the text), I would likely increase it even more since its an interesting method."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "See \"Summary\""}, "weaknesses": {"value": "See \"Summary\""}, "questions": {"value": "See \"Summary\""}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Wj00aiP5Me", "forum": "AN9YpAdfPl", "replyto": "AN9YpAdfPl", "signatures": ["ICLR.cc/2026/Conference/Submission7944/Reviewer_EfQp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7944/Reviewer_EfQp"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7944/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762196988236, "cdate": 1762196988236, "tmdate": 1762919961988, "mdate": 1762919961988, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}