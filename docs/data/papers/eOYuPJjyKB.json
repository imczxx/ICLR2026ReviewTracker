{"id": "eOYuPJjyKB", "number": 21753, "cdate": 1758321294334, "mdate": 1759896904904, "content": {"title": "Sequencing the Neurome: Towards Scalable Exact Parameter Reconstruction of Black-Box Neural Networks", "abstract": "Inferring the exact parameters of a neural network with only query access is an NP-Hard problem, with few practical existing algorithms. Solutions would have major implications for security, verification, interpretability, and understanding biological networks. The key challenges are the massive parameter space, and complex non-linear relationships between neurons. We resolve these challenges using two insights. First, we observe that almost all networks used in practice are produced by random initialization and first order optimization, an inductive bias that drastically reduces the practical parameter space. Second, we present a novel query generation algorithm that produces maximally informative samples, letting us untangle the non-linear relationships efficiently. We demonstrate reconstruction of a hidden network containing over 1.5 million parameters, and of one 7 layers deep, the largest and deepest reconstructions to date, with max parameter difference less than 0.0001, and illustrate robustness and scalability across a variety of architectures, datasets, and training procedures.", "tldr": "We present a new, state of the art algorithm for exact recovery of neural network weights", "keywords": ["Deep neural networks", "Interpretability", "Weight Recovery", "Reverse Engineering"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b6fa125c553b54e77fddd4aa46d5938b401392cb.pdf", "supplementary_material": "/attachment/55f1256f8d03324364411ce9608c2b6c16d879e1.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses the problem of exactly reconstructing neural network parameters solely from query access to a trained model. The authors build upon the studentâ€“teacher paradigm and claim to achieve the first-ever exact recovery of full network parameters without additional neurons, recovering models far larger than prior work (up to 1.5M parameters, 7 layers). The key innovations include: (1) Exploiting inductive biases from Glorot initialization and first-order optimization to reduce the search space. (2) Committee Disagreement Sampling, an active query strategy that uses backpropagation to learn inputs maximizing disagreement among candidate networks. The authors evaluate on various architectures (MLPs, CNNs, RNNs) and show substantially improved recovery rates compared to earlier reconstruction and model-extraction approaches. The paper also provides a detailed, albeit heuristic, treatment of network isomorphisms (symmetries) required for evaluation."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* **[S1] Ambitious problem.** The task of full parameter recovery of neural networks has implications for privacy, interpretability, and model security, making the research question highly relevant to the community.\n\n\n* **[S2] Empirical scale and scope.** The experiments convincingly extend reconstruction to larger networks than prior work, indicating strong practical progress.\n\n\n* **[S3] Well-motivated assumptions.** Building on Glorot initialization and gradient-based training reflects common practice and helps constrain the search space effectively.\n\n\n* **[S4] Awareness of symmetry issues.** The discussion of some of the most prominent network isomorphisms (permutations, scaling) shows conceptual care and attention to the identifiability problem - the treatment is however heuristic due to the intractability of the problem."}, "weaknesses": {"value": "* **[W1] Theoretical foundation.** The paper claims its approach is *\"well motivated by theory\"* (line 92) and repeatedly cites work on NTK and lazy vs. rich training. However, this is purely motivational. The paper provides no rigorous theoretical analysis of its own algorithm. There are no convergence guarantees, no sample complexity analysis, and no formal link between the cited theories and why this specific student-teacher disagreement algorithm should converge to the exact parameters. The *Convergence Analysis* in Sec 2.4 is purely descriptive and empirical.\n\n\n* **[W2] Novelty.** The approach largely reuses ideas from query-by-committee (e.g., Seung et al., 1992). Using backpropagation to optimize queries for active learning is also not new. The novelty appears primarily empirical rather than conceptual. The paper needs to do a better job of situating its *Committee Disagreement Sampling* relative to these established ideas and pinpointing its specific, novel contribution.\n\n\n* **[W3] Insufficient methodological exposition.** The paper is difficult to read due to its structure and lack of detail. The main text feels bloated with high-level motivation and citations of known results, while the actual algorithms (e.g. 1 and 2) that form the paper's core contribution are relegated to the appendix and are not discussed in detail. This makes it hard for the reader to grasp the method and follow the exposition.\n\n\n* **[W4] Formatting issues.** Multiple typographical and citation errors, broke table formatting (e.g. Tables 4 and 5 are unreadable) hinder understanding.\n\n* **[W5] Focus on Parameter-Level Recovery:** The paper focuses intensely on recovering exact parameters (modulo isomorphism). However, it doesn't clearly articulate why this is superior to achieving functional equivalence, which is the goal of most model extraction attacks. Is there a reason to care beyond evaluation?"}, "questions": {"value": "Please address the following questions and the above listed weaknesses in the rebuttal. \n\n[Q1] Does the L1-based permutation alignment guarantee correct correspondence (I do not think it does), or might it actually overstate reconstruction accuracy? Taking a Bayesian stance here, the latter would happen with probability one for non-degenerate parameter distributions.\n\n\n[Q2] In what precise way does the proposed method differ from classical query-by-committee and backprop-based query optimization? (Related to [W2])\n\n[Q3] Is functional equivalence as described in Fig. 3 also given for the more complex tasks like CIFAR10? Please relate this also with [W5]."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "E386BJDCb1", "forum": "eOYuPJjyKB", "replyto": "eOYuPJjyKB", "signatures": ["ICLR.cc/2026/Conference/Submission21753/Reviewer_jd5e"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21753/Reviewer_jd5e"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21753/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761056974544, "cdate": 1761056974544, "tmdate": 1762941919671, "mdate": 1762941919671, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper primarily explores how to recover the exact parameters of a neural network from query access. This problem is considered NP-hard but is crucial for areas such as security, interpretability, and understanding biological networks. The paper simplifies the problem by focusing on networks that are randomly initialized and trained through gradient optimization, effectively restricting the practical parameter space. It introduces a novel query generation algorithm, Committee Disagreement Sampling, aimed at generating maximally informative samples to efficiently untangle the complex nonlinear relationships in neural networks. The authors demonstrate the reconstruction of a hidden network with over 1.5 million parameters and a 7-layer deep network, with a maximum parameter difference of less than 0.0001. The paper shows that the method exhibits strong robustness in small-scale experiments across various architectures, datasets, and training procedures, outperforming existing methods in sample efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The problem addressed in this paper is of significant value, as it tackles the challenging task of recovering the parameters of a network through black-box optimization.\n- The paper introduces an  approach that leverages query-based methods and incorporates practical constraints from modern training processes to reconstruct the exact parameters of deep neural networks.\n- This method has been validated on networks with over 1.5 million parameters and up to 7 layers deep. It has been tested across a variety of network architectures, datasets, and optimization procedures."}, "weaknesses": {"value": "- The overall writing and formatting of the paper are quite poor, significantly impacting readability. There are numerous grammatical and typographical errors, making the paper appear as an unpolished draft (e.g. Table 4 and Table 5 ). The font size of Figure 2 is too small to be legible.\n- The authors should discuss in more detail the significant differences between their approach and classic \"distillation\" techniques in LLMs.\n- The evaluation metrics presented in the paper are difficult to understand. For example, in Table 1, the number of sampled samples varies, and the accuracy appears to be slightly worse compared to previous work. It is hard to grasp the superiority of the proposed method based on these metrics.\n- While the experiments are conducted across various architectures, the datasets and models used are still relatively simple. I remain concerned about the scalability of the method, especially as it seems difficult to directly extend to current large-scale language models.\n- The method assumes that the network architecture and various activation functions are known, but in practice, many hyperparameters are often unknown, which could limit its application in cases where the architecture is unknown or highly opaque."}, "questions": {"value": "1. Could the authors elaborate on how their method differs from traditional knowledge distillation techniques, particularly in the context of large models with potentially billions of parameters? What unique advantages does their approach offer in such scenarios?\n2. What is the precise definition of the error $\\epsilon$ used in the paper? Given the issue of isomorphism, is it both sufficient and necessary to present the reconstruction error as the primary evaluation metric?\n3. The evaluation metrics presented in the paper, particularly in Table 1, are somewhat difficult to interpret. The number of sampled queries varies, and the accuracy appears slightly worse compared to previous work. Can the authors clarify how the evaluation was conducted and explain why their method is considered superior, despite these discrepancies in sample size and accuracy? Would it be possible to provide a more detailed analysis or direct comparisons to prior work?\n4. Could the authors offer insights into how the method might be adapted or scaled for larger models, particularly in the context of current large-scale language neural networks?\n5. How does the method perform when the architecture of the target network is unknown or highly opaque? Are there modifications or adaptations that could make the method more applicable to black-box models where the architecture is not provided?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FqPExsGbvN", "forum": "eOYuPJjyKB", "replyto": "eOYuPJjyKB", "signatures": ["ICLR.cc/2026/Conference/Submission21753/Reviewer_HGGv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21753/Reviewer_HGGv"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21753/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761730945375, "cdate": 1761730945375, "tmdate": 1762941919385, "mdate": 1762941919385, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper considers the problem of exact model reconstruction in a gray-box manner, assuming the knowledge of: (1) architecture, (2) data normalization, (3) the Initialization scheme of the trained network, and (4) full logit access. The proposed idea is to use a \"committee\" of $p$ student networks who have exactly the same architecture and initialization scheme as the reconstructed. At each time, the"}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The setting of this paper and their proposed method is easy to follow."}, "weaknesses": {"value": "First things first, I admit that I am not an expert in this direction, so my review might be biased. However, I have many concerns with this paper as follows:\n\n### Presentation weaknesses\n\n1. Underwhelming presentation: I find the writing of this paper to be underwhelming, if not poor. For example:\n\n  - Introduction: the authors should spend a separate paragraph, if not a section, elaborating their contribution. Besides, the storytelling in the introduction is also not well-written. \n  - Results: right after the introduction, the authors go directly to demonstrating this result. This is a very weird flow, at least for me. The authors should at least: (1) have a formal problem setting, (2) state the assumption clearly and concisely, and compare with prior works about the setting. Then the author can go to their methodology, and then the results. \n  - Methods: the method section is even mentioned AFTER the results section, making it very hard to keep track. I need to know what the authors are trying to do, what new insight/methodology the authors are proposing, before even looking at the results.\n\n2. Many critical typos: apart from the presentation, I do not think that the author did a good job of screening the typos of this paper. For example, Tables 4 and 5 have a clear format error, though they are critical components of this paper. \n\n### Technical weaknesses\n1. Missing key components: the number of population $p$, which is a key component of their method, is mentioned NOWHERE in the paper. Without such information, it is very hard to evaluate the computational efficiency of this method. Besides, to make the sampling scheme of the proposed method to work reasonably, $p$ should be reasonably high. However, I assume that it would make the method very computationally inefficient, increasing at least $p$ times compared to using a single student.\n\n2. The experiments are small-scale.\n\n3. The results are not promising:\n  - High error with even small models: even for small models, the error rate can be of 430,200% (for CNN) and 517,200% (for RNN) (see Tables 4, 5). This is very upsetting. \n  - Highly unreliable: In the Limitation, the authors mentioned that the success rate is about two-thirds of the time. This is another critical weakness that cannot be treated as a \"normal limitation\". At least, the authors have to have some scheme to detect failure WITHOUT accessing the true model. If not, the proposed method will be very weak, and the reported results will also be unreliable. \n\nThese are the most critical issues of this paper that I can detect. Due to the reasons above, I unfortunately have to recommend a strong rejection of this draft. I recommend that the authors make multiple passes through this draft, make it at least look reasonable, and send it to their colleagues for cross-reviewing before even trying to submit this draft to any other conference."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jdldX37Sgk", "forum": "eOYuPJjyKB", "replyto": "eOYuPJjyKB", "signatures": ["ICLR.cc/2026/Conference/Submission21753/Reviewer_hac2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21753/Reviewer_hac2"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21753/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761864834406, "cdate": 1761864834406, "tmdate": 1762941919092, "mdate": 1762941919092, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a method for exactly reconstructing the full parameters of a neural network, given its architecture, initialization and optimization method, using only query access. Given these priors, the method assumes that the real weights lie in a smaller subspace of rand-init & sgd-trained networks, which can be recovered through gradient-based methods.\nReconstruction works by training a student network that attempts to match the teacher's parameters, via samples generated via committee disagreement sampling. Since isomporphisms manifest in the parameter space of neural networks, the authors normalize each layer into a canonical form, accounting for permutation, scaling and polarity symmetry. Evaluations show empirical reconstruction of an order of magnitude larger and deeper architectures (up to 1.6m parameters) compared to prior works."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* The paper sets out to achieve an ambitious goal, that of fully reconstructing model weights, with a solid theoretical motivation.\n* Results presented in the paper showcase impressive reconstruction accuracy compared to the scale of prior art.\n* The committee disagreement sampling method is an elegant method of generating the maximally informative samples for training the student model."}, "weaknesses": {"value": "* The method is claimed to work only 2/3 of the time. How does an adversary know which is the working versions of the reconstruction?\n    - Further exploring the failure modes would help mapping the impact and importance of the method.\n    - Shedding more light in the dynamics of CNN and RNN networks would be a great plus.\n    - Showcasing a proof-of-concept on a transformer architecture would also be important.\n* The method requires significant computation for generating the training queries and results are mainly focused on toy-scale tasks.\n* The results are mainly empirical and lack a formal proof of convergence of identifiability of a solution.\n* The paper could significantly ameliorate its presentation:\n    - Writing could be more standardized, instead of having the bulk of the method in the appendix.\n    - No formal threat model present in the paper.\n    - Figures are currently illegible and could use a better description of their setup.\n    - The paper misses a dedicated section on how to defend against such attacks."}, "questions": {"value": "* Does the method work on dynamic architectures (e.g., MoE models)?\n* Is the reconstruction accuracy bound to the numerical representation of the parameters/activations (see quantization)?"}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety", "Yes, Potentially harmful insights, methodologies and applications"]}, "details_of_ethics_concerns": {"value": "The paper does raise a potential impactful technique of reconstructing model parameters, which can be an attack vector of IP. It fails to describe how it has ensured responsible disclosure and has also failed presenting defense mechanisms against such attacks."}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "PHLkGrvy6j", "forum": "eOYuPJjyKB", "replyto": "eOYuPJjyKB", "signatures": ["ICLR.cc/2026/Conference/Submission21753/Reviewer_UJ7W"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21753/Reviewer_UJ7W"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21753/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761955331564, "cdate": 1761955331564, "tmdate": 1762941918798, "mdate": 1762941918798, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This submission studies exact parameter reconstruction of black box neural networks, assuming unconstrained query access. The proposed solution focuses in limiting the search space of possible reconstructions, taking into consideration inductive biases such as the model initialisation to a known distribution and 1st order optimisation through gradient descent, and introduces a generation algorithm for inference queries that aim to maximise the information extracted from each model invocation."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The claim results indicate that the proposed approach may be able (under given assumptions) to accurately reconstruct the weights of larger models than prior work has explored thus far.\n- Some interesting insights are presented and discussed in the experiments; that can motivate further development of future work."}, "weaknesses": {"value": "- Although pushing the limits of weight reconstruction approaches in terms of scale, the proposed solution seems to remain computationally plausible only on toy-example scaled models. This limits the practical real-world applications of the proposed methodology. \n- It is unclear whether the imposed assumptions on reconstructing randomly initialized models (with a known distribution) that undergone 1st order backprop training, are still applicable / can be relaxed on the most commonly setting of further finetuning models on domain specific data, following pre-training on larger scale datasets. This can severely affect the applicability (and thus impact) of the proposed approach in realistic scenarios. \n- The manuscript does not examine at all the applicability of the proposed approach on Transformer architectures, nor discusses the challenges of this extension.\n- The structure of the manuscript (section structure, content and titles) is quite irregular. e.g. the proposed solution is not clearly described anywhere other than the introduction section and some parts of the Appendix, and related work is mostly discussed in a section named \"methods\"."}, "questions": {"value": "Please consider replying on the comments raised in the weaknesses section above. \n\nMinor comments:\n- Tables 4 and 5 suffer from significant formatting issues. \n- row 111: spacing issue in parenthesis. \n- row 242: consider adding a reference, instead of referring to the method using the author's name directly."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Z6poJkzkBg", "forum": "eOYuPJjyKB", "replyto": "eOYuPJjyKB", "signatures": ["ICLR.cc/2026/Conference/Submission21753/Reviewer_HJTS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21753/Reviewer_HJTS"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission21753/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959955124, "cdate": 1761959955124, "tmdate": 1762941918594, "mdate": 1762941918594, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}