{"id": "PzIc2TxhwN", "number": 18075, "cdate": 1758283542184, "mdate": 1759897134936, "content": {"title": "Seek-CAD: A Self-refined Generative Modeling for 3D Parametric CAD Using Local Inference via DeepSeek", "abstract": "The advent of Computer-Aided Design (CAD) generative modeling will significantly transform the design of industrial products. The recent research endeavor has extended into the realm of Large Language Models (LLMs). In contrast to fine-tuning methods, training-free approaches typically utilize the advanced LLMs, thereby offering enhanced flexibility and efficiency in the development of AI agents for generating CAD parametric models. However, the lack of a mechanism to harness Chain-of-Thought (CoT) limits the potential of LLMs in CAD applications. The Seek-CAD is the pioneer exploration of locally deployed inference LLM DeepSeek-R1 for CAD parametric model generation with a training-free methodology. This study is the investigation to incorporate both visual and CoT feedback within the self-refinement mechanism for generating CAD models. Specifically, the initial generated parametric CAD model is rendered into a sequence of step-wise perspective images, which are subsequently processed by a Vision Language Model (VLM) alongside the corresponding CoTs derived from DeepSeek-R1 to assess the CAD model generation. Then, the feedback is utilized by DeepSeek-R1 to refine the initial generated model for the next round of generation. Moreover, we present an innovative 3D CAD model dataset structured around the SSR (Sketch, Sketch-based feature, and Refinements) triple design paradigm. This dataset encompasses a wide range of CAD commands, thereby aligning effectively with industrial application requirements and proving suitable for the generation of LLMs. Extensive experiments validate the effectiveness of Seek-CAD under various metrics.", "tldr": "", "keywords": ["CAD generative modeling; parametric CAD sequence;"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/064c4843a1fe4734ffaea644452aa849d81e3f0c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces Seek-CAD, a novel framework for generating 3D parametric CAD models. The framework's core features are that it is training-free and locally deployable.\n\nIt uses an open-source LLM  as its core, combining RAG with a novel \"SSR\" design paradigm to generate complex CAD code.\n\nIts core innovation is a self-refinement loop.\n\nExperiments show Seek-CAD exceeds other training-free methods in geometric accuracy and even surpasses the fine-tuned CAD-Llama model."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The framework's key innovation is using a VLM to align the LLM's Chain-of-Thought (CoT) with step-wise visual renderings, thereby validating the design process rather than just the final product.\nDespite being training-free, Seek-CAD surpasses the fully fine-tuned CAD-Llama on key geometric metrics, proving the potential of its \"generate-verify-refine\" agent loop.\nThe system is a practical, self-contained solution, using a locally deployed LLM (DeepSeek-R1) and an essential local RAG corpus instead of relying on expensive, closed-source APIs."}, "weaknesses": {"value": "The entire refinement loop's effectiveness hinges on the VLM's (Gemini-2.0) ability to accurately assess the alignment between the CoT and the step-wise images. The paper admits in its limitations (Sec 5) that VLMs can have biases or misunderstand complex geometry. If the VLM hallucinates or misinterprets (as seen in Fig 4b), it will provide faulty feedback, causing the LLM to make incorrect \"corrections.\"\n\n\nThe \"LLM $\\rightarrow$ Render $\\rightarrow$ VLM $\\rightarrow$ LLM\" loop is computationally slow. More critically, Table 2 shows that going from Round 1 to Round 2 of refinement yields marginal performance gains (e.g., IoGT only 0.72 $\\rightarrow$ 0.73) but causes the code compilation success rate (Pass@2) to drop sharply (from 0.72 to 0.55). This suggests multi-turn refinement may lead the LLM into a state of confusion or over-correction, breaking the code's validity."}, "questions": {"value": "The refinement loop (LLM $\\rightarrow$ VLM $\\rightarrow$ LLM) is expensive in time, and Table 2 shows its success rate (Pass@k) drops significantly with more iterations. Compared to a one-pass, fine-tuned model (CAD-Llama), is Seek-CAD still competitive in terms of actual wall-clock time and API call costs?\n\n\nThe system relies on a VLM (Gemini) as a \"referee\" to validate the LLM's (DeepSeek) CoT. If the VLM and the LLM share the same misunderstanding of the user's prompt (e.g., they both misinterpret the meaning of \"chamfer\"), will the system \"confidently\" refine toward a wrong answer, because the referee (VLM) will incorrectly validate the executor's (LLM) flawed logic?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hJtfePI7dR", "forum": "PzIc2TxhwN", "replyto": "PzIc2TxhwN", "signatures": ["ICLR.cc/2026/Conference/Submission18075/Reviewer_fiYb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18075/Reviewer_fiYb"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18075/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761841779460, "cdate": 1761841779460, "tmdate": 1762927856611, "mdate": 1762927856611, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Seek-CAD, a training-free framework that locally runs DeepSeek-R1-32B-Q4 with RAG over a CAD-code corpus to generate SSR-style CAD programs, then iteratively self-refines them using step-wise visual feedback: rendering intermediate + final shapes and asking a VLM (Gemini-2.0) to judge alignment with the LLM’s CoT, feeding that back for correction."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1- Method novelty in feedback: evaluates intermediate renders + CoT rather than final-image only; ablations show inter-image cues matter.\n\n2- Empirical signal: Seek-CAD beats prior training-free refiners and edges a tuned model on geometric fidelity (CD/HD/IoGT), with qualitative evidence."}, "weaknesses": {"value": "1- VLM Feedback Quality: The authors acknowledge that VLMs struggle with geometric descriptions without domain-specific training (Section 5.5), but this fundamental limitation undermines the core refinement mechanism. No quantitative analysis is provided on how often Gemini-2.0's feedback is actually helpful vs. harmful.\n\n2- Compilation Failure Rate: The Pass@k metric reveals concerning compilation failure rates. Even after 2 refinement rounds, only 55% of generated models compile successfully (Table 2). This significantly limits practical applicability. The paper doesn't adequately address strategies to improve this."}, "questions": {"value": "1- Can you provide analysis on when/why Gemini-2.0 feedback helps vs. hurts?\n\n2- Can you provide failure case analysis beyond the two examples in Figure 4(b)?\n\n3- How does performance vary with CAD model complexity (e.g., number of features)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8lc6lNbRBy", "forum": "PzIc2TxhwN", "replyto": "PzIc2TxhwN", "signatures": ["ICLR.cc/2026/Conference/Submission18075/Reviewer_AAaN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18075/Reviewer_AAaN"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18075/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761873364836, "cdate": 1761873364836, "tmdate": 1762927856181, "mdate": 1762927856181, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents Seek-CAD, a training-free framework for generating 3D parametric CAD models from text. It uses a locally deployed LLM (DeepSeek-R1) to generate code following a novel SSR design paradigm. A key innovation is a self-refinement loop where step-wise renders of the CAD model are evaluated by a VLM (Gemini-2.0) against the LLM's Chain-of-Thought reasoning; the resulting feedback iteratively improves the code. The authors also contribute a new 40k-sample dataset based on the more complex SSR paradigm. Experiments show Seek-CAD outperforms existing methods in geometric fidelity and text alignment."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.The use of step-wise visual renders paired with the LLM's Chain-of-Thought for feedback is new. This provides a richer, more granular signal for refinement than methods using only the final render.\n\n2.The proposed SSR triple and the CapType reference mechanism enables the generation of complex CAD models beyond the limitations of prior \"Sketch-Extrude\" methods."}, "weaknesses": {"value": "1.The paper mentions that models failing to compile are excluded from metric calculation. A more detailed analysis of the reasons for compilation failures would be insightful. \n\n2.While the CapType mechanism is innovative, the description in the appendix mentions that when refinement commands involve primitives not identifiable by CapType, those primitives are simply excluded. How often does this happen in the dataset/generation? Does it lead to models that are missing intended refinements?\n\n3.The RAG corpus has 10,000 samples. Was an ablation study performed on the size of this corpus? Is there a point of diminishing returns, or could a smaller corpus suffice?"}, "questions": {"value": "Beyond compilation failures, what are the most common types of geometric or logical errors that the refinement loop fails to correct?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "j9GVyRyaXn", "forum": "PzIc2TxhwN", "replyto": "PzIc2TxhwN", "signatures": ["ICLR.cc/2026/Conference/Submission18075/Reviewer_vupC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18075/Reviewer_vupC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18075/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761901225532, "cdate": 1761901225532, "tmdate": 1762927855348, "mdate": 1762927855348, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Authors proposed seek-cad, a training free approach for generating CAD code from textural input. It formulate data in a novel SSR template, and use a captype reference to effectively support chamfer and fillet operations on new surfaces introduced by CAD operations. The RAG system is also novel with an additional one round of step-wise visual feedback in the code refinement stage showing to help improve generation quality."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The proposed training-free approach is novel and the first few works that explored this direction. The SSR data format with captype reference is also more general and applicable to real-world scenarios than simple sketch-and-extrude. SVF is also a nice solution for incorporating step-vise visual feedback into the system and enable the model to verify each step in the built process. Evaluation on the new dataset demonstrate the improvement of seek-cad."}, "weaknesses": {"value": "Writing and paper layout can be improved. Figure 1 is too small, and SSR definition is in the later paragraph whereas a lot of reference to it is at the front. Overall, this makes reading the paper difficult than it should be. \n\nEvaluation is done entirely on the authors’ new SSR dataset. There is no comparison to previous methods on existing public CAD data like DeepCAD / Omni-CAD / WHUCAD. Figure 7 and 8 shows their dataset is much more complex than DeepCAD, this raise the concern that metric improvement could come from the 10,000 more complex RAG data, e.g better novelty than other methods.\n\nAuthors did not clearly explain how the test set is different from training set. E.g what kind of deduplication or similarity filter was applied. \n\nAuthors do not provide concrete implementation details for Eq. (1) and Eq. (2) — only high-level descriptions of what those equations represent conceptually. This makes reproducing the work fairly complicated."}, "questions": {"value": "(1) Why not use a single vllm model like Qwen-VL or InternVL. The proposed design using DeepSeek for text and Gemini 2.0 for visual is fairly complicated. Is there a particular reason why authors use this pipeline?\n\n(2) How is the dataset constructed? What method is used to avoid data leaking from training to test set? Does it have the clearance from OnShape to be allowed to be publicly released? \n\n(3) How important is the RAG data? Does the increase in complexity help? \n\n(4) Is it possible to use exsiting public CAD data as the RAG data and see how it compares to baselines? This seems like the fair way to compare without the results been affected by the new dataset. \n\n(5) Please provide implementation details in the paper for reproducible results."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "fkktgBwQb7", "forum": "PzIc2TxhwN", "replyto": "PzIc2TxhwN", "signatures": ["ICLR.cc/2026/Conference/Submission18075/Reviewer_TUi8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18075/Reviewer_TUi8"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18075/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762194550207, "cdate": 1762194550207, "tmdate": 1762927854796, "mdate": 1762927854796, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}