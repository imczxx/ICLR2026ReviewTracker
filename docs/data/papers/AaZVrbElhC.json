{"id": "AaZVrbElhC", "number": 61, "cdate": 1756728348185, "mdate": 1763563167161, "content": {"title": "CaRe-BN: Precise Moving Statistics for Stabilizing Spiking Neural Networks in Reinforcement Learning", "abstract": "Spiking Neural Networks (SNNs) offer low-latency and energy-efficient decision-making on neuromorphic hardware by mimicking the event-driven dynamics of biological neurons.  However, the discrete and non-differentiable nature of spikes leads to unstable gradient propagation in directly trained SNNs, making Batch Normalization (BN) an important component for stabilizing training. In online Reinforcement Learning (RL), imprecise BN statistics hinder exploitation, resulting in slower convergence and suboptimal policies. While Artificial Neural Networks (ANNs) can often omit BN, SNNs critically depend on it, limiting the adoption of SNNs for energy-efficient control on resource-constrained devices. To overcome this, we propose Confidence-adaptive and Re-calibration Batch Normalization (CaRe-BN), which introduces (i) a confidence-guided adaptive update strategy for BN statistics and (ii) a re-calibration mechanism to align distributions. By providing more accurate normalization, CaRe-BN stabilizes SNN optimization without disrupting the RL training process. Importantly, CaRe-BN does not alter inference, thus preserving the energy efficiency of SNNs in deployment. Extensive experiments on both discrete and continuous control benchmarks demonstrate that CaRe-BN improves SNN performance by up to $22.6$% across different spiking neuron models and RL algorithms. Remarkably, SNNs equipped with CaRe-BN even surpass their ANN counterparts by $5.9$%. These results highlight a new direction for BN techniques tailored to RL, paving the way for neuromorphic agents that are both efficient and high-performing.", "tldr": "", "keywords": ["Spiking Neural Networks", "Batch Normalization", "Reinforcement Learning"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b4cee0dce933a504b9f7b0fcd2441a7b662ca239.pdf", "supplementary_material": "/attachment/d24c798f75e7488595b21d7268076fb8c487bb43.zip"}, "replies": [{"content": {"summary": {"value": "This work presents Confidence-adaptive and Re-calibration Batch Normalization (CaRe-BN) to stabilize Spiking Neural Networks (SNNs) in Reinforcement Learning (RL). Addressing imprecise BN statistics in online RL that hinder SNN performance, CaRe-BN integrates a confidence-guided adaptive update for BN statistics and a periodic recalibration mechanism, ensuring accurate normalization without disrupting RL training or compromising SNN energy efficiency at inference. Evaluated on MuJoCo continuous control tasks, it boosts SNN performance by up to 22.6% across neuron models/RL algorithms, even outperforming ANNs by 5.9%, advancing BN techniques for SNN-RL."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "First, it addresses SNN-RL's BN statistic imprecision via dual mechanisms, stabilizing training without disrupting RL processes or losing SNN energy efficiency .\n\nSecond, it shows strong adaptability, boosting SNN performance by up to 22.6% across diverse neuron models and RL algorithms .\n\nThird, it outperforms ANNs by 5.9%, proving SNNs‚Äô potential for efficient, high-performance control ."}, "weaknesses": {"value": "First, it only evaluates on MuJoCo continuous control tasks, lacking tests on more complex or real-world RL scenarios .\n\nSecond, it fails to report comparisons of training time and memory with existing BN methods for SNN-RL .\n\nThird, it doesn‚Äôt explore CaRe-BN‚Äôs performance with more advanced spiking neuron models."}, "questions": {"value": "see Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "zqxFjcy14g", "forum": "AaZVrbElhC", "replyto": "AaZVrbElhC", "signatures": ["ICLR.cc/2026/Conference/Submission61/Reviewer_eBqg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission61/Reviewer_eBqg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission61/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761379551690, "cdate": 1761379551690, "tmdate": 1762915444164, "mdate": 1762915444164, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work presents Confidence-adaptive and Re-calibration Batch Normalization (CaRe-BN) to stabilize Spiking Neural Networks (SNNs) in Reinforcement Learning (RL). Addressing imprecise BN statistics in online RL that hinder SNN performance, CaRe-BN integrates a confidence-guided adaptive update for BN statistics and a periodic recalibration mechanism, ensuring accurate normalization without disrupting RL training or compromising SNN energy efficiency at inference. Evaluated on MuJoCo continuous control tasks, it boosts SNN performance by up to 22.6% across neuron models/RL algorithms, even outperforming ANNs by 5.9%, advancing BN techniques for SNN-RL."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "First, it addresses SNN-RL's BN statistic imprecision via dual mechanisms, stabilizing training without disrupting RL processes or losing SNN energy efficiency .\n\nSecond, it shows strong adaptability, boosting SNN performance by up to 22.6% across diverse neuron models and RL algorithms .\n\nThird, it outperforms ANNs by 5.9%, proving SNNs‚Äô potential for efficient, high-performance control ."}, "weaknesses": {"value": "First, it only evaluates on MuJoCo continuous control tasks, lacking tests on more complex or real-world RL scenarios .\n\nSecond, it fails to report comparisons of training time and memory with existing BN methods for SNN-RL .\n\nThird, it doesn‚Äôt explore CaRe-BN‚Äôs performance with more advanced spiking neuron models."}, "questions": {"value": "see Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "zqxFjcy14g", "forum": "AaZVrbElhC", "replyto": "AaZVrbElhC", "signatures": ["ICLR.cc/2026/Conference/Submission61/Reviewer_eBqg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission61/Reviewer_eBqg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission61/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761379551690, "cdate": 1761379551690, "tmdate": 1763771729191, "mdate": 1763771729191, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper highlights the misalignment between the true and computed activation distributions when batch normalization is applied in spiking neural networks (SNNs). In particular, the work discusses issues with existing batch normalization methods in SNN models that can negatively impact performance in reinforcement learning (RL) tasks.\n\nInspired by the Kalman filter, the authors propose a confidence-guided approach that more accurately estimates batch statistics. They also discuss a recalibration method to align the computed batch statistics with those of the training data.\n\nThe proposed method is evaluated on several RL tasks and compared against multiple baselines from both ANN- and SNN-based RL frameworks. Furthermore, an ablation study is conducted to demonstrate the performance improvements contributed by each individual component of the method."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Most of the paper is easy to follow. \n\nThe problem highlighted is an interesting issue in BN for reinforcement learning. \n\nI believe the discussion of related work is adequate and also provides the necessary background to understand the problem."}, "weaknesses": {"value": "I believe the novel part of the method is the confidence adaptive updation of batch statistics; however, the second part, recalibration, is a modification of the existing method. \n\nA few things are not clear, which are mostly related to the proposed method, which can be found in the questions section."}, "questions": {"value": "Line 204: The authors mention that ‚Äúconventional ANN-based RL algorithms do not employ BN.‚Äù This raises an important question ‚Äî is batch normalization (BN) truly necessary in SNN-based RL frameworks? How does the proposed SNN model perform without BN? A comparison or ablation along these lines would strengthen the justification for including BN in SNNs.\n\n\nLine 233: The authors provide a proof for computing the optimal K value. It appears that \\mathbb{D} is computed recursively. Could the authors please elaborate on this derivation and clarify the recursive relationship involved?\n\n\nThe definition and interpretation of the measure \\mathbb{D} are unclear. Could the authors provide more explanation regarding what \\mathbb{D}  quantifies and how it relates to the overall estimation or confidence process?\n\n\nThe rationale behind approximating \\mathbb{D} as shown in Equation (9) is not clearly justified. Please clarify why this specific approximation is valid and under what assumptions it holds.\n\n\nThe terminology ‚Äúconfidence-based adaptive scheme‚Äù is somewhat confusing. Why is the deviation from the actual value interpreted as confidence? A clearer explanation of how ‚Äúconfidence‚Äù is defined and why it is used in this context would be helpful."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "WJQxJeL7Ot", "forum": "AaZVrbElhC", "replyto": "AaZVrbElhC", "signatures": ["ICLR.cc/2026/Conference/Submission61/Reviewer_EiPv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission61/Reviewer_EiPv"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission61/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761735727284, "cdate": 1761735727284, "tmdate": 1762915444011, "mdate": 1762915444011, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a method to improve the estimation of Batch Normalization (BN) statistics. The authors apply this improved BN to spiking neural networks (SNNs) and report that it outperforms other BN variants on six reinforcement learning (RL) tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is relatively easy to follow.\n\n2. Multiple tasks are evaluated."}, "weaknesses": {"value": "1. The claim that ‚Äúdue to the discrete and non-differentiable nature of spikes, directly trained SNNs rely heavily on BN to stabilize gradient updates‚Äù is misleading. BN is not designed to solve non-differentiability in SNNs; please revise this.\n\n2. It is unclear whether the contribution is primarily for ANNs or SNNs. Figure 1 suggests general applicability to ANNs, yet experiments are focusing on SNNs‚Äîplease clarify the intended scope and update the paper.\n\n3. Section 5.2 / Figure 3: The evidence in Figure 3 appears insufficient to conclude that the method yields more precise BN statistics, and contributes to better reward. We can only observe that CaRe-BN gets obviously higher expected rewards on three tasks out of five. It is unknown what is the root cause of such observation. \n\n4. How many time steps are used in the SNNs? How sensitive is performance to this hyperparameter, and what justifies the chosen value to be used in the baseline setting? Also, ablation study on the time step should be provided."}, "questions": {"value": "1. Figure 1: What does the ‚Äúupdate step‚Äù represent‚Äîtraining parameter updates or an SNN inference time step?\n\n2. I could not find details of the network architectures used. Please describe the models (layers, widths, neuron types, readouts, etc.).\n\n3. How are SNN time steps integrated with the RL policy? Do you aggregate/compress time steps to produce the actor/critic outputs? Which components are SNNs and which components are not?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1iHKVrmaqI", "forum": "AaZVrbElhC", "replyto": "AaZVrbElhC", "signatures": ["ICLR.cc/2026/Conference/Submission61/Reviewer_Yg5y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission61/Reviewer_Yg5y"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission61/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761823889073, "cdate": 1761823889073, "tmdate": 1762915443881, "mdate": 1762915443881, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a method to improve the estimation of Batch Normalization (BN) statistics. The authors apply this improved BN to spiking neural networks (SNNs) and report that it outperforms other BN variants on six reinforcement learning (RL) tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is relatively easy to follow.\n\n2. Multiple tasks are evaluated."}, "weaknesses": {"value": "1. The claim that ‚Äúdue to the discrete and non-differentiable nature of spikes, directly trained SNNs rely heavily on BN to stabilize gradient updates‚Äù is misleading. BN is not designed to solve non-differentiability in SNNs; please revise this.\n\n2. It is unclear whether the contribution is primarily for ANNs or SNNs. Figure 1 suggests general applicability to ANNs, yet experiments are focusing on SNNs‚Äîplease clarify the intended scope and update the paper.\n\n3. Section 5.2 / Figure 3: The evidence in Figure 3 appears insufficient to conclude that the method yields more precise BN statistics, and contributes to better reward. We can only observe that CaRe-BN gets obviously higher expected rewards on three tasks out of five. It is unknown what is the root cause of such observation. \n\n4. How many time steps are used in the SNNs? How sensitive is performance to this hyperparameter, and what justifies the chosen value to be used in the baseline setting? Also, ablation study on the time step should be provided."}, "questions": {"value": "1. Figure 1: What does the ‚Äúupdate step‚Äù represent‚Äîtraining parameter updates or an SNN inference time step?\n\n2. I could not find details of the network architectures used. Please describe the models (layers, widths, neuron types, readouts, etc.).\n\n3. How are SNN time steps integrated with the RL policy? Do you aggregate/compress time steps to produce the actor/critic outputs? Which components are SNNs and which components are not?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1iHKVrmaqI", "forum": "AaZVrbElhC", "replyto": "AaZVrbElhC", "signatures": ["ICLR.cc/2026/Conference/Submission61/Reviewer_Yg5y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission61/Reviewer_Yg5y"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission61/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761823889073, "cdate": 1761823889073, "tmdate": 1763720278297, "mdate": 1763720278297, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper targets a practical instability in online RL with SNNs: BatchNorm (BN) statistics are hard to estimate under non-stationary data and replay, leading to train‚Äìinference mismatch and noisy updates. It proposes CaRe-BN, a two-part BN strategy: (i) Confidence-adaptive BN (Ca-BN), which linearly fuses the previous moving estimate and the current mini-batch estimate using variance-based gains (a Kalman-style, minimum-MSE update under stated assumptions); and (ii) Re-calibration (Re-BN), which periodically re-estimates inference statistics from larger replay samples to correct accumulated drift. CaRe-BN is drop-in and leaves the inference path unchanged. Integrated with TD3/DDPG and LIF/CLIF neurons, experiments on MuJoCo report consistent gains and, on average, SNN+CaRe-BN outperforming a vanilla ANN-TD3 baseline. The paper also argues that ‚Äúmore precise BN statistics‚Äù improve exploration quality."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear problem framing with a simple, principled fix. The paper isolates BN statistic mismatch as a key bottleneck in SNN-RL and proposes a plug-and-play estimator with an intuitive confidence-weighted fusion + periodic re-calibration backed by a tractable derivation.\n\n2. Consistent empirical gains with informative ablations. Across several MuJoCo tasks and spiking neuron types, CaRe-BN improves stability/returns, and ablations suggest Ca-BN and Re-BN are complementary, supporting the design rationale.\n\n3. Practical applicability and minimal engineering overhead. The method does not alter the inference graph, is easy to integrate into standard actor‚Äìcritic pipelines, and is plausibly extensible beyond SNNs to other online/temporal settings where BN statistics drift."}, "weaknesses": {"value": "1. Theory‚Äìdata distribution mismatch in Theorem 1 (target inconsistency between moving BN and batch BN)\nThe theorem assumes that the ‚Äúmoving/prior‚Äù BN estimator and the ‚Äúmini-batch/observation‚Äù BN estimator are unbiased estimates of the same target distribution with correctly specified variances. In online RL with replay, this assumption is typically violated: the moving BN statistics track the current inference distribution, while the batch BN statistics are computed from a replay mixture of (often older) policies, with temporal correlation and potentially heavy-tailed activations. Consequently, the two estimators do not share the same target, unbiasedness/i.i.d. fail, and the linear fusion with gain ùêæ is not guaranteed to be valid or optimal (and may introduce bias). \n\n2. Limited experimental scope beyond MuJoCo \nAlthough the paper compares against common SNN normalization baselines (e.g., BNTT), the evaluation remains restricted to MuJoCo continuous control. To substantiate generality and the claimed benefits under stronger non-stationarity, the method should also be tested on exploration-hard and vision-based benchmarks (e.g., Atari).\n\n3. Exploration claim lacks causal evidence and proper metrics\nSection 5.2 infers ‚Äúmore precise BN statistics ‚Üí better exploration‚Äù primarily from an ‚Äúexploration return‚Äù curve without defining the metric, controlling confounders (action-noise schedule, value-estimation bias, policy smoothness), or reporting standard exploration measures (state-coverage/visitation, occupancy entropy, trajectory diversity, feature-space coverage). No experiments are provided on exploration-hard tasks or against classic intrinsic-motivation baselines (ICM, RND, NGU/Plan2Explore, count-based variants). The authors need to further analyze the reason why the proposed method can improve the efficiency of exploration. \n\n4. Unestablished advantage over strong ANN-RL and unmeasured energy claims\nThe only ANN comparison uses a vanilla ANN-TD3 (in the appendix). Modern, stronger ANN-RL baselines (e.g., SAC; TD3/SAC with LN/GN/RMSNorm or Batch Renorm/AdaBN; distributional critics; entropy/parameter-noise regularization) are not evaluated, so superiority over ANN remains unproven. Moreover, the touted energy advantage of SNNs is theoretical and specific to neuromorphic hardware; no deployment-phase energy/latency measurements (or credible proxies) are reported, nor is training vs. inference cost disentangled. Open discussion: beyond theoretical energy efficiency on neuromorphic hardware, what concrete advantages does SNN + CaRe-BN have over strong ANN-RL methods (e.g., sample efficiency under non-stationarity, stability under distribution shifts, low-latency control, small-batch robustness), and can the authors provide controlled evidence for them?"}, "questions": {"value": "1. Theory & Theorem 1 assumptions (target inconsistency and variance modeling).\nCould you formally define the target distribution for BN statistics in online RL and quantify the mismatch between moving BN (inference) and batch BN (replay) (e.g., TV/Wasserstein distance over activations)? Please provide bias/variance bounds for your fused estimator under distribution shift, report effective sample size N_\"eff\" with autocorrelation estimates for replayed batches, and clarify how you separate process noise vs. observation noise when computing the confidence gains (consider an adaptive Kalman/EM treatment instead of a single residual EMA).\n2.‚ÄúBetter exploration‚Äù claim: metrics, confounders, and causal evidence.\nWhat is the exact definition of exploration return? To establish causality, could you (i) align random seeds and action-noise schedules, (ii) report standard exploration metrics‚Äîstate coverage/visitation counts (or pseudo-counts), occupancy entropy, trajectory diversity, feature-space coverage, and (iii) add Actor-only vs. Critic-only CaRe-BN ablations and noise-aligned runs? Please also include tests on exploration-hard benchmarks (e.g., Atari) and comparisons to intrinsic-motivation baselines (ICM, RND).\n3.External validity beyond MuJoCo and advantage over strong ANN-RL.\nBeyond MuJoCo, can you evaluate on vision-based and non-stationary settings (context/reward switches, parameter drift) and compare against stronger ANN baselines (e.g., SAC; TD3/SAC with LN/GN/RMSNorm or Batch Renorm/AdaBN; distributional critics; entropy/parameter-noise regularization)? If the paper claims energy advantages, please report deployment-phase energy/latency (or credible proxies/ simulation power consumption estimation) and disentangle training vs. inference costs; otherwise, consider narrowing the energy-efficiency claims."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "uoJucUYcdI", "forum": "AaZVrbElhC", "replyto": "AaZVrbElhC", "signatures": ["ICLR.cc/2026/Conference/Submission61/Reviewer_gu7R"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission61/Reviewer_gu7R"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission61/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761975330645, "cdate": 1761975330645, "tmdate": 1762915443775, "mdate": 1762915443775, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}