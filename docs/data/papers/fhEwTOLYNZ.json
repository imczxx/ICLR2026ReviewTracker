{"id": "fhEwTOLYNZ", "number": 12601, "cdate": 1758208892132, "mdate": 1763754843756, "content": {"title": "Designing Affine-Invariant Neural Networks for Photometric Corruption Robustness and Generalization", "abstract": "Standard Convolutional Neural Networks are notoriously sensitive to photometric variations, a critical flaw that data augmentation only partially mitigates without offering formal guarantees. We introduce the *Scale-Equivariant Shift-Invariant* (*SEqSI*) model, a novel architecture that achieves intensity scale equivariance and intensity shift invariance by design, enabling full invariance to global intensity affine transformations with appropriate post-processing. By strategically prepending a single shift-invariant layer to a scale-equivariant backbone, *SEqSI* provides these formal guarantees while remaining fully compatible with common components like ReLU. We benchmark *SEqSI* against *Standard*, *Scale-Equivariant* (*SEq*), and *Affine-Equivariant* (*AffEq*) models on 2D and 3D image-classification and object-localization tasks. Our experiments demonstrate that *SEqSI* architectural properties provide certified robustness to affine intensity transformations and enhances generalization across non-affine corruptions and domain shifts in challenging real-world applications like biological image analysis. This work establishes *SEqSI* as a practical and principled approach for building photometrically robust models without major trade-offs.", "tldr": "Scale-Equivariant & Shift-Invariant NN rendered Affine invariant for application to image classification and object localization", "keywords": ["Computer Vision", "Robust neural network", "invariance", "equivariance", "biological imaging", "microscopy", "classification", "object localization"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a59b100eab4aa259bd0f94b1cbd8cc50475b4790.pdf", "supplementary_material": "/attachment/8efc0e8eed73f623d27c314e83749ac15cc84336.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces SEqSI, a convolutional network that guarantees invariance to global shifts and equivariance to global scales by design. The proposed SEqSI block ensures equivariance to scale and invariance to shifts by constraining the weights of the kernel to be zero-sum in the first block. Equivariance to scale is maintained through the rest of the network via bias-free networks. Notably, the network is significantly less constrained compared to [Herbreteau, 2023] by only requiring weight constraint at the first layer, instead of throughout the network. This yields a network that is significantly more efficient in terms of training, inference, and memory complexity while maintaining the core functionality and achieving on par or better performance. Furthermore, the paper introduces pipeline to extend the affine-equivariance to thresholding tasks such as object localization. This is achieved by replacing the conventional sigmoidal thresholding with a novel thresholding based on the standard deviation of the entire map, which is provably equivariance, as well as a novel Z-MSE loss function.\n\nOn classification tasks, SEqSI is shown to have better performance than baseline models (SEq, AffEq, etc) when no data augmentation is available and performance on par with baselines under augmentation. SEqSI also achieves strong performance to non-affine transformations that it is not specifically designed for, showcasing flexibility. These result showcases the benefits of designing for invariance and equivariance in a convolutional network. \n\nOn object localization tasks SEqSi significantly outperforms baseline methods, including a straight sweep for affine-transformation, both under and without augmentation. It achieves strong performance as well for non-affine transformations. This can be attributed to its novel thresholding scheme that preserves equivariance and invariance throughout the entire transformation.\n\nOverall SEqSI represents an elegant solution to a problem with clear motivations and practical applications, such as biomedical imaging. My initial recommendation is a 6 (weak accept) which should be easily increased to an 8 (strong accept) with a few clarifications from the authors (please see weaknesses and questions section)."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The paper is well motivated and provides an elegant solution.\n* SEqSI is provably equivariant to scale and invariant to shift. Furthermore, SEqSI achieves this with significantly less constraint than baseline line methods.\n* SEqSI introduces a pipeline and loss function that extends equivariance to thresholding tasks, enabling wider application to tasks such as object localization and binary segmentation.\n* SEqSI demonstrates strong performance compared to baseline methods on both classification and object localization task, both with and without data augmentation, and under affine and non-affine transformations.\n* SEqSI has computational efficiency significantly better than fully affine-equivariant baselines and on par with standard models without any equivariance and only scale-equivariance models."}, "weaknesses": {"value": "While I believe this is overall a good paper that meets all ICLR standards for acceptance, I do think there are a few weaknesses that I would like the authors to address during rebuttal.\n1. The classification test in Table 3 is done on a relatively small and low resolution dataset (CIFAR-10). It would be more compelling if the authors could also present results on higher resolution (ie Stanford Cars, Oxford Pets, Caltech-101) and larger datasets (ImageNet). I don't think it is reasonable to run all experiments or the ImageNet dataset in the rebuttal time frame. If the authors can showcase results for non-augmented train set under only the four affine transformations for standard, SEqSI, and SEq for datasets such as Oxford Pets, that would convince me the scalability of the model.\n2. I think it would be cool to showcase binary segmentation results on a small toy dataset such as Caltech-101, if time permits.\n3. I am confused as to why Table 4 only includes non-equivariant baselines? While this demonstrates the benefits of equivariance, I don't think that was ever in question. Filling out the additional baselines would serve the paper much better.\n4. I think the authors should spend more time talking about the architectural differences between SEqSI and [Herbreteau, 2023], as they appear very similar on first glance, in terms of what they want to achieve and the ways they go about achieving them."}, "questions": {"value": "1. The authors mentioned that the proposed thresholding scheme can also be extended to tasks such as foreground-background segmentation. Would this hold for tasks requiring additional classes such as semantic segmentation? This may further extend the use case of the proposed method for situations such as autonomous driving where cameras are often subject to significantly interference with light sources such as the sun or metallic reflection.\n2. While not completely related, since 2023 there have been works that deal with perceptual variation in images from the point of view of color equivariance. Specifically [1] first introduced hue-equivariance using Group CNNs [2] by rotating the RGB cube through (1,1,1). [3] achieves this using soft equivariance. [4] extends this idea to cover equivariance to hue, saturation, and luminance. I wonder if it would be worth while to talk about these in related works.\n\n[1] Attila  Lengyel, et al. \"Color Equivariant Convolutional Networks.\" NeurIPS 2023.\\\n[2] Taco Cohen, and Max Welling. \"Group Equivariant Convolutional Networks.\" ICML 2016.\\\n[3] Hyunsu Kim, et al. \"Variational Partial Group Convolutions for Input-Aware Partial Equivariance of Rotations and Color-Shifts.\" ICML 2024.\\\n[3] Yulong  Yang, et al. \"Learning Color Equivariant Representations.\" ICLR 2024"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "c3wAg8EaFd", "forum": "fhEwTOLYNZ", "replyto": "fhEwTOLYNZ", "signatures": ["ICLR.cc/2026/Conference/Submission12601/Reviewer_Ssow"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12601/Reviewer_Ssow"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12601/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761321966967, "cdate": 1761321966967, "tmdate": 1762923450489, "mdate": 1762923450489, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General comment"}, "comment": {"value": "In response to the reviewers' valuable feedback, we have substantially revised the manuscript to clarify key aspects of our contributions. To facilitate the review process, all significant modifications have been highlighted in red. A summary of the major changes is provided below.\n\nIn the Main Text:\n- Experiment 2 (Macromolecule Classification in Cryo-ET): We have included the AffEq and SEq models in our comparison to provide a more comprehensive evaluation.\n- Experiment 3 (Object Localization): We have added a new Figure 4 to empirically demonstrate the superior robustness of SEqSI against spatially varying intensity shifts, a key scenario where standard intensity normalization fails.\n\nIn the Appendix:\n- Supp B.4: Adding of a formal proof for the invariance of Min-Max Normalization.\n- Supp. C.8 & C.9: Adding of a new scalability study on large-scale and more complex datasets (Oxford-IIIT Pets and Stanford Cars)\n- Supp. D.4: Adding of a direct comparison between our architectural properties and intensity normalization pre-processing strategy to highlight the benefits for domain shift robustness.\n- Supp. E.3.2: Adding of a detailed analysis of the differing behaviors between a Standard model with intensity normalization and SEqSI when facing spatially varying intensity shifts, complementing the new Figure 4.\n- Supp. F: Including of a new study demonstrating the robustness of our method for binary segmentation in biological imaging.\n\nA specific response to each reviewer is provided in the following comments."}}, "id": "31vO81npfN", "forum": "fhEwTOLYNZ", "replyto": "fhEwTOLYNZ", "signatures": ["ICLR.cc/2026/Conference/Submission12601/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12601/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12601/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763755153364, "cdate": 1763755153364, "tmdate": 1763755153364, "mdate": 1763755153364, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces SEqSI, a convolutional network that guarantees invariance to global shifts and equivariance to global scales by design. The proposed SEqSI block ensures equivariance to scale and invariance to shifts by constraining the weights of the kernel to be zero-sum in the first block. Equivariance to scale is maintained through the rest of the network via bias-free networks. Notably, the network is significantly less constrained compared to [Herbreteau, 2023] by only requiring weight constraint at the first layer, instead of throughout the network. This yields a network that is significantly more efficient in terms of training, inference, and memory complexity while maintaining the core functionality and achieving on par or better performance. Furthermore, the paper introduces pipeline to extend the affine-equivariance to thresholding tasks such as object localization. This is achieved by replacing the conventional sigmoidal thresholding with a novel thresholding based on the standard deviation of the entire map, which is provably equivariance, as well as a novel Z-MSE loss function.\n\nOn classification tasks, SEqSI is shown to have better performance than baseline models (SEq, AffEq, etc) when no data augmentation is available and performance on par with baselines under augmentation. SEqSI also achieves strong performance to non-affine transformations that it is not specifically designed for, showcasing flexibility. These result showcases the benefits of designing for invariance and equivariance in a convolutional network. \n\nOn object localization tasks SEqSi significantly outperforms baseline methods, including a straight sweep for affine-transformation, both under and without augmentation. It achieves strong performance as well for non-affine transformations. This can be attributed to its novel thresholding scheme that preserves equivariance and invariance throughout the entire transformation.\n\nOverall SEqSI represents an elegant solution to a problem with clear motivations and practical applications, such as biomedical imaging. My initial recommendation is a 6 (weak accept) which should be easily increased to an 8 (strong accept) with a few clarifications from the authors (please see weaknesses and questions section)."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The paper is well motivated and provides an elegant solution.\n* SEqSI is provably equivariant to scale and invariant to shift. Furthermore, SEqSI achieves this with significantly less constraint than baseline line methods.\n* SEqSI introduces a pipeline and loss function that extends equivariance to thresholding tasks, enabling wider application to tasks such as object localization and binary segmentation.\n* SEqSI demonstrates strong performance compared to baseline methods on both classification and object localization task, both with and without data augmentation, and under affine and non-affine transformations.\n* SEqSI has computational efficiency significantly better than fully affine-equivariant baselines and on par with standard models without any equivariance and only scale-equivariance models."}, "weaknesses": {"value": "While I believe this is overall a good paper that meets all ICLR standards for acceptance, I do think there are a few weaknesses that I would like the authors to address during rebuttal.\n1. The classification test in Table 3 is done on a relatively small and low resolution dataset (CIFAR-10). It would be more compelling if the authors could also present results on higher resolution (ie Stanford Cars, Oxford Pets, Caltech-101) and larger datasets (ImageNet). I don't think it is reasonable to run all experiments or the ImageNet dataset in the rebuttal time frame. If the authors can showcase results for non-augmented train set under only the four affine transformations for standard, SEqSI, and SEq for datasets such as Oxford Pets, that would convince me the scalability of the model.\n2. I think it would be cool to showcase binary segmentation results on a small toy dataset such as Caltech-101, if time permits.\n3. I am confused as to why Table 4 only includes non-equivariant baselines? While this demonstrates the benefits of equivariance, I don't think that was ever in question. Filling out the additional baselines would serve the paper much better.\n4. I think the authors should spend more time talking about the architectural differences between SEqSI and [Herbreteau, 2023], as they appear very similar on first glance, in terms of what they want to achieve and the ways they go about achieving them."}, "questions": {"value": "1. The authors mentioned that the proposed thresholding scheme can also be extended to tasks such as foreground-background segmentation. Would this hold for tasks requiring additional classes such as semantic segmentation? This may further extend the use case of the proposed method for situations such as autonomous driving where cameras are often subject to significantly interference with light sources such as the sun or metallic reflection.\n2. While not completely related, since 2023 there have been works that deal with perceptual variation in images from the point of view of color equivariance. Specifically [1] first introduced hue-equivariance using Group CNNs [2] by rotating the RGB cube through (1,1,1). [3] achieves this using soft equivariance. [4] extends this idea to cover equivariance to hue, saturation, and luminance. I wonder if it would be worth while to talk about these in related works.\n\n[1] Attila  Lengyel, et al. \"Color Equivariant Convolutional Networks.\" NeurIPS 2023.\\\n[2] Taco Cohen, and Max Welling. \"Group Equivariant Convolutional Networks.\" ICML 2016.\\\n[3] Hyunsu Kim, et al. \"Variational Partial Group Convolutions for Input-Aware Partial Equivariance of Rotations and Color-Shifts.\" ICML 2024.\\\n[3] Yulong  Yang, et al. \"Learning Color Equivariant Representations.\" ICLR 2024"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "c3wAg8EaFd", "forum": "fhEwTOLYNZ", "replyto": "fhEwTOLYNZ", "signatures": ["ICLR.cc/2026/Conference/Submission12601/Reviewer_Ssow"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12601/Reviewer_Ssow"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12601/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761321966967, "cdate": 1761321966967, "tmdate": 1763756984937, "mdate": 1763756984937, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a neural network architecture intended to be “scale-equivariant and shift-invariant” to photometric corruption, but the equivariance and invariance operate only on global pixel-intensity transformations rather than spatial changes. The method prepends a single convolutional layer with zero-sum weights and uses bias-free layers to enforce these properties, and then applies simple post-processing (e.g., standardization) to obtain affine-invariant predictions. The paper evaluates the approach on CIFAR-10, Cryo-ET classification, and microscopy localization, claiming improved robustness."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is reasonably well written and clearly structured.\n2. The authors conduct a large number of experiments across several tasks and datasets, providing extensive empirical evaluations."}, "weaknesses": {"value": "1. The paper initially gives the impression that it addresses spatial affine transformations, but the invariance is only with respect to global intensity changes. Even spatial affine equivariance is already well studied and not particularly novel; restricting the scope further to global intensity scaling and shifting makes the contribution very limited. These transformations are trivial to handle with standard preprocessing or normalization. Removing biases to enforce scale equivariance, or imposing zero-sum weights in the first layer to enforce shift invariance, is not a substantial architectural idea and does not constitute a meaningful contribution.\n2. Despite the many experiments, the paper does not seem to have compare against simple preprocessing baselines such as per-image normalization or mean subtraction. These standard techniques may provide the same robustness without any architectural modification. Without such comparisons, it is unclear that the proposed method offers any practical advantage. In fact, enforcing zero-sum filters in the initial layer appears effectively equivalent to preprocessing.\n3. Overall, the contribution is very limited. The architectural modification is minimal and conceptually straightforward, and robustness to global intensity transforms can already be achieved with standard pipelines. The work does not demonstrate sufficient novelty or significance."}, "questions": {"value": "Please see the above comments. My primary concern is the significance, novelty, and timeliness of the work. I would be interested to hear how the authors can clarify the architectural novelty (given that it appears to be a trivial modification) in a way that changes my assessment."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lvhQkZkDWS", "forum": "fhEwTOLYNZ", "replyto": "fhEwTOLYNZ", "signatures": ["ICLR.cc/2026/Conference/Submission12601/Reviewer_tYPp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12601/Reviewer_tYPp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12601/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761788803440, "cdate": 1761788803440, "tmdate": 1762923449646, "mdate": 1762923449646, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This is a paper which builds on the concept of scale equivariant (SEq) networks, adding shift invariance (SI). This leads to a network which is equivariant to scale operations on pixels in the image, and invariant to shifts in pixel values. In comparison to existing approaches for full affine equivariance, this approach is faster; centrally because it can leverage standard ReLU activations as opposed to the SortPool activations required for full equivariance.\n\nThe authors also propose an approach to preserve the logit outputs of their networks through various post-processing stages such as the argmax operation and thresholding.\n\nThe authors validate their approach for three tasks including classification and localisation. In all cases, the approach demonstrates strong overall performance combined with robustness both to affine and non-affine corruptions of the images."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well structured. The mathematics are clearly presented and easy to follow. The experiments are generally well motivated to demonstrate the benefits which the authors claim to achieve.\n\nThe results which are presented seem to me to be strong. The authors demonstrate the utility of their approach in a controlled setting (CIFAR-10), a macromolecule classification task and a localisation test. In all cases, the SEqSI framework outperforms performs either competitively or outperforms comparisons without degraded performance in the case of unwarped inputs compared to standard network architectures. \n\nIn particular, experiments where networks are compared with various different transforms at train time, and are evaluated under various shifts at test time, are particularly compelling for this architecture."}, "weaknesses": {"value": "My central reservation about this paper is the magnitude of its technical contribution. In terms of the technical innovative step, it appears to me that the contribution is principally a zero-sum weight in the first layer of the neural network, and a different transformation of output logits to preserve the equivariance/invariance at output.\n\nNonetheless, I would support an acceptance of this paper owing to the results which support the view that the method has clear utility. My view would be strengthened if the authors were able demonstrate the effectiveness of their approach more extensively. While the authors do propose several test settings, and the results appear strong, my concerns are as follows:\n- CIFAR-10 results appear good, and I would particularly credit the wide range of augmentations used within the evaluation framework. However, this dataset is relatively small and not so complicated, and so these results need to be supported by other results in the paper.\n- Macromolecule classification results also appear strong, and this test setting is the most interesting in my view. However, I see that the Affine equivariant and SEq approaches are omitted here, and I cannot find an explanation for this in the paper. I feel that either the inclusion of these baselines, or provision of a reason for their exclusion is essential.\n- The 3D localisation test set is also compelling, and the testing framework is strong here. However, as a synthetic dataset it would be useful to have a real-world comparison. This is presented in the form of the Data Science Bowl set (DSB). But in the main paper the DSB is only mentioned as demonstrating the invariance of the approach, whereas I feel that highlighting the robustness of the method to augmentation (Figure 10) was the most important outcome of this test for supporting the method proposed. I feel that if the DSB dataset is mentioned in the main paper, then the paper would be strengthened by including a table or chart of the main results from that dataset in the main paper (i.e. from Figure 10). Alternatively, I feel that demonstrating utility for a different real-world dataset for another task such as segmentation would strengthen the case for this method significantly.\n\nI also found the presentation of the DSB results in the supplementary results to be confusing in some places. In particular I would highlight that the specification that $d=0$ seems to clash with the definition of TP(d) as \"the number of pairs of centers *less than* d voxels apart\" (emphasis added). I also found the term 'accuracy' in table 16 led me initially to think that this was showing a comparison with ground truth."}, "questions": {"value": "1. In table 5, your SEqSI network outperforms a standard network both in the no augmentation at train/no augmentation at test, and in the affine at train / affine at test setting. Do you have a good heuristic for why this is the case? Is it because of the network's ability to efficiently learn over variations in the train set? It seems to be a curious result to me if the SEqSI approach is missing both layer biases and has a constraint on the first set of weights. \n\n2. In figure 10, the selected values of $\\mu$ and $\\lambda$ are significant in comparison to the range of the original image. As I read it, the chosen value of $\\mu$ would mean there was no overlap between the two distributions in the shift case. Is there a reason that such a significant perturbation was chosen?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yV63kfgJxx", "forum": "fhEwTOLYNZ", "replyto": "fhEwTOLYNZ", "signatures": ["ICLR.cc/2026/Conference/Submission12601/Reviewer_FUb7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12601/Reviewer_FUb7"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12601/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969981857, "cdate": 1761969981857, "tmdate": 1762923449151, "mdate": 1762923449151, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}