{"id": "M14YpuTejd", "number": 6901, "cdate": 1758000991528, "mdate": 1762955579294, "content": {"title": "Understanding the Task and Data Misconceptions in Online Map Based Motion Prediction for Autonomous Driving and a Boundary-Free Baseline", "abstract": "In autonomous driving (AD), online high-definition (HD) map estimation is gaining increasing attention. To examine how online-estimated HD maps impact downstream tasks, the protocol of online mapping based motion prediction emerges. This protocol follows a two-stage training paradigm: online mapping models are firstly trained and then used to output map elements which are fed as inputs for motion prediction models. In this paper, we conduct in-depth study to investigate the challenges and misunderstandings associated with the protocol and propose OMMP-Bench, a well-defined and insightful benchmark of online map based motion prediction. We identify that the current dataset splits are unsuitable for two-stage training, leading to a severe train-validation gap, and thus we design a new data partitioning split. Furthermore, we find that the perception range of map prediction models does not fully meet the requirements of motion prediction, resulting in a lack of map elements for agents far from the ego vehicle. This issue is obscured by incorrect metrics that evaluate only the ego vehicle’s trajectory. We address it by refining the metrics to evaluate all moving vehicles and separately report performance for agents under different distance ranges. Further, to alleviate the issue of missing map elements for faraway agents, we introduce a new baseline that directly uses image features generated by the online mapping model. These features are not constrained by perception range and could supplement environmental information around agents beyond the online map’s coverage. We further explore how different map elements influence motion prediction, as existing online mapping models have different designs of output format.\n\nWe conduct thorough experiments to verify the proposed corrections. We will open source the related code and checkpoints. We hope OMMP-Bench could solve the long-standing mis-usage and misunderstanding of the emerging field and provide insights for further co-development of online mapping and motion prediction models.", "tldr": "", "keywords": ["Motion Prediction"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/94d5f8dbc4d69d58a434a3cc232b5d1f60aba480.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates misconceptions in online map–based motion prediction for autonomous driving, a two-stage paradigm where online mapping models generate HD maps from sensor data, which are then used for motion prediction. The authors identify key flaws in existing setups — inappropriate dataset splits, mismatched perception ranges between mapping and prediction, and non-discriminative metrics — and propose OMMP-Bench, a new benchmark addressing these issues. They also introduce a boundary-free baseline that integrates image features to compensate for missing map elements. Experiments on nuScenes show that their benchmark and baseline mitigate train–val gaps and improve motion prediction, particularly for distant agents."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The author design a new dataset seperation method to alleviate the train-val gap in traditional two stage motion prediction framework: stage-1 train map model on training dataset, and then stage-2 train motion prediction model using the trained map model on the same datasets. The author finds that in stage 2,, the used map model may overfit on training set and gives the motion model perfect map resulst, which maybe leads to bad test results as the map model maybe behave bad on test set. And experiment shows that model trained on new dataset seperation get better results.\n2. This paper is trying to combine some experiment result into the part introducing method, I think this is a good idea for communities like autonomous driving that people care about the results of each design choice. As the reader can immediately see the experiment table after see the design choices proposed by the author."}, "weaknesses": {"value": "Limited Strategic Relevance – The work focuses on refining a modular two-stage pipeline (mapping → prediction) while the field is shifting toward end-to-end autonomous-driving frameworks. Its contribution may have diminishing long-term impact.\n\nOver-emphasis on Perception Range Expansion – The paper prioritizes broader spatial coverage as a performance driver, overlooking the fact that practical systems and human drivers focus on risk-relevant objects rather than exhaustive detection."}, "questions": {"value": "1. In line 321-322, you said that \"To enable those distant agents to obtain environment information, we propose a new baseline in OMMP-Bench to allow all agents to extract features from their corresponding nearby regions of raw image features.\" So, do you use the image produced by camera munted on ego car? If so, those agents far away from the ego seems likely to be obscured by other agents more close to ego car.\n2. In your framework, you found that integrating image feature helps to predict agents far away, do you think \"integrateing image features (maybe from perception module)\" is a kind of design choice of \"end to end\" (instead of set planning as last goal, here motion prediction is the final goal)?\n\n\nTypos:\nAt line 230-231, ignored space after ③"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4XMF3rsnre", "forum": "M14YpuTejd", "replyto": "M14YpuTejd", "signatures": ["ICLR.cc/2026/Conference/Submission6901/Reviewer_uhbr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6901/Reviewer_uhbr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6901/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761841935481, "cdate": 1761841935481, "tmdate": 1762919144460, "mdate": 1762919144460, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "Vo17GMcJJ9", "forum": "M14YpuTejd", "replyto": "M14YpuTejd", "signatures": ["ICLR.cc/2026/Conference/Submission6901/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6901/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762938131081, "cdate": 1762938131081, "tmdate": 1762938131081, "mdate": 1762938131081, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper points out that there exists an hd map construction performance train-val gap in the trajectory prediction task based on online hd map, resulting in the trajectory prediction part being trained on high-quality online hd map but tested on low-quality online hd map. Therefore, nuScenes is divided into three parts: Map train, Motion train, and Motion val to solve this problem."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1.Motivation is clear"}, "weaknesses": {"value": "1.Unfortunately, I do not consider the \"train-val gap\" proposed in this paper to be a problem. In practical commercial applications of autonomous driving, there are usually separate training data for map generation and motion plan, which do not overlap, so this problem does not exist.\n2.The non-overlapping division method of nuScenes proposed in this paper has already been presented in StreamMapNet.\n3.The approach of integrating image features into the trajectory prediction process proposed in this paper is the same as that in ViP3D, where the 3D query in ViP3D includes 2D features from images.\n4.As a submission to ICLR 2026, this paper actually does not discuss any relevant articles published in 2025. I believe the authors have overlooked many of the latest advancements.\n5.Without the open-source nuscenes division of this paper, I cannot even verify the authenticity of the experiments, as the experiments on the baseline methods in this paper are not conducted on the previously published nuscenes division."}, "questions": {"value": "What are the data volumes of different splits between the nuScenes division in this paper and the default nuScenes division?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9iq9lqaTzz", "forum": "M14YpuTejd", "replyto": "M14YpuTejd", "signatures": ["ICLR.cc/2026/Conference/Submission6901/Reviewer_K2Xt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6901/Reviewer_K2Xt"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6901/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761898026702, "cdate": 1761898026702, "tmdate": 1762919143832, "mdate": 1762919143832, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the online map-based motion prediction (OMMP) paradigm and argues that current protocols are flawed due to (1) train–val gaps in dataset splits, (2) spatial range mismatch between online map estimation and motion prediction, and (3) metrics that overemphasize trivial ego/static agents. The authors propose OMMP-Bench, a benchmark with spatially disjoint splits and evaluation focused on non-ego moving agents, and introduce a boundary-free baseline that supplements map features with deformable-attention image features to provide context for agents outside the map coverage range. Experiments across multiple mapping and prediction models show that the revised protocol yields more discriminative evaluations and that the baseline improves far-agent accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Clearly identifies and empirically demonstrates key issues in existing OMMP evaluation setups.\n- Provides a benchmark with improved data splits and metrics that better reflect the intended prediction task.\n- Introduces a simple and practical baseline that addresses the map coverage mismatch and yields consistent improvements for far-away agents.\n- Conducts comprehensive evaluations across multiple combinations of mapping and prediction models."}, "weaknesses": {"value": "- The primary contribution is benchmark and protocol correction, with limited methodological novelty.\n- The boundary-free baseline is incremental, given that deformable attention feature aggregation is already widely used in recent end-to-end forecasting and driving frameworks (UniAD, SparseDrive).\n- Limited discussion on how OMMP-Bench insights transfer to end-to-end pipelines where mapping and prediction are co-trained.\n- All experiments rely on ground-truth agent trajectories. Robustness to upstream detection/tracking noise is not evaluated, which limits conclusions about real-world deployment."}, "questions": {"value": "- How sensitive are results to the specific geographic split design?\n- How does performance compare if deformable-attention image features are used for all agents (i.e., map-free baseline)? \n- Does the improved data split also benefit end-to-end visual forecasting pipelines (e.g., UniAD, SparseDrive)? \n- What is the runtime and memory overhead of the boundary-free baseline and how does this compare to previous approaches?\n- How robust are the evaluated methods to noise in agent positions and histories?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UJV6sdG1qS", "forum": "M14YpuTejd", "replyto": "M14YpuTejd", "signatures": ["ICLR.cc/2026/Conference/Submission6901/Reviewer_NpAT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6901/Reviewer_NpAT"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6901/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762317536654, "cdate": 1762317536654, "tmdate": 1762919143074, "mdate": 1762919143074, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}