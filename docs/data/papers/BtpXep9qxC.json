{"id": "BtpXep9qxC", "number": 10711, "cdate": 1758180143038, "mdate": 1763691263998, "content": {"title": "Learning Locally, Revising Globally: Global Reviser for Federated Learning with Noisy Labels", "abstract": "In pursuit of data privacy, federated learning (FL) collaboratively trains a global model by aggregating local models learned from decentralized data. However, FL heavily depends on high-quality labels, which are often impractical in the real world, leading to the federated label-noise (F-LN) problem. Unlike traditional noisy labels, F-LN problem is exacerbated by the inherent heterogeneity of FL, where clients experience varying levels and types of label errors. In this study, we observe that the global model of FL exhibits slow memorization of noisy labels, suggesting its ability to maintain reliable predictions and robust representations in FL. Based on this insight, we propose a novel method termed Global Reviser for Federated Learning with Noisy Labels (FedGR) to improve the robustness of FL against F-LN problem. Specifically, FedGR first leverages the label-noise-robust characteristics of the global model to filter and refine the noisy labels on each client using the sieving-and-refining module. Then, it regularizes local model training with the assistance of the global model through following two modules: the globally revised exponential moving average (EMA) distillation module and the global representation regularization module. Extensive experiments on three widely used F-LN benchmarks demonstrate the superior performance of FedGR, outperforming seven state-of-the-art baselines even in complicated label-noise and data heterogeneity. The code will be released upon acceptance.", "tldr": "This study firstly observes an unrecognized phenomenon that the global model of FL exhibits slow memorization of noisy labels and propose FedGR to improve the label-noise robustness of FL based on this.", "keywords": ["Federated Learning", "Learning with Noisy Labels"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c9dbcb5a1db756a22ca457bfb1cae20aa0a2e622.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes an algorithm learning from noisy samples distributed across client devices in a federated setting. The setting assumes label heterogeneity and label noise heterogeneity across the clients. The main insight is that the instance-level loss values can separate the samples with clean labels and noisy labels. Further, the algorithm uses pseudo-labels as true labels where the clients have a high label noise ratio. The experiments done in vision datasets show that the method beats baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper addresses an important problem in the FL setting.\n2. The method of separating the samples with noisy labels and clean labels is interesting, especially with more in-depth analysis. I think it'll produce nice reusable insights.\n3. Empirical results show that the method outperforms the baselines."}, "weaknesses": {"value": "1. What is the privacy implication of sharing instance-specific loss values in each round from each client? It seems that this will leak more information than sharing the model parameters only. Can the authors discuss/quantify the privacy loss?\n\n2. It is unclear if each round, a new GMM is trained or if the GMM is maintained over rounds. Also, possibly the GMM can also be trained using FedAvg, but why it hasn't been tried is unclear.\n\n3. The algorithm assumes that the loss values have a bimodal distribution and thus can be modeled by a GMM with two components. But can the authors put a figure showing this? I am interested in knowing the four categories of samples: where a sample can have the right label vs a noisy label, and the model predicts accurately vs wrongly. Also, the case when a sample has a noisy label but the model predicts it correctly. Is it possible to show/measure that the GMM can capture these different categories of samples accurately? The figures in Figure 3(a) show that the ratio captured by the GMM is correct, but is there a possibility that the model captures the ratio appropriately but makes mistakes in partitioning?\n\n4. The EMA module is full of hyperparameters and symbols. I couldn't quite get how it works. It will be good to see a more coherent read in 3.3. While the rest of the paper is very well written and interesting, this part kind of feels like fixing the algorithm.\n\n5. Overall, the symbols can be simplified to improve readability.\n\n6. I'm confused about the \\Phi and Sym, and Asym in Table 1. Isn't \\Phi a random number as mentioned in line 373, then what is the meaning of 0.6 and 1 in the table, in unclear.\n\t\n\nDetailed comments:\n7. Fig 3(a): Can this plot have scale 0-1 instead of 0-100, please? Otherwise, please change the labels accordingly -- ratio typically means 0-1 scaling.\n\n8. Fig 3(b): F scores are typically reported in the scale of 0-1, please conform to that. Also, the negative F score is confusing; if this is because of plotting them in a violin pattern, can you use a box plot instead?"}, "questions": {"value": "As above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4gl764kO6e", "forum": "BtpXep9qxC", "replyto": "BtpXep9qxC", "signatures": ["ICLR.cc/2026/Conference/Submission10711/Reviewer_MpYY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10711/Reviewer_MpYY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10711/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761663006597, "cdate": 1761663006597, "tmdate": 1762921946822, "mdate": 1762921946822, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes FedGR, a framework to improve robustness in federated learning (FL) under noisy labels. The key idea is that the global FL model tends to memorize noisy labels more slowly than local models, giving it a natural noise-robust property. FedGR uses this global model as a “reviser” to (1) filter and refine noisy labels on clients and (2) regularize local updates via globally revised EMA distillation and global representation constraints."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Identification of empirical observation that the global FL model exhibits slower memorization of noisy labels and thus maintains more reliable predictions.\n- Extensive experiments across diverse noise types, heterogeneity settings, and real-world noise (Clothing1M) support the approach."}, "weaknesses": {"value": "- Limited theoretical support for the claimed intrinsic noise-robust property of the global model; the paper relies on empirical evidence only. Since this insight is the core motivation, a deeper explanation or theoretical reasoning would strengthen the contribution.\n- Modest improvement on real-world noisy dataset (Clothing1M) compared to synthetic federated noise settings, which raises questions on whether the proposed federated label-noise setup captures real-world noise complexity.\n- FedGR requires every client to be sampled at least once during the warm-up stage to collect loss statistics for sieving. This assumption may be impractical in real-world FL settings with large-scale or intermittently available clients."}, "questions": {"value": "- Could the authors provide intuition or theoretical support for why the global model inherently memorizes noisy labels more slowly than centralized training?\n- FedGR assumes all clients are sampled at least once during warm-up. How would the method perform if only a portion of clients? Can the authors provide empirical results or analysis for this scenario?\n- The evaluation reports the average accuracy over the last 10 epochs instead of the best accuracy. Could the authors also provide the best accuracy for comparison? Additionally, plotting training curves for FedGR and the baselines would help illustrate the benefit of averaging over the last 10 epochs.\n- Why is the improvement on Clothing1M relatively small? Does the federated noise simulation differ significantly from real-world noise characteristics?\n- Why does FedGR show less improvement on CIFAR-100 vs. CIFAR-10, and why does noisy CIFAR-100 degrade less severely? Any insights on dataset complexity vs. noise resilience?\n- FedGR sometimes exceeds FedAvg trained on clean data. Is this due to regularization rather than noise handling?\n- How did $\\gamma_g$ and $\\gamma_l$ decided in the Equation 12? Could the authors provide more justification or sensitivity analysis?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "o6M9ZiPdf9", "forum": "BtpXep9qxC", "replyto": "BtpXep9qxC", "signatures": ["ICLR.cc/2026/Conference/Submission10711/Reviewer_1rw9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10711/Reviewer_1rw9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10711/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761858940522, "cdate": 1761858940522, "tmdate": 1762921946379, "mdate": 1762921946379, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the federated learning with noisy labels (F-LNL) problem, which is exacerbated by heterogeneity in both label noise patterns and data distributions across clients. The authors make a novel observation that the global model in federated learning exhibits slower memorization of noisy labels compared to centralized training, demonstrating what they term \"intrinsic label-noise robustness of FL.\" Leveraging this observation, they propose FedGR, which consists of three main components: (1) a sieving-and-refining module that uses the global model to partition and correct noisy labels, (2) a globally revised EMA distillation module that regularizes local training, and (3) a global representation regularization module. Experiments on various datasets demonstrate that FedGR outperforms seven state-of-the-art baselines under various noise levels and federated settings."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper addresses federated learning with noisy labels under heterogeneous settings, which is a realistic and important scenario for real-world FL deployment where label quality varies across clients.\n2. The experiments span multiple datasets (CIFAR-10/100, Clothing1M) and consider various noise settings (symmetric, asymmetric, mixed) under both I.I.D. and Non-I.I.D. data distributions."}, "weaknesses": {"value": "1. Incremental Method Design: The three modules (sample selection via GMM, EMA distillation, representation regularization) are standard techniques that have been widely used in learning with noisy labels. The main contribution is applying the global model to these existing techniques, which is a relatively straightforward extension\n2. Insufficient Analysis of the Key Observation: No analysis of when this property fails (e.g., very high noise and extreme heterogeneity). How does this phenomenon vary with noise levels (e.g., 40%, 60%, 80%)?\n3. Unclear Methodological Novelty: The paper follows the same framework as prior F-LNL work: identify clean/noisy samples then adjust learning. FedCorr (2022) already uses server-side GMM on aggregated statistics for sample selection and relabeling. FedDiv (2024) aggregates probability density functions at the server for collaborative filtering. This paper's components (server-side GMM, pseudo-labeling, EMA distillation, representation regularization) are standard techniques. The paper does not clearly explain what FedGR can do that FedCorr/FedDiv/FedFixer cannot, or how the \"slower memorization\" observation leads to a methodologically distinct approach beyond motivating use of the global model (which prior work already does)."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2OSjUSNDEf", "forum": "BtpXep9qxC", "replyto": "BtpXep9qxC", "signatures": ["ICLR.cc/2026/Conference/Submission10711/Reviewer_29PX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10711/Reviewer_29PX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10711/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761915661625, "cdate": 1761915661625, "tmdate": 1762921945942, "mdate": 1762921945942, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}