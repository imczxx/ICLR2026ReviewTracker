{"id": "ndHE6IfOnw", "number": 8555, "cdate": 1758090810028, "mdate": 1759897776759, "content": {"title": "Discovering Architectures via an Evolutionary Agentic Framework", "abstract": "In complex, long-horizon tasks such as scientific discovery, Large Language Models (LLMs) have primarily served as assistants to human researchers rather than acting as autonomous agents capable of driving innovation from hypothesis to discovery. In this paper, we attempt to empower an LLM to not only conduct the entire scientific workflow end-to-end but also to evolve its strategies by learning from experimental outcomes. Our system manages the process from hypothesizing novel ideas and implementing code to conducting experiments and analyzing results. Specifically, we introduce the \\modelname framework, which utilizes specialized agents—a Researcher for proposing ideas, an Engineer for evaluation, and an Analyst for interpreting outcomes—to autonomously navigate the research lifecycle. We validated our approach in the challenging domain of linear attention, where our LLM agent conducted 1,773 iterative experiments, leading to the discovery of 105 entirely new architectures. These novel designs outperform existing state-of-the-art (SOTA) models, with their effectiveness confirmed across various model scales and benchmarks. In addition, we conducted a detailed analysis of the LLM's emergent design patterns, providing valuable insights for the research community. We have open-sourced our code and the collection of discovered SOTA models.", "tldr": "We created an LLM-powered agent that automates the entire scientific research loop. We pointed it at the linear attention problem, and it autonomously discovered 105 novel architectures that beat current SOTA models.", "keywords": ["LLM; Agent; Linear attention"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a8146991d33de3e6520382968b19eba13ee632c3.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper selects the topic of designing linear attention structure. To tackle the problem, the authors propose ASI-ARCH, a novel framework designed to allow LLM agents to conduct the entire scientific workflow for architectural discovery. The system includes three agents. (1) Researcher: Researcher proposes new architectural ideas and implements the necessary coding. (2) Engineer: Engineer tests model performance. (3) Analyst: Analyst systematically analyzes the design’s strengths and weaknesses to inform subsequent experiments. \n\nThe system discovers 105 novel architectures that outperform existing state-of-the-art models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The topic is meaningful and tractable. The architecture design with linear attention is meaningful and is easy to conduct evaluation. The design is reasonable and the performance is good."}, "weaknesses": {"value": "(1) The novelty is incremental. This paper proposes three agents, e.g., Researcher, Engineer, and Analyst. Actually, researches, such as AI-CoScientists, designs even more special agents to tackle even more complex and innovative problems. Therefore, the authors should clarify their actual innovations in multi-agent system design.\n\n(2) The writing is not very clear. The detailed questions are:\n     (i) In Line 118, the author explains \\detal_performance. However, it does not appear in Eq. (2), which includes \\delta_loss and \\delta_benchmark.\n     (ii) In the introduction, the author claimed that researchers will write codes, and engineers will run the code. However, the author did not specify how to write the code.\n\n(3) Insufficient comparison. The authors are required to compare their methods with state-of-the-art methods in NAS. Or sufficiently explain why not compare ?"}, "questions": {"value": "Please see the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Gb2QDTCXdJ", "forum": "ndHE6IfOnw", "replyto": "ndHE6IfOnw", "signatures": ["ICLR.cc/2026/Conference/Submission8555/Reviewer_xavQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8555/Reviewer_xavQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8555/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761548391035, "cdate": 1761548391035, "tmdate": 1762920408835, "mdate": 1762920408835, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Authors propose a pipeline, ASI-ARCH, for automating the architecture search process through an agentic LLM setup. The proposed pipeline was used to conduct 1,773 experiments on linear attention architectures and discovered 105 architectures that surpassed existing state-of-the-art models, offering some performance gains on a subset of benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- I think the main idea of using LLMs to suggest architecture changes while measuring performance in a closed evolutionary algorithm based scoring is interesting and could scale well with sufficient available compute.\n- The paper's results are extensive and cover a variety of different benchmarks on finding improved linear attention models.\n- The paper is easy to read and ASI-ARCH introduces some interesting novel ideas in the context of architecture design literature."}, "weaknesses": {"value": "- The paper lacks ablations of proposed agent components.\n- The paper lacks comparison to previous architecture discovery approaches mentioned in the related works. Does the additional cost of the agentic AI setup outperform more traditional neural architecture search approaches?\nImportant experimental details are only found in the appendix, e.g. how was the agentic pipeline implemented and which models were used.\n- The paper’s results will be difficult to reproduce for other researchers as only proprietary models GPT-4.1 and GPT-o3 are used for the proposed setup. \n- A critical discussion of limitations and potential pitfalls is missing.\n- The paper performs experiments on (comparably small) 20M and 340M parameters models given today’s model sizes. The proposed setup is computationally very costly and it seems that eventually only a small fraction of “novel” solutions is explored, raising an important question whether approaches like ASI-ARCH only work because we have a large pool of already validated human-created model mechanisms.\n- Overall improvements according to Table 1 are limited, ASI-ARCH can discover improved architectures, but not reliably on all benchmarks, raising some claims on the robustness of this approach, especially given the large computational costs and the lack of comparison to more simple baselines.\n- Insufficient description of the prompts in the main and the prompt design process (see also comment below). How were the prompts designed and did you do ablations with minimal prompt designs? \n\n**Comments**\n- Some of the claims remained imprecise to me: “discovery of 105 entirely new architectures.” (l.21-22). From the main paper it is not clear if this refers to (i) new compositions of existing classes and modules or (ii) the design of novel classes and integration into novel architectures. I believe after revising Appendix D.1 that the latter is the case, but this should be made very clear in the main paper. Also from revising the details, it seems that a lot of manual expertise went into the prompt design, e.g., “if If {static architectures, deterministic patterns} repeat,” explore the following."}, "questions": {"value": "- To what extent were the “Implementation Quality Standards” like “Ensure O(Nlog N) or better for all operations” (see Appendix D.1) fulfilled by the resulting architectures?\n- What is the typical standard deviation on the results over different weight initialization, e.g. in Table 1? I am sure this is computationally very expensive, but a partial analysis over five seeds on the existing architectures would be insightful as it remains unclear if the improvements are statistically significant.\n- Assuming that the identified components have advantages over previous ones: did you check or analyze to what extent the novel solutions were actually novel (requires clearly stating your notion of novel).\n- Are resulting architectures safe for usage without in-depth human analysis? I think in the current form, the framework poses a risk to propose malicious software.\n\n**Summary**\nWhile I overall think the paper proposes relevant ideas and presents a proof-of-concept, in its current form it lacks methodological rigor and the main claims are not sufficiently supported by evidence."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Iyf31F7zYm", "forum": "ndHE6IfOnw", "replyto": "ndHE6IfOnw", "signatures": ["ICLR.cc/2026/Conference/Submission8555/Reviewer_z2i2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8555/Reviewer_z2i2"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8555/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761644136529, "cdate": 1761644136529, "tmdate": 1762920408436, "mdate": 1762920408436, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces **ASI-ARCH**, a framework that leverages large language models (LLMs) to conduct end-to-end scientific workflows, evolving its strategies by learning from experimental outcomes. The framework comprises three specialized agents: a Researcher for hypothesis generation, an Engineer for implementation and evaluation, and an Analyst for interpreting outcomes. The approach is validated on linear-attention tasks, where it reportedly outperforms existing state-of-the-art methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper proposes a framework aimed at enabling autonomous scientific discovery, encompassing hypothesis generation, experimental implementation, and evaluation.\n\n2. The framework integrates a cognition base that consolidates knowledge from prior literature.\n\n3. The writing is generally clear and the overall structure easy to follow."}, "weaknesses": {"value": "1.\tThe cognition base is distilled from 100 seminal papers on linear attention, yet the selection process is not well described. What criteria were used to choose these papers? How would scaling up or changing the topic affect performance and efficiency? Moreover, how costly would it be to rebuild the cognition base for new research domains?\n2.\tAccording to the statistical analysis of architectural-component usage, the agents tend to propose modifications centered around established elements such as gating mechanisms and convolutions. Does this indicate that the model is prone to mode collapse—i.e., converging to common solutions? Is this collapse related to the diversity of the cognition base, or to limitations of the underlying LLM itself?\n3.\tIn Table 1, when comparing with baseline methods, are hyperparameters such as the number of epochs, parameter counts, and optimization settings kept consistent to ensure a fair comparison?\n4.\tThe paper mentions the use of an LLM evaluator. Given that LLM-based evaluation can be unstable and model-dependent, how do the authors mitigate issues of bias and inconsistency?\n5.\tThe paper lacks direct comparison with other AI-agent frameworks discussed in the related-work section.\n6.\tIt is unclear how the system handles cases where the code generated by the Researcher agent fails to run when passed to the Engineer. Are any fallback or error-correction mechanisms implemented?"}, "questions": {"value": "Please see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bIcrgazcRo", "forum": "ndHE6IfOnw", "replyto": "ndHE6IfOnw", "signatures": ["ICLR.cc/2026/Conference/Submission8555/Reviewer_oxxN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8555/Reviewer_oxxN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8555/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761737768010, "cdate": 1761737768010, "tmdate": 1762920408119, "mdate": 1762920408119, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ASI-ARCH, a multi-agent framework enabling Large Language Models (LLMs) to autonomously conduct the full scientific workflow for neural architecture discovery. The system includes three agent roles (Researcher, Engineer, and Analyst) which collectively propose, implement, evaluate, and analyze model architectures in a closed evolutionary loop. Applied to the linear-attention domain, ASI-ARCH executed 1,773 experiments and discovered 105 architectures claimed to outperform strong baselines (DeltaNet, Gated-DeltaNet, Mamba2). The paper also analyzes emergent design patterns and reports open-sourcing of the code and discovered architectures."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- This is an ambitious and timely paper, pushing toward autonomous scientific discovery.\n- The idea of automating the discovery of architectures is interesting."}, "weaknesses": {"value": "- It is difficult to fully appreciate the novelty of the work or the gaps of previous approaches that the current work is addressing because the related works is all the way at the bottom.\n- Using LLM as a judge to give a qualitative fitness score is a good idea. However, as with every LLM judge, they might be hackable or have some trends or biases that they prefer. Did the authors see any of such phenomenon happening? How much this be eventually solvable?\n- The retrieval mechanism using embedding search is very similar to what was done in this approach (https://arxiv.org/abs/2405.15568). RAG should be cited too.\n- There are a lot of handcrafted design choices in each part of the algorithm ((Researcher, Engineer, and Analyst). It is difficult to see how each of these handcrafted design choices might affect the overall algorithm. A qualitative analysis or more ablations can be helpful.\n- The fitness score seems arbitrary. Were there any solution that the authors found that should have been kept but was discarded because of the heuristic chosen? Could a better way to tackle this be to use train/test sets?\n- \"This convergence mirrors the typical methodology of human scientists: achieving state-of-the-art results by primarily iterating and innovating upon a foundation of proven technologies, rather than pursuing novelty for its own sake.\" A better quantitative way to support this statement is to how the number of different component uses changes across the evolutionary training iterations instead of just at the end. Did it converge over the training iterations or was it always exploring the same distribution throughout?\nRelatedly, did the experience (from experiments) change what was being explored?"}, "questions": {"value": "- How was the selection for the final 5 architectures done?\n- The paper in the abstract was claiming that the discovered algorithms outperform SoTA, however it seems like the paper only compared with strong baselines, and not necessarily SoTA algorithms. Is the claim really right? I am not super familiar with what the current best scores are for the benchmarks mentioned."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4NECWA1JA6", "forum": "ndHE6IfOnw", "replyto": "ndHE6IfOnw", "signatures": ["ICLR.cc/2026/Conference/Submission8555/Reviewer_q31N"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8555/Reviewer_q31N"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8555/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976216963, "cdate": 1761976216963, "tmdate": 1762920407446, "mdate": 1762920407446, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes an agentic framework for automatically discovering and testing new neural network architectures. The approach is applied to the problem of designing linear attention algorithms, and the resulting architectures are analyzed in terms of their performance, complexity, and novelty."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Automated scientific discovery is an interesting and important problem, and the specific problem of discovering linear attention algorithms is a tractable testbed for studying automated scientific workflows.\n- The proposed approach includes several interesting components, including a combination of quantitative and qualitative evaluation of the identified architectures, and a knowledge base of previous human-proposed approaches.\n- The approach is fully autonomous, with the agent carrying out all aspects of research including proposal of new approaches, coding and automated evaluation, and analysis of resulting performance."}, "weaknesses": {"value": "- The primary weakness is that the resulting architectures yield only small and unreliable improvements over human-generated baselines. There is not a single architecture with performance that consistently stands out across benchmarks. Moreover, based on the trajectory of the fitness score (figure 3b) it appears that improvement has plateaued, suggesting that the approach cannot be scaled to meaningfully improve upon current baselines.\n- There are no ablations to the various components in the agentic architecture. It is unclear which of these elements is actually important for generating improved models, and it is unclear whether a simpler approach would perform just as well. Additionally, no other approaches to automated research are tested and compared with the previous approach.\n- Beyond the fact that the target domain (linear attention) is unique to this work, it is not discussed how the proposed approach differs from previous proposals for automated scientific discovery.\n- It is not clear whether the authors have carefully checked the codebase for any of the resulting architectures, beyond a check to ensure that the causal masking is working.\n- There is not sufficient detail provided on the discovered architectures, only an informal description of each of the top-performing approaches. More detail, such as algorithm statements or architecture diagrams, are needed to understand the architectures discovered by the agent."}, "questions": {"value": "- Can ablations be performed to assess the importance of each of the agent's components?\n- How does the proposed approach differ from previous automated scientist proposals?\n- Have the authors carefully checked the codebase for the proposed architectures?\n- Can more detail be provided on the top-performing architectures?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "x4UNYLkzZV", "forum": "ndHE6IfOnw", "replyto": "ndHE6IfOnw", "signatures": ["ICLR.cc/2026/Conference/Submission8555/Reviewer_drBL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8555/Reviewer_drBL"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission8555/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762115248137, "cdate": 1762115248137, "tmdate": 1762920406972, "mdate": 1762920406972, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}