{"id": "NuYcnDYQuQ", "number": 12327, "cdate": 1758207081920, "mdate": 1759897516781, "content": {"title": "Evil in the Pairing Assumption: Multimodal Attribution via Adaptive Information Bottleneck", "abstract": "Multimodal attribution methods such as M2IB aim to interpret vision-language models without requiring task-specific labels, but they often rely on the assumption of accurate semantic alignment between image-text pairs. This assumption does not hold in open-world settings, where noisy or mismatched inputs are common. Under such conditions, existing attribution methods tend to overfit and generate forced explanations, compromising the reliability and trustworthiness of interpretability results. To address this issue, we observe that a well-balanced trade-off between the compression and prediction terms in the information bottleneck objective can mitigate overfitting. Based on this insight, we propose an attribution framework that leverages an adaptive information bottleneck optimization objective. Our method dynamically adjusts the bottleneck constraints without assuming reliable cross-modal alignment. Extensive experiments on large-scale image-text datasets demonstrate that our approach consistently outperforms existing attribution methods in both quantitative metrics and qualitative interpretability, providing more robust and trustworthy explanations while relaxing the requirement for aligned image-text pairs.", "tldr": "", "keywords": ["Interpretability", "Information Bottleneck", "Multi-Modal Learning"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f903e5b772f37c88c438f15328380508958f2921.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes an Adaptive Information Bottleneck (AdaIB), which reformulates the classic IB objective to use sample-dependent weights, $f(X,Y)$ and $g(f)$, for the sufficiency and compression terms, respectively. The authors provide a theoretical analysis in Section 4.3 and Appendix B to ground this new objective, presenting theorems on its asymptotic behavior (sufficiency and minimality) and a proposition on \"bounded leakage\"."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is commendable for attempting to provide a principled, formal justification for its adaptive objective, rather than just presenting it as an empirical heuristic.\n2. Proposition 1 clearly situates the classic IB as a special case of AdaIB, which is helpful for understanding the proposed generalization.\n3. The variational derivation of the objective in Appendix B.1 appears to be standard and correct."}, "weaknesses": {"value": "1. The main theoretical results (Theorems 1 and 2) are purely asymptotic, analyzing the behavior only as $f \\to \\infty$ or $f \\to 0$. This provides little to no theoretical insight into the method's behavior in the \"Moderate Fit\" regime (as shown in Figure 2), which is presumably the most common and important case.\n2. There appears to be a significant disconnect between the theory and the implementation.\n    (i).  The primary theory (Sec 4.3, e.g., Theorem 3 assumes $g$ is a non-increasing *function of* $f$.\n    (ii).  The actual implementation (Sec 5.2) *decouples* these: $f$ is a fixed L2 distance, and $g$ is an independently parameterized MLP.\n    (iii).  While Appendices B.5 and B.6 *mention* this decoupled case, the main theoretical justifications presented in the paper (Sec 4.3) are based on the non-decoupled version. It is unclear if the guarantees from Sec 4.3, which rely on the $g(f)$ relationship, apply to the implemented model.\n3.  Proposition 2 (\"No Gratuitous Leakage\") and its proof seem to be a trivial consequence of the objective function's definition. It merely states that for a fixed sufficiency $I(Z;Y)$, the term $-g(f) \\cdot I(Z;X)$ will, by definition, prefer a smaller $I(Z;X)$ (since $g(f)>0$). This does not feel like a strong guarantee that information is not \"leaking,\" especially in the high-$f$ regime where $g(f)$ (and thus the penalty) might be learned to be very small."}, "questions": {"value": "1.  Do the authors have any theoretical guarantees for the non-asymptotic case (i.e., for $f$ in a moderate range $[a, b]$), which is not covered by Theorems 1 and 2?\n2.  Regarding the theory-practice disconnect: Do the theoretical properties from Sec 4.3 (like the adaptive trade-off in Thm 3) hold for the *decoupled* implementation where $g$ is a separately learned MLP? Was any monotonicity of $g$ with respect to $f$ enforced during training?\n3.  Can the authors provide an *empirical* validation of the \"bounded leakage\" claim (Prop 2)? For example, could a decoder trained to reconstruct $X$ from $Z$ demonstrate that, even for high-$f$ samples, $Z$ does not contain significantly more information about $X$ than necessary?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6DkqAiNaqc", "forum": "NuYcnDYQuQ", "replyto": "NuYcnDYQuQ", "signatures": ["ICLR.cc/2026/Conference/Submission12327/Reviewer_NkdQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12327/Reviewer_NkdQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12327/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761925407891, "cdate": 1761925407891, "tmdate": 1762923251922, "mdate": 1762923251922, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents AdaIB, an adaptive extension of Information Bottleneck (IB) attribution methods. The core methodological contribution is to replace the fixed IB trade-off parameter ($\\beta$) with a dynamic, sample-specific mechanism. This mechanism consists of two parts: a heuristic relevance function $f(X,Y)$ (instantiated as L2 distance) and a learnable compression function $g(f(X,Y))$ (instantiated as a shallow MLP). The authors provide extensive ablation studies to justify these design choices and demonstrate that this adaptive approach outperforms fixed-weight baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The motivation for an adaptive trade-off is intuitive and well-illustrated by Figure 2. The idea that different samples require different compression levels is a clear and sensible improvement over a one-size-fits-all $\\beta$.\n2. The proposed $f$ and $g$ functions are a significant improvement over the more naive heuristics (e.g., $g=1/f$) discussed in prior work.\n    * Designing $g$ as a learnable MLP is a strong choice, as it allows the model to learn complex compression strategies directly from the data.\n    * The ablation studies in Appendix E (Tables 6 and 7) are comprehensive and provide strong empirical backing for the final design choices (L2 for $f$, and a $1 \\to 32 \\to 1$ ReLU MLP for $g$).\n3. Figure 4 (Appendix D) is particularly insightful. It shows that even for samples with a similar $f$ value (L2 distance), the learned $g$ (compression weight) can vary wildly. This strongly supports the authors' claim that $g$ is capturing \"nuanced, context-dependent characteristics\" beyond what the simple L2 distance heuristic can provide."}, "weaknesses": {"value": "1. While effective, the core idea is an extension of M2IB and NIB. The contribution of an \"adaptive weight\" is a solid, but arguably incremental, step rather than a major conceptual leap.\n2. The authors motivate the need for a learnable, adaptive approach, yet they settle on a \"half-fixed, half-learnable\" design. $f(X,Y)$ is a fixed, hand-crafted heuristic (L2 distance), while $g$ is a flexible, learnable function. This seems inconsistent. Why not also learn the relevance function $f_{\\theta}(X,Y)$, as the authors themselves propose in Definition 2?\n3. The analysis of Figure 4 stops short. The paper claims $g$ learns \"deeper data properties\" but never defines what these might be. Is $g$ learning to compress more based on text length? Image entropy? Object count? Without this, the claim remains vague."}, "questions": {"value": "1.  The authors propose a fully learnable $f_{\\theta}(X,Y)$ in Definition 2. Did they experiment with this? Why was the final design choice a fixed L2 heuristic for $f$ but a learnable MLP for $g$?\n2.  Following up on Figure 4: Can the authors provide a more concrete analysis of what the learnable $g$ function is actually learning? For example, can they show any correlation between the learned $g$ value and other data properties (e.g., text length, number of objects in the image, etc.)?\n3.  How sensitive is the model to the specific architecture of $g$? Table 7 shows Model 2 ($1 \\to 32 \\to 1$) is best, but Model 4 ($1 \\to 64 \\to 64 \\to 1$) also performs well. Is this choice stable across datasets, or must the $g$-network be carefully re-tuned for each new task?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "N1VkMQTkxf", "forum": "NuYcnDYQuQ", "replyto": "NuYcnDYQuQ", "signatures": ["ICLR.cc/2026/Conference/Submission12327/Reviewer_EUcm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12327/Reviewer_EUcm"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12327/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761925595215, "cdate": 1761925595215, "tmdate": 1762923251506, "mdate": 1762923251506, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper argues that multimodal attribution methods (e.g., M2IB/NIB) implicitly assume well-aligned image‚Äìtext pairs and can overfit under mismatch. It proposes AdaIB, which replaces the fixed IB coefficient with sample-adaptive weights: a relevance score f(X,Y) scales the sufficiency term I(Z;Y) and a compression weight g(f) (or a decoupled gœï(X,Y)) scales I(Z;X). The authors derive a variational training objective, prove limiting properties (sufficiency/minimality), and report improved quantitative/qualitative attribution across CLIP-based benchmarks (CC3M, Flickr8k, LAION-400M, RefCOCOg)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper formalizes when fixed-Œ≤ IB can under/overfit and proves that AdaIB recovers classical IB as a special case, with limiting behavior toward sufficiency (large ùëì) and minimality (small ùëì).\n2. The derivation yields a practical per-sample loss with KL regularization against a variational prior r(z).\n3. Results cover multiple datasets and metrics (Drop/Increase, ROAR, pointing-game IoU); tables show consistent gains over M2IB/NIB and gradient/perturbation baselines."}, "weaknesses": {"value": "1. Some typos (with exact locations).\n- ‚ÄúFollowing the approach of MI2B and NIB‚Äù ‚Üí M2IB. \n- ‚ÄúCOCOA(Lin et al., 2022)‚Äù (missing space) ‚Üí COCOA (Lin et al., 2022). \n- Table-4 caption: ‚Äúcompared to baselines M2IB and NI‚Äù ‚Üí NIB. \n- Radford et al. (2021) venue string: ‚ÄúPmLR‚Äù ‚Üí PMLR.\n2. The text defines large f(X,Y) as high relevance (emphasizing sufficiency), but the experiments state ‚Äúfor f we choose the L2 distance by default,‚Äù where larger distance means lower relevance. This inverts the intended semantics unless an explicit inversion/monotone mapping is applied. The paper should either use similarity / inverse-distance (as later proposed) or clarify the transformation used in ¬ß5.2. \n3. Theory in ¬ß4.1‚Äì4.3 assumes g is non-increasing in f, but ¬ß4.4 later decouples fŒ∏(X,Y) and gœï(X,Y) (both learnable). Without restoring a monotonicity constraint or proving new conditions, several theorems no longer directly apply. The paper claims properties ‚Äúcontinue to hold,‚Äù but this needs a precise statement of assumptions and a proof sketch in the main text.\n4. Eq. (13) proposes ùëî(ùëì)=1/(ùëì+ùúñùëî), which indeed yields strong compression when ùëì‚Üí0. But combined with the distance-as-ùëì choice in ¬ß5.2, this makes compression weaker for larger distances, contradicting the intended ‚Äúcompress more when relevance is low.‚Äù The paper should reconcile Eq. (13) with the actual ùëì used.\n5. All results appear to use CLIP ViT-B/32; adding other backbones (e.g., RN50, ViT-L) would test robustness. \n6. Beyond the main experiments (e.g., the ~31M-pair LAION subset), the paper includes a supplementary diagnostic that samples 2,000 pairs per dataset (CC3M/Flickr8k/LAION) to form balanced matched vs. mismatched sets for separability analysis (Fig. 3). Please make this distinction explicit in the experimental setup and consider reporting how conclusions scale from the 2,000-pair diagnostic to the full-scale settings."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ggdYNO5UNw", "forum": "NuYcnDYQuQ", "replyto": "NuYcnDYQuQ", "signatures": ["ICLR.cc/2026/Conference/Submission12327/Reviewer_DL8r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12327/Reviewer_DL8r"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12327/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994732225, "cdate": 1761994732225, "tmdate": 1762923251162, "mdate": 1762923251162, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper identifies the implicit reliance on the pairing assumption of existing multimodal attribution methods. It extends Multimodal Information Bottleneck (M2IB) by dynamically controlling the tradeoff between compression and fitting."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- This paper studies how to dynamically control the tradeoff between compression and fitting, a common challenge for information bottleneck-based attribution methods.\n- The experiments are comprehensive, covering relevant baselines and four different datasets"}, "weaknesses": {"value": "1. The implementation of f and g is unclear. \n- What's the range of g? In definition 1, $g(f(X,Y)) \\in (0,\\inf)$. In sec 5.2, g is an MLP with relu (is relu added in the middle layers or after the last layer of mlp as in line 314?), which also doesn't have an upper bound.  However, in Figure 4, g seems to be bounded by [0,1].\n- Is g learned for every sample? It seems that the authors use definition 2 in implementation, discarding the constraint that g is a nonincreasing function on f. If g is learned for each sample, as f(x,y) is a constant given x and y, we can keep maximizing the objective by pushing g(x,y) to 0.\n- It's unclear why f is chosen to be a fixed function while g is a learnable function. The experiments have tested different fixed function choices for f and different architectures for g, but don't explain this core design.\n- If f is intended to reflect the relevance between x and y, shouldn't f be inverse L2 instead of L2?\n2. The authors state they prioritize I(Z;Y) for highly relevant image-text pairs, using L2 distance to determine this relevance. However, this metric is problematic for complex captions. A caption might list many objects present in the image alongside some that are not,  resulting in a higher L2 distance (and thus low \"relevance\"). In this scenario, all present objects should be highlighted, but the current implementation will encourage compression. Many visualizations presented in this paper have shown this over-compression. For example, in the \"dog running down a snow covered hill\" example (fifth row of figure 7), AdaIB highlights \"dog\" and \"snow\" \"hill\" in the text but only highlights the \"dog\" in the image. This suggests the adaptive mechanism may be too aggressive, pruning relevant semantic concepts that are part of the intended explanation."}, "questions": {"value": "See weakness\n- How's the AdaIB's performance on negation (e.g. \"a photo without a dog\")?\n- How is Figure 1 AdaIB figure obtained? Each heatmap is usually normalized, so it should have at least some red areas. Is any thresholding applied?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "36h68QwsEA", "forum": "NuYcnDYQuQ", "replyto": "NuYcnDYQuQ", "signatures": ["ICLR.cc/2026/Conference/Submission12327/Reviewer_aFzw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12327/Reviewer_aFzw"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12327/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762152859037, "cdate": 1762152859037, "tmdate": 1762923250495, "mdate": 1762923250495, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}