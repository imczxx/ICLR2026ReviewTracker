{"id": "NMV0XdGnaP", "number": 22823, "cdate": 1758335894876, "mdate": 1759896844483, "content": {"title": "Faster Sampling from Gibbs Distributions with Quantum Variance Reduction", "abstract": "We present quantum algorithms that provide provable speedups for approximate sampling from probability distributions of the form $\\pi \\propto e^{-f}$, where $f$ is a potential function that can be written as a finite sum, i.e., $f= \\frac{1}{n}\\sum_{i=1}^n f_i$. Our approach focuses on stochastic gradient–based methods with only oracle access to individual gradients \\{$\\nabla f_i$\\}$_{i\\in [n]}$. The techniques of our quantum algorithms are based on a non-trivial integration of quantum mean estimation techniques and existing variance reduction techniques such SVRG and CV. \n\n As these techniques often require occasional full-gradient calculations, the key challenge is that an unbalanced weighting between variance reduction and quantum mean estimation results in a regime where the quantum advantage is lost due to frequent full-gradient computation. We overcome this difficulty by carefully optimizing the target variance level. Our algorithms improve the number of gradient queries of classical samplers, such as Hamiltonian Monte Carlo (HMC) and Langevin Monte Carlo (LMC), in terms of dimension,  precision, and other problem-dependent parameters.", "tldr": "We propose quantum algorithms to reduce the gradient query complexities of HMC and LMC for sampling from convex and non-convex potentials.", "keywords": ["Gibbs sampling", "MCMC methods", "quantum sampling", "quantum mean estimation", "LMC", "HMC", "quantum algorithm"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/31fca4bff8f581b396d009961de2db15bb702f90.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces quantum-enhanced stochastic gradient samplers that integrate unbiased quantum mean estimation with classical variance reduction techniques to accelerate approximate sampling from Gibbs distributions in finite-sum settings. The authors provide non-asymptotic analyses showing that their proposed QSVRG/QCV variants of HMC and LMC achieve improved gradient-query complexity over the current state-of-the-art classical methods under strong convexity and log-Sobolev assumptions. Overall, the work aims at establishing a theoretically grounded avenue for quantum speedups in sampling algorithms."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The paper indeed tackles a crucial in many domains, i.e., sampling from Boltzmann-Gibbs type of distributions. \n- It does a thoroughly analysis of related works and also carries forward a rigorous mathematical analysis of the proposed method. \n- The paper is well structured, the related work section is very extensive and the preliminaries section exhaustive."}, "weaknesses": {"value": "- The paper is very hard to follow at times: Many notions and concepts are mentioned in the introduction and not properly introduced. For example, the concept of oracle, is extensively mentioned in the first section without never being properly defined. This can represent a serious blocker for people without a strong background in quantum computing. \n- I have the impression the paper is too focused on quantum computing. For this reason, it may be hardly accessible to the broader audience normally targeted at top tier ML conferences. I believe a specialised quantum computing conference or journals are a better venue for publishing this work. \n- Again, also notation is sometimes not defined when appearing for the first time, thus making the paper not easy to follow. See for example eq (5) on page 2. \n- The bottom of page 2 from line 84 onwards also appears fairly verbose and hard to parse. Furthermore, algorithms are hereby introduced with their acronym without appropriate refs and or explanations. \n- Limitations are not discussed explicitly. \n- Conclusions are also missing thus making the paper appearing incomplete. \n- The experimental section is missing. While the authors admit that their theoretical works is based on fault-tolerant quantum devices, I still believe it is important to have a section that validates theoretical works. In this regards I wonder if the authors can simply use quantum computer simulators without any source of error to showcase the advantages of their approach in comparison to others. \n- Without an appropriate empirical analysis, I find it unfair to claim any practical advantage of the proposed approach over existing classical algorithms. While theoretically there should be an advantage, the classical algorithm can be tested and ran while the proposed approach, as it relies on fault tolerant quantum device cannot be compared. \n- I believe the authors should extend their work (if possible) by accounting for non fault tolerant quantum devices or error corrected qubits so that at least some sort of empirical evaluation can be carried out."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "Not applicable."}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "B5Hl8qWi57", "forum": "NMV0XdGnaP", "replyto": "NMV0XdGnaP", "signatures": ["ICLR.cc/2026/Conference/Submission22823/Reviewer_X1zp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22823/Reviewer_X1zp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22823/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761811989853, "cdate": 1761811989853, "tmdate": 1762942400297, "mdate": 1762942400297, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a new variance reduction approach for Hamiltonian Monte Carlo. The key idea is to replace the stochastic gradient estimation in SG-HMC via a quantum mean estimator. Since the quantum mean estimator has a quadratic improvement in $\\epsilon$ compared to classical algorithms, the proposed idea can improve the gradient variance in HMC."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "+ The idea of using a quantum mean error estimator in HMC is out-of-box. This idea can be transformative if it really works.\n+ This paper also presents a set of theorertical proofs to show the potential advantage of this method in Section 4.\n+ The introduction/tutorial about quantum computing is very intuitive, and it's easy to follow for generic machine learning researchers."}, "weaknesses": {"value": "While the presented idea is very interesting, my main concern is that this paper draft looks so incomplete, and many key points are missing.\n1.  No numerical/simulation results are provided to support the claimed benefit;\n2.  No conclusion was made about the paper either\n3. While this paper uses quantum mean estimator as a blackbox (which is OK), it did not provide the key details about quantum mean estimation. For instance, how a quamtum mean estimator will be implemented (algorithmically and in practical hardware)? Withoug such details, readers can hardly implement this idea.\n4.  This paper didn't talk about the feasibility of implementing this idea either. Can this algorithm be impelmented using existing quantum hardware or quantum/classical hybrid processor? If not, how many quantum gates are needed in the future to enable real implementation?"}, "questions": {"value": "I have a few questions:\n1. Can you explain how the quantum mean estimator will be implemented in the HMC context?\n2. Can you explain how many quantum gates are needed to implement this framework? If a classical/quantum hybrid architecture is needed, how would this hybrid architecture look?\n3. Measuring the results of a quantum computing framework is often very challenging in practical engineering implementation. Can you explain how you can measure the result of the quantum mean estimator for the gradient?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jrlwcRKHR6", "forum": "NMV0XdGnaP", "replyto": "NMV0XdGnaP", "signatures": ["ICLR.cc/2026/Conference/Submission22823/Reviewer_wgCL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22823/Reviewer_wgCL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22823/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761891175594, "cdate": 1761891175594, "tmdate": 1762942400044, "mdate": 1762942400044, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces quantum algorithms that accelerate approximate sampling from Gibbs distributions $\\pi(x) \\propto e^{-f(x)}$, where $ f = \\frac{1}{n}\\sum_i f_i $. The authors integrate quantum mean estimation with classical variance reduction techniques (e.g., SVRG, CV) to design quantum analogues of stochastic-gradient samplers such as Langevin Monte Carlo (LMC) and Hamiltonian Monte Carlo (HMC). They analyze how to optimally balance quantum variance estimation costs with occasional full-gradient computations to preserve quantum advantage. The resulting algorithms achieve provable asymptotic reductions in gradient-query complexity over the best classical methods under both strong convexity and Log-Sobolev assumptions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Originality: Introduces the framework combining quantum mean estimation with classical variance reduction (SVRG, CV) for stochastic-gradient-based sampling, bridging two previously separate areas—quantum optimization and classical sampling theory.\n- Quality: Provides detailed theoretical analysis, including variance control lemmas and nonasymptotic convergence bounds under both strong convexity and Log-Sobolev assumptions, leading to rigorously proven quantum query speedups.\n- Clarity and structure: The paper is well-organized, with clear motivation, formal assumptions, and explicit algorithmic descriptions that parallel classical counterparts (LMC/HMC).\n- Significance: Demonstrates asymptotic improvements in gradient-query complexity (e.g., from $\\tilde{O}(n^{1/2}\\varepsilon^{-1})$ to $\\tilde{O}(n^{1/3}\\varepsilon^{-1})$), clarifying where quantum advantages can arise in sampling—a central task in machine learning and statistical physics."}, "weaknesses": {"value": "- Complexity accounting: The relation between query complexity (oracle calls) and total gate complexity is not specified, making direct comparison with classical cost a little ambiguous.\n\n- Parameter dependence: Several results require knowledge of problem constants such as the Log-Sobolev constant $\\alpha$, which are typically unknown in practice.\n\n- A bit concern of novelty: quantum mean estimation is widely used to accelerate machine learning and optimization tasks. Could the author explain more about its specific technical novelty in combining them with the sampling framework?"}, "questions": {"value": "See the weakness part, the concern of novelty."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "99IPNP7Lq1", "forum": "NMV0XdGnaP", "replyto": "NMV0XdGnaP", "signatures": ["ICLR.cc/2026/Conference/Submission22823/Reviewer_LTAk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22823/Reviewer_LTAk"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22823/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761919625942, "cdate": 1761919625942, "tmdate": 1762942399778, "mdate": 1762942399778, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents quantum algorithms that accelerate the sampling from probability distributions $\\pi \\propto e^{-f}$, where $f = \\frac{1}{n}\\sum_i f_i$. By assuming access to individual gradients $\\{\\nabla f_i\\}$, and leveraging quantum mean estimation techniques to existing variance reduction techniques in the classical literature, the new quantum algorithms achieve sub-quadratic speedups in key problem parameters such as dimension $n$ and accuracy $\\epsilon$."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Drawing ideas from quantum stochastic optimization methods, such as multi-dimensional quantum mean estimation and quantum gradient estimation, to improve large-scale, noisy sampling tasks.\n- A non-trivial integration of quantum mean estimation to existing variance reduction techniques, leading to polynomial quantum speedups.\n- Quantum speedups demonstrated for various sampling algorithms, including LMC and HMC. Three quantum speedups are identified in Table 1, two for strongly convex problems and one under the standard LSI assumptions."}, "weaknesses": {"value": "All three reported quantum speedups are sub-quadratic: \n- QSVRG-HMC: $n^{1/2}\\epsilon^{-3/4}$ v.s. classical SVRG-HMC: $n^{2/3}\\epsilon^{-2/3}$.\n- QCV-HMC: $\\epsilon^{-3/2}$ v.s. classical CV-HMC: $\\epsilon^{-2}$\n- QSVRG-LMC: $n^{1/3}\\epsilon^{-1}$ v.s. classical SVRG-LMC: $n^{1/2}\\epsilon^{-1}$. \nIt is noted that, to achieve the claimed speedups, fully fault-tolerant quantum computers are required. While theoretically non-trivial, such quantum speedups are of fairly limited value in practice. In fact, people commonly believe that a quadratic quantum speedup (in the asymptotic sense) may not be sufficient to yield a realistic performance gain due to the overhead of quantum error correction (QEC). \n\nMoreover, this paper does not discuss the limitations of quantum speedups for this class of problems. If it can be established (or at least argued) that this type of stochastic sampling problem cannot be further accelerated (for example, with some query/sample lower bounds), it would be of greater impact on the field of quantum computing."}, "questions": {"value": "1. The assumption on the stochastic gradient oracle appears to be quite strong, as it requires a superposition of individual gradients. In most practical problems, the individual gradients are only available in an incoherent superposition (i.e., a classical ensemble, such as batched SGD). Can you give some concrete scenarios where this type of quantum oracle is achievable, meaning that their quantum implementation costs are not significantly higher than implementing the classical stochastic gradient oracle?\n2. My understanding is that the proposed quantum algorithms are actually hybrid quantum-classical algorithms, since the iteration steps are still performed on classical computers, while only the gradient estimation steps are replaced using quantum variance reduction. If that's the case, it should be mentioned explicitly, as this approach is quite different from a number of existing quantum sampling algorithms (e.g., [Childs et al., 2022], [Ozgul et al., 2024]) that do not perform classical iteration steps but produce a quantum state that encodes the target measure $\\pi$: \n3. Recently, there has been a new approach for probabilistic sampling using differential operators and QSVT: https://arxiv.org/abs/2505.05301. Is this a relevant approach for stochastic sampling? If so, how does the performance compare to the tabulated results in the paper?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LqdDCtAN2a", "forum": "NMV0XdGnaP", "replyto": "NMV0XdGnaP", "signatures": ["ICLR.cc/2026/Conference/Submission22823/Reviewer_39VQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22823/Reviewer_39VQ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22823/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762716804978, "cdate": 1762716804978, "tmdate": 1762942399586, "mdate": 1762942399586, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}