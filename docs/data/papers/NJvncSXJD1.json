{"id": "NJvncSXJD1", "number": 14621, "cdate": 1758240278964, "mdate": 1759897359014, "content": {"title": "Generating Samples to Probe Trained Models", "abstract": "There is a growing need for investigating how machine learning models operate. With this work, we aim to understand trained machine learning models by questioning their data preferences. We propose a mathematical framework that allows us to probe trained models and identify their preferred samples in various scenarios including prediction-risky, parameter-sensitive, or model-contrastive samples. To showcase our framework, we pose these queries to a range of models trained on a range of classification and regression tasks, and receive answers in the form of generated data.", "tldr": "In order to explain trained models, we pose questions in the form of functions on the data space, answers of which are generated data points.", "keywords": ["Model Understanding", "Data Generation"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/743af1832237004e58ab694b3803c9b9ae701f1a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a framework for generating synthetic data that probes already trained models under various objectives.\nIt examines four key objectives: uncertainty — data points near the decision boundary; disagreement — where two models make opposite predictions; sensitivity — where small parameter changes strongly affect the output, and counterfactuals —inputs that yield a fixed target label. For each objective they define a probe energy over inputs that induces a Gibbs distribution; sampling from it yields examples for that objective.\nThe framework is evaluated across toy tasks, real-world tabular datasets, MNIST, and latent probes of pretrained ImageNet classifiers, showing that the generated samples accurately capture each probing objective."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is original in framing model probing as a data generation problem using a Bayesian Gibbs formulation. It is clearly written, with solid theoretical grounding and well-chosen illustrative experiments. The framework is significant in that it offers a unified and general-purpose approach for probing trained models —both differentiable and non-differentiable— across multiple axes of behavior, including uncertainty, disagreement, sensitivity, and counterfactual exploration. \nIt also has potential to extend beyond probing — for example, to adversarial testing, fairness auditing and enforcement, or post-hoc robustness evaluation."}, "weaknesses": {"value": "- Evaluation is mostly qualitative relying primarily on visual examples and descriptive comparisons; adding quantitative metrics for uncertainty, sensitivity,  disagreement and counterfactual would strengthen the evidence.\n- The latent-space sampling relies on a pretrained VAE but lacks explicit regularization to prevent drift off the data manifold, which may affect sample fidelity in practice.\n\n- Hyperparameter sensitivity is unexplored; the temperature $\\tau$ and sampling parameters likely affect the generated samples. An ablation could clarify the framework’s robustness to these choices.\n\n- No information is provided on runtime or computational cost, which would help assess the practical feasibility of the approach.\n\n- Despite claiming applicability to both classification and regression, all empirical results focus on classification tasks. A regression case study would help substantiate the framework’s generality.\n\n\nFormulation inconsistencies: \n- Although the framework is presented as general over $\\mathcal{Y}$, Eq.~(6) for parameter-sensitive samples assumes a binary output through the term $1 - y_{\\theta^*}(x)$. The paper should either restrict this objective to binary tasks or provide a general formulation.\n- The formulation R_G(x) = $|x - x_a|_r^r$​ in Equations (4)–(7) lacks an explicit regularization weight $\\lambda$, which is essential for controlling the trade-off between locality and the probing objective. Including $\\lambda$ would improve the completeness and clarity of the formulation."}, "questions": {"value": "1) Why are quantitative metrics for uncertainty, disagreement, sensitivity or counterfactuals not used more broadly to support the probing scenarios?\n\n2) How do you ensure that samples generated in latent space remain on the data manifold, especially without explicit regularization or constraints on the latent variables?\n\n3) How sensitive are the generated samples to the specific design of the probing function G(x) (e.g., choice of loss term, temperature, or regularizer)? Some analysis or ablation could clarify how robust the framework is to these design choices.\nDo the experiments include a tunable regularization weight \\lambda for R_G(x)?\n\n4) In Figure~6, the gender distribution of the generated counterfactual samples appears roughly balanced, yet the text claims that most samples shift from female to male. Could the authors clarify how this distribution was computed and whether the claimed gender shift is quantitatively supported? Could this observation simply reflect that gender is not a significant factor in the model’s prediction?\n\n5) Eq.~(6) for parameter-sensitive samples appears to assume binary outputs through the term $1 - y_{\\theta^*}(x)$. How would this objective be defined for multi-class or regression tasks where such a complement is not well-defined?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "leop0F6W0I", "forum": "NJvncSXJD1", "replyto": "NJvncSXJD1", "signatures": ["ICLR.cc/2026/Conference/Submission14621/Reviewer_pffq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14621/Reviewer_pffq"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14621/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761840327165, "cdate": 1761840327165, "tmdate": 1762924999350, "mdate": 1762924999350, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a general mathematical framework for probing trained models by generating synthetic samples that satisfy custom-defined probing objectives. The approach draws a symmetry between model training (parameter optimization) and model probing (data optimization), and includes analytical and empirical demonstrations across regression and classification tasks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The idea of formulating probing as a generative process is interesting and connects interpretability with probabilistic modeling. Overall, the proposed framework is flexible, allowing different “questions” to be posed to a trained model."}, "weaknesses": {"value": "Overall, I find the paper’s organization difficult to follow, particularly in Section 2. The core mathematical framework is presented in a dense and abstract way, which obscures how the proposed method is actually implemented. Several key equations (e.g., Eq. 2–4) are introduced without sufficient intuition or explanation. Moreover, the design rationale behind the probing function G across different use cases remains unclear—for instance, it is not evident why Eq. (5) appropriately captures model-contrasting samples. These gaps in exposition make it challenging to fully assess the technical quality and contribution of the work. \n\n\nMinor: \n1. Line 84: \"First, our notation:\" sounds like an unfinished sentence\n2. Line 98: \"The loss function F in 1\" should be \"... Equation (1)\""}, "questions": {"value": "Can you clarify the computational steps for constructing $G(x)$ and sampling  $p(x)$ in non-trivial models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "Z04qZx8O1o", "forum": "NJvncSXJD1", "replyto": "NJvncSXJD1", "signatures": ["ICLR.cc/2026/Conference/Submission14621/Reviewer_FUym"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14621/Reviewer_FUym"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14621/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762003079329, "cdate": 1762003079329, "tmdate": 1762924998264, "mdate": 1762924998264, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a general mathematical framework for generating synthetic samples that reflect specific model behaviors. The idea is to take a \"dual\" view of model training: given a fixed model (or distribution of model parameters), sample data according to a specific user-defined probing function. Samples can be drawn using Langevin dynamics. By choosing different forms of G, the approach can produce various kinds of synthetic samples, such as model-contrastive, prediction-risky, or parameter-sensitive. The method is demonstrated on linear regression, tabular data, and vision models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper introduces a clear variational formulation that symmetrically parallels model training and data synthesis. The proposed framework is very general, can handle various kinds of objective functions, and is model-agnostic."}, "weaknesses": {"value": "While the conceptual insight is interesting, at least based on my knowledge in this domain, the paper has relatively marginal novelty in its specific algorithm (which is not necessarily a weakness, though). \n\nThe paper currently lacks a discussion of how the proposed framework can be extended to the discrete input space. While a VAE decoder can enforce data-manifold constraints, this is still difficult for generating language data. \n\nThe experiments are mostly qualitative and small-scale. \n\nNo baselines are being compared in the experiments. However, I am not sure whether there are no prior works on this problem. For example, adversarial examples are being generated using similar gradient-based algorithms."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8ghgoeBJGu", "forum": "NJvncSXJD1", "replyto": "NJvncSXJD1", "signatures": ["ICLR.cc/2026/Conference/Submission14621/Reviewer_skCR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14621/Reviewer_skCR"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14621/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762383591748, "cdate": 1762383591748, "tmdate": 1762924997824, "mdate": 1762924997824, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}