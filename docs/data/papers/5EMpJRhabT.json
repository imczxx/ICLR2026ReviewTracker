{"id": "5EMpJRhabT", "number": 10299, "cdate": 1758166405978, "mdate": 1759897659933, "content": {"title": "Decision Potential Surface: A Theoretical and Practical Approximation of LLM's Decision Boundary", "abstract": "Decision boundary, the subspace of inputs where a machine learning model assigns equal classification probabilities to two classes, is pivotal in revealing core model properties and interpreting behaviors. While analyzing the decision boundary of large language models (LLMs) has raised increasing attention recently, constructing it for mainstream LLMs remains computationally infeasible due to the enormous vocabulary-sequence sizes and the auto-regressive nature of LLMs. To address this issue, in this paper we propose Decision Potential surface (DPS), a new notion for analyzing LLM decision boundary. DPS is defined on the confidences in distinguishing different sampling sequences for each input, which naturally captures the potential of decision boundary. We prove that the zero-height isohypse in DPS is equivalent to the decision boundary of an LLM, with enclosed regions representing decision regions. By leveraging DPS, for the first time in the literature, we propose an approximate decision boundary construction algorithm, namely $K$-DPS, which only requires $K$-finite times of sequence sampling to approximate an LLM's decision boundary with negligible error. We theoretically derive the upper bounds for the absolute error, expected error, and the error concentration between $K$-DPS and the ideal DPS, demonstrating that such errors can be trade-off with sampling times. Our results are empirically validated by extensive experiments across various LLMs and corpora.", "tldr": "", "keywords": ["Decision Boundary", "Large Language Models"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4348f770f53db524a725f04014e96eba6b6dad3a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper extends the concept of decision boundaries to LLMs by framing the prediction of output sequences as a multiclass classification task, and aims to derive a method to efficiently estimate the decision boundary."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is generally well-written (except for few minor weaknesses, see weaknesses)\n- The problem of estimating the decision boundary is important and well motivated in the paper\n- The idea of extending the concept of decision boundaries to LLMs is certainly interesting and correctly modeled in large parts"}, "weaknesses": {"value": "- **W1) Limited contribution.** The proposed approach to estimate the decision boundary has a critical limitation: It can only estimate the LLM's \"confidence\" in distinguishing the two most likely output sequences *for a fixed input*. This means for a given input prompt, we can check if it’s on the decision boundary \"between two output sequences\" (when the potential function is zero). However, constructing a decision boundary means finding input points (ideally all of them) that lie on the decision boundary (as in Theorem 4.3). Although the paper claims it can construct the decision boundary, it actually just estimates the confidence of the LLM for fixed inputs. This limitation is not well communicated and also not sufficiently discussed in the paper.\n\n- **W2) Limited discussion.** To model decision boundaries for LLMs, this paper frames output generation as a multiclass classification problem. However, multiple output sequences can represent equivalent or semantically similar responses to the same prompt, especially since LLMs are designed to produce diverse outputs. The paper does not sufficiently discuss that focusing on a single output ignores the underlying semantic decision boundary (which might be entirely different).\n\n**Minor weaknesses**\n- Theorem 3.3 should be a definition as it only introduces the concept of decision boundaries for LLMs and does not contain any mathematical statement. It is also only referred to as a definition (line 218, line 230, line 237, etc.).\n- $\\mathcal{D}$ is called a distribution, but it is actually just a finite subset of the finite-length token sequence space. \n- The connection to the LLM uncertainty literature is not sufficiently discussed. \n\nOverall, while the confidence estimation seems to work, it remains unclear if this confidence estimation approach can be actually helpful in constructing (or estimating) the decision boundary in the input prompt space."}, "questions": {"value": "How do you compute the approximate number of decision regions in the introduction (line 059)? At this stage of the paper it is not yet clear what exactly constitutes the decision boundary of LLMs (see also your research question afterwards in line 065)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OErVovtGzB", "forum": "5EMpJRhabT", "replyto": "5EMpJRhabT", "signatures": ["ICLR.cc/2026/Conference/Submission10299/Reviewer_UCjU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10299/Reviewer_UCjU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761406835426, "cdate": 1761406835426, "tmdate": 1762921648469, "mdate": 1762921648469, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DSP, a new notion for analyzing LLM decision boundaries of LLMs. Given the huge hypothesis space (O(vacaulary size^seq len)),  the paper proposes the concept of Decision Potential Surface to simplify the concept with the two most highest probability sequences, and further proposes an approximate decision boundary construction algorithm to approximate the LLM's decision boundary by sampling. The error is characterized by both theoretical and practical analysis.  Overall, the paper is solid with multiple concepts built for analyzing the decision boundaries of LLMs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper's main contribution is the novel concept of DPS. It cleverly transforms the geometric problem of the \"decision boundary\" into a function problem based on probability differences and rigorously proves their equivalence at zero.\n\n2. The K-DPS approximation algorithm is practical. It provides the first method in literature with theoretical guarantees to feasibly approximate an LLM's decision boundary.\n\n3. The paper doesn't just propose an approximation; it provides a complete error bound analysis. This makes the method a fundamental and mathematically-backed tool, not just a heuristic."}, "weaknesses": {"value": "1. The accuracy of K-DPS is entirely dependent on the sample size K. If K is too small, the sample may fail to capture the true top-2 sequence (especially if its probability is low), leading to a large approximation error. Choosing a \"good enough\" K is a practical trade-off (the paper uses 20000 as a proxy for the ideal value, which is a non-trivial sample size).\n\n2. It is better to provide some insights to guide practice, e.g., how to improve LLM performance. Otherwise, it is of no use.\n\n3. DPS focuses only on the \"potential difference\" between the top-1 and top-2 sequences. While this is sufficient to define the boundary, it may ignore other complexities of the decision landscape. For example, a scenario where the top-2, top-3, and top-4 sequences are all very close in probability would have a similar DPS value to a scenario where only the top-2 is close, even though the model's \"uncertainty\" is different."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Bf7ji9p0jF", "forum": "5EMpJRhabT", "replyto": "5EMpJRhabT", "signatures": ["ICLR.cc/2026/Conference/Submission10299/Reviewer_GGrG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10299/Reviewer_GGrG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761985977456, "cdate": 1761985977456, "tmdate": 1762921648089, "mdate": 1762921648089, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper mainly focuses on studying the decision boundary of LLMs, which is an important tool to figure out the core model properties and interpret behaviors. However, due to the computational infeasibility of LLMs and the enormous vocabulary-sequence sizes, it is hard to do so. In this paper, a new notion, Decision Potential Surface, is proposed to analyze the decision boundary of LLMs."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper studies the decision boundary of LLMs, which is a simple yet essential problem. The problem studied in the paper is valuable.\n2. The paper provides theoretical analyses for the problem, which makes the paper convincing. \n3. The empirical results reported in the paper are good."}, "weaknesses": {"value": "1. The paper is difficult to read. The formulations are a little bit confusing, and there are no remarks to help understand the paper."}, "questions": {"value": "1. What does the $\\mathcal{M}$ mean in Line 163? The definition should be added.\n2. What does Definition 3.1 mean? Specifically, why does it assume $p_m=p_n$?\n3. As a follow-up question to Question 2, the assumption that there exist two maximal probabilities seems too strong. Or could you provide some intuitive explanations for this assumption?\n4. Eq. (4) also looks a little bit strange. From the equation, I think the main goal here is to find two tokens that have the largest differences."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Jkk7mb6hrt", "forum": "5EMpJRhabT", "replyto": "5EMpJRhabT", "signatures": ["ICLR.cc/2026/Conference/Submission10299/Reviewer_9Cff"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10299/Reviewer_9Cff"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762160425540, "cdate": 1762160425540, "tmdate": 1762921647675, "mdate": 1762921647675, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces the first theoretically grounded and computationally feasible approximation of an LLM’s decision boundaries. Using the proposed Decision Potential Surface (DPS) and its K-sampled approximation (K-DPS), the authors provide both theoretical analysis and empirical visualizations of how LLMs form decision regions. Their theoretical results show that the approximation error decreases in a sub-linear order of $1/\\sqrt{K}$ as the number of sampled generations $K$ increases. Extensive experiments confirm this trend and illustrate interpretable decision boundaries across multiple datasets and models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well written and, to my understanding, represents the first work to formally approximate and analyze decision boundaries of LLMs, potentially opening a new line of research for both theoretical exploration and practical applications. The proposed framework is mathematically grounded, with theoretical results that are clearly presented and supported by consistent empirical evidence. While I would like to examine the theoretical proofs in more depth, the formalism and presentation appear sound and understandable."}, "weaknesses": {"value": "**W1)** The main limitation of the paper lies in the lack of clear insights or downstream implications gained from the proposed decision boundary approximation. While the theoretical contribution appears solid, it remains unclear how this framework deepens our understanding of LLM behavior or what practical applications it could enable. Previous work on decision boundaries in classical models provided interpretability or robustness insights; I would like to see similar discussion or evidence of such implications here.  \n\n**W2)** A more minor concern is that some of the visualizations could be improved for clarity and informativeness. For example, Figure 2 would benefit from a log–log scale to better reveal convergence trends, and Figure 4 could include bar plots or summaries at fixed percentages of $K$ for easier comparison. The current Figure 4 is visually interesting but somewhat difficult to interpret or connect directly to the theoretical claims. Additionally, using simpler synthetic datasets could help validate and illustrate the theoretical results in a more controlled and interpretable setting."}, "questions": {"value": "**Q1)** Following up on the main weakness: what new insights about LLM behavior can be derived from the proposed decision boundary approximation? It would be helpful to clarify what interpretability or diagnostic value this framework provides beyond theoretical formulation.  \n\n**Q2)** Wouldn’t the two highest-probability sequences often be nearly identical—differing only in the final token or a small local variation? If so, the top-1 and top-2 outputs might not represent meaningfully distinct decisions, which could limit the interpretability of the analysis. The authors should provide concrete examples to illustrate this point or clarify if I am misunderstanding the setup.  \n\n**Q3)** Are there any observed behaviors or trends regarding model size or vocabulary size, or any ablation results on these factors? Such experiments could offer the most direct empirical insights from the proposed decision boundary approximation framework.\n\n**Q4)** I believe there was some formatting issue for the references. Just a reminder to fix that."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Z9LBTacrzy", "forum": "5EMpJRhabT", "replyto": "5EMpJRhabT", "signatures": ["ICLR.cc/2026/Conference/Submission10299/Reviewer_7hfg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10299/Reviewer_7hfg"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762166360675, "cdate": 1762166360675, "tmdate": 1762921647340, "mdate": 1762921647340, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}