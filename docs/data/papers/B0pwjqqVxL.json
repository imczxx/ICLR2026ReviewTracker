{"id": "B0pwjqqVxL", "number": 528, "cdate": 1756744220290, "mdate": 1763561083221, "content": {"title": "Think Smarter, Focus Wisely: Adaptive Cognitive Allocation for LLM Reasoning", "abstract": "Encouraging longer chains of thought is a common design practice for improving LLM reasoning. However, recent studies show that “thinking more” can backfire.\nIn response, prior studies have typically employed augmented reasoning strategies to enhance performance. While these approaches often improve reasoning robustness and yield higher accuracy, they may also generate excessively long chains, which introduce redundant checks, demand disproportionate reasoning effort, and ultimately lead to inefficient consumption of cognitive resources.\nThis paper introduces {\\bf{A}}daptive {\\bf{R}}easoning via {\\bf{C}}ognitive {\\bf{A}}llocation ({\\bf{ARCA}}), a structured reasoning framework that adaptively allocates cognitive resources across reasoning phases based on their reasoning state, thereby mitigating the efficiency–accuracy trade-off.\nThe core idea of ARCA is to structure the reasoning procedure into classified phases, while grounding the process and suppressing incoherent drift.\nWithin each phase, ARCA generates candidate directions and employs a Borda-Aggregated selector to identify the most promising ones, while steering inference along phase-aware directions and pruning redundant exploration.\nThrough the dynamic allocation of cognitive resources, the proposed ARCA framework can achieve a balance between accuracy and efficiency.\nAcross six reasoning benchmarks, ARCA consistently outperforms strong baselines, either in terms of enhanced accuracy or reduced reasoning cost.", "tldr": "", "keywords": ["Large language model"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cf0b0d6054556a6f1a0caa60d59cbf4626c812d8.pdf", "supplementary_material": "/attachment/c516b0ea9cdfe589cea0ce01b357e5bf960ed95d.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes ARCA (Adaptive Reasoning via Cognitive Allocation), a structured reasoning framework designed to balance accuracy and efficiency in large language model (LLM) reasoning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The topic of research is promising;\n\n2. Experimental results are good."}, "weaknesses": {"value": "1. I don’t think this paper provides any meaningful insights. Specifically, in Section 3.1, the authors decompose the task into several sub-tasks, similar to [1]. In Section 3.2, the conceptual novelty over prior structured-reasoning methods such as Tree-of-Thought, Graph-of-Thought, or Meta-Reasoner remains somewhat unclear. The paper largely re-packages known search-and-selection patterns under new terminology;\n\n2. Many key components (e.g., Phase Generator, Phase Classifier, Direction Generator, Borda-aggregated selector) are vaguely defined and appear heuristic. It is not obvious how they are implemented, trained, or verified to work autonomously;\n\n3. The framework illustration (Figure 2) is quite difficult to interpret. The authors introduce many specific technical terms without providing sufficient explanations or context. Furthermore, using Sudoku as an illustrative example is not ideal, as it assumes the reader has prior knowledge of the game, which may not always be the case. Overall, while I can grasp the general idea of the framework, the detailed mechanisms remain vague and unclear.\n\n\n[1] Least-to-Most Prompting Enables Complex Reasoning in Large Language Models"}, "questions": {"value": "The paper claims to introduce “cognitive resource allocation,” but this is essentially adaptive search-depth control. Please clarify how ARCA differs theoretically from existing meta-reasoning or dynamic-depth frameworks."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XPrcxYA4ei", "forum": "B0pwjqqVxL", "replyto": "B0pwjqqVxL", "signatures": ["ICLR.cc/2026/Conference/Submission528/Reviewer_2zpx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission528/Reviewer_2zpx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission528/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760968775705, "cdate": 1760968775705, "tmdate": 1762915539162, "mdate": 1762915539162, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an Adaptive Reasoning via Cognitive Allocation framework under a carefully designed, prompt engineering flow with a robust scoring tool. The aim is to address the trade-off between accuracy and efficiency in LLM reasoning, achieving high accuracy while maintaining efficient reasoning. The core argument is that instead of letting a large model think blindly, it's better to let it intelligently plan its thinking process, allocating more computational resources only where necessary, thus avoiding performance degradation due to over-reasoning.\nThe ARCA framework has two core modules:\n1) Reasoning Chain Construction: Using a Phase Generator to decompose complex tasks into logically ordered reasoning stages.\n2) Cognitive Resource Allocation: Dynamically allocating reasoning resources at both the macro-level (Phase Classifier) ​​and micro-level (Direction Generator + Borda-Aggregated Selection).\n\nThe paper conducts experiments on six reasoning tasks, including AQUA, BBEH, GSM8K, Game of 24, Sudoku, and AIME, claiming superior accuracy and efficiency compared to existing baseline methods."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1.The paper addresses a critical challenge in LLM reasoning: balancing accuracy and efficiency. This is highly relevant given the high inference costs of reasoning models. The motivation is clearly articulated through an intuitive Sudoku example (Figure 1), effectively demonstrating that some reasoning phases require minimal cognitive resources (\"think less\") while others demand deeper exploration (\"think more\"). The problem formulation of \"cognitive resource allocation\" provides a fresh perspective on reasoning efficiency.\n\nS2.The two-stage ARCA framework is well-structured. Stage 1 (Reasoning Chain Construction) decomposes tasks into logical phases, providing structured guidance to prevent fragmented reasoning. Stage 2 (Cognitive Resource Allocation) operates at two complementary levels: macro-level phase identification and micro-level direction selection. This hierarchical design is conceptually sound.\n\nS3.The experimental work is substantial, covering six diverse reasoning tasks spanning different domains.\n\nS4.The paper is generally well-written with clear structure and logical flow\n\nS5.The paper provides detailed implementation specifics in the appendices, including prompts for Phase Generator, Phase Classifier, and Direction Generator (Appendix C.2), as well as algorithmic details for Borda-aggregated selection (Algorithm 1). This level of detail facilitates reproducibility and practical adoption."}, "weaknesses": {"value": "W1. The core of this paper is to use LLM to judge the merits of inference directions, but the reliability of this hypothesis has not been verified. A key missing experiment is: for tasks with ground truth, actually execute each candidate direction to see which one actually yields the correct answer, and then calculate the accuracy of the LLM+Borda selection. \n\nW2. In multi-step inference, is there a possibility of the final step being a \"lucky guess\"? Does the planning in each phase truly play a role? The paper's logic is \"use LLM to judge -> Borda aggregation -> select the optimal,\" but the definition of \"optimal\" comes from LLM itself, forming a circular argument and failing to distinguish whether the improvement truly finds a better path or reinforces model bias.\n\nW3. Are there systematic biases in the underlying LLM system? For example, positional bias might not be detected: LLM might favor the first or last option. Style and phrasing biases could also exist: LLM might be drawn to certain \"academic\" terms. ARCA performs well on DeepSeek-V3 simply because it happens to cater to the specific biases and preferences of that model, rather than because the method itself is general.\n\nW4. The paper claims that Borda is better, but lacks theoretical support. Key issue: The voting theory assumptions maybe not applicable. Borda theory is based on multiple independent rational voters, stable preferences, and no position effect, but LLM is a single model called multiple times, which may have systematic bias, random output, and obvious position bias. The paper directly borrows the conclusions but does not verify the rationality of the hypothesis transfer.\n\nW5. ARCA requires multiple LLM calls (Phase Generator + Classifier + Direction Generator + Borda comparison), while CoT may only requires once. Although the number of tokens is similar, the latency cost of multiple rounds of interaction is negligible. Compare this to the accuracy of CoT with the same token budget.\n\nW6. Only the Borda parameter was ablated, lacking ablation of Phase Generator, Phase Classifier, different aggregation methods, and different LLM evaluators, making it impossible to understand the true contribution of each component.\n\nW7. The problems criticized in the paper may also apply to itself. (1) It criticizes the \"structural rigidity\" of Skills-in-Context, but ARCA's Phase Generator also predefines the phase structure, and if the LLM generation quality is poor (as the paper acknowledges), this \"automatic rigidity\" is even more dangerous; (2) It criticizes the \"specialization\" of Meta-Reasoner, but ARCA also needs to tune hyperparameters (m, n, max_directions, max_depth) for different tasks, and lacks a meta-learning framework; (3) It does not clearly distinguish itself from core works such as CToT and Self-Refine, and fails to verify the marginal contributions of Phase and Borda through ablation experiments. The paper should discuss the advantages and disadvantages of each method more objectively and in a balanced way."}, "questions": {"value": "Q1. The paper acknowledges in Appendix B.3 that the generated phases are \"generally broader and less consistent than those produced by human experts.\" Has anyone compared the performance differences between manually designed phases and automatically generated phases?\n\nQ2. If the Phase Generator generates unreasonable phases (such as incorrect phase order), can subsequent Phase Classifiers and selections correct them?\n\nQ3. Page 6 of the paper mentions using the Borda score instead of the Copeland score because of \"robustness against minor inconsistencies.\" Could you provide theoretical analysis or experimental evidence to prove that the Borda score is indeed more robust than the Copeland score in your setting? A known problem with the Borda score is its susceptibility to irrelevant alternatives. Would this be a problem in your scenario?\n\nQ4. Why does your method show significant improvement in some tasks but only slight improvement in others? Could you analyze which types of tasks are best suited to your method?\n\nQ5.The main results of the paper are based on DeepSeek-V3, with results for Qwen3-8B in the appendix. How does it perform for smaller models (e.g., 7B, 1B)? Smaller models may not perform well in Phase Generation and Direction Generation. How does it perform for other architectures (e.g., Claude, GPT-4)? Have you tested the differences between open-source and pripretary models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "uHtSVSWOEv", "forum": "B0pwjqqVxL", "replyto": "B0pwjqqVxL", "signatures": ["ICLR.cc/2026/Conference/Submission528/Reviewer_HZU1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission528/Reviewer_HZU1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission528/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761815863533, "cdate": 1761815863533, "tmdate": 1762915539055, "mdate": 1762915539055, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This article proposes the Adaptive Resource Allocation for Cognition (ARCA) framework to address the trade-off between accuracy and efficiency in Large Language Model reasoning, avoiding overthinking and resource waste caused by traditional COT approaches. The ARCA framework decomposes complex tasks into structured reasoning phases via ReasonGen and dynamically focuses resources using PhaseClass. At the micro level, it generates multiple reasoning directions and employs a Borda aggregation selection mechanism based on LLM preference feedback to identify the optimal reasoning path. Experimental results demonstrate that ARCA significantly improves accuracy while reducing reasoning costs, making it particularly suitable for complex long-chain reasoning tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.It presents a novel and timely perspective by addressing the efficiency-accuracy trade-off caused by \"overthinking\" in LLM reasoning. For the first time, it introduces a structured decomposition approach and a dynamic hierarchical resource allocation mechanism.\n2.The paper features a clear line of reasoning, drawing inspiration from the hierarchical cognitive processes through which humans solve problems."}, "weaknesses": {"value": "1. The effectiveness of ARCA depends on ReasonGen generating valid phase structures. While tasks like Sudoku and 24-point have clear structures, can ReasonGen introduce errors or miss key phases in more open-ended tasks requiring complex domain knowledge?\n2.Given that all ARCA components (main solver, ReasonGen, PhaseClass, and LLM Evaluator) rely on a single large LLM (e.g., GPT-4), does this lead to prohibitively high inference costs?\n3.ARCA claims efficiency, yet the Borda aggregation mechanism requires generating multiple candidates and performing $O(N^2)$ pairwise comparisons, which introduces additional inference calls and delays, conflicting with the claim of negligible overhead."}, "questions": {"value": "What are the criteria for switching between inference stages (e.g., from \"locating potential numbers\" to \"eliminating impossible options\")? Do these transition conditions have soft or hard cutoffs? We are concerned that near the end of a stage, the LLM might experience a \"transitional oscillation,\" repeatedly switching between adjacent stages and thereby wasting resources instead of conserving them."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PCMwxEVzN3", "forum": "B0pwjqqVxL", "replyto": "B0pwjqqVxL", "signatures": ["ICLR.cc/2026/Conference/Submission528/Reviewer_b2YF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission528/Reviewer_b2YF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission528/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761893559322, "cdate": 1761893559322, "tmdate": 1762915538906, "mdate": 1762915538906, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "To address the trade-off between accuracy and efficiency in long chain-of-thought reasoning, this paper proposes Adaptive Reasoning via Cognitive Allocation. By combining reasoning-chain construction and cognitive-resource allocation, the method guides structured reasoning and selects more promising reasoning paths. Experiments are conducted on a broad range of reasoning tasks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper proposes an adaptive cognitive allocation mechanism that uses a macro/micro hierarchical structure combined with the Borda aggregation algorithm to evaluate different reasoning steps and prioritize the most promising ones. This provides a practical idea for pruning reasoning paths in multi-step reasoning."}, "weaknesses": {"value": "The paper lacks clear novelty. The authors should better clarify how their method differs from Tree of Thoughts (ToT) and Graph of Thoughts (GoT), which also employ multi-step reasoning with verification. Although Borda scoring is used, it appears conceptually similar to Pairwise Comparison [1], differing mainly in the scoring formulation (win count vs. win rate).\n\nEach stage of the proposed method is generated via prompting an LLM, meaning the performance is highly dependent on how well the LLM interprets and executes instructions. Prior research [2–3] shows that LLMs are sensitive to prompt positional information, which may affect reproducibility and stability.\n\nIn Section B.3, the authors state:”While these phases are often broader and exhibit less consistency compared to those created by human experts, they prove to be sufficiently accurate to effectively guide the reasoning process.”\nIt remains unclear how these phase divisions were evaluated against human-created ones — what metrics or criteria were used?\n\n[1]Zhang Z Y, Han S, Yao H, et al. Generating Chain-of-Thoughts with a Pairwise-Comparison Approach to Searching for the Most Promising Intermediate Thought[C]//International Conference on Machine Learning. PMLR, 2024: 58967-58983.\n\n[2]Guo Y, Guo M, Su J, et al. Bias in large language models: Origin, evaluation, and mitigation[J]. arXiv preprint arXiv:2411.10915, 2024.\n\n[3]Zheng C, Zhou H, Meng F, et al. Large language models are not robust multiple choice selectors[J]. arXiv preprint arXiv:2309.03882, 2023."}, "questions": {"value": "1.Since each stage of the method is generated via prompting, I suggest performing LLM consistency evaluation by executing the same prompts multiple times (and swapping candidate order) to test stability.\n\n2.Compare the generated reasoning paths with human reasoning trajectories on the same tasks to analyze the method’s advantages or differences.\n\n3.The evaluation of candidate reasoning steps is relatively simple; how efficient is Borda aggregation when applied to large-scale or more complex reasoning paths?\n\n4.How is the reasoning cost specifically computed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FJX8qBGIrB", "forum": "B0pwjqqVxL", "replyto": "B0pwjqqVxL", "signatures": ["ICLR.cc/2026/Conference/Submission528/Reviewer_taAD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission528/Reviewer_taAD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission528/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761914586173, "cdate": 1761914586173, "tmdate": 1762915538751, "mdate": 1762915538751, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}