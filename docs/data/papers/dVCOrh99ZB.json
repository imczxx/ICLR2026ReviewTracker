{"id": "dVCOrh99ZB", "number": 22859, "cdate": 1758336416140, "mdate": 1759896842306, "content": {"title": "Counterfactual Residual Data Augmentation for Regression", "abstract": "Data-driven modeling in real-world regression tasks often suffers from limited\ntraining samples, high collection costs, and noisy observations. Inspired by the\nimpact of data augmentation in vision and language, we propose a novel Counterfactual Residual Data Augmentation (CRDA) technique for tabular regression.\nOur key insight is that once a regressor has modeled the systematic component of\nthe data, the remaining noise can be viewed as an invariant residual that remains\nstable under small perturbations of carefully selected features. We exploit this\nresidual invariance to generate new, yet realistic, training samples, effectively expanding the dataset without requiring additional real data. Our method is model-agnostic and readily applicable to various types of regressors. In experiments\nacross datasets from a variety of benchmark repositories, on average, CRDA reduces an MLP Regressor’s MSE by 22.9% and an XGBoost Regressor’s MSE by 6.4%. When compared to existing state-of-the-art synthetic data generators,\nCRDA consistently outperforms in MSE reduction. By adding principled counterfactual variations to the training data, our method offers a simple and efficient remedy for noise-prone, small-sample regression settings.", "tldr": "", "keywords": ["Data Augmentation", "Counterfactual Reasoning", "Tabular Regression", "Residual Modeling", "Synthetic Sample Generation"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/13a23020ce6db6dc29576d5a5366005ce1f3e54f.pdf", "supplementary_material": "/attachment/c93315644ee4e450e9741f8ee7d24ff6d9fd0f8f.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a data augmentation technique called as counterfactual residual data augmentation (CRDA) for tabular regression problem. When the number of samples are few, CRDA empirically provides evidence of performance improvements. CRDA relies on residual invariance assumption and the experiments show improvements over baselines."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is written well, easy to read and understand.\n2. The proposed method is simple and model agnostic.\n3. This paper addresses crucial challenges in real-world tabular tasks such as overfitting and limited sample size.\n3. Experimental results show good improvements compared to baselines."}, "weaknesses": {"value": "1. There is no theoretical analysis of how the proposed method achieves good performance using the proposed data augmentation method.\n2. CRDA is applied on only two methods: MLP and XGBoost. For example, CatBoost often outperforms XGBoost. It is crucial to check if other popular methods for tabular data can benefit from the CRDA.\n3. What kinds of underlying causal data generating processes or causal graphs satisfy the Assumption 1? I believe the problems caused by hidden confounding (see [1-2] below), which is common in real-world tabular data, cannot be addressed by CRDA. I appreciate some discussion around it both in rebuttal and in the revision.\n4. In step 3 of the algorithm, if a causal graph check is performed using PC algorithm, it is mentioned that all variables that are directly connected to the residual are excluded from $X_P$ but if a correlation check is performed, variables with high correlation are excluded. These two ideas contradict with each other in a case where there is a variable that is highly correlated with $Z$ but is indirectly connected to $Z$. \n5. As acknowledged, when the dataset size is small, obtaining reliable estimates for causal graph or statical tests is challenging (step 3 of the algorithm).\n\nReferences:\n\n1. Prashanth et al. Scalable Out-of-distribution Robustness in the Presence of Unobserved Confounders\n2. Gowtham et al. When Shift Happens - Confounding Is to Blame."}, "questions": {"value": "See the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UC272WD2YX", "forum": "dVCOrh99ZB", "replyto": "dVCOrh99ZB", "signatures": ["ICLR.cc/2026/Conference/Submission22859/Reviewer_qFtg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22859/Reviewer_qFtg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22859/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760899890441, "cdate": 1760899890441, "tmdate": 1762942417107, "mdate": 1762942417107, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a Counterfactual Residual Data Augmentation (CRDA) method, increasing the dataset size while remaining loyal to the residual distribution under the fixed identified invariant feature set. The proposed method is shown to improved generalization in regression tasks over a range of tabular datasets, mitigating the overfitting problem in small-dataset settings."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Overfitting to small datasets is a well-known problem in regression and domain-agnostic data augmentation is not straight forward due to inability to find the transformations that retains the correct labels. The motivation and problem definition is clearly stated in the paper. The authors provide a brief background summary, propose a novel method to augment the residual noise by identifying and counterfactually perturbing the invariant feature set and use this procedure to generate new sample points that preserve the noise structure and remain consistent with the systematic behavior of the dataset.\n\nThe proposed CRDA method improves the prediction accuracy and reduces the variance in regression tasks with tabular data especially in the small-dataset regime.\n\nThe paper is well written and the reasoning is easy to follow. The theoretical analysis is supported by the results in the experiments section. The idea is to incorporates residual with novelty to perform data augmentation, while residuals are good identifiers for model uncertainty."}, "weaknesses": {"value": "While data augmentation for regression is a scarcely studied complex problem, some previous work are missing from the paper e.g. [Hwang'21, Schneider'23] which might be relevant to include (not relevant to the given rating).\n\nThe empirical results in the paper are limited to comparison with no-augmentation baseline on UCI and comparison with generative augmentation on synthetic 3d dataset. It is difficult to assess the true potential of the method when it is not compared to other regression data augmentation algorithms like RegMix, C-Mix or Anchor data augmentation on the more complex sets of datasets. I will reconsider the given rating if e.g. UCI experiments with any of these algorithms are included in the results.\n\n[Hwang'21] Regmix: Data mixing augmentation for regression, Seong-Hyeon Hwang, Steven Euijong Whang, arXiv preprint arXiv:2106.03374, 2021\n\n[Schneider'23] Anchor Data Augmentation,Nora Schneider, Shirin Goshtasbpour, Fernando Pérez-Cruz, NeurIPS 2023"}, "questions": {"value": "Similar to the proposed CRDA method, Anchor Data Augmentation (ADA) [Schneider'22] is rooted in CSM and linear augmentation of the features. The non-linear version of the augmentation process is the most similar to CRDA although in ADA augmentation alters the labels which is estimated according to the first-order Taylor approximation of the regressor. CRDA comes at the additional cost of Peter-Clark and correlation based feature elimination to retain the original labels of the data and relies on the assumption that removing the first order and linear connections to the residual is sufficient to retain the labels.  \n\n1 - Can the authors explain whether the feature selection phase in CRDA can be reformulated as an improved instance of Anchor matrix selection in a pretraining phase in ADA? If not how different the generated augmentations in CRDA are from ADA's in theory?\n\n2 - What is the additional computation complexity of the method due to the feature selection process? \n\n3 - Can the authors show how realistic the Assumption 1 is in practice e.g. for UCI? What is the expected divergence between $\\mathbb P(Z|X_P,X_R)$ and $\\mathbb P(Z|X_R)$ ? How effective is Peter-Clark or correlation removal step in reducing the divergence?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Iz2pTceBxq", "forum": "dVCOrh99ZB", "replyto": "dVCOrh99ZB", "signatures": ["ICLR.cc/2026/Conference/Submission22859/Reviewer_rEDf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22859/Reviewer_rEDf"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22859/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761755585442, "cdate": 1761755585442, "tmdate": 1762942416869, "mdate": 1762942416869, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Counterfactual Residual Data Augmentation (CRDA) for improving the performance of regression on tabular data. It is based on the assumption that there some features on which perturbations do not alter the distribution of the residual given a reasonably good regression model. After fitting a base regressor, the method identifies “perturbable” features that are conditionally independent of the residual given the remaining features, and generates counterfactual inputs by applying small perturbations only on those features. The counterfactual labels are generated by adding the predicted value of the base model and the original residual. Across nine benchmarks, CRDA reduces MSE for MLPs by 22.9% and for XGBoost by 6.4%, and outperforms TabDDPM, TVAE, and CTGAN on average"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* A key strength of this work is that it tackles an important yet under-explored problem: principled data augmentation for tabular regression. Unlike many tasks in computer vision and NLP, augmenting tabular data with counterfactual regression labels is less obvious, especially compared to classification where the labels are discrete and finite. The paper addresses this gap by formalizing a residual-invariance assumption and prove its viability through empirical experiments.\n* The core idea of the proposed method is easy to implement. After identifying the features, the augmentation process is simply adding noise and re-compute the labels. The feature selection process is flexible and can be performed according to various criteria.\n* The experimental evidence is strong. The approach consistently reduces improves performance across nine tabular-regression benchmarks for both MLP and XGBoost."}, "weaknesses": {"value": "* As discussed at the end of Section 6, the method does not work well if the dataset is too small because it needs a reasonably good model to begin with.\n* Some simple and simple baselines/ablations are missing, e.g. perturbing all features randomly, fixing the label after perturbation, etc. These experiments will help verify the basic assumption of residual invariant to some features.\n* The intuition behind the assumption still doesn’t convince me."}, "questions": {"value": "* Is it possible to do this iteratively (train a model with augmented data, and then generate new augmentation from the new model) to get further improvement?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dFcoWSePcW", "forum": "dVCOrh99ZB", "replyto": "dVCOrh99ZB", "signatures": ["ICLR.cc/2026/Conference/Submission22859/Reviewer_S8VY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22859/Reviewer_S8VY"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22859/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980126570, "cdate": 1761980126570, "tmdate": 1762942416605, "mdate": 1762942416605, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Counterfactual Residual Data Augmentation (CRDA), a novel, model-agnostic technique designed to enhance the robustness and generalization capabilities of models in tabular regression tasks characterized by limited training samples, high collection costs, and observational noise. The core principle relies on residual invariance: after training a base regressor to capture the behavior of the data, the remaining noise, or residual, is treated as an invariant component that remains stable under counterfactual perturbations of specific input features. New synthetic samples are generated by perturbing these selected features and assigning a counterfactual label preserving the original noise structure. CRDA includes checks for feature-residual independence and a validation safeguard via the Wilcoxon signed-rank test to ensure statistical significance before committing to the augmented dataset. Empirically, CRDA achieves substantial reductions in Mean Squared Error (MSE), averaging 22.9% for MLP regressors and 6.4% for XGBoost regressors, consistently outperforming state-of-the-art deep generative augmentation models."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The method successfully addresses its target domain, showing its greatest benefit in low to moderate data-scarce regimes (e.g., 2.5k to 20k samples in synthetic tests). This confirmation of a \"sweet spot\" is crucial, as is the observed average MSE reduction of 22.9% for the MLP Regressor, highlighting its ability to provide valuable signal for data-hungry neural models.\n\nThe inclusion of multiple checks acts as a filtering mechanism to prevent harmful augmentation.\n\nThe Wilcoxon signed-rank test on paired cross-validation errors provides a statistical safeguard where if no statistically significant improvement is found, CRDA reverts to the baseline model.\n​\nCRDA generates synthetic samples that are faithful to the underlying noise distribution, which the authors argue is the reason it reliably surpasses deep generative baselines."}, "weaknesses": {"value": "While efficient in the \"sweet spot,\" CRDA suffers at the boundaries of data scarcity. When the dataset is too small, the base model is too weak to produce meaningful, independent residuals, and the statistical tests may lack power. When the dataset is very large, the benefits diminish as the baseline is already highly accurate, limiting the practical application domain.\n\nCRDA is designed for regression tasks limiting its immediate utility across general learning problems.\n\nCRDA hinges on the Residual Invariance Principle (Assumption 1), which states that the noise must be conditionally independent of the perturbable features given the fixed features. In practice, this assumption is unverifiable from finite data. The paper acknowledges that Assumption 1 may be violated if the base predictor is poorly fitted (common in very small datasets) or if unobserved confounders are present, which are factors the initial PC algorithm check is ill-equipped to handle reliably."}, "questions": {"value": "For very small datasets where the base model is weak and the Wilcoxon test lacks power, are there modifications to the methodology that could improve the fidelity of the residuals being generated, mitigating the risk of non-significant performance degradation?\n\nhave the authors explored conceptualizing the \"residual\" as uncertainty or confidence scores that could be sampled from an invariant distribution, rather than requiring a numerical difference from the true label?\n\nHow might CRDA's feature partitioning approach be integrated with causal inference techniques designed to handle proxies for unobserved confounders?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "RA0GFiYaYC", "forum": "dVCOrh99ZB", "replyto": "dVCOrh99ZB", "signatures": ["ICLR.cc/2026/Conference/Submission22859/Reviewer_TQy8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22859/Reviewer_TQy8"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22859/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762302843181, "cdate": 1762302843181, "tmdate": 1762942416372, "mdate": 1762942416372, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}