{"id": "dMFKprC7vR", "number": 14896, "cdate": 1758245268151, "mdate": 1759897342945, "content": {"title": "FFHQ-Makeup: Paired Synthetic Makeup Dataset with Facial Consistency Across Multiple Styles", "abstract": "Paired bare-makeup facial images are essential for a wide range of beauty-related tasks, such as virtual try-on, facial privacy protection, and facial aesthetics analysis. However, collecting high-quality paired makeup datasets remains a significant challenge. Real-world data acquisition is constrained by the difficulty of collecting large-scale paired images, while existing synthetic approaches often suffer from limited realism or inconsistencies between bare and makeup images.\nCurrent synthetic methods typically fall into two categories: warping-based transformations and text-to-image generation. The former often distorts facial geometry and compromises makeup precision, while the latter tends to alter facial identity and expression, undermining consistency.\nIn this work, we present FFHQ-Makeup, a high-quality synthetic makeup dataset that pairs each identity with multiple makeup styles while preserving facial consistency in both identity and expression. Built upon the diverse FFHQ dataset, our pipeline transfers real-world makeup styles from existing datasets onto 18K identities by introducing an improved makeup transfer method that disentangles identity and makeup. Each identity is paired with 5 different makeup styles, resulting in a total of 90K high-quality bare–makeup image pairs.\nWe release FFHQ-Makeup as the first large-scale, multi-style, paired bare–makeup dataset, which we expect will serve as a valuable resource for future research in beauty-related tasks.", "tldr": "", "keywords": ["Makeup dataset", "Synthetic Dataset", "Makeup transfer", "3D Morphable Model"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a97b69958f0b027da993b8477b3e55ad192dc499.pdf", "supplementary_material": "/attachment/32b1f4b0384a5cf32a7027aabeb735e649e2c65b.zip"}, "replies": [{"content": {"summary": {"value": "This paper constructs a new facial makeup dataset, named FFHQ-Makeup, to support the research in the area of face image beautification and aesthetic analysis. The key idea is to disentangles identity and makeup so multiple makeup styles can be rendered while preserving facial consistency in both identity and expression. The constructed FFHW-Makeup dataset contains 90K (18Kx5) images, which could serve as a valuable resource for future research in face-related vision research."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Originality. I think simultaneous rendering of multiple makeup images has its novelty. To my knowledge, most previous methods only studied the single output scenario. Single-in-Multiple-out has its merit due to the large scale and diversity.\nQuality. The reported experimental results as shown in figures and tables generally support the superiority of the proposed method to the baseline/benchmark methods.\nClarity. The paper is easy to follow and understand its contributions.\nSignificance. The constructed dataset will be a valuable contribution to support facial beauty-related research in computer vision."}, "weaknesses": {"value": "1. Generally speaking, the technical depth of a paper on dataset construction is shallow. This paper is based on known style transfer techniques and does not develop new algorithms or tools. The novelty can be at most argued at the system or application level.\n2. I think the biggest weakness of this work lies in the significance part. It is difficult to advocate for a paper with a relatively narrow technical scope (e.g., face beautification). The ultimate impact along this line of research is limited.\n3. Relevance to ICLR. If I were the authors, I would submit this work to CV conferences including biometrics (e.g., FG2025). I don't think face beauty-related work will attract wide interest from the ICLR attendees.\n4. Literary presentation. There are several places authors could have polished - e.g., the lack of balance between background and new contribution in abstract write-up, the conciseness of Sec. 3.2 (Method), Fig. 8 appears before Fig. 7, and the shortage of material in Appendix."}, "questions": {"value": "1. What modification to 3DMM did you adopt for the makeup transfer to work? If any, I think this could be some contribution you can claim and elaborate on.\n2. Can this line of research be extended into other style transfer of face images than makeup (e.g., aging, expression, race, and gender)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "p2JG69Cayl", "forum": "dMFKprC7vR", "replyto": "dMFKprC7vR", "signatures": ["ICLR.cc/2026/Conference/Submission14896/Reviewer_1uty"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14896/Reviewer_1uty"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14896/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760724480096, "cdate": 1760724480096, "tmdate": 1762925241666, "mdate": 1762925241666, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a high-quality synthetic makeup dataset FFHQ-Makeup, which pairs each identity with multiple makeup styles while preserving facial consistency in both identity and expression. In order to achieve that, they introduce an improved makeup transfer method that disentangles identity and makeup and transfers real-world makeup styles from existing datasets onto 18K identities upon the diverse FFHQ dataset. Evaluations show that FFHQ-Makeup outperforms existing datasets in both visual quality and facial consistency."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Dataset contribution. This work onstructs a large-scale high-quality and multi-style paired makeup dataset, which would benefit a wide range of future makeup-related research and applications."}, "weaknesses": {"value": "1. Limited technical novelty. The pipeline mainly relies on the existing model Stable-Makeup. The data construction pipeline appears to merely process existing data using off-the-shelf models, without addressing any substantive technical challenges.\n2. Insufficient motivation and lack of interpretability. The ablation study focus on two variants of feature extraction: makeup residual and sampling and re-rendering augmentation. This appears to be only a minor modification of the module, which seems more like an engineering adjustment, and there seems to be no explanation in the methods or experiments section regarding the motivation or justification for this change.\n3. Insufficient dataset evaluation. Relying solely on large models for dataset evaluation lacks stability. Furthermore, the evaluation prompts are overly simplistic and fail to provide the models with clear scoring criteria for assessing makeup realism and facial consistency, resulting in low reliability of the evaluation results.\n4. Lack of quantitative comparison in ablation study.\n5. The document layout does not conform to the required formatting guidelines; it must be set in a single-column format."}, "questions": {"value": "1. What's the motivation of the improvements in both facial structure control and makeup feature extraction?\n2. How is the score for Facial Consistency on the FFHQ-Makeup dataset? Has it been compared with other datasets?\n3. Could any other evaluation metrics beyond large models be provided to assess the dataset quality?\n4. Is there quantitative comparison results for ablation study？\n5. For the two key improvements in both facial structure control and makeup feature extraction, it seems that only the ablation results of makeup feature extraction are provided. Is there ablation results of facial structure control?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "RTo7V1Hk3I", "forum": "dMFKprC7vR", "replyto": "dMFKprC7vR", "signatures": ["ICLR.cc/2026/Conference/Submission14896/Reviewer_jFz8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14896/Reviewer_jFz8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14896/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761732230464, "cdate": 1761732230464, "tmdate": 1762925241130, "mdate": 1762925241130, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces FFHQ-Makeup, a large-scale synthetic paired makeup dataset built upon FFHQ. The authors propose a 3D Morphable Model (3DMM)-guided pipeline that disentangles facial structure from makeup appearance. The dataset aims to provide high facial consistency while maintaining makeup realism and style diversity."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The dataset construction pipeline is well-structured and combines multiple techniques to improve facial consistency.\n- The paper provides thorough ablation studies and qualitative comparisons against existing synthetic datasets, showing clearer visual fidelity and identity preservation.\n- The public release of such a large paired dataset could be beneficial for downstream research in makeup transfer and facial analysis."}, "weaknesses": {"value": "- Limited novelty. The work primarily extends existing diffusion-based makeup transfer pipelines with 3DMM-based residual computation. While this combination is technically reasonable, it appears more as an incremental improvement rather than a conceptual breakthrough. The paper could better clarify what is fundamentally novel about the method compared to previous synthetic data generation approaches.\n- In addition, insufficient validation on downstream tasks. The dataset is evaluated mainly on perceptual metrics and user preference studies, but there is no demonstration of how using FFHQ-Makeup actually improves performance on downstream tasks such as makeup transfer, face recognition, or virtual try-on.\n- Structural distortion in synthetic faces. Although the paper emphasizes facial consistency, examples show that facial geometry can subtly change after generation. These deformations may be inherent to the diffusion-based synthesis pipeline, but they raise concerns about whether such synthetic pairs truly reflect consistent identity and structure. The paper acknowledges these issues but does not quantify their impact or provide mitigation analysis.\n- Unclear handling of partial makeup in FFHQ. Since many faces in FFHQ likely contain light or partial makeup, it is questionable whether applying synthetic makeup on top of already makeup-bearing faces introduces unintended compounding artifacts. The paper briefly mentions manual filtering (Appendix Fig. 10) but does not clarify how consistently this issue is addressed or how many such cases remain."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NhHA5uzvaZ", "forum": "dMFKprC7vR", "replyto": "dMFKprC7vR", "signatures": ["ICLR.cc/2026/Conference/Submission14896/Reviewer_3fvG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14896/Reviewer_3fvG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14896/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761915640130, "cdate": 1761915640130, "tmdate": 1762925240502, "mdate": 1762925240502, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper releases FFHQ‑Makeup, a synthetic paired bare–makeup dataset built by transferring makeup from real sources onto FFHQ faces. The pipeline builds on Stable‑Makeup/FreeUV with three ingredients: reconstruct a bare face from a makeup image using 3DMM fitting; compute a 3DMM‑based “makeup residual” and re‑render it on target geometry for style disentanglement; and apply mask‑guided background blending plus extensive manual filtering. The resulting dataset contains 18K identities, each paired with five makeup styles. Quality is assessed via identity/semantic similarity metrics (ArcFace, DINO‑I, SSIM) on pairs, ablations of residual/augmentation, and an automated visual preference study using VLMs (GPT‑4o, Gemini 2.5, Claude) on a small subset. The paper claims better facial consistency and comparable realism to prior synthetic resources (e.g., LADN‑Syn, BeautyBank) and positions the dataset as a general resource for makeup transfer, VTO, and related tasks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- Scale and structure: reasonably large, paired, multi‑style dataset; pairs are useful for supervised training and controlled evaluation.\n- Clear construction pipeline with pragmatic engineering (3DMM‑based residual, re‑rendering augmentation, background blending) and documented manual cleaning.\n- The paper is clearly written and acknowledges several remaining limitations (e.g., bias toward daily styles, 3DMM/segmentation artifacts)."}, "weaknesses": {"value": "- Utility not convincingly demonstrated. A dataset paper should show that training models on the new data substantially improves downstream tasks (e.g., makeup transfer, virtual try‑on, recognition under makeup) against strong baselines and across public test sets. The paper lacks such end‑task training/evaluation; results are mostly pairwise similarity and small‑scale preference checks, which do not establish practical value.\n- No human evaluation. All “preference” judgments use VLMs on ~50 groups, which are not a substitute for human raters and can be biased by prompts or model idiosyncrasies. A user study assessing realism, identity/expression preservation, and artifact rate is essential for a perceptual domain like makeup.\n- Limited fairness and coverage analysis. FFHQ provides diversity, but the paper does not quantify demographic distributions and performance disaggregations (skin tone, age, gender presentation). For a face dataset, absence of such analysis is a major gap.\n- Modest novelty. The pipeline is an incremental engineering combination over Stable‑Makeup/FreeUV/ControlNet with 3DMM fitting and residual re‑rendering; as a dataset contribution, this is fine, but then the burden of proof shifts to rigorous evidence of utility (missing here).\n- Evaluation scope and rigor. Identity/semantic similarity metrics are reported, but there is no cross‑dataset generalization (train on FFHQ‑Makeup, test on real‑world sets), no comparisons under challenging conditions (extreme styles, occlusions), and no stress/failure analysis beyond a few visuals. The VLM preference study uses unfiltered outputs and a small sample; sensitivity to prompt/model choice is not examined."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["Yes, Discrimination / bias / fairness concerns", "Yes, Privacy, security and safety", "Yes, Potentially harmful insights, methodologies and applications"]}, "details_of_ethics_concerns": {"value": "The work releases a large facial dataset derived from real identities; demographic balance and subgroup performance are not analyzed, and there is no human oversight study. Potential misuse includes identity manipulation and appearance‑based profiling."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "iUQk4k05Ak", "forum": "dMFKprC7vR", "replyto": "dMFKprC7vR", "signatures": ["ICLR.cc/2026/Conference/Submission14896/Reviewer_pEds"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14896/Reviewer_pEds"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14896/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762050370203, "cdate": 1762050370203, "tmdate": 1762925239015, "mdate": 1762925239015, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}