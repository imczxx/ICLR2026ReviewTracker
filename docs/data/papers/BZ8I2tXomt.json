{"id": "BZ8I2tXomt", "number": 12913, "cdate": 1758211588170, "mdate": 1759897477017, "content": {"title": "Sharpness-Aware Machine Unlearning", "abstract": "We characterize the effectiveness of Sharpness-aware minimization (SAM) under machine unlearning scheme, where unlearning forget signals interferes with learning retain signals. While previous work prove that SAM improves generalization with noise memorization prevention, we show that SAM abandons such denoising property when fitting the forget set, leading to altered generalization depending on signal strength. We further characterize the signal surplus of SAM in the order of signal strength, which enables learning from less retain signals to maintain model performance and putting more weight on unlearning the forget set. Empirical studies show that SAM outperforms SGD with relaxed requirement for retain signals and can enhance various unlearning methods either as pretrain or unlearn algorithm. Motivated by our refined characterization of SAM unlearning and observing that overfitting can benefit more stringent sample-specific unlearning, we propose Sharp MinMax, which splits the model into two to learn retain signals with SAM and unlearn forget signals with sharpness maximization, achieving best performance. Extensive experiments show that SAM enhances unlearning across varying difficulties measured by memorization, yielding decreased feature entanglement between retain and forget sets, stronger resistance to membership inference attacks, and a flatter loss landscape. Our observations generalize to more noised data, different optimizers, and different architecures.", "tldr": "We reveal the effectiveness of sharpness-aware minimization in machine unlearning; we extend existing theory to provide refined characterization of SAM in unlearning, and propose novel algorithm based on detailed empirical results.", "keywords": ["Machine Unlearning", "Sharpness-Aware Minimization"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/732e84b224f00abf2a6c4c1521e57bcb4e5aaf8e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes using SAM for unlearning. They provide theoretical evidence in support of their proposition as well as experimental evaluations that substantiate their claims. The authors also point out that unlearning difficult examples is facilitated by overfitting and as a result the propose Sharp MinMax, a novel algorithm that utilizes this observation."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "The paper has several contributions.\n\nFrom a theoretical standpoint:\n\nThey show that for the negative gradient unlearning method one can minimize the test error for SAM always under proper assumptions, while this is not the case when someone uses SGD, which is interesting.\n\nFrom a heuristics standpoint:\n\nBased on their theoretical findings and that SAM fails to remove noise for the forget set unlike its behavior for the retain they suggest a sharp minimax algorithm with the purpose of overfitting to the minima in order to unlearn the samples of the forget set effectively. The idea of overfitting is in general an interesting proposition.\n\nFrom an empirical standpoint:\n\nThe paper provides extensive experimental evaluations of the methods over multiple datasets. With respect to the ToW metric they provide SOTA performance, making the empirical findings substantial in support of their claims.\n\nThe paper also provides a study on the effect of the weighting $\\alpha$ of the negative gradient method, for SGD and SAM based methods which can be beneficial for the community."}, "weaknesses": {"value": "The main weakness that I find in the paper is an assumption that is made implicitly but yet not discussed substantially. The assumption is the following: \"Conversely, a sample i ∈ F of class j, which we want to predict −j in unlearning\" as stated in line 217. Although this is some times the case a lot of the time it is not and recent works [1],[2] have demonstrated that empirically and theoretically respectively this assumption will lead to an \"illusion\" of unlearning where the model does not behave as an oracle model that has never seen the data in the Forget set. This can be remedied with a relevant discussion or a clarification as there are unlearning settings where this assumption actually holds necessarily by definition as they clarify in [3] for the RB or RC unlearning scenarios.\n\nDespite the aforementioned weakness which is inherent in some part of the unlearning literature, in my opinion, I find the idea that one unlearns by overfitting in the retain or through SAMs property of dealing with noise in the retain but not in the forget intriguing.\n\nAdditionally I would like to mention a minor weakness in my opinion which is less significant and deducts from the presentation of the work. At line 470 the authors state that the experimental evaluations verify their claim. Since the claim about $\\alpha$ does not have an extensive proof I believe that the correct term would be that it supports, instead of \"This verifies our claim that α depends more than retain-forget ratio.\"\n\n[1] Attribute-to-Delete: Machine Unlearning via Datamodel Matching, Kristian Georgiev, Roy Rinberg, Sung Min Park, Shivam Garg, Andrew Ilyas, Aleksander Madry, Seth Neel\n\n[2] Ascent Fails to Forget, Ioannis Mavrothalassitis, Pol Puigdemont, Noam Itzhak Levi, Volkan Cevher\n\n[3] Towards Unbounded Machine Unlearning, Meghdad Kurmanji, Peter Triantafillou, Jamie Hayes, Eleni Triantafillou"}, "questions": {"value": "My main questions involve the weaknesses that I issued above.\n\n1. In [1] the authors introduce as a metric for successful unlearning KLoM. Does SAM achieve an improved KLoM when using Negative Gradient in comparison to the SGD alternative?\n2. Does SAM resolve the issues raised about data dependencies between retain and forget as raised in [2]?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uu2HNiELSs", "forum": "BZ8I2tXomt", "replyto": "BZ8I2tXomt", "signatures": ["ICLR.cc/2026/Conference/Submission12913/Reviewer_Ti1T"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12913/Reviewer_Ti1T"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12913/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760456970274, "cdate": 1760456970274, "tmdate": 1762923686240, "mdate": 1762923686240, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a theoretical and empirical investigation of machine unlearning through the perspective of sharpness-aware optimization. The paper studies how SAM, originally designed to improve generalization, behaves under unlearning scenarios that involve conflicting forget and retain signals."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors develop a signal–noise decomposition framework to analyze how SAM and SGD behave when learning (retain) and unlearning (forget) signals interact, giving novel insights on how SAM affects unlearning performance.\n2. The paper further proposes Sharpness MinMax, a novel optimization method that improves machine unlearning performance.\n3. The effectiveness of the proposed method is evaluated on multiple datasets. The paper also gives additional evaluations such as feature entanglement and privacy evaluations."}, "weaknesses": {"value": "1. For the evaluation metrics, run-time evaluations are missing. Employing SAM on both forget and retain loss might significantly increase run time, and this efficiency trade-off should be evaluated.\n\n2. Evaluations of unlearning robustness are missing, such as evaluating the performance of the unlearned models against relearning attacks [1]. Sharpness-aware minimization employed in LLM unlearning [2] increases the robustness of the unlearned models against relearning by perturbing the model with a 'worst-case' perturbation at each optimization step. In light of [2], does Sharp MinMax decrease the robustness of unlearning by maximizing the sharpness of the forget loss? I think this concern should be studied in this paper. \n\n3. There are limited explanations on the weight mask design for Sharp MinMax. The authors use 5 % cutoff for ImageNet and 30 % cutoff for CIFAR‑100. However, it seems that there are no explanations or ablation studies on this.\n\n4. Please refer to the questions for additional concerns.\n\n[1] From Dormant to Deleted: Tamper-Resistant Unlearning Through Weight-Space Regularization\n\n[2] Towards LLM Unlearning Resilient to Relearning Attacks: A Sharpness-Aware Minimization Perspective and Beyond"}, "questions": {"value": "1. In Section 3.2, line 290-294: Could the authors explain the motivation of this weight mask design, and why it is different from SalUn [1]?\n2. I think a rather important baseline is missing in the experiments: performing SAM on the retain loss only. According to the paper, this should improve retain performance without degrading forget performance. Additionally, this can be more efficient in run-time compared to Sharp MinMax. By comparing this baseline to Sharp MinMax, the authors can show the effectiveness of sharpness maximization on the forget loss. Could the authors explain why they did not include this baseline in the experiments?\n\n3. Could the findings in this paper be extended to machine unlearning in image generation tasks [1]? This could greatly enhance the soundness of the proposed method. \n\n[1] https://arxiv.org/pdf/2310.12508"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gZmBZOqipV", "forum": "BZ8I2tXomt", "replyto": "BZ8I2tXomt", "signatures": ["ICLR.cc/2026/Conference/Submission12913/Reviewer_F8sS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12913/Reviewer_F8sS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12913/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760699170275, "cdate": 1760699170275, "tmdate": 1762923685976, "mdate": 1762923685976, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper revisits Sharpness-Aware Minimization (SAM) in the context of machine unlearning (under the NegGrad unlearning framework) and demonstrates that SAM exhibits a desirable property in distinguishing between the retain and forget sets, as the forget set tends to overfit. The analysis is conducted using a simple two-layer CNN setup. The authors further observe that incorporating SAM into NegGrad allows effective unlearning with a smaller ratio between the retain and forget sets. Experimental results consistently show that SAM-augmented methods outperform their counterparts that do not employ SAM regularization."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper provide in-depth theoretical analysis on how SAM would impact the unlearning quality.\n2. Experiments contains sufficient evidence on how well SAM argumented model performs compared to the original classic unlearning methods."}, "weaknesses": {"value": "1. The paper is not well polished and contains numerous grammatical errors and excessive notation, which makes it difficult to read. While analytical papers often introduce complex notation to convey ideas precisely, this paper’s presentation suffers from a combination of grammar issues, overly long sentences, and vague explanations. A few specific examples:\n    1. Equation 8 and corresponding description is very vague, and I cannot get how this equation is used in the proposed work. Is it on forget set right? How it connects to all the description in 3.1? There is no sufficient connection given here. \n    2. Line 115: Each image consists of ..... This sentence is long, contains grammar error, and it is not parsable. \n    3. Definition of noise coefficients $\\xi_{j,r,i}^{(t,b)}$. I got totally lost with such type of notions. I think it is unnecessary notation complexity introduced; without them, the paper reads fine.\n\n2. The use of Sharpness-Aware Minimization (SAM) in unlearning is not new. The claimed contribution of this work is therefore unclear. If the main purpose is to provide analysis, the key takeaway appears to be that SAM allows unlearning with a smaller retain set. However, in practice, the exact ratio of the retain set is not a major bottleneck in most unlearning scenarios. The authors should justify why this analysis provides meaningful new insight or practical benefit compared to prior work.\n\n3. All experimental results are reported solely using the ToW metric, which does not appear to be a standard evaluation measure for unlearning. While introducing a new metric can be valuable, the absence of established unlearning metrics (e.g., retention accuracy, forgetting efficacy, or relearning resistance) raises concern. It remains unclear whether SAM genuinely improves unlearning performance in practice. A broader evaluation would be needed to substantiate the claimed advantages."}, "questions": {"value": "Where equation 8 is used in the proposal eventually? Is it used to train on forget set?\nWhy is the discovery of smaller ratio $\\alpha$ such useful? Is it generalizable to other unlearning algorithms? or those with gradient descent/ascent only?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5JmEEIP02o", "forum": "BZ8I2tXomt", "replyto": "BZ8I2tXomt", "signatures": ["ICLR.cc/2026/Conference/Submission12913/Reviewer_U1T3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12913/Reviewer_U1T3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12913/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761749086090, "cdate": 1761749086090, "tmdate": 1762923685682, "mdate": 1762923685682, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigate the idea of sharpness aware optimization for the machine unlearning, they characterize SAM under NegGrad unlearning and the theoretical study of bounding and choosing weight factors. The paper provides a comprehsive theoretical proof to show that SAM can acheive successful unleasrning with significantly smaller damage to the retain accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Theoretical analysis of SAM is robust. The paper has done a good job of analyzing it in relation to Random Labeling and especially NegGrad. I appreciate they were honest about SAM+NegGrad giving worse forget accuracy than SGD+NegGrad before their discussion of overfitting."}, "weaknesses": {"value": "1. UMAP Visualization Clarity\nThe UMAP visualizations are difficult to interpret. For instance, Figure 1 is intended to illustrate inter- and intra-class movements after unlearning; however, these differences are not visually discernible. The colors used are too similar, and the expected variations are not immediately perceptible. I recommend improving visual clarity by adopting a more distinct color palette, varying marker shapes, or explicitly highlighting changes using arrows, circles, or other annotations. This would make the patterns of change more evident to the reader.\n\n2. ToW Score Chart Interpretation\nWhile the chart presenting the ToW scores supports the claim that SAM is an effective optimization method, it lacks fine-grained detail. Including additional breakdowns or complementary metrics could help the reader better understand how SAM contributes to performance improvements beyond the aggregated ToW score.\n\n3. Reporting Underlying Accuracy Metrics\nThe paper notes that SAM+NegGrad achieves higher forget-set accuracy than SGD+NegGrad, but these results are only reflected indirectly through the ToW score. It would strengthen the analysis to report the individual accuracy components that contribute to ToW alongside it. Relying solely on a composite metric can obscure nuances in model behavior; providing detailed accuracy values would enable a clearer assessment of the unlearning method’s performance.\n\n4. Lack of Statistical Evaluation\nThe reported results appear to lack statistical evaluation—no mean or standard deviation values are provided (e.g., in Tables)."}, "questions": {"value": "The memorization classes F(high) etc. do not seem to follow a linear pattern in the ToW scores. For instance sometimes mid has the highest score, sometimes mid has the lowest score. Why should we believe that memorization is a worthwhile way to classify these different forget sets if they don't have a clear correlation to increasing difficulty?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XJG5E7dlrr", "forum": "BZ8I2tXomt", "replyto": "BZ8I2tXomt", "signatures": ["ICLR.cc/2026/Conference/Submission12913/Reviewer_pWni"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12913/Reviewer_pWni"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12913/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972121676, "cdate": 1761972121676, "tmdate": 1762923685384, "mdate": 1762923685384, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}