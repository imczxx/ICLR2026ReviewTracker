{"id": "utVraPnnZw", "number": 18955, "cdate": 1758292333376, "mdate": 1759897070989, "content": {"title": "GAPA: Post-Hoc Uncertainty Quantification for Pre-Trained Models via Activation-Space Gaussian Processes", "abstract": "Weight-space uncertainty methods (BNNs, ensembles, Laplace) are difficult to apply post-hoc to frozen foundation models due to retraining requirements or prohibitive second-order computations. We introduce Gaussian Process Activations (GAPA), which replace deterministic activations with Gaussian processes whose prior mean equals the original nonlinearity—preserving predictions exactly while adding principled epistemic uncertainty. Using a 1-nearest-neighbour FITC surrogate with FAISS, GAPA yields closed-form, distance-aware uncertainties with $O(\\log M)$ retrieval and $O(d)$ per-layer compute without sampling. Across regression, classification, segmentation, and language modelling (including GPT-2, 124M), GAPA matches or exceeds deep ensembles and Laplace in calibration and OOD detection while running 10–100× faster at test time. GAPA uniquely enables post-hoc deployment, single-pass inference, exact mean preservation, and scalable epistemic UQ for frozen backbones.", "tldr": "We introduce GAPA, a novel method that adds single-pass, scalable uncertainty to frozen neural networks by modeling activations with Gaussian Processes.", "keywords": ["Uncertainty quantification", "Gaussian processes", "post-hoc methods", "epistemic uncertainty", "neural network activations", "foundation models", "calibration", "out-of-distribution detection"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2f4a1d5626ffab2785b06260b4ccfcceb635bcde.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposed using GP in the activation layer to estimate uncertainty and with strong theories guarantee"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. this paper proposed a method that applied into activation layer \n2. Adds uncertainty to any frozen model without modifying trained weights or requiring gradient updates/fine-tuning, making it suitable for “large model reuse” scenarios\n3. Validated across regression, classification, segmentation, and language modeling tasks; multiple metrics matched or outperformed strong baselines, demonstrating the method's versatility"}, "weaknesses": {"value": "1. High-dimensional scenarios require a large number of induction points\n2. Requires caching a large number of intra-layer activations and constructing/persisting FAISS indexes\n3. Single-neighbor FITC makes variance determined almost solely by the “distance to the nearest cache activation,” if the activation spatial metric is not aligned with the actual distribution drift\n4. **Please use ICLR template!!!**"}, "questions": {"value": "please check weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "EdlYStp8Zc", "forum": "utVraPnnZw", "replyto": "utVraPnnZw", "signatures": ["ICLR.cc/2026/Conference/Submission18955/Reviewer_f3W9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18955/Reviewer_f3W9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18955/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761952585447, "cdate": 1761952585447, "tmdate": 1762931009766, "mdate": 1762931009766, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Gaussian Process Activations (GAPA), a novel post-hoc uncertainty quantification method for frozen pre-trained models that avoids the retraining or high computational costs of traditional weight-space techniques. GAPA replaces deterministic activations with Gaussian Processes, using a scalable 1-nearest-neighbour FITC surrogate to add principled, distance-aware epistemic uncertainty while perfectly preserving the original model's mean predictions. The method matches or exceeds existing baselines on calibration and OOD detection across regression, classification, and language tasks, offering a fast, single-pass inference solution."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper addresses a critical and practical need for fast, scalable, post-hoc uncertainty quantification for pre-trained foundation models.\nInstead of focusing on the intractable weight space, it proposes a novel shift to modeling uncertainty in the activation space. The GAPA formulation, which preserves the backbone's mean predictions while adding principled epistemic uncertainty via a GP, seems a creative idea. The claims are well-supported both theoretically and empirically, showing good performance across a diverse set of tasks (regression, classification, segmentation, LLM token corruption) and models (ResNet, U-Net, GPT-2, LLaMA-3.2 ).\nThe paper is well-written, and the core concepts are communicated clearly."}, "weaknesses": {"value": "1. The GP hyperparameters (length-scale, amplitude) are set via empirical statistics (e.g., median pairwise distance) rather than optimization. While this is fast, the paper lacks a sensitivity analysis. It is unclear how robust the method's calibration and OOD detection are to this specific heuristic, especially in activation spaces with non-uniform density.\n\n2. Using the first-order Delta method for variance propagation is a key approximation in the paper. However, this approximation could be inaccurate for very deep architectures. The authors haven't discussed under which scenario this approximation could fail. Adding a dicussion about that could be beneficial."}, "questions": {"value": "1. Could the authors elaborate on the instability observed with the \"Variant B\" attention propagation? This is a key finding. Does this point to a more general fragility of first-order Delta method propagation in deep transformers? Furthermore, does \"Variant A\" risk systematically underestimating the propagated uncertainty, even if it is more stable?\n\n2. The 1-NN surrogate bases the entire epistemic uncertainty on a single cached activation. This seems potentially high-variance in high-dimensional spaces. Have the authors considered a $k$-NN variant or a local sparse GP (for example $M=10$) as a more robust alternative to the $M=1$ approximation?\n\nMinor:\nM3 section: \"Random vs Futhers Point Sampling\" \nline 410: it's likely --> it is likely"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yiar1qGrCE", "forum": "utVraPnnZw", "replyto": "utVraPnnZw", "signatures": ["ICLR.cc/2026/Conference/Submission18955/Reviewer_PkPt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18955/Reviewer_PkPt"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18955/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993795968, "cdate": 1761993795968, "tmdate": 1762931009064, "mdate": 1762931009064, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a post-hoc UQ technique termed GAPA. GAPA replaces deterministic activations in existing layers in a pretrained model with gaussian activations where the mean is the same as the pretrained network activations and the variance is calculated as follows (i) the authors pass the training dataset through the frozen network and store the activations, and (ii) the nearest neighbor for a test datapoint is retrieved and the kernel distance between the retrieved data point and test data point is calculated. This distance populates the posterior variance. The variance is propagated (each layer requires a customized propagation)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. **Intuitive method:** The authors propose an intuitive methodology to introduce variance in activations. \n\n2. **Clarity**: The paper is well written. Additionally, the figures (especially both parts of Fig 2) instantly communicate the method well.\n\n3. **Problem settings**: Across the paper, the authors mention multiple times that the underlying predictions must remain the same. This is highly appreciated. Multiple papers that perform UQ change the training regimen that substantially decreases the primary objective of the network.\n\n4. **Diverse results**: The authors showcase results on regression, image classification, and language token prediction across multiple metrics."}, "weaknesses": {"value": "1. **Definition of Epistemic Uncertainty**: How are the authors defining their GAPA uncertainty estimation? The authors cite the distance-aware UQ method SNGP [1]. SNGP assumes that distances are preserved (and enforces it via bi-lipshitz constraints) so that the variance approximation head is a `distance' measure. The results are showcased for OOD detection where it is clear that OOD data is distant from the training distribution. Granted that SNGP is more restrictive and leads to original performance loss [2] which the authors are explicitly accounting for. However, I cannot seem to summarize GAPA in a similar way, connecting the definition of the uncertainty measured vs its demosntration in the results. The variance propagation stage (line 229) introduces additional terms (this was not motivated before). It is unclear to me what the authors are finally measuring (parameter uncertainty? aleatoric uncertainty? distance awareness? or sensitivity analysis?). \n\n2. **Result comparisons**: In my opinion, GAPA is a distance-aware UQ estimate (similar to SNGP) rather than Last layer laplace (LLL) and variants. As such, I am unsure why most of the results are compared against LLL and variants. There are a very large number of gradient-based post-hoc OOD estimators (that also provide UQ) [ex: 3,4]. Additionally, I would point the authors towards trust quantification techniques [5] that also do something similar (nearest neighbor to a subset of training data)\n\n3. **Layer-wise variance propagation**: Since the method requires variance propagation, individual types of layers must have their own GAPA add-ons. This makes the proposed method a bit more complex for application by the community as it is not a plug and play method. \n\n4. **Robustness**: It is unclear how well the frozen network must be trained to obtain a good UQ estimate. For instance, MNIST and FMNIST are easy datasets and the underlying model performs very well (are maybe overfit). Distance-based methods perform well here. More difficult datasets have issues with good distance estimations. Please note that I am talking about the model being very well trained on simple datasets rather than the robustness experiments with the rotated MNIST that the authors showcase.\n\n[1] Simple and Principled Uncertainty Estimation with Deterministic Deep Learning via Distance Awareness\n\n[2] Transitional Uncertainty with Layered Intermediate Predictions\n\n[3] On the Importance of Gradients for Detecting Distributional Shifts in the Wild\n\n[4] Counterfactual Gradients-based Quantification of Prediction Trust in Neural Networks\n\n[5] To Trust Or Not To Trust A Classifier"}, "questions": {"value": "Please see the weaknesses. Specifically,\n\n1. What uncertainty estimate does GAPA provide?\n\n2. Why are the authors comparing against mostly LLL variants? \n\n3. Can the authors showcase results for early stopping which is a well known UQ technique so as to show the robustness? I understand that the primary objective (accuracy) may reduce.\n\n4. It will be good to showcase failure instances, either because of the 1-NN approximation or any other approximation in variance propagation"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "T3LX9ivK72", "forum": "utVraPnnZw", "replyto": "utVraPnnZw", "signatures": ["ICLR.cc/2026/Conference/Submission18955/Reviewer_cyz2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18955/Reviewer_cyz2"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18955/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762387006679, "cdate": 1762387006679, "tmdate": 1762931007839, "mdate": 1762931007839, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes an approach for applying post-hoc uncertainty quantification to trained, frozen networks. The main idea is that the epistemic uncertainty is modeled in the network's activation space using Gaussian Processes (GPs), while the initial model's mean prediction is preserved. The method builds on established GP theory, and makes use of recent computational tricks in order to propose a practical algorithm."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- the fact that the mean prediction is preserved decouples effectively the main task from the uncertainty quantification task\n\n- the method exhibits a very competitive performance, especially on regression benchmarks\n\n- the proposed 1-Nearest-Neighbor Fully Independent Training Conditional (FITC) approximation allows for obtaining a variance estimate with log query-time complexity down from a cubic time GP regression thanks to the use of FAISS"}, "weaknesses": {"value": "- the \"principled epistemic uncertainty\" claim has at least two weak points; the first one, which is generally assumed for practical reasons, is about treating the neurons in the same layer as conditionally independent. Although adopting this approach is common and understandable, it does not make the method \"principled\". Secondly, and more importantly, the variance propagation through an attention layer is buried in K.3 despite its major impact on LLM uncertainty estimation. The principled variant B is abandoned for complexity/\"compounding\" reasons, and variant A is proposed. However, this latter is a surrogate which treats the weights as deterministic constants.This implies that the method's uncertainty propagation in a transformer disregards completely the QK dot products, which are a significant (if not the most significant) source of uncertainty. This problem should be dug up from the appendix and discussed as it is a critical limitation and significantly weakens the scope of the algorithm\n\n- the experiments highlight a NLL/OOD tradeoff which the document ignores to discuss. In Table 2, the method achieves SOTA OOD-AUC, while lagging in NLL behind MAP. However, Table 8 shows that the best NLL is obtained by placing GAPA only at level 3, while stacking GAPA at all layers provides the worst NLL while maintaining the SOTA OOD perf. This implies a tradeoff based on inflating the variance which is beneficial for OOD detection but detrimental to in-D calibration, making the model underconfident. The present setup seems optimized for OOD at the expense of NLL, a fact which is clearly important and swept under the carpet."}, "questions": {"value": "Please discuss and address the two main weaknesses mentioned above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "nothing to worry about"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PaGfEV5Ivv", "forum": "utVraPnnZw", "replyto": "utVraPnnZw", "signatures": ["ICLR.cc/2026/Conference/Submission18955/Reviewer_A4X3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18955/Reviewer_A4X3"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18955/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762470765393, "cdate": 1762470765393, "tmdate": 1762931007404, "mdate": 1762931007404, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}