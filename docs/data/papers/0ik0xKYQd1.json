{"id": "0ik0xKYQd1", "number": 5426, "cdate": 1757908438590, "mdate": 1759897976097, "content": {"title": "LiNC: Lightweight Noise Correction via Adaptive Label Refinement", "abstract": "Medical imaging datasets often contain label noise due to factors such as inter-rater variability, annotation errors, and ambiguous cases, which may severely undermine the reliability and clinical effectiveness of machine learning models trained using those datasets. To address this challenge, we introduce Lightweight Noise Correction (LiNC), which is an intuitive and powerful approach that assigns a trainable trust parameter, $\\alpha_i$, to each individual training sample. Initially initialized to fully trust the observed labels, these parameters adaptively shift trust towards model predictions through a gradient-based optimization process, effectively identifying and reducing the impact of noisy labels by correcting them. After this correction process, usual model training is carried out. Our method requires minimal computational overhead, making it practical for widespread adoption in cases where noise is suspected within a dataset. Extensive evaluations on ten medical imaging datasets from the MedMNISTv2 collection reveal significant improvements in classification accuracy and AUROC across various uniform label noise levels (ranging from 0\\% to 50\\%) and robust detection of mislabeled samples, underscoring LiNC's potential to improve noisy machine learning.", "tldr": "assign each sample a trainable trust parameter that shifts from label to prediction to correct noise", "keywords": ["noise", "correction", "trust", "lightweight", "mislabels"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/81cbc0403cccf6a47faa6a06c85bb69c354843cb.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper suggests a method for network training based on noisy labels. The technique gradually 'corrects' the labels by shifting them from the original label to the predicted class."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The paper addresses an important problem of handling a training set with unreliable labels."}, "weaknesses": {"value": "The paper is not well written. The method is not well motivated and not clearly presented. An algorithm box (that is not well written) is not a replacement for a clear presentation and an algorithm motivation. Although network training based on noisy labels is a well-studied method, there is no comparison to previous works."}, "questions": {"value": "What was the noise model you used in the experiments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Hxplj7jER4", "forum": "0ik0xKYQd1", "replyto": "0ik0xKYQd1", "signatures": ["ICLR.cc/2026/Conference/Submission5426/Reviewer_hJsW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5426/Reviewer_hJsW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5426/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760590322822, "cdate": 1760590322822, "tmdate": 1762918055423, "mdate": 1762918055423, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduced a noise correction technique in mechical image classification. It leveraged a trainable parameter for each data to reduce the negative impact of samples with higher noise level. The experimental results demonstrate that the methods can sucessfully get performance improvement on ten medical datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Easy-to-plug: The methods can be directly applied in any classification framework with a plug-and-play manner. The core idea is direct and simple.\n\n2. Wide range of evaluation: The authors tested the results on ten medical datasets with many noise levels and two metrics. The benchmark is comprehensive.\n\n3. Motivation: The authors regarded alpha as \"confidence\", providing a novel perspective to the noise removal task."}, "weaknesses": {"value": "1. The novelty is limited. Although authors provided a new perspective, the core part of the methods is still linear interpolation, which is highly similar to early bootstrapping. The paper lacks clear theoretical or empirical evidence that distinguishes it from these classic methods.\n\n2. The claimed \"differentiable\" Otsu is confusing. The standard Otsu in the text is a discrete threshold selection rather than a differentiable operator.\n\n3. Unprofessional result presentation and poor figure readability. Results in Table 1 reports AUROC only at fixed epochs(2/10), rather than following the standard ML protocol of reporting test performance from the best validation checkpoint. Furthermore, Figure 1 and 2 are less informative. \n\n4. No key abliations. There is no systematic ablation on whether α continues to be updated, or alternative thresholding strategies (Otsu vs. others). Also there is no other comparison against the other baselines on the other datasets. \n\n5. The noise setting is limited. Onlyl summetric uniform label noise is tested. In medical analysis, class-dependent or instance-dependent noise is more common. There should be comparison against other baselines such as Co-teaching [1], DivideMix [2], etc. \n\n[1] Han, B., Yao, Q., Yu, X., Niu, G., Xu, M., Hu, W., ... & Sugiyama, M. (2018). Co-teaching: Robust training of deep neural networks with extremely noisy labels. Advances in neural information processing systems, 31.\n\n[2] Li, J., Socher, R., & Hoi, S. C. (2020). Dividemix: Learning with noisy labels as semi-supervised learning. arXiv preprint arXiv:2002.07394."}, "questions": {"value": "1. What is the core differences between LiNC and bootstrapping, label smoothing, and Mixup?\n\n2. What is the evidence of \"Otsu is differentiable\"?\n\n3. How would the performance go if conducting multi-round labeling and training?\n\n4. How about the robustness of the model towards hyperparameters including learning rate, warmup epochs, threshold strategies, etc?\n\n5. Why there is only one noise setting in Table 1?\n\n6. Stronger baselines are suggested to be involved."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "a9bfOQDKUp", "forum": "0ik0xKYQd1", "replyto": "0ik0xKYQd1", "signatures": ["ICLR.cc/2026/Conference/Submission5426/Reviewer_6wrZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5426/Reviewer_6wrZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5426/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761686005487, "cdate": 1761686005487, "tmdate": 1762918055118, "mdate": 1762918055118, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles label noise in medical imaging through a straightforward pre-training approach called Lightweight Noise Correction (LINC). The idea is to identify and correct mislabeled samples before standard training begins, rather than trying to handle noise during training itself.\nThe core mechanism is simple. \n1. The method assigns each training sample a learnable \"trust parameter\" $\\alpha_i \\in [0, 1]$, initially set to 1 (full trust in the label). During a short warmup phase, these parameters are updated via gradient descent alongside the model weights. The intuition is that clean labels produce low loss and small gradients, keeping $\\alpha_i$ near 1, while noisy labels generate high loss and conflicting gradients that push $\\alpha_i$ toward 0.\n2. After warmup, the authors assume the $\\alpha_i$ values have separated into a bimodal distribution—one mode for clean samples, another for noisy ones. \n3.They use Otsu's thresholding to automatically find the split point between \"trusted\" and \"suspicious\" samples. The suspicious samples then have their labels corrected (typically replaced with the model's current prediction), and the model is retrained from scratch on this cleaned dataset.\n\nThe validation is performed on ten MedMNISTv2 datasets across various noise levels (0-50%). The results show that LINC effectively identifies mislabeled samples and improves both classification accuracy and AUROC compared to baselines that either ignore noise or use existing noise-handling techniques."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper's primary strength lies in its simplicity and practical utility for a common and difficult problem.\n1. Originality and Simplicity: The paper introduces LiNC, an \"intuitive and powerful approach\"\n a. that boils the complex problem of noise correction down to a single, trainable \"trust parameter\" $\\alpha_i$ assigned to each sample\n b. This design is conceptually simple, \"lightweight\"\nc. and easy to grasp.\n2. Practicality and Ease of Use: The method is significant because it is designed for real-world use. It is \"lightweight, flexible, and can be easily incorporated into existing training... workflows\", acting as a \"plugin\" module that refines the dataset.\n3. It requires \"minimal computational overhead\", as it only \"adds one extra trainable parameter per sample\".\n4. Most importantly, it \"does not require a clean validation set or meta-set\", which is a major practical advantage, especially in domains like healthcare where such clean data is often unavailable."}, "weaknesses": {"value": "I have serious concerns about both the clarity of the methodology and the experimental validation. These issues make it difficult to assess whether the approach actually works as intended or offers any advantage over existing methods.\n1. The most troubling problem is a fundamental contradiction in how the method is described. Section 3 presents the refined label as $\\tilde{y_i} = (1-\\alpha_i) \\cdot s_i + \\alpha_i \\cdot \\tilde{y_i}​$, which appears to be circular since $\\tilde{y_i}$ appears on both sides. Algorithm 1 seems to address this by introducing an interpolated label   (Line 10), but then the loss function in Line 15 is defined as $\\mathcal{L} = l(f_\\theta(x), \\tilde{y})$ —using the original noisy label $\\tilde{y}$, not the interpolated one. This creates a fundamental problem: if the loss doesn't depend on $\\alpha_j$​, how is the gradient $\\nabla_{\\{\\alpha_j\\}} \\mathcal{L}$ in Line 19 computed, and why wouldn't it just be zero? I've read this section multiple times and cannot reconcile these descriptions. This makes the core mechanism impossible to reproduce or verify.\n\n2. The reliance on Otsu's thresholding feels equally problematic. The entire correction phase hinges on the assumption that $\\alpha_i​ values will form a clean bimodal distribution—one mode for clean samples, another for noisy ones. But the paper provides no visualizations or empirical evidence that this actually happens. Otsu's method will always produce a threshold, even if the distribution is unimodal or multimodal in unexpected ways, and in those cases the resulting split would be arbitrary. Why not use more robust clustering methods like Gaussian Mixture Models that can adapt to the actual distribution shape? The choice seems unjustified given how critical this step is to the method's success.\n\n3. My biggest concern, though, is the experimental setup. The paper never compares LINC's final classification performance against other noise correction methods. Table 1 shows noise identification metrics (comparing against AUM and similar methods), but Tables 2 and 3—which contain the main accuracy and AUROC results—only compare \"With LINC\" versus \"Without LINC.\" This is a simple baseline that tells us the method does something, but not whether it's competitive with existing approaches. The related work mentions standard techniques like bootstrapping and label smoothing, but none of these appear in the experimental comparison. Without this, I can't tell if LINC's multi-stage process offers any real advantage over simpler, well-established methods that would be far easier to implement.\nThese issues collectively make it hard to recommend acceptance. The methodological ambiguity needs to be resolved before the approach can be reproduced, and the experiments need to demonstrate clear advantages over existing noise correction techniques."}, "questions": {"value": "1. Clarification of the Core Algorithm: I am having difficulty understanding the core mechanism in Algorithm 1.\n* Line 10 calculates an interpolated label $\\tilde{I}j=(1-\\{\\alpha{j}\\})*s{j}+(\\{\\alpha{j}\\})*\\tilde{y}{j}$.\n* However, the loss function in Line 15 is defined as $\\mathcal{L}=l(f_{\\theta}(x),\\tilde{y})$, which uses the original, noisy label $\\tilde{y}$.\nIf the loss $\\mathcal{L}$ is not a function of $\\alpha_j$, how is the gradient $\\nabla_{\\{\\alpha_{j}\\}}\\mathcal{L}$ in Line 19 computed (i.e., how is it not zero)? Is Line 15 a typo, and should the loss actually be $\\mathcal{L}=l(f_{\\theta}(x),\\tilde{I}_{j})$? This seems critical to the method's function.\n\n2. Justification for Otsu's Method: The correction step in Line 13 hinges on Otsu's method, which, as noted, \"exploits bimodality\".\n* Could the authors please provide a visualization (e.g., a histogram) of the $\\alpha_i$ parameter distribution after the warmup phase? This would help validate the core assumption that the values are indeed bimodal.\n* What is the method's behavior if this assumption fails and the $\\alpha_i$ distribution is not bimodal (e.g., a single broad, unimodal smear)?\n* Could the authors justify why Otsu's method was chosen over more robust clustering methods (like a simple Gaussian Mixture Model) that might be less sensitive to this bimodal assumption?\n\n3. Absence of Comparative Baselines in Main Results: The experimental validation in Table 2 (Accuracy) and Table 3 (AUROC)  only compares the model \"With LiNC\" against \"Without LiNC\". While Table 1  compares noise identification AUROC, the main tables never compare the final model performance against other noise correction methods.\n* Why did the authors not compare LiNC's final accuracy against the established noise-correction techniques (e.g., Bootstrapping , Label Smoothing) discussed in the Related Work? Without this, it is impossible to gauge if this multi-stage method is actually more effective than simpler, standard approaches."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NYlbqwsG9w", "forum": "0ik0xKYQd1", "replyto": "0ik0xKYQd1", "signatures": ["ICLR.cc/2026/Conference/Submission5426/Reviewer_6jc6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5426/Reviewer_6jc6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5426/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762210053585, "cdate": 1762210053585, "tmdate": 1762918054771, "mdate": 1762918054771, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an adaptive label refinement method for addressing the problem of noisy labels in medical learning. The authors introduce a per-sample trust parameter, which is dynamically updated during model training. Experiments on medical datasets demonstrate the superiority of the proposed method. Thanks to its lightweight and adaptive per-sample noise modeling, the approach performs particularly well in scenarios with high label noise (~0.5)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea is clearly presented and easy to understand.\n2. The authors conduct extensive experiments on multiple medical datasets for comparison."}, "weaknesses": {"value": "1. The presentation of the results is unclear. For example, in Table 2, the meaning of the arrow symbols is not explained.\n2. The title should include the keyword “Medical.” Without it, the title is misleading, as it implies a general adaptive label refinement method rather than one specific to medical data.\n3. In the algorithm, $\\alpha_j$ in Line 6 is not defined. There are several different $\\alpha$ terms, which makes the notation confusing.\n4. In the algorithm, Line 18 should read “if epoch > $w$” instead.\n5. The authors should provide more discussion regarding the source of supervision."}, "questions": {"value": "1. The proposed method appears somewhat counterintuitive. The authors should further explain why introducing a new trainable parameter can lead to performance improvements.\n2. How does the proposed method behave on clean datasets? Since the parameter is adaptive, one would expect it to converge to all 0s or all 1s in the absence of label noise."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4alv4ZuYnQ", "forum": "0ik0xKYQd1", "replyto": "0ik0xKYQd1", "signatures": ["ICLR.cc/2026/Conference/Submission5426/Reviewer_XuU7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5426/Reviewer_XuU7"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5426/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762250216620, "cdate": 1762250216620, "tmdate": 1762918054333, "mdate": 1762918054333, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes LiNC, a method for handling label noise in medical imaging by assigning a trainable per-sample trust parameter $\\alpha_i$ to each training sample. These parameters interpolate between observed labels and model predictions, with values learned via gradient descent during a warmup phase. After warmup, Otsu thresholding binarizes the α values to determine which labels to correct. Experiments on ten MedMNIST datasets show improvements in accuracy and AUROC."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Simplicity and efficiency: The method adds only one parameter per sample and integrates naturally into existing training workflows without requiring auxiliary models or clean validation sets.\n- Interpretability: The learned α values provide direct insight into which samples are likely mislabeled, enabling potential human-in-the-loop auditing."}, "weaknesses": {"value": "- Limited novelty: The core contribution is essentially bootstrapping (Reed et al., 2014) with learnable per-sample mixing weights instead of a fixed global parameter. The paper acknowledges bootstrapping but understates the similarity. The main novelty is making α per-sample and learnable, which is incremental.\n- Insufficient baseline comparisons: Tables 2–3 only compare the performance with and without LiNC, without including other noise correction baselines. Moreover, the comparisons lack recent state-of-the-art methods from 2024–2025.\n- Degradation on some datasets: OCTMNIST and TissueMNIST show consistent accuracy drops with LiNC (Table 2). The paper mentions these are \"hardest tasks\" but provides no analysis. Investigate failure modes and provide explanations or guidance on when LiNC should/shouldn't be used.\n- The writing style could be further improved, with more attention to consistency in capitalization and punctuation, especially in the section describing the contributions or novelty of the work."}, "questions": {"value": "- Otsu is applied once at epoch $\\omega$ (Line 13), making a permanent binary decision. If the model is poorly calibrated at epoch 10, incorrect corrections cannot be reversed. Why this one-shot correction is better than continuous soft interpolation. You can give ablation on key hyperparameters: $\\omega$, $\\alpha_{lr}$, $\\alpha_{wd}$ or some other evidence.\n- I am curious about the computational overhead (time, memory) compared to baseline training? How does it scale with dataset size?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "KXPuFePH9U", "forum": "0ik0xKYQd1", "replyto": "0ik0xKYQd1", "signatures": ["ICLR.cc/2026/Conference/Submission5426/Reviewer_s9LC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5426/Reviewer_s9LC"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission5426/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762262315693, "cdate": 1762262315693, "tmdate": 1762918054113, "mdate": 1762918054113, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}