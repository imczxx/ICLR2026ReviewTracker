{"id": "Zvy2agYouY", "number": 2091, "cdate": 1756987020950, "mdate": 1759898170109, "content": {"title": "TrajTok: What makes for a good trajectory tokenizer in behavior generation?", "abstract": "Behavior generation in autonomous driving aims to simulate dynamic driving scenarios from recorded driving logs. A popular approach is to apply next-token-prediction with discrete trajectory tokenization. In this work, we explore what makes a good trajectory tokenizer from the perspective of logged data usage. We first analyze the four properties (coverage, utilization, symmetry and robustness) of vocabularies of data-driven and rule-based trajectory tokenizers and their impact on performance and generalization. Data-driven tokenizers often build vocabularies with better utilization but suffer from insufficient coverage and sensitivity to noise, while rule-based methods have better coverage but contain too many useless tokens. With these insights, we propose TrajTok, a trajectory tokenizer that combines the two methods with rule-based vocabulary candidate setup and data-driven filtering and selection processes. The tokenizer has balanced coverage and utilization as well as good symmetry and robustness. Furthermore, we propose a spatial-aware label smoothing method for the cross-entropy loss to better model the similarities between the trajectory tokens. Our method wins first place in the 2025 Waymo Open Sim Agents Challenge.", "tldr": "", "keywords": ["behavior generation", "tokenizer", "autonomous driving"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6c9b04c5e22fc5a0261176cd331fb3808d4cdb5a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes TrajTok, a trajectory tokenizer for discrete next-token-prediction (NTP) behavior generation in autonomous driving. It combines data-driven and rule-based trajectory tokenizers, and has balanced coverage and utilization as well as good symmetry and robustness. It builds on top of the SMART NTP behavior generation backbone. It shows decent results in the 2025 Waymo Open Sim Agents Challenge."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The coverage, utilization, symmetry, and robustness perspectives are intuitive and useful.\n2. The algorithm is simple and the resulting vocabulary is nice and clean. \n3. The algorithm achieves good empirical results and high ranking on Waymo Open Sim Agents Challenge."}, "weaknesses": {"value": "1. The authors claim that TrajTok wins first place in the Waymo Open Sim Agent Challenge 2025. This contradicts Table 1, which shows SMART-R1 wins the first place, while TrajTok places 2nd. Looking at the official leaderboard (https://waymo.com/open/challenges/2025/sim-agents/) we see that TrajTok placed the 5th. \n2. TrajTok changes the tokenizer on top of the SMART backbone. Since the top 5 models on the official leaderboard are all variants of SMART, it seems TrajTok’s contribution is incremental or marginal."}, "questions": {"value": "The results on Table 2 use 20% of the training set. Do other tokenizers (VQ-VAE, K-means, K-disks, Grid) close the gap using a larger training set?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5YU1Dxe9im", "forum": "Zvy2agYouY", "replyto": "Zvy2agYouY", "signatures": ["ICLR.cc/2026/Conference/Submission2091/Reviewer_edLu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2091/Reviewer_edLu"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2091/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761882371150, "cdate": 1761882371150, "tmdate": 1762916017954, "mdate": 1762916017954, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies what makes for a good trajectory tokenizer for next token prediction behavior generation and proposes TrajTok, a plug and play tokenizer that combines rule based vocabulary construction with data driven filtering and expansion. The method explicitly targets four properties of a vocabulary, namely coverage, utilization, symmetry, and robustness, and introduces a spatial aware label smoothing scheme that assigns higher probability to tokens that are closer in trajectory space to the ground truth. The authors evaluate on the Waymo Open Motion Dataset and the Waymo Open Sim Agents Challenge and report first place on the 2025 leaderboard with consistent gains when TrajTok is used with a SMART backbone on validation metrics."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- There is a clear problem framing and taxonomy of desirable tokenizer properties. The paper analyzes how data driven methods often achieve high utilization but limited coverage and how rule based methods tend to overcover with many unused tokens. This motivates a hybrid design that TrajTok implements.\n- The construction pipeline is simple and reproducible. The four step procedure is easy to follow, from agent centric normalization and symmetry by flipping, to grid based candidate selection, to neighborhood based filtering and expansion, to final token generation including curve interpolation when a selected cell has no examples.\n- The paper reports strong results on both the public leaderboard and controlled comparisons, showing first place on WOSAC 2025 and better validation performance than VQ VAE, K means, K disks, and a pure grid, using a SMART based model under a common vocabulary size. Cross dataset and low data experiments further support generalization."}, "weaknesses": {"value": "- Scope is limited to trajectory tokenization. The method relies on a base next token prediction model, most experiments use SMART tiny, and the paper makes a few implementation choices that deviate from the original backbone, such as separate heads per agent type. It would help to isolate how much gain comes purely from the tokenizer versus modest architecture changes.\n- Computational cost and model scale trade offs are not discussed. The approach can yield large vocabularies across agent types, and spatially aware label smoothing appears to require computing distances from each target to many tokens. A brief cost analysis and a description of any approximations would improve clarity. The paper notes overall training settings but not the incremental overhead from TrajTok and the smoothing.\n- Minor presentation issue - I could not find what the highlight colors mean in Tables 1 and 2."}, "questions": {"value": "1. The appendix switches to separate prediction heads per agent type. How much of the improvement in validation metrics is due to this change rather than the tokenizer? A brief ablation on common heads versus separate heads would clarify attributions.\n2. How sensitive are the reported gains to the grid range and resolution per agent type and to the neighborhood thresholds for filtering and expansion? A small sweep around the appendix settings would help readers tune the method.\n3. In L377, “Increasing the vocabulary size improves the ability to represent complex distributions but may lead to model underfitting”, should this be the opposite (i.e. a smaller size causes underfitting)? Intuitively a larger vocabulary size should need more data, is under-training a better word?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mDikdGp9qI", "forum": "Zvy2agYouY", "replyto": "Zvy2agYouY", "signatures": ["ICLR.cc/2026/Conference/Submission2091/Reviewer_scBZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2091/Reviewer_scBZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2091/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761948105120, "cdate": 1761948105120, "tmdate": 1762916017659, "mdate": 1762916017659, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies trajectory tokenization for next-token-prediction (NTP) behavior generation in autonomous driving simulators. \nIt argues that existing data-driven tokenizers such as VQ-VAE or K-disks have good utilization but poor coverage and symmetry, while rule-based grid tokenizers have wide coverage but many redundant or unrealistic tokens.\nTo balance these properties, the authors propose TrajTok, a hybrid tokenizer that first builds a rule-based grid vocabulary and then filters and expands it using logged trajectory data. They also introduce spatial-aware label smoothing for cross-entropy loss, where non-ground-truth tokens are weighted according to spatial distance.\nExperiments on the Waymo Open Motion Dataset and the 2025 Waymo Open Sim Agents Challenge show that TrajTok ranks first on the leaderboard and yields slightly higher realism metrics than baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tClear motivation from data analysis. The authors systematically examine four tokenizer properties (coverage, utilization, symmetry, robustness) and relate them to logged data usage. This diagnostic perspective is useful for understanding tokenization quality.\n\n2.\tSimple yet general method. TrajTok is a lightweight combination of rule-based and data-driven principles that can be plugged into existing NTP architectures without retraining structural components.\n\n3.\tPractical evaluation. The paper reports results on the Waymo Open Sim Agents Challenge with official metrics, including the Realism Meta score, and provides ablations for label smoothing and vocabulary size."}, "weaknesses": {"value": "# Major\n\n- Unclear evidence of improvement: In Table 1, TrajTok achieves 0.7852 while SMART-R1 reaches 0.7855, and SMART-tiny-CLSFT gives 0.7846. These gaps are within noise. It is difficult to identify a clear gain attributable to the tokenizer.\n\n- Ambiguous reference tokenizer: Table 2 compares TrajTok with VQ-VAE, K-means, K-disks, and grid tokenizers, but it is not stated which tokenizer SMART-tiny originally used on the leaderboard. The reader cannot determine whether the new tokenizer outperforms the baseline used in the challenge submission.\n\n- Vague qualitative evidence: Figure 4 does not convincingly demonstrate that the proposed tokenizer contributes to better behavior generation. The visualization focuses on scene outcomes rather than showing how tokenization differences influence the trajectories. Without comparisons using the same scenario and seeds, the figure offers little empirical value.\n\n- Questionable justification of symmetry: The paper claims symmetry is critical for vehicle kinematics and real-world diversity, yet real traffic is not necessarily symmetric. For example, in right-hand traffic countries, turning behaviors are directionally biased. The necessity of symmetric flipping should be justified with more empirical or theoretical evidence. Table 6 shows a small gain from symmetry, but the physical rationale is not convincing.\n\n# Minor\n\n- Limited exploration of failure cases: The discussion does not examine cases where the tokenizer introduces unrealistic motion patterns or under-represents long-tail behaviors."}, "questions": {"value": "What tokenizer was used in the SMART-tiny baseline that appears in Table 1? Without knowing this, it is difficult to measure the real gain from TrajTok.\n\nHave you tested TrajTok on prediction tasks that use continuous outputs rather than discrete NTP models to verify that the benefit comes from tokenization rather than training heuristics?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "uJq5RTJyap", "forum": "Zvy2agYouY", "replyto": "Zvy2agYouY", "signatures": ["ICLR.cc/2026/Conference/Submission2091/Reviewer_9sjc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2091/Reviewer_9sjc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2091/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762084898648, "cdate": 1762084898648, "tmdate": 1762916017384, "mdate": 1762916017384, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents TrajTok, a hybrid trajectory tokenizer designed for behavior generation in autonomous driving. It investigates what constitutes an effective trajectory tokenizer under the next-token prediction (NTP) paradigm, analyzing four key properties—coverage, utilization, symmetry, and robustness—of existing data-driven and rule-based approaches. TrajTok integrates the advantages of both: it first constructs a rule-based grid of trajectory candidates and then applies data-driven filtering and expansion to balance vocabulary coverage and data efficiency. Additionally, the authors propose a spatial-aware label smoothing technique that weights token similarity by spatial distance, improving model generalization. Experiments on the Waymo Open Motion Dataset demonstrate that TrajTok achieves state-of-the-art performance, ranking first in the 2025 Waymo Open Sim Agents Challenge with superior realism and robustness across datasets and data scales."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "(1) This paper makes a clear and timely contribution by looking closely at what makes a good trajectory tokenizer in the next-token prediction (NTP) setup. The four proposed criteria—coverage, utilization, symmetry, and robustness—give a simple but useful way to understand and compare different tokenizers, which hasn’t really been discussed in earlier work like Trajeglish or MotionLM.\n\n(2) The proposed TrajTok method is simple but well thought out. It combines a rule-based start with data-driven filtering and expansion, which makes sense and nicely balances coverage and efficiency. This hybrid idea helps fix problems that appear in purely data-driven (too noisy) or rule-based (too redundant) tokenizers.\n\n(3) The paper also adds a spatial-aware label smoothing technique that slightly changes the standard cross-entropy loss. It’s an intuitive idea that takes spatial similarity between tokens into account, helping the model generalize better without depending on any specific architecture."}, "weaknesses": {"value": "(1) The paper only validates TrajTok within the SMART model [1]. Since TrajTok is designed as a general tokenizer, applying it to other NTP-based architectures (such as Trajeglish [2] or MotionLM [3]) would further support its claimed generality.\n\n(2) The paper defines several thresholds for the filtering and expansion process, but the actual parameter values and tuning details are not provided. It is unclear how sensitive the model is to these choices or whether small changes in these thresholds would affect the final vocabulary and performance. Including the specific values or a short sensitivity analysis would help improve reproducibility and confidence in the results.\n\n[1] Wei Wu, et al. “Smart: Scalable multi-agent real-time motion generation via next-token prediction.” Advances in Neural Information Processing Systems, 37:\n114048–114071, 2024.\n[2] Jonah Philion, et al. “Trajeglish: Traffic modeling as next-token prediction.” arXiv preprint arXiv:2312.04535, 2023\n[3] Ari Seff, et al. “Motionlm: Multi-agent motion forecasting as language modeling.” In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp.\n8579–8590, 2023."}, "questions": {"value": "Please refer to the weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xu83GAXxLJ", "forum": "Zvy2agYouY", "replyto": "Zvy2agYouY", "signatures": ["ICLR.cc/2026/Conference/Submission2091/Reviewer_kf6b"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2091/Reviewer_kf6b"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2091/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762183947002, "cdate": 1762183947002, "tmdate": 1762916017090, "mdate": 1762916017090, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}