{"id": "HSqfxmwXix", "number": 6543, "cdate": 1757988397618, "mdate": 1759897908860, "content": {"title": "LiteGS: a high-performance framework to train 3dgs in subminutes via system and algorithm codesign", "abstract": "3D Gaussian Splatting (3DGS) has emerged as promising alternative in 3D representation. However, it still suffers from high training cost. This paper introduces LiteGS, a high performance framework that systematically optimizes the 3DGS training pipeline from multiple aspects. At the low-level computation layer, we design a \"warp-based raster'' associated with two hardware-aware optimizations to significantly reduce gradient reduction overhead. At the mid-level data management layer, we introduce dynamic spatial sorting based on Morton coding to enable a performant \"Cluster-Cull-Compact'' pipeline and improve data locality, therefore reducing cache misses. At the top-level algorithm layer, we establish a new robust densification criterion based on the variance of the opacity gradient, paired with a more stable opacity control mechanism, to achieve more precise parameter growth. Experimental results demonstrate that LiteGS accelerates the original 3DGS training by up to 13.4x with comparable or superior quality and surpasses the current SOTA in lightweight models by up to 1.5x speedup. For high-quality reconstruction tasks, LiteGS sets a new accuracy record and decreases the training time by an order of magnitude.", "tldr": "LiteGS achieves state-of-the-art speed and accuracy in 3D Gaussian Splatting, with up to 13.4× faster training through warp-based rasterization, Morton-coded cluster-culling, and robust densification.", "keywords": ["gaussian splatting", "acceleration", "3dgs"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3bf5bb2542269a29ad0b4ff69448d02261d560ca.pdf", "supplementary_material": "/attachment/4303cee8dcd54adb3d428293c92a19d775619d35.zip"}, "replies": [{"content": {"summary": {"value": "This paper comprehensively analyze the 3DGS training system and detects related issues with the current paradigm. Based on these insights, it proposes a co-optimization for 3DGS systems, covering high-level algorithm design to low-level CUDA backbones, integrating GPU kernel design, memory layout, and algorithmic improvements. The resulting method considers fast training speed, compact storage size and high-quality reconstruction."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is well-motivated and targets at a research gap where scare previous works exist. The 3DGS efficiency is of significance and requires comprehensive efforts for improvements. \n2. This work integrates effective technical methods to improve the 3DGS training efficiency, including warp-based rasterization which accelerates tile-based rasterization, mixed precision training in 3DGS, cluster-cull-compaction with Morton code sorting, and opacity reset strategy considering variance as a metric. \n3. The overall performance accelerates the 3DGS training process, makes the storage compact, while maintaining reasonable reconstruction quality."}, "weaknesses": {"value": "1. The paper contributions and novelties are hard to judge. This paper includes multiple off-the-shelf techniques, such as scanline, integer warp reduce, and mixed precision, which are not first established while primarily combined in this work. These elements make the proposed method a good adaptation of the previous thoughts and techniques, while it is difficult to state their novelty compared to previous CUDA acceleration techniques.\n2. Paper illustration. The CUDA operations in this paper are not intuitive to understand, and more visualizations are favorable for a better illustration.\n3. Method effectiveness. This paper employs three model variants, turbo, balance and quality, with different model hyperparameters for different comparisons. Although these variants perform well in their own specific domain, this fails to verify that the proposed method achieves a superior efficiency-quality trade-off over baseline methods. The proposed method still relies on fine-grained adjustments to 'transfer' to different versions for better performance on partial metrics, leading to low confidence on a comprehensively effective method. When implementation, the users still need to state their requirements and select one variant compromising some other metrics. This leads to significant concerns on the effectiveness."}, "questions": {"value": "1. The primary concern is on the method effectiveness. As illustrated in the weakness, the method is not a universally excellent solution to the efficiency-performance trade-off, and it requires multiple variants to show comparisons on different aspects. The authors are expected to provide justifications on this.\n2. The authors are expected to provide more clarifications on its paper novelty, especially ones related to the GPU backbone.\n3. It is recommended to provide more visual illustrations to aid paper readability. For example, the Supp Fig. 3 4 5 can be placed to the main paper part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "WvvBOjAJGl", "forum": "HSqfxmwXix", "replyto": "HSqfxmwXix", "signatures": ["ICLR.cc/2026/Conference/Submission6543/Reviewer_WH8U"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6543/Reviewer_WH8U"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6543/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760954097759, "cdate": 1760954097759, "tmdate": 1762918891153, "mdate": 1762918891153, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents LiteGS, a high-performance framework that significantly accelerates the training of 3D Gaussian Splatting (3DGS) through a comprehensive, multi-layer co-optimization of system and algorithm design.\nThe authors identify key bottlenecks in 3DGS training — including inefficient gradient reduction, poor spatial data locality, and unstable densification — and address them via three major contributions:\n\nWarp-based Rasterization: A “one warp per tile” raster paradigm that minimizes gradient reduction overhead by fusing intra-thread accumulation and a single warp-level reduction, complemented by a scanline-based data reuse scheme and strategic mixed-precision computation to mitigate register pressure.\n\nCluster-Cull-Compact Pipeline: A Morton-code-based spatial sorting and clustering strategy enabling efficient cluster-level culling and memory compaction, improving cache coherence and reducing warp divergence.\n\nOpacity Gradient Variance Metric: A new densification criterion based on the variance of per-pixel opacity gradients, paired with an opacity decay mechanism that improves the robustness and precision of geometric refinement.\n\nEmpirical results show that LiteGS accelerates 3DGS training by up to 13.4× while maintaining or even improving rendering quality. For high-quality setups, it achieves up to 10.8× speedup over quality SOTA (3DGS-MCMC) with better PSNR. The framework is open-sourced and demonstrates superior performance in both lightweight and full-quality scenarios."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper presents a systematic and multi-level optimization for 3D Gaussian Splatting training. While individual optimizations in GPU computation or densification have appeared in prior works, LiteGS’s holistic co-design across low-level GPU kernels, mid-level data management, and high-level algorithmic logic is novel. The introduction of a variance-based opacity gradient metric for densification is particularly innovative and conceptually elegant.\n- The paper provides solid technical depth and engineering rigor. The proposed warp-based rasterization, mixed-precision accumulation, and Morton-code clustering are well justified and clearly described with mathematical precision. The methods are hardware-conscious yet algorithmically generalizable, demonstrating a rare balance between system-level and algorithmic contributions.\nExperimental results are comprehensive, with ablation studies validating the necessity of each design choice and comparisons against multiple baselines (e.g., 3DGS, 3DGS-MCMC, Minisplatting v2).\n- The paper is well structured and clearly written, with a logical flow from problem analysis to multi-layer solutions. The figures and appendices (as referenced) likely aid understanding of complex system details. The exposition effectively explains how low-level optimizations propagate benefits to higher-level algorithmic efficiency."}, "weaknesses": {"value": "- While LiteGS is highly effective for 3DGS, it remains unclear whether the proposed techniques — especially the warp-based rasterization and Morton-based clustering — generalize well to other Gaussian-based rendering systems (e.g., Gaussian Surfels, Spec-Gaussians) or non-Gaussian volumetric methods. A brief discussion or experiment on this generalizability would strengthen the work’s impact.\n- Although the paper mentions “comprehensive ablation studies,” it is unclear how the individual contributions interact (e.g., how much additional speedup is achieved when combining warp-based rasterization with clustering, beyond their individual effects). Providing a layer-wise ablation table could make the quantitative benefits more interpretable.\n- The mixed-precision strategy may introduce numerical instability or minor visual artifacts, particularly in regions with fine opacity transitions. A quantitative error analysis (e.g., comparing FP32 vs. mixed-precision PSNR or SSIM) would make the claims of “comparable or superior quality” more convincing.\n- The paper could benefit from a more detailed visualization of performance bottlenecks before optimization (e.g., profiling charts showing GPU utilization or cache miss rates). This would make the motivation more concrete for readers unfamiliar with GPU-level optimization."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "5wLythh8Sp", "forum": "HSqfxmwXix", "replyto": "HSqfxmwXix", "signatures": ["ICLR.cc/2026/Conference/Submission6543/Reviewer_VD5m"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6543/Reviewer_VD5m"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6543/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761756972858, "cdate": 1761756972858, "tmdate": 1762918890734, "mdate": 1762918890734, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes LiteGS, a novel 3D Gaussian Splatting (3DGS) framework designed to substantially reduce the computational overhead for 3DGS training. To this end, the authors introduce several efficiency-oriented techniques, including a warp-based rasterizer, cluster-cull-compact pipeline, and a novel densification metric. Experimental results demonstrate that the proposed method achieves high-quality reconstruction performance while significantly shortening training time."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Warp-based rasterizer enables both fast forward and backward pass, leading to a significant reduction in training time.\n\n- Morton curve-based clustering allows efficient cluster-level culling, resulting in computational benefits.\n\n- This method achieves high rendering quality despite the minimal training costs."}, "weaknesses": {"value": "- The overall manuscript is difficult to follow due to unclear writing and structure. Improving the notations, descriptions, and overall presentation would enhance readability.\n\n- This method mainly focuses on hardware-related optimizations and therefore lacks sufficient technical novelty from a methodological perspective.\n\n- Despite the high performance, the emphasis on hardware-level efficiency may not align well with the focus of this conference."}, "questions": {"value": "- GPU memory usage is also an important factor of training efficiency. Could you clarify how the proposed method improves performance with respect to the memory footprint?\n\n- The performance reported in Table 4 is not consistent with that shown in Table 1. Please clarify which variant corresponds to the scores in Table 4.\n\n- Most of the techniques are related to training acceleration. Then, which component of this method contributes to the improvement in rendering quality, not the training efficiency, compared to existing 3DGS approaches? \n\n- How to apply the proposed metric in densification? Could you explain more details on this part?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qEbyGnfGfX", "forum": "HSqfxmwXix", "replyto": "HSqfxmwXix", "signatures": ["ICLR.cc/2026/Conference/Submission6543/Reviewer_48y1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6543/Reviewer_48y1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6543/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761829092011, "cdate": 1761829092011, "tmdate": 1762918890247, "mdate": 1762918890247, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the critical bottleneck of slow training times in 3D Gaussian Splatting (3DGS), which currently hinders its broader application. The authors propose LiteGS, a high-performance framework that systematically optimizes the entire 3DGS training pipeline through a novel \"system and algorithm codesign\" approach."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. The performance gain is very impressive.\n2. Deep and Novel Technical Contributions: Each of the three core contributions is substantial and novel in its own right.\n- The Warp-based Rasterizer is an excellent piece of systems engineering, demonstrating a hardware-aware design that cleverly uses scanline algorithms and mixed-precision (including the novel use of integer warp-reduce for float accumulation) to solve the specific bottlenecks of 3DGS backpropagation.\n- The Cluster-Cull-Compact pipeline is a smart adaptation of a known (but from a different domain) technique to the dynamic training of 3DGS, effectively solving the cache-locality and warp-divergence problems that worsen as the model grows."}, "weaknesses": {"value": "The \"opacity gradient variance\" metric is a key contribution to improving PSNR, as demonstrated through extensive experiments in the paper. However, it would be helpful if the authors could provide additional visualizations of the Gaussian distributions (e.g., gradient histograms, variance heatmaps) to better illustrate the concept and assist the reviewer in understanding the method. \n\nNevertheless, I am not an expert in 3D-GS rendering pipelines, so I would defer to other reviewers’ opinions on this aspect."}, "questions": {"value": "I have no more questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "t68QHh5zha", "forum": "HSqfxmwXix", "replyto": "HSqfxmwXix", "signatures": ["ICLR.cc/2026/Conference/Submission6543/Reviewer_LPDX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6543/Reviewer_LPDX"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6543/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761924607461, "cdate": 1761924607461, "tmdate": 1762918889872, "mdate": 1762918889872, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Novelty Rebuttal (for R2W2, R4W1，R4Q2)"}, "comment": {"value": "We fully agree that simply combining known GPU techniques such as scanline, warp reductions, or mixed precision would not constitute meaningful novelty. LiteGS is not a collection of such isolated components. Its main contribution is a unified algorithm–system co-design framework that addresses a set of coupled bottlenecks in 3DGS training. These bottlenecks were previously treated as unrelated, yet they directly constrain each other. Below, we clarify why LiteGS is technically non-trivial and cannot be reduced to reusing existing optimizations.\n\n# LiteGS is the first framework that constructs a closed-loop, cross-layer bottleneck diagnosis for 3DGS training\n\nOur analysis shows that the main limitations in 3DGS training do not stem from any single component. They arise from the interaction among densification, spatial/memory locality, and rasterization parallelism. Prior work improved these steps independently. LiteGS is the first to describe and optimize them jointly:\n\n1. **Densification progressively breaks spatial and memory locality.** As densification begining, new primitives are appended to memory, breaking memory locality. LiteGS restores locality through online cluster-level reorganization. This enables cluster-level culling and avoids substantial redundant computation. Earlier methods do not maintain locality after densification and therefore incur unnecessary cost.\n\n2. **Warp-based rasterization facing hardware I/O limits without locality restoration.** While warp-based raster increases throughput, it also exposes memory bandwidth limits. If spatial locality is degraded, the rasterizer suffers from cache misses, and warp stalls. With our locality restoration, warp-based rasterization can actually reach its intended performance.\n\n3. **Warp-based rasterization enables a new class of densification strategies —— gradient statistics instead of sheuristic or sampled scoring.** Our densification metric computes opacity-gradient variance across all views. This requires fast, dense multi-pixel accumulation. Traditional 3DGS pipelines cannot do this efficiently; they rely on heuristics or sample only 10–20 views because pixel-level accumulation is too slow. The limitation is systemic, not algorithmic. With warp-based rasterization, dense statistics become feasible, making our densification formulation practical.\n\nIn summary, LiteGS is not a collection of isolated optimizations, but the first framework to jointly address this densify → locality → rasterization → densify closed-loop bottleneck, which prior works neither recognized nor attempted to unify.\n\n# Warp-per-tile rasterization is a new parallelization model, not a low-level trick\n\nThe novelty is not the use of warp reductions or scanline in isolation. It is the mapping that assigns an entire warp to a coherent screen-space region. Recent works explore other mappings—per-splat (TamingGS), tensor-core groups (TC-GS), or block-per-tile (DistWard)—but none use warp-per-tile mapping.\n\nIf warp-per-tile rasterization were a straightforward combination of scanline, mixed-precision, and warp reduction, prior 3DGS works—which already use these components—would have converged to the same design. They did not. The difficulty lies in making this mapping viable: controlling register footprint, aligning memory behavior, and inter-tile accumulation. LiteGS resolves these difficulty and demonstrates our warp-based raster.\n\n# A densification metric that corrects a long-standing issue\n\nOur densification metric is a new algorithmic contribution, not an engineering trick. LiteGS introduces a intuitive and effective metric for the densification. We identified a a long-standing issue in 3DGS densification. The periodic opacity reset distorts gradient magnitude and leads to incorrect densification decisions. To correct this, we propose a simple and elegant metric—opacity gradient variance.\nImportantly, computing this variance efficiently requires fast, dense statistics, which previous rasterization methods could not provide. Our warp-based rasterization makes this feasible, enabling gradient aggregation at low cost.\n\n# Mathematical compatibility with the 3DGS ecosystem\n\nLiteGS intentionally preserves the original 3DGS formulation. This allows LiteGS to serve as drop-in infrastructure for the entire ecosystem (AnySplat, SSS, ImageGaussian, and others). This design choice ensures broad compatibility and fast adoption. It should not be interpreted as a lack of novelty; rather, it reflects our goal to improve the system foundation without altering the mathematical model."}}, "id": "d1dwvfcTx0", "forum": "HSqfxmwXix", "replyto": "HSqfxmwXix", "signatures": ["ICLR.cc/2026/Conference/Submission6543/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6543/Authors"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6543/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763373327390, "cdate": 1763373327390, "tmdate": 1763373327390, "mdate": 1763373327390, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}