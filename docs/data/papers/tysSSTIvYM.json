{"id": "tysSSTIvYM", "number": 16366, "cdate": 1758263780093, "mdate": 1759897245444, "content": {"title": "VALUEFLOW: Toward Pluralistic and Steerable Value-based Alignment in Large Language Models", "abstract": "Aligning Large Language Models (LLMs) with the diverse spectrum of human values remains a central challenge: preference-based methods often fail to capture deeper motivational principles. Value-based approaches offer a more principled path, yet three gaps persist--extraction often ignores hierarchical structure, evaluation detects presence but not calibrated intensity, and therefore, the steerability of LLMs at controlled intensities remains insufficiently understood. To address these limitations, we introduce VALUEFLOW, the first unified framework that spans extraction, evaluation, and steering with calibrated intensity control. The framework integrates three components: (i) HiVES, a hierarchical value embedding space that captures intra- and cross-theory value structure; (ii) the Value Intensity DataBase (VIDB), a large-scale resource of value-labeled texts with intensity estimates derived from ranking-based aggregation; and (iii) an anchor-based evaluator that produces consistent intensity scores for model outputs by ranking them against VIDB panels. Using VALUEFLOW, we conduct a comprehensive large-scale study across ten models and four value theories, identifying asymmetries in steerability and composition laws for multi-value control. This paper establishes a scalable infrastructure for evaluating and controlling value intensity, advancing pluralistic and accountable alignment of LLMs.", "tldr": "VALUEFLOW introduces the first unified framework for value-based alignment in LLMs—spanning extraction, evaluation, and calibrated intensity steering—providing scalable infrastructure for pluralistic and accountable control.", "keywords": ["LLM", "Human Values", "Value-based Alignment", "Value Evaluation"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/775e36aa44d55ce23b59b5f5c1f2d0161999a833.pdf", "supplementary_material": "/attachment/5d1ccaa5d88ae194a111b22809523cbf16fd8b23.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces VALUEFLOW, a unified framework for value-based LLM alignment focused on steerable intensity control. The authors argue that existing methods fail to capture value hierarchies or reliably measure value intensity, leading to unstable evaluations. VALUEFLOW addresses this with three components: HIVES, a hierarchical value embedding space; VIDB, a large-scale database of texts with intensity scores derived from robust ranking aggregation using a Plackett-Luce model; and a stable anchor-based evaluator that ranks outputs against VIDB. Using this framework, the authors conduct a comprehensive study on ten models across four value theories, characterizing model-specific asymmetries in steerability, identifying a \"strong-anchor dominance\" effect in multi-value control, and providing a scalable infrastructure for pluralistic alignment."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "This paper addresses an important and timely question, how to systematically examine and steer the value representations embedded in current large language models under pluralistic and controllable conditions.\n\nIt proposes a comprehensive engineering framework that connects extraction, evaluation, and steering into a closed loop, forming an end-to-end pipeline for value-based alignment.\n\nThe experiments are large-scale and multi-dimensional, covering 10 models, 4 value theories, and 32 value dimensions, including both single-value and multi-value steering, refusal analysis, and downstream evaluation. These results provide broad and empirically grounded insights into asymmetric steerability and anchor dominance effects."}, "weaknesses": {"value": "The reliance on LLM-as-a-Judge remains a concern. It would be valuable to include an analysis of inter-model differences in judging behavior, as well as quantitative consistency checks between LLM-based and human annotations.\n\nThe paper’s writing and structure are sometimes hard to follow; a clearer organization and smoother transitions would significantly improve readability.\n\nThere are two minor typos at Lines 296 and 417, the paragraph titles should be followed by a period."}, "questions": {"value": "See the **Weaknesses** section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4Z6mcE8SiZ", "forum": "tysSSTIvYM", "replyto": "tysSSTIvYM", "signatures": ["ICLR.cc/2026/Conference/Submission16366/Reviewer_cFGL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16366/Reviewer_cFGL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16366/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761035977218, "cdate": 1761035977218, "tmdate": 1762926492506, "mdate": 1762926492506, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces VALUEFLOW, a unified framework for value-based alignment in large language models, encompassing three core components: extraction, evaluation, and intensity-controlled steering. The framework includes: (1) HIVES - a hierarchical value embedding space capturing multi-theory value structures; (2) VIDB - a large-scale value intensity database with calibrated intensity estimates via ranking aggregation; (3) an anchor-based evaluator producing consistent intensity scores through ranking rather than rating. The authors conduct large-scale experiments across 10 models and 4 value theories, identifying asymmetries in steerability and composition laws for multi-value control, while demonstrating improved demographic alignment through value-based profiling."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Problem Focus and Contribution Scope:\n    - Addresses three critical gaps in value alignment research: extraction lacks hierarchical structure, evaluation detects presence but not intensity, and steerability remains insufficiently understood - the problem formulation is clear and important.\n    - First to propose \"steerability with intensity,\" extending value alignment from directional control to graded intensity control, opening a new dimension for pluralistic value alignment.\n\n2. Method Mechanism:\nHIVES's two-stage training design is well-motivated: Stage 1 aligns intra-theory structure via hierarchical contrastive learning, while Stage 2 unifies heterogeneous theories through cross-theory anchors - the technical approach is sound.\n\n3. Empirical Evaluation:\n\n    - Comprehensive experimental scope: 10 mainstream models (open and closed source) × 4 value theories × 32 value dimensions × 500 prompts, providing broad coverage.\n    - Valuable empirical patterns discovered: asymmetry in negative steering, strong-anchor dominance effect, value similarity affecting composition laws, etc."}, "weaknesses": {"value": "- Technical Correctness: Plackett-Luce model assumes Independence of Irrelevant Alternatives (IIA), but value judgments may exhibit context-dependent effects; the paper does not discuss robustness when this assumption is violated.\n\n- Evaluation Scope: Experiments mainly focus on \"short-term prompt-driven value steering\" and do not explore the stability of value expression in long-term dialogues (e.g., whether the model deviates from the target intensity after multi-turn interactions). They also fail to test value alignment effects in low-resource language or niche cultural contexts, resulting in limited scenario coverage.\n\n- Loss function weights in two-stage training (λind=0.5, λtheory=1.0) lack ablation study support; the impact of different weight configurations on final representation quality is unknown."}, "questions": {"value": "- Theoretical Foundation: Why is the Plackett-Luce model suitable for value intensity aggregation? Have other ranking models (e.g., Bradley-Terry, Thurstone) been tested? How does the model perform when value judgments exhibit non-transitivity?\n\n- How do the 274 cross-theory anchor concepts ensure balanced coverage across theories? Is there any theory dominating the anchor set?\n\n- How applicable is the framework to non-English languages or non-Western value systems (e.g., Confucian, Buddhist values)?\n\n- Is the computational cost of ranking evaluation at inference time (k=6, m=3 implies 18 LLM calls) acceptable in real applications?"}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety", "Yes, Potentially harmful insights, methodologies and applications", "Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fNDHvhjUIb", "forum": "tysSSTIvYM", "replyto": "tysSSTIvYM", "signatures": ["ICLR.cc/2026/Conference/Submission16366/Reviewer_wGtp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16366/Reviewer_wGtp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16366/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761381380101, "cdate": 1761381380101, "tmdate": 1762926492054, "mdate": 1762926492054, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Beyond preference-based methods, this paper accounts for alignment with real human values that are diverse and serve as more stable principles in decision-making. \n\nIt aims to address two main challenges: (1) value extraction, current studies rely on static questionnaires or simple judgments, limiting the ability to capture signals from open-ended conversational contexts and rarely encode the hierarchical nature of values. (2) value evaluation, current studies measure presence rather than strength, overlooking intensity in open-ended outputs. \n\nFor these, they introduce a unified framework VAUEFLOW, with HIVES, a hierarchical value embedding space to capture value profiles, and a ranking-based value evaluator together with a value-intensity database VIDB. Then, they conduct experiments to verify the effectiveness of HIVES and the ranking-based evaluator, as well as the whole framework for value steerability."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper proposes VALUEFLOW, a unified framework spanning value extraction, evaluation and steering in LLMs, allowing for end-to-end steerable value alignment.\n2. To address the challenge of value extraction, it constructs a HIVES method to unify heterogeneous value theories.\n3. Accounting for the intensity of values and instability of current rating-based evaluations, this paper builds a value-intensity database and designs a ranking-based evaluation method of intensity.\n4. Some experiments and analysis are conducted to demonstrate the usage in value steerability."}, "weaknesses": {"value": "1. Baselines of value extraction on open-ended conversational contexts are largely ignored both in the Introduction part (Line 52) and Related Work part. I think there are some works on this task.\n2. The whole method needs better clarification:\n- A structural algorithm is desired to formulate the whole framework, especially how the hierarchical value embedding space is built.\n- More descriptions are required for the Sec 4.3 Two Stage Training Process, what are the inputs and what are the outputs? How to obtain the ground truth data for training?\n- What is the value steering method for AI used in this paper?\n- What are the ground truth and evaluation metrics used for the experiments in Figure 4.\n3.  There lack sufficient baselines for comparison in both Table 1 and Table 2, limiting the reliability of effectiveness about your method. There are evaluators in Denevil, ValuePrism, etcs mentioned in this paper, which should be considered for comparison.\n4. There are some problematic settings in your method and experiments.\n- In Line 259, when constructing the VIDB dataset, you use multiple LLMs to generate the intensity rating label for each text. However, you mentioned in Sec 3.2 that LLMs’ ratings on value intensity are highly unstable. So this would decrease the accuracy of the VIDB dataset.\n- In Sec 6.3, you first construct value profiles from the dataset, then use these value profiles as the alignment target, finally compute the accuracy between the alignment with the data which are used for constructing value profiles. This could incur a risk of data contamination, limiting the significance of the experiments."}, "questions": {"value": "1. Figure 2 is currently a little confusing about which LLM generates the rating score respectively.\n2. Figure 8 is hard to understand."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rAa0NqA7Vt", "forum": "tysSSTIvYM", "replyto": "tysSSTIvYM", "signatures": ["ICLR.cc/2026/Conference/Submission16366/Reviewer_Uk4Z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16366/Reviewer_Uk4Z"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16366/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761897067769, "cdate": 1761897067769, "tmdate": 1762926491656, "mdate": 1762926491656, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "VALUEFLOW introduces a unified framework for value-based LLM alignment, addressing extraction, evaluation, and steering gaps. It comprises hierarchical value embeddings unifying SVT, MFT, duties, rights, large-scale intensity-labeled texts via ranking aggregation, and a ranking-based evaluator using VIDB anchors for calibrated intensity scores. Experiments across 10 models reveal steerability asymmetries, multi-value composition laws, and improved demographic prediction on OpinionQA (>10% accuracy gains). The framework enables pluralistic, intensity-controlled alignment."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The ranking-based value evaluation is a novel and timely contribution. It's a promising direction to overcome the reliability and consistency issue of prior evaluation methods.\n- Unifying heterogeneous value theories is an interesting and pioneering attempt.\n- The large-scale intensity database, upon its open-source, is a significant contribution to the community."}, "weaknesses": {"value": "The methodological section is hard to follow. For example, it is unclear what the motivation and theoretical basis are for the two-stage training process (Section 4.3). How does the unified taxonomy contribute to the value evaluation? What is the relationship between the anchors in Section 4.3 and those in Section 5.2? In Figure 3, how are parts (a) and (b) used together synergistically?\n\nWhat is the theoretical justification is for using the Plackett–Luce model among all possible scales?\n\nIs the zero-shot, ranking-based value evaluation reliable? Was the evaluator trained? The experiments in Section 3 seem to focus only on SVT values, rather than on all the values used in this study. How do you validate the accuracy of the value evaluation?\n\nHow well do your embedding model and value evaluator generalize across different context lengths?\n\nThere appears to be no alignment training, despite the claims in the abstract and introduction.\n\nThe evaluations in Sections 6.2 and 6.3 have also been conducted in prior work. How does your evaluation improve upon previous ones? Are there any novel insights?\n\nWhat is the motivation behind designing a unified framework if the components are not trained synergistically? In what way is the end-to-end workflow superior to prior approaches that design individual components separately?"}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OfsuCNvPwV", "forum": "tysSSTIvYM", "replyto": "tysSSTIvYM", "signatures": ["ICLR.cc/2026/Conference/Submission16366/Reviewer_GBae"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16366/Reviewer_GBae"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16366/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761917523250, "cdate": 1761917523250, "tmdate": 1762926491296, "mdate": 1762926491296, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}