{"id": "XcCqRcHzJ3", "number": 24267, "cdate": 1758354741123, "mdate": 1759896773407, "content": {"title": "Instance-wise Adaptive Scheduling via Derivative-Free Meta-Learning", "abstract": "Deep Reinforcement Learning has achieved remarkable progress in solving NP-hard scheduling problems. However, existing methods primarily focus on optimizing average performance over training instances, overlooking the core objective of solving each individual instance with high quality. While several instance-wise adaptation mechanisms have been proposed, they are test-time approaches only and cannot share knowledge across different adaptation tasks. Moreover, they largely rely on gradient-based optimization, which could be ineffective in dealing with combinatorial optimization problems. We address the above issues by proposing an instance-wise meta-learning framework. It trains a meta model to acquire a generalizable initialization that effectively guides per-instance adaptation during inference, and overcomes the limitations of gradient-based methods by leveraging a derivative-free optimization scheme that is fully GPU parallelizable. Experimental results on representative scheduling problems demonstrate that our method consistently outperforms existing learning-based scheduling methods and instance-wise adaptation mechanisms under various task sizes and distributions.", "tldr": "", "keywords": ["Scheduling", "Neural Combinatorial Optimization", "Meta-learning"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6cc74ea8ec515f96bf481d68dbd09e9bd1ae75c0.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Instance-wise Adaptive Scheduling via Derivative-Free Meta-Learning, a framework that improves deep reinforcement learning for complex scheduling problems such as the Flexible Job-Shop Scheduling Problem (FJSP). It uses meta-learning to learn a generalizable initialization for fast per-instance adaptation and replaces gradient-based optimization with a derivative-free method based on Evolution Strategies, enhanced by GPU parallelization for efficiency. Experiments show that the approach consistently outperforms existing baselines like Active Search and Efficient Active Search in solution quality, adaptability, and generalization."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper’s key strengths lie in its novel integration of meta-learning with derivative-free optimization to improve instance-wise adaptability in complex scheduling tasks. By leveraging Evolution Strategies and a GPU-parallelized implementation, the approach achieves efficient, gradient-free training and fine-tuning that reportedly scales well to large problem instances."}, "weaknesses": {"value": "While the paper demonstrates solid implementation and empirical results, its conceptual novelty is limited. The proposed framework largely repurposes the MAML paradigm with minor modifications, and the use of derivative-free optimization appears incremental rather than innovative. The motivation for replacing gradient-based methods is not well justified, with very limited theoretical or empirical evidence. Consequently, the work feels more like an engineering improvement than a substantial methodological advance, lacking deeper analysis or insight into why the proposed approach is fundamentally superior.\n\nA key weakness appears to be the use of two nested evolutionary processes, one for instance-level adaptation and another for meta-level optimization. They make the method highly computationally expensive and sample inefficient. Since evolutionary algorithms already demand large populations and many evaluations, nesting them greatly amplifies the cost. Although GPU parallelization helps with runtime, it does not address this fundamental inefficiency. The paper also lacks analysis showing that such a two-level structure is necessary, raising concerns about scalability and practical applicability.\n\nAs acknowledged by the authors, a potential advantage of the proposed nested design is that it avoids computing second-order derivatives, which can be costly in traditional MAML frameworks. However, it remains unclear why ES is the preferred or necessary choice for achieving this goal. There exist several other first-order or gradient-approximation approaches that could eliminate second-order terms with far lower computational cost. The paper does not provide justification or comparative analysis to show that ES offers a clear advantage over these alternatives, making the design choice appear arbitrary and potentially inefficient.\n\nA significant flaw lies in the paper’s misuse of the term “natural gradient.” Although the authors claim to adopt Natural Evolution Strategies (NES), their algorithm actually follows the OpenAI-ES formulation, which estimates a standard Monte Carlo gradient without the Fisher preconditioning required for true NES. In particular, Equation (4) is mathematically identical to the OpenAI-ES update rule, showing no theoretical modification or geometric correction. This indicates a misunderstanding of NES and renders the claim of “natural gradient estimation” technically inaccurate, undermining both the paper’s methodological novelty and its conceptual soundness.\n\nThe claim that “the entire fitness evaluation process is offloaded to GPU” in the paper appears overstated. In practice, the feasibility of full GPU offloading strongly depends on the problem structure and the simulator used for fitness evaluation. Many scheduling environments, particularly those involving discrete event simulation or complex resource constraints, are not inherently GPU-friendly and may still require significant CPU-side computation or data transfer. Without demonstrating that the underlying environment is fully GPU-parallelizable, this claim lacks general validity. As a result, the reported efficiency gains may not generalize beyond the specific experimental setup used in the paper.\n\nWhile the experimental results in the paper show consistent improvements over baselines such as Active Search and Efficient Active Search, the gains are generally incremental rather than dramatic. The improvements in optimality gap are often modest (a few percentage points) and achieved under carefully controlled synthetic settings, which may not fully reflect real-world complexity. Moreover, the experiments primarily benchmark against older or relatively simple baselines, without comparison to stronger contemporary meta-learning or hybrid optimization approaches. Given the method’s high computational cost and limited novelty, the reported results, though positive, do not convincingly demonstrate a major performance breakthrough or justify the added algorithmic complexity."}, "questions": {"value": "1. How does the proposed framework meaningfully advance beyond standard MAML or existing derivative-free meta-learning methods, and what concrete evidence supports the need to replace gradient-based approaches?\n\n2. Given the high computational cost of two nested evolutionary loops, can the authors justify why such a design is necessary, and provide analysis demonstrating its scalability and efficiency in practical settings?\n\n3. Since the algorithm appears to follow the OpenAI-ES formulation rather than true NES, and GPU offloading may be problem-dependent, how do the authors substantiate their claims of “natural gradient” estimation and general computational efficiency?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GGUiasnwnl", "forum": "XcCqRcHzJ3", "replyto": "XcCqRcHzJ3", "signatures": ["ICLR.cc/2026/Conference/Submission24267/Reviewer_kVaC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24267/Reviewer_kVaC"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24267/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760600458574, "cdate": 1760600458574, "tmdate": 1762943024401, "mdate": 1762943024401, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a key limitation of learning-based approaches for NP-hard scheduling problems: models are often trained to optimize average performance, rather than the solution quality for each specific instance. Existing instance-level adaptation methods are typically used only at test time and rely on gradient-based optimization, which can be ineffective in combinatorial search spaces.\n\nInspired by MAML, the authors propose an instance-level meta-learning framework to learn a model initialization that can quickly adapt to new instances. Its main novelty lies in the use of a *fully derivative-free optimization (DFO)* method, specifically Natural Evolution Strategies (NES), for both the inner-loop adaptation and the outer-loop meta-optimization. This avoids the need for complex gradient calculations and is better suited for instance-level search tasks, which can trap gradient-based methods in local optima.\n\nTo stabilize the DFO process, the paper introduces two Monte Carlo estimation strategies (MC averaging and MC best-sample). Furthermore, they develop an efficient GPU-based parallel framework to manage the computational cost of the population-based NES.\n\nThe effectiveness of the method is demonstrated through extensive experiments on Flexible Job Shop Scheduling (FJSP) and Job Shop Scheduling (JSP), applying it to two base models: Reinforcement Learning (DANIEL) and Self-supervised (SPN). The results show consistent and significant improvements over the base models and sota adaptation baselines, such as Active Search (AS) and Efficient Active Search (EAS)."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper addresses a critical and practical problem in Neural Combinatorial Optimization (NCO).\n2. The core contribution—a fully derivative-free meta-learning framework for instance-level NCO. While MAML and NES are existing methods, their combination to solve the specific limitations of gradient-based instance adaptation in scheduling is a sufficient methodological contribution.\n3. The comprehensive experiments are a strength.\n   - The method is tested on two different scheduling problems (FJSP, JSP), two different learning paradigms (RL and self-supervised), multiple synthetic datasets (SD1, SD2), and standard public benchmarks (mk, la, Taillard).\n   - Comparison against strong and relevant baselines, including exact solvers (OR-Tools), strong heuristics (MWKR), base models (DANIEL, SPN), and state-of-the-art gradient-based adaptation methods (AS, EAS).\n   - Sufficient ablation studies: DFO vs. Gradient Adaptation, DFO-Meta vs. DFO-only, DFO-Meta vs. Gradient-Meta, the proposed MC estimators, and GPU parallelization.\n4. The method performs well on both the RL-based DANIEL and the self-supervised SPN. Furthermore, the scalability experiments on larger $50 \\times 20$ and $100 \\times 20$ instances (Table 8) are impressive, highlighting a benefit of the DFO approach: much higher memory efficiency than gradient-based adaptation (AS/EAS).\n5. The motivation is clear, the logical flow is sound, and it effectively uses figures (Figs 1, 2) and algorithms (Algs 2, 3) to explain the complex framework."}, "weaknesses": {"value": "1. **Training Cost:** The main drawback is the computational cost of DFO, which the authors acknowledge. Appendix C confirms the method requires approximately 1.5-2x the training time and GPU memory of the gradient-based FOMAML baseline. While the authors argue this is a reasonable trade-off for offline training, the high cost of population-based methods remains a significant barrier. A population size of $\\mu=100$ and 200 epochs represent a substantial computational investment.\n2. **Hyperparameter Sensitivity:** NES and other DFO methods are often highly sensitive to hyperparameters (e.g., population size $\\mu$, noise standard deviation $\\sigma$, step sizes $\\alpha, \\beta$). The paper states these were tuned on the smallest instance size and fixed, which is a reasonable protocol. However, the paper lacks a sensitivity analysis. Given that DFO methods can be \"notoriously\" difficult to tune, including a brief analysis (e.g., in the appendix) showing how performance varies with different $\\mu$ or $\\sigma$ values would significantly enhance the paper's practical value and demonstrate the method's robustness. The sensitivity of DFO methods like NES to hyperparameters such as population size $\\mu$, noise standard deviation $\\sigma$, and learning rates $\\alpha, \\beta$ is well-known. The paper fails to provide any sensitivity analysis for these critical hyperparameters. This calls the reproducibility and robustness of the experimental results into serious question. We cannot judge whether the current SOTA results are the product of immense hyperparameter-babysitting or if the method is genuinely robust.\n3. The paper's core contribution is an effective combination of two well-known techniques—MAML (meta-learning) and NES (derivative-free optimization)—applied to a known problem (instance-level adaptation). Neither meta-learning for NCO nor instance-level adaptation (as shown by AS/EAS) are entirely new concepts.\n4. The choice of NES (a DFO method) as the core optimization strategy might be a \"brute-force\" choice. It essentially uses massive computational resources and sample complexity (population-based search) to bypass the (researchable) challenges faced by gradient-based adaptation. One of the key comparisons in the paper (Table 5) shows that the authors' proposed DFO method offers a relatively weak performance improvement over standard gradient meta-learning (FOMAML) (e.g., on $20 \\times 10$ SD2, greedy mode only improves from 21.22% to 23.21%, and sampling mode only from 14.72% to 19.36%). To achieve this slight improvement, Appendix C (Table 9) shows that the authors' method requires **1.5 to 2 times** the training time and GPU memory. Exchanging 2x the computational resources for a 2-4% performance gain makes the method's adoption in other domains difficult.\n5. DFO not needing to store gradients at inference time, thus having low memory usage, is its inherent characteristic, but its training-stage cost (Table 9) is large (e.g., $11.2$ hours for $20 \\times 10$)."}, "questions": {"value": "1. **Training Time vs. Baselines:** Appendix C provides an excellent comparison of training costs against FOMAML. However, how does the total meta-training time (e.g., 11.2 hours for $20 \\times 10$) compare to the *original pre-training time* of the DANIEL baseline? Understanding the *total* training budget (pre-training for DANIEL vs. meta-training for the proposed method) would provide a clearer picture of the overall computational trade-off. Training a model that requires 11 hours ($20 \\times 10$) suggests that addressing the conflict between \"inference-time memory advantage\" and \"training-time catastrophic cost\" might be a necessary component.\n2. **Rationale for MC Estimators in Ablation:** In Section 5.2, the paper states \"MC averaging\" is used for greedy mode and \"MC best-sample\" for sampling mode. This is intuitive. However, in the ablation study (Figure 3), all estimators (including MC averaging) are evaluated in *sampling mode*. Can you clarify this? Was MC averaging also evaluated in greedy mode? Was the MC best-sample strategy *also* shown to be suboptimal for greedy mode, or is MC averaging indeed the best choice for greedy mode?\n3. **\"Perturbation-on-Perturbation\" Variance:** The paper makes an interesting point in 4.1.2 that the \"perturbation-on-perturbation\" mechanism increases the variance of the natural gradient estimate. Does this imply that the \"NES\" baseline in Table 3 (i.e., DFO fine-tuning *without* meta-learning) is more stable or converges faster (per-instance) during its test-time adaptation, even if its final solution quality is worse?\n4. **Sensitivity to Population Size:** The population size $\\mu=100$ seems to be a critical hyperparameter. What was the rationale for choosing this specific value? How much does performance degrade if a smaller, computationally \"cheaper\" population is used (e.g., $\\mu=20$ or $\\mu=50$)? A sensitivity analysis on key NES hyperparameters (especially population size $\\mu$ and noise $\\sigma$) may be needed. This is a core issue for DFO methods. Without this analysis, reviewers cannot assess whether your method is robust or requires extreme tuning to achieve the claimed performance.\n5. Given that the authors' method (Appendix C) requires up to 2x the training overhead, while the performance gain over standard gradient meta-learning FOMAML (Table 5) is small, strong evidence may be needed to prove that this complex, computationally expensive DFO framework truly offers a substantial advantage over simple FOMAML. An elaboration on this would strengthen the paper.\n6. **Justification for MC Best-Sample:** Using MC best-sample (Eq. 3) to estimate fitness in the inner loop seems to \"overfit\" to the \"sampling mode\" during the meta-training phase. Does this estimator harm the model's performance in \"greedy mode\"? Did the authors compare whether the greedy mode performance would be better if MC averaging was used uniformly?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zi9ZS48jUe", "forum": "XcCqRcHzJ3", "replyto": "XcCqRcHzJ3", "signatures": ["ICLR.cc/2026/Conference/Submission24267/Reviewer_2y5p"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24267/Reviewer_2y5p"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24267/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761376382139, "cdate": 1761376382139, "tmdate": 1762943023957, "mdate": 1762943023957, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the problem that existing DRL approaches for job-shop and flexible job-shop scheduling optimize the average performance across training instances, which often leads to poor performance on specific individual instances. Existing test-time adaptation methods improve individual instances through fine-tuning, but they operate only at inference time, do not transfer adaptation knowledge across instances, and rely on gradient-based optimization, which can be ineffective in combinatorial search settings.\n\nThe authors propose a derivative-free instance-wise meta-learning framework. Instead of learning a single general policy, the method meta-learns an initialization of the policy parameters that is explicitly optimized to be adapted efficiently to each new scheduling instance. The approach uses NES to perform both inner-loop adaptation and outer-loop meta-updates, avoiding gradients entirely. Additionally, the paper introduces a GPU-parallelized population evaluation mechanism, enabling efficient large-scale derivative-free optimization.\n\nExperiments on FJSSP (and additionally JSSP with a non-RL model) show that the meta-learned initialization enables faster and better per-instance adaptation than prior approaches, and generalizes to larger unseen scheduling instances."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The authors explicitly shift the learning objective from maximizing average policy performance to optimizing instance-wise adaptability, which departs from the dominant paradigm in DRL-based scheduling. In addition, the paper contributes a system-level innovation, parallelizing population evaluations on GPUs. Hence, the paper offers a novel combination of ideas, which to my knowledge has not been applied in NCO. While individual components (MAML, NES, DRL scheduling) exist, the integration and the shift in optimization objective represent a meaningful contribution.\n\n- The authors claim that their meta-learned initialization enables more effective per-instance adaptation than gradient-based approaches. The experiments include multiple baselines (heuristic, OR-Tools, DRL, AS, EAS) and include ablation studies that isolate the effect of meta-learning and derivative-free optimization independently.\n\n- The experimental setup is thorough and follows best practice: standard benchmark datasets and larger unseen instances are evaluated. Further, hyperparameters and architectures are reported in sufficient detail for reproducibility. The ablations and generalization tests strengthen the claim that improvements arise from the proposed components rather than from tuning or dataset-specific effects."}, "weaknesses": {"value": "- The paper combines multiple complex components at once (meta-learning, NES, scheduling, PPO), but the authors do not clearly modularize the explanation. Heavy notation is introduced early, creating a high cognitive load before the conceptual flow is fully established. Although figures exist, they are not tightly integrated with the algorithmic description, which makes it difficult to follow how the components interact.\n\n- The authors state that NES is superior to gradient-based adaptation, but the paper does not provide a deeper narrative or analytical justification beyond empirical observation. There is no analysis of failure modes or why gradient-free adaptation is particularly effective in this setting.\n\n- The experimental section includes many numerical comparisons, but offers very limited interpretation of the observed behavior. The focus is on performance differences rather than understanding the mechanism behind them.\n\n- The authors claim the approach is architecture- and domain-agnostic. The experiments do demonstrate architecture-agnostic behavior to a certain degree, but domain-agnostic generality is not evidenced, as all evaluations are restricted to JSS/FJSS scheduling problems."}, "questions": {"value": "- Could you provide evidence or analysis showing why gradient-based adaptation fails and identify cases where gradient-based adaptation performs similarly or better? Additionally, what properties of the problem or model determine when NES has an advantage over gradient-based optimization?\n\n- Could you provide a more detailed efficiency analysis such as wall-clock runtime breakdown, GPU utilization, and the contributions of population size and sampling to compute cost? Additionally, is the training overhead representative for inference as well, or does inference scale differently?\n\n- Since the computational cost of NES scales roughly linearly with population size, could you provide an ablation study showing how different values of the population size affect solution quality, runtime, and adaptation stability?\n\n- Do you have an idea, which characteristics a problem must have for your method to be effective?\n\n- The empirical section shows strong quantitative improvements. However, you do not provide qualitative insights into how the adapted decisions change. Could you include a qualitative or visual analysis showing how adaptation alters decisions and why it leads to better performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FuBWmLfmZl", "forum": "XcCqRcHzJ3", "replyto": "XcCqRcHzJ3", "signatures": ["ICLR.cc/2026/Conference/Submission24267/Reviewer_3mss"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24267/Reviewer_3mss"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24267/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761726775648, "cdate": 1761726775648, "tmdate": 1762943023758, "mdate": 1762943023758, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a derivative-free meta-learning framework for solving NP-hard scheduling problems (JSP and FJSP). The approach aims to address two main limitations of existing learning-based scheduling methods: (1) they optimize average performance rather than instance-specific quality, and (2) existing test-time adaptation methods like Active Search (AS) and Efficient Active Search (EAS) use gradient-based optimization and don't share knowledge across instances.\n\nThe proposed approach builds on MAML (an efficient DRL-based appraoch) and on Natural Evolution Strategies (NES) for derivative-free optimization"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1) Novelty: while neither component (MAML and NES) is novel in itself, they are used in a way that is novel for the domain.\n\n2) Comprehensive evaluation: the evaluation covers multiple environment sizes and consists of several public benchmarks.\n\n3) Empirical improvement: the appraoch achieves consistent improvement across multiple experiments."}, "weaknesses": {"value": "1) Lack of statistical significance tests: while the appraoch shows improvement in most cases, in some cases the improvement is small. The standard deviation is not presented (except for one table in the appendix), so it is impossible to determine whether the results are significant. Statistical significance tests would strengthen the authors' claims regarding the superior performance of their approach.\n\n2) Training cost no sufficiently emphasized and discussed: while parallelization is a plus, the training cost is significant. In some cases, training can take more than twice the time of competitors. Moreover, the gap (i.e. the difference in percentages between the proposed approach and FOMAML) seems to grow as the problem grows more complex. This raises significant questions regarding the feasibility of the approach for large-scale problems.\n\n3) No analysis of hyperparameters or sensitivity analysis: No analysis is provided on sensitivity to key parameters like population size (μ=100), noise standard deviation (σ=0.2), or number of inner-loop steps (K=3). How robust is the method to these choices?"}, "questions": {"value": "I invite the authors to address the weaknesses mentioned above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ETPLjMwJab", "forum": "XcCqRcHzJ3", "replyto": "XcCqRcHzJ3", "signatures": ["ICLR.cc/2026/Conference/Submission24267/Reviewer_3BUB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24267/Reviewer_3BUB"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24267/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762032088044, "cdate": 1762032088044, "tmdate": 1762943023380, "mdate": 1762943023380, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}