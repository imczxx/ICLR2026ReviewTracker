{"id": "QSU9JediCa", "number": 15372, "cdate": 1758250699840, "mdate": 1759897311046, "content": {"title": "DESIGN: Encrypted GNN Inference via Server-Side Input Graph Pruning", "abstract": "Graph Neural Networks (GNNs) enable powerful graph learning, yet Fully Homomorphic Encryption (FHE) makes inference prohibitively expensive. We present DESIGN (EncrypteD GNN Inference via sErver-Side Input Graph pruNing), a server-side framework that reduces FHE cost without client changes. DESIGN computes encrypted degree–based importance scores and uses homomorphic comparisons to produce multi-level masks, which drive two optimizations: logical pruning of low-importance nodes and edges, and importance-aware assignment of low-degree polynomial activations to most nodes while reserving higher degrees for critical ones. Across standard benchmarks, DESIGN substantially accelerates encrypted GNN inference while maintaining competitive accuracy. Code is available at \\href{https://anonymous.4open.science/r/DESIGN-7F93}{\\url{https://anonymous.4open.science/r/DESIGN-7F93}}.", "tldr": "", "keywords": ["GNN", "FHE", "Pruning", "Encrypted inference"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/862bde4824c6720cedfb9a22ea40ef1b0e1305bd.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes DESIGN, a server-side method for homomorphically encrypted GNN inference. The key idea is to estimate node importance directly over encrypted graphs via degree statistics and approximate homomorphic comparisons, enabling pruning of low-importance structure. It also assigns polynomial activation degrees based on importance levels to reduce costly multiplications. Experiments over multiple benchmarks report noticeable latency reductions while maintaining accuracy in a comparable range to recent FHE-GNN systems."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper addresses a meaningful problem setting: fully server-side FHE-GNN inference without client modifications.\n2. Experimental results show that the proposed method can achieve consistent latency improvements across multiple datasets.\n3. This paper includes ablations and sensitivity analysis to illustrate cost-accuracy trade-offs.\n4. The proposed framework is modular and could integrate with various GNN layers."}, "weaknesses": {"value": "1. The “degree” to “importance” assumption is weakly motivated and likely task-misaligned. Accuracy drops indicate that important information is pruned away.\n2. The degradation pattern suggests structural brittleness that without a more expressive encrypted importance estimator, the system cannot improve through incremental refinement.\n3. Contribution remains primarily system-level optimization, without a clear conceptual advance."}, "questions": {"value": "1.\tWhat empirical evidence supports degree as a reliable proxy for task importance under encrypted inference? Have you compared against any other encrypted-feasible statistics (e.g., weighted degree, simple encrypted feature norms)?\n2.\tHow does the method behave on graphs where degree is anti-correlated with classification relevance (e.g., heterophilic graphs)?\n3.\tIn Table 2: why does SEAL achieve 68.10% on Cora while OpenFHE drops to 28.00%, despite both being foundational FHE implementations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "uCfUla3ZUl", "forum": "QSU9JediCa", "replyto": "QSU9JediCa", "signatures": ["ICLR.cc/2026/Conference/Submission15372/Reviewer_YBd8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15372/Reviewer_YBd8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15372/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761869322109, "cdate": 1761869322109, "tmdate": 1762925654765, "mdate": 1762925654765, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the significant computational overhead of performing Graph Neural Network (GNN) inference on sensitive data under Fully Homomorphic Encryption (FHE). The high cost of homomorphic operations makes direct application of FHE prohibitively slow for practical use. The authors propose DESIGN, a server-side framework that accelerates encrypted GNN inference without requiring any client-side modifications.\nThe core contribution is a novel \"dual-pruning\" scheme that operates entirely on encrypted data. First, the framework computes an FHE-compatible importance score for each node (using encrypted node degree as an efficient proxy). Second, it uses approximate homomorphic comparison protocols to partition nodes into multiple importance levels, generating a set of encrypted masks. These masks then drive two concurrent optimizations during inference: (1) the logical pruning of unimportant nodes and their incident edges, reducing the volume of data to be processed, and (2) an adaptive activation mechanism that assigns computationally cheaper, low-degree polynomial activation functions to less important nodes while reserving more accurate, high-degree polynomials for critical ones. The authors claim that across several benchmark datasets, DESIGN substantially accelerates inference (e.g., 1.67x-2.39x speedup over a SEAL baseline) while maintaining competitive accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe paper tackles an important and timely problem—improving the practicality of encrypted GNN inference under FHE—and proposes a coherent, end-to-end framework that operates entirely on the server side.\n2.\tThe dual-pruning design is technically elegant and well-justified: a single encrypted importance metric (degree) drives both pruning and adaptive activation allocation, which efficiently balances latency and multiplicative depth."}, "weaknesses": {"value": "1.\tThe pruning masks are generated dynamically at runtime for each encrypted graph, meaning computation patterns (e.g., number of masked nodes or chosen activation degrees) depend on input data. This introduces potential side-channel leakage through timing or resource-usage patterns, which could reveal structural information such as degree distribution. The paper does not acknowledge or mitigate this risk, leaving a gap in its privacy analysis.\n2.\tThe choice of node degree as the sole importance metric is efficient but simplistic. The authors justify it by low homomorphic cost, yet DESIGN has not been tested on graphs where degree poorly correlates with node importance (e.g., heterophilic or feature-dominant graphs). The generality of the approach is therefore unverified.\n3.\tThe trade-off between the initial HE.AprxCmp partitioning cost and subsequent latency savings is not quantitatively analyzed. While Table 3 includes partial timing information, there is no full phase-by-phase breakdown or multiplicative-depth accounting to confirm where gains originate or when the upfront cost is amortized.\n4.\tThe “Pruning-Only” variant sometimes achieves higher accuracy than the baseline, but the explanation remains speculative. No diagnostic analysis (e.g., degree quantiles or label consistency of pruned nodes) is provided to substantiate the claim that pruning removes noisy neighborhoods.\n5.\tScalability remains unclear. All evaluations use small graphs (≤10K nodes) and shallow architectures (two-layer GCNs). Although the authors acknowledge that HE.AprxCmp has quadratic complexity in node count, they provide no empirical or theoretical scaling analysis to indicate practical limits.\n6.\tThe evaluation section contains predictive wording (“expected,” “anticipated”) in places where results have already been measured (e.g., Table 1). This inconsistent tone weakens the paper’s empirical rigor.\n7.\tThe notion of “importance” is narrowly defined. The authors do not discuss how importance could be generalized to incorporate features or learned weights while maintaining FHE efficiency."}, "questions": {"value": "1.\tHave the authors considered possible side-channel leakage due to data-dependent computation patterns (runtime pruning and adaptive activation)?\nCould a server observing timing or resource usage infer graph structural information (e.g., degree distribution)?\n2.\tCould you provide a clearer runtime and multiplicative-depth breakdown across the major stages—HE.AprxCmp and masking versus per-layer aggregation and activation?\nThis would help verify that the initial cost is offset by the subsequent gains.\n3.\tHow sensitive is DESIGN to the node-degree assumption?\nHave you tested or can you discuss cases (e.g., heterophilic graphs, feature-dominant tasks) where degree may not correlate with importance?\n4.\tThe “Pruning-Only” variant improves accuracy over the baseline on some datasets.\nCan you analyze which nodes are pruned (e.g., degree quantile, label homophily) to validate whether this acts as regularization?\n5.\tWere iteration limits and encryption parameters consistent across all baselines (SEAL, Penguin, LinGCN, CryptoGCN)?\nIf not, please clarify the resource budgets to justify fairness.\n6.\tWhat are the practical scalability limits of the homomorphic comparison stage?\nAt what graph size or number of partitions does its cost dominate overall latency?\n7.\tHow would DESIGN generalize to deeper GNNs or different architectures (GraphSAGE, GAT) that use multi-hop or attention-based aggregation?\n8.\tCould you discuss how “importance” might be extended or learned under FHE while maintaining efficiency, for instance by mixing structural and feature-based metrics?\n9. Others see Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bhpX9rxcKM", "forum": "QSU9JediCa", "replyto": "QSU9JediCa", "signatures": ["ICLR.cc/2026/Conference/Submission15372/Reviewer_A5uV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15372/Reviewer_A5uV"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15372/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761901335597, "cdate": 1761901335597, "tmdate": 1762925654186, "mdate": 1762925654186, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper DESIGN proposes an efficient framework for encrypted GNN inference under fully homomorphic encryption. It introduces server-side input graph pruning and adaptive polynomial activations to reduce the computational cost of FHE-based operations. Node degree is used as an encrypted importance indicator, enabling structure-aware pruning and selective activation without decrypting the graph."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. tackles the practical challenge of efficient GNN inference under fully homomorphic encryption (FHE).\n2.Clearly defines the computation and accuracy trade-off in encrypted GNNs and provides quantitative evidence."}, "weaknesses": {"value": "(1)Lack of justification for using node degree as the importance metric.\n The use of node degree as the only importance metric is heuristic and may not reflect true semantic importance.\n(2)Missing analysis on sensitivity or correlation.\nAlthough Appendix C analyzes pruning thresholds, there is no quantitative analysis showing how well degree-based importance aligns with actual contribution to model accuracy or message propagation strength.\n(3) The adaptive activation scheme lacks theoretical justification and error analysis.\n(4) The encrypted degree computation may still leak structural patterns statistically, posing privacy risks."}, "questions": {"value": "See weakness above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "66w8W6q65W", "forum": "QSU9JediCa", "replyto": "QSU9JediCa", "signatures": ["ICLR.cc/2026/Conference/Submission15372/Reviewer_8TpL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15372/Reviewer_8TpL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15372/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761914926392, "cdate": 1761914926392, "tmdate": 1762925653664, "mdate": 1762925653664, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "DESIGN presents an efficient framework for performing GNN inference on fully homomorphically encrypted data, enabling privacy-preserving computation through server-side graph pruning and adaptive processing. The framework securely estimates node importance scores under encryption to prune less significant regions of the graph, thereby reducing redundant homomorphic operations. Additionally, it enhances efficiency by dynamically selecting polynomial activation functions of different degrees according to each node’s importance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The research problem is both meaningful and timely, as reducing inference latency remains a critical challenge in privacy-preserving GNN computation. The proposed approach of offloading computation to the server side is practical and well-aligned with real-world deployment scenarios, making the framework readily adaptable for practical implementation."}, "weaknesses": {"value": "In the evaluation section, the latency breakdown is insufficiently detailed, it remains unclear how much of the total runtime is attributed to graph pruning versus HE computation within the GNN. Furthermore, the process of generating encrypted graph masks appears to introduce additional HE operation complexity compared to prior methods. This aspect should be further clarified and quantitatively analyzed by the authors to better understand its impact on overall performance and scalability.\n\nWith the proposed method, the pruned graph produces encrypted binary masks. Although these masks represent Boolean outcomes based on thresholding, it is unclear how the encrypted zeros can practically contribute to accelerating inference. Further clarification is needed on how computation on these encrypted masks leads to latency reduction?"}, "questions": {"value": "see weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "no"}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "OBRadDI9vG", "forum": "QSU9JediCa", "replyto": "QSU9JediCa", "signatures": ["ICLR.cc/2026/Conference/Submission15372/Reviewer_scBn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15372/Reviewer_scBn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15372/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761946047915, "cdate": 1761946047915, "tmdate": 1762925653237, "mdate": 1762925653237, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}