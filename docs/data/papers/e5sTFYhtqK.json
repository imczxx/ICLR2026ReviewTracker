{"id": "e5sTFYhtqK", "number": 23250, "cdate": 1758341295879, "mdate": 1763744218474, "content": {"title": "Estimating Latent Regularization Parameters in Ill-Posed Problems with Semi-Definite Programming", "abstract": "Tikhonov smoothing is often used in estimation problems in ill-posed settings. In a variety of applications ranging from human-computer interaction to model explainability, it is important to retroactively estimate smoothing parameters from an already trained model. We introduce an inverse regularization problem - one that infers latent smoothing hyperparameters obtained from a trained model and its dataset; and show a fast and effective solution using semi-definite programming. The algorithm directly exploits the stationarity conditions of Tikhonov models to jointly recover the model parameter's prior mean $\\mu$ and Tikhonov precision matrix $T$ from observed optimum $\\theta^*$. Our method formulates this as a multi-constraint least squares problem, providing a novel and interpretable approach. Empirically, our results show that our solution outperforms Bayesian approaches and solver-agnostic baselines on diverse benchmarks including diabetes, lung cancer, and California housing datasets.", "tldr": "We propose an SDP-based solution for inverse regularization problem that recovers the prior mean and Tikhonov precision for a trained model from it’s observed optima, outperforming Bayesian & solver-agnostic baselines across diverse datasets.", "keywords": ["Inverse regularization", "Tikhonov regularization", "Semi-definite programming", "Machine Learning", "Hyperparameter estimation", "precision matrix recovery"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/dc2d1a912c40cd056fe5588b9fe7236d1856fcf7.pdf", "supplementary_material": "/attachment/dbb8d244e0b5a3c1647019e5c7eeed35d3ff01ac.zip"}, "replies": [{"content": {"summary": {"value": "The paper seeks to infer an L2/Tikhonov prior $(\\mu,T)$ from a trained parameter $\\hat\\theta$ via the KKT relation\n$X^\\top(y-X\\hat\\theta)=\\lambda\\,T(\\hat\\theta-\\mu)$. Two procedures are proposed: an alternating SDP and a stacked-equation ``Diverse Priors'' variant using multiple fits. While the algebraic setup is neat, the single-fit problem is non-identifiable in common regimes (large $n/p$, small $\\lambda$), and the theory/experiments do not address this central limitation."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. Clear algebraic formulation via KKT; easy to implement.\n2. Two pragmatic solution paths (alternating SDP; stacked equations)."}, "weaknesses": {"value": "$\\textbf{Non-identifiability}$ In $n \\gg p$ or small $\\lambda$ (typical weight decay), $X^\\top(y-X\\hat\\theta)\\approx 0$ so a single fit pins $\\mu\\approx\\hat\\theta$ but leaves $T$ unconstrained. This is not analyzed or bounded.\n\n$\\textbf{Scope shift.}$ The strongest results rely on multiple retrained solutions (``Diverse Priors''), which is a different setting than the advertised single-fit inverse problem.\n\n$\\textbf{Theory light.}$ No population target, no single-fit identifiability conditions, and no asymptotical or finite-sample guarantees; weaker than existing work on learning optimal Tikhonov regularizers (e.g., Alberti, Giovanni S., et al. \"Learning the optimal Tikhonov regularizer for inverse problems.\" Advances in Neural Information Processing Systems 34 (2021): 25205-25216.).\n\n$\\textbf{Simple evaluation.}$ Lacks stress tests for small $\\lambda$, large $n/p$, ill-conditioning, or modern training (decoupled weight decay); no simple diagnostics (e.g., whether $\\rho=\\|X^\\top(y-X\\hat\\theta)\\|_2$ is small)."}, "questions": {"value": "1. Under what minimal structure on $T$ (e.g., $T=\\alpha I$) is single-fit recovery identifiable?\n\n2. How does recovery error scale with $\\lambda$ (or $\\kappa$) and with the residual in realistic small-$\\lambda$ regimes?\n\n3. If multiple fits are essential, can guarantees be provided for that setting, with the single-fit scope clearly delimited?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "O39F7adk0p", "forum": "e5sTFYhtqK", "replyto": "e5sTFYhtqK", "signatures": ["ICLR.cc/2026/Conference/Submission23250/Reviewer_9rNt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23250/Reviewer_9rNt"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23250/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761450751314, "cdate": 1761450751314, "tmdate": 1762942574494, "mdate": 1762942574494, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "We thank all the reviewers for their detailed and valuable feedback. We choose to withdraw our paper and focus on improving its issues."}}, "id": "ZuzA7StqT1", "forum": "e5sTFYhtqK", "replyto": "e5sTFYhtqK", "signatures": ["ICLR.cc/2026/Conference/Submission23250/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23250/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763744217587, "cdate": 1763744217587, "tmdate": 1763744217587, "mdate": 1763744217587, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the \"inverse\" estimation of regularization parameters for linear problems (least-square with Tinkhonov regularization). It describes two methods for finding the mean and the matrix for regularizing the $\\ell_2^2$ norm: one method relies on the first order conditions of the least-square, and the other one on an inverse problem."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The idea of finding regularization parameters from the data is an important problem."}, "weaknesses": {"value": "I think the article suffers from many problems that prevents me to recommend it for acceptance: overall, the paper is poorly written (the claims are overly general, vague, and the same ideas are repeated multiple times) and lacks clarity, with a weak scientific contribution.\n\nFirst the paper misses the context: the introduction contains no references and addresses a problem that has already been extensively studied since at least 30 years (the inverse estimation of regularization parameters).\nThe paper overlooks the existing literature entirely, mentioning only a few examples without providing any meaningful comparison or discussion with the proposed approach. The authors make no effort to place their work in a broader context: it remains unclear how this paper differs from existing approaches or what its real contribution is beyond what has already been published.\n\nMoreover most of what is presented as a contribution could be directly taken from a standard machine learning textbook.\nFrom a methodological point of view, there are many problems with the methods proposed. To take (a few) concrete exemples:\n\nMethod 1 is poorly defined and lacks consistency. For example, it is unclear what $b^\\star$ represents or whether it depends on $T^k$. According to the text, either $b^\\star = T^\\star(\\theta^\\star - \\mu^\\star)$, which is not known, or $b^\\star = T^k(\\theta^\\star - \\mu^k)$, in which case the right-hand term disappears.\nThe statement that the solution is of rank one (and that a new “method” must therefore be proposed) suggests that the authors themselves did not clearly understand what they were doing.\nIn reality, this corresponds to the well-known minimization of the trace or nuclear norm of a matrix, a standard technique in inverse problems, which has no connection with the stationarity condition mentioned earlier. (As a side note: the derivation of the optimality conditions for least-square is well known and might as well be taken from a standard reference instead of being derivated).\n\nMethod 2 is no more convincing. It is never explained how the means $\\mu_j$ are chosen in practice, and several sentences are nonsensical, such as: “We use L-BFGS (Quasi-Newton Constrained Residual Minimization) and sum-of-squares loss so that the stationarity equation is exactly recovered.” \n\nThe experimental section is a list of bullet points without clear discussion or critical analysis. Competing methods are not described, their relevance to the considered problem is not explained, and no theoretical comparison with the proposed approach is provided.\nThe reported results are doubtful: the evaluation metrics depend on $T_{\\text{true}}$ for real datasets, a quantity that is in fact inaccessible. The authors mention that $T_{\\text{true}}$ is sampled from a Wishart distribution based on a “reference operator” $Q$, but this $Q$ is never concretely defined for any real dataset.\nOverall, the paper lacks rigor, novelty, and clarity. The paper fails to present any clear or original contribution to the field."}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bURlWBJtFo", "forum": "e5sTFYhtqK", "replyto": "e5sTFYhtqK", "signatures": ["ICLR.cc/2026/Conference/Submission23250/Reviewer_sWgW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23250/Reviewer_sWgW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23250/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761654078081, "cdate": 1761654078081, "tmdate": 1762942574121, "mdate": 1762942574121, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a new setup: given a regularized Ridge regression estimation, i.e., given the learned parameters $\\theta$, how to estimate the value of the Ridge regularization parameters?\nFor this new problem, authors derive a way to estimate the regularization parameters"}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "I see no strength"}, "weaknesses": {"value": "- Lack of motivation. The authors introduce a whole new setup that lack true experimental grounding: **the authors exclusively study (generalized) linear regression**, but constantly provide motivating examples of much more complex settings, using vague and not precise formulation:\n    - \"Consider an LLM performing in-context learning where it classifies new examples provided to it based on a few given examples. How do we characterize the inductive biases used to make these inferences from a small number of examples?\"\n    - \"“assuming that the LLM roughly behaves like a logistic regression, what\nprior beliefs do they have about the parameters?”. \"\n    - \"The interpretation of this problem is most clear in an agentic context. Consider a black-boxy agent that is only known to be applying a linear policy that is a function of state xi .\"\n\n    It feels like authors came with an artificial problem, and thus had to resolve to examples that are way to far from the setting they study.\n    Could authors provide clear and impactful motivating examples for hte setting they study?\n\n- IMO, Equation 1-4 are the basics of machine learning, and should be removed\n- Can authors exactly pinpoint which optimization problem/fixed-point equation is solved?\n- Could authors precisely show the proposed method in an algorithm environment? I did not understand the exact procedure.\n- Can authors confirm that all experiments are done on \"semi synthtetic\" data?"}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "stCtQA1Kqy", "forum": "e5sTFYhtqK", "replyto": "e5sTFYhtqK", "signatures": ["ICLR.cc/2026/Conference/Submission23250/Reviewer_7iFP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23250/Reviewer_7iFP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23250/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761929425057, "cdate": 1761929425057, "tmdate": 1762942573763, "mdate": 1762942573763, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "One can think of a least-squares problem as solving for a MLE problem for theta.  A ridge-regularized least-squares problem corresponds to having a Gaussian prior on the coefficients $\\theta$.  This paper asks whether one can go backwards: Given some training data, and the value for $\\theta$ that the algorithm produces can one infer the mean and variance of the prior (or equivalently the regularization parameters)?\n\nThe paper formulates this as an optimization problem and presents two methods for solving it.  The first is their “Biconvex SDP” method.  They let $T$ be the covariance matrix corresponding to the regularization prior, and $\\mu$ be the mean.  They then solve for $T$ and $\\mu$ by alternating between optimizing over $T$ and $\\mu$.  Their optimization problem includes the nature term of the form $\\|T(\\theta - \\mu) - b\\|,$ corresponding to the fact that $\\theta$ should fit the regularized problem, along with penalty terms that encourage $T$ to have small trace, and $\\mu$ to have small norm.  $T$ is constrained to be PSD, and so their optimization procedure is implemented with SDP.\n\nThe second approach they call the “Diverse priors” method.  The issue is that $T$ is typically underconstrained, and so there is not generally a unique solution. To get around this, they imagine that there are several priors $\\mu_1, \\ldots, \\mu_k$ that are chosen ahead of time. Then observing the coefficients $\\theta_i$ produced for each $\\mu_i$ gives more information about $T$, allowing it to be recovered."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "Recovering the regularization parameters is a nice and well-motivated problem.  The authors give some examples where this might be useful.  For instance a model like an LLM might be used for some classification task, and it’s interesting to try to infer information about the model’s priors, which may give insight into the model.   The optimization methods are fairly standard, but natural and well-motivated. The experiments are generally reasonable and show that these algorithms can be implemented in practice."}, "weaknesses": {"value": "The optimization methods are pretty standard, so in my opinion the main interest in the paper is in the idea of trying to recover priors from observing how a model behaves. This seems interesting, and I wish that the paper leaned into this a bit more.  As it stands I’m not entirely sold on the methods and experiments.  For instance, the experiments show that the diverse priors method dramatically outperforms everything else.  But if I understand the method  correctly, this isn’t particularly surprising. The diverse priors method gets to choose various $\\mu_i$ and so this give the diverse priors additional information that the other algorithms don’t have.   It’s not clear to me whether one has the flexibility to choose $\\mu$ in situations where this method would be useful.  The Biconvex SDP method also doesn’t seem to be a major improvement on other methods, given the experiments, although it appears to be comparable to more standard approaches.  This makes sense – the experiments do not seem to be designed specifically for low-rank $T$, and so the nuclear norm penalty might not give a particular advantage."}, "questions": {"value": "Can the authors give an example of an application where the diverse priors methods could naturally be applied in practice?\n\nWhat was the motivation for using a trace penalty rather than say a Frobenius penalty in the biconvex SDP method?\n\n— Minor Comments —-\nPage 1 “T = A^T. A” – This dot notation is used throughout.  I’m not sure if it’s clearer than just A^T A\n“Black-boxy” -> “black box”\n“While all the baselines…” – remove “while”"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SylRlcL6y7", "forum": "e5sTFYhtqK", "replyto": "e5sTFYhtqK", "signatures": ["ICLR.cc/2026/Conference/Submission23250/Reviewer_HjYq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23250/Reviewer_HjYq"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23250/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761936419247, "cdate": 1761936419247, "tmdate": 1762942573501, "mdate": 1762942573501, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes methods for solving an inverse estimation problem, where given an optimal linear predictor $\\theta^{\\*}$ w.r.t the mean square loss, the goal is to infer the Tikhonov regularization parameter used in the forward problem (i.e., that which produces $\\theta^{\\*}$). The methods rely on the stationarity condition of the forward problem to recover the regularization parameters as the solutions to a constrained least squares objective. Experiments are conducted to quantify the performance of the methods against a collection of baselines."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The topic is relevant to the research community and has applications in high-stakes domains (e.g., medicine). The experiments are carried out on both real-world and synthetically generated data."}, "weaknesses": {"value": "Unfortunately, the paper is ridden with shortcomings at present. Broadly speaking, significant parts of related literature are missing, the presentation lacks conciseness, the technical approach to solving the stated problem formulation is not well motivated or sound, and the paper contains technical mistakes. In particular: \n\n\n\n1. **Related literature**\n\t* The claim of \"we present a new estimation problem called Inverse Regularization.\" is not upheld in the light of i) missing a significant chunk of literature on inverse optimization (detailed below) and ii) a differential analysis w.r.t. the cited literature (given that the modeling approach is claimed to be novel, a thorough comparison of modeling approaches is needed to uphold the claim. The comparison should cover similarities in mathematical formulation, and a differential analysis of approaches to solving them w.r.t. existing methods).\n\t* The studied problem is part of the large niche of inverse optimization which is not discussed. Regularized problems have a corresponding constrained version (see [11] page 243). Through this lens, all works targeted at recovering constraints from the optimal model apply here, yet are not included/discussed (since the literature is too vast to cover here, please see [12, 13, 14] and backtrack through their cited references). \n\n\n2. **Citation practice**\n\t* Inappropriate citations: The appropriate citation for SGD in line 161 is \"Herbert Robbins and Sutton Monro (1951). A Stochastic Approximation Method”. The appropriate citation for L-BFGS line 161 besides the included Liu & Nocedal (1989) is \"Nocedal, Jorge. \"Updating quasi-Newton matrices with limited storage.\" Mathematics of computation 35.151 (1980)\". Citing the sklearn library should follow the instructions [here](https://scikit-learn.org/stable/about.html), and cite \"Pedregosa, Fabian, et al. Scikit-learn: Machine learning in Python. JMLR (2011)\". \n\t* Missing citations: \n\t\t- Examples 1, 2 and 3 should be accompanied by citations and not be merely didactic. The reason is multifold: to inform the respective authors that new research has been developed for their real-world use case; to allow the reader to delve deeper into the practical problem, should they choose to; and to ground the statement that this problem is relevant in practice. \n\t\t- Section 4.1: The biconvex relaxation for approximately solving SDPs via alternate minimization was proposed, based on a summary search, by Shah, Sohil, et al. in \"Biconvex relaxation for semidefinite programming in computer vision. ECCV. 2016.\", yet this work is not cited.\n\t\t- Section 5.4: citation missing for Hamiltonian Monte Carlo, see [9-10] below\n\n\n3. **Technical approach for solving the problem**\n\t* The method in lines 224 - 229 does not ensure PSD-ness of $T$ with projections, factorizations, or the like, so PSD-ness of the approximate solution is not guaranteed\n\t* Section 4.1: No motivation is provided for choosing the bi-convex approach over classical IPMs [1-3] or other cheaper first-order methods [4-8]. Moreover, no commentary is provided on the convergence problems encountered by this type of alternating minimization method and what, if anything, was done to address them (e.g., special initialization schemes).\n\t* Section 4.2: Solving the forward problem requires knowing $A$ and therefore $T$. However, by the problem statement, one does not have access to them, since they're precisely the parameters one seeks to recover. Furthermore, knowledge of $\\mu_j$ is assumed in the forward problem. To my understanding, these statements are in contradiction.\t\n     * Equation B3: the PSD constraint is dropped along with the Trace regularization term, and the latter is not justified\n     * Line 264: Projecting the closed-form solution onto the PSD cone is not identical to computing the constrained minimizer.\n     * The choice of SDP reformulation as a biconvex optimization problem is not motivated by the authors\n\t\n\n4. **Inconsistencies and oddities in the mathematical notation and terminology**\n\t* Strange and non-standard mathematical notation:  (unless it is a repeated typo) line 040, 135, 142, 301, 307, 310 use notation $A^T.A$ to denote matrix multiplication. Even if this was intentional notation, it is neither consistent, nor defined e.g., in a notation section.\n\t* The authors define the regularization parameter $T = A^T.A$ in line 142, but later switch to $T = \\lambda A^T A$ in line 154\n\t* The regularization strength is first denoted as $\\alpha$ in line 135 but further renamed (without reason) as $\\lambda$ in line 140\n\t* Once the data is placed in a matrix, the sum in line 148 should no longer be there\n\t* Notation in line 152, $\\nabla \\theta$ is improper. The gradient $\\nabla$ should be applied to the $\\theta$-dependent function inside the argmin of line 148\n\t* The SDP alluded to in section 4.1 has to be clearly stated in standard form, rather than described in words. Additionally, it is unusual to refer to it as a \"Biconvex SDP\" since the \"biconvex\" qualifier pertains to the specific manner of reformulating SDPs, rather than the SDPs themselves. \n\n5. **Presentation**\n\t* The presentation is verbose, with sections being roughly repeated throughout the paper without adding further information or nuance (e.g., lines 64-73 and lines 113 - 120; lines 029-039 and lines 127-140; the forward optimization problem is stated 3 times without any significant variation in lines 148, 139, 167;) \n\t* Verbal description is preferred over concise mathematical formulations (detailed above), making this paper difficult to follow and imprecise. \n\n\n6. **Experiments and figures**\n\t* The significance of the red dashed line is not explained, though one can presume it indicates the performance level of the best-performing approach\n\t* Convergence plots for the methods used in Sections 4.1 and 4.2 are not provided (and they should, in the light of above comments)\n\t* Hyperparameter tuning approach and final choices thereof are missing \n\n\n7. **Other (minor) notation issues and typos**\n\t* Using $T$ for both the matrix transpose (as a superscript) and for denoting the regularization parameter makes the writing less neat. A solution would be to use the symbol $^\\top$ to denote the transpose. \n\t* Line 437 $\\Sigma$, line 191 \"in-turn\", line 130 \"it's\", 172 \"boxy\"\n\n\n\n\n[1] Nesterov, Yurii, and Arkadii Nemirovskii. Interior-point polynomial algorithms in convex programming. Society for industrial and applied mathematics, 1994.\n\n[2] Alizadeh, Farid. \"Interior point methods in semidefinite programming with applications to combinatorial optimization.\" SIAM journal on Optimization 5.1 (1995): 13-51.\n\n[3] Vandenberghe, Lieven, and Stephen Boyd. \"Semidefinite programming.\" SIAM review 38.1 (1996): 49-95.\n\n[4] Jaggi, Martin. \"Revisiting Frank-Wolfe: Projection-free sparse convex optimization.\" International conference on machine learning. PMLR, 2013.\n\n[5] Burer, Samuel, and Renato DC Monteiro. \"A nonlinear programming algorithm for solving semidefinite programs via low-rank factorization.\" Mathematical programming 95.2 (2003): 329-357.\n\n[6] Wen, Zaiwen, Donald Goldfarb, and Wotao Yin. \"Alternating direction augmented Lagrangian methods for semidefinite programming.\" Mathematical Programming Computation 2.3 (2010): 203-230.\n\n[7] Yang, Liuqin, Defeng Sun, and Kim-Chuan Toh. \"SDPNAL+: a majorized semismooth Newton-CG augmented Lagrangian method for semidefinite programming with nonnegative constraints.\" Mathematical Programming Computation 7.3 (2015): 331-366.\n\n[8] Yurtsever, Alp, Suvrit Sra, and Volkan Cevher. \"Conditional gradient methods via stochastic path-integrated differential estimator.\" International conference on machine learning. PMLR, 2019.\n\n[9] Duane, Simon, et al. \"Hybrid monte carlo.\" Physics letters B 195.2 (1987): 216-222.\n\n[10] Neal, Radford M. \"MCMC using Hamiltonian dynamics.\" Handbook of markov chain monte carlo 2.11 (2011): 2.\n\n[11] James, Gareth, et al. An introduction to statistical learning: with applications in R. Vol. 103. New York: springer, 2013.\n\n[12] Ren, Ke, Peyman Mohajerin Esfahani, and Angelos Georghiou. \"Inverse Optimization via Learning Feasible Regions.\" arXiv preprint arXiv:2505.15025 (2025).\n\n[13] Chan, Timothy CY, and Neal Kaw. \"Inverse optimization for the recovery of constraint parameters.\" European Journal of Operational Research 282.2 (2020): 415-427.\n\n[14] Chan, Timothy CY, Rafid Mahmood, and Ian Yihang Zhu. \"Inverse optimization: Theory and applications.\" Operations Research 73.2 (2025): 1046-1074."}, "questions": {"value": "* Is there any reason why, in \"Phase 2: Forward Regularization\", you choose to train a model rather than rely on the closed-form solution? \n* What initialization scheme do you use in the method in lines 224 - 229? \n* How do the authors know that the poor performance of the \"Biconvex SDP\" is due to \"preference for rank-deficient solutions\" rather than the alternating minimization getting stuck in local minima?\n* Figure 2a) would have benefited from \"average + error-bar\" type plots, as they convey the information more clearly.\n* Do the authors have an explanation for the close performance of Zero Mean Ridge, and their two proposed approaches in Fig. 1b?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "oX6akhVChq", "forum": "e5sTFYhtqK", "replyto": "e5sTFYhtqK", "signatures": ["ICLR.cc/2026/Conference/Submission23250/Reviewer_Qw1Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23250/Reviewer_Qw1Q"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission23250/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762014823252, "cdate": 1762014823252, "tmdate": 1762942573240, "mdate": 1762942573240, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}