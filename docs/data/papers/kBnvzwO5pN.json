{"id": "kBnvzwO5pN", "number": 6959, "cdate": 1758003412280, "mdate": 1759897881503, "content": {"title": "FaLW: A Forgetting-aware Loss Reweighting for Long-tailed Unlearning", "abstract": "Machine unlearning, which aims to efficiently remove the influence of specific data from trained models, is crucial for upholding data privacy regulations like the ``right to be forgotten\". However, existing research predominantly evaluates unlearning methods on relatively balanced forget sets. This overlooks a common real-world scenario where data to be forgotten, such as a user's activity records, follows a long-tailed distribution. Our work is the first to investigate this critical research gap. We find that in such long-tailed settings, existing methods suffer from two key issues: Heterogeneous Unlearning Deviation and Skewed Unlearning Deviation. To address these challenges, we propose FaLW, a plug-and-play, instance-wise dynamic loss reweighting method. FaLW innovatively assesses the unlearning state of each sample by comparing its predictive probability to the distribution of unseen data from the same class. Based on this, it uses a forgetting-aware reweighting scheme, modulated by a balancing factor, to adaptively adjust the unlearning intensity for each sample. Extensive experiments demonstrate that FaLW achieves superior performance.", "tldr": "", "keywords": ["Long-tailed learning", "Unlearning", "Fairness"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/969209d7bd1e89ca7d01610c2f872c033278ae25.pdf", "supplementary_material": "/attachment/37c65385fce70fe0b27a24c05541a22eed4d213f.zip"}, "replies": [{"content": {"summary": {"value": "FaLW addresses machine unlearning when forget sets are long-tailed. It quantifies instance-level unlearning deviation by comparing a sample’s confidence to unseen-class probability distributions, then reweights forgetting loss with a class-aware balance factor, mitigating over-forgetting and under-forgetting and improving accuracy and MIA performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Strengths:\n\n1. This paper first works on the long-tailed forgetting data unlearning\n2. This paper proposes a new plug-and-play instance-wise unlearning method"}, "weaknesses": {"value": "Weaknesses:\n\n1. This paper lacks an explanation of the differences between the unlearning on the general datasets and the long-tailed datasets.\n2. This paper assumes that the class-conditional prediction is a Gaussian distribution, which is too strong. This paper lacks the validation of this key assumption\n3. This paper does not conduct an effective ablation study for each component in Eq. 3.\n4. The results do not contain std\n5. This paper only uses VGG16 for experiments. More models should be tried."}, "questions": {"value": "Please refer to the weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TTb2MKp624", "forum": "kBnvzwO5pN", "replyto": "kBnvzwO5pN", "signatures": ["ICLR.cc/2026/Conference/Submission6959/Reviewer_PHd4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6959/Reviewer_PHd4"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6959/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761630257377, "cdate": 1761630257377, "tmdate": 1762919185241, "mdate": 1762919185241, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces FaLW (Forgetting-aware Loss Weighting), a novel loss design intended to improve the reliability and controllability of machine unlearning. The key idea is to dynamically reweight forgetting and retaining objectives based on the model’s forgetting confidence and feature-space similarity, thus preventing over-forgetting and instability observed in prior works. The authors derive an adaptive weighting function grounded in information-theoretic uncertainty and validate their approach on several image classification benchmarks using standard unlearning baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe paper is, to the best of my knowledge, the first to explicitly formulate long-tailed forget sets (not long-tailed training data) and to show that existing approximate unlearning methods exhibit heterogeneous and skewed unlearning deviations under this realistic setting. This is an underexplored but practical scenario.\n2.\tThe proposed FaLW is conceptually simple, instance-wise, and orthogonal to most gradient-based unlearning pipelines. It can be adopted with minor code changes.\n3.\tThe direction-aware weighting derived from per-class unseen distributions provides a principled way to decide whether to increase or decrease forgetting pressure for each sample, which directly matches the identified deviation phenomena.\n4.\tThe paper is well-written and logically consistent, with clear motivation method experiment alignment."}, "weaknesses": {"value": "1.\tLimited theoretical justification – while the adaptive weighting function is motivated by uncertainty, the derivation remains heuristic. The paper lacks formal analysis or convergence guarantees explaining why the proposed weighting yields more reliable unlearning.\n2.\tAblation insufficiency – although the paper reports a few ablations, it does not disentangle the specific contributions of the uncertainty term versus the similarity term in the weighting function.\n3.\tLack of comparison with recent conformal or calibration-based approaches – given the growing body of work, FaLW should also be compared in terms of uncertainty calibration and reliability metrics to position itself clearly.\n4.\tPotential instability in extreme regimes – adaptive weighting can introduce oscillations or under-forgetting when uncertainty estimates are unreliable, but the paper does not report sensitivity or failure cases."}, "questions": {"value": "See the comments above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gdrUxSUs7e", "forum": "kBnvzwO5pN", "replyto": "kBnvzwO5pN", "signatures": ["ICLR.cc/2026/Conference/Submission6959/Reviewer_N7tQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6959/Reviewer_N7tQ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6959/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761965022326, "cdate": 1761965022326, "tmdate": 1762919184667, "mdate": 1762919184667, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the long-tailed nature of the forgotten data distribution, which is an important and underexplored problem in machine unlearning. The authors identify two key issues in existing methods: Heterogeneous Unlearning Deviation (HUD) and Skewed Unlearning Deviation (SUD), which leads to biased forgettiing and uneven performance across samples. To mitigate these challegnes, they propose a dynamic loss reweighting strategy that adaptively adjusts learning signals based on forgetting difficulty. Experiments on multiple benchmarks demonstrate that the proposed method effectively reduces unlearning bias while maintaining model utility."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper highlights an under-explored but practically important phenomenon in machine unlearning that the forgotten data often follows a long-tailed distribution. The problem is important and the motivation of the work is clear. \n\n2. The formulation of Heterogeneous Unlearning Deviation (HUD) and Skewed Unlearning Deviation (SUD) provides a structured way to analyze performance degradation in unlearning systems, which offers a useful framing for future work.\n\n3. The proposed FaLW is simple but effective. The paper evaluates multiple metrics and the results consistently show that the proposed achieves better balance between unlearning completeness and retained-task performance.\n\n4. The paper is well-organized and easy to follow."}, "weaknesses": {"value": "1. Lack of empirical validation for plug-and-play claim: Although the proposed FaLW (Forgetting-Aware Loss Reweighting) is described as a plug-and-play solution, the paper only evaluates FaLW as a standalone framework. There are no experiments demonstrating its integration into other existing unlearning methods.\n\n2. Limited analysis of the identified issues HUD and SUD: The paper identified two important issues: Heterogeneous Unlearning Deviation (HUD) and Skewed Unlearning Deviation (SUD) as key motivating factors. Howerver, these notions closely resemble exiting sideas such as sample difficulty bias and class imbalance bias from the broader learning literature. The paper does not sufficiently differentiate its definitions from these established concepts, nor provides diagnostics or ablations to examine HUD and SUD independently.\n\n3. Lack of isolated analysis for HUD and SUD: It remains unclear whether HUD and SUD always co-occur or can arise independently. The experiments treat them as jointly existing phenomena under the long-tailed setting, but no analysis is presented to determine their individual effects on unlearning performance.\n\n4. Lack of discussion on design choices and hyperparameter sensitivity: While the method introduces a dynamic loss reweighting mechanism, the paper provides limited justification for specific design choices, like the form of the weighting function,or the dynamic adjustment rule. A more detailed discussion on hyperparameter selection, or sensitivity analysis would strengthen the paper."}, "questions": {"value": "1. How easily can FaLW be incorporated into other unlearning frameworks? Would additional tuning or architecture changes be required, or can it indeed serve as a simple plug-and-play loss modification?\n\n2. How do the proposed HUD and SUD differ formally from sample difficulty bias and class imbalance bias that have been widely discussed in prior works? Are there conditions under which HUD/SUD reduce to these known phenomena?\n\n3. Have the authors considered running controlled experiments to isolate HUD and SUD individually (e.g., a balanced dataset for HUD-only, or uniform sample difficulty for SUD-only) to better understand their respective contributions?\n\n4. What is the rationale for the specific dynamic weighting formulation and update rule? Have alternative forms been tested or theoretically compared?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "M28zEcvJY1", "forum": "kBnvzwO5pN", "replyto": "kBnvzwO5pN", "signatures": ["ICLR.cc/2026/Conference/Submission6959/Reviewer_zD1B"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6959/Reviewer_zD1B"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6959/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977065719, "cdate": 1761977065719, "tmdate": 1762919183996, "mdate": 1762919183996, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the problem of machine unlearning under long-tailed data distributions in the forget set. It demonstrates that in real-world scenarios, the data to be forgotten can be highly skewed. It identifies two interesting  phenomena while unlearning in this situation, Heterogeneous Unlearning Deviation and Skewed Unlearning Deviation and demonstrates them.  To address these issues, the paper  propose FaLW (Forgetting-aware Loss Weighting), an instance-wise dynamic loss reweighting method. The weighting considers model’s current prediction confidence for a sample to the distribution of prediction confidences on unseen data of the same class.  The authors  conduct experiments on multiple image classification benchmarks (CIFAR-10, CIFAR-100, Tiny-ImageNet) demonstrate the effectiveness of FaLW."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper studies a novel problem arising in the context of unlearning and proposes a novel solution to address this. The problem addressed is quite relevant and practical. \n\nThe paper  demonstrates empirically the unlearning deviation problem under long tailed distribution setups,  and  defines  the problem clearly, proposing two kinds of unlearning deviation.   \n\nThe proposed FaLW is sound, addressing the identified problem to the extent possible. \n\nSrong empirical results on several real world data sets to demonstrate the effectiveness of the proposed methodology.  \n\nThe presentation of the paper is clear and well written."}, "weaknesses": {"value": "The methodology addresses the problem to a good extend but suffers from some drawbacks\n\n1. The requirement to have unseen data points from the same class might be impractical.-  in practice such auxulliary data may not be available\n2. FaLW does not provide a formal guarantee or certification that the influence of the forget set is removed \n3. The definition of unlearning deviation in the paper involves a threshold $\\tau_i$, but in the proposed weighing scheme the paper seems to have ignored this. \n4.  The choice of Nornal distribution to model the distribution of predicitive probabailities is not clear.  Why not use a distribution with support in [0,1] which is more appropriate to model distributions."}, "questions": {"value": "1.  How does this approach scale to a setup where we want to unlearn a particular class rather than unlearning a particular point from a given class.  \n2. The paper describes FaLW as plug-and-play, but seems to have demonsrated it using only one specific unlearning approach. how can  FaLW can be used in practice an any  generic unlearning approach ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rYEycD6Zw4", "forum": "kBnvzwO5pN", "replyto": "kBnvzwO5pN", "signatures": ["ICLR.cc/2026/Conference/Submission6959/Reviewer_V5ik"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6959/Reviewer_V5ik"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6959/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761999997870, "cdate": 1761999997870, "tmdate": 1762919183418, "mdate": 1762919183418, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}