{"id": "QRxcXPFWyp", "number": 15678, "cdate": 1758253792416, "mdate": 1759897289598, "content": {"title": "Histogram-constrained Image Generation", "abstract": "Diffusion models have emerged as a dominant paradigm in generative modeling, enabling high-fidelity sampling from complex data distributions. Despite impressive capabilities, controlling diffusion models to produce outputs aligned with user intent remains an open challenge, especially when balancing global coherence with local precision. Existing control mechanisms vary in the granularity of their conditioning signals. For example, textual prompts guide generation globally through high-level semantics, while ControlNet-like approaches secure precise local structure via dense conditions. In this work, we introduce **H**istogram-constrained **I**mage **G**eneration (**HIG**), a novel control mechanism that falls into the middle ground of control granularity. Our framework enforces user-specified distributional constraints (e.g., color histograms or latent token distributions) during the generation process with exact precision. We model such control as an optimal transport (OT) problem and apply explicit guidance transformations during sampling, thereby driving the diffusion trajectory to align with the desired histogram. We demonstrate the versatility of HIG across diverse applications, including constrained generation via color/latent histograms and high-capacity information embedding through histogram-level encoding. Our findings underscore the promise of distributional control, a flexible and interpretable control scheme that is fully compatible with existing control mechanisms, diversifying the hybrid strategies for controllable image generation.", "tldr": "We introduce a novel control scheme that enforces distributional constraints on the generated images.", "keywords": ["Diffusion Models", "Constrained Generation"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/12dd90305a7cb179a95bee418fd8eafe6709061a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Histogram-Constrained Image Generation (HIG), a diffusion-based method that enforces user-specified histogram constraints (e.g., color or latent token distributions) during the image generation process. The constraint is modeled as an Optimal Transport problem and applied as explicit perturbations in the sampling process. The authors present this as a new form of “distributional control” between global semantic and local structural conditioning. Experiments show that HIG can produce images whose color histograms exactly match the given targets and can embed information via histogram encoding."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The proposed method is training-free and compatible with existing control methods, such as ControlNet or LoRA.\n\n2. The method can enforce exact alignment between the generated images and the target histograms, as shown by the zero HistKL values in Table 1, which confirms the precision of the proposed constraint mechanism.\n\n3. The paper is clearly written and easy to follow."}, "weaknesses": {"value": "1. **Unclear application distinction and benefits**: While the paper claims that HIG ensures distributional consistency and enables several applications (line 89), two of these applications substantially overlap with existing tasks.\n\n* Color-constrained generation appears conceptually similar to classical style transfer. The paper could better articulate what fundamental distinction HIG introduces, or why strict histogram alignment is particularly advantageous for this task. In terms of performance, in several examples (e.g., Fig. 5, first row, third image), histogram alignment introduces visible artifacts, while in others (e.g., Fig. 5, third row, last image), content consistency is compromised. These issues undermine the claimed controllability and visual fidelity.\n\n* The information embedding task also largely overlaps with diffusion-based steganography methods such as DiffSteg [4] and HiDiffusion [5]. However, the manuscript reports results in isolation, without any quantitative or qualitative comparison to such baselines. It is unclear what unique benefits that histogram-based embedding provides compared to prior diffusion-based steganography approaches.\n\n2. **Novelty concerns**: The proposed use of histogram matching for style transfer is not new — similar ideas have already been explored, such as [1]. In addition, employing Optimal Transport (OT) for color transfer and histogram alignment has been extensively studied in prior works [2][3]. This work mainly adapts these established concepts into the diffusion sampling loop, rather than introducing a novel formulation or demonstrating clear advantages over existing OT-based histogram matching approaches.\n\n3. **Concerns about generalization and robustness**: The main experiments rely on SDXL, an outdated backbone. Although the authors claim HIG is compatible with newer DiT-based models, Appendix E only shows HIG's color transfer results on FLUX.1[dev], without comparing with state-of-the-art DiT-based style transfer methods or visualization. In addition, integrating HIG with DreamBooth produces noticeable identity inconsistence in the “LoRA anime” case (Appendix B, Fig. 9), but the paper did not analyze the cause of this degradation.\n\n\n\n**References**\n\n[1] Zhang, Y. et al., Exact Feature Distribution Matching for Arbitrary Style Transfer and Domain Generalization, CVPR 2022.\n\n[2] Lim, F. et al., Order Constraints in Optimal Transport, ICML 2022.\n\n[3] Larchenko, M. et al., Color Transfer with Modulated Flows, AAAI 2025.\n\n[4] Zhang, H. et al., DiffSteg: Diffusion Model for Image Steganography, ICCV 2023.\n\n[5] Wang, J. et al., HiDiffusion: Hiding Information in Diffusion Models for Steganography and Watermarking, CVPR 2024."}, "questions": {"value": "See my comments in Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YTYJtF92Dw", "forum": "QRxcXPFWyp", "replyto": "QRxcXPFWyp", "signatures": ["ICLR.cc/2026/Conference/Submission15678/Reviewer_jNUJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15678/Reviewer_jNUJ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15678/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761739259397, "cdate": 1761739259397, "tmdate": 1762925932087, "mdate": 1762925932087, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors proposed a new conditional image generation method that adds optimal transport steps to adjust color distribution during diffusion model inference. The target color histogram can be either extracted from a real reference image or implicitly obtained from optimizing the so-called information embedding of an LLM. The authors showed that the proposed method can generate quality images with higher semantic and aesthetic scores, and advertised the efficient training-free nature of the method."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is really well-presented. The generated images in the paper are visually appealing. Diagrams are clear. Most of the paper is easy to follow, except for the information embedding part. See my question below.\n2. The proposed method outperforms the baselines both visually and quantitatively. Being efficient is also important for any practical usage of diffusion models."}, "weaknesses": {"value": "1. My main concern for this paper is that, if 1-2 optimal transports are already sufficient for generating the target color distribution, this task might not be difficult enough. Looking at the reference images presented in the paper, they are almost all synthetic images with highly concentrated color histograms, meaning there are only a few colors to spread. How difficult is this transferring task? An important baseline should be directly applying optimal transport to the output without interfering with the diffusion model. The resulting images might have some artifacts, but one can simply run more denoising steps to fix them, which essentially falls into the 1 optimal transport step case of the method.\n2. The perhaps more interesting case with latent histograms is less discussed. Figure 8 shows some harder reference images, but the results are less satisfying. For the TiTok model, the generated image did not preserve the unconstrained generation but became very similar to the reference image. This is against the authors' claim that \"the transformation remains close to the original diffusion trajectory\"."}, "questions": {"value": "1. Using the normalized information embedding as an implicit histogram feels weird to me. They are fundamentally different objects. Could the authors elaborate on the logic behind this? Did the authors specifically design the multi-option optimal transport to make the color histogram the same dimension as the token embeddings?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "IQWKMzOiB8", "forum": "QRxcXPFWyp", "replyto": "QRxcXPFWyp", "signatures": ["ICLR.cc/2026/Conference/Submission15678/Reviewer_7m5F"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15678/Reviewer_7m5F"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15678/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969027709, "cdate": 1761969027709, "tmdate": 1762925930695, "mdate": 1762925930695, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces **Histogram-Constrained Image Generation (HIG)**, a training-free control framework for diffusion models that enforces user-specified distributional constraints (e.g., color histograms, latent token distributions) during sampling. HIG fills the \"middle ground\" of control granularity, between high-level text prompts and low-level dense signals (e.g., ControlNet edge maps), by modeling distributional alignment as an Optimal Transport (OT) problem. It applies minimal-cost OT-based transformations to intermediate diffusion outputs (via a decode-transform-encode cycle) to guide the generation trajectory toward the target histogram."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Optimal Transport Ensures Precision and Minimal Distortion\n   1. OT’s minimal-cost property preserves visual quality.\n   2. Multi-option binning mitigates content distortion.\n   3. Post-hoc OT guarantees exact alignment.\n2. Training-Free Design Enables Low Overhead and Compatibility\n   1. Negligible inference overhead.\n   2. Compatibility with existing controls.\n   3. Generalization to flow-based models.\n3. Diverse Applications Demonstrate Versatility\n   1. Color-constrained generation.\n   2. High-capacity information embedding.\n   3. Latent histogram control.\n4. Reproducibility and Transparency\n   1. Detailed implementation.\n   2. Failure case analysis."}, "weaknesses": {"value": "1. Incomplete Analysis of OT and Binning Design Choices\n   1. Bin count and channel choice lack sensitivity analysis. d=4096 is used for all experiments, but no tests on smaller or larger d or single-channel histograms (e.g., grayscale) are reported. Appendix K compares latent vs. pixel histograms but not bin count’s effect on control precision.\n   2. Multi-option binning k-value selection is arbitrary. $k=16$ is used for multi-option binning (Section 5.1) but no ablations on $k\\in{8,32}$ are provided. It is unclear if larger k improves fidelity or if smaller k reduces computation.\n2. Mathematical and Notation Ambiguities\n   1. OT cost matrix construction is underspecified. Section 3.2 states cost is based on \"L1 distance between color tuples/latent embeddings\" but does not clarify if latent embeddings are pre-trained (e.g., CLIP) or tokenizer-specific (e.g., VQ-GAN codebook). Appendix B’s pseudocode uses RGB L1 but not latent costs, creating ambiguity for latent histogram implementation.\n   2. Soft-prompt to histogram mapping lacks rigor. Equation 6 (soft-prompt optimization) uses a fixed norm $B=40.0$, but no justification for this value is provided. The inverse mapping (Section 4.2) mentions \"scaling factor k\" but does not derive k’s uniqueness mathematically, leaving uncertainty about decoding reliability.\n   3. Intermediate step selection (T) is heuristic. Table 5 shows $T={40}$ (early step) improves CLIP (27.19) while $T={10}$ (late step) improves HistKL (0.54), but no method for optimal T selection is proposed. Users must manually tune T, reducing practicality.\n3. Limited Evaluation of Content Preservation and Generalization\n   1. Content distortion in high-semantic latent spaces. Section 5.4 (TiTok) shows semantic control but no metrics for content preservation (e.g., CLIP alignment with original prompt vs. guidance image). It is unclear if latent OT distorts intended content while enforcing token histograms.\n   2. Lack of user study for aesthetics. Aesthetics scores (LAION-Aesthetics) are used, but no user evaluations of perceptual quality (e.g., preference between HIG and StyleShot) are conducted. Quantitative metrics may not capture subjective judgments of \"naturalness\" after OT."}, "questions": {"value": "1. **How do OT solver choice (simplex vs. Sinkhorn) and bin parameters (d, k) impact speed, alignment, and fidelity, and what guidance can be provided for tuning them?** The paper uses a vanilla simplex solver and fixed d=4096/k=16. Could you add a table comparing Sinkhorn (with entropic regularization) vs. simplex on SDXL, reporting HistKL, latency, and Aesthetics for $d\\in{512,2048,4096}$ and $k\\in{8,16,32}$? Additionally, could you provide a heuristic (e.g., \"choose d=2048 for balanced speed/alignment\") for users with different hardware constraints?\n2. **How does HIG preserve intended content when applying OT to high-semantic latent spaces (e.g., TiTok), and can you quantify this with content-specific metrics?** It is a well-known problem of all granularity control methods that enforcing constraints may distort intended content. Section 5.4 shows semantic control via latent histograms but no content preservation measures.Could you add experiments where you enforce a latent histogram from a \"cat\" image onto a \"dog\" prompt, reporting CLIP scores for \"dog\" (content) and \"cat histogram\" (constraint)? This would clarify if HIG distorts intended content. Also, could you test if adding a content loss (e.g., CLIP between original and OT-transformed latents) mitigates distortion?\n3. **Can you formalize the soft-prompt to histogram mapping (and inverse) and validate its uniqueness across diverse text sequences?** Section 4.2 uses a fixed norm B=40.0 and exponential mapping but no mathematical proof of uniqueness. Additionally, could you test decoding uniqueness by mapping two different soft prompts to histograms, generating images, and verifying that decoded prompts match the original (not swapped)?\n4. **Can you conduct a user study to evaluate perceptual quality and naturalness of HIG-generated images compared to baselines?** While LAION-Aesthetics scores are reported, subjective judgments of \"naturalness\" may not align with quantitative metrics. Could you run a user study where participants rate images from HIG vs. StyleShot and other baselines on a Likert scale for naturalness and preference? This would provide stronger evidence of HIG’s perceptual quality.\n\nOverall, the paper presents a technically sound framework for histogram-constrained image generation via Optimal Transport. I tend to accept the paper, but it would benefit from addressing incomplete analyses (OT solver choice, bin parameters), mathematical ambiguities (cost matrix, soft-prompt mapping), and content preservation evaluations (latent OT distortion). Addressing these questions would strengthen the contribution and practical guidance for users."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "croeANlAzQ", "forum": "QRxcXPFWyp", "replyto": "QRxcXPFWyp", "signatures": ["ICLR.cc/2026/Conference/Submission15678/Reviewer_ZzyM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15678/Reviewer_ZzyM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15678/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984368300, "cdate": 1761984368300, "tmdate": 1762925929255, "mdate": 1762925929255, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Histogram-Constrained Image Generation (HIG), a training-free, inference-time guidance technique for diffusion and flow-based generative models. It enforces user-specified statistical constraints, typically color or latent histogram, directly during sampling by applying optimal-transport based histogram matching to intermediate outputs. The algorithm alternates standard denoising steps with a histogram-projection step that minimally perturbs the diffusion trajectory while achieving the target distribution exactly. Experiments show precise histogram alignment and on-par realism and aesthetics."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**Mathematically sound.**\nThe proposed guidance method is mathematically grounded with an OT projection that ensures precise compliance with user-defined distributions.\n\n**Training-free method.**\nThe proposed approach is training-free and can be integreated to any pretrained generator, which is shown in Fig. 9. This training-free feature implies wide application. It can also be applied to other domains where a distribution can be properly defined, such as 3D, video generation, etc.\n\n**An interesting view of controllable image generation.**\nThis control mechanism serves as a novel paradigm, which extends controllable generation beyond textual and structural prompts to statistical constraints."}, "weaknesses": {"value": "**Debatable histogram-constrained control paradigm.**\nThe core concept, imposing explicit histogram constraints during generation, may be philosophically and practically debatable. Perceptual style or appearance can be achieved more simply through existing style-transfer or color-transfer networks, which already approximate similar outcomes with lower computational cost. The mathematical precision of histogram alignment is appreciated, but this does not necessarily correspond to significant perceptual gains or artistic value, as shown in Tab. 1 (CLIP and Aesthetics), where improvements are marginal and debatable. Unfortunately, in real-world applications, users desire semantic or aesthetic control rather than strict statistical conformity.\n\n**Limited exploration of latent-space histograms.**\nMost experiments focus on color-space constraints. The analysis of latent histogram guidance remains preliminary in Fig. 8 and appendix L. The effect of changing histogram parameters on perceptual or semantic outcomes was not measured, as this would help understand the controllability of the proposed approach under latent guidance."}, "questions": {"value": "1. Why is a solution to the OT problem corresponds to minimal impact on a trained latent generative model? Is this a pure hypothesis or can be mathematically proved?\n\n2. How does computational cost scale with image resolution and number of bins? Since the OT solution is at least O(n^2) complexity, provided approximation is used, this would naturally scale poorly when generating ultra-high resolution images."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ifipVBU8en", "forum": "QRxcXPFWyp", "replyto": "QRxcXPFWyp", "signatures": ["ICLR.cc/2026/Conference/Submission15678/Reviewer_34Z3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15678/Reviewer_34Z3"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15678/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993540188, "cdate": 1761993540188, "tmdate": 1762925928810, "mdate": 1762925928810, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}