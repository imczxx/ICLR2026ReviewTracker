{"id": "BTJmEqVUDF", "number": 3336, "cdate": 1757404539714, "mdate": 1759898095077, "content": {"title": "PhysHandi: Physics-Based Reconstruction of Hand-Deformable Object Interactions", "abstract": "While existing methods for reconstructing hand–object interactions have made impressive progress, they either focus on rigid or part-wise rigid objects—limiting their ability to model real-world objects (e.g., cloth, stuffed animals) that exhibit highly non-rigid deformations—or model deformable objects without full 3D hand reconstruction. To bridge this gap, we present PhysHandi (Physics-based Reconstruction of Hand and Deformable Object Interactions), a framework that enables full 3D reconstruction of both interacting hands and non-rigid objects. Our key idea is to physically simulate object deformations driven by forces induced from densely reconstructed 3D hand motions, ensuring that the reconstructed object dynamics are both physically plausible and coherent with the interacting hand movements. Furthermore, we demonstrate that such simulation of object deformations can, in turn, refine and improve hand reconstruction via inverse\nphysics. In experiments, PhysHandi outperforms the state-of-the-art baseline across reconstruction, future prediction, and generalization to unseen interactions.", "tldr": "", "keywords": ["Interacting hand-object reconstruction"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/84258ab38fd68bd1ba93cc43345acdd54edb5dfd.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper, PHYSHANDI: Physics-Based Reconstruction of Hand–Deformable Object Interactions, proposes a framework for dense 3D reconstruction of interacting hands and deformable objects. The key idea is to couple a parametric hand model (MANO) with a spring–mass simulation of deformable objects, where interaction forces are induced by hand mesh motion. The pipeline consists of three stages: hand reconstruction, object reconstruction, and hand refinement through inverse physics. Experiments on the PhysTwin dataset and a newly collected DENSEHDI dataset show improvements over the prior baseline PhysTwin in reconstruction, future prediction, and generalization"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Inverse physics for hand refinement: The idea of improving hand reconstruction by leveraging reconstructed deformable object dynamics is interesting.\n\n2. Dataset contribution: The authors additionally collect a new dataset (DENSEHDI) featuring denser hand–object contacts, which could benefit the community."}, "weaknesses": {"value": "1. Limited generalization beyond lab conditions:\nAll experiments are conducted in highly controlled RGB-D capture setups (three synchronized RealSense cameras). There is no evidence that the method generalizes to in-the-wild scenarios (e.g., monocular RGB videos, unconstrained lighting, cluttered backgrounds). Given the reliance on multi-view depth, the method is unlikely to scale to real-world applications.\n\n2. Strong assumption on contact regions:\nAs discussed in Section 5, the framework assumes a fixed hand–object contact topology within a sequence. This is a very strong and unrealistic assumption: in real interactions, contacts appear and disappear dynamically (e.g., fingers releasing or sliding over cloth). This limitation significantly reduces the applicability of the method.\n\n3. Lack of extensive visualizations:\nWhile a few qualitative figures are shown in the main paper (e.g., Fig. 3), the visual results are limited in scope. For a reconstruction method, more extensive qualitative evidence (especially videos in supplementary material) is crucial for evaluating realism and stability. Without this, it is hard to be fully convinced of the claimed improvements."}, "questions": {"value": "Please refer to Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "5I0keWBZxf", "forum": "BTJmEqVUDF", "replyto": "BTJmEqVUDF", "signatures": ["ICLR.cc/2026/Conference/Submission3336/Reviewer_rJqj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3336/Reviewer_rJqj"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3336/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760488298205, "cdate": 1760488298205, "tmdate": 1762916678572, "mdate": 1762916678572, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces PHYSHANDI, a physics-based framework for reconstructing hand-deformable object interactions from sparse-view RGB-D videos. PHYSHANDI reconstructs deformable objects with the interaction forces, which are simulated based on reconstructed hand motions. The method further refines hand reconstruction using inverse physics from object deformations."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-written and well-organized.\n\n2. The topic of hand-deformable object reconstruction is interesting."}, "weaknesses": {"value": "1. More HOI methods using Spring-Mass models, such as CPF [1], have not been discussed.\n\n2. The proposed framework relies on the initial MANO-based hand reconstruction to drive the subsequent deformable object simulation. If the hand mesh contains significant errors or inaccuracies, to what extent can PHYSHANDI still reconstruct a meaningful deformable object? Have the authors evaluated the robustness of the object reconstruction under degraded or noisy hand estimates?\n\n3. Is the proposed method sufficiently innovative compared to the baseline method? For example, is there any substantial difference between Section 3.1 and PhysTwin?\n\n4. The paper only compares one method. Please provide comparisons with more methods on more datasets. For the qualitative comparison, please provide results from multiple methods on the same test samples.\n\n[1] CPF: Learning a Contact Potential Field to Model the Hand-Object Interaction. ICCV 2021."}, "questions": {"value": "Same as the above weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8Tz9tyb3yS", "forum": "BTJmEqVUDF", "replyto": "BTJmEqVUDF", "signatures": ["ICLR.cc/2026/Conference/Submission3336/Reviewer_S4t5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3336/Reviewer_S4t5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3336/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760976999482, "cdate": 1760976999482, "tmdate": 1762916678359, "mdate": 1762916678359, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes PHYSHANDI, a physics-based framework that jointly reconstructs a full 3D hand and deformable objects from sparse RGB-D sequences. The method treats the dense MANO hand mesh as boundary conditions that drive a spring-mass object via virtual springs, and then performs inverse-physics refinement so that the learned object model provides supervision and correction for the hand. Experiments on PhysTwin scenarios and the new DENSEHDI dataset report improvements over PhysTwin on reconstruction/resimulation, future prediction, and generalization."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The work specifically targets deformable-object interaction within hand–object reconstruction, which remains underexplored, and it fills a tangible gap.\n2. The supp. discusses the choice of $\\delta$, a key hyperparameter; surfacing part of this analysis in the main paper would further clarify the design.\n3. The paper releases a dataset that benefits the community."}, "weaknesses": {"value": "1. Relative to PhysTwin, the contribution appears incremental. The main change introduces MANO as a topological prior for the hand to improve physical modeling near contact. This design understandably differs from PhysTwin, which targets a robot-arm-plus-gripper setting and therefore does not emphasize detailed hand modeling.\n2. MANO has limited expressiveness for elastic skin and soft-tissue effects. While it encodes hand topology, optimizing $\\Theta$ alone does not capture elastic deformation.\n3. The method depends on several potentially brittle components: accurate depth (which consumer sensors like D455 often noise), and CoTracker for initialization. The accuracy of CoTracker likely has a first-order effect on downstream object reconstruction quality."}, "questions": {"value": "1. Beyond introducing MANO as a hand prior, does the approach support broader application scenarios than PhysTwin, or does it offer a deeper theoretical contribution that the paper can articulate more explicitly?\n2. When modeling hand deformation, do the authors consider alternatives (e.g., non-rigid extensions, blendshape or learned corrective fields) that may better account for elastic effects than optimizing $\\Theta$ alone?\n3. Can the authors include ablations on input quality (e.g., depth noise, missing data) and on dependencies (e.g., CoTracker accuracy, initialization errors) to quantify robustness?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mRkYzhepaf", "forum": "BTJmEqVUDF", "replyto": "BTJmEqVUDF", "signatures": ["ICLR.cc/2026/Conference/Submission3336/Reviewer_asRB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3336/Reviewer_asRB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3336/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920001226, "cdate": 1761920001226, "tmdate": 1762916678187, "mdate": 1762916678187, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces PHYSHANDI, a physics-based framework for reconstructing and simulating 3D hand-deformable object interactions from sparse-view RGB-D videos. The technical contributions include: (1) Dense hand modeling using the MANO parametric hand model. (2) Deformable object simulation via a spring-mass system, where object deformations are driven by forces from reconstructed hand motions. (3) A three-stage optimization pipeline. In experimetns, the method outperforms the state-of-the-art baseline (PhysTwin) in reconstruction accuracy, future prediction, and generalization to unseen interactions, particularly in scenarios with dense hand-object contacts."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe novel dataset DENSEHDI focuses on dense hand-object contacts, addressing a gap in existing benchmarks. \n\n2.\tThis paper achieves the dense 3D reconstruction of both hands and deformable objects simultaneously, ensuring physical plausibility and coherence between hands and object dynamics. \n\n3.\tThe inverse physics design help improve accuracy in sparse-view settings, especially the single-view cases."}, "weaknesses": {"value": "1.\tPhysics-based simulation and optimization may require significant computational resources. Computational cost should be clarified. \n\n2.\tThis paper lacks experiments directly evaluating the accuracy of hand reconstructions. The title of the paper gives hand and object the equal position, but only evaluate objects. The claim in the Abstract “such simulation of object deformations can, in turn, refine and improve hand reconstruction via inverse physics” is not fully supported. \n\n3.\tThe quantitative results do not significantly outperform previous PhysTwin method in Table. 1, especially for  metrics such as SSIM. Why?\n\n4. It seems that the model assumes fixed hand-object contact topology within a sequence, limiting its applicability to interactions with dynamic contact changes (e.g., sliding or rolling). \n\n5. Previous paper \"InteractionFusion: Real-time Reconstruction of Hand Poses and Deformable Objects in Hand-object Interactions, ACM SIGGRAPH 2019.\" should be cited. This is \"another kind\" of hand-deformable object interactions\". In comparison with this paper, this manuscript is more like a dynamic object simulation or cloth simulation paper with a hand-refinement module, which targets refining the object dynamics at the end."}, "questions": {"value": "The main flaw is lack of experiments on hand reconstruction quality."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "oCaSmdUZXO", "forum": "BTJmEqVUDF", "replyto": "BTJmEqVUDF", "signatures": ["ICLR.cc/2026/Conference/Submission3336/Reviewer_rNHX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3336/Reviewer_rNHX"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3336/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993700032, "cdate": 1761993700032, "tmdate": 1762916678034, "mdate": 1762916678034, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}