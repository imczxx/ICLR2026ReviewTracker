{"id": "JsNmDdKJmx", "number": 20011, "cdate": 1758301465157, "mdate": 1759897006363, "content": {"title": "MAR: Medical Asymmetric Retriever for Efficient Chinese Medical Dense Retrieval", "abstract": "Embedding models are critical for domain-specific information retrieval (IR), particularly in healthcare, where accurate, low-latency access to medical knowledge can enhance clinical decision support and mitigate hallucinations in retrieval-augmented generation (RAG) systems.\nHowever, Chinese medical retrieval remains underdeveloped due to the absence of high-quality medical retrieval benchmark. To address this limitation, we propose a novel high-quality Chinese **Med**ical **T**ext **E**mbedding **B**enchmark (**MedTEB**), which covers three practical tasks close to real-world scenarios: retrieval, reranking, and semantic textual similarity (STS). We introduce comprehensive LLM-based annotation in the construction process to improve the quality of curated datasets. Through evaluating existing powerful general-purpose embedding models on MedTEB, we demonstrate that MedTEB is a challenging domain-specific embedding benchmark to evaluate models' retrieval capabilities on Chinese medical retrieval.\nOn this foundation, we propose **M**edical **A**symmetric **R**etriever (**MAR**), an asymmetric embedding architecture that decouples query and document encoding: a lightweight encoder handles online queries with minimal latency, while a powerful and offline LLM-based encoder preserves retrieval quality. Optimizing the asymmetric architecture brings to new challenges. We introduce a novel two-stage optimization framework: 1) **query encoder alignment** and 2) **joint fine-tuning**.\nThrough the novel approach, MAR achieves state-of-the-art (SOTA) performance on MedTEB while maintaining lightweight inference speeds comparable to small-size BERT-style embedding models, leading to an excellent trade-off on accuracy and efficiency and thus offering a practicable and effective solution for real-world Chinese medical retrieval scenarios.\nOur code, data and model will be made publicly available to facilitate future research on domain-specific IR.", "tldr": "We introduce MedTEB (a high-quality Chinese medical retrieval benchmark) and MAR (a lightweight asymmetric retriever), enabling accurate, low-latency Chinese medical retrieval.", "keywords": ["Information Retrieval", "Medical Text Embedding", "Chinese Medical Domain", "Asymmetric Architecture"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ed2e545006cb9a2e8778e253f60d455c2bf2e2b1.pdf", "supplementary_material": "/attachment/787d942a866b631cf25d6eb2c1c8f7b1f02e3ca9.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces MedTEB, a new benchmark for Chinese medical text embeddings covering three tasks—retrieval, reranking, and synonym STS—and proposes MAR (Medical Asymmetric Retriever), an asymmetric dual-encoder framework pairing a lightweight query encoder with a large document encoder.\n\nThe authors then design a two-stage optimization scheme (query alignment and joint fine-tuning) and demonstrate state-of-the-art performance on MedTEB while maintaining efficiency comparable to smaller BERT-style models."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper introduces a comprehensive benchmark (MedTEB) for Chinese medical embeddings with multiple tasks, addressing an underexplored but practically important domain.\n\n2. This paper provides thorough empirical evaluation comparing MAR against a wide range of strong baselines (BGE, GTE, Qwen, etc.), demonstrating consistent efficiency–accuracy improvements."}, "weaknesses": {"value": "1. The proposed MAR framework is primarily a combination of existing asymmetric retrieval and distillation methods (e.g., KALE, HotelMatch), with only minor architectural differences (removing projection layer, using MSE + InfoNCE). The methodological innovation is minimal.\n\n2. Annotation reliability not verified: LLM-based labeling is claimed to be high-quality, but no inter-LLM agreement or human validation statistics are reported.\n\n3. Improvement margins are modest (≈1.3–1.5%), and the methods rely heavily on proprietary LLMs for annotation. The authors also did not  compare with baselines using more parameters such as Qwen-3-embedding-4b, GTE etc.\n\n4. It would be better to also evaluate over different retrieval-based applications such as chinese medical QA. \n\n5. Missing references on medical retrievers:\n\n> [1] Xu et al. \"BMRetriever: Tuning Large Language Models as Better Biomedical Text Retrievers.\" Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. 2024.\n> [2] Jin et al. \"Medcpt: Contrastive pre-trained transformers with large-scale pubmed search logs for zero-shot biomedical information retrieval.\" Bioinformatics 39.11 (2023): btad651.\n> [3] Li et al. \"R2MED: A Benchmark for Reasoning-Driven Medical Retrieval.\" arXiv preprint arXiv:2505.14558 (2025)."}, "questions": {"value": "1. Can you quantify inter-LLM agreement rates or human verification accuracy to support the claim of “high-quality annotation”?\n\n2. How sensitive is MAR to the choice of base document encoder (e.g., Qwen3 vs. BGE)?\n\n3. How would MAR perform in non-medical Chinese retrieval tasks? Does the alignment generalize beyond the medical corpus?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qP2fSC2jwv", "forum": "JsNmDdKJmx", "replyto": "JsNmDdKJmx", "signatures": ["ICLR.cc/2026/Conference/Submission20011/Reviewer_TpzX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20011/Reviewer_TpzX"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20011/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760999511944, "cdate": 1760999511944, "tmdate": 1762932914701, "mdate": 1762932914701, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MedTEB, a new benchmark for Chinese medical text embeddings covering three tasks—retrieval, reranking, and synonym STS—and proposes MAR (Medical Asymmetric Retriever), an asymmetric dual-encoder framework pairing a lightweight query encoder with a large document encoder.\n\nThe authors then design a two-stage optimization scheme (query alignment and joint fine-tuning) and demonstrate state-of-the-art performance on MedTEB while maintaining efficiency comparable to smaller BERT-style models.\n\n### Disclaimer\nI am surprised to find that my review was labeled as \"fully llm-generated\" in https://iclr.pangram.com/. Here I would like to clarify that all the points I wrote here are my own judgments after reading the paper, and I used GPT to make the review more fluent."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper introduces a comprehensive benchmark (MedTEB) for Chinese medical embeddings with multiple tasks, addressing an underexplored but practically important domain.\n\n2. MAR achieves state-of-the-art (SOTA) performance on MedTEB while maintaining lightweight inference speeds comparable to small-size BERT-style embedding models, leading to an excellent trade-off on accuracy and efficiency and thus offering a practicable and effective solution for real-world Chinese medical retrieval scenarios."}, "weaknesses": {"value": "1. The main method for MAR framework is a combination of existing asymmetric retrieval and distillation methods (e.g., KALE, HotelMatch), with only minor architectural differences (removing projection layer, using MSE + InfoNCE). The methodological innovation is minimal.\n\n2. This paper relied on LLM-based annotation. However, this step may introduce additional bias and inaccuracies and no inter-LLM agreement or human validation statistics are reported.\n\n3. Improvement margins are modest (≈1.3–1.5%), and the methods rely heavily on proprietary LLMs for annotation. The authors also did not  compare with baselines using more parameters such as Qwen-3-embedding-4b, GTE etc.\n\n4. It would be better to also evaluate over different retrieval-based applications such as chinese medical QA. \n\n5. Missing references on medical retrievers:\n\n> [1] Xu et al. \"BMRetriever: Tuning Large Language Models as Better Biomedical Text Retrievers.\" Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. 2024.\n> [2] Jin et al. \"Medcpt: Contrastive pre-trained transformers with large-scale pubmed search logs for zero-shot biomedical information retrieval.\" Bioinformatics 39.11 (2023): btad651.\n> [3] Li et al. \"R2MED: A Benchmark for Reasoning-Driven Medical Retrieval.\" arXiv preprint arXiv:2505.14558 (2025)."}, "questions": {"value": "1. Can you provide more case studies on the quality of LLM annotations?\n\n2. How sensitive is MAR to the choice of base document encoder (e.g., Qwen3 vs. BGE)?\n\n3. How would MAR perform in non-medical Chinese retrieval tasks? Does the alignment generalize beyond the medical corpus?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qP2fSC2jwv", "forum": "JsNmDdKJmx", "replyto": "JsNmDdKJmx", "signatures": ["ICLR.cc/2026/Conference/Submission20011/Reviewer_TpzX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20011/Reviewer_TpzX"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20011/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760999511944, "cdate": 1760999511944, "tmdate": 1763342048642, "mdate": 1763342048642, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MedTEB, a high-quality benchmark for Chinese medical text retrieval, reranking, and synonym understanding, addressing limitations in existing datasets. To enable both strong accuracy and low latency, the authors propose MAR, an asymmetric retriever that combines a lightweight query encoder with a powerful offline document encoder, aligned through a two-stage training strategy. MAR achieves state-of-the-art performance on MedTEB while remaining efficient for real-time medical retrieval and RAG applications."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "+ By leveraging the capabilities of LLMs, this paper validates the issues and shortcomings present in current benchmarks, thereby uncovering noise-related problems in the data. \n+ The authors introduce an asymmetric retrieval framework and demonstrate its effectiveness on this benchmark, achieving state-of-the-art performance.\n+ The research objectives are clearly defined and effectively addressed."}, "weaknesses": {"value": "Perhaps due to space constraints, several issues remain unclear to me:  \n+ For instance, in which specific aspects do the existing benchmarks fall short, and to what extent are these deficiencies present? Can experiments based solely on LLMs sufficiently support the claim made in the original text: \"However, the retrieval tasks suffer from annotation noise and false negatives, leaving only the reranking tasks relatively reliable\"?  \n+ The description of the benchmark construction process in this paper lacks sufficient detail. It is unclear whether many of the construction details, such as data distribution, adhere to benchmark construction standards.  \n+ The proposed model employs an asymmetric structure, yet why are all the baselines symmetric? The selection of baselines does not appear to be comprehensive."}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "T6DawvVXqc", "forum": "JsNmDdKJmx", "replyto": "JsNmDdKJmx", "signatures": ["ICLR.cc/2026/Conference/Submission20011/Reviewer_Qri6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20011/Reviewer_Qri6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20011/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761704880782, "cdate": 1761704880782, "tmdate": 1762932914171, "mdate": 1762932914171, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The research seeks to address the challenge in medical information retrieval where existing search systems must tradeoff being fast but inaccurate or accurate but slow, making them impractical for real-time clinical use. This problem is stated as especially acute for Chinese medical text, where testing benchmarks are incomplete and specialized tools are lacking. Researchers propose two contributions: MedTEB, a comprehensive benchmark using real medical queries and multi-AI verification systems, and MAR (Medical Asymmetric Retriever), an innovative two-part search architecture that separates the search process into complementary components.\n\nMARs uses a small \"query encoder\" to process searches in real-time paired with a large, powerful \"document encoder\" that pre-processes medical documents offline. This approach—trained through a three-stage process of independent training, alignment, and joint fine-tuning—eliminates the traditional speed-accuracy trade-off. The results claim to demonstrate that MAR achieves the high accuracy of larger models while maintaining the processing speed of smaller ones."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The work seeks to address the tradeoffs between speed, computational cost and accuracy often encountered in document retrieval systems. This is an important (albeit well-established) challenge in this area. The application to Chinese text documents and a curated, benchmark dataset of such documents along with the code is also a clear contribution of this work. Also, and in general, the paper is well-written and technically sound."}, "weaknesses": {"value": "As noted above, the challenge itself is not novel, per se, nor is the strategy of preprocessing and creating an index offline and using the index at run time (hence my rating). Perhaps more detail on what is special about this specific manifestation of the problem and on the 2-tier solution could increase the novelty of this work. Also, once the dataset and the code has matured and the community has built on it, this work will have much greater impact. The authors should be encouraged to pursue this direction."}, "questions": {"value": "Could the authors provide a better characterization of the novelty of both the problem and the solution?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZqFuvJz6jy", "forum": "JsNmDdKJmx", "replyto": "JsNmDdKJmx", "signatures": ["ICLR.cc/2026/Conference/Submission20011/Reviewer_7fKN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20011/Reviewer_7fKN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20011/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761871184276, "cdate": 1761871184276, "tmdate": 1762932913505, "mdate": 1762932913505, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses key gaps in Chinese medical dense retrieval: the lack of high-quality benchmarks and the accuracy-efficiency trade-off of embedding models. It proposes two core contributions: (1) MedTEB, a Chinese Medical Text Embedding Benchmark covering 3 new tasks (Retrieval, Reranking, Synonym STS) and 2 existing high-quality datasets, constructed via multi-LLM consensus annotation to reduce noise; (2) MAR, a Medical Asymmetric Retriever with a lightweight online query encoder and a powerful offline document encoder, optimized via a two-stage framework (query alignment + joint fine-tuning) to achieve SOTA performance on MedTEB while maintaining low latency. The authors also commit to open-sourcing the benchmark, models, and code."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "1. Fills the gap of reliable Chinese medical retrieval benchmarks: MedTEB solves annotation noise and false negatives in existing datasets (e.g., C-MTEB), providing a rigorous evaluation standard.\n2. Practical asymmetric architecture: MAR balances real-time deployment needs (low-latency query encoder) and retrieval quality (powerful document encoder), breaking the accuracy-latency trade-off.\n3. Significant domain value: Focuses on underdeveloped Chinese medical retrieval, supporting clinical decision support and medical RAG; open-source resources facilitate follow-up research."}, "weaknesses": {"value": "1. Insufficient validation of LLM annotation professionalism: No clinical expert sampling verification or inter-annotator agreement metrics (e.g., Cohen’s Kappa) for MedTEB labels, risking \"pseudo-professional\" errors.\n2. Unclear LLM annotation disagreement details: Fails to report the proportion of partially agreed samples or analyze disagreement causes, potentially compromising benchmark comprehensiveness.\n3. Ambiguous document encoder pretraining: No information on the proportion of medical data in Qwen3’s pretraining corpus; lacks baseline comparisons (e.g., Llama3-8B) to verify Qwen3’s medical advantages.\n4. Incomplete ethical/data compliance: No details on IRB approval for online user queries, specific anonymization steps, or exact public data sources, raising compliance concerns.\n5. Lack of comparison with medical RAG methods: No performance comparison with domain-specific methods (e.g., Hyper-RAG), limiting competitiveness assessment."}, "questions": {"value": "see weaknesses"}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety", "Yes, Legal compliance (e.g., GDPR, copyright, terms of use, web crawling policies)", "Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "details_of_ethics_concerns": {"value": "1. Privacy risks: No confirmation of residual personal identifiers in \"anonymized user queries\" or detailed anonymization methods.\n2. Legal gaps: Lack of IRB approval for user query data (potential human subjects) and unclear legal sourcing of public corpora, violating data protection laws.\n3. Inadequate responsible disclosure: No information on annotator management (e.g., expert compensation) or safeguards against clinical misuse of released data."}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pnE0FtWz3A", "forum": "JsNmDdKJmx", "replyto": "JsNmDdKJmx", "signatures": ["ICLR.cc/2026/Conference/Submission20011/Reviewer_EYLG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20011/Reviewer_EYLG"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20011/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762080910227, "cdate": 1762080910227, "tmdate": 1762932913006, "mdate": 1762932913006, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}