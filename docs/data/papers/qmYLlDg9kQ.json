{"id": "qmYLlDg9kQ", "number": 18095, "cdate": 1758283760138, "mdate": 1759897133891, "content": {"title": "E-Agent: A Cost-Efficient Agentic Framework for Knowledge-Intensive and Reasoning Tasks", "abstract": "The deployment of large language model (LLM)-powered agents for knowledge-intensive and reasoning tasks is often prohibitively expensive, since processing large volumes of evidence incurs massive token costs. Existing techniques such as prompt compression and model routing attempt to reduce token usage, but they often compromise accuracy or fail to capture the fine-grained structure of reasoning tasks. In this work, we introduce E-Agent, a cost-effective framework that leverages the pricing asymmetry of LLMs to significantly reduce monetary cost without sacrificing performance. E-Agent adopts an executor–verifier paradigm: multiple small, locally deployed models act as executors to generate candidate answers, which are then verified by a powerful cloud-based model. This design shifts token consumption from expensive outputs to relatively cheaper inputs. The framework further supports specialized workflows for both retrieval-augmented generation (RAG) and non-RAG tasks, and employs structured outputs to minimize candidate answer length. Experiments on GSM8K, ALFWorld, HotpotQA, and StrategyQA demonstrate that E-Agent reduces token usage by 10\\%–50\\% compared with strong baselines, while maintaining or even improving accuracy.", "tldr": "", "keywords": ["agent", "token", "cost", "efficient"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/60687d4df2cff3455dc8951f1130d1a649a3bae6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces E-Agent, a framework designed to reduce the monetary cost of deploying LLM-powered agents for knowledge-intensive and reasoning tasks. The key insight is to exploit the pricing asymmetry between input and output tokens in commercial LLMs (where output tokens cost 3-10× more than input tokens). E-Agent uses an executor-verifier paradigm: multiple small, locally-deployed models generate candidate answers (cheap/free), which are then verified by a powerful cloud model that ideally only outputs a selection indicator (expensive but minimal). The framework enforces structured outputs to further compress token usage and supports both RAG and non-RAG workflows. Experiments on GSM8K, ALFWorld, HotpotQA, and StrategyQA demonstrate 10-50% cost reduction while maintaining or improving accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The pricing asymmetry observation is insightful and the proposed solution directly addresses a real deployment concern.\n2. Four diverse benchmarks (arithmetic, embodied agents, multi-hop QA, strategy QA) with two different cloud models provide reasonable coverage.\n3. Table 4 effectively demonstrates that heterogeneous executor ensembles outperform individual models, and Table 5 shows both components (collaboration + structured outputs) are necessary.\n4. Unlike pure compression methods, E-Agent maintains or improves accuracy while reducing costs.\n5. Detailed experimental setup, hyperparameters, and dataset descriptions in the appendix."}, "weaknesses": {"value": "1. The paper mainly combines existing ideas — model ensembles, structured generation, and verification — but doesn’t really offer new theoretical insight. There’s no clear analysis of *why* or *when* this approach should work, or a principled way to decide which executors to use.\n\n2. Local GPU costs are brushed off a bit too quickly. For teams without existing GPU infrastructure, that’s a real expense. There’s also no discussion of latency — since E-Agent needs *n + 1* model calls instead of just one. And the cloud API cost comparison is based on a single snapshot from September 2025, even though prices can fluctuate quite a lot.\n\n3. The method only works under certain conditions — when small models can generate decent candidates, when verification is easier than generation, when you have access to local GPUs, and when tasks have structured outputs. That rules out creative writing, hard reasoning tasks where small models fail, and latency-sensitive applications.\n\n4. There’s no comparison with simpler baselines like using a single cloud model but with a shorter output or lower temperature. It also barely compares to newer routing methods, and doesn’t include recent prompt compression approaches like RECOMP or Selective Context.\n\n5. There’s no statistical significance testing, even though decoding is stochastic. The “all-cloud large model” baseline in Table 5 isn’t clearly defined — are the prompts the same? And the paper doesn’t really dig into what kinds of errors E-Agent introduces or avoids. The reflection mechanism for non-RAG tasks also feels under-evaluated.\n\n6. All the benchmarks are short and in English. There’s nothing on long-context tasks (say, 100k+ tokens) where cost really becomes critical. And since the approach relies on structured outputs, it might not generalize to open-ended or creative tasks. Also, results might not hold up as model pricing or capabilities evolve.\n\n7. Table 3 is a bit overwhelming — it’s hard to see the relationship between cost savings and accuracy. In some cases, cost goes down *and* accuracy goes up, but there’s no explanation why. It would help to discuss where E-Agent actually *doesn’t* make sense to use."}, "questions": {"value": "1. What happens when all executors produce incorrect answers? How does verifier performance degrade? Can you provide statistics on how often this occurs?\n2. E-Agent requires n+1 sequential model calls. How does end-to-end latency compare to baselines? Is there a cost-latency Pareto frontier analysis?\n3. How sensitive are results to executor choice? Is there a principled way to select executors for a new task, or is this manual tuning?\n4. What exactly is the prompt used for the verifier? How does it know when all candidates are wrong?\n5. How does performance change with number of executors (n=1,2,3,4,5)? What about with different cloud models?\n6. How would E-Agent perform on tasks requiring creative generation or very long contexts?\n7. In Table 5, why does \"all cloud large model\" cost more than any baseline in Table 3? What's different about this configuration?\n8. How much does performance degrade if structured outputs are not possible (e.g., for creative writing)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "s12IoLhQjx", "forum": "qmYLlDg9kQ", "replyto": "qmYLlDg9kQ", "signatures": ["ICLR.cc/2026/Conference/Submission18095/Reviewer_kpJQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18095/Reviewer_kpJQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18095/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761770866801, "cdate": 1761770866801, "tmdate": 1762927867197, "mdate": 1762927867197, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces E-Agent, a cost-efficient agentic framework for knowledge-intensive and reasoning tasks. It follows an executor–verifier paradigm, where multiple local-based executors generate candidate answers that are subsequently validated by a cloud-based verifier. Experiments on GSM8K, ALFWorld, HotpotQA, and StrategyQA demonstrate that E-Agent reduces token usage by 10%–50% compared with strong baselines such as ReAct, while maintaining accuracy or even improving it."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Cost-efficient agentic architecture exploiting pricing asymmetry\nThe proposed E-Agent framework explicitly leverages the input–output pricing asymmetry of commercial LLMs to reduce overall token expenditure by shifting computation from expensive output decoding to cheaper input prefilling, achieving 10%–50% cost savings across benchmarks.\n2. Experimental evidence (Table 3) is compelling\n E-Agent consistently reduces aggregate token and monetary costs by a meaningful margin (10–50%) relative to strong baselines, while accuracy is maintained or improved. These results are corroborated by runtime measurements (Figure 3)."}, "weaknesses": {"value": "1. Lack of Methodological Originality\n\nThe proposed E-Agent framework lacks sufficient originality. Using structured outputs as inputs to cloud models to reduce token usage and improve accuracy is not a novel idea, as similar techniques have been widely adopted in agentic LLM prompt designs (e.g., A-Mem [1]). Likewise, employing multiple local LLMs for cost optimization has already been demonstrated in FrugalGPT [2]. The paper is encouraged to clarify its methodological novelty compared with these prior works.\n\n2. Insufficient Discussion of Related Work\n\nThe “Related Work” section does not adequately compare E-Agent with closely related recent studies (e.g., KnowAgent [3]). As a result, the paper’s positioning within the landscape of cost-efficient agentic framework design remains unclear.\n\n3. Lack of Cost-Efficient Baselines\nAlthough several cost-reduction methods such as LLMLingua[4] and FrugalGPT[2] (which provide open-source implementations) are mentioned in the related work section, they are not included as baselines in the experiments. This omission weakens the empirical validation of E-Agent’s cost efficiency.\n\n4. Missing Theoretical Analysis of Failure Modes\n\nWhile the paper motivates cost reduction by shifting computation to input tokens, it does not model or analyze failure cases when all local executors fail. In such scenarios, the cloud verifier must regenerate answers from scratch. The frequency and impact of these failures are not quantified, nor are worst-case cost or robustness metrics provided.\n\n5. Vague System Description\n\nThe description of the Cost-Efficient Agentic framework remains vague. The equations in Section 3.2 are mostly symbolic process representations and lack formal definitions of key implementation details such as candidate generation, structured output constraints, and task assignment. It would be helpful to elaborate on how user inputs are mapped to executor tasks and how the cloud LLM coordinates with or supervises different executors.\n\n6. Unbalanced Experimental Baselines\n\nAlthough the related work section discusses token-efficient methods like FrugalGPT[2], the experiments only compare E-Agent against reasoning-oriented baselines such as ReAct. Including additional comparisons with token-efficient agentic frameworks would strengthen the empirical evaluation and clarify the claimed advantages.\n\n7. Minor Typographical Errors\n\nThere are small spelling mistakes in the paper, such as “Ouput” → “Output” in Table 5 and “StrategrQA” → “StrategyQA” in Figure 3.\n\nReferences\n\n[1] Wujiang Xu, Zujie Liang, and Kai Mei. A-Mem: Agentic Memory for LLM Agents. NeurIPS, 2025.\n\n[2] Lingjiao Chen, Matei Zaharia, and James Zou. FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance. Trans. Mach. Learn. Res., 2024.\n\n[3] Yuqi Zhu, Shuofei Qiao, and Yixin Ou. KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents. ACL, 2025.\n\n[4] Huiqiang Jiang, Qianhui Wu, Chin-Yew Lin, Yuqing Yang, and Lili Qiu. LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models. EMNLP, 2023."}, "questions": {"value": "1. How does the framework ensure that executors produce structured outputs compliant with the JSON/Schema format? How does the system robustly handle cases where the output format is incorrect?\n2. When the verifier needs to “regenerate an answer” rather than simply verify one, what are the common failure modes? Could you provide some examples?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hn01YSQerK", "forum": "qmYLlDg9kQ", "replyto": "qmYLlDg9kQ", "signatures": ["ICLR.cc/2026/Conference/Submission18095/Reviewer_u63t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18095/Reviewer_u63t"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18095/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761910378276, "cdate": 1761910378276, "tmdate": 1762927866688, "mdate": 1762927866688, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Given the cost imbalance between input and output tokens in LLMs, the authors propose a framework where multiple smaller models generate candidate solutions, and a larger model verifies and synthesizes the final output. This approach is evaluated on several knowledge- and reasoning-intensive datasets, achieving superior performance compared to both reasoning and non-reasoning agentic baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed idea, using small models for generation and a large model for verification, is conceptually sound and empirically supported.\n2. The paper is clearly written and easy to follow."}, "weaknesses": {"value": "1. While the paper claims to exploit input–output price asymmetry of the same model, the technical solution is based on pricing differences between small and large models. Thus, the contribution is a new collaboration framework balancing the use of small and large models, rather than directly addressing token cost asymmetry.\n2. Consequently, since the contribution centers on a collaborative modeling framework, comparisons with other similar methods (e.g., speculative decoding, model routing) should be included for a fair evaluation.\n3. The analysis overlooks the computational or API cost of running the smaller/local models, which should be factored into the total cost using either token prices or FLOPs."}, "questions": {"value": "See weaknesses above\n\nDid you use structured outputs for the baseline methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1RzRFqiMDJ", "forum": "qmYLlDg9kQ", "replyto": "qmYLlDg9kQ", "signatures": ["ICLR.cc/2026/Conference/Submission18095/Reviewer_KnxN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18095/Reviewer_KnxN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18095/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761936862495, "cdate": 1761936862495, "tmdate": 1762927866322, "mdate": 1762927866322, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "E-Agent introduces a cost-efficient agentic framework for knowledge-intensive and reasoning tasks by exploiting the input–output pricing asymmetry of large language models (LLMs). It follows an Executor–Verifier paradigm, where multiple small local models generate structured candidate answers that are verified by a powerful cloud model, thus shifting computation from expensive output tokens to cheaper input tokens. The framework supports both retrieval-augmented and non-retrieval tasks, enforces structured outputs to reduce redundancy, and demonstrates consistent token cost reductions (10–50%) across GSM8K, ALFWorld, HotpotQA, and StrategyQA, while maintaining or improving accuracy and runtime efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper introduces a novel exploitation of LLM input–output pricing asymmetry, achieving significant monetary savings without compromising reasoning performance.\n2. The multi-executor verification mechanism effectively balances small-model efficiency with large-model accuracy, improving scalability for agentic systems.\n3. Enforcing structured (JSON/Schema) outputs not only reduces token consumption but also enhances verification quality and reasoning interpretability.\n4. Extensive experiments across diverse benchmarks and ablations (e.g., model ensemble, structured output impact) validate both the efficiency and robustness of the approach."}, "weaknesses": {"value": "1. Although the framework leverages pricing asymmetry, its theoretical analysis of cost modeling and optimization remains shallow, lacking a systematic mathematical or economic formulation.\n2. The experiments focus mainly on text-based reasoning tasks (e.g., GSM8K, HotpotQA), without verifying the framework’s generalizability to more complex scenarios such as multimodal reasoning or code generation.\n3. The framework fundamentally relies on cloud-based large models for final verification, making its cost advantage sensitive to potential API pricing or latency fluctuations.\n4. The selection of executor models (e.g., Qwen, Llama, Phi) is based on empirical combinations rather than automated or theoretically grounded criteria.\n5. The paper does not sufficiently analyze error propagation or performance degradation caused by inconsistencies between executors and the verifier.\n6. Although the local GPU electricity cost is roughly estimated, the paper lacks a detailed evaluation of long-term, concurrent, or distributed deployment cost feasibility."}, "questions": {"value": "See the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "czfFdcSZr4", "forum": "qmYLlDg9kQ", "replyto": "qmYLlDg9kQ", "signatures": ["ICLR.cc/2026/Conference/Submission18095/Reviewer_tF8W"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18095/Reviewer_tF8W"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18095/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977316474, "cdate": 1761977316474, "tmdate": 1762927865842, "mdate": 1762927865842, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}