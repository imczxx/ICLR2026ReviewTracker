{"id": "BhNVSmIKln", "number": 8315, "cdate": 1758078394600, "mdate": 1759897792321, "content": {"title": "Real-Time Evaluation for Novel Class Discovery at Test Time", "abstract": "We introduce Test-Time Discovery (TTD), a real-time evaluation protocol for novel class discovery under sequential test-time conditions. Unlike post-hoc NCD evaluation, which assesses clustering only after the full test set is processed, TTD requires models to classify known categories and discover novel ones in real time as samples arrive. To address this setting, we propose a training-free Hash Memory (HM) method. HM encodes feature norm and direction into semantic-aware hash codes, enabling Locality-Sensitive Hashing (LSH) for efficient retrieval and consistent reuse of discovered classes. A global-to-local strategy combines prototypes for stable known-class predictions with memory-based reasoning for flexible novel discovery. A lightweight self-correction mechanism further improves reliability by removing mislabeled entries from early discoveries. Experiments on diverse benchmarks show that HM achieves more accurate and stable real-time discovery than NCD and TTT methods, while maintaining performance on known classes. Our code will be released.", "tldr": "We introduce Test-Time Discovery (TTD), a real-time evaluation protocol for novel class discovery under sequential test-time conditions.", "keywords": ["Test-Time Discovery", "Novel Category Discovery", "Online Learning", "Test-Time Training"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d92ff89b8113e951626133c8ec6cecacbd49132f.pdf", "supplementary_material": "/attachment/86ee0a29881009dc33e928a27e83b994bc1d90a3.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes the task of test-time discovery, i.e. generalized category discovery (classifying known categories and identify new ones) where at test time data is processed online, making clustering more difficult. To tackle this task the paper proposes a hash memory method that uses locality-sensitive hashing and a global-to-local strategy for efficient retrieval and novel class formation, with a lightweight self-correction mechanism."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The focus on a online testing setting for novel class discovery is interesting and makes the problem more suitable for different scenarios\n***\n\n- The experiments exploring the effect of the number of unknown classes and different test-time distributions are appreciated. this analysis adds some empirical depth beyond a single evaluation setup."}, "weaknesses": {"value": "- relation to prior work and conceptual clarity\n- The paper does not sufficiently situate its contribution within prior work. It is unclear whether similar approaches have already been explored in the GCD or related literature. The related work sections and problem definition settings do attempt to do this but it remains unclear\n-  For instance, the intro states \"In TTD, the model must not only classify known categories but also decide in real time whether a sample belongs to a previously discovered class or should initiate a new one.\". This is exactly what the problem of generalized category discovery addresses. This is also not mentioned when GCD is described in the related work. It is made clearer in the comparison in Table 1 but should be clear from the start.\n- The relation to PHE (Zheng et al., 2024) is unclear. That work also claims an online or real-time discovery setting, in contrast to how it is represented in Table 1. It is also missing from the related work despite clear conceptual overlap.\n- PHE is compared to in the experiments, however the conceptual difference should be made clear\n***\n\n- comparisons to state-of-the-art\n- related to the above point since the main difference between GCD and the proposed task is the online testing it seems that GCD methods should be compared to, at least in the post evaluation setting\n- it would also strengthen the papers claims to compare to GCD methods in the online setting by iteratively testing as the test set expands to demonstrate that GCD methods are either much worse in this setting or too computationally expensive.\n***\n\n- experimental design and fairness\n- The choice of datasets and the 7:3 known–unknown class ratio is not well justified. Given the similarity to GCD or on the fly category discovery (OCD), it would be more convincing to adopt standard datasets and splits used in priors works. Some of the datasets are the same but it isn't clear why tiny-imagenet is chosen over imagenet-100 and why Stanford cars isn't used. Prior works also tend to use a 1:1 ratio of known to unknown classes.\n- The new evaluation metrics introduced in the paper seem to obscure rather than clarify the relationship between GCD/OCD and the proposed setting. While some new evaluation is reasonable, several metrics appear to be renamed or slightly altered versions of existing GCD/OCD metrics, making interpretation difficult.\n***\n\n- ablation study\n- The ablation study is limited, evaluating only the presence of the hash memory and self-correction components. Key elements such as the graph-augmented retrieval or the global-local hybrid strategy are not analyzed.\n- The reported ablation results are unconvincing. While cluster agreement improves, both true-label agreement and known-class accuracy (KA) decline. With the issue mentioned above, its hard to interpret these metrics and weight which is more important and evaluate whether the proposed components are actually benefitting the model. \n***\n\n- presentation\n- The paper relies heavily on acronyms, which makes the results and reasoning difficult to follow in places."}, "questions": {"value": "- How does your approach relate to PHE (Zheng et al., 2024), which also performs online or real-time discovery? The distinction is unclear from both the related work and Table 1.\n***\n\n- How does the proposed test-time discovery (TTD) setting fundamentally differ from Generalized Category Discovery (GCD) beyond the sequential or streaming data assumption? Why are GCD baselines not included in the post evaluation comparisons?\n***\n\n- Why were the chosen datasets and the 7:3 known–unknown ratio used? Would the method still perform well on standard GCD datasets and splits?\n***\n\n- Several of the proposed evaluation metrics seem to be renamed or modified versions of standard ones. Can you clarify the link between existing metrics and new metrics and justify why new terminology was introduced instead of extending existing metrics?\n***\n\n- The ablation omits analysis of several important components (e.g., graph-augmented retrieval, global-local hybrid strategy). Could you provide further justification or additional experiments?\n***\n\n- In Table 7, cluster agreement improves but true-label agreement and KA decrease. What does this trade-off imply about the quality of the discovered clusters?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "q2uEnx3K5a", "forum": "BhNVSmIKln", "replyto": "BhNVSmIKln", "signatures": ["ICLR.cc/2026/Conference/Submission8315/Reviewer_ucGd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8315/Reviewer_ucGd"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8315/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761320241892, "cdate": 1761320241892, "tmdate": 1762920242128, "mdate": 1762920242128, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Test-Time Discovery (TTD), a new protocol for real-time novel class discovery that requires models to simultaneously classify known categories and identify emerging ones under sequential test-time constraints. The authors propose a training-free Hash Memory (HM) framework that combines semantic-aware hashing of feature norms and directions, a cooperative inference strategy integrating global prototypes and memory-based reasoning, and a self-correction mechanism to refine mislabeled samples. Experimental results across multiple benchmarks show that HM achieves more accurate and stable real-time discovery than prior NCD and TTT methods while maintaining strong performance on known classes."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- First of all, the paper introduces Test-Time Discovery (TTD), a sequential real-time evaluation protocol that bridges the gap in existing NCD approaches by jointly measuring classification and discovery.\n- The proposed Hash Memory combines semantic-aware hashing, graph-augmented retrieval, and self-correction into a simple yet effective training-free design for real-time novel class discovery. Especially, a hybrid strategy integrates a global prototype classifier for confident known samples with an LSH-based local voting mechanism for ambiguous or novel ones, ensuring stability on known classes while enabling flexible discovery.\n- Comprehensive experiments analyze real-time vs. post-hoc metrics (KA, KF, TA, CA), parameter sensitivity, and robustness under varied memory sizes, sample orders, and data distributions, consistently outperforming NCD and TTT baselines across benchmarks."}, "weaknesses": {"value": "- A first concern is an inherent ambiguity in the term real-time evaluation. It is unclear whether it refers to quantitative latency and memory overheads for hashing, neighbor retrieval, and SC updates.\n- The system relies on multiple heuristic mechanisms, making it difficult to clearly attribute performance gains to individual modules and to isolate their true effectiveness within the overall framework. \n- The provided results are limited to relatively short sequential test streams with a small number of discovered classes, leaving it unclear how the method would perform under long-term discovery or class reoccurrence which are central challenges in realistic continual open-world scenarios."}, "questions": {"value": "- How does it estimate or calibrate prediction confidence to prevent early pseudo-label errors from propagating?\n- What is the computational and memory complexity of the hash-based graph retrieval and self-correction steps as the number of discovered classes grows, and can the method remain real-time in longer streams?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "guvRLV3Zsq", "forum": "BhNVSmIKln", "replyto": "BhNVSmIKln", "signatures": ["ICLR.cc/2026/Conference/Submission8315/Reviewer_vbHh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8315/Reviewer_vbHh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8315/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761904933608, "cdate": 1761904933608, "tmdate": 1762920241834, "mdate": 1762920241834, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper deals with the problem of discovering novel classes in real-time test scenarios. Along with discovering novel samples, the task is also to maintain the performance of known classes. To tackle the challenge of online discovery, the proposed work maintains a hash memory of feature norm and direction. A new class is discovered by querying the buckets. For robustness against noisy data, the top-k neighbors of a bucket are augmented while applying discovery process. For the final decision, global prototypes and hash memory are leveraged to ensure performance in both known and novel classes. Finally, to purify misassigned samples for novel discovered classes, a memory self-correction mechanism is applied. Experiments are conducted in 4 datasets."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Real-time discovery of novel classes is a practical setting of NCD, as introduced by the paper. The problem of TTD is well-motivated by highlighting rediscoveries of novel classes from existing solutions that focus on non-real-time-based postdoc evaluation.\n- The paper gives a good overview of the related works regarding NCD and TTT.\n- The proposed method is practical for real-time discovery problem."}, "weaknesses": {"value": "- Will the feature norm and directions of the first identified sample of a novel class be representative to identify all the future samples of the same class? As we see more samples, do we need aggregation?\n- Some of the details in the paper are missing. For example: How to construct the dynamic graph? What is the frequency of updating the graph?\n- The notation k is used for multiple purposes. It is recommended to use distinct notations for specific purposes.\n- What is the value of ε, α? How to determine the values?\n- If the graph is not used, how does it affect the performance?  Also, how does k in the top-k of the graph neighborhood impact the performance?\n- How to determine the optimal size of stored samples in the self-correction module?"}, "questions": {"value": "Please refer to the weakness section"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FROVsoFc9D", "forum": "BhNVSmIKln", "replyto": "BhNVSmIKln", "signatures": ["ICLR.cc/2026/Conference/Submission8315/Reviewer_18vv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8315/Reviewer_18vv"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8315/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761955434624, "cdate": 1761955434624, "tmdate": 1762920241471, "mdate": 1762920241471, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Test-Time Discovery (TTD), a real-time evaluation framework for novel class discovery, along with a training-free Hash Memory (HM) method that integrates semantic-aware hashing, a global-to-local prototype-to-LSH classifier, and a lightweight self-correction mechanism. TTD focuses on per-sample decision-making during streaming evaluation rather than relying on post-hoc clustering. Experiments on CIFAR100D, CUB-200D, Tiny-ImageNetD, and AircraftD demonstrate consistent improvements on new real-time metrics (TA and CA) while maintaining stability on known classes."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The TTD protocol effectively reveals practical issues often overlooked in post-hoc NCD and clearly identifies three key challenges.\n- The method is appealingly simple and efficient at test time. Hash codes represent both feature norm and direction, LSH buckets are reused to avoid redundant rediscovery, and known-class predictions rely on a fallback prototype classifier.\n- Overall, the paper is well written and easy to follow."}, "weaknesses": {"value": "- The semantic-aware hash employs random projections and a norm bin, which is practical but offers limited conceptual novelty compared with existing prototypical hashing or LSH-based retrieval methods. Please provide a clearer positioning against closely related online discovery and hashing approaches to highlight the contribution.\n- The approach relies on several design choices, such as κ for norm binning, the number of random directions, the number of bucket-graph neighbors (k), memory size (K), EMA factor (α), and the self-correction cadence. The current sensitivity analysis is limited; robustness claims would be more convincing with systematic parameter sweeps and a clearer examination of latency–memory trade-offs under streaming conditions."}, "questions": {"value": "- How were κ (norm discretization), number of random directions n, bucket neighbor count k, and memory size K chosen? Please provide ranges, validation protocols, and wall-clock latency/throughput under streaming loads.\n- Have you tried larger-scale open-world streams (e.g., ImageNet-derived streams with >1k categories) or non-vision modalities?\n- Dataset split descriptions are useful; a quick table in the main text (with known/unknown counts and stream length) would aid readability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NqXcPmRheJ", "forum": "BhNVSmIKln", "replyto": "BhNVSmIKln", "signatures": ["ICLR.cc/2026/Conference/Submission8315/Reviewer_1TV7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8315/Reviewer_1TV7"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8315/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761983740499, "cdate": 1761983740499, "tmdate": 1762920241078, "mdate": 1762920241078, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}