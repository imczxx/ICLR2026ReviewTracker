{"id": "ilr07ypuYl", "number": 2708, "cdate": 1757214317805, "mdate": 1759898132298, "content": {"title": "FUSE: Full‑spectrum Unlearnable Examples via Spectral Equalization", "abstract": "Unlearnable examples (UEs) protect training data by injecting imperceptible perturbations so that models fail to extract exploitable representations. In this paper, we reveal that existing UEs exhibit a critical failure once low-pass filtering is applied, indicating that the effective perturbation signals for unlearnability concentrate predominantly in high frequencies. Hence, we argue that reliable UEs should remain effective across the full spectrum. To this end, we propose **F**ull-spectrum **U**nlearnable Examples via **S**pectral **E**qualization (**FUSE**), which aims to generate spectrum-agnostic perturbations by equalizing the contributions from different bands and enforcing cross-band consistency. Specifically, FUSE adopts a Random Spectral Masking (RSM) strategy during generator training, which randomly removes a contiguous frequency band, forcing the remaining bands to maintain unlearnability. In addition, FUSE further integrates Cross-Band Guidance (CBG), which enforces mutual consistency between high- and low-frequency components, thereby further enhancing low-frequency unlearnability and regulating high-frequency perturbations to preserve the semantic fidelity of images. Extensive experiments across multiple datasets, architectures, and spectral filtering demonstrate the strong protection achieved by FUSE.", "tldr": "", "keywords": ["Unlearnable Examples", "Data Privacy"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c673fb0a2dc082df8e380f6933c69e87c0ff0c66.pdf", "supplementary_material": "/attachment/400385d4646597fce73b8565e81b6ec3d14ed532.zip"}, "replies": [{"content": {"summary": {"value": "In this paper, to address the vulnerability of unlearnable sample generation methods,  authors propose Full Spectrum Unlearnable examples via Spectral Equalization (FUSE), which aims to generate spectrum-agnostic perturbations by equalizing the contributions from different bands and enforcing cross-band consistency.  Specifically, FUSE adopts a Random Spectral Masking (RSM) strategy during generator training, which randomly removes a contiguous frequency band, forcing the remaining bands to maintain unlearnability. In addition, FUSE further integrates Cross-Band Guidance (CBG), which enforces mutual consistency between high- and low-frequency components, thereby further enhancing low-frequency unlearnability and regulating high-frequency perturbations to preserve the semantic fidelity of images. Extensive experiments across multiple datasets, architectures, and spectral filtering demonstrate the strong protection achieved by FUSE."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The work verifies that existing unlearnable examples (UEs) generated by existing methods are vulnerable for low-pass filter. That indicates that  UEs rely on the high frequency components to achieve the unlearnable target.  Once these components are suppressed, deep models still can learn residual information of removed high frequency components. Through experiments on several datasets with different deep model, the proposed overcome the spectral vulnerability of existing methods.\n\n2. This work propose a novel UEs generation method FUSE.FUSE is a novel frequency-agnostic framework designed to distribute perturbation effects across the entire frequency range through spectral equalization, ensuring that unlearnability is preserved even when specific frequency bands are suppressed.\n\n3. The paper conducted extensive experiments on multiple datasets (CIFAR-10, CIFAR-100, SVHN), various model architectures (ResNet-18, ResNet-50, VGG-11, DenseNet-121, ViT), and different filtering scenarios. The experimental results show that FUSE consistently outperforms existing methods, achieving stronger non learnability in both low-pass filtering and unfiltered settings, while maintaining the imperceptibility of perturbations. For example, on the CIFAR-10 dataset, FUSE reduced the testing accuracy to 10.13% under low-pass filtering, which is much lower than other baseline methods under unfiltered settings. FUSE also achieved the lowest testing accuracy on most dataset architecture pairs, proving that its perturbation is still effective without spectral distortion. The paper also conducted ablation research to verify the contributions of RSM and CBG to FUSE performance, and analyzed the influence of hyperparameters such as frequency segmentation radius.\n\n4. FUSE also evaluated common defense strategies such as data augmentation (Cutout, CutMix, Mixup) and adversarial training. The experimental results show that FUSE maintains a low testing accuracy under all settings, approaching the level of random guessing. This indicates that its spectrum independent design can effectively prevent the model from avoiding disturbances through reinforcement or adversarial retraining, demonstrating comprehensive resistance to a wide range of defense mechanisms.\n\n5. The perturbations generated by FUSE exhibit stronger reliability when migrating across datasets, and remain effective even under spectral suppression For example, when perturbations are generated on CIFAR-100 and migrated to CIFAR-10, FUSE reduces accuracy to 9.98% without filtering, while baseline methods such as TUE and GUE exceed 90% This indicates that the generality of FUSE surpasses the limitations of existing methods."}, "weaknesses": {"value": "1. Although FUSE aims to distribute perturbations across the entire frequency range, the paper mentions that when perturbations only act on high-frequency regions, low-frequency structures (such as object shapes) still have information and continue to support learning when discussing existing UE methods. Although FUSE attempts to address this issue through the CBG mechanism, its complete non learnability for extremely low-frequency semantic information still requires further theoretical analysis and experimental verification to ensure that low-frequency information is not exploited by the model in extreme situations.\n2. The paper points out that larger perturbations ($\\epsilon$ values) will inevitably reduce visual imperceptibility, highlighting the inherent trade-off between perturbation intensity and image quality. Although FUSE set a perturbation budget of $\\epsilon=8/255$ in the experiment to ensure imperceptibility, the tolerance for perturbation intensity and image quality may vary for different application scenarios. Although the paper mentions this trade-off, it does not delve into how to dynamically adjust the $\\epsilon$ value according to specific application needs, as well as strategies to maximize non learnability while maintaining imperceptibility.\n3. In ablation research, the paper found that the frequency segmentation radius rc is a key factor affecting the performance of FUSE. Being too small (rc=0.2) can lead to insufficient low-frequency semantics, unstable guidance signals, and weak learnability; If it is too large (rc=0.8), it will excessively reduce the difference between high and low frequency bands and weaken cross band interaction. Although the paper experimentally determined that rc=0.5 is the optimal value, the optimal rc value may vary for different types of datasets or tasks. The paper can further explore how to adaptively determine the optimal RC to improve the universality and usability of FUSE.\n4.  The FUSE framework introduces complex mechanisms such as random spectral masking and cross band guidance, which may increase the training time and computational resource requirements of the model. Although the paper mentions the use of NVIDIA L40S GPU for training, it does not provide a detailed discussion on the training efficiency, inference speed, and computational cost of FUSE under different hardware conditions compared to existing methods. In practical applications, computational efficiency is an important indicator for measuring the practicality of methods, and this information can be further supplemented."}, "questions": {"value": "Please refer weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2darAE7SRc", "forum": "ilr07ypuYl", "replyto": "ilr07ypuYl", "signatures": ["ICLR.cc/2026/Conference/Submission2708/Reviewer_Vrst"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2708/Reviewer_Vrst"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2708/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761383719630, "cdate": 1761383719630, "tmdate": 1762916337953, "mdate": 1762916337953, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes FUSE (Full-spectrum Unlearnable Examples), a novel framework that aims to generate spectrum-agnostic unlearnable perturbations through spectral equalization. The key idea is to distribute unlearnability across the entire frequency spectrum by combining two complementary components: Random Spectrum Masking (RSM) to enhance frequency diversity and Cross-band Guidance (CBG) to enforce consistency between different frequency bands. Experimental results on multiple datasets and architectures demonstrate that FUSE achieves strong protection against unauthorized model training, outperforming prior unlearnable example methods under low-pass filtering attacks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper starts from a simple yet insightful observation about the vulnerability of existing unlearnable examples to frequency filtering, and develops a very intuitive and targeted idea to overcome it.\n2. The writing is fluent, clear, and well-organized, making the paper easy and pleasant to read.\n3. The experimental results are strong, generally reaching or surpassing state-of-the-art unlearnable example baselines under comparable settings."}, "weaknesses": {"value": "1. Overly favorable threat model / limited generalization: FUSE is trained jointly with a surrogate classifier that is also used as the target model during evaluation. As a result, the perturbations are tightly coupled to the specific architecture used in training. This effectively assumes that the data owner knows the attacker’s model architecture—a strong and unrealistic assumption. While the paper claims cross-architecture robustness, all reported results use the same backbone for both surrogate and target models, which makes the transferability and real-world applicability of FUSE questionable. \n2. Claim–evidence mismatch for “full-spectrum” robustness: The central claim of being “spectrum-agnostic” or “full-spectrum” is not convincingly supported by experiments. All frequency-domain evaluations focus solely on low-pass filtering (removing high-frequency components). There is no evidence that FUSE remains effective under high-pass or band-stop filtering, which would be necessary to substantiate the “full-spectrum” claim. \n3. The current objective is written as $\\min_\\theta \\min_\\delta \\mathcal{L}(\\theta,\\delta)$, following prior work “Unlearnable Examples: Making Personal Data Unexploitable”, ICLR 2021, which uses PGD to explicitly update $\\delta$. However, since FUSE updates $\\delta$ in a implicit way by using a trainable perturbation generator $\\delta=\\mathcal{G}(x)$, it is better to define the parameters of $\\mathcal{G}$ as $\\psi$ and update the objective formulation to $\\min_\\theta \\min_\\psi \\mathcal{L}(\\theta,\\mathcal{G}_{\\psi}(x))$ or clarity and correctness.\n4. Given the relatively complex two-branch training and frequency masking pipeline, a concise pseudocode block would significantly improve readability.\n5. It would be helpful to cite related papers, such as *DAT: Improving Adversarial Robustness via Generative Amplitude Mix-up in Frequency Domain*, NeurIPS 2024, which shares conceptual connections to frequency-domain data manipulation."}, "questions": {"value": "See Weaknesses. I am willing to raise the score if the authors address my concerns."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6Gypo3kMBD", "forum": "ilr07ypuYl", "replyto": "ilr07ypuYl", "signatures": ["ICLR.cc/2026/Conference/Submission2708/Reviewer_DnDi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2708/Reviewer_DnDi"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2708/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761665852473, "cdate": 1761665852473, "tmdate": 1762916337697, "mdate": 1762916337697, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper observes that existing methods for generating unlearnable examples can be defeated by applying a low-pass filter. They then proceed to defeat this defence by making unlearnable examples that work across all frequency bands."}, "soundness": {"value": 4}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* The introduction and motivation of the method is clear.\n* Figure 1 gives clear evidence that a low-pass filter defeats other methods.\n* While the method is complex, the ablation experiments show that all parts of the method are needed.\n* Source code is available."}, "weaknesses": {"value": "* The experimental setting is not clearly specified: is this a class-wise or sample-wise attack? How much of the data is attacked?\n* The architecture is also not made clear enough. Are you generating individual unlearnable examples, or training a generator that turns any input into an unlearnable example? And in the second case, what is the architecture of the generator, and what data is used to train this generator?\n* Only the optimization objective is presented, not the optimization method.\n* Because these details are missing, it would be hard to reproduce the results from only the paper.\n* The method was only tested on small images (32×32 pixels), parameters like spectral cutoff might need to be very different for larger images."}, "questions": {"value": "* Is it necessary to use structural similarity in the cross-band-guidance term? I would expect that only cosine similarity would be enough.\n* \"Formally, for a perturbation δ, its shifted Fourier transform is defined as $\\hat{\\delta} = \\text{fftshift}(F[\\delta])$.\"  \n  This is not a useful definition, because it doesn't say what fftshift is."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4doYJecq53", "forum": "ilr07ypuYl", "replyto": "ilr07ypuYl", "signatures": ["ICLR.cc/2026/Conference/Submission2708/Reviewer_eftW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2708/Reviewer_eftW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2708/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761845816797, "cdate": 1761845816797, "tmdate": 1762916336938, "mdate": 1762916336938, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper identifies a major weakness in current Unlearnable Examples (UEs): their protective perturbations are concentrated in high frequencies and can be easily broken by low-pass filtering. To address this, the authors propose FUSE, a new framework for generating \"full-spectrum\" UEs. FUSE uses two main strategies: 1) Random Spectral Masking, which strengthens the perturbations across all frequencies by forcing the system to work even when a contiguous band is removed, and 2) Cross-Band Guidance, which aligns the high and low-frequency components to enhance low-frequency effectiveness and maintain the original image's visual fidelity."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well-structured and clearly presented. It demonstrates sufficient novelty, and the core idea of coupling unlearnability across both the low-frequency and high-frequency bands is compelling."}, "weaknesses": {"value": "**Ambiguity**: \n+ 1. In Equation (3), the definition of the shifted Fourier transform is somewhat unclear. What does $F(\\delta)$ represent? Specifically, what is being \"shifted\" in this context?\n\n+ 2. The details regarding the cutoff require further elaboration. Equation (6) does not provide useful information on how the cutoff is determined or implemented.\n\n+ 3. The authors should provide a more thorough explanation of how loss function (7) achieves the goal of transferring the information that makes the model less learnable from high frequencies to low frequencies. The current explanation does not sufficiently connect the design of the loss to the stated purpose above.\n\n**Experiment Design**\n+ 1. A critical omission from the experimental evaluation is the analysis of generalization. Assessing the transferability of unlearnable examples (UEs) to unknown target models is a vital aspect of their evaluation. The current results lack this dimension. The authors state in the experimental setup: \"We use ResNet-18..., as the surrogate classifier and target model both in training and testing.\" However, the subsequent results (e.g., in Table 1) exclusively report performance where the surrogate and target models are identical. This does not constitute a generalization test. The key experiment—evaluating UEs trained on one surrogate model against a different, unseen target model—is missing and its absence severely undermines the effectiveness of FUSE.\n\n+  2. Section 4.3 discusses the impact of different $r_c$ values. In this set of experiments, is the $r_c$ used for training the UE kept fixed, or does it vary along with the $r_c$ of the low-pass filter used for defense? In other words, does FUSE also exhibit generalization capability with respect to $r_c$? After all, in practical scenarios, it is unknown what $r_c$ value a defender might adopt for the low-pass filter.\n\n\n+ 3. Regarding potential defense strategies: JPEG compression is a very common preprocessing method in real-world scenarios. Since JPEG typically has a significant impact on the frequency-domain information of UEs, and FUSE incorporates substantial design focused on the frequency domain, I suspect that JPEG compression could considerably undermine the effectiveness of FUSE, substantially weakening its unlearnability capability.\n\n+ 4. The current image resolution under consideration is relatively low. Thus, the range of the frequency band is also quite limited. When the image size increases, the range of the frequency band expands accordingly. At this point, the parameters of the algorithm, such as $r_c$, may become more sensitive. Additionally, it is no longer sufficient to simply categorize the information as high-frequency or low-frequency, as it may also include mid-to-high frequency, mid-to-low frequency, and other components. Therefore, the lack of experiments in this area makes it difficult to fully validate the effectiveness of the method."}, "questions": {"value": "See the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "jG4wwoLWKu", "forum": "ilr07ypuYl", "replyto": "ilr07ypuYl", "signatures": ["ICLR.cc/2026/Conference/Submission2708/Reviewer_KZCx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2708/Reviewer_KZCx"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2708/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762169426830, "cdate": 1762169426830, "tmdate": 1762916336532, "mdate": 1762916336532, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}