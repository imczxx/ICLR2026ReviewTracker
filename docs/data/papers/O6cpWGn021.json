{"id": "O6cpWGn021", "number": 24124, "cdate": 1758353041374, "mdate": 1763718822925, "content": {"title": "How LLMs Learn to Reason: A Complex Network Perspective", "abstract": "Training large language models with Reinforcement Learning with Verifiable Rewards (RLVR) exhibits a set of distinctive and puzzling behaviors that remain poorly understood, including a two-stage learning curve, a V-shaped response-length trajectory, and a pronounced vulnerability to catastrophic forgetting. In this work, we propose that these behaviors are emergent collective phenomena governed not by neural implementation details, but by the topological evolution of the latent reasoning graph in semantic space. By demonstrating a dynamical isomorphism between a 1.5B-parameter LLM and a minimal Concept Network Model (CoNet), we trace the causal source to the self-organization of a sparse concept web pinned to an average degree of two. This geometric perspective provides a unified physical explanation for the observed anomalies: the V-shaped trajectory tracks the evolution from parallel local skill optimization to global network integration; catastrophic forgetting stems from the topological disconnection of critical \"trunk'' edges; and policy collapse arises from the accumulation of sequential transitions at the web's leaf nodes, where broad exploration abruptly freezes into rigid, high-reward trajectories. Identifying a \"maximally frustrated state'' at the transition between learning stages, we propose Annealed-RLVR, a principled algorithm that injects a targeted SFT \"heating'' step to resolve this topological bottleneck. Experiments confirm that this theory-driven intervention outperforms standard RLVR on both in-distribution and out-of-distribution benchmarks (including Minerva and AIME). By recasting RLVR from black-box optimization into a predictable process of structural self-organization, our work provides a new physical intuition for engineering the emergent reasoning capabilities of future AI systems.", "tldr": "We explain RLVR training dynamics in LLMs via frustration and phase-transition mechanisms, introduce a minimal complex network model, and propose Annealed-RLVR to restore exploration.", "keywords": ["Interpretability", "Large Language Models", "Reinforcement Learning from Verifiable Rewards (RLVR)", "Complex Network Models", "Frustration and Phase Transitions", "Policy Collapse"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c62c1f5eea99c55cf32ced347b3e2a9e308c6dd5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a theory of the learning trajectory of reasoning models, cast in terms of the evolution of a Markov process describing the transitions between semantic states during reasoning traces. The theory is supported by analysis of a proxy model, CoNet, that explicitly learns transitions in an artificial multitask path-learning setting. This model exhibits a phase transition from isolated paths to a large connected component that unifies tasks. This finding is used to explain two-stage piecewise-linear learning curves and V-shaped trajectories of response length as a function of training time. The paper then proposes an Annealed RLVR method that attempts to intervene at the point of the phase transition, selectively applying SFT to problems with low accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Potentially useful perspective on learning and reasoning dynamics\n\nNovel variation on RLVR with good empirical results"}, "weaknesses": {"value": "Overall the evidence for the proposed theory is circumstantial and not so strong.\n\nIt’s tenuous to conclude that two models that produce two rather simple patterns as in figure 1 do so by the same underlying mechanisms.\n\nThe multitask CoNet and the artificial task it is trained on rely on many assumptions. I think more foundational work is required to establish multitask CoNet as a meaningful proxy for real LLMs before applying it to the questions addressed in the present paper. For example the learning dynamics in multitask CoNet hinge on resolving disagreements between different QA paths on the outgoing probabilities of nodes they intersect on (appx E paragraph 1). This hinges on the Markov property of the CoNet dynamics, which does not apply to LLMs. In an LLM earlier context disambiguates between different questions so that the model is not bound only by what it most recently output.\n\nThe paper assumes there is a single shift underlying the transition from decreasing to increasing responses and the transition from slow learning to fast learning, but these transitions don’t appear to coincide. Moreover the relative timing differs between the two models: In CoNet the bottom of the V is at about 40 training steps while the kink in the learning curve is at about 80. In the LLM these numbers look to be about 400 and 30.\n\nSection 2 argues for a topological explanation of the phase of increasing response lengths, but I don’t see an explanation for the initial phase of decreasing response lengths, or for the two-phase learning curve.\n\nRegarding the annealing proposal, extra training on the more difficult items seems like a pretty generic approach, so its success doesn’t necessarily support the theory."}, "questions": {"value": "It would help to include early definitions of concept web, semantic state, and logical transitions.\n\nWhat is the formal evidence that fig 2b really shows two stage learning? Learning curves are almost always concave like this. \n\nFig 3a would be easier to read if the distributions were normalized.\n\nWhy does a disconnected concept graph yield longer responses? The paper mentions traversing long intermediate paths, but what are those paths? More generally what is the relationship between traversing paths in a concept graph (which I assume happens during reasoning, not the final response) and the length of a response?\n\nHow do you formally determine when to intervene for annealing, i.e., when the maximally frustrated state occurs?\n\nIs there any analysis of the network topology that supports the interpretation of how annealing helps?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "KiB0grL5DM", "forum": "O6cpWGn021", "replyto": "O6cpWGn021", "signatures": ["ICLR.cc/2026/Conference/Submission24124/Reviewer_sf2x"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24124/Reviewer_sf2x"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24124/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761587130873, "cdate": 1761587130873, "tmdate": 1762942946643, "mdate": 1762942946643, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper provides a complex networks perspective to elucidate the behavior of reasoning models during RLVR training. As a proxy, the paper uses Co-NET which was shown to replicate the training dynamics of large scale LLM model.  I think the paper is very good, a little hard to read, but, the novelty contribution and explanations are excellent."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "The paper in my opinion is phenomenal in its clarity and its contribution. \nThe theoretical insights at the beginning of the paper are clear, concise and strongly motivate the algorithm at the end."}, "weaknesses": {"value": "- Not enough experiments on the algorithm. \n- Compuational complexity of the algorithm is not studied. \n- I wold like some mathematical modeling of these phenomenons, carefully modelled with precise theorems and lemma. I understand this could be a future work and will look forward to that paper.\n- At many places in the paper, the English is very strong, the use of obscure words is common, I am okay with it, but, such strong english might reduce accessibility to the paper. For example, this sentence \n\n*Our sparse web theory reveals that the smooth, aggregate reward curve of RLVR training masks a dramatic\nmicroscopic behavior. Individual problem trajectories in Fig. 5 reveal a fundamental tension born from the\nnetwork’s sparse topology: a subtractive process of frustration-induced forgetting, peaking at the onset of\nslow learning, and an opposing, additive process of phase-transition-like learning that drives knowledge\nintegration throughout the slow-learning stage.*\n\nI mean, it took me a few seconds to grasp this. For better readability, i recommend making the prose a little lighter. This is novel level prose."}, "questions": {"value": "- Does the expansive concept web emerge as a property or something changes in the optimization procedure to attain this and how is this property of generating a complex web related to overfitting which would potentialy lead to forgetting.\n\n- When RLVR training resolders the severed connection by the SFT, does it not lead to a push-pull type mechanism, which might deteriorate the learning effectiveness in the long run? Doe you think there is a relationship between this dynamic and the frustration-phase transition dynamic you talk about later in the paper.\n\n- It is curious to see that, the more complex the connectivity gets, the better the model responds to a variety of prompts? Intuitively, I would think that a denser graph is probably more amenable to better generaliztaion, is there any link between the two, that you found in your study?\n\n- the annealing required for RLVR, how does it relate to the discount factors probably present in the GRPO being used in the underlying training and how is the annealing designed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 10}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ccqQHgOvmh", "forum": "O6cpWGn021", "replyto": "O6cpWGn021", "signatures": ["ICLR.cc/2026/Conference/Submission24124/Reviewer_w85W"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24124/Reviewer_w85W"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24124/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761925058198, "cdate": 1761925058198, "tmdate": 1762942946331, "mdate": 1762942946331, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes to explain RLVR’s distinct behaviors (e.g., two-stage learning, V-shaped response lengths, and catastrophic forgetting) through a unified theory of a sparse concept web. This topology unifies learning and forgetting: early “skill islands” compete under sparsity, causing frustration-induced forgetting, followed by phase-transition-like growth as new skills are integrated. Based on this insight, the authors propose Annealed-RLVR, which introduces a brief SFT phase to overcome bottlenecks before resuming RLVR. Experiments on a 1.5B model show improved reasoning and generalization over standard RLVR."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper offers a unique and conceptually rich framework that connects RLVR training dynamics with complex network theory. By modeling reasoning as the self-organization of a sparse concept web, it provides an interesting explanation for several long-observed yet poorly understood phenomena in RLVR.\n\n- The proposed sparse-web hypothesis is also accompanied by empirical illustrations such as the compelling visualizations that align well with the theoretical predictions and empirical RLVR training dynamics."}, "weaknesses": {"value": "- The paper’s central motivation is not clearly articulated. While it introduces a novel complex-network perspective on RLVR training, it does not sufficiently explain why existing explanations are inadequate or how/where their framing offers better practical or conceptual advantages.\n\n- The most direct and actionable contribution is perhaps the proposed \"Annealed-RLVR.\" Though intriguing, the experiments are only conducted on a single 1.5B-parameter model across two datasets (one of which is questionable, as discussed in the questions section). The limited experiments restricted to one model lack broader validation to verify the empirical implications and generalization of the proposed sparse-web hypothesis. In addition, many essential experimental details (e.g., the LM adopted, the training/evaluation datasets used, baselines compared with) are omitted in the main content.\n\n- The paper heavily relies on analogies and terminology from physics and complex network theory without providing sufficient background knowledge or clear empirical mappings between the proposed sparse concept web and measurable LLM internals. While theoretically appealing, this abstraction makes it difficult for readers without prior background in complex networks to follow, making the paper dense and quite challenging to read."}, "questions": {"value": "- For the in-distribution experiments, the evaluation dataset is described as “randomly selected 512 training problems.” Are these examples part of the same training set used during Annealed-RLVR training? If so, how do you distinguish between training and evaluation performance in these results and potential contamination issues?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Ko5JugmRub", "forum": "O6cpWGn021", "replyto": "O6cpWGn021", "signatures": ["ICLR.cc/2026/Conference/Submission24124/Reviewer_jYxa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24124/Reviewer_jYxa"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24124/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762145364199, "cdate": 1762145364199, "tmdate": 1762942945890, "mdate": 1762942945890, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}