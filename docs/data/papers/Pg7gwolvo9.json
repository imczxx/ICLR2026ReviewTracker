{"id": "Pg7gwolvo9", "number": 8069, "cdate": 1758057949088, "mdate": 1759897810583, "content": {"title": "MARAGE: Multi-Model Adversarial Attack for Retrieval-Augmented Generation Database Extraction", "abstract": "Retrieval-Augmented Generation (RAG) mitigates hallucinations in Large Language Models using externally retrieved data. Although useful, RAG can expose the retrieved data to extraction attacks. Previous work has demonstrated the feasibility of RAG extraction, but has failed to simultaneously ensure high-coverage retrieval of the entire knowledge database and verbatim extraction of lengthy retrieved data. To broaden attack capabilities, we propose MARAGE, an optimization-based RAG database extraction method. To obtain high-coverage retrieval, we propose a semantic-aware query selection strategy which optimizes the diversity of retrieved chunks from the database. We then employ an adversarial string appended to each query to force verbatim output of the retrieved RAG chunks. To adapt to the uniquely lengthy target of RAG databases, we introduce Primacy weighting, which prioritizes initial tokens in the optimization target to enhance the extraction capability of optimized adversarial strings. Our evaluations show that MARAGE outperforms both manual and optimization-based baselines across multiple LLMs and RAG databases. On an end-to-end RAG pipeline, MARAGE surpasses the manual attack baseline by 329 +- 165% in extracting RAG data. To understand why MARAGE is more effective than the baselines, we probe and analyze the model's internal state to isolate the benefit of our approach.", "tldr": "We propose MARAGE, an optimization-based RAG database extraction attack that combines semantic-aware query selection, adversarial strings, and primacy weighting to achieve high database coverage, and verbatim RAG chunk extraction.", "keywords": ["LLM", "RAG", "Extraction Attack"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/85e8f0aba0cce754ddf90b18e078b71477985968.pdf", "supplementary_material": "/attachment/c24a7a49224fce59bff988b37bee442e86ca8db3.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose an extraction attack that intends to extract verbatim data from the RAG database. The authors formulate the problem as a novel token optimization problem, and utilize continualized gradient descents to ease the discrete optimization problem. A delay-weight-based loss is adopted, observing that the first few tokens are more decisive, particularly for long sequence targets. The numerical results show high accuracy, large coverage, extension to long sequences, and evasive to existing defenses."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The proposed method is innovative. I particularly like equations (3) and (4) -- they are very beautiful. The study is also thorough and comprehensive, and the numerical studies are rich."}, "weaknesses": {"value": "I'm not sure if cosine similarity is the most appropriate metric. If the basis of the embedding space has been selected, then it might be hard for a subsequent query to have absolutely small similarities with all selected query embeddings. Alternatively, a characterization of how dense or sparse the selected query embeddings are distributed across the embedding space might be another option. Did the authors consider a similar or any other metrics? If not, certain results might be helpful.\n\nThe experiment sample size is relatively small. For example, 50 targets are considered, and 100 queries are used to retrieve 300 chunks.\n\nThere is no theoretical development, but I guess this is beyond the scope of this paper (and I think this can be for another paper, given the rich contribution of this work)."}, "questions": {"value": "1. The authors mention that queries are selected strategically. Specifically, for each subsequent query, they evaluate the cosine similarity between the embedding of it and that of the existing query pool. I have one question and one suggestion about it. How large is the computational cost? It looks like the search cost can be up to n factorial where n is the number of data instances in the database.\n\n2. The discrete optimization is not described clearly. I have two questions here:\n\n(A) The authors mention that the algorithm by Wen et al. (2023) is adopted as the optimization foundation. It seems to me that a multi-model extension is proposed. However, it would be helpful if the authors could explain more clearly what their contribution is on top of the adaptation of Wen et al. (2023).\n\n(B) Like the authors mentioned, not all instances of the continuous embedding values correspond to valid tokens. Since the gradients of the adversarial embeddings are computed. It is not clear to me how they are eventually converted back to the token level.\n\n3. It is good to see that the proposed method is optimized over a series of models. However, I'm more concerned about the training over different d's. This boils down to two questions.\n\n(A) In order for equation (4) to learn successfully, I guess a large optimization dataset D_p is needed. In Section 4.1, the authors mention that the size of D_p is 50. Is this sufficient? (Looks so based on the numerical results, but I'm still doubtful.)\n\n(B) How's the generalization result? In other words, would a D_p of size 50 be enough for the attack model to verbatim recite any data instances from the data base?\n\n4. A quick clarification: what's the retriever of the RAG? Based on the data description, is it true that the \"pre-defined query/data pairs\" already have data retrieved from the database accordingly?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "vWdvLLjkjc", "forum": "Pg7gwolvo9", "replyto": "Pg7gwolvo9", "signatures": ["ICLR.cc/2026/Conference/Submission8069/Reviewer_GoSm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8069/Reviewer_GoSm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8069/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761167199405, "cdate": 1761167199405, "tmdate": 1762920058316, "mdate": 1762920058316, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "MARAGE attacks RAG systems by (1) selecting semantically diverse queries to retrieve broad database coverage and (2) appending optimized adversarial strings that force LLMs to output retrieved data verbatim. Authors propose primacy weighting (exponentially decaying loss components) that prioritizes early tokens, exploiting autoregressive generation where starting correctly makes continuation likely. Authors show strong extraction rates (47-80% exact match) and  compares against basic  gradient baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.Proposes exponential decay for weighting loss terms is well-motivated for long targets and demonstrating higher success than prior approaches (Pleak).\n\n2. Extensive evaluation across multiple models and datasets with analyzing attack success in presence of defenses."}, "weaknesses": {"value": "1. The paper does not justify on why a new optmization technique is needed for this? There has been a long line of work on jailbreaks and prompt injection based techniques along side GCG like search-based methods and RL approaches."}, "questions": {"value": "The paper introduces a new method without first establishing that existing techniques are inadequate. Beyond GCG and Pleak, numerous established adversarial approaches—search-based methods, RL-based optimization, and LLM-guided generation—remain untested despite being applicable to this problem. It would be better to systematically pick some of these representative methods, identifying their specific limitations for long-target RAG extraction, and then justifying the new approach."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yBHjUPk9Wl", "forum": "Pg7gwolvo9", "replyto": "Pg7gwolvo9", "signatures": ["ICLR.cc/2026/Conference/Submission8069/Reviewer_zPvH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8069/Reviewer_zPvH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8069/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761683280772, "cdate": 1761683280772, "tmdate": 1762920057925, "mdate": 1762920057925, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MARAGE, an extraction attack aiming to extract data stored in RAG databases. MARAGE increases the diversity of extracted content via strategic query selection, improves the transferability of the adversarial query by averaging losses over multiple models, and enhances exact extraction of long chunks by incorporating decaying weights into the loss objective."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation and main method are clearly explained and easy to follow. \n2. The experimental section is thorough, and the additional details in the Appendix are appreciated. \n3. The explanation on using a weighted loss that emphasizes earlier tokens is helpful."}, "weaknesses": {"value": "1. The overall contribution is incremental. Many components of the proposed approach resemble existing techniques. For example, \n\n   - Diversity enhancement is achieved using cosine-similarity-based measures, which is similar in spirit to a number of prior works using cosine similarity for diversification, e.g., [1, 2]. \n\n   - The second contribution, approximating discrete optimization by continuous optimization, follows existing work [3] as authors admitted. \n\n   - The fourth contribution, evading perplexity-based defense, is achieved by adding a perplexity penalty into the objective. Such penaltized optimization strategy is widely used in ML community. \n\n   - Similarly, improving transferability by aggregating loss across multiple models/targets is also a widely used practice.\n\n2. Some clarification questions. \n\n   - Could you please provide an example showing the adversarial query derived by MARAGE?\n\n   - What is the underlying intuition for why MARAGE can successfully evade system prompts? How would MARAGE perform if the system prompt or the design of LLM implementing a rule to reject reporting exact text in the prompt? E.g., involving a step that checks the similarity before returing the final answer? \n\n   - The paper reduces the default number of greedy token evaluations from 512 to 16 for baseline attacks. What happens when this value is increased for the baselines?\n\n[1] Wang Z, Bi B, Luo Y, et al. Diversity Enhances an LLM's Performance in RAG and Long-context Task[J]. arXiv preprint arXiv:2502.09017, 2025.  \n\n[2] Gao H, Zhang Y. Vrsd: Rethinking similarity and diversity for retrieval in large language models[J]. arXiv preprint arXiv:2407.04573, 2024.\n\n[3] Yuxin Wen, Neel Jain, John Kirchenbauer, Micah Goldblum, Jonas Geiping, and Tom Goldstein. Hard prompts made easy: Gradient-based discrete optimization for prompt tuning and discovery."}, "questions": {"value": "Please see Weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AZavnlSqNr", "forum": "Pg7gwolvo9", "replyto": "Pg7gwolvo9", "signatures": ["ICLR.cc/2026/Conference/Submission8069/Reviewer_V9A9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8069/Reviewer_V9A9"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8069/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761683386069, "cdate": 1761683386069, "tmdate": 1762920057576, "mdate": 1762920057576, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents MARAGE, an optimization-based adversarial attack against RAG systems. Unlike prior prompt-leaking or manually crafted attacks, MARAGE formulates RAG extraction as a continuous embedding optimization problem to learn transferable adversarial suffixes that induce LLMs to reproduce retrieved database content verbatim. It introduces (1) a semantic-aware query selection strategy for high database coverage, (2) primacy weighting to handle long RAG chunks, (3) multi-model gradient aggregation for transferability, and (4) a perplexity-constrained loss to evade perplexity-based defenses. Experiments across five LLMs and multiple RAG datasets show strong improvements over GCG, Pleak, and manual baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is clearly written and well-organized, with extensive experiments, ablation studies, and analysis supporting the claims.\n2. MARAGE is the first optimization-based RAG extraction attack and achieves significant improvements over strong baselines such as GCG and Pleak. Beyond quantitative results, the paper provides mechanistic insights (e.g., layer-wise probing, primacy weighting effects) that help explain why the proposed optimization approach works."}, "weaknesses": {"value": "1. The experiments rely on relatively old and mid-sized open-source models (LLaMA-3, Vicuna, OPT, etc.). Modern RAG deployments often use stronger open-source model (Qwen3, DeepSeek, etc.) or closed-source models (GPT-5, Gemini, etc.). Without evaluating on or at least discussing these stronger and more representative models, it remains unclear whether MARAGE scales to or transfers across the modern RAG system.\n2. The paper primarily studies a single-turn retrieval pipeline with static retrievers, whereas real-world RAG systems often employ agentic or multi-stage retrieval strategies, such as query reformulation, iterative reasoning, tool use, etc.\nThese dynamic retrieval behaviors can alter both the exposure of database content and the model’s susceptibility to adversarial suffixes.\nEvaluating or simulating MARAGE under such agent-based, reasoning-enhanced RAG pipelines would provide stronger evidence of practical relevance and robustness."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "DOmUdVE3Ke", "forum": "Pg7gwolvo9", "replyto": "Pg7gwolvo9", "signatures": ["ICLR.cc/2026/Conference/Submission8069/Reviewer_dJsV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8069/Reviewer_dJsV"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8069/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996211949, "cdate": 1761996211949, "tmdate": 1762920057096, "mdate": 1762920057096, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}