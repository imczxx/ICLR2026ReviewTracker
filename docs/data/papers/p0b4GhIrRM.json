{"id": "p0b4GhIrRM", "number": 11129, "cdate": 1758189962781, "mdate": 1759897606286, "content": {"title": "Patient-Specific Biomolecular Instruction Tuning of Graph-LLMs", "abstract": "Proteomics data is imperative to pathogenic understanding of a disease phenotype. In cancer, analysis of molecular signatures enables precision medicine through the identification of biological processes that drive individualized tumor progression, therapeutic resistance, and clinical heterogeneity. Recent advances in multimodal large language models (LLMs) have shown remarkable capacity to integrate and reason across heterogeneous data modalities. However, performing multi-modal language modeling for molecular understanding of patient-specific proteomics remains a significant challenge due to 2 barriers: (1) the lack of instruction-tuning datasets that enable clinical interpretation from proteomics data, and (2) the absence of language-modeling architectures designed to capture the rich heterogeneity of molecular data. In this work, we introduce cptac-prot-instruct, the first patient-centric instruction tuning dataset for molecular understanding of oncology, comprising over 370k open-ended examples derived from individualized proteomic profiles curated from the largest national proteomics cancer study (CPTAC). Additionally, we propose KRONOS (Knowledge Representation of individualized Omics Networks via Structured tuning), a novel graph-llm framework that leverages molecular interaction topology with proteomics to learn patient-specific graph representations for enhanced clinical reasoning. In this work, w show that KRONOS achieves consistent improvements across benchmark clinical tasks, with AUC performance of up to $0.857\\pm0.025$ in prognostic tasks such as mortality prediction, cancer type OS prediction, and tumor stage classification from proteomics data. Ultimately, this approach empowers LLMs to understand patient-level pathogenesis, advancing precision medicine through more accurate diagnosis, prognosis, and treatment stratification.", "tldr": "", "keywords": ["Large Language Models", "Foundation Models", "Graph-LLM", "Instruction Tuning", "Multi-modal LLMs", "Bioinformatics", "Proteomics"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b28b9828b3c8226dd9036a22aec1866f030ff332.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "In this work, the authors finetuned LLMs to accurately extract from soft tokens <1> precise and verifiable information about patient proteomics data (such as relative and absolute abundance values), but also <2> the answer to more ambitious questions about the patient (such as future treatment response, mortality predictions, and other clinical reasoning subtasks). These questions are generated synthetically using both ground truth data and synthetic augmentations by LLMs. The dataset will be released upon publication.\n\nTo encode the proteomics data before projection to soft tokens, a graph neural network is used. Multiple algorithms are considered, with their representative power evaluated by the downstream tasks. Approaches that do not rely on the graph itself are also evaluated. The approach of the authors, named KRONOS, outperforms linear models, patient-similarity graph baselines, and LLM+tabular encoders. The reported ablation studies suggest that graph encoders, especially GAT, outperform basic node encoders."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The authors release (one of) the first patient-specific proteomics instruction-tuning corpus for oncology.\n* The injection of a PPI-graph embedding as a special token into an LLM follows the recent trend initiated by VLMs, and applies it to the combination of structured biological topology and natural-language reasoning.\n* The authors reported systematic ablations across multiple GNN families (SAGE/GAT/GIN) and a comparison against node encoders and MLP encoders within the same LLM backbone, giving ample confidence about their findings.\n* Evaluation and syntetic data generation ensures that both hard-verifiable and more creative tasks are both represented, enabling cross-evaluation and rule out mere task adaptation without incorporation of real patient data in all their complexity.\n* The usage of two stages (first hard data, then more open question answering) enables precise analysis of the model capabilities learned by the various contributions to the dataset, which is very valuable."}, "weaknesses": {"value": "* The metrics on the basic synthetic tasks (e.g. relative and absolute abundances) are not reported. It would be interesting to know how the use-case finetunings affect the performance of the basic tasks, if at all, and how well the model performs on them.\n* The usage of the STRING PPI network to create the graphs is never truly ablated. While the paper proves that the graphs created work better than an MLP per node and a node encoder, all these alternatives seem to share the same node structure, and it's not entirely clear to me how the feature representation of these nodes are computed.\n* Using DeepSeek-R1-distilled models to generate the questions will probably not generate the diversity of questions hoped initially, as RL models are known for their lack of generative diversity. An improved version of the dataset would need to use several different models to generated the questions and paraphrases, as a proxy for a larger and more diverse downstream usage.\n* The paper demonstrates that KRONOS beats LLM+MLP/NODE, but a strong graph-only predictor without an LLM is not reported in the same training data regime. This control would be needed to disentangle the contribution of instruction-tuned LLMs versus better graph representations.\n* The parameter capacity and the added FLOPS required by the model types are not fully documented. Could it be possible that KRONOS simply benefits from larger effective capacity or more training compute than the non-graph LLM baselines? Was the performance of the network converged when the training ended, or were they all still improving?"}, "questions": {"value": "* Have you considered the impact of the number of soft tokens used to represent the patient, and its placement in the prompt? These factors are known to impact VLMs significantly.\n* Did you consider other designs than STRING PPI networks for creating your graphs? Did you try alternative PPI/interaction graphs (BioGRID, IID, HINT, HuRI, Reactome FI) or integrate multiple sources? How sensitive are results to the graph choice and confidence cutoff?\n* Did you consider weighting the nodes by prevalence - suprise in the MLP baslines, to separate the effect of simple attention over the effect of the graph connections (cross-attention)?\n* Would you be able to provide the training time, GPU hours, and parameter counts of the considered models?\n* Are there subgroup analyses (by cancer type, stage) showing where KRONOS helps most?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DQjvazz6U9", "forum": "p0b4GhIrRM", "replyto": "p0b4GhIrRM", "signatures": ["ICLR.cc/2026/Conference/Submission11129/Reviewer_Dkd1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11129/Reviewer_Dkd1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11129/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761413519017, "cdate": 1761413519017, "tmdate": 1762922301207, "mdate": 1762922301207, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this study, the authors proposed to integrate graph embedding with LLMs using instruction learning like in LLaVa, which achieved the highest performance in cancer mortality, type classification etc. It is a good improvement."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Using the instruction learning/turning to combine proteomics data graph with LLM for sample classification/prediction. \nThe evaluation results showed the best performance."}, "weaknesses": {"value": "The prediction of cancer mortality, survival etc are not only based on omics data but also the other confounding factors, like age, gender, stage, ... which should be considered in the model. \nIn cancer biology, phenotype prediction (with the limited performance improvement) is less important than target and mechanism identification. It is unclear if the model can uncover the mechanisms associated with these phenotypes or not."}, "questions": {"value": "It is unclear if the model can uncover the mechanisms associated with these phenotypes or not.\nAdding the confounding factors in the prediction, in addition to the proteomics data."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rc223vUK0C", "forum": "p0b4GhIrRM", "replyto": "p0b4GhIrRM", "signatures": ["ICLR.cc/2026/Conference/Submission11129/Reviewer_vXGu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11129/Reviewer_vXGu"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11129/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761700425513, "cdate": 1761700425513, "tmdate": 1762922300470, "mdate": 1762922300470, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces CPTAC-PROTSTRUCT, the first large-scale instruction tuning dataset for proteomic understanding in oncology, and proposes KRONOS, a graph-LLM architecture that integrates protein-protein interaction (PPI) networks with patient-specific proteomics for clinical reasoning tasks. CPTAC-PROTSTRUCT contains over 370k examples derived from the CPTAC cohort, targeting schema alignment and clinical reasoning challenges unique to the proteomics domain. KRONOS augments language modeling capability with structured graph representations of patient omics, enabling improved performance on benchmark clinical tasks, including mortality prediction, cancer type, survival, and staging."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. CPTAC-PROTSTRUCT is a large and thoughtfully curated dataset, tackling both schema-level alignment and clinical reasoning, and offers clear value as a resource for future work.\n\n2. Experimental results (Table 3) demonstrate that KRONOS outperforms multiple strong baselines, including linear models, MLPs, and both node- and graph-based approaches in a rigorous 5-fold cross-validation. For example, KRONOS achieves AUC 0.857 (±0.025) and Macro-F1 0.742 on key tasks, emphasizing tangible improvements over prior state-of-the-art."}, "weaknesses": {"value": "1. The paper claims improved interpretability via the use of graph-based molecular knowledge, but lacks a concrete illustration of this point. For instance, no case studies or saliency analyses are provided showing which proteins/interactions the model relies on for clinical reasoning. Counterexamples or failure analyses are absent as well.\n\n2. The authors only compare against classical and GNN models. There is no comparison to recent instruction-tuned LLMs applied to medical or omics data (e.g., BioInstruct, scGPT), workflows that could be strong or even more competitive baselines; this makes claims of state-of-the-art incomplete.\n\n3. The rationale for freezing the LLM backbone (Section 4.2.1) in schema alignment and then fine-tuning in clinical reasoning is not well-motivated. Do alternatives (e.g., full fine-tuning vs. partial) yield better/worse results? No ablation or discussion exists."}, "questions": {"value": "1. Please clarify the architectural and training specifics for the connector network and GNN encoder, including hyperparameters and merging strategy. For instance, what is the dimensionality of $\\mathbf{z}_i$ and $\\mathbf{e}_i$, and is the pooling strategy (max, mean, attention) critical?\n\n2. Is the two-stage curriculum training approach significantly better than joint or single-stage training? Any quantitative or qualitative support?\n\n3. Can you extend the analysis by providing interpretability visualizations (e.g., attention maps, gradient-based saliency) to demonstrate how the model reasons over proteins/interactions during clinical tasks?\n\n4. Could you elaborate on procedures used to strictly segment patient-level data between instruction datasets, schema alignment, and benchmarking? How is the fold assignment managed when multiple template-derived questions per patient exist?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "7b6BFp6IjU", "forum": "p0b4GhIrRM", "replyto": "p0b4GhIrRM", "signatures": ["ICLR.cc/2026/Conference/Submission11129/Reviewer_V6MQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11129/Reviewer_V6MQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11129/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761925856167, "cdate": 1761925856167, "tmdate": 1762922299915, "mdate": 1762922299915, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces both a dataset, CPTAC-PROTSTRUCT, and a model for analyzing it, called KRONOS.  CPTAC-PROTSTRUCT  is an instruction-tuning corpus that pairs patient-specific proteomic profiles from CPTAC with schema-alignment prompts and clinically framed question-answer pairs. The authors curate proteins using centrality, variance, and cancer knowledge bases, then generate 354k paraphrased schema questions and 26k clinical reasoning items to adapt a general LLM to the proteomics modality. \nThe companion model, KRONOS, embeds each patient’s proteomic measurements on a STRING PPI graph, encodes it with a GNN, maps the graph embedding into the LLM token space via a connector, and uses a two-stage curriculum for schema alignment and clinical reasoning.\n\nOn CPTAC-derived prognostic tasks, KRONOS consistently outperforms strong linear, MLP, patient-similarity, and graph baselines across multiple clinically relevant endpoints. The work’s primary contributions are: introducing a large, task-targeted instruction set for proteomics; proposing a clear graph-to-LLM integration via a learnable connector with a staged training curriculum; showing benefits over node-only and non-graph alternatives; and providing detailed preprocessing, code, and hyperparameter settings to facilitate reproducibility."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "[S1] Overall workflow clarity:\nThe overall workflow figures are clear and easy to follow.\n\n[S2] Dataset contribution:\n The instruction-tuning dataset is large and explicitly decomposed into schema alignment and clinical reasoning stages, aligning the curriculum with the model architecture. I believe this dataset is the paper’s biggest contribution.\n\n[S3] Comparative study:\nA comparative study spans multiple families of baselines, including linear models, MLPs, patient-similarity networks, and PPI-graph classifiers, facilitating a comparison of gains.\n\n[S4] Consistent improvements:\nReported gains are consistent across four clinically meaningful endpoints, not just a single metric or task, which strengthens the case for this LLM-graph integration to be adopted by others."}, "weaknesses": {"value": "[W1] Need for more detailed methodological descriptions: \nWhile the authors have provided a mathematical description of KRONOS, it would be beneficial to include a companion figure that illustrates the model's inner workings. This visual aid would complement the text and provide a clearer understanding of the model. Currently, the diagrams that describe the pipeline are superficial, and more detail is needed regarding the inner workings of the model to facilitate understanding and reproducibility. Additionally, it would be helpful to more explicitly highlight the aspects of the model that differ from existing approaches that combine LLMs with graph-based architectures, so that the contribution is clearer to readers.\n\n[W2] Phi operator definition: The definition for the $\\phi$ operator related to the connector was not made explicit; the authors only refer to it as a `network`. Additionally, the relationship between W, b, and the connector should be stated in the main text. Judging from the code on the `tinyllava\\modelconnector`, I can see that it can take multiple forms, but these need to be described thoroughly in the main text. The paper should be self-explanatory without requiring reference to the code for definitions. \n\n[W3] Study generalizability: While it is acknowledged that the model is trained and evaluated on CPTAC, it is also important to test these limitations beyond CPTAC and TCGA, since they have a certain degree of overlap. To enhance the generalizability of this research, I recommend testing the model on an independent cohort or across institutions. This will help to probe for distribution shift and extend this work to other clinical settings.\n\n\n\n[W4] Figure captions need to be improved: The figure captions could be improved, especially for figures 1 and 2. They should describe the content of the images and explain their significance in relation to the overall workflow."}, "questions": {"value": "[Q1] Out-of-sample validation:\nRegarding external validity and W3: Could the authors perform an out-of-sample evaluation using a non-CPTAC/TCGA cohort (since there is some overlapping data between these datasets)? \n\n[Q2] Leakage controls: How do the authors guarantee that instruction generation, imputation, and graph construction are performed strictly within each training fold, with no statistics/calculations crossing splits? A simple per-fold data flow schematic or description would be helpful.\n\n[Q3] Related to W1 and W4: Please define undefined terms, such as the connector, and provide more detailed descriptions of the model. This includes improving Figures 1 and 2 to reflect this change and making the framework more transparent."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HQnOTkTF8B", "forum": "p0b4GhIrRM", "replyto": "p0b4GhIrRM", "signatures": ["ICLR.cc/2026/Conference/Submission11129/Reviewer_1ZLW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11129/Reviewer_1ZLW"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11129/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991695805, "cdate": 1761991695805, "tmdate": 1762922299418, "mdate": 1762922299418, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}