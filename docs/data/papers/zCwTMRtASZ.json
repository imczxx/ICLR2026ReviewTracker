{"id": "zCwTMRtASZ", "number": 10303, "cdate": 1758166495557, "mdate": 1759897659692, "content": {"title": "Softmax is not Enough (for Adaptive Conformal Classification)", "abstract": "The merit of Conformal Prediction (CP), as a distribution-free framework for uncertainty quantification, depends on generating prediction sets that are efficient, reflected in small average set sizes, while adaptive, meaning they signal uncertainty by varying in size according to input difficulty. A central limitation for deep conformal classifiers is that the nonconformity scores are derived from softmax outputs, which can be unreliable indicators of how certain the model truly is about a given input, sometimes leading to overconfident misclassifications or undue hesitation. In this work, we argue that this unreliability can be inherited by the prediction sets generated by CP, limiting their capacity for adaptiveness. We propose a new approach that leverages information from the pre-softmax logit space, using the Helmholtz Free Energy as a measure of model uncertainty and sample difficulty. By reweighting nonconformity scores with a monotonic transformation of the energy score of each sample, we improve their sensitivity to input difficulty. Our experiments with four state-of-the-art score functions on multiple datasets and deep architectures show that this energy-based enhancement improves the adaptiveness of the prediction sets, leading to a notable increase in both efficiency and adaptiveness compared to baseline nonconformity scores, without introducing any post-hoc complexity.", "tldr": "", "keywords": ["Conformal Prediction", "Energy-based Models", "Uncertainty Estimation"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/89416005036a13f46ae11bc373ab85013002926a.pdf", "supplementary_material": "/attachment/25b42b57dfebc572fac0409dad23ab21dd804b9e.zip"}, "replies": [{"content": {"summary": {"value": "The authors argue that the standard output of a multi-class classifier is not expressive enough for adaptive conformal classification. They propose an input-dependent reweighting strategy based on the Free Energy of the model class probabilities. The new conformity score can be used in combination with existing conformal classification techniques and is shown to reduce the size of the prediction sets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Reweighting conformity scores is a simple and powerful technique to improve CP adaptivity. The possibility of integrating the proposed strategy with existing approaches makes it potentially relevant and easy to use in many practical scenarios.\n\n- The proposed free energy seems to be a good proxy of an instance's difficulty when labels are not available."}, "weaknesses": {"value": "- Reweighting approaches are not new and are mostly used for regression. In the classification setup, [1] proposes a reweighting approach based on the entropy of the class probabilities. The authors may comment on the difference between their approach and that technique. \n\n- As the goal is to show adaptivity, the authors should report some approximate measure of models' conditional coverage.\n\n- The authors may give an intuitive explanation of why *model-implied data density* is a good measure of the epistemic uncertainty, for example,  by summarising the arguments of y (Fuchsgruber et al., 2024; Zong & Huang, 2025).\n\n- It is unclear whether the strategy only consists of removing the normalisation and the exponentiation in softmax-based scores.   \n\n[1]\nLuo, Rui, and Nicolo Colombo. \"Entropy Reweighted Conformal Classification.\" The 13th Symposium on Conformal and Probabilistic Prediction with Applications. PMLR, 2024."}, "questions": {"value": "- CP conformity scores are insensitive to monotonic transformations. Why is temperature scaling expected to have bad effects on the size of the prediction sets?\n\n- How is the marginalisation over $y$ defined? Doesn't summing over y in Eq.3 give 1?\n\n- What is the intuitive difference between Free Energy and Entropy? \n\n- How do you compute the normalisation factor, $Z$, in  Eq. 5?\n\n- Does the better separability in Figures 2 and 3 come from removing the logit?\n\n- What are the technical challenges of proving Theorem 2.2? Do you assume the trained classifier is correct?\n\n- Can a sample free energy be used as an unlabeled proxy of the label-dependent difficulty? If so, how is it possible without assumptions between true labels and model-generated probabilities?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "h6E7xpWuok", "forum": "zCwTMRtASZ", "replyto": "zCwTMRtASZ", "signatures": ["ICLR.cc/2026/Conference/Submission10303/Reviewer_Xpr8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10303/Reviewer_Xpr8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10303/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761656253234, "cdate": 1761656253234, "tmdate": 1762921652118, "mdate": 1762921652118, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel framework to enhance the adaptiveness of Conformal Prediction (CP), addressing the limitation where standard CP methods rely on unreliable Softmax probabilities for uncertainty quantification. The authors' core idea is to use the Helmholtz Free Energy, derived from Logits, as a more robust metric for sample uncertainty. The proposed method, Energy-Based Nonconformity Scores, is a simple post-hoc step that multiplicatively reweights existing nonconformity scores (like APS, RAPS, SAPS) using the energy score. This reweighting mechanism achieves two goals: (1) Amplifies scores for easy samples, leading to the generation of smaller, more efficient prediction sets. (2) Dampens scores for difficult or Out-of-Distribution (OOD) samples, leading to larger, more robust prediction sets."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1.\tImportant and Well-Defined Problem: The paper addresses a recognized, significant problem-the deficiency of softmax probabilities for uncertainty quantification and how this directly harms the adaptiveness of Conformal Prediction. The motivation is clear and compelling.\n2.\tNovel and Principled Solution: Using Helmholtz Free Energy (derived from logits, not softmax) as an uncertainty metric is a novel and theoretically grounded (via EBM framework) idea . This is more robust than relying on heuristics or unreliable softmax outputs.\n3.\tSimplicity and Generality: The method is a simple post-hoc step that reweights existing nonconformity scores (like APS, RAPS, SAPS) using the energy score. It does not require model retraining and can serve as a \"plug-and-play\" enhancement to existing CP workflows.\n4.\tExtremely Thorough and Strong Empirical Evaluation: The experimental design is rigorous, covering the key aspects needed to evaluate an uncertainty method."}, "weaknesses": {"value": "The proposed score design introduces two hyperparameters, $\\tau$ and $\\beta$. The authors should clarify how these parameters are selected in practice and provide justification for the chosen values."}, "questions": {"value": "1.\tRegarding the hyperparameter $\\tau$: In your main experiments (Tables 1, 2, 3), how was the energy temperature $\\tau$ selected? Was it a single value shared across all experiments, or was it tuned for each dataset/model pair? The sensitivity to $\\tau$ seems like a key practical consideration for this method; could you please clarify the overhead of tuning it?\n2.\tThe results in Table 2 show that as $\\alpha$ increases, the improvement in prediction set size when using the energy score becomes more pronounced. Could you explain the reason behind this behavior?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "W3v9YePxks", "forum": "zCwTMRtASZ", "replyto": "zCwTMRtASZ", "signatures": ["ICLR.cc/2026/Conference/Submission10303/Reviewer_rMqU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10303/Reviewer_rMqU"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10303/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761744842764, "cdate": 1761744842764, "tmdate": 1762921651639, "mdate": 1762921651639, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the limitations of using softmax probabilities as nonconformity scores in conformal prediction and argues that they fail to capture per-sample uncertainty adaptively. The authors propose an energy-based reweighting of the conformity score using the negative Helmholtz free energy derived from pre-softmax logits. The transformation is monotonic and thus preserves marginal coverage while aiming to improve adaptiveness and efficiency. Empirical results show smaller average prediction set sizes and better OOD sensitivity compared to softmax-based baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Addresses a timely and relevant issue in conformal prediction: softmax overconfidence and lack of adaptiveness.\n2. The proposed energy-based transformation is simple, intuitive, and easy to integrate into existing CP pipelines.\n3. Empirical results are consistent across several datasets and show modest but clear improvements in prediction-set efficiency."}, "weaknesses": {"value": "1. The logical argument connecting “softmax overconfidence” to “inefficient conformal prediction” is not rigorously analyzed; the paper relies mainly on anecdotal intuition rather than formal reasoning.\n2. The claim that “monotonic transformations preserve validity” is standard, and no formal analysis of efficiency or adaptive coverage is provided.\n3. Experiments only report marginal coverage and average set size, lacking conditional coverage evaluation, significance tests, and ablations on the energy transformation ($\\lambda$, $\\phi$).\n4. The conclusion “Softmax is not enough” is overgeneralized; the proposed method is heuristic and may not fundamentally resolve calibration issues."}, "questions": {"value": "1. What is the formal mechanism linking softmax miscalibration to conformal inefficiency?\n2. How exactly does the energy transformation improve efficiency beyond temperature scaling?\n3.  Can the authors provide conditional coverage or per-group analyses to verify “adaptive” coverage rather than just marginal improvements?\n4. How sensitive are the results to $\\lambda$ and the specific transformation $\\phi(·)$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "c8jAsDivIv", "forum": "zCwTMRtASZ", "replyto": "zCwTMRtASZ", "signatures": ["ICLR.cc/2026/Conference/Submission10303/Reviewer_sxcL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10303/Reviewer_sxcL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10303/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761936127438, "cdate": 1761936127438, "tmdate": 1762921651300, "mdate": 1762921651300, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}