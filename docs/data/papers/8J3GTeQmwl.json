{"id": "8J3GTeQmwl", "number": 15109, "cdate": 1758247880071, "mdate": 1763673587011, "content": {"title": "Graphon Cross-Validation: Assessing Models on Network Data", "abstract": "Graphon models have emerged as powerful tools for modeling complex network structures by capturing connection probabilities among nodes. A key challenge in their application lies in accurately characterizing the graphon function, particularly with respect to parameters that govern its smoothness, which significantly impact the estimation accuracy. In this article, we propose a novel graphon cross-validation method for selecting tuning parameters and estimation approaches.\nOur method is both theoretically sound and computationally efficient.\nWe show that our proposed cross-validation score is asymptotically parallel to the estimation error. Through extensive simulations and real-world applications, we demonstrate that our method consistently delivers superior computational efficiency and accuracy.", "tldr": "", "keywords": ["Graphon", "Link prediction", "Cross-Validation", "Graph imputa- tion", "Selection consistency"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/aa6f21f9a86c58445a4e22c07294e8ddccee4234.pdf", "supplementary_material": "/attachment/f4b297064ba16b1d5f5abf030bcc9a6bee931659.pdf"}, "replies": [{"content": {"summary": {"value": "This paper addresses the problem of model selection in graphon estimation by proposing a new cross-validation method for selecting tuning parameters and estimation approaches. The authors prove that their cross-validation score is asymptotically aligned with the estimation error. Extensive numerical simulations and real-data analyses are provided."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. I feel the proposed method quite smart. By randomly replacing a portion of the edges, the authors introduce a controllable bias, while obtaining edges that are (conditionally) independent of the training set for validation. The idea is interesting and provides insights for existing research.\n\t\n2.\tThe authors show that minimizing $V_k(M)$ approximately corresponds to minimizing $L(M)$, which provides a theoretical justification for the proposed method.\n\t\n3. The authors have provided sufficient numerical simulations and applied their method to real data examples.\n\t\n4. I enjoyed reading the paper. The writing is clear and well-structured."}, "weaknesses": {"value": "1. It is confused whether $v_i$ in Line 97 is a typo, since it is unusual for a node label to be a random variable. In addition, if $v_i$ is intended to be $\\mu_i$, then $p_{ij}$ would be random, see my Questions 1 and 2.\n\t\n2. It is unusual that the paper does not impose any assumptions on the graphon function. It is unclear what role the graphon function plays in their framework.\n\n3. The proofs need to be written more rigorously. See my Question 2, 5."}, "questions": {"value": "1. Could the authors clarify whether line 560 contains a type error? Should it perhaps be something like $P((v_i,v_j)\\in S_k)P(b_{ij}=1, a_{i'j'}=1) + P((v_i,v_j)\\notin S_k)P(a_{ij}=1,a_{i'j'}=1)?$ In addition, could the authors explain how the term $P(a_{ij}=1)P(a_{i'j'}=1)$ in line 561 is obtained? If I understand correctly, the edges $(i,j)$ and $(i',j')$ are correlated when $i=i'$ since they share the same $\\mu_i$.\n\t\n2. Line 597 could be made clearer. More precisely, the statement holds conditional on all $\\mu_i$'s.\n\t\t\n3. If all $\\mu_i$'s are treated as deterministic, then it is unclear why the paper introduces the graphon function.\n\t\t\n4.  It would be helpful if the authors could comment on the computational complexity of calculating $V_K(M)$, for example when $K\\asymp n$.\n\t\t\n5.  Could the authors clarify why Line 610 is correct? It seems that $S_k$ is random.\n\t\t\n\t\t\n6. It would be helpful if the authors could provide more clarification on when  Condition 1 is satisfied. For instance, including a toy example or specifying sufficient conditions would make it clearer. In addition, could the authors comment on whether this condition depends on $w_k$ and $\\theta$?\n\t\n7. It seems that the theorem holds for any fixed $\\theta$. What would happen if $\\theta = 0$ or 1? In addition, in the appendix the authors set $\\theta$ as a random variable, then how would this affect the validity of the theorem?\n\n\n8. It would be helpful if the authors could provide a theoretical comparison between their method and ECV in terms of implementation time.\n\t\n9. It would be interesting to know how the theoretical results behave when $p_{ij}$ tends to zero as $n$ increases.\n\t\n10.  Some minor errors: \n\t\nLine 158: $w_k\\theta$: $w_k\\theta 11^\\top$.\n\nLine 249, 251: five: four.\n\nLine 573: equation equation 8: equation 8."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fbmM4AYqru", "forum": "8J3GTeQmwl", "replyto": "8J3GTeQmwl", "signatures": ["ICLR.cc/2026/Conference/Submission15109/Reviewer_8g5b"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15109/Reviewer_8g5b"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15109/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761320219901, "cdate": 1761320219901, "tmdate": 1762925431989, "mdate": 1762925431989, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces an improved cross-validation method with random imputation, which is unbiased and efficient compared to existing methods including edge sampling approaches and the matrix completion method proposed by Li et al. (2020). The paper compares against these baselines across multiple graphon estimation methods, demonstrating effectiveness in terms of both accuracy and computational efficiency. The authors provide theoretical justification showing that their cross-validation score is asymptotically correct. I found that this paper is strong and provides a comprehensive analysis based on both theory and numerical evidence. The case studies are insightful and demonstrate practical applicability of the proposed method."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The authors effectively articulate the fundamental challenge in applying cross-validation to network data, particularly how traditional edge sampling destroys network topology.\n\n2.  The random imputation strategy is quite simple and very effective. I could not think of any simpler way.\n\n3. The paper provides extensive experiments across multiple graphon models (varying in density and rank properties) and estimation methods (NS, SAS, USVT, ICE). Section 6's case studies are particularly compelling.\n\n4. Unlike ECV which requires low-rank assumptions and only has theoretical guarantees for specific models (SBM, RDPG), CV-imputation works for the general graphon model class"}, "weaknesses": {"value": "1. I could not follow the theoretical justification precisely, but I get the intuition behind it which is that the training and test data are independent of each other. Therefore, it doesn't change the distribution of the edge probabilities. It is worthwhile to note that this is valid only when the presence orabsense of an edge is independent of that of other edges.\n\n2.  While the paper tests networks up to approximately 2,600 nodes, many real-world networks contain tens or hundreds of thousands of nodes, yet no discussion addresses computational or memory requirements at such scales. I understand to some extent because the number of pairs for increases quadratically with respect to the number of nodes. But it is nicer to discuss a solution to scale up the method."}, "questions": {"value": "I am unclear why the computational time differs across estimation methods (Figure 3), since the cross-validation procedure itself should be independent of the estimation method being evaluated. I suspect the authors calculated the total CPU time, which includes both the cross-validation procedure and the estimation method execution, rather than isolating the cross-validation overhead alone. This make it unclear the actual speedup specifically attributable to CV-imputation compared to ECV. The authors should clarify what operations are included in their reported CPU times and, ideally, provide a breakdown separating cross-validation overhead from estimation costs."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fLjZrdIRBf", "forum": "8J3GTeQmwl", "replyto": "8J3GTeQmwl", "signatures": ["ICLR.cc/2026/Conference/Submission15109/Reviewer_9pGj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15109/Reviewer_9pGj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15109/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761769095561, "cdate": 1761769095561, "tmdate": 1762925431518, "mdate": 1762925431518, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Responses (1/3)"}, "comment": {"value": "We thank all reviewers for their thoughtful and constructive feedback. We are encouraged that they found the paper clear and well written (Reviewers 8g5b, NTvL), our proposed CV-imputation method “simple and very effective” (Reviewer 9pGj) and “quite smart” (Reviewer 8g5b), with theoretical soundness (Reviewers NTvL, Q27V, 8g5b, 9pGj) and strong empirical validation through \"extensive experiments\" (Reviewer 9pGj) and \"sufficient numerical simulations\" (Reviewer 8g5b).\n\n### **1. Computational order complexity of the method**\n\n\n**Response:** We thank reviewers for the insightful comment. To evaluate a set of $|\\mathcal{M}|$ candidate hyperparameters on an $n$-node network using $K$-fold cross-validation, the total computational complexity of our CV-imputation method is  **$O(|\\mathcal{M}| \\cdot (KC_{estim}(n) + n^2))$**, while the competing ECV method has complexity **$O(|\\mathcal{M}| \\cdot   (KC_{estim}(n) + KT_{\\text{mc}}(n)))$**. Here,  $C_{\\text{estim}}(n)$ denotes the cost of the specific graphon estimator (e.g., NS, ICE), $T_{\\text{mc}}(n)$ is the matrix completion complexity. When using full SVD for matrix completion, $T_{\\text{mc}}(n)$ has $O(n^3)$, in which case, ECV has computation $O(|\\mathcal{M}| \\cdot   (KC_{estim}(n) + Kn^3))$.\n\n\n\n*Detailed Complexity Breakdown:* For each hyperparameter candidate, CV-imputation repeats the following procedure:\n\n(1) *Partition step.* Constructing and randomly partitioning the edge set $\\{(v_i, v_j) : 1 \\le i < j \\le n\\}$ into $K$ folds touches each edge once, so the cost is $O(n^2)$.\n\n(2)  *Imputation step.* For a fixed fold $k$, constructing the training matrix $\\mathbf{A}^{\\text{train}}$ by masking and imputing the edges in $S_k$ visits $|S_k| \\asymp n^2 / K$ entries, so the cost is $O(n^2 / K)$ per fold and $O(n^2)$ over all $K$ folds.\n\n(3)  *Training step.* Fitting model $M$ to $\\mathbf{A}^{\\text{train}}$ has cost $C_{estim}(n)$ per fold, hence $O\\bigl(K \\cdot C_{estim}(n)\\bigr)$ over all folds.\n\n(4) *Debiasing step.* In fold $k$, the debiased predictions are computed only for the edges in validation set $S_k$, because these are the entries involved in the fold-$k$ validation loss. Since $|S_k| \\asymp n^2/K$, the cost is $O(n^2/K)$ per fold and $O(n^2)$ overall across all folds. \n\n\n(5) *Validation score.* For each fold $k$, the validation error is computed by comparing the held-out edges $a_{ij}$, $(i,j)\\in S_k$, with their debiased predictions.  Since $|S_k|\\asymp n^2/K$, the cost is $O(n^2/K)$ per fold and $O(n^2)$ across all folds.\n\nTherefore, if we have $|\\mathcal{M}|$ hyperparameters to evaluate,  the total cost of CV-imputation for hyperparameter tuning is $O(|\\mathcal{M}| \\cdot (KC_{estim}(n) + n^2))$.\n\nECV follows the same outer loop structure with $K$ folds and identical partitioning. The critical difference lies in step (2): while our method performs imputation only, ECV performs both imputation (in a different way, i.e., masking $S_k$ to all zero) and matrix completion on the masked $n  \\times n$ matrix to produce a completed surrogate before estimation. This matrix completion step is computationally heavy, as it must operate on the full matrix and is repeated once per fold. The subsequent estimation and validation steps follow the same computational order as described above, except that ECV omits the de-biasing step. Therefore, ECV's total complexity is $O(|\\mathcal{M}| \\cdot   (KC_{estim}(n) + KT_{\\text{mc}}(n)))$.\n\n**Action:** (1) On page 4 in the revised manuscript, we have added a paragraph summarizing this computational complexity comparison. (2) On pages 16–18, we have added a new Section S.8 that provides the detailed breakdown of the computational complexity for CV-imputation and ECV.\n\n### **2. Generalizability of CV-imputation to broader class of  models**\n\n \n**Response:** We appreciate reviewers' insightful comment. Here, we present empirical evidence and discuss how our theoretical results can be extended to two representative settings: latent-space models and sparse network models.\n\n\n \n#### **2.1 New Empirical Evidence**\n\n(1) Latent space model. We first evaluated CV-imputation on latent space models where latent positions $\\mu_i$ were sampled from uniform distribution over $[0,1]^d$, and edge probabilities were generated via an inner-product function $f(\\mu_i, \\mu_j) = (1+\\mu_i^T \\mu_j) / d$. We considered four settings: $d \\in 2, 4, 6, 8$. \n\nFor each simulated network, we applied the NS and USVT estimation method to obtain estimates of the probability matrix. Although the NS and USVT methods were originally developed for graphon models, they remain applicable as general-purpose procedures that take the adjacency matrix as input and output an estimate of the edge probability matrix. In this experiment, our focus is on evaluating how effectively different hyperparameter selection strategies guide these estimators."}}, "id": "nZjV1L0pAg", "forum": "8J3GTeQmwl", "replyto": "8J3GTeQmwl", "signatures": ["ICLR.cc/2026/Conference/Submission15109/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15109/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15109/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763658578665, "cdate": 1763658578665, "tmdate": 1763671281878, "mdate": 1763671281878, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new cross-validation approach for graphon estimation, introducing a random-imputation strategy to handle dependency structures in networks and to tune hyperparameters from a single observed graph. The authors argue that existing edge-sampling methods lead to bias by degrading network connectivity, and they provide a careful theoretical treatment to show consistency of their approach. The work is technically sound and well written, but the contribution represents a relatively narrow conceptual advance within the specific context of graphon models rather than a broader methodological step forward for network machine learning. The empirical results, while generally positive, do not convincingly demonstrate consistent or substantial gains over edge-based cross-validation (ECV). The paper would be strengthened by a deeper analysis of when and why ECV fails in practice, clearer discussion of how the proposed method could generalize beyond the graphon setting, and a more comprehensive evaluation showing robust and meaningful performance improvements across a wider range of network types."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses a legitimate technical challenge: how to form cross-validation sets in under dependence in networks. The proposed CV-imputation scheme is clearly described, mathematically justified, and accompanied by consistency proof. The implementation appears efficient, and the experiments consider several graphon estimators (NS, SAS, USVT, ICE), as well as both synthetic and real-world graph datasets. The manuscript is generally clear and thorough."}, "weaknesses": {"value": "(1)\tScope and generality. The method applies specifically to graphon models and depends on smoothness and exchangeability assumptions. It is unclear how the proposed theoretical framework or random-imputation idea would extend to broader classes of network models (e.g., latent-space, temporal, or sparsified networks). Thus the paper’s claims of general applicability thus seem overstated.\n(2)\tEmpirical impact. The experimental gains over ECV are modest. In Table 1, SAS and ICE show no meaningful improvement, suggesting that differences arise mainly from estimator robustness rather than from the proposed validation method. In real-world datasets, results are essentially tied on three of four networks. Only the drug–disease network shows a visible advantage, which is not analyzed in depth. Without more in-depth analysis demonstrating the impact of ECV bias, it is difficult to conclude that the differences are practically important.\n(3)\tEfficiency gains. Although Figure 3 shows a computational speed-up relative to ECV, the paper does not provide an asymptotic complexity comparison. Moreover, the statistical efficiency results in Figure 5 are averaged across all graphon models and may be dominated by the weaker performance of NS and USVT, making it hard to assess whether the gains are consistent or meaningful across settings."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mfbFxDfKMg", "forum": "8J3GTeQmwl", "replyto": "8J3GTeQmwl", "signatures": ["ICLR.cc/2026/Conference/Submission15109/Reviewer_NTvL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15109/Reviewer_NTvL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15109/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762097757138, "cdate": 1762097757138, "tmdate": 1762925431126, "mdate": 1762925431126, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes CV-imputation, a cross-validation method for selecting graphon-based models on network data. The method is model-agnostic, computationally efficient, and supported by theoretical guarantees of asymptotic consistency. Empirical results show that it outperforms or matches existing methods across various networks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. CV-imputation does not assume a specific form of the graphon, allowing it to be applied across diverse network structures without model restrictions. \n2. The method avoids expensive singular value decomposition (SVD), reducing runtime and enabling scalability to large networks. \n3. It is supported by a convergence result showing that its validation criterion aligns with mean squared error minimization in the asymptotic regime."}, "weaknesses": {"value": "This work assumes the data comes from a graphon and the goal is to assess graphon-based estimators. However, would such a method be extended beyond this assumption? Discussion about the limitations of applicability would be a nice addition to the paper.\n\nAdditional discussion on the order complexity of the method vs the baselines would strengthen the paper."}, "questions": {"value": "1. How sensitive is CV-imputation to violations of the graphon assumption? Are the theoretical guarantees still meaningful outside the graphon framework?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "SMReVqeC0m", "forum": "8J3GTeQmwl", "replyto": "8J3GTeQmwl", "signatures": ["ICLR.cc/2026/Conference/Submission15109/Reviewer_Q27V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15109/Reviewer_Q27V"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15109/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762140152824, "cdate": 1762140152824, "tmdate": 1762925430682, "mdate": 1762925430682, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}