{"id": "zVOgqaR261", "number": 23792, "cdate": 1758348489915, "mdate": 1759896797110, "content": {"title": "Semantic Probabilistic Control of Language Models", "abstract": "Semantic control entails steering LM generations towards satisfying subtle non-lexical constraints--*e.g.*, toxicity, sentiment, or politeness--attributes that can be captured by a sequence-level *verifier*. It can thus be viewed as sampling from the LM distribution conditioned on the target attribute, a computationally intractable problem due to the non-decomposable nature of the verifier. Existing approaches to LM control either only deal with syntactic constraints which cannot capture the aforementioned attributes, or rely on sampling to explore the conditional LM distribution, an ineffective estimator for low-probability events. In this work, we leverage a verifier's gradient information to efficiently reason over *all* generations that satisfy the target attribute, enabling precise steering of LM generations by reweighing the next-token distribution. Starting from an initial sample, we create a local LM distribution favoring semantically similar sentences. This approximation enables the tractable computation of an *expected sentence embedding*. We use this expected embedding, informed by the verifier's evaluation at the initial sample, to estimate the probability of satisfying the constraint, which directly informs the update to the next-token distribution. We evaluated our approach on the tasks of controlling the toxicity, sentiment, and topic-adherence of LMs yielding generations satisfying the constraint with high probability without degrading their quality.", "tldr": "We leverage the gradient information of a constraint verifier to efficiently perform exact inference over generations satisfying the constraint, enabling precise steering of LM generations.", "keywords": ["LM control", "semantic control", "inference-time alignment", "probabilistic reasoning", "constraints", "tractable probabilistic reasoning"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f38d611cde63a0c466464c3e2b24b06525719086.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes SConE, a method for exerting semantic control over the outputs of autoregressive language models at inference time. The approach leverages first-order gradient information from a sequence-level verifier (for attributes like toxicity, sentiment, or topic) to estimate, for each next-token choice, the probability that future generations will satisfy a given semantic constraint. This is achieved by constructing a locally contextualized approximate distribution and calculating the expected sentence embedding in that neighborhood. The resulting probability is used to reweight the LM’s next-token distribution. The authors evaluate SConE on tasks involving toxicity, sentiment, and topic control, reporting higher rates of constraint satisfaction compared to sampling-based baselines such as best-of-n, with little to no loss in fluency measured by perplexity. The method operates at inference time without requiring model fine-tuning and is designed to work alongside existing syntactic control techniques."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Originality: The paper presents a distinctive inference-time strategy for semantic control in language models, using verifier gradients to efficiently reweight generation probabilities, which differs appreciably from established sampling or heuristic approaches.\n\nQuality: The theoretical justification is solid, and the core methodology is implemented and tested on well-chosen tasks. Experimental results demonstrate substantial improvements in constraint satisfaction without major disruptions to output quality.\n\nClarity: The writing is generally clear, figures are informative, and the organization facilitates understanding of both the motivation and technical details. Prior work is discussed sufficiently to highlight the contribution.\n\nSignificance: The work tackles an important and timely problem and shows practical effectiveness, indicating value and relevance to both researchers and practitioners interested in controlled text generation."}, "weaknesses": {"value": "Comparative Experimental Coverage: while the experiments convincingly compare SConE to best-of-n and baseline generation methods, the paper does not empirically evaluate against methods in activation steering adaptors, or other types of steering. \n\nScalability and Efficiency Analysis: while SConE is presented as computationally attractive, a systematic analysis of its runtime and scaling characteristics is missing. The paper would be improved by benchmarking generation runtimes and memory use against baselines for several sequence lengths and constraint types.\n\nAblation and Sensitivity Studies: ablation experiments varying the parameters (e.g., different numbers of samples, alternative verifiers, different LM sizes) could provide insight into robustness and limitations, as well as guidance for practitioners on setting these hyperparameters.\n\nBreadth of Task and Domain Evaluation: the current tasks rely on strong, well-curated verifiers. It remains unclear how SConE performs on less well-defined attributes or in more complex domains (e.g., multi-turn dialogue, factual correctness, style transfer). Commenting on this would be valuable."}, "questions": {"value": "Please address weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cxKBEgKZax", "forum": "zVOgqaR261", "replyto": "zVOgqaR261", "signatures": ["ICLR.cc/2026/Conference/Submission23792/Reviewer_s9Dw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23792/Reviewer_s9Dw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23792/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761885691608, "cdate": 1761885691608, "tmdate": 1762942809500, "mdate": 1762942809500, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Work Summary\nThis paper focuses on the semantic control problem of language models (LMs), aiming to address the computational intractability of steering LM generations to satisfy sequence-level non-decomposable constraints (e.g., toxicity, sentiment, topic adherence). The authors propose a Semantic Control Estimator (SConE) that leverages verifier gradient information and knowledge compilation techniques: starting from a lookahead sample, a locally contextualized LM distribution favoring semantically similar sentences is constructed; the expected sentence embedding under this approximate distribution is computed via a decomposable and smooth circuit; finally, the next-token distribution is reweighted using the constraint probability estimated from the expected embedding and verifier gradients. The method is evaluated on three tasks (toxicity control, sentiment control, topic adherence control) with models like Llama-3.2 (1B) and GPT2-medium, showing that it outperforms baselines (e.g., BoN, DExperts) in constraint satisfaction while maintaining generation fluency and diversity."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "Strengths\nThe experimental design is relatively comprehensive. The authors validate the proposed method across three distinct semantic control tasks (toxicity, sentiment, topic), covering both \"constraint satisfaction\" (e.g., detoxification, positive sentiment) and \"constraint enhancement\" (e.g., toxification) scenarios. For each task, multiple base models (Llama-3.2, GPT2-medium) and diverse baselines (training-free methods like random, beamsearch, BoN; training-based methods like PPLM, DExperts, LMSteer) are included for comparison. Evaluation metrics also cover multiple dimensions: constraint satisfaction (e.g., Toxic Prob, Sentiment Prob), generation fluency (perplexity), and diversity (Dist-1), providing a relatively holistic assessment of the method’s performance."}, "weaknesses": {"value": "Critical Weaknesses and Reasons for Rejection\n1.Severe Gaps in Related Work Comparison, Leading to Incomplete Contribution Positioning\nThe core idea of this work—Bayesian-based probabilistic inference for LM semantic control—falls into a research paradigm that was extensively explored around 3 years ago, yet the authors fail to compare with key representative works in this field, resulting in an unclear positioning of the work’s novelty. Specifically:\nOmission of classic Bayesian control methods: Works like GeDi (Krause et al., 2021) and FUDGE (Yang & Klein, 2021) are foundational for Bayesian-based LM semantic control. GeDi uses generative discriminators to model attribute-aware distributions and adjust token probabilities via KL divergence constraints; FUDGE leverages factorized Bayesian inference to balance fluency and constraint satisfaction. Both share the same \"probabilistic inference for distribution adjustment\" core as SConE, but the paper does not discuss differences in technical routes (e.g., whether SConE’s \"local contextualized distribution + knowledge compilation\" is more efficient than GeDi’s discriminator-guided KL control) or comparative performance. Without this comparison, it is impossible to verify whether SConE truly addresses the limitations of earlier Bayesian methods or merely repeats existing ideas with minor tweaks.\nLack of discussion on paradigm evolution: The paper does not contextualize its method within the broader evolution of LM control research. Around 2021–2022, Bayesian-based methods (including the aforementioned GeDi, FUDGE) were widely studied, but with the advent of large language models (LLMs) like ChatGPT (2022), this paradigm has gradually been phased out. The authors ignore this key trend, failing to explain why a Bayesian-based method is still meaningful today, nor do they compare SConE with modern LM control approaches (e.g., instruction tuning, RLHF, in-context learning) that are more compatible with LLMs. This omission makes the work’s practical value questionable.\n2. Ignorance of Critical Limitations of Bayesian Methods in Large-Scale LMs, Undermining Practicality\nThe paper claims that SConE maintains generation quality while improving constraint satisfaction, but it completely ignores a well-known flaw of Bayesian-based LM control methods: as LM scale increases, the trade-off between \"constraint satisfaction\" and \"generation quality\" becomes increasingly severe, which is precisely why this paradigm was abandoned in the LLM era. Specifically:\nScalability bottleneck: Bayesian methods like SConE rely on complex probabilistic inference (e.g., Gibbs sampling for lookahead samples, knowledge compilation for circuit construction) and gradient computations of verifiers. For small models (e.g., Llama-3.2 1B, GPT2-medium) used in the experiments, these computations are manageable, but for large-scale LLMs (e.g., GPT-4, Llama 3 70B), the computational overhead of inference and gradient calculation will increase exponentially. The paper does not evaluate SConE on large models, nor does it discuss optimization strategies for scalability, making the method impractical for real-world LLM applications.\nHidden quality degradation under strong constraints: The experiments only test \"weak to moderate\" constraint intensities (e.g., detoxification of non-toxic prompts, positive sentiment for movie reviews). However, in scenarios requiring strong semantic constraints (e.g., strict topic adherence for professional domains, zero-toxicity for child-friendly content), Bayesian methods often force the LM to prioritize constraint satisfaction by sacrificing lexical diversity and contextual coherence—manifested as repetitive expressions, rigid syntax, or disconnected logic. The paper does not design experiments for strong constraint scenarios, nor does it analyze potential quality degradation, leading to an overoptimistic assessment of the method’s performance.\nVerifier dependency without mitigation: SConE’s constraint satisfaction is highly dependent on the accuracy of the sequence-level verifier (e.g., RoBERTa-based toxicity classifier). In the LLM era, verifiers often struggle to capture subtle semantic nuances of large models (e.g., sarcasm, implicit toxicity), and Bayesian methods amplify this dependency—errors in verifier judgments will directly distort the next-token distribution adjustment. The paper does not discuss strategies to mitigate verifier bias (e.g., multi-verifier ensemble, human-in-the-loop correction), further limiting the method’s robustness in practical use.\n3. Insufficient Technical Justification for Core Modules\nKey technical designs of SConE lack in-depth justification, raising doubts about the method’s reliability:\nArbitrariness of local contextualized distribution parameters: The paper uses \"top-k=10\" and \"2 Gibbs sampling chains\" as default parameters for constructing the local contextualized distribution, but does not explain why these parameters are chosen (e.g., why top-k=10 is better than top-k=5 or 25 in balancing efficiency and constraint coverage). The ablation study only briefly mentions that top-k=25 improves performance but increases time by 8.71x, without analyzing how parameter adjustments affect the \"semantic similarity bias\" of the local distribution—e.g., whether a larger top-k leads to diluted contextual information, or whether fewer sampling chains cause mode collapse.\nAmbiguity in knowledge compilation implementation: The paper claims to use \"decomposable and smooth circuits\" to compute expected embeddings, but does not provide details on circuit construction (e.g., how to map the local contextualized distribution to circuit nodes, how to handle variable dependencies for long sequences). For complex sequences (e.g., 60-token topic control tasks), whether the circuit can maintain decomposability and smoothness, and whether the computational complexity remains tractable, are not verified. This ambiguity makes it difficult for other researchers to reproduce the work or assess its technical validity."}, "questions": {"value": "same to weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "wVGkGC9bkf", "forum": "zVOgqaR261", "replyto": "zVOgqaR261", "signatures": ["ICLR.cc/2026/Conference/Submission23792/Reviewer_aVGK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23792/Reviewer_aVGK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23792/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761900693049, "cdate": 1761900693049, "tmdate": 1762942809220, "mdate": 1762942809220, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a way to control the semantics of LLM generations at inference time. The method (SConE) operates at decoding, reweighting the LLM's output token probability distribution in a way that privileges desired semantics of the future output. \"Desired semantics\", e.g., not being toxic, is given by a neural attribute classifier (e.g. a BERT-like toxicity classifier) that takes strings to ratings in [0,1]. The paper shows that the problem of reweighting the output token probabilities computationally boils down to finding the future generations' expected embedding under the attribute classifier. The expected embedding step of the approach is efficient because it can be vectorized. The process of sampling future generations can be made more efficient using HogWild! Gibbs sampling. Experimentally, the approach outperforms existing baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. ScoNE is lightweight method that demonstrably outperforms existing baselines on toxicity, sentiment, and topic control.\n2. The method is timely and relevant, as it it proposes a way to control generation by LLMs using only their output probabilities."}, "weaknesses": {"value": "A primary weakness of the paper is insufficient contextualization wrt prior work. A missing paper is FUDGE https://arxiv.org/pdf/2104.05218 which also operates by reweighing token probabilities with Bayes rule, via some attribute classifier on future generations. Since FUDGE is very close to your method, it should be discussed up front and tested as a baseline.\n\nA second crucial weakness of the paper is the mathematical exposition. The paper was difficult to read, taking many close readings in order to grasp the intent of the paper flow. The main detractor was the abruptness with which the writing moved from concrete to very abstract topics (e.g. knowledge compilation). In general, the lack of \"connective tissue\" between sections put the burden on the reader to infer the author's intent. These however should be easy to improve. \n\nIf both points are addressed, I will increase my score to an accept.\n\n## Detailed comments\n\n1. l118 Needs some explanation here of Y_i, e.g., \"...of random variable Y_i over the output token at time t=i.\"\n\n2. Eq 2 is very similar in spirit to previous works such as FUDGE. Please add references here to at least FUDGE (maybe also DExperts, Gedi) and state the extent to which ScoNE is similar; if not, why not.\n\n3. Section 4.1 I found this section to be confusing as it lacked concrete examples. What does it mean for \"different sentences to depend on different sets of conditionals\"? Can you edit this paragraph to map \"sentences\" and \"conditionals\" concretely onto the mathematical expressions in Eq (6)? Also, could you provide a concrete natural language example? \n\n4. Similarly, I did not understand the difference between $y$ and $\\tilde y$. Can you provide an example of a semantic neighborhood $\\tilde y$ compared to $y$? I find the current explanation to be rather opaque and disconnected to later sections.\n\n5. Algorithm 1: Please add the algorithm of CondMarginals somewhere\n\n6. l294 \"We denote by emb:...\" the introduction of $\\overline{emb}$ needs to be gentler, given the previous paragraphs. I would first write Eq (7) purely in terms of $s$ and $y_{1:T}$, then motivate the current Eq (7) using the fact that the embedding function of the verifier is a deterministic function of the LM generation-- i.e., we can do the Taylor trick replacing the token outputs with their embedding. For consistency, I would replace $\\nabla \\phi_a(s)$ with the version you have in Algo 3: $\\nabla_{emb(s)} \\phi_a$. Otherwise, it's not transparent as written; I had thought that you were taking the gradient with respect to $s$, thereby missing a chain rule from the embedding to $s$ in the first-order Taylor expansion.\n\n7. l301 Do we have any theoretical guarantees on how good this approximation is?\n\n8. l309 We need to better motivate the path from knowledge compilation to average embeddings here. These few paragraphs start by introducing decomposability and smoothness of circuits. I would instead start by stating the goal, i.e., to compute the expected embedding from samples using a single pass.\n\n9. Relatedly, the discussion on how to compute the expected embedding (l343) reads as disconnected to the previous part. If I understand correctly, this part describes how to, given a collection of sampled outputs, do one pass through the computation graph of the BERT verifier and produce the expected embedding over this sample. This is not obvious given how it is written. I recommend that, instead of only introducing $\\tilde p$, also stating that this circuit is the \"computation graph\" of the $emb$ function (i.e. the part of the verifier that you extract the embedding out of).\n\n10. Finally, a connection is missing from the last part of that subsection to the circuit $\\tilde p$ being smooth and decomposable. It doesn't need to be a formal proof, just a short justification that your verifier of choice has this property. Alternatively, because it takes up too much space and doesn't add much to the main contribution, I would even move the smoothness/decomposable parts entirely to the Appendix."}, "questions": {"value": "Here are some more concrete suggestions to smooth the writing.\n\n1. l269 to approximate ..., the constraint probability, *such as the likelihood a sentence is toxic*.\n\n2. l408 State the sample size for ScoNE in the main (or mark clearly in Fig 3).\n\n3. l193 Next, we will show how to compute *an approximation of* the above expectation in closed form...\n\n4. Dist-1 is the type-token ratio (TTR), a well-known measure in NLP and linguistics. I would suggest renaming it for consistency with the literature."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DGIZRen74A", "forum": "zVOgqaR261", "replyto": "zVOgqaR261", "signatures": ["ICLR.cc/2026/Conference/Submission23792/Reviewer_afpf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23792/Reviewer_afpf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23792/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761933390759, "cdate": 1761933390759, "tmdate": 1762942808730, "mdate": 1762942808730, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Here is my understanding of the algorithm (please correct if wrong). \nFor each position, \n\n1. Get AR logits, which are then used to get top-k tokens. Use these as “seeds” and expand the batch using this. \n\n2. Using a short gibbs sampling chain to obtain look ahead completions, given the initial top-k tokens. \n\n3. Use the MLM to obtain pseudo-logits, which are then used to compute an expected embedding. \n\n4. Use the expected embeddings to compute the gradient of the constraint and use a first order taylor approximation to estimate the change in the constraint for each continuation. \n\nThey demonstrate superior empirical performance on sentiment control, language detoxification, and topic control."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**Empirical Performance**: The empirical performance does appear quite strong, and the paper demonstrates that this does scale to larger models. \n\n**Experiment Design**: The experimental design also seems very strong: the selected prompts for each task (toxicity, sentiment, topic) seem appropriate given the constraint; and the evaluation metrics are reasonable."}, "weaknesses": {"value": "**Framing and Motivation**: The paper is framed as performing exact inference of an approximate distribution, but I feel that this is not quite accurate. Finite time Gibbs is an MCMC method, which converges as the number of sampling steps -> infinity. Pseudo-likelihoods from a masked language model do not necessarily correspond to a valid joint distribution [1]. Thus the gibbs sampling algorithm may not even be sampling from a well defined distribution. The Taylor approximation also introduces another approximation layer. \n\nAs a result, I do not find the overall motivation for this approach to be convincing. \n\n**Complexity**: The method is extremely complex for an algorithm sampling from an approximation of the true distribution — it requires 3 models (masked language model, autoregressive base, and external classifier). This isn’t a negative in itself: plenty of effective algorithms for sampling (no U-turn sampler) are complex. \n\nThe issue is that this complexity seems at odds with the motivation of using an approximate distribution instead of the actual distribution: typically an approximate distribution is used because it enables an easier target to sample from. In this case, their approximate distribution still necessitates the use of an external MLM to estimate pseudo-likelihoods, on top of first order Taylor approximations and computational circuits. \n\n**Incomplete Literature Review**: [2] was published at ICLR last year and also focuses on semantic control via gradients. They guide an autoregressive model to satisfy external, differentiable constraints using biases computed from the gradient of the constraint. They rely on discrete gradient based sampling, which can also be interpreted as applying a Taylor approximation to the log density of the target distribution (in this case, the constraint) [3]. They also perform experiments on sentiment control, language detoxification, and topic control. The experiments presented in SCoNE are arguably more thorough and larger scale (DAB focuses on GPT2 size models, but SCoNE examines performance on LLama), but it would at least be worth mentioning this work, discussing the divergent motivations, and how SCoNE compares. While this work definitely does include larger scale experiments and has a slightly different experimental setup (and I prefer SCONE's experimental design), it would be at least worth discussing.\n\n[1] Exposing the Implicit Energy Networks Behind Masked Language Models via Metropolis-Hastings. Goyal et al. ICLR 2022.\n\n[2] Controlled LLM Decoding via Discrete Auto-regressive Biasing. Pynadath, Zhang. ICLR 2025. \n\n[3] A Langevin-like Sampler for Discrete Distributions. Zhang et al. ICML 2022."}, "questions": {"value": "1. What is the actual benefit over “exact inference of approximate distribution” v.s “approximate inference with exact distribution”? \n\n\n2. What is the motivation behind this method? What is the problem that this method identifies with prior approaches, and how does it fix this?  It is mentioned that SMC deals require a lot of samples, and BON doesn’t factor in constraints during generation, but EBM based approaches do both. What is the insight that I should take away from reading this paper regarding controllable generation?\n\n\n3. How are incompatible vocabularies handled? Does ModernBERT MLM / classifier use the same tokenizer as Llama? \n\n\n4. What are the perplexities when sampling the base models using top-k of 10, which is the default for SCoNE? If scone uses a top-k of 10, then the natural baseline perplexity would be when sampling the AR model using top-k of 10. \n\n\n5. (This is not a critique, I am asking purely out of interest) If the algorithm design hinges on having access to marginals for each position, which requires bidirectional attention, why choose a base model to be autoregressive? It feels that this algorithm would be much more natural to apply on masked diffusion language models, like LLada or Dream? These would circumvent the problem with the autoregressive factorization, remove the need for computing expectations using a different model's probability, and perhaps simplify some of the algorithm. How would the algorithm need to change — would it increase or decrease the complexity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PYwU68WUXk", "forum": "zVOgqaR261", "replyto": "zVOgqaR261", "signatures": ["ICLR.cc/2026/Conference/Submission23792/Reviewer_yLkE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23792/Reviewer_yLkE"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23792/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762012665991, "cdate": 1762012665991, "tmdate": 1762942808510, "mdate": 1762942808510, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}