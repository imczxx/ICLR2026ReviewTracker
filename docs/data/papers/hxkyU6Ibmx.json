{"id": "hxkyU6Ibmx", "number": 18488, "cdate": 1758288195028, "mdate": 1762949689599, "content": {"title": "ChatRearrange: Learning Text-guided 3D Scene Rearrangement", "abstract": "In this paper, we propose ChatRearrange, a novel framework for the text-guided 3D scene rearrangement task. Instructing an algorithm with a text description to rearrange 3D furniture objects remains an unsolved problem in the 3D field. Unfortunately, developing algorithms to address this problem presents two critical challenges. First, we lack appropriate text-labeled scene data for the training procedure. Second, evaluating performance is challenging due to the absence of appropriate benchmarks. To address the first issue, we propose the ChatRearrange framework, which includes an LLM-based Inverse Distillation algorithm, enabling ChatRearrange to train without description-labeled scene data. Additionally, we incorporate a novel gradient-field-based student network to learn the text-3D knowledge from the LLM. For the second challenge, we benchmark the text-guided 3D scene rearrangement task by proposing a new dataset called TextRoom. We also include various metrics for the evaluation. The results show that our algorithm outperforms other baselines by a large margin. We are committed to releasing all the code and dataset if the paper is accepted.", "tldr": "We propose a novel framework called ChatRearrange to achieve the goal of rearranging a messy room based on a text description.", "keywords": ["3D Vision", "LLM", "Chain-of-Thought"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/c879bb0854e3c371b6a5abd02cce6e5dfd501c98.pdf", "supplementary_material": "/attachment/af443f72adea0be09ef2b384b8f0d4a9f857bbe6.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces ChatRearrange, a novel framework designed to rearrange 3D furniture objects within a scene according to a natural language text prompt. This paper proposes an LLM-based Inverse Distillation (LID) pipeline. Instead of labeling messy scenes with text, this method starts with well-arranged ground-truth scenes and uses an LLM to generate corresponding natural text descriptions. This process is guided by a 3D Scene Chain-of-Thought (3DSCoT) technique to ensure high-quality text."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. The paper tackles a well-defined, practical, and challenging task. Text-guided rearrangement has clear applications in robotics and design , and the paper does a good job of differentiating it from related tasks like scene generation or unconditional rearrangement.\n\n2. The core challenge for this task is the lack of labeled data. The proposed \"inverse distillation\" is a good solution. Generating text from existing high-quality scenes is more scalable than trying to manually create (messy scene, text prompt, clean scene) triplets. The use of 3DSCoT to refine rule-based descriptions into natural language is a solid contribution.\n\n3. The choice of a score-based generative model (Gradient-Field Learning) is well-suited for this conditional generation task. Using a GNN to model the inter-object spatial relationships is a very natural fit, as rearrangement is fundamentally about these relationships (e.g., \"bed between nightstands\")."}, "weaknesses": {"value": "1. The primary weakness is the choice of baselines. The paper compares ChatRearrange against large language models (GPT-4o, Gemini, etc.). However, these are general-purpose text models, not specialized 3D geometry models. The paper itself argues (and shows) they are bad at this task. A much stronger comparison would have been against other 3D rearrangement methods (like LEGO-Net , mentioned in the related work ) adapted for text-conditioning. The paper dismisses these as not being text-conditioned  but doesn't attempt to create a stronger baseline by, for example, conditioning their latent space on the BERT text embedding. This makes the comparison not very solid.\n\n2. The examples provided are relatively simple, involving a small number of objects (e.g., a bed, two nightstands, a wardrobe). It is unclear how the method would scale to more complex scenes with many objects or more complex, compositional text prompts (e.g., \"Put the desk by the window, place the chair in front of it, and arrange the three bookshelves along the opposite wall\")."}, "questions": {"value": "1. The paper is vague on how the LLM baselines (GPT-4o, Gemini) were made to perform this task. How was the 3D scene represented as input, and how were 3D coordinates/transformations decoded from their text output? This detail is critical for understanding and reproducing the comparisons in Table 1.\n\n2. Could the authors provide an ablation study that trains the TRGF model only on the 319 human-labeled TextRoom samples? This would directly quantify the value and necessity of the 11,166-sample synthetic dataset generated by LID."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yeXMgVfXcu", "forum": "hxkyU6Ibmx", "replyto": "hxkyU6Ibmx", "signatures": ["ICLR.cc/2026/Conference/Submission18488/Reviewer_TPLT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18488/Reviewer_TPLT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18488/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761452995005, "cdate": 1761452995005, "tmdate": 1762928183212, "mdate": 1762928183212, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "N6K7rvj3Xm", "forum": "hxkyU6Ibmx", "replyto": "hxkyU6Ibmx", "signatures": ["ICLR.cc/2026/Conference/Submission18488/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18488/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762949688591, "cdate": 1762949688591, "tmdate": 1762949688591, "mdate": 1762949688591, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ChatRearrange, a pipeline for text-guided 3D scene rearrangement. It tackles the lack of text-labeled training data via an LLM-based Inverse Distillation (LID) procedure that converts ground-truth object layouts into natural language using rule-based relation extraction plus a “3D Scene Chain-of-Thought” prompt. A Text-guided Rearranger with Gradient-Field Learning (TRGF) then learns a conditional score over object transformations given objects and text. The authors also introduce TextRoom and a Text-Scene-Matching Score (TSMS) that converts layouts back to text with GPT-4o and measures cosine similarity with Sentence-BERT. They report 11,166 synthetic training pairs and strong gains over LLM baselines on FID/KID/EMD/TSMS."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. LID is a reasonable twist on distillation (inverse mapping Text≈f̃(U,O)) and is clearly motivated.\n2. Conditional gradient-field over transformations with a GNN is technically sound and fits multi-object constraints."}, "weaknesses": {"value": "1. Baselines are weakly matched: Main comparisons are to general-purpose LLMs prompted to place furniture (Qwen, GPT-4o, Gemini, DeepSeek). Other existing text-to-3D-layout baselines like InstructScene, EchoScene, LayoutGPT, and LayoutVLM are not included in the paper.\n2. Lack of related works: Some recent related works that focus on scene synthesis and rearrangement are not discussed, especially for those works that also used GNN-based methods for scene layout generation, like InstructScene and EchoScene.\n3. Limited test size/scope: TextRoom has only 319 scenes from 3D-FRONT; it’s unclear how diverse the prompts are, whether rooms/categories overlap with training, and whether generalization holds for other room types or open-vocabulary objects.\n4. Missing implementation detail for reproducibility. The paper omits many specifics: GNN architecture/topology, noise schedule, σ_t, λ(t), PointNet/BERT variants and dims, relation rule thresholds, and collision/overlap handling.\n5. Circularity of the TSMS Metric: TSMS converts layouts back to text with GPT-4o and then compares to the input via Sentence-BERT; this risks style leakage (training text is also produced with an LLM after a rule stage) and couples evaluation quality to a black-box vendor model. Human judgments or relation-level precision/recall would strengthen claims."}, "questions": {"value": "1. Can the authors provide more detail on the \"Rule-based Relation Understanding\" module? What specific spatial predicates (e.g., \"left of,\" \"behind\") are supported? How does it handle relationships between more than two objects, or more abstract/non-axial concepts?\n2. Can you adapt text-to-layout methods to your setting and compare?\n3. Why BERT over vision-language encoders (e.g., CLIP-style) for text? Did you try instruction-tuned text encoders?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VXBAoZf2J5", "forum": "hxkyU6Ibmx", "replyto": "hxkyU6Ibmx", "signatures": ["ICLR.cc/2026/Conference/Submission18488/Reviewer_ECZi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18488/Reviewer_ECZi"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18488/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761716903138, "cdate": 1761716903138, "tmdate": 1762928182379, "mdate": 1762928182379, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ChatRearrange, a framework for the text-guided 3D scene rearrangement task. It aims to address the lack of text-labeled training data and the absence of evaluation benchmarks by introducing an LLM-based Inverse Distillation (LID) algorithm to generate training data and a Gradient-Field-based student network (TRGF) to learn spatial relationships."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This paper presents a new benchmark dataset, TextRoom, and a new evaluation metric, TSMS, for semantic alignment. The idea of ChatRearrange demonstrates improved control over text-conditioned scene rearrangement."}, "weaknesses": {"value": "1. The first motivation presented in the paper, i.e., “the lack of text-labeled scene data” is not convincing. Utilizing Vision-Language Models (VLMs) to generate object-level textual annotations is a well-explored direction in the literature, and several works such as InstrcutScene have successfully demonstrated this. The claim that this is a major obstacle does not hold, and the motivation for the proposed method is not sufficiently convincing.\n\n2. The proposed method employs a score-matching objective, which is closely related to diffusion models. However, the authors do not compare their approach with any existing diffusion-based scene generation or rearrangement methods. Given the similarity in formulation, this omission significantly weakens the contextualization of the proposed method within the broader generative modeling landscape.\n\n3. The role of 3DSCoT is unclear. Intuitively, transforming hard-coded spatial relationships into natural language descriptions does not require a Chain-of-Thought (CoT) mechanism. The authors introduce 3D Scene Chain-of-Thought (3DSCoT) without providing sufficient details or justification. The necessity and contribution of this component are unclear, and its implementation is also not adequately explained.\n\n4. The proposed model does not clearly embody the concept of a \"student\" network in the traditional knowledge distillation sense. Instead, it appears to learn spatial and relational priors directly from the dataset. However, the dataset itself is not sufficiently described, e.g., its structure, statistics, and how it supports the learning of these priors are largely omitted, making it difficult to assess the validity of this approach.\n\n5. Although the authors claim to introduce a new dataset (TextRoom) for evaluation, the paper provides minimal information about its construction, annotation process, or diversity. At the same time, there is also no explanation of how this dataset is used as a benchmark to validate model performance."}, "questions": {"value": "In the problem formulation section Line218-228, the authors define the input as object set O and the goal as predicting transformations U. However, the variable Y, which presumably represents the text labels or descriptions, is introduced without a clear definition or role in the formulation. This omission creates confusion about the exact learning objective and weakens the clarity of the proposed framework."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nmnDsPYv6p", "forum": "hxkyU6Ibmx", "replyto": "hxkyU6Ibmx", "signatures": ["ICLR.cc/2026/Conference/Submission18488/Reviewer_q1VC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18488/Reviewer_q1VC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18488/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986635929, "cdate": 1761986635929, "tmdate": 1762928179721, "mdate": 1762928179721, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ChatRearrange, a novel framework for text-guided 3D scene rearrangement using LLM-based Inverse Distillation and gradient-field learning. It trains without human-annotated text descriptions and introduces the TextRoom benchmark with 319 labeled scenes. Experimental results demonstrate superior performance over LLM baselines across all metrics."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well written and easy to follow.\n\n2. The proposed dataset could be helpful to some domains (e.g. 3D object detection, 3D generation/understanding)."}, "weaknesses": {"value": "1. The novelty is limited. The pipeline combines established techniques. \n\n2. The experiment is limited. It only compares LLM-based methods. The paper lacks comparisons with existing learning-based approaches for scene rearrangement or layout generation, such as LEGO-Net, diffusion-based scene synthesis methods, or other neural architecture designs. Without these comparisons, it is difficult to assess whether the proposed gradient-field GNN architecture provides advantages over alternative learning-based designs.\n\n3. The proposed metric TSMS relies on GPT-4o to convert layouts back to text, then uses Sentence-BERT for similarity. This creates circular dependency: using an LLM to evaluate what was generated using LLM distillation."}, "questions": {"value": "Is there any error during LLM labeling? If yes, how do you handle it?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "T80pTicMhr", "forum": "hxkyU6Ibmx", "replyto": "hxkyU6Ibmx", "signatures": ["ICLR.cc/2026/Conference/Submission18488/Reviewer_zrXR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18488/Reviewer_zrXR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18488/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762063954017, "cdate": 1762063954017, "tmdate": 1762928178785, "mdate": 1762928178785, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}