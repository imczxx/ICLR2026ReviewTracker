{"id": "Pjcz6ik78E", "number": 1793, "cdate": 1756931469805, "mdate": 1759898186269, "content": {"title": "Some Neural Networks Inherently Preserve Subspace Clustering Structure", "abstract": "It has long been conjectured and empirically observed that neural networks tend to preserve clustering structure. This paper formalizes this conjecture. Specifically, we establish precise conditions for cluster structure preservation and derive bounds to quantify its extent. Through this analysis we are able to show that certain neural networks are learning parameters that preserve the clustering structure of the original data in their embeddings, without the need to impose mechanisms to promote this behavior. Extensive numerical analysis and experiments validate our results. Our findings offer deeper insight into neural network behavior, explaining why certain data types (such as images, audio, and text) benefit more from deep learning. Beyond theory, our findings guide better initialization, feature encoding, and regularization strategies.", "tldr": "", "keywords": ["Clustering", "Subspace", "Neural Networks", "Activation Functions", "Preserving Structure"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cc8929a32b860ae0241e91f8df591212bd172ac7.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper theoretically investigates the ability of certain neural networks to preserve subspace clustering structures and formalizes this conjecture using empirical research."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper offers a novel perspective, connecting the empirical success of neural networks to the classical theory of subspace clustering.\n2. The writing is generally clear. The proofs are well-structured and convey the core ideas.\n3. The experimental design is comprehensive, progressing from synthetic data to diverse real-world datasets, supporting the arguments.\n4. It provides a viable explanation for the effectiveness of deep learning on data with inherent clustering structure."}, "weaknesses": {"value": "1. The theoretical extension from single-layer to multi-layer networks is overly simplified. Section 6 claims to extend the results to multi-layer networks, but this is not fully elaborated.\n2. The paper states that CNNs/Transformers achieve high accuracy without maintaining the original structure. It is worth exploring in depth the circumstances under which maintaining the original structure is preferable to reconstructing a new one.\n3. The paper does not clearly specify the specific loss function and architectural details used for training the neural network."}, "questions": {"value": "1. What specific training objectives did you use in the deep network, LSTM, and real-data experiments in Sections 6, 7, and 8? Was it autoencoders and mean squared error loss, or something else?\n2. For the multi-layer extension in Section 6, can it provide a rigorous mathematical formulation or derivation of how Theorem 3.1 applies to $L$ layers via the joint bound? What is the resulting total error bound, and what requirements does it impose on the error $\\epsilon_\\ell$ for each layer?\n3. The theory assumes additive noise Z. Has the conclusion been explored for more complex, non-additive, or data-dependent noise?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zzDkGTReXD", "forum": "Pjcz6ik78E", "replyto": "Pjcz6ik78E", "signatures": ["ICLR.cc/2026/Conference/Submission1793/Reviewer_fY3w"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1793/Reviewer_fY3w"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1793/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761722972584, "cdate": 1761722972584, "tmdate": 1762915892072, "mdate": 1762915892072, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper attempts to develop theoretical understanding on the observation of some neural networks preserving clustering structure, in which precise conditions for clustering structure preserving is provided. Some theoretical results are developed to bound the gap beween the projected differences between the clean data, transformed data and the output data after one-layer transform. Moreover, numerical analysis and empirical evaluation on real world data are shown, with some explaination and discussions."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "+ It is appealing to investigate the observation of clustering structure preserving with some theoretical justification."}, "weaknesses": {"value": "1. The mathematical analysis in the paper is confusing. Symbols used in proofs are not clearly defined or without any interpretation. For example, the norm of the matrix, $\\| Z\\|$ and $\\| Z \\|_\\infty$ are not clearly defined, $\\sin (\\Theta)$ is not clearly defined. Even worse, the projection $P$ and $W$ are also not clear.   \n\n2. The derivations in the proofs are incorrect. \n- For example, in the proof of Lemma 4.1, the third equality seems incorrect. How to build the equality from a trace of the two projected matrix to the squared Frobenius norm of them? \n- In the proof of Lemma 4.2, the reviewer cannot see how \"plugging this and (5) in (6) we obtain the lemma.\" The reviewer cannot obtain the result in Lemma 4.2. The proof for Lemma 4.2 are wrong.  Moreover, for the matrix $W$, it is weight matrix, without any implicit assumption on the rank (if not specially claimed). \n\n3. Regarding to Theorem: It is not clear how the condition of $\\delta_1$ which is defined as the singular value gap of $X$ and $X^\\ast$ is actually used. \n\n4. The empirical evaluations are insufficient and incomplete. How the neural networks are trained actually? Which loss function is used? Are the empirical results obtained from the synthetic data generalizable in a broad sense, or it is just because of the special structure of the synthetic data? The way to generate the synthetic data is to form a set of nearly orthogonal subspaces. \n\n5. Is the initialization of $W$ reasonable? What happens if $W$ is initialized with an iid Gaussian of zero mean and variance of $1/m$? From the viewpoint of the reviewer, it is more natural and making sense, or even with nice property.  Why initialize $W$ with i.i.d. uniform entries in the range of $(- \\sqrt(m), \\sqrt(m))$? \n\n6. The worse results in Fig.2 (right panel) are not clearly interpreted.  In Fig. 5, why CNN and Transformers are failed to preserve the clustering structure? How the clustering accuracy is obtained in Fig.4?  \n\n7. Minor issues: \n- The format for the citation in some places seems not properly used.\n- The first three paragraphs of the introduction read like generated automatically via a LLM. Some contents are not factual."}, "questions": {"value": "Please read the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5Je11Hlfie", "forum": "Pjcz6ik78E", "replyto": "Pjcz6ik78E", "signatures": ["ICLR.cc/2026/Conference/Submission1793/Reviewer_R2m9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1793/Reviewer_R2m9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1793/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761760227240, "cdate": 1761760227240, "tmdate": 1762915891919, "mdate": 1762915891919, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a theoretical analysis of when neural networks preserve clustering structure under a union of subspaces (UoS) model. It derives conditions ensuring that a networkâ€™s learned representations retain the subspace structure of clean data, even when inputs are noisy. Through a perturbation analysis, the authors show that the row space of the learned representation closely matches that of the original data. Experiments support the theory, revealing that certain networks naturally maintain clustering structure, offering insights into initialization, feature encoding, and regularization."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper fills a theoretical gap by analysing the clustering behaviour of neural networks using subspace clustering and perturbation theory, offering a proof for a long-standing empirical intuition.\n- Synthetic experiments demonstrate that gradient descent naturally enforces the theoretical condition without explicit regularisation.\n- Provides insights for neural network design decisions, like initialisation"}, "weaknesses": {"value": "- The UoS model and large spectral-gap condition may not hold in realistic settings\n- The paper relies only on projection-distance measures; evaluating standard clustering metrics (e.g., NMI, ARI) could show how clustering performance is linked to the network architecture and behaviour of projection-distances. \n- The paper only briefly discusses that breaking subspace clustering structure, as seen in CNNs and Transformers, may actually contribute to their strong empirical performance. I found this insight actually very interesting, as these architectures are more commonly used in practice than MLPs."}, "questions": {"value": "- How is the final clustering performance measured w.r.t. to the ground truth (e.g., with ACC, NMI or ARI) of a network linked to its preservation of subspace clustering structure? I imagine that clustering performance of CNN's or Transformers would generally be higher than the performance of MLPs\n- In the paper you mention: \"The large projection distances exhibited by Transformers and CNNs show that these networks are clustering through some mechanism other than the closed-form solution, and such mechanism does not preserve the original clustering structure.\" Could you elaborate on this? This is a very interesting insight, and I would be curious to see a more in depth discussion in the paper on this point."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DjcZcni1Jn", "forum": "Pjcz6ik78E", "replyto": "Pjcz6ik78E", "signatures": ["ICLR.cc/2026/Conference/Submission1793/Reviewer_QkDR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1793/Reviewer_QkDR"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1793/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988506393, "cdate": 1761988506393, "tmdate": 1762915891755, "mdate": 1762915891755, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}