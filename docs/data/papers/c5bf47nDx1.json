{"id": "c5bf47nDx1", "number": 5191, "cdate": 1757863450389, "mdate": 1763637748605, "content": {"title": "Expanding the Capability Frontier of LLM Agents with ZPD-Guided Data Synthesis", "abstract": "Unlocking advanced reasoning in large language model agents is hindered by a scarcity of training data situated at the very frontier of their capabilities. We address this with a novel data synthesis approach inspired by the educational theory of the Zone of Proximal Development (ZPD), which conceptualizes this frontier as tasks an LLM cannot solve independently but can master with guidance. We operationalize this principle through the AgentFrontier Data Engine, an automated pipeline that synthesizes high-quality, multidisciplinary data situated precisely within an LLM's ZPD. The engine yields two synergistic outputs: knowledge-intensive data for continued pre-training and frontier-level reasoning trajectories for post-training. Concurrently, it produces the ZPD Exam, a self-evolving benchmark for evaluating agent capabilities by compelling them to reason beyond their parameterized knowledge. By training our AgentFrontier-30B-A3B model on the synthesized data, we achieve state-of-the-art results on demanding benchmarks like Humanity's Last Exam, outperforming several leading proprietary agents. This work establishes ZPD-guided data synthesis as a scalable and effective paradigm for cultivating increasingly capable LLM agents.", "tldr": "We introduce a ZPD-inspired data synthesis engine that co-generates frontier reasoning trajectories and a self-evolving benchmark (the ZPD Exam), enabling a 30B LLM to achieve state-of-the-art on expert-level tasks.", "keywords": ["data synthesis", "multidisciplinary benchmark", "LLM agents"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/dd7a24a4de5e9dc4760d914d360c4052ac68e4f4.pdf", "supplementary_material": "/attachment/f673c44c122ee6c46bddce9b60e33a0ba95abc75.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces a novel framework for data synthesis and evaluation guided by the Zone of Proximal Development (ZPD) principle from educational psychology. The authors propose the AgentFrontier Engine, a multi-agent pipeline that automatically generates, refines, and filters reasoning tasks that lie just beyond a model’s current competence but within its learnable range. By distinguishing between what a base model (LKP) can solve independently and what a stronger agent (MKO) can solve with tools, the framework creates a dynamic “ZPD dataset” that pushes model capabilities systematically. The paper also presents ZPD Exam, an evolving benchmark derived from these tasks. Experiments on Qwen and other models demonstrate significant performance gains across reasoning and tool-augmented benchmarks, suggesting that ZPD-guided synthesis effectively expands model reasoning frontiers."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "This paper introduces a compelling theoretical grounding (ZPD) for guiding data generation, a fresh and rigorous way to define model capability boundaries. The model trained with the data generated by the designed pipline outputperfom state-of-the-art results on\ndemanding benchmarks. The authors denote that their data and model will be public, which should be a great source to advance the deep research ability of public models. Overall, I think this is a good paper."}, "weaknesses": {"value": "1. The paper lack analysis on how to config the MKO and LKP.\n2. Whlst the paper says \"ZPD-guided synthesis continually redefines the capability frontier based on the model’s evolving competence\", the pipline to generate the data is complicated and might not easy to implement."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HoJP86On4B", "forum": "c5bf47nDx1", "replyto": "c5bf47nDx1", "signatures": ["ICLR.cc/2026/Conference/Submission5191/Reviewer_eHCL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5191/Reviewer_eHCL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5191/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761334789321, "cdate": 1761334789321, "tmdate": 1762917937403, "mdate": 1762917937403, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work presents a novel data synthesis framework grounded in the Zone of Proximal Development (ZPD). It targets tasks at the frontier of a model’s ability: those that the base model fails at alone but that a stronger, tool-using agent can solve.The framework produces a targeted training dataset and living benchmark to enhance and evaluate agentic reasoning. Training on this dataset boosts performance on various agentic benchmarks and enhances tool use."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1) The work offers a clear rule to select data (i.e. when LKP fails in all N=3 unaided attempts while the MKO succeeds). The work validates the approach with experiments.   \n2) A self-evolving benchmark seems useful, especially given the rate of saturation of existing static benchmarks."}, "weaknesses": {"value": "1) The paper uses just one LKP/MKO pair with LKP=deepseek-r1 and MKO=deepseek-v3.1+tools (apologies if I am mistaken). Thus, it is unclear how general the results are under different LKP and/or MKO.  \n2) The paper attributes observed gains to ZPD-calibration strategy, but doesn’t directly verify the mechanism. It might be helpful to ablate the calibration policy (ie one could plasibly show how heuristic of random selection compares to the ZPD-calibration). Additionally, it would be nice to see how sensitive the overall framework is to e.g., BoN N and to redundancy threshold $\\epsilon$."}, "questions": {"value": "1) How do results change if you swap the LKP for a different model? Or if you use LKO+tools as the MKO instead of a strictly stronger model?\n2) How sensitive are the results to BoN N and to the redundancy threshold $\\epsilon$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "aoKG6TgFak", "forum": "c5bf47nDx1", "replyto": "c5bf47nDx1", "signatures": ["ICLR.cc/2026/Conference/Submission5191/Reviewer_9U8J"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5191/Reviewer_9U8J"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5191/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761686541720, "cdate": 1761686541720, "tmdate": 1762917937098, "mdate": 1762917937098, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work presents a data synthesis framework aimed at generated synthetic data that is not overly difficulty or overly easy for models during training, an associated benchmark, and results on continued pretraining and posttraining of an open-weight model."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Overall, I found the method described in the paper to be interesting and a valuable contribution. Notably:\n- the proposed method seems to work reasonably well, compared to other available datasets for the tested models\n- the dataset baselines are reasonable, comparing to 3 other available training datasets. \n- Section 5's analysis is interesting, as you'd expect ample best-of-N gains given the training data generation method, and that's what you see, which is a good verification."}, "weaknesses": {"value": "- The proposed method should scale to other domains, but the provided results are only on QA settings single-turn settings?  \n- There's a risk that the LLM-based difficulty refinement leads to lack of diversity in how the questions are difficult (for e.g. one failure mode could be that all questions are difficult because they involving chaining questions together or are difficult in unrealistic ways). This is not addressed by the reranking-based filtering as that corrects for semantic diversity issues. It would be good to see some analysis on this. \n- There is no baseline for no-finetuning, which would be useful to contextualize the gains. \n- It does seem that the ZPD exam and the Stage 2 and 3 refining and filtering are likely very sensitive to the specific LLM's capability profiles (in this case, Deepseek R1 and V3.1). I'm curious if that's why V3.1 performs nearly identically to the trained model in ZPD. \n- ZPD seems not that useful to evaluate tasks that models find moderately difficult with tools. As agentic tasks become more valuable to train for, this seems like it would be increasingly more useful to evaluate."}, "questions": {"value": "1. How does escalation in Stage 2 actually happen? Is there a prompt provided?\n2. How sensitive is the filtering and calibration to the specific LLMs chosen (Deepseek R1 vs V3.1).\n3. Was the automated grading in ZPD manually verified in a small sample?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "roKMUwJVAb", "forum": "c5bf47nDx1", "replyto": "c5bf47nDx1", "signatures": ["ICLR.cc/2026/Conference/Submission5191/Reviewer_PuhY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5191/Reviewer_PuhY"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5191/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761789267314, "cdate": 1761789267314, "tmdate": 1762917936873, "mdate": 1762917936873, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the AgentFrontier Data Engine, a process for generating samples for continued pre-training and reinforcement fine-tuning datasets. Inspired by the educational theory of the Zone of Proximal Development (ZPD), the main idea behind the data generating process is to use a pair of agents/personas--one relying entirely on parametric knowledge and the other equipped with a set of knowledge retrieval tools--to identify Q/A pairs that are reliably answered incorrectly by the base model but are within reach when allowed to act more agentically. This process is used to generate the ZPD exam, a training dataset that elicits at-or-near-frontier performance from Qwen3 models."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Originality: Not clear that this is very original. I think we're essentially looking at context distillation with some ZPD trappings.\n\nQuality: I think my major concern is about the quality of the dataset. The paper mentions that samples that the MKO can't solve are flagged for human review, but no details of the human review process are provided. With an entirely LLM-generated dataset, human review and validation seems necessary. Comparison against both open- and closed-source models is good.\n\nClarity: the description of the process is clear. The results are presented well, though the graphs are misleading (using bar graphs, the y axis should start at 0) and there are no confidence intervals.\n\nSignificance: I'm definitely not an expert in the training data synthesis literature and active practices, but I'm guessing this is either more of the same or a marginal contribution to the frontier tool-belt."}, "weaknesses": {"value": "See strengths, wrote them together"}, "questions": {"value": "1. Can you please describe the review process for Dhuman?\n2. What other human review was done?\n3. What types of errors do the models continue to make after training on ZPD Exam, and what types of failures are trained away?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "21PzJglkKd", "forum": "c5bf47nDx1", "replyto": "c5bf47nDx1", "signatures": ["ICLR.cc/2026/Conference/Submission5191/Reviewer_7KJK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5191/Reviewer_7KJK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5191/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762254509650, "cdate": 1762254509650, "tmdate": 1762917936620, "mdate": 1762917936620, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "Dear Reviewers,\n\nWe would like to extend our sincerest gratitude to all of you for your valuable time and dedicated effort in reviewing our manuscript. We deeply appreciate your insightful comments and constructive suggestions, which have been instrumental in helping us improve the quality of our work.\n\nWe have carefully considered all the points you raised and have provided a detailed **point-by-point response** to each of your comments below. To facilitate your reviews of the revised manuscript, we have highlighted all major revisions and the results of newly added experiments **in blue**.\n\nWe believe these revisions have substantially strengthened our paper and addressed your concerns. We look forward to your feedback and would be delighted to engage in further discussion.\n\nThank you once again for your thoughtful reviews.\n\n\nBest regards,\n\nSubmission5191 Authors"}}, "id": "ZeuasvYB40", "forum": "c5bf47nDx1", "replyto": "c5bf47nDx1", "signatures": ["ICLR.cc/2026/Conference/Submission5191/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5191/Authors"], "number": 11, "invitations": ["ICLR.cc/2026/Conference/Submission5191/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763637771067, "cdate": 1763637771067, "tmdate": 1763637771067, "mdate": 1763637771067, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "Dear Reviewers,\n\nWe would like to extend our sincerest gratitude to all of you for your valuable time and dedicated effort in reviewing our manuscript. We deeply appreciate your insightful comments and constructive suggestions, which have been instrumental in helping us improve the quality of our work.\n\nWe have carefully considered all the points you raised and have provided a detailed **point-by-point response** to each of your comments below. To facilitate your reviews of the revised manuscript, we have highlighted all major revisions and the results of newly added experiments **in blue**.\n\nWe believe these revisions have substantially strengthened our paper and addressed your concerns. We look forward to your feedback and would be delighted to engage in further discussion.\n\nThank you once again for your thoughtful reviews.\n\n\nBest regards,\n\nSubmission5191 Authors"}, "title": {"value": "With Thanks to the Reviewers: Response to Comments on Submission #5191"}}, "id": "ZeuasvYB40", "forum": "c5bf47nDx1", "replyto": "c5bf47nDx1", "signatures": ["ICLR.cc/2026/Conference/Submission5191/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5191/Authors"], "number": 11, "invitations": ["ICLR.cc/2026/Conference/Submission5191/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763637771067, "cdate": 1763637771067, "tmdate": 1763716248970, "mdate": 1763716248970, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}