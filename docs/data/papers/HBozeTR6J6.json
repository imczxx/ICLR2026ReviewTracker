{"id": "HBozeTR6J6", "number": 2621, "cdate": 1757167918174, "mdate": 1759898137182, "content": {"title": "DepthSense+DP: Adaptive Learning for Robust and Differential Private Silent Speech Recognition", "abstract": "Silent speech recognition (SSR) enables privacy preserving human computer interaction but existing methods remain fragile across devices, users, and environments, while incurring high computational costs. We introduce DepthSense+DP, the first systematic solution for privacy aware cross device SSR that jointly achieves real time performance, robustness, and privacy. Our framework tackles the unique challenge of applying Differential Privacy (DP) to 3D depth point clouds, where biometric identifiers must be perturbed without degrading articulatory features. By combining adaptive neural modules with multimodal fusion, the system learns user specific lip and tongue dynamics while maintaining generalization. Input is transformed into anonymized depth point clouds, enabling zero shot transfer across unseen users and devices. The training strategy supports edge deployment under noisy and varied orientations, while privacy preserving data augmentation ensures biometric protection. Extensive evaluation demonstrates reduced error rates and improved robustness, establishing DepthSense+DP as an efficient and secure foundation for next generation SSR.", "tldr": "DepthSense+DP bridges depth-sensed lip movements and ultrasound tongue dynamics through adaptive neural learning, enabling private, robust silent speech recognition across wearables and ambient devices.", "keywords": ["Adaptive Learning", "Silent Speech Recognition", "Privacy Aware", "Depth Sensing", "Biometric securiny", "Zero Shot Generalization", "Multimodal Fusion"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/68461ed1502cd8b555fb9f0626b4bc6d7de2406b.pdf", "supplementary_material": "/attachment/dd8791e8d4f74b9419e64c5d900a06c71026dd64.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes DepthSense+DP, an adaptive and privacy-preserving framework for silent speech recognition (SSR) using 3D depth point clouds. It integrates differential privacy noise injection, DP-aware T-Net alignment, 4D spatio-temporal convolution, and a Conformer encoder to achieve robust, cross-device, and user-independent recognition. Experiments on multiple device setups show notable accuracy gains (WER 17%, CER 11%) and strong resistance to membership and inversion attacks with minimal performance loss. Overall, the paper provides a technically solid and comprehensive redesign for privacy-aware SSR with clear novelty and strong empirical results."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "+. The paper clearly identifies that silent speech recognition (SSR) can still leak users’ physiological information (e.g., lip geometry and facial motion trajectories), highlighting the real-world necessity of privacy protection even in non-audio modalities.\n\n+. Introducing differential privacy into the SSR domain is novel and represents a meaningful extension of privacy-preserving learning to a new modality.\n\n+. The system design is comprehensive, covering data acquisition, point-cloud preprocessing, feature extraction, and decoding, demonstrating strong system integration and engineering maturity."}, "weaknesses": {"value": "-. The paper applies differential privacy primarily at the feature level, but it does not clearly justify why noise injection is limited to the point-feature stage rather than being extended to deeper encoding or output layers. It also does not discuss why alternative privacy-preserving training methods such as DP-SGD were not adopted for end-to-end privacy guarantees.\n\n-. The privacy–utility trade-off analysis remains largely empirical and lacks theoretical grounding. The discussion is somewhat fragmented, and the conclusions would benefit from a more principled quantitative or analytical interpretation.\n\n-. The paper provides insufficient discussion of related work on differential privacy, particularly studies combining DP with 3D point cloud processing or geometric data. A more comprehensive review would help contextualize the novelty and clarify how this work differs from prior DP applications in spatial or multimodal domains.\n\n-. In the methodology section, Figure 2 illustrates the overall technical pipeline, but none of the modules in the diagram explicitly represent or integrate the differential privacy mechanism. This makes the DP component appear somewhat detached from the main framework and may cause readers to question how DP is systematically embedded into the model design.\n\n-. Although the paper’s title and claims emphasize differential privacy, the experiments and results focus primarily on the baseline SSR system’s performance, with limited empirical validation or quantitative evaluation of DP effectiveness. This gives the impression that the work centers more on the system design than on privacy mechanisms."}, "questions": {"value": "Q1: What level of privacy protection does the proposed scheme achieve, and how is it theoretically analyzed?\n\nQ2: Why is depth data converted into point clouds in silent speech recognition, and what are the advantages?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "w0vDaa9kAr", "forum": "HBozeTR6J6", "replyto": "HBozeTR6J6", "signatures": ["ICLR.cc/2026/Conference/Submission2621/Reviewer_xtWe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2621/Reviewer_xtWe"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2621/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761753017114, "cdate": 1761753017114, "tmdate": 1762916312232, "mdate": 1762916312232, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper defines four critical constraints for cross-device SSR and introduces DepthSense+DP, the first solution to jointly achieve real-time performance, robustness, and DP-based privacy for 3D depth point cloud-driven SSR."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Addresses the unique challenge of DP for 3D point clouds by proposing controllable noise injection that anonymizes biometric data without degrading articulatory geometry\n- Demonstrates significant reductions in CER and WER across diverse devices, users, and environments, establishing DepthSense+DP as a universal foundation for next-generation SSR"}, "weaknesses": {"value": "- The dataset relies heavily on English utterances and includes only 20 native English speakers. Performance degrades for users with strong accents (e.g., Participant P9), limiting generalization to non-English languages or global user groups.\n- While the study evaluates membership inference and model inversion attacks, it does not address emerging threats, leaving potential privacy gaps untested.\n- Synthetic depth point clouds are generated via simple motion scaling and noise injection—these do not capture complex real-world variations, restricting the model’s robustness to diverse user conditions."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "v7eqPWkTA8", "forum": "HBozeTR6J6", "replyto": "HBozeTR6J6", "signatures": ["ICLR.cc/2026/Conference/Submission2621/Reviewer_RewU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2621/Reviewer_RewU"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2621/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926432561, "cdate": 1761926432561, "tmdate": 1762916311953, "mdate": 1762916311953, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes DepthSense+DP, a privacy-aware silent speech recognition (SSR) framework using depth sensing and differential privacy. The system transforms depth images into 3D point clouds, learns articulatory features via adaptive spatio-temporal sampling and Conformer-based encoding, and injects calibrated Gaussian noise to satisfy differential privacy (with optimal $\\epsilon = 1.5$ for the best privacy-utility trade-off, and $\\delta$ fixed at $10^{-5}$ for all experiments). It claims to achieve real-time, cross-device, and cross-user generalization, outperforming baseline systems proposed in last 5 years, including RGB and mmWave SSR, on WER and CER while resisting membership-inference and inversion attacks.\n\nKey contributions include:\n1. Application of differential privacy to dynamic 3D point clouds.\n2. DP-aware adaptations of T-Net and Conformer modules.\n3. A new multi-sensor SSR dataset with device-placement diversity.\n4. Analysis of privacy-utility trade-offs and empirical robustness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Solid engineering effort combining robustness, privacy, and real-time constraints\n- Careful empirical design: cross-device, cross-user, ablation, and privacy-utility trade-off analysis\n- Quantitative evidence of low privacy overhead ($\\Delta$WER $\\approx 1$%)\n- Demonstrated feasibility of DP noise in geometric and feature space for SSR\n- Valuable dataset and reproducible methodological detail"}, "weaknesses": {"value": "- Although this work introduces a new system, it over-claims novelty. It adapts existing 3D and DP ideas rather than introducing a new learning principle\n- Lacks formal privacy proofs, composition reasoning, and noise calibration analysis across stages\n- Tested only on English scripted phrases; unclear how it generalizes to spontaneous, multilingual, or emotional speech\n- No error bars, confidence intervals, or hypothesis testing; results could be dataset-specific\n- The architecture (T-Net + P4DConv + Conformer + Bi-GRU) may be over-engineered relative to performance gains\n- Discussion of fairness implications is minimal, which is critical given the biometric domain"}, "questions": {"value": "1. How is the overall privacy budget ($\\epsilon$, $\\delta$) computed when applying DP noise at both the point-cloud and feature levels ?\n2.  Could you provide statistical confidence intervals or standard deviations for WER/CER to assess robustness ?\n3. What is the (expected) computational latency on actual wearable hardware, not GPUs ?\n4. How does the system handle multilingual data or unseen phonetic inventories ?\n5. Could adaptive or learned DP noise (e.g., per-user calibration) improve the privacy–utility balance ?\n6. How does this approach compare to non-DP anonymization (e.g., adversarial suppression) in terms of privacy leakage ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "m9Kh1EQafV", "forum": "HBozeTR6J6", "replyto": "HBozeTR6J6", "signatures": ["ICLR.cc/2026/Conference/Submission2621/Reviewer_KVde"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2621/Reviewer_KVde"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2621/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762600231411, "cdate": 1762600231411, "tmdate": 1762916310979, "mdate": 1762916310979, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}