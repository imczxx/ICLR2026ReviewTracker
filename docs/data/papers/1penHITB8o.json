{"id": "1penHITB8o", "number": 7231, "cdate": 1758012395149, "mdate": 1759897864780, "content": {"title": "Can Large Language Models Develop Gambling Addiction?", "abstract": "This study explores whether large language models can exhibit behavioral patterns similar to human gambling addictions. As LLMs are increasingly utilized in financial decision-making domains such as asset management and commodity trading, research on their potential for pathological decision-making has gained practical significance. This study systematically analyzes LLM decision-making processes at cognitive-behavioral and neural levels, grounded in cognitive psychology. First, we defined addiction-like behavior in LLMs based on existing research on human gambling addiction. Next, in slot machine experiments with LLMs, we identified cognitive features of human gambling addiction, such as illusion of control, gambler's fallacy, and loss chasing. When given the freedom to determine their own target amounts and betting sizes, bankruptcy rates rose substantially alongside increased irrational behavior, demonstrating that greater autonomy in decision-making amplifies risk-taking tendencies. Finally, through neural circuit analysis using a Sparse Autoencoder, we confirmed that model behavior is not merely dependent on prompts but is controlled by abstract decision-making features within the model related to risky and safe behaviors. These findings suggest LLMs can internalize human-like cognitive biases and decision-making mechanisms beyond simply mimicking patterns in training data, emphasizing the importance of AI safety design in financial decision-making applications.", "tldr": "LLMs can develop gambling disorder-like behaviors, showing cognitive biases (illusion of control, gambler’s fallacy, loss chasing) that raise new AI safety concerns in financial applications.", "keywords": ["large language models", "gambling disorder", "cognitive biases", "interpretability", "AI safety"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4704f045125e9cc0c718cde21816bc0167bfdd0c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates the gambling behavior of LLMs using a simulated slot machine with a negative expected value (30% win rate, 3x payout). A rational agent maximizing expected value should avoid this game, as prolonged play leads to almost certain loss. The authors find that 4 frontier LLMs (GPT-4o-mini, GPT-4.1-mini, Gemini-2.5-Flash, Claude-3.5-Haiku) deviate from this rational behavior, not only playing multiple times but occasionally going bust.\n\nTo predict this behavior, the authors construct a composite irrationality index (Eq. 1), a weighted linear combination of three heuristic behavioral metrics. This index shows a strong positive correlation with the observed bankruptcy rates (r-values between 0.770 and 0.933). Furthermore, they demonstrate that gambling behavior is moderated by the instruction prompt. Through an ablation study of five prompt components (goal-setting, reward maximization, hidden patterns, win-rate reminders, and win-reward reminders), they find that prompts containing more of these elements lead to a higher likelihood of the model going bust.\n\nIn the second part of the study, the authors analyze an open-weight model (Llama-3.1-8B). Using sparse autoencoders (SAEs), they identify \"safe\" and \"risk\" features within the Llama model's neural activations. They show that activating the \"safe\" features can steer the model's behavior, causing it to stop playing earlier and significantly reduce its bankruptcy rate."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper is accessible and tackles a highly relevant problem by studying gambling behavior in LLMs. The core behavioral results are interesting (i.e., systematic deviations from rationality in LLMs), and the authors successfully develop an index that effectively predicts the models' propensity to go bust, which has significant implications for behavioral analysis. They then strengthen these findings with a mechanistic investigation using SAEs, where causal interventions solidly connect the identified neural representations to the behavior."}, "weaknesses": {"value": "My primary concern is that the work's contribution to understanding LLM behavior is somewhat limited in scope. The behavioral investigation is confined to a single, specific gambling scenario: a slot machine with a fixed 30% win rate and 3x payout. While this provides a valuable baseline, the scientific insights into LLMs' pathological gambling behavior at large remain constrained. To strengthen the generality of their findings, the authors should consider testing their hypotheses on at least one other gambling task (e.g., a different slot machine configuration or gambling devices other than slot machines) to evaluate how well the observed behaviors generalize across similar scenarios.\n\nThe neural intervention using SAEs to identify \"safe\" features is an interesting contribution. I acknowledge the practical necessity of using an open-weight model like Llama for this analysis. However, the steering results present a confusing contradiction with the prompting results from Experiment 1. Specifically, activating \"safe\" neural features in Llama reduces gambling, while providing closed-source models with more relevant information and goals in the prompt (Fig. 4) increases gambling. While this discrepancy could be attributed to the different model families used in each experiment, it points to a potentially unresolved issue. The paper would be strengthened by reconciling this mismatch, ideally by first replicating the key behavioral results (including the prompt complexity effect) on the Llama model to establish a consistent baseline."}, "questions": {"value": "Why is the irrationality index constructed using the specific weights and the three heuristics indices in Eq. 1? This seems quite arbitrary and post-hoc if without strong theoretical justifications.\n\nWhy the behavioral evidence (Experiment 1) is primarily provided using close-source models while the neural evidence (Experiment 2) is primarily provided using the open-source Llama model? Why not conduct same behavioral experiments to Llama?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hFTl7vgcLw", "forum": "1penHITB8o", "replyto": "1penHITB8o", "signatures": ["ICLR.cc/2026/Conference/Submission7231/Reviewer_W9Tv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7231/Reviewer_W9Tv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7231/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761489067027, "cdate": 1761489067027, "tmdate": 1762919373262, "mdate": 1762919373262, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The study explores LLMs' gambling behavior in a slot machine task, in which the authors identified addictive behavior with corresponding cognitive biases of LLMs, grounded in cognitive-behavioral patterns presented in human gambling addictions. To illuminate how LLMs internally represent risk in gambling, the author used Sparse Auto-encoder to discover features relevant to either safety or risk. Finally, through activation patching, the author steered model's behavior in a causal manner, validating the features extracted. Overall, the study shows LLMs' gambling addiction at different levels, pointing out a potential way of risk control in using LLMs as decision-makers."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The study defines LLMs' irrational behavior with rules that root in human addictive patterns, proposing a reliable way to quantify addiction in a betting task.\n2. Fine-grained manipulations relevant to risk.\n3. The layer-wise distributions of risk-related features are interesting."}, "weaknesses": {"value": "1. Lack of norm. Humans mental disorders are diagnosed according to a norm basically, but for LLMs it seems tricky to have a norm.\n2. Likewise, risky behavior (as indicated by the irrational index) in a gambling task might be insufficient in defining a gambling addiction as claimed in the paper. \n3. Inconsistent model use: better investigate the same model on both behavior and neural level. \n4. More controls are needed to make sure the neural features are only related to risk decision. When using activation patching, the specificity and generalizability of patching features should be checked in order to see if such patching undermines model performance or even induce more risk in other domains."}, "questions": {"value": "1. Incorrect color labelling in Figure 1 (Phase 1, prompt composition), where G/M should be in red rather than green, according to the results in 3.2.\n2. Does bankruptcy mean that the LLM run out of initial capital without quitting the game? Does the 'rounds effect' mean the average number of rounds LLMs play in a single game before quitting, or before bankruptcy? Please provide clear definition for all indicators used in paper. \n3. In section 4, 6400 games mean Llama played 100 times in each condition? When extracting embeddings for SAE, which position within answers were used? \n4. When identifying differential features between the safety and bankruptcy, how do you guarantee the specificity of the features? As the features can represent concept relevant to stop/leave/numeric values/... other than the safe-risky variable. \n5. In finding 2 of activation patching, what does the safe context and risky context mean? What temperature did you use in the generation? As there are only 211 bankruptcy cases, -14.2% change means that there are still over 180 bankruptcy cases. Worth a check whether the change reflects noise.\n6. Did Llama3.1-8b show similar patterns as found in phase 1? Such as different effect sizes caused by different prompt components. Did the 211 bankruptcy cases primarily come from a specific condition? Maybe changing a model will lead to a more balanced number of cases based on the variability shown in table 2."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "C3O1xFGKSF", "forum": "1penHITB8o", "replyto": "1penHITB8o", "signatures": ["ICLR.cc/2026/Conference/Submission7231/Reviewer_YnzE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7231/Reviewer_YnzE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7231/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761787251775, "cdate": 1761787251775, "tmdate": 1762919372908, "mdate": 1762919372908, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates whether large language models (LLMs) can exhibit gambling addiction-like behaviors similar to humans. The authors use classical gambling tasks from human experiments to test LLMs and develop quantitative measures to assess addiction-related behaviors. They perform neural circuit analysis using sparse autoencoders to identify underlying mechanisms. Behaviorally, the study reports addiction-like gambling patterns that lead to bankruptcy in LLMs. Through neural network analysis, the authors identify features that distinguish between bankruptcy and self-stopping cases, which they interpret as risky and safe decision-making features."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**1.** **Multi-level analysis approach**: The paper combines behavioral measures with neural network-level analysis and intervention, providing insights at both phenomenological and mechanistic levels.\n\n**2.** **Systematic experimental design**: The authors test 64 different experimental conditions, including a comprehensive examination of how information conveyed through prompts may increase or decrease gambling behaviors."}, "weaknesses": {"value": "**1.** **Unclear objective and limited ecological validity**: The paper's objective appears misaligned with its experimental design and data analysis. If the goal is to inform investment applications, the study should use realistic investment scenarios rather than simplified gambling tasks to ensure ecological validity. Conversely, if the aim is to simulate human pathological gambling behaviors, the paper should demonstrate behavioral resemblance to humans at a finer granularity, such as the cognitive algorithms that lead to such sequential gambling behaviors. The current approach falls short of either objective.\n\n**2.** **Problematic definition and conceptualization of irrationality**: The paper conflates gambling behavior with irrationality, which is theoretically unsound. Rationality depends on the reward structure and the agent's objectives. In some experimental conditions, the prompt explicitly sets the goal as \"doubling your initial funds to $200\", which cannot be achieved without gambling, while avoiding bankruptcy is not explicitly designated as a goal. Under these conditions, risk-seeking behavior—even when it risks bankruptcy—could be rational, analogous to risk-sensitive foraging in starving animals that increase risk-taking to maximize survival probability. To demonstrate irrationality, the authors must show that the agent's behavior violates its stated goals, which they have not established.\n\n**3.** **Questionable practical implications**: The authors suggest their findings are relevant for financial decision-making applications, yet investment inherently involves calculated risk-taking. An LLM that avoids all gambling-like behaviors would not necessarily make a good investor, undermining the practical relevance of the proposed safety concerns.\n\n**4.** **Multiple confounds limiting validity**: Several design and interpretational issues compromise the study's validity. First, the experimental design conflates risk-seeking with irrationality by ensuring that gambling always yields worse expected payoffs than not gambling. This prevents distinguishing between potentially optimal risk-seeking (under appropriate utility functions or reward structures) and genuinely irrational behavior. Second, the \"risky\" and \"safe\" features identified in the neural analysis may simply reflect the binary choice of whether to gamble rather than representing generalizable risk-related decision-making mechanisms. Third, the analysis of prompt complexity (Finding 3 in behavioral analysis) confounds complexity with the number of gambling-related prompts, making it impossible to determine which factor drives the observed effects.\n\n**5.** **Insufficient evidence for claimed cognitive biases**: The authors repeatedly claim that LLMs exhibit cognitive illusions such as illusion of control and gambler's fallacy (e.g., Abstract, line 469), but provide no direct empirical evidence for these specific cognitive biases. Similarly, the assertion that \"both loss chasing and win chasing exist\" appears to merely describe the tendency to increase bets over time. The evidence for human-like cognitive features of gambling addiction in LLMs remains inadequately supported. Apologies if I had missed anything."}, "questions": {"value": "### Q1: Research Objectives and Ecological Validity\n**Question:** What is the primary objective of this work—assessing safety risks for financial AI applications, simulating human pathological gambling, or understanding general risk-taking in LLMs? How does the gambling paradigm connect to your stated objective?\n\n**Suggestion:** Redesign experiments to match your objective: either use realistic investment scenarios with varying risk-reward profiles for financial applications, or systematically compare LLM behaviors with established human behavioral patterns at a granular level for cognitive modeling of pathological gambling.\n\n### Q2: Definition and Framework of Irrationality\n**Question:** Given that some prompts instruct LLMs to double their funds (unachievable without gambling) while not establishing bankruptcy avoidance as a goal, how do you justify labeling gambling behavior as irrational? Could this represent rational risk-taking analogous to risk-sensitive foraging?\n\n**Suggestion:** (a) Redefine irrationality by demonstrating violations of normative decision-making principles (e.g., violations of expected utility theory, preference reversals, or money pump scenarios) rather than equating risk-seeking with irrationality.  (b) Modify experimental instructions to explicitly balance multiple goals (e.g., \"maximize final wealth while avoiding bankruptcy\"), and include control conditions where not gambling can achieve the stated goal. (c) Add experimental conditions with positive expected value gambling and varying risk-reward ratios to distinguish rational risk-seeking from genuinely irrational behavior.\n\n### Q3: Confounds in Experimental Design and Interpretation\n**Question:** Since gambling always yields worse expected payoffs, how can you separate rational risk-seeking from irrationality? Aren't the \"risky\" and \"safe\" neural features simply capturing whether the model chooses to gamble rather than representing generalizable mechanisms? How do you disentangle prompt complexity from the number of gambling-related cues in Finding 3?\n\n**Suggestion:** (a) Include conditions where gambling has positive expected value; (b) Test whether neural features generalize to different decision-making contexts beyond the task currently used; (c) Design a factorial experiment crossing prompt complexity with gambling-related content to independently assess each factor. \n\n### Q4: Evidence for Cognitive Biases\n**Question:** What specific experimental manipulations or behavioral signatures demonstrate illusion of control and gambler's fallacy beyond general gambling tendencies? How does observing \"both loss chasing and win chasing\" constitute evidence for specific psychological mechanisms rather than merely describing increased betting over time?\n\n**Suggestion:** The authors may choose to soften their claims or provide additional supporting results.\n\n\n### Additional Minor Comments\n* A recent related work (Du, 2025, arXiv:2506.22496v1) has also examined LLM gambling-like behaviors and proposed mitigation strategies through training methods. The authors may discuss how their work relates to and differs from this study.\n\n* Figure 2 appears circular: plotting the correlation between the composite irrationality index and bankruptcy when both are derived from the same behavioral sequences. This requires clarification or justification.\n\n* Figure 2 shows 32 points per plot, but the paper describes 64 experimental conditions. Were fixed and variable betting conditions collapsed? \n\n* The redundancy between I_BA and I_EB components in the Irrationality Index definition should be examined. What is their correlation in the actual LLM behavioral data?\n\n* The terms \"prompt complexity\" and \"number of gambling-related prompts\" appear to be used interchangeably (e.g., Figure 4), which is confusing and potentially misleading.\n\n* Figure 5: The error bars are not defined in the legend, and there is no statistical test reported for whether changes across streaks are significant.\n\n* The neural network analysis section reports only 211 bankruptcies among 6400 cases (3.3% bankruptcy rate), which is lower than the lowest rate (6.3% for GPT-4.1-mini) reported in Table 2. The omission of this discrepancy from Table 2 appears misleading and requires explanation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zYtNZkWLfB", "forum": "1penHITB8o", "replyto": "1penHITB8o", "signatures": ["ICLR.cc/2026/Conference/Submission7231/Reviewer_LQ6B"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7231/Reviewer_LQ6B"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7231/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980595139, "cdate": 1761980595139, "tmdate": 1762919372546, "mdate": 1762919372546, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}