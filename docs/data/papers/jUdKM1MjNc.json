{"id": "jUdKM1MjNc", "number": 14710, "cdate": 1758242266903, "mdate": 1759897353565, "content": {"title": "QMill: Quantum Data Generation for Effective and Efficient Quantum Machine Learning", "abstract": "Quantum machine learning (QML) has the potential to transform various fields, especially the ones that utilize quantum datasets, as QML tasks with quantum datasets have provable speedups. Yet, QML’s progress is limited by a lack of suitable quantum datasets for training and evaluation. While methods have been proposed to generate synthetic quantum datasets, these methods fail to accurately capture the entanglement properties necessary for effective generation of QML datasets. This lack of diverse and entanglement-rich data hampers the development and benchmarking of QML models. To address this, we present QMILL, a versatile quantum data generation framework that\nemulates diverse classical and quantum data distributions with low circuit depth, producing entangled, high-quality dataset samples to support QML advancement.", "tldr": "This paper introduces QMILL, a framework that generates synthetic quantum data with realistic, variable distributions of entanglement to address the data scarcity bottleneck hindering progress of quantum machine learning.", "keywords": ["Quantum Computing", "Dataset Generation", "Quantum Machine Learning"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/49dad0106f1adbc0c0c18b7a4a9125fc304fc26b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces QMILL, a low-depth algorithm that produces synthetic quantum data with an arbitrary target distribution of considerable entanglement (CE) across the generated quantum states. The algorithm starts from Haar-random product states, applies one of four shallow trainable ansatz circuits, and optimizes circuit parameters to minimize the total variation distance (TVD) between the generated CE histogram and the target one. The CE measurements are obtained through measurement surrogates and the optimization is done through dual annealing. QMILL also implements a SWAP-test -based diversity check to assure that the generated states differ from each other. \nThe authors test the algorithm with target CE distribution obtained from classical (MNIST, Fashion-MNIST, CIFAR-10) and quantum (chemistry, soil moisture, dark matter) sources and artificial ones. The authors also demo a 3-qubit QNN trained on QMILL-generated CE features performing comparably under ideal vs. noisy settings."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The problem is of interest and, unlike previous work, it bridges the lack of entanglement-rich datasets for QML by targeting full CE distributions rather than a single CE value.\n\n- Adding a diversity check strengthens the approach\n\n- The whole pipeline is simple and the presence of experiments gives useful evidence, even if they are not satisfactory (see weaknesses)."}, "weaknesses": {"value": "Although the above strength, I do not think the paper currently achieves the high standards required by ICLR. My main concern is the scalability of the algorithm with the number of qubits, under different aspects:\n\n- First, I am not sure the surrogate measure for CE is indeed efficient for a large number of qubits. To compute NZP it is required to estimate the probability of outputting the bitstring 0^n, which becomes infeasible as n grows, as it amounts to rare-event estimation/post-selection.\n\n\n- Furthermore, no claims are made on the performance of the algorithm (shot cost, optimization time, depth required) depending on the number of qubits.\n\n\n- In addition to all of this, experiments are only provided for a small number of qubits (3/4), which casts doubts on the performance of the algorithm for larger numbers of qubits.\n\n- Separately, the algorithm does not reproduce the right-skewed (right-wing) distribution, indicating a clear limitation."}, "questions": {"value": "- Could the authors clarify theoretically how the cost of performing NZP scales with n, as well as the scaling of other quantities like shot cost and time complexity?\n\n\n- Could the authors run experiments for a larger number of qubits (around 10) to assess the performance and the scaling with time of the algorithm?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "K1pMoggPVA", "forum": "jUdKM1MjNc", "replyto": "jUdKM1MjNc", "signatures": ["ICLR.cc/2026/Conference/Submission14710/Reviewer_hvP2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14710/Reviewer_hvP2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14710/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761477530291, "cdate": 1761477530291, "tmdate": 1762925073776, "mdate": 1762925073776, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The manuscript proposes a low-depth quantum data generation framework designed to mitigate the lack of suitable training data in quantum machine learning. The authors argue that existing synthetic data approaches fail to capture essential entanglement characteristics, limiting their relevance for QML tasks. By generating entangled, high-quality samples that emulate both classical and quantum distributions, QMILL aims to facilitate more representative benchmarking and improve the development and evaluation of QML models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "the work provide the extensive numerical evaluations on the proposed dataset."}, "weaknesses": {"value": "1. The proposed method might suffer scalability issue for generating dataset for QML. for instance:\n* as it select TVD as objective function, the computational complexity might grow exponentially as the system increase. \n* as it utilize the SWAP test for sample diversity validation, it would double the system size which is intractable for large system.\n2. many typos such as in line 187, double cite; $\\phi$->phi in line 310."}, "questions": {"value": "1. In 295, the standardized data are reduced via PCA from $2^n-1$ feature to $n$ qubits and then encode them into amplitude. why does it not directly encodes the feature into amplitude, it also only need $n$-qubit quantum states to store the feature vector without information lose.\n2. The paper mentions the use of amplitude encoding. However, efficiently implementing such encoding circuits typically incurs significant resource overhead for large systems. Could the authors elaborate on how scalability is maintained?\n3. In line 304, what's the quantum-sensed workloads used for? are they the other two dataset mentioned in 299?\n4. The manuscript claims that the proposed dataset offers advantages over the previous dataset with fixed CE. However, it is unclear where the supporting numerical evidence for this claim is presented. Could the authors provide or highlight the corresponding experimental results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5eN3FaxXwC", "forum": "jUdKM1MjNc", "replyto": "jUdKM1MjNc", "signatures": ["ICLR.cc/2026/Conference/Submission14710/Reviewer_Y2Gp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14710/Reviewer_Y2Gp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14710/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761725265102, "cdate": 1761725265102, "tmdate": 1762925073386, "mdate": 1762925073386, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present QMILL, a quantum data generation framework aimed at addressing the lack of suitable quantum datasets for quantum machine learning. Since most QML research currently relies on classical data, QMILL provides a way to generate synthetic quantum datasets that capture essential entanglement properties, especially concentratable entanglement. The framework uses low-depth, customizable quantum circuits with SWAP tests to efficiently produce high-quality, entangled samples across a range of concentratable entanglement values. The authors validate QMILL on multiple classical and quantum distributions, showing that it generates more realistic and diverse quantum data than existing approaches, thereby enabling better training and evaluation of QML models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "S1. The paper clearly lays out the data scarcity problem in QML and shows how QMILL tackles it by generating diverse, entangled datasets.\n\nS2. The explanation of the low-depth circuits and SWAP-test validation is straightforward and shows why QMILL works well on current hardware.\n\nS3. The dataset analysis is clear and convincing, showing good variability and robustness to noise."}, "weaknesses": {"value": "W1. The overall impact is a bit unclear since the usefulness of synthetic quantum datasets is still limited and not fully established.\n\nW2. The evaluation feels more like a proof of concept, with few benchmarks comparing models trained on QMILL data to other datasets.\n\nW3. It’s not clear how well QMILL generalizes across different hardware setups or noise levels.\n\nW4. The experiments only use a small three-qubit QNN, so broader testing would be needed to show real scalability.\n\nW5. There’s no solid quantitative comparison against other synthetic dataset methods."}, "questions": {"value": "Q1. How were the four ansatz designs chosen for comparison, what criteria guided the picks, and are there other families (e.g. hardware-efficient) you considered?\n\nQ2. Why limit the experiments to a three-qubit QNN—hardware or training constraints? Could you scale to more qubits/deeper models and report results?\n\nQ3. Beyond experiments, can you offer any theoretical guarantees on when QMILL-generated datasets help (e.g. generalization bounds) and where they might fail?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2N31tU4ukC", "forum": "jUdKM1MjNc", "replyto": "jUdKM1MjNc", "signatures": ["ICLR.cc/2026/Conference/Submission14710/Reviewer_e1Qp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14710/Reviewer_e1Qp"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14710/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992292530, "cdate": 1761992292530, "tmdate": 1762925072840, "mdate": 1762925072840, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of the scarcity of high-quality, representative quantum training data . The authors argue that QML's promise of speedups is contingent on operating on quantum data (i.e., data with entanglement), but the field is stuck using classical datasets due to this data gap. The paper identifies a key flaw in existing synthetic data generation methods: they typically target a single, fixed value of Concentratable Entanglement (CE), which is not representative of real quantum datasets that exhibit a distribution of CE values. To solve this, the authors propose QMILL, a low-depth quantum data generation framework. The core contribution is its ability to generate quantum data samples whose CE values, in aggregate, match a user-specified target distribution."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Novelty of the Goal: The conceptual shift from targeting a single CE value (as in prior work ) to a full CE distribution is the key insight. This is a far more realistic and representative target for emulating real-world quantum data.\n\n- Empirical Validation: The authors have been exceptionally thorough. They test their framework against 12 different distributions (4 synthetic, 8 real) . They design and compare 4 different low-depth ansatzes (Fig. 2, Fig. 9) . They explicitly check for mode collapse using SWAP tests (Fig. 8a) . They also run on both ideal simulators, noisy simulators, and real hardware (IBM Sherbrooke). This is a comprehensive evaluation."}, "weaknesses": {"value": "- On the motivation of CE. The entire framework is predicated on the assumption that Concentratable Entanglement (CE) is the primary, sufficient proxy for \"quantum-ness\". While it's an important metric, it's an open question whether matching the CE distribution is sufficient to capture all the relevant correlations and structures of a quantum dataset that a QML model might exploit. The paper demonstrates this is a necessary step forward, but not definitively that it is the final step.\n\n- Unusual Noisy Result: In Table 1, the QNN trained on \"Noisy\" data (84.8% accuracy) inexplicably outperforms the one trained on \"Ideal\" data (81.8%). The paper frames this as simple robustness , but it's a counter-intuitive result that is left unexplained.\n\n- Ansatz-Dependent Performance: The results in Section 6.5 (Fig. 9) show that the choice of ansatz matters significantly, with A3 being the best all-rounder. This implies that a user must still engage in a trial-and-error process to find the right ansatz for their target distribution, rather than the framework being a single, universal generator."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Uhcnc3nNnK", "forum": "jUdKM1MjNc", "replyto": "jUdKM1MjNc", "signatures": ["ICLR.cc/2026/Conference/Submission14710/Reviewer_deqn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14710/Reviewer_deqn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14710/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762160786837, "cdate": 1762160786837, "tmdate": 1762925072431, "mdate": 1762925072431, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}