{"id": "ztCVzRbnvQ", "number": 13140, "cdate": 1758214006847, "mdate": 1759897461437, "content": {"title": "HiPO-MILP: Hierarchical Preference Optimization for MILP Solving", "abstract": "Mixed-integer linear programming (MILP) is a fundamental yet computationally challenging optimization problem in operations research.\nTo accelerate the solving process, recent machine learning methods predict an initial solution and confine the subsequent search to a local trust region.\nHowever, these models face two critical challenges during training.\nFirst, the models are typically trained on a collection of high-quality solutions weighted by their objective values, which fails to account for a solution's distant to the near-optimal region and leads to a biased training signal.\nSecond, weighting by objective value provides an ambiguous preference signal, which prevents the model from learning to explicitly distinguish between high-quality and local optimal solutions.\nTo address the challenges, we introduce HiPO-MILP, a novel Hierarchical Preference Optimization framework. \nOur key idea is to define a quality score for each solution that combines its objective value with its distance to the convex hull of optimal solutions. \nBased on this score, HiPO-MILP constructs a three-tiered preference hierarchy that distinguishes between near-optimal, high-quality, and perturbed solutions, thereby providing a clear and robust learning signal.\nBy training with explicit preference pairs derived from this hierarchy, HiPO-MILP learns to navigate the solution space towards regions that are not only high-scoring but also structurally closer to the global optimum. \nExperiments demonstrate that HiPO-MILP substantially improves solving efficiency across a diverse range of MILP benchmarks.", "tldr": "We propose a hierarchical preference optimization for MILP solving.", "keywords": ["Learning to Optimize", "Machine Learning for Combinatorial Optimization", "Mixed-Integer Linear Programming"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/26cdb80e93aba3b11cfb09c2ee4b1fc35e49e92c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces HiPO-MILP, an extension of the predict-and-search (PS) framework that incorporates two key advancements: (i) using the distance to the optimal region as a scoring criterion for candidate solutions, and (ii) employing a hierarchical preference-based loss function. Experiments on widely-used public benchmarks demonstrate its superiority over both PS and contrastive PS."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The concept of a holistic quality score, which integrates geometric and algebraic properties, offers a more comprehensive evaluation of candidate solutions and is a noteworthy contribution."}, "weaknesses": {"value": "1. **Insufficient baselines**: Section 2.1 acknowledges a wide range of learning-to-optimize methods. Under the \"learn to accelerate\" paradigm, learning-based LNS approaches—such as CL-LNS [1] and BTBS-LNS [2]—are promising and should be included for comparison. Similarly, under the \"end-to-end learning\" paradigm, methods like DiffILO and Apollo-MILP are mentioned but not evaluated. **The primary goal is to enhance MILP solving using any technique, rather than improving a particular pipeline (e.g., PS).**\n2. **Insufficient ablation study**: The two proposed improvements—(i) the holistic score and (ii) hierarchical preference optimization—warrant an ablation study to isolate their individual contributions.\n 3. **minor comments**: Table 3 indicates that HiPO-MILP is outperformed by ConPS for sample sizes 32 and 512. Does this suggest that HiPO-MILP is sensitive to hyperparameter settings?\n\n[1] Huang, Taoan, et al. \"Searching large neighborhoods for integer linear programs with contrastive learning.\" International conference on machine learning. PMLR, 2023.\n[2] Yuan, Hao, et al. \"BTBS-LNS: Binarized-Tightening, Branch and Search on Learning LNS Policies for MIP.\" The Thirteenth International Conference on Learning Representations."}, "questions": {"value": "1.  The authors emphasize the importance of structural proximity to local optima among suboptimal solutions. However, the best solution $x$ obtained in the training set and the optimal solution $x^*$ to the original problem may not be identical. What if $x$ is locally optimal but far from $x^*$? Conversely, suppose a suboptimal solution $x'$ in the training set is close to $x^*$. In that case, $x'$ would be a good candidate but would be penalized under the proposed scoring scheme due to its distance from $x$.\n2.  Why is structural proximity considered important? Moreover, Figure 1 does not sufficiently justify this, as linear objectives in MILPs may inherently imply that high-quality solutions lie near the optimal region.\n3.  Given the emphasis on structural proximity, if PS and neural diving collect numerous high-quality solutions, why not simply select the best one among them?\n4.  In Table 2, when $S_2$ is omitted, it seems like the resulting approach is very similar to contrastive PS? But why does it falls behind ConPS?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WwD6AMYOK4", "forum": "ztCVzRbnvQ", "replyto": "ztCVzRbnvQ", "signatures": ["ICLR.cc/2026/Conference/Submission13140/Reviewer_zEPs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13140/Reviewer_zEPs"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13140/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761738716330, "cdate": 1761738716330, "tmdate": 1762923858178, "mdate": 1762923858178, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work presents a ML-based approach for MILPs. While the topic is relevant, the paper in its current form has significant shortcomings that prevent it from being a strong contribution. The core motivation is conceptually flawed, the theoretical contributions are overstated, and the empirical validation is insufficient. The method's reliance on multiple hyper-parameters also raises concerns about its practicality and generalizability."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper is easy to follow."}, "weaknesses": {"value": "### Major\n\n- **Motivation & Figure 1:** The argument that objective value is an inadequate proxy for proximity to optimality is flawed. For a linear objective, the set of optimal solutions lies on a hyperplane. A solution with a near-optimal value is inherently close to this set, making the objective a valid proximity measure. The distance to a single arbitrary optimal point (e.g., $x_3$) is not a meaningful metric.\n\n- **Theoretical Contributions:** The presented \"Theorems\" (e.g., 4.1-4.3) are definitions or observations, far from novel theoretical results. This overstates the paper's theoretical contribution.\n\n- **Empirical Evaluation:** The scope of the evaluation is limited. Benchmarks on a standard, diverse dataset like **MIPLIB 2017** are necessary to properly assess generalizability and performance.\n\n### Minor Points & Clarifications\n\n- **Hyperparameters:** The method introduces several hyperparameters $(\\lambda, \\eta, \\gamma, \\beta)$. A discussion on their sensitivity, tuning cost, and impact on generalization is needed.\n- **Unclear Notation:** The symbol $\\sigma$ in Eq. (8) is not defined.\n- **Grammar:** Use \"an MILP\" instead of \"a MILP\"."}, "questions": {"value": "See the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BWcVNX4JfY", "forum": "ztCVzRbnvQ", "replyto": "ztCVzRbnvQ", "signatures": ["ICLR.cc/2026/Conference/Submission13140/Reviewer_aJ8X"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13140/Reviewer_aJ8X"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13140/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761816394787, "cdate": 1761816394787, "tmdate": 1762923857855, "mdate": 1762923857855, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes HiPO-MILP, a hierarchical preference optimization framework for predict-and-search MILP solving. It introduces a holistic quality score that combines the objective value with the distance to a near-optimal convex hull of solutions, and constructs a three-tier preference hierarchy (near-optimal hull, high-quality feasible, perturbed). Training uses SimPO-style preference learning alongside BCE. Experiments on CA/SC/IP/WA and a MIPLIB subset show lower gaps and faster convergence than PS/ConPS and solvers."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Clear motivation: objective-only labels are noisy; adding geometry via the convex hull distance is sensible.\n- Method is well-instantiated: holistic score + three-tier preferences + SimPO integration.\n- Strong empirical results with useful ablations (tier removal, pair count, temperature/margin, search params)."}, "weaknesses": {"value": "- Training/data prep overhead is not quantified: computing many near-optimal solutions, convex hull projection (QP via OSQP), and generating perturbed solutions can be expensive; it’s unclear whether the added cost is justified relative to the observed runtime gains.\n- Preference pair acquisition on hard instances is under-explored: for very large problems or tiny feasible regions, obtaining diverse near-optimal sets and meaningful negative pairs may be difficult.\n- Baselines are dated on the prediction side: newer predict-and-search variants and solution-prediction method."}, "questions": {"value": "- Please report the end-to-end overhead: (i) number of solver calls per instance to collect near-optimal solutions; (ii) time for convex hull distance (QP) vs. Hamming fallback; (iii) total data-prep/training time vs. PS/ConPS. Are the test-time speed/quality gains worth the extra offline cost?\n\n- How robust is preference-pair construction on harder instances with small feasible regions and >100k decision variables? Can you test on at least one large-scale case to assess scalability of hull distance, pair mining, and overall training stability?\n\n- Will you add stronger, recent baselines and report under the same search hyperparameters?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "HU5kaKzt5D", "forum": "ztCVzRbnvQ", "replyto": "ztCVzRbnvQ", "signatures": ["ICLR.cc/2026/Conference/Submission13140/Reviewer_Coox"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13140/Reviewer_Coox"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13140/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761987869646, "cdate": 1761987869646, "tmdate": 1762923857545, "mdate": 1762923857545, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes HiPO-MILP, which introduces *Preference Optimization* into the process of using GNNs to predict initial solutions for MILP problems. The method employs three-tiered optimization signals as the optimization objectives in preference optimization."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper introduces Preference Optimization signals to guide the GNN training process for MILP optimization.\n2. Experimental results show that HiPO-MILP outperforms the compared baseline methods."}, "weaknesses": {"value": "1. HiPO requires the preparation of preference pairs prior to training, which introduces additional computational overhead compared with existing paradigms.\n2. The paper should compare HiPO-MILP with more recent *predict-and-search* approaches for MILP solving, such as DiffILO.\n3. While the paper introduces the concept of three-tier solutions through Hierarchical Preference Optimization (lines 270–281), the loss computation in Section 4.4 appears only weakly related to this three-tier structure."}, "questions": {"value": "1. What is the computational cost of preparing the preference pairs? How is the solution list used to construct preference pairs obtained for each problem instance before training?\n2. The paper acknowledges that the pair interval influences HiPO-MILP’s performance. How can one ensure that every MILP instance used in HiPO-MILP training has sufficiently many and high-quality preference pairs (e.g., a well-balanced distribution between preferred and rejected solutions)? If the feasible region of a problem is small, wouldn’t obtaining preference pairs become difficult?\n3. Equation (6) requires computing $d(x,\\text{conv}(S^*))$. Since this involves the convex hull of all optimal solutions $\\text{conv}(S^*)$, does this imply that all optimal solutions of a MILP instance must be known when preparing preference pairs? This seems impractical—how is it actually implemented in HiPO-MILP?\n4. Compared with existing work such as Contrastive Predict-and-Search (ConPS), what are the concrete algorithmic differences in HiPO-MILP beyond the introduction of the Holistic Quality Score?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vaixFbJFwb", "forum": "ztCVzRbnvQ", "replyto": "ztCVzRbnvQ", "signatures": ["ICLR.cc/2026/Conference/Submission13140/Reviewer_whbN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13140/Reviewer_whbN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13140/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989251527, "cdate": 1761989251527, "tmdate": 1762923857296, "mdate": 1762923857296, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}