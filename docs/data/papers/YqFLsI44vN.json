{"id": "YqFLsI44vN", "number": 4786, "cdate": 1757767410222, "mdate": 1759898012974, "content": {"title": "BMAS: A Brain-Inspired Multi-Agent System with PFC-Guided Task Coordination and Hippocampus-Neocortex Dual Memory for Scalable Multi-Step Reasoning", "abstract": "Multi-Agent Systems (MAS) leveraging large language models have shown promise in tackling complex, multi-step tasks by distributing responsibilities across specialized agents. Recent research has introduced mechanisms such as explicit role assignment, hierarchical task allocation, and dynamic coordination strategies to improve agent collaboration and execution quality. However, most efforts focus separately on task scheduling or information sharing, overlooking the interplay between system-level architecture and memory management. This gap gives rise to two coupled challenges: static architectures limit adaptive coordination, which in turn amplifies the accumulation of long interaction histories, leading to inefficiency, instability, and degraded scalability.\nInspired by the human brain, we propose the Brain-inspired Multi-Agent System (BMAS), a principled framework that explicitly links architectural design with memory management. BMAS introduces a prefrontal cortex (PFC) like module responsible for hierarchical task decomposition, dynamic coordination, and working memory management, addressing the rigidity of conventional MAS architectures. Complementing this, a hippocampus-neocortex-inspired dual-memory system enables selective consolidation and semantic retrieval of task-relevant information, mitigating context inflation and enhancing backtracking capabilities.\nWe validate BMAS on diverse complex task datasets in mathematics and coding, demonstrating superior performance in accuracy, efficiency, and reasoning stability compared to existing MAS. Our approach bridges neuroscience insights and MAS design, providing a scalable framework for collaborative AI systems requiring long-horizon reasoning. The code is available at https://anonymous.4open.science/r/BMAS-AAD0.", "tldr": "", "keywords": ["Multi-Agent Systems", "Large Language Models", "Brain-inspired", "Hierarchical Task Decomposition", "Memory Management"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f418e2f55a4923761967a17606fac1a694f5700a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper identifies several shortcomings of current multi-agent systems and draws inspiration from the human brain to propose a Brain-Inspired Multi-Agent System, where different modules of the multi-agent framework correspond to distinct regions of the brain. Designing agent architectures based on brain mechanisms is a meaningful direction, and it may enable principled planning and coordination pathways, as well as efficient memory structures as the authors suggested.\n\nI reviewed this paper before during the NeurIPS 2025 review process. Unfortunately, it seems that the valuable comments raised by the reviewers at that time have not been addressed or incorporated into this version."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Using the analogy of the human brain to understand multi-agent systems is an interesting and insightful perspective. The ablation study in Section 4.4, which examines the relationship between the memory mechanism and turn and accuracy, is well-designed."}, "weaknesses": {"value": "I have compared the previous version with the current one. Unfortunately, some important weaknesses from the last reviews remain unresolved:\n\n1. Unsupported claim on efficiency [Line 32]. There is no comparison or experiments using any efficiency metrics, so the claim remains unsubstantiated.\n\n2. Limited scope of experiments and weak baselines. Although the authors propose a multi-agent framework, no agentic tasks are evaluated.\n\n3. Limited novelty and lack of a solid theoretical foundation for the advantages of the proposed MAS."}, "questions": {"value": "Could the authors provide details on what changes or improvements have been made in this version compared to the previous one?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6v9PUONZRq", "forum": "YqFLsI44vN", "replyto": "YqFLsI44vN", "signatures": ["ICLR.cc/2026/Conference/Submission4786/Reviewer_1sGq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4786/Reviewer_1sGq"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4786/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761225590435, "cdate": 1761225590435, "tmdate": 1762917576634, "mdate": 1762917576634, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes BMAS, a novel brain-inspired framework for multi-agent systems, designed to overcome the limitations of static architectures and inefficient memory management. The system introduces a module that dynamically decomposes tasks and coordinates agents, moving beyond rigid, predefined structures. This is complemented by a dual-memory system which selectively consolidates and retrieves relevant information to mitigate context inflation in long-horizon tasks. The authors validate BMAS on complex mathematics and coding datasets, demonstrating improved efficiency, stability, and reasoning robustness. This approach effectively unifies architectural design and memory management, offering a more scalable solution for multi-step reasoning."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "1.  **Novel Task Management:** The design featuring **hierarchical task decomposition and dynamic simplification** is an intelligent approach to managing complex problems, improving adaptability over static methods.\n\n2.  **Strong Empirical Performance:** The proposed system **consistently outperforms strong MAS baselines** across diverse and challenging tasks, demonstrating its practical effectiveness and robustness."}, "weaknesses": {"value": "1.  **Poor Presentation:** The paper's clarity suffers from a cluttered presentation. Figure 1 and Section 3.2 are crowded with biological analogies, lacking a clean, abstract illustration of the architecture. The main process diagram is cognitively overloaded, while the task decomposition figure is overly simple, failing to effectively demonstrate the proposed hierarchical simplification.\n\n2.  **Limited Related Work:** The related work section is insufficient. Section 2.1 uses only a few citations to represent entire research areas and does not discuss the experimental baselines. Section 2.2 strangely includes \"Least-to-Most\" prompting and \"Atom-of-Thought,\" which are not memory-oriented methods, without properly introducing the MAS systems that supposedly use them.\n\n3.  **Inconsistent Evaluation Protocol:** The evaluation protocol is inconsistent, using different LLMs across experiments (Qwen3-Plus in Table 1, GPT-4-Turbo/mini in Table 2, GPT-4.1 mini in Table 3). This raises questions about whether the system's effectiveness is dependent on specific model implementations for different tasks.\n\n4.  **Insufficient Ablation Study:** The ablation study in Section 4.4 is inconclusive. By removing both the task management and memory modules at the same time, it fails to independently explore the contribution of each component, making it impossible to assess their individual impact."}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "e3CMs3vVcy", "forum": "YqFLsI44vN", "replyto": "YqFLsI44vN", "signatures": ["ICLR.cc/2026/Conference/Submission4786/Reviewer_7BVJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4786/Reviewer_7BVJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4786/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761461793602, "cdate": 1761461793602, "tmdate": 1762917575064, "mdate": 1762917575064, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a BMAS multi-agent system comprised of modules inspired by how the human brain solves complex tasks through decomposition, planning and working and long-term memory. The authors claim that BMAS addresses the adaptive coordination challenge in MAS and applies the hierarchical task simplification to avoid static architectural choices. The framework is evaluated on AIME, MATH, and HumanEval datasets, showing improvements over the single model baseline and some existing multi-agent frameworks."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- Brain-inspired analogies in system workflow and agent modules provide an elegant motivation for the architecture design choices.\n- The paper evaluates the system across two domains (mathematics and coding) using three different datasets (AIME, MATH, HumanEval).\n-  The system shows measurable improvements over baselines, particularly on the challenging AIME dataset."}, "weaknesses": {"value": "1. The paper claims \"dynamic coordination\" as a key contribution, but the actual mechanism remains unclear. The agent interaction sequence looks fixed (Task Decomposition -> Instructor -> Actor -> Confidence Evaluator -> Rethink -> Instructor).\n2. The paper mentions \"hierarchical task simplification\" repeatedly but does not clearly explain what makes it hierarchical. The task decomposition appears to be a flat list as explicitly stated in the Task Decomposition Agent prompt in Appendix C.1: \"3-5 subtasks total, each subtask should not have sub-tasks\"). \n3. The paper claims superiority over systems with central schedulers, but the Instructor Agent appears to function as a central coordinator, controlling task flow and issuing instructions.\n4. OWL is chosen as a baseline for AIME based on GAIA benchmark performance, which is not relevant to mathematical reasoning tasks. The authors should compare against multi-agent architectures tested on mathematical reasoning in general or on AIME in particular.\n5. AutoGen is listed as a baseline but AutoGen is a framework, not a fixed architecture. The exact multi-agent system architecture built with AutoGen is not specified, making the comparison meaningless.\n6. No analysis is provided on how performance varies with different backbone models. For a framework claimed to be a general-purpose multi-agent solution, it should demonstrate consistent improvements across multiple LLM backbones.\n7. Claims about the major performance gain because of multi-stage reasoning, dynamic memory management, and reflection mechanisms in Sections 4.2 and 4.3 are not supported with any explicit evidence or analysis.\n8. The paper claims (Section 4.2) BMAS is a \"general-purpose, requiring no task-specific role configuration\", but: (i) the Task Decomposition Agent prompt (Appendix C.1) contains explicit instructions for coding and math problems; (ii) the Actor Agent prompt (Appendix C.1) provides detailed instructions for specific math problem types; (iii) in the guidelines for adaptation (Appendix E) it is recommended to \"integrate domain-specific experience into prompts\" contradicting the general-purpose claim."}, "questions": {"value": "1. Where exactly does dynamic coordination occur if the pipeline is predetermined? Can the system break this fixed sequence based on runtime needs?\n2. How is the hierarchical task decomposition implemented?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sHdGsdC6eb", "forum": "YqFLsI44vN", "replyto": "YqFLsI44vN", "signatures": ["ICLR.cc/2026/Conference/Submission4786/Reviewer_qeZR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4786/Reviewer_qeZR"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4786/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761736797578, "cdate": 1761736797578, "tmdate": 1762917574363, "mdate": 1762917574363, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a brain-inspired multi-agent system (BMAS), consisting of a prefrontal cortex inspired module for hierarchical task decomposition and dynamic adjustment of tasks based on feedback, and a dual memory system, consisting of working memory and long term memory. Specifically BMAS consists of five modules dynamically interacting with each other - Task Decomposition Agent, Instructor Agent, Actor Agent, Confidence Evaluator, and Rethink Agent—together with a two-tier memory architecture inspired from hippocampus-neocortex. Working memory contains information relevant for the current subtask, and long term memory selectively stores filtered working-memory traces and supports semantic retrieval by both the Instructor and Actor agents. BMAS shows improvements on mathematical and coding tasks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. A brain inspired multi agent system is proposed for complex multistep reasoning tasks, consisting of modules like task decomposition, reflection, dual memory system containing task specific information, storing historical contexts and retrieval for long term reasoning\n2. Improvements on mathematical and coding tasks"}, "weaknesses": {"value": "1. Recent work proposed modular agentic planner (MAP) [1], consisting of different modules like task decomposer, monitor, actor, evaluator etc inspired from different brain regions. The authors don’t discuss how BMAS differs from MAP and should also be evaluated as a baseline for comparison.\n\n2. The different agents requires lots of specific instructions and prompts, its not clear how sensitive is BMAS to prompt engineering, and also how would this generalize to complex multi-step reasoning/planning tasks, except mathematics and coding.\n\n3. There are no analysis of failure modes, specifcially which modules are primarily bottlenecks.  \n\n[1] - Webb, T., Mondal, S.S. & Momennejad, I. A brain-inspired agentic architecture to improve planning with LLMs. Nat Commun 16, 8633 (2025). https://doi.org/10.1038/s41467-025-63804-5"}, "questions": {"value": "1. Some targeted ablations would be helpful in understanding which mechanisms are most important for BMAS agent, like how does it perform just without the task decomposer, just without long-term memory, just without reflection etc? \n\n\n2. How does the performance vary with confidence threshold?\n\n\n3. Unlike parallel approaches\nsuch as ”Tree of Thought” (Yao et al., 2023), humans reason along a single path, using self-correction\nand strategy shifts for creativity. - humans reason along single path doesn’t seem correct, can the authors cite evidence for that?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JI0hJERyx4", "forum": "YqFLsI44vN", "replyto": "YqFLsI44vN", "signatures": ["ICLR.cc/2026/Conference/Submission4786/Reviewer_1tpk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4786/Reviewer_1tpk"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4786/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762023599816, "cdate": 1762023599816, "tmdate": 1762917573837, "mdate": 1762917573837, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}