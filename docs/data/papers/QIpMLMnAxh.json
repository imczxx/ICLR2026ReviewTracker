{"id": "QIpMLMnAxh", "number": 7466, "cdate": 1758023372245, "mdate": 1759897851229, "content": {"title": "Categorical Distributions are Effective Neural Network Outputs for Event Prediction", "abstract": "We demonstrate the effectiveness of using a categorical distribution as a neural network output for the task of next event prediction. We find that training set sizes help explain performance differences between models: when training sets are increased, performance differences largely disappear. We introduce 3 new datasets which provide informative ways to explore model performance; they demonstrate cases where larger models and the use of the categorical output are effective.", "tldr": "Outputting a categorical distribution can be used effectively for event prediction. Secondary: we explain performance of neural TPP models wrt model size, model output structure and dataset properties.", "keywords": ["point processes", "temporal data", "datasets", "neural networks", "spike prediction", "neuroscience"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c4e9a5d958ba17e475590c572055723ea2d0afef.pdf", "supplementary_material": "/attachment/a6a29ac31ffa2b748da22b7a25eba56b9921e451.zip"}, "replies": [{"content": {"summary": {"value": "disclaimer: i dont use any LLMs to write this review. Everything is purely from my understanding from reading this paper (without any help of LLM) \n\nThe paper challeges the traditional way of predict next event given event history , which typically treat the next event as a continuous random variable ( i.e. E_{t~f(t)} [t] ) where f(t) is the probability density of next event. Instead the author(s) proposed to use discrete N bins for modeling the distribution of next event. They found such proposed method works well on quite a lot of synthetic and real benchmarks esp. training set size is large. They also find a real application for using discretized bin for spike prediction – the data from chicken RGCs."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The main strength is it provides a different angle to look at next event prediction.  \nThe authors have conducted many experiments to support their claim as suggested by the title CATEGORICAL DISTRIBUTIONS ARE EFFECTIVE NEURAL NETWORK OUTPUTS FOR EVENT PREDICTION."}, "weaknesses": {"value": "originality : it is okay, but it can be improved with some theoretical insight of the gain of NLL (or LL) with the categorical distribution. \n\nQuality: The authors should include other evaluation metric such as MAE, MSE than NLL in the figure 3. For Table 1: I am not sure if the proposed method is better.  I also think readers will appreciate more if the authors elucidate with some theoretical underpinnings on the threshold of the LL increases as training set size increases in Figure 3. \n\nClarity: I am not sure if it is the best way to write this paper. I thought there is no proposed method contained and it was purely an assignment from class project. In the end I figured out the flow of this paper.  \n\nSignificance. It can be interesting to TPP community. However, it is rather strange to discretize it since TPP and its continuous characterization of next event are so elegant and well established.  As the authors mention that the current model only support TPP without marks, limiting its significance."}, "questions": {"value": "1.\tHow do you select N ? I know you mention folling Kvamme & Borgan (2021). \n\n2.\tAnother comment is one application Chicken RGCs is fairly limiting. The authors can incorporate 1-2 more."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "T54Zr2HHFF", "forum": "QIpMLMnAxh", "replyto": "QIpMLMnAxh", "signatures": ["ICLR.cc/2026/Conference/Submission7466/Reviewer_dsSi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7466/Reviewer_dsSi"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7466/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761161706161, "cdate": 1761161706161, "tmdate": 1762919582599, "mdate": 1762919582599, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes modeling inter-event times in temporal point processes by discretizing the time distribution into quantile-based bins and predicting a categorical distribution over these intervals. The authors argue that this piecewise-constant representation is better aligned with real-world datasets that exhibit discrete temporal spikes. The authors additionally examine how training set size impacts model performance and introduce several new datasets."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- Focus on a practically motivated issue: real event-time data often contains discrete patterns (e.g., NYC taxi), where density-based likelihoods may be unstable.\n- Clear and intuitive modeling approach.\n- Contribution of new datasets may facilitate future research."}, "weaknesses": {"value": "- Theoretical formulation lacks rigor and clarity.\n  - The hybrid model combining discrete time bins with continuous likelihoods is not formally defined, leaving ambiguity in the underlying probability space.\n  - The suitability of the negative log-likelihood objective is questionable in this mixed setting. For example, in the NYT dataset, likelihood can be artificially inflated by collapsing predictive variance toward zero at discrete timestamps, making likelihood comparisons unreliable.\n- Table 1 reports only NLL, omitting standard point-forecasting metrics (e.g., MAE, RMSE) widely used in time-series forecasting to avoid density anomalies.\n- The paper does not compare against simple continuous regression losses (MSE/MAE), which is necessary to establish whether the proposed discretization offers real benefits over standard formulations.\n- The paper does not compare against recent NN-based models [2, 3, 4].\n- Claims regarding improved loss behavior, sensitivity to dataset size, and the impact of newly collected datasets are mixed, resulting in limited analysis of each claim and making it difficult to assess their individual contributions.\n- The contribution may be overstated relative to prior work employing quantile-based timestamp transformations in TPPs [1].\n- Writing can be strengthened by correcting grammatical errors, eliminating repetition, and avoiding unsupported generalizations (e.g. \"This type of distribution is not uncommon\", \"For this dataset, not only are events from a real-world process, the task itself replicates the requirements of a real-world task.\").\n\n[1] Learning Quantile Functions for Temporal Point Processes with Recurrent Neural Splines (2022)\n\n[2] Recurrent marked temporal point processes: Embedding event history to vector (2016)\n\n[3] The neural hawkes process: A neurally self-modulating multivariate point process (2017)\n\n[4] Latent ordinary differential equations for irregularly-sampled time series (2019)"}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DHwgzHqRHv", "forum": "QIpMLMnAxh", "replyto": "QIpMLMnAxh", "signatures": ["ICLR.cc/2026/Conference/Submission7466/Reviewer_zYmH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7466/Reviewer_zYmH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7466/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761577294580, "cdate": 1761577294580, "tmdate": 1762919582121, "mdate": 1762919582121, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present three contributions to the problem of predicting event distributions. First they show that a categorical distribution (rather than a continuous specification) is effective. Second, they show that differences between models (with continuous and discrete distributions) get smaller as the size of the dataset increases. Third, they introduce three datasets, two synthetically generated so that in one performance is less dependent on sample size while in the other sample size is correlated with expected performance. The third dataset is for a spike prediction task motivated by retinal prosthetics."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This is mainly an experimental paper that seeks to demonstrate scenarios in which a discrete distribution is useful to characterize event distributions and the circumstances under which it is expected to perform better than a continuous specification. For the most part, the experiments are well motivated and justified, and the experiments are convincing and sufficiently detailed in the supplementary material."}, "weaknesses": {"value": "The main weakness of the paper is that it seems to show two fairly evident phenomena event prediction, namely that in general, given sufficient sample size continuous, discrete and implicit (via sampling) event distribution estimates perform similarly and well specified models (meaning those that match the underlying process) perform better. This naturally does not take away the effort put by the authors in demonstrating it empirically.\n\nAlthough the introduced artificial datasets help illustrate the points above, it is less clear whether they further our understanding of models for event distribution prediction, especially, in practical settings where sample sizes and knowledge of the underlying process are usually limited.\n\nUnderstanding that this is an experimental contribution, it is worth mentioning that the technical contributions are minimal."}, "questions": {"value": "- Results in Table 1 are provided with error bars in Table 4. Consider indicating the significance of the differences in Table 1.\n- The motivation for the Metropolis lognormal dataset is understood, however, it is unclear whether it is a representation of something that is likely to happen in practice. After all, none of the other real-world datasets being considered seem to support it. In a sense, the dataset seems almost to contrived.\n- Consider having results for the spike prediction task with a range of sample sizes."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1oFZg5K4Th", "forum": "QIpMLMnAxh", "replyto": "QIpMLMnAxh", "signatures": ["ICLR.cc/2026/Conference/Submission7466/Reviewer_1ngV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7466/Reviewer_1ngV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7466/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994983903, "cdate": 1761994983903, "tmdate": 1762919581631, "mdate": 1762919581631, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates the use of categorical distributions as neural network outputs for temporal point process modeling and event time prediction. The authors propose discretizing inter-event times into quantile-based intervals and predicting a categorical probability for each bin. They state that it can be an effective alternative to traditional continuous-density distributions (e.g., exponential or lognormal mixtures). Results indicate that categorical outputs perform competitively with, or better than, lognormal mixtures and other TPP models. They show that the proposed method benefits from the data with inherent discreteness or spikes. The paper concludes that output choice and dataset structure jointly determine performance trends in neural TPPs.\n\nThe authors propose an interesting methodology that replaces standard continuous output distributions with interval-based categorical representations. They demonstrated that this approach can be effective for event-time distributions with sharp peaks or for clear discrete structures. However, the research lacks the overall depth of analysis.\nThe paper’s main weakness is that it centers on comparing lognormal mixture models and their shortcomings, while the inclusion of other TPP models (NHP, RMTPP, THP) lacks meaningful qualitative analysis that directly compares their behavior to the categorical distribution method. The section on the Metropolis Lognormal Event Dataset is methodologically sound, but it does not clearly relate to the categorical distribution method. The paper should clarify how this section is connected to the evaluation of categorical outputs.\nSimilarly, the Event Sequences from Modulo Addition section lacks clarity in its connection to the stochastic foundations of TPP modeling, since the process is described as deterministic except for the initial point parameters a and v. Clarify how this example relates to the overall aim of evaluating categorical representations in stochastic TPP modeling, such as by specifying whether the deterministic design exposes strengths or limitations of the proposed methodology. Additionally, some terms, such as “usable information,” are introduced without formal definition or theoretical grounding, which weakens the analysis.\nThe paper lacks focus on the proposed discretization method. It should more directly address clarifying its theoretical boundaries, comparing it with other TPP family models, and avoiding lateral discussion of general neural TPP training behaviors.\n\nThe paper is poorly written and difficult to follow. The abstract does not clearly establish the main focus. It is unclear whether the core contribution lies in the categorical distribution formulation or in the introduction of new datasets, and how these two aspects are conceptually connected. The overall narrative lacks coherence, and transitions between sections are abrupt, making the paper hard to read and potentially limiting its impact and accessibility.\nSeveral parts of the experiments appear disjointed and do not build on one another consistently, which reduces the clarity of the study's overall findings. The figures are challenging to interpret, especially Figure 11, where plots are arranged by methods rather than by dataset dimensionality, making it difficult to compare methods within the same dimension.\nThe discussion of results is also overly superficial. The authors mostly describe outcomes without analyzing the underlying causes or implications. Overall, while the experiments are extensive, the presentation quality is well below ICLR standards.\n\nThe authors present an interesting and intuitive idea of using categorical discretization for event time prediction and demonstrate two concrete cases where this approach is well justified (Spike prediction and natively discrete problems). However, the overall exploration of the method’s capabilities and its theoretical or empirical boundaries is limited.\nThe relationship between model performance and the number of categorical bins is not analyzed, leaving open whether the method is sensitive or robust to discretization granularity. Comparisons with alternative TPP model families (e.g., NHP, RMTPP, diffusion- or ODE-based approaches) are only superficial, lacking a deeper qualitative discussion of why categorical heads might outperform or underperform across different regimes.\nThe paper fails to define which dataset characteristics justify the method's use. It is unclear when discretization is beneficial (e.g., for quantized or multimodal peak datasets) or harmful (e.g., for smooth continuous distributions). Additionally, several experiments do not directly address the main hypothesis. Section 5 (Metropolis Lognormal) prioritizes scalability rather than the categorical formulation, while Section 7 (Modulo Addition), though conceptually related, is poorly integrated and weakly motivated.\nThe paper fails to analyze how the number of bins affects training efficiency or model complexity, and provides no actionable guidance for practitioners. As a result, despite the originality and potential impact of the central idea, the work is underdeveloped and fragmented."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- Conceptual novelty: The paper introduces an interesting idea to represent inter-event times via categorical distributions instead of traditional continuous outputs. It provides a fresh and intuitive perspective on temporal point process modeling by focusing on probability mass rather than density.\n- Comprehensive empirical evaluation: The authors conduct extensive experiments across a wide range of real-world and synthetic datasets. The results consistently demonstrate that categorical outputs are competitive with, and sometimes superior to, lognormal mixtures. It has been explicitly shown for datasets with discrete or multimodal event-time structures. The analysis of how training set size affects model performance is particularly insightful.\n- New benchmark datasets: Three newly introduced datasets enrich the TPP research landscape, which can be useful for future TPP research:\nMetropolis Lognormal Dataset — a synthetic benchmark for studying data scaling effects and model size sensitivity.\nRetinal Spike Prediction Dataset — a biologically grounded benchmark linking TPPs with neuroscience applications.\nModulo Addition Family — synthetic discrete-time datasets enabling controlled evaluation of model generalization.\n- Practical robustness and interpretability: The categorical formulation avoids the numerical instabilities of mixture models. Also, it naturally aligns with tasks with discretized or quantized observations (e.g., logs, sensor data, neural spikes).\n- Useful insights for the TPP community: The paper highlights that differences between neural TPP models are often connected to differences in training set size and regularization, rather than architectural complexity alone. It also raises the important discussion of evaluating probability mass within intervals rather than the continuous function. This perspective could influence future research on loss design for temporal models."}, "weaknesses": {"value": "- Lack of focus and narrative coherence: The paper attempts to address multiple directions — categorical outputs, dataset scaling, and new synthetic processes. However, these threads are not well integrated. As a result, the core contribution (the categorical output formulation) is diluted by other sections, such as Metropolis Lognormal and Modulo Addition, which contribute little to the central research question.\n- Insufficient theoretical depth: The paper’s arguments about regularization effects and “usable information” remain qualitative and speculative. No formal analysis (e.g., entropy measures, mutual information, or bias–variance trade-offs) is provided to support the claimed advantages of discretization.\n- Limited comparative analysis: Although several baselines are included, the main comparison is conducted with the lognormal mixture models; other models are covered superficially. The discussion does not explore why categorical heads succeed or fail under different conditions, except for a couple of concrete examples.\n- Missing sensitivity and ablation studies: The method’s dependence on the number of bins, binning strategy, and dataset properties (e.g., presence of discrete peaks) is not analyzed. Without this, it is unclear how generalizable or robust the approach is across domains.\n- Poor presentation quality: The writing is fragmented and difficult to follow. Figures, particularly Figure 11, are confusingly organized and under-labeled, making interpretation challenging. The discussion of results is mostly descriptive rather than analytical.\n- Reproducibility issue: Although the paper explicitly states that it provides supplementary code and datasets for full reproducibility, I was unable to find the link in the submission. Given that reproducibility is one of the claimed strengths, the absence of an accessible codebase substantially undermines the credibility of the results."}, "questions": {"value": "- Reproducibility: You mention that supplementary code and datasets are provided for all experiments, but I was unable to find a repository link or reference in the submission. Could you kindly clarify where the code and data will be available?\n- Sensitivity to bin count: How does the model’s performance depend on the number of categorical bins? Is there a principled way to choose this number based on dataset characteristics?\n- Generalization boundaries: For which types of datasets (e.g., continuous vs. discrete, unimodal vs. multimodal) do you expect the categorical output to perform best? Have you tested cases where discretization could harm performance?\n- Relation to existing methods: Could you discuss how your approach compares empirically and conceptually with other modern neural TPPs, except for the lognormal mixture families, such as Neural Hawkes Processes, RMTPP, THP, Neural ODE-based, or diffusion-based TPPs?\n- Regularization hypothesis: You argue that different output structures act as implicit regularizers. Your work would benefit from quantitative evidence (e.g., learning curves, entropy of predicted distributions, or generalization gaps) supporting this claim.\n- Theoretical grounding: The paper frequently uses the term “usable information” without a formal definition. Could you possibly connect this concept to established measures (e.g., mutual information)?\n- Section relevance: How do the Metropolis Lognormal and Modulo Addition datasets sections connect to validating the categorical approach? They seem to be only weakly related to the main hypothesis. Could you elaborate on how these experiments strengthen your central claim?\n- Computational aspects: How does the categorical formulation affect training speed and memory compared to mixture-based models? Based on your experience, is the categorical head not only more stable but also more efficient?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "LdGBKGimZ4", "forum": "QIpMLMnAxh", "replyto": "QIpMLMnAxh", "signatures": ["ICLR.cc/2026/Conference/Submission7466/Reviewer_uxbv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7466/Reviewer_uxbv"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7466/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762004876624, "cdate": 1762004876624, "tmdate": 1762919581257, "mdate": 1762919581257, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}