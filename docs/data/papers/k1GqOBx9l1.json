{"id": "k1GqOBx9l1", "number": 18939, "cdate": 1758292175978, "mdate": 1762949719207, "content": {"title": "Multi-Modality Brain Disease Prediction with  Progressive Curriculum Graph Learning", "abstract": "Recently, graph-based multi-modality learning approaches have been studied to handle multi-modality medical brain data analysis. \nAlthough they have achieved some promising performance, they still suffer from two main issues. First, current works generally fail to capture the inherent relationships of subjects (samples) from both feature and semantic/label perspectives. Second, for brain disease prediction tasks, the number of modalities is usually large (usually more than 4) and existing methods generally employ simple multi-modal fusion techniques that fail to carefully capture the dependencies of different modalities. To address these issues, this paper proposes a novel approach for multi-modality brain disease prediction by developing curriculum multi-modality learning. Our approach stems from observing that multi-modality learning becomes more challenging as the number of modalities increases, while recognizing curriculum learning as providing an explicit mechanism for tackling easy-to-hard learning tasks. This motivates us to propose a new progressive multi-modality learning strategy by leveraging the curriculum learning pipeline. Specifically, we first propose to dynamically learn a context-graph representation by jointly modeling the relationships of subjects from both feature and semantic label cues. Then, we propose a new multi-modality brain data representation by employing progressive curriculum learning. Experiments demonstrate the advantages of the proposed curriculum multi-modality learning strategy.  The code of our method will be released upon acceptance.", "tldr": "We propose a novel unified framework for multi-modality brain disease prediction, which integrates the curriculum learning with dual graph convolution to better serve the feature representation learning within and between modalities.", "keywords": ["Multi-Modality Learning", "Multi-Modality Brain Disease Prediction", "Context-Graph Representation", "Curriculum Learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/ef4e00ac5c141f560ef26d42a705f54a6c1ce754.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a curriculum based learning + multimodal graph based framework (using both feature and label graphs) for brain disease prediction. Experiments demonstrate slight advantages over previous techniques."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Well-specified architecture: dual-relational context graph with learnable feature edges and a label-edge branch, clear loss function equations and modules are concretely presented. \n\n- Progressive multi-modality curriculum pipeline with inter-modality attention is laid out with equations and an explicit label-smoothing curriculum is shown.\n\n- Competitive main results with ablation studies showing benefits of curriculum learning."}, "weaknesses": {"value": "- The paper claims that the task becomes harder with more modalities, but this is not strongly supported. Furthermore, random order vs proposed order of modalities isn't tested. \n\n- Table 2 shows large improvements from MMCL, but LE adds very little gains. Since no statistical significance tests are reported, it's difficult to justify that the label-graph is necessary.\n\n- Despite being claimed as a \"general scheme which can be applied for various multi-modality learning with many modalities\", only two datasets are tested, and both are within the same domain. To bolster this claim, maybe test on  datasets outside of brain disease prediction.\n\n- This is a general issue I've spotted in this research area: cross-paper comparability is very unclear. While you use 10-fold CV and processed datasets, the paper does not say whether prior fold indices (e.g. MMGL, MGDR) are reused."}, "questions": {"value": "See weaknesses.\n\nAdditionally:\n\n- With regard to l71, why do existing graph-based or cross attention approaches suffer from increasing the number of modalities? Is there a difference in computational cost? If so, what is the computational cost of this framework?\n\n- How does the visualisation of T-SNE add evidence? This is a very weak and configuration sensitive indicator. I suggest changing the phrasing to show this is for visualisation purposes only and doesn't necessarily add evidence."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "60FqWDqFuo", "forum": "k1GqOBx9l1", "replyto": "k1GqOBx9l1", "signatures": ["ICLR.cc/2026/Conference/Submission18939/Reviewer_PqDj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18939/Reviewer_PqDj"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18939/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761428713620, "cdate": 1761428713620, "tmdate": 1762930996434, "mdate": 1762930996434, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "B7XcZc0fPG", "forum": "k1GqOBx9l1", "replyto": "k1GqOBx9l1", "signatures": ["ICLR.cc/2026/Conference/Submission18939/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18939/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762949718095, "cdate": 1762949718095, "tmdate": 1762949718095, "mdate": 1762949718095, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel framework for multi-modal brain disease prediction, designed to address two persistent challenges in the field: the suboptimal integration of feature- and label-based subject relationships, and the difficulty of fusing an increasing number of data modalities. The authors propose a synergistic approach that combines a \"Dynamical Context-Graph Representation\" with a \"Multi-Modality Curriculum Learning\" (MMCL) strategy. The context-graph jointly models relationships between subjects based on their intrinsic data features and semantic class labels, creating a rich substrate for a custom Dual Graph Convolutional Network (DGCN). The core innovation, however, is the MMCL module, which reframes curriculum learning from a progression of easy-to-hard data samples to an easy-to-hard progression of data modalities. The model is trained by progressively increasing the number of modalities from one to many, which is hypothesized to facilitate a more robust fusion of complex, high-dimensional data. The authors validate their method on the public ABIDE and TADPOLE datasets, reporting that it achieves state-of-the-art performance against a comprehensive suite of baseline models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The conceptualization of curriculum learning for modality fusion is novel and interesting, from sample-based progression to modality-based progression.\n2. The main experiments are comprehensive. The authors validate their framework on two public benchmarks against an extensive suite of eleven baseline methods."}, "weaknesses": {"value": "1. The empirical results do not fully substantiate the claim of achieving the new state-of-the-art performance. The performance gains over the best-performing baseline methods are marginal. Considering the standard deviations, the proposed method seems to achieve performance that is statistically comparable (using t-test) to the state-of-the-art baselines (Table 1).\n2. Similar to Table 1, if considering the standard deviations, it’s hard to justify the contributions of each model component (Table 2), or the performance gains of some more complex additions (Tables 3 & 4).\n3. The framework defines its \"easy-to-hard\" curriculum based on the quantity of modalities rather than their intrinsic difficulty, progressing from a single source to many. This design makes the model's performance contingent on the sequential order of modality introduction. Yet, the paper fails to specify the sequence used or analyze the model's sensitivity to this critical variable. This omission represents a significant methodological gap, as the arbitrary choice of the initial modality could create a path dependency that influences the final learned representation and predictive outcome.\n4. The description of the training protocol is ambiguous, particularly regarding the implementation of the multi-stage curriculum loss function. Also, there is a lack of hyperparameter sensitivity analysis.\n5. The DGCN architecture employs a single set of learnable weight parameters, shared across both feature- and label-propagation branches. This design choice implicitly assumes that the optimal transformation for aggregating neighborhood information is identical for two semantically and structurally distinct graphs: one based on dynamic feature similarity and the other on static class identity. This is a strong constraint that may be suboptimal.\n6. The Multi-Modality Curriculum Learning (MMCL) module incorporates a label smoothing schedule where the smoothing factor, $\\alpha$, is designed to increase as more modalities are introduced. This hard-codes the assumption that task difficulty invariably increases with the number of modalities. This heuristic may not be universally valid; the addition of a highly discriminative modality could, in fact, simplify the classification task, in which case a less-smoothed, more confident predictive distribution would be more appropriate. The schedule's inflexibility prevents the model from adapting to the actual information content of the fused modalities."}, "questions": {"value": "Please see the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8hG8P8oQN5", "forum": "k1GqOBx9l1", "replyto": "k1GqOBx9l1", "signatures": ["ICLR.cc/2026/Conference/Submission18939/Reviewer_zpRB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18939/Reviewer_zpRB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18939/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959737708, "cdate": 1761959737708, "tmdate": 1762930996011, "mdate": 1762930996011, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors point out that existing approaches for multi-modal brain data analysis primarily focus on graph construction while overlooking the label perspective. They also note that as the number of modalities increases, learning becomes challenging due to the heightened model complexity.\n\nTo overcome these limitations, the proposed method introduces a context-graph, where the adjacency matrix is computed based on feature similarity across modalities and further optimized using a Dirichlet energy function. In addition, another adjacency matrix is constructed to connect nodes that share the same label. Feature representations are then refined through a Dual Graph Convolution Module, which updates modality-specific representations and combines them through summation.\n\nFurthermore, the authors propose a multi-modality curriculum learning strategy that progressively enhances the interaction among different modalities during training.\n\nThrough experiments in the TADPOLE and ABIDE datasets, the authors demonstrate the effectiveness of the proposed method."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The authors propose a novel method that enforces smoothness on the graph from both the feature and label perspectives.\n\n- The introduction of curriculum learning is a sound and effective strategy to address the complexity of multi-modal data learning."}, "weaknesses": {"value": "- Despite the methodological complexity, the performance improvement achieved by the proposed approach appears incremental.\n\n- In Figure 2, the performance gap narrows significantly as the labeled ratio decreases. Given that biological labels are typically scarce, this represents a substantial limitation.\n\n- A sensitivity analysis (e.g., on the parameter β) is missing and should be provided to assess the model’s robustness."}, "questions": {"value": "- Since the reported performance improvement is relatively modest, the authors are encouraged to present additional advantages of the method, such as computational efficiency or reduced training time.\n\n- One possible reason for the reduced performance gap at low labeled ratios could be the reliance on the label-based graph. To validate this, the authors should perform an ablation study under the 10% labeled setting by removing the label graph, thereby isolating the contribution of the other components."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "AQScp42p5b", "forum": "k1GqOBx9l1", "replyto": "k1GqOBx9l1", "signatures": ["ICLR.cc/2026/Conference/Submission18939/Reviewer_xuFi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18939/Reviewer_xuFi"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18939/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991276316, "cdate": 1761991276316, "tmdate": 1762930995643, "mdate": 1762930995643, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}