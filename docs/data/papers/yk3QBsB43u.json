{"id": "yk3QBsB43u", "number": 21298, "cdate": 1758316009712, "mdate": 1759896930058, "content": {"title": "Tackling the Noisy Elephant in the Room: Label Noise-robust Out-of-Distribution Detection via Loss Correction and Low-rank Decomposition", "abstract": "Robust out-of-distribution (OOD) detection is an indispensable component of modern artificial intelligence (AI) systems, especially in safety-critical applications where models must identify inputs from unfamiliar classes not seen during training. While OOD detection has been extensively studied in the machine learning literature—with both post hoc and training-based approaches—its effectiveness under noisy training labels remains underexplored. Recent studies suggest that label noise can significantly degrade OOD performance, yet principled solutions to this issue are lacking. \nIn this work, we demonstrate that directly combining existing label noise-robust methods with OOD detection strategies is insufficient to address this critical challenge. To overcome this, we propose a $\\textit{robust}$ OOD detection framework designed to $\\textit{cleanse}$ feature embeddings, thereby mitigating the adverse effects of noisy labels on OOD performance. Towards this, we introduce an end-to-end training strategy that integrates loss correction methods from the noisy-label learning literature with low-rank and sparse decomposition techniques from signal processing.  Building on this strategy, we derive a novel metric that quantifies the “OOD-ness” content within training data, which in turn leads to a label noise-robust OOD detection scoring technique. \nExtensive experiments on both synthetic and real-world datasets demonstrate that our method significantly outperforms the state-of-the-art OOD detection techniques, particularly under severe noisy label settings.", "tldr": "", "keywords": ["out-of-distribution detection", "noisy labels", "robust learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4cc6247aafb62e6c08393ded3f459f354d386f88.pdf", "supplementary_material": "/attachment/324d1953d2ad0710af08ade06744f62d1a0cf077.zip"}, "replies": [{"content": {"summary": {"value": "This paper studies the problem of OOD detection under noisy labeled datasets. The algorithm utilizes established loss functions that are made for noisy label classification and further regularizes the loss by an intuition on the separability of ID and OOD features. Experiments on training DenseNets from scratch on the synthetic and naturally noisy CIFAR-10 datasets outline successful results."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is easy to read and follow. The experimental results of the paper seem strong. The problem is well motivated."}, "weaknesses": {"value": "Although the problem is well-motivated, the solution is not. That is, although the authors reference to Fig 1 to establish their intuition for the effect of noise on OOD performance, I can't follow their argument completely. Mainly that the OOD vs ID classes are generally distinguishable in all the figures.\n\nThe authors do not address the added complexity for their regularization and do not mention how much this algorithm increases training time.\n\nThe section on 'Low-rank plus Sparse Decomposition' is not well written and cause confusion. The authors need to improve the exposition of this section to clear any confusion.\n\nThe tables are hard to understand by themselves and this stems from questionable experimental setups. The tables should have further dividers for methods that are aware of the noisy label setup vs those that are not.\n\nID accuracies for table 1 are not provided.\n\nThe fact that the NOODLE rows are not with a constant loss function or constant score is concerning. That is, the authors seem to experiment with all the noise-aware losses for their NOODLE method and choose the best one to report. This is not a good fair experiment.\n\n\nThe methodology is for training from scratch. Given the prevalence of using pre-trained models, it is perhaps more important these days to look at methods and experiments that work on such pre-trained models. \n\nMoreover, it could be interesting to see results on ViTs as well.\n\nFinally, there are certain baselines that are missing. For example, LINe [1] is a post-hoc method that seems to perform well in many scenarios, at least in the absence of noise. Similarly, there are many works that utilize OOD data during training  like [2] and [3] that could also be interesting to compare with. For a more extensive list please see [https://github.com/Jingkang50/OpenOOD](https://github.com/Jingkang50/OpenOOD).\n\n\n[1] Ahn YH, Park GM, Kim ST. Line: Out-of-distribution detection by leveraging important neurons. In 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2023 Jun 17 (pp. 19852-19862). IEEE.\n\n[2] Sharifi S, Entesari T, Safaei B, Patel VM, Fazlyab M. Gradient-regularized out-of-distribution detection. InEuropean Conference on Computer Vision 2024 Sep 29 (pp. 459-478). Cham: Springer Nature Switzerland.\n\n[3] Jiang W, Cheng H, Chen M, Wang C, Wei H. Dos: Diverse outlier sampling for out-of-distribution detection. arXiv preprint arXiv:2306.02031. 2023 Jun 3."}, "questions": {"value": "I can not understand some results as they don't seem to make sense. Specifically, Tables 3,4,5, and 6. For example in Table 3, Noise=worst has a noise level of around 40%, yet most algorithms have an accuracy of around 80%. How does this work? Same question for the other tables."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LfrJemqP4J", "forum": "yk3QBsB43u", "replyto": "yk3QBsB43u", "signatures": ["ICLR.cc/2026/Conference/Submission21298/Reviewer_kwRU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21298/Reviewer_kwRU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21298/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760474043422, "cdate": 1760474043422, "tmdate": 1762941679253, "mdate": 1762941679253, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this work, the authors aim to improve the robustness of OOD detection methods to label noise. To this end, they introduce a novel  NOODLE training framework, consisting of a loss correction module, a decomposition of the pre-logit feature matrix, and a distance-based OOD detector paired with a novel scoring function."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well written and well-structured. The method is clearly motivated. Addressing the robustness of OOD detectors is a potentially important and overlooked task. Observing that robustness to noisy labels might be different for feature-based OOD detectors than for classification tasks is insightful. The paper reports strong gains in the considered setup (more on the setup in weaknesses)."}, "weaknesses": {"value": "1. Experimental Setup:  \nThe major weakness of this paper is its experimental setup. Almost all presented experiments are done on (a variant of) Cifar10, with a DenseNet, which is outdated for todays standards. The paper does not consider large-scale setups (ImageNet and beyond), varied pretraining schemes, a range of model architectures (including ViT variants), as is standard in current works (e.g. https://arxiv.org/pdf/2503.08023, https://arxiv.org/abs/2505.18032, …). This is likely connected to the fact that the proposed method is a train-time method that requires training from scratch, and has potentially llimited scalability (more on this below). Further, the selection of OOD detection baselines misses important recent work: (FDBD [1], ViM[2], Maha++ [3], Neco[4], AdaScale[5], RMD[6], NNguide[7], …). \n\n2. Scalability:  \nI have concerns regarding the scalability of the method. In the text, the authors describe that the proposed method requires decomposing the entire training feature matrix (DxN, with N the total number of training samples). In Algorithm 1, H is also written as the full feature matrix [h(x1), …, h(xN)], but there is also a comment that the features are only from batch B. Therefore it is unclear to me whether the full feature matrix needs to be decomposed for every gradient update or only the feature matrix corresponding to the current batch. In both cases, I suspect significant scalability issues for large datasets or datasets with many classes / large feature dimensions. In the latter case, I also expect dependencies on the batch size. \n\n3. Score Construction:  \nThe authors write that “larger [OOD-ness] scores indicate greater deviation... (e.g., noisy or ambiguous samples), while smaller scores correspond to clean, representative ID examples”. Instead of using the most representative examples, they chose the most challenging ones from the train set (with largest OOD score), and compute the distance to those examples as OOD score. This implies the detector's reference set is built from the noisiest, most ambiguous samples, which is counter-intuitive. This is either an error in the text or a (poorly explained) idea that requires justification - I cannot immediately see why this choice would be “robust”. If the OOD-ness score indeed measures OOD-ness, why not use it directly for OOD detection? It seems to be similar to a residual score, as used in ViM [2] or Neco [4].\n\n4. Hyperparameters:  \nThe method introduces several new hyperparameters (lambda, K, p). Table 7 shows that the method is quite susceptible to changes in lambda (comparing e.g. SVHN and iSUN with lambda = 0.0001 and lambda=0.0005). There is no ablation on K, which likely has a strong impact, especially when transferring to other ID datasets (the mixed results on CIFAR100 indicate this already). \n\n\n5. More remarks:  \n- on CIFAR100 NOODLE brings little advantages over just using CM or SCE (Fig 5). Given that CIFAR100 is an extremely similar dataset to CIFAR10, I expect even stronger deviations for other (larger) datasets\n- CM and SCE are used but never properly introduced. Overall, the loss correction paragraph is not well explained\n- Figure 1: Even though the ID clusters are less separated, there is still a pretty good separation between ID and OOD clusters. It is thus unclear to me why the FPR changes so much. \n- The ID accuracy for NOODLE is always higher than for baseline methods (even for clean data there is a difference of 5\\%, Table 3), which raises the question if the baseline methods were properly tuned, or NOODLE potentially overfitted by tuning the hyperparameters\n- CIDER and SSD+ have suspiciously low ID accuracy (Table 3), and it is surprising that they are so much worse than regular Mahalanobis and KNN\n\n\nTypos: \n\n359 Energy method (“The” missing)\n\n362 CIDAR instead of CIDER \n\nAlgorithm 1: missing ref in line 733, two while statements\n\n225: most columns has (have)\n\n227 do / does\n\n228 solving an optimization problem\n\n[1] Liu, L. and Qin, Y. Fast decision boundary based out-of-distribution detector. ICML, 2024. \n\n[2] Wang, H., Li, Z., Feng, L., and Zhang, W. Vim: Out-of-distribution with virtual-logit matching. In CVPR, 2022. \n\n[3] Müller and Hein, Mahalanobis++: Improving OOD Detection via Feature Normalization, ICML 2025\n\n[4] Ammar, M. B., Belkhir, N., Popescu, S., Manzanera, A., and Franchi, G. NECO: NEural collapse based out-of-distribution detection. In The Twelfth International Conference on Learning Representations, 2024. \n\n[5] Sudarshan Regmi, AdaSCALE: Adaptive Scaling for OOD Detection, arxiv preprint: https://arxiv.org/abs/2503.08023, 2025\n\n[6] Ren, J., Fort, S., Liu, J., Roy, A. G., Padhy, S., and Lakshminarayanan, B. A simple fix to mahalanobis distance for improving near-ood detection, 2021. \n\n[7] Park, J., Jung, Y. G., and Teoh, A. B. J. Nearest neighbor guidance for out-of-distribution detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision"}, "questions": {"value": "The core assumption of the method is that the feature matrix H can be decomposed into a low-rank component L and a sparse component S. The sparse component is thought to model “outliers”. However, to me it seems there are two different variants of outliers: ID samples with noisy labels, and OOD samples. Why would S (or H-OOD) capture both noisy labels and OOD samples as a single sparse component in a sensible way?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "koZ4BiN3u6", "forum": "yk3QBsB43u", "replyto": "yk3QBsB43u", "signatures": ["ICLR.cc/2026/Conference/Submission21298/Reviewer_v1hQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21298/Reviewer_v1hQ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21298/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761205845696, "cdate": 1761205845696, "tmdate": 1762941678909, "mdate": 1762941678909, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes the *NOODLE* framework, which purifies feature embeddings by integrating loss correction with low-rank sparse decomposition. And one OOD score is introduced to quantify \"OOD-ness\" content in training data, thereby computing robust OOD detection scores. Extensive experiments demonstrate that NOODLE achieves strong OOD detection performance when the training data contains noise."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. OOD detection is important for safety-critic applications of machine learning models. \n2. The setting of OOD detection under noisy training labels is both practical and interesting.\n3. Extensive experiments demonstrate the efficacy of the method."}, "weaknesses": {"value": "1. The effectiveness of NOODLE: Since NOODLE requires SVD to compute singular vectors for the Low-rank plus Sparse Decomposition, its computational efficiency is still a concern. Although the authors claim the acceleration via power iteration, the computational cost of this method is still very high due to the typically high dimensionality of the feature matrix.\n2. Compatibility issues with logit-based methods: The paper's experimental setup does not include testing logit-based post-hoc methods (e.g., MSP) on the fine-tuned model, as it only uses KNN as the post-hoc score. Therefore, it remains an open question whether this fine-tuning degrades the performance of logit-based methods.\n3. Lack of OOD detection evaluation on the clean-label setting: While the paper's primary focus is on the noisy-label training setting, this setting's practical applicability is limited by the difficulty of assessing noise levels in the real world. (We commend the authors for their setup of different noise levels in the main experiments.) The paper would be more solid if it also included an evaluation on clean training datasets. This would verify the score's baseline effectiveness in a conventional setting and enhance the paper's completeness.\n4. Lack of comprehensive experiments: The experiments were performed with only CNN architecture (The inclusion of experiments on ViT would strengthen the paper's claims). And no experiments were carried out on the ImageNet benchmark, which is more challenging for OOD detection.\n5. Lack of comprehensive comparison: A number of recent related works have not been compared in the paper, e.g., [1], [2], and [3].\n6. Questions Regarding Some Test Results: As shown in Table 3 of the Appendix, the ID accuracy of CIDER and SSD+ is particularly low, which suggests that its hyper-parameters may not have been properly tuned.\n\n[1] Haoqi Wang, Zhizhong Li, Litong Feng, and Wayne Zhang.Vim: Out-of-distribution with virtual-logit matching. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022.\n\n[2] Yue Song, Nicu Sebe, and Wei Wang. Rankfeat: Rank-1 feature removal for out-of-distribution detection. Advances in Neural Information Processing Systems, 35:17885–17898, 2022.\n\n[3] Yue Song, Wei Wang, and Nicu Sebe. Rankfeat&rankweight: Rank-1 feature/weight removal for out-of-distribution detection. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2024."}, "questions": {"value": "Please see the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mnRG2OQ5JB", "forum": "yk3QBsB43u", "replyto": "yk3QBsB43u", "signatures": ["ICLR.cc/2026/Conference/Submission21298/Reviewer_udQU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21298/Reviewer_udQU"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21298/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761894289576, "cdate": 1761894289576, "tmdate": 1762941678609, "mdate": 1762941678609, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the problem of out-of-distribution (OOD) detection under the presence of label noise. It introduces a framework named NOODLE, which integrates loss correction techniques from noisy-label learning with a low-rank plus sparse decomposition module for feature-level denoising. The method also defines an “OOD-ness” score to measure the deviation of samples from the in-distribution subspace and employs this score for robust distance-based OOD detection. Experiments are conducted on both synthetic and real-world noisy datasets, including CIFAR-10N, CIFAR-100N, and Animal-10N, covering various noise rates and OOD benchmarks.The results include comparisons with standard OOD detection methods and noise-robust learning baselines, as well as ablation studies on different combinations of loss correction and scoring metrics."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The work is among the first to systematically study OOD detection under noisy-label supervision. The paper clearly articulates why label noise degrades OOD performance.\n2. The low-rank + sparse decomposition idea is elegant and conceptually well-motivated: enforcing low-rank structure recovers class-consistent subspaces, while sparse residuals capture noise and anomalies.\n3. Clarity and Writing:The paper is well-organized and readable."}, "weaknesses": {"value": "1. Applicability of the Low-Rank Assumption.\nThe proposed method fundamentally relies on the assumption that class-conditional feature representations are approximately low-rank.\nHowever, this assumption may not hold for fine-grained or multimodal datasets (e.g., ImageNet or text-based tasks).\nIt is recommended to evaluate the robustness of the method in more complex or diverse scenarios.\n2. Lack of Theoretical Analysis.\nAlthough the paper provides an intuitive explanation, it lacks theoretical justification for how the low-rank decomposition improves ID–OOD separability.Incorporating a concise theoretical discussion.\n3. Limited Ablation and Comparative Analysis.\nWhile the experimental results convincingly demonstrate the overall effectiveness of NOODLE, the analysis remains somewhat superficial.\nThe paper mainly reports aggregate performance metrics (FPR95 / AUROC) without deeper ablation to isolate the contribution of each component.\nFurthermore, there is no direct comparison with recent robust OOD methods (e.g., ReAct, CSI,CIDER,) under label noise, which would more clearly establish NOODLE’s advantage in this specific setting.\nFinally, the paper does not report training stability or computational cost associated with the low-rank decomposition, which would be valuable for assessing practicality."}, "questions": {"value": "1. How stable is the low-rank decomposition (PI-based) during training? Is it recomputed per epoch or per batch? What is its computational overhead relative to baseline methods?\n2. Have you tried applying NOODLE on large-scale noisy datasets (e.g., WebVision, Clothing1M)?\n3. Could the OOD-ness score be used as an auxiliary regularizer or confidence measure during training rather than only for post-hoc filtering?\n4. What happens under asymmetric or instance-dependent noise models? Would the framework generalize naturally?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zVCZ3sYOM4", "forum": "yk3QBsB43u", "replyto": "yk3QBsB43u", "signatures": ["ICLR.cc/2026/Conference/Submission21298/Reviewer_8YkH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21298/Reviewer_8YkH"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21298/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761916990944, "cdate": 1761916990944, "tmdate": 1762941678297, "mdate": 1762941678297, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}