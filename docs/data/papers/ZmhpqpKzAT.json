{"id": "ZmhpqpKzAT", "number": 7297, "cdate": 1758014655660, "mdate": 1759897861373, "content": {"title": "IGC-Net for conditional average potential outcome estimation over time", "abstract": "Estimating potential outcomes for treatments over time based on observational data is important for personalized decision-making in medicine. However, many existing methods for this task fail to properly adjust for time-varying confounding and thus yield biased estimates. There are only a few neural methods with proper adjustments, but these have inherent limitations (e.g., division by propensity scores that are often close to zero), which result in poor performance. As a remedy, we introduce the iterative G-computation network (IGC-Net). Our IGC-Net is a novel, neural end-to-end model which adjusts for time-varying confounding in order to estimate conditional average potential outcomes (CAPOs) over time. Specifically, our IGC-Net is the first neural model to perform fully regression-based iterative G-computation for CAPOs in the time-varying setting. We evaluate the effectiveness of our IGC-Net across various experiments. In sum, this work represents a significant step towards personalized decision-making from electronic health records.", "tldr": "We develop a novel neural method that performs G-computation in an iterative end-to-end training algorithm for conditional average potential outcome estimation over time.", "keywords": ["causal inference", "potential outcomes", "treatment effects", "healthcare"], "primary_area": "causal reasoning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/270eed7e86e712771bfef394a122d0c846ae8a90.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes IGC-Net, a neural network approach for estimating conditional average potential outcomes (CAPO) over time in the presence of time-varying confounding. The key contribution is a fully regression-based iterative G-computation method that avoids the instabilities associated with inverse probability weighting when propensity scores are close to zero. The methodology uses a clever forward-generation approach with neural networks (LSTM or transformer) to approximate sequential conditional expectations through pseudo-outcomes. The paper includes both semi-synthetic experiments based on MIMIC-III data and real-world validation, demonstrating improved performance over existing methods, particularly under strong confounding."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "## Strengths\n\n1. **Excellent presentation and writing**: The introduction and related work sections are very well written, providing clear context and concrete problem motivation. The mathematical framing, particularly Equation 2, makes the problem formulation clear and accessible.\n\n2. **Strong methodological foundation**: The sequential recursive formulation (Equations 6 and 7) is smart and theoretically sound, using conditional expectation projections from the remote future into the present. The approach is intuitive and properly grounded in causal inference principles.\n\n3. **Effective problem motivation**: Table 1 does an excellent job showcasing the limitations of existing methods and positioning the contribution. The paper clearly articulates why inverse probability weighting methods fail under strong confounding.\n\n4. **Comprehensive evaluation**: The paper includes both semi-synthetic and real-world MIMIC-III data (Supplement E), providing strong empirical validation. The results consistently demonstrate that the method works well, particularly when confounding strength is higher.\n\n5. **Good ablation studies**: Testing both transformer and LSTM backbones provides useful insights into model architecture choices."}, "weaknesses": {"value": "1. **Identifiability concern**: The main weakness is the lack of discussion about empirical identifiability of pseudo-observations across different random initializations (not the theoretical identifiability or SUTVA). If two IGC-Net instances with different initializations give the same g_{t+tau} but very different intermediate pseudo-observations at t+delta (delta < tau), the interpretation of conditional expectations becomes questionable. The paper addresses theoretical identifiability (SUTVA-like assumptions) but not the practical identifiability of neural network approximations.\n\n2. **Limited treatment flexibility**: The setup only considers binary treatments, which may not align well with MIMIC-III data where emergency room interventions are typically not binary. The paper lacks discussion on extending to multi-valued or continuous treatments.\n\n3. **Missing interpretability discussion**: Given the conservative nature of clinical applications, there should be discussion about interpretability trade-offs. Even when neural networks provide better accuracy, clinicians often prefer logistic regression for its transparency and explainability.\n\n4. **Presentation issues**:\n   - Figures 6 and 7 in supplement are too busy and difficult to read\n   - Abstract should mention the use of synthetic MIMIC-III data\n   - Should add a sentence explicitly stating that real-world data confirms the findings (currently only in supplement)\n\n5. **Ablation analysis implication**: While the paper shows transformer performs slightly better than LSTM, there's insufficient discussion of why this is the case and what this tells us about the method. Is it because transformers are better at generative tasks while LSTMs are better at prediction?\n\n6. **Unexplored training alternatives**: The paper doesn't discuss why intermediate-step training (using y_{t+delta} for delta < tau with actual outcomes rather than pseudo-outcomes) wasn't considered or wouldn't work. \n\n## Minor Issues\n\n- The observation about CT and TE-CDE (2022) lacking proper adjustments while older methods like RMSN (2018) and G-Net (2021) have them is interesting but not discussed\n- No discussion on whether more powerful pre-trained generative models could improve results"}, "questions": {"value": "I have listed structured questions (with help of LLM) in the above weakness part. I am going to say here my honest thoughts when reading the paper as it presents, and hopefully this can help you understand how a new reader perceives your paper. These raw feelings are genuine and I hope they provide a more human-to-human communication and contexts for the structured question above.\n\n\n\n# Review of Paper 7297: IGC-Net for Conditional Average Potential Outcome Estimation\n\n## Initial Impressions on abstracts\n\nThis is a paper on IGC-Net for conditional average potential outcome estimation over time. The main problem addresses potential outcomes over time when confounding can be time-varying. The paper proposes a neural network for proper adjustment of time-varying confounding. I agree with the claim that not dividing by the propensity score creates limitations and instability when the propensity score is often close to 0. The estimation focuses on conditional average potential outcomes, which is fine.\n\nThe paper claims to be the first to perform fully regression-based iterative G-computation for CAPO in a time-variant setting. I think this section can be improved—I don't understand why performing the full regression iterative G-computation method is significant. The evaluation is based on experiments, and while we have experiment-based evaluation, I need to look at the simulation setting more carefully. Also, for ICLR conferences, it would be good to have real-world data. Since this is treatment over time, I imagine MIMIC-III data would be a good fit.\n\n## Table 1 Analysis\n\nI'm not following the literature too closely on neural network-based estimation, but Table 1 is actually very good at showcasing the problem. One thing I'm curious about: why do CT and TE-CDE, which are more recent, lack proper adjustments, whereas RMSN and G-Net in Table 1 are further away in the past but have proper adjustments? This is a very interesting observation. I have not read the literature review of those papers (CT, TE-CDE), so I don't know the full context. The CT paper and the TE-CDE paper are from 2022, the RMSN paper is from 2018, and the G-Net paper is from 2021.\n\n## Introduction\n\nI have general knowledge about causal inference. For the last paragraph, it would be good if you could explain a little bit about what G-computation is so that I don't have to Google it again. I just happen to be more familiar with the terminology from Don Rubin rather than James Robins.\n\nThe introduction is really good. It paints a clear picture of the field and its limitations—a very concrete problem it's trying to address. One thought: there is actually good reason for there not being many developments related to neural networks for causal inference. First, on clean tabular data, tree-based models have higher popularity. Second is interpretability. If you're using a clinician observational study dataset from EHR, even logistic regression is better understood—it's explainable and more transparent. Even when logistic regression performs worse (say, within 10% compared to neural networks), a clinician would tend to use logistic regression. It's just the conservative nature of humans—nothing we can do about that. I think it's still worthwhile to pursue this type of research using neural networks because accuracy is important. I'm just curious whether the authors have any discussion on this later. (Hey I came back from future, and the authors don’t have discussion on interpretability)\n\n## Related Work\n\nIn the related work section, line 83 mentions a group of methods is not working, and I am convinced based on the narrative. I then flipped to the numerical example section and indeed saw that when the confounding strength is higher, the mentioned approach suffers higher bias. This is good validation. I also realized it's using MIMIC-III synthetic data, which answers my question from when I was reading the abstract. You should mention that in your abstract.\n\nThe related work is excellent—really well written. It tells me what's the problem with inverse probability weighting IPW and defers to a later proposition. But it's a known problem, so I would completely trust that.\n\n## Setup and Methodology\n\nIn the setup, only binary treatment is considered. As I recall, MIMIC-III probably doesn't have binary treatment data for emergency room interventions, but it's okay for now. I'm curious if there's a discussion later on treatment that is more than just binary.\n\nThe setup and estimation tasks are all excellent. Line 126 on identifiability is very good—it's standard and very thoughtful to include those assumptions. Line 137 is correct about future potential confounding, and the explanation placed here is really good.\n\nI really like Equation 2. Causal inference is all about mathematical framing, and Equation 2 makes the problem very clear. It would be good to explain how Equation 3 differs from Equation 2. After staring at it, I see it's basically adjusted by the probability of the “A” distribution. I understand that Supplement C has this formula. This looks intuitively right, so I wouldn't check it, but it would be helpful—I'm just being lazy—if you could still explain the intuition here.\n\nThis is a very good presentation. When I look at Equation 3, I would think a naive or straightforward approach is just through integration, and then it's pointed out that the integration has this distributional estimation problem. Very intriguing.\n\n## Pseudo Outcomes and Methodology\n\nIn line 173, you use \"low variance pseudo outcome.\" I'll need to read more, but one thing I was thinking when I read this was: in general, it is not great to look at the future Y variable when you're developing the causal method. I'm curious to see how you make that happen. In what sense is the outcome \"pseudo\"?\n\nThe iterative regression in line 180 is intuitively right. In causal inference, we use sequential, carefully constructed regression as an estimation vehicle. That is a very standard technique. Very nice opening to Section 4 at line 184.\n\nEquations 6 and 7 are smart. They're basically regression, looking at the conditional expectation, gradually projected down from the remote future into the present. Because of the conditional expectation property, of course, it's unbiased. The sequential recursive formula is basically a sequential projection.\n\nLine 222 is where I first became not crystal clear about how it is being done. How is your pseudo-data generated? Shouldn't it just be a natural projection down? Why does that generate predictions? So interesting. Rather than the true mathematical way of keep projecting from the future to present, the learning actually reverses that. Like data assimilation, you generate the future step, keep generating. And then after generating the tau steps, you produce the loss, matching this generated tau-step-ahead with the actual Y. And therefore, that's why you use neural networks as an approximator. Otherwise, before line 225, you don't really need neural networks yet. The math is tight for backward recursion, but computationally prohibitive. Line 225 introduces a neural network forward-generator to that true conditional expectation.\n\n## Training Questions\n\nThat brings me to a question about this training. If you are generating t+tau steps ahead and then doing the regression, what if I generate just delta steps ahead (delta smaller than tau), and then do the regression of y_{t+delta} directly, not using the pseudo outcome but using the actual outcome to match the generated pseudo outcome? Is it because it actually has the realization, so it fails to be a proper projection from step y_{t+tau}? Is that why you didn't do that?\n\nYou are using LSTM or transformer. I would say a transformer or using pre-trained generators from existing generative AI pre-trained networks, it feels like if you have a more powerful generator, it would help. In your case, there is actually a very good link between generative AI and conditional expectation, which is very interesting. But I agree that this neural backbone can be swapped. I like that you tested at least two: transformer and LSTM.\n\n## Results Section\n\nI'm going to skip ahead to look at the results to see if transformer and LSTM actually give you a substantial difference. My impression when it comes to causal inference and this type of analysis is that transformers are actually not that helpful on top of LSTM. They should provide similar levels of results.\n\nYour Figures 6 and 7 in supplement are too busy to read. Oh, the transformer is indeed giving you slightly better results than the LSTM. Is there a particular reason? Is it because transformers are just better at generative AI and LSTM is more for prediction? What does that ablation study tell you?\n\nFigure 2 gives a very good schematic of how the thing is cascading. It's pretty intuitive. The training couples the generation step and the learning step. It generates and contrasts what's generated with the actual observation tau periods later, constructs a loss, and does this iteratively.\n\n## Identifiability Concerns\n\nAnother question just popped into my mind: would there be an identifiability issue? That is, two trained networks will give you the same g_{t+tau} because they are labeled on y_tau. However, during the process from t to t+tau—you know, the t+delta part—the two networks could give you very different results. I know that earlier you have an identifiability section, but that is in line 126, more from a theoretical perspective of SUTVA-like assumptions. How will actual neural networks behave? We know that neural networks could achieve the same accuracy with two drastically different networks.\n\nI'll skip ahead to Algorithm 1. I think I have a fairly good intuition now. Indeed, the Y is used as G_{t+tau}. All the rest are pseudo-Y, pseudo observations. So how do you make sure that your pseudo observation is actually identifiable?\n\nOtherwise, I think the procedure is tight. Now skipping ahead to the experiment part, Section 5. By Section 4, I'm very convinced about what's going on, so I will accept that.\n\n## Experimental Results\n\nSkipping ahead to Section 5, which I previously briefly reviewed. The results are indeed good, and I have good intuition for why they are good. You have MIMIC-III data for semi-synthetic experiments, which is very good.\n\nIn Figure 3, my question is: why does Figure 3 show the LSTM is slightly worse than the transformer? It would be good to discuss why the transformer is better than the LSTM as a backbone.\n\nOh, you do have real-world data in Supplement E—the real-world MIMIC-III data. That's fairly strong. Let me look at the figures. You should add a sentence saying that the real-world data confirms the findings. Using real-world MIMIC-III data confirms the same findings.\n\n## Overall Assessment\n\nRight now, I think it's a very solid paper. The only question I have is on identifiability. If I initialize your IGC-Net with another random initialization and train another instance of your IGC-Net, will they give the same pseudo observations g_{t+tau}? Why or why not? If not, then the interpretation of conditional expectation becomes a little bit questionable. If it is the case, I'm kind of not seeing how the structure is preserved and why it's exactly identifiable from an intuitive perspective.\n\n**Overall: Excellent paper, well-written, very enjoyable to read.**"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "3ahOXmurJm", "forum": "ZmhpqpKzAT", "replyto": "ZmhpqpKzAT", "signatures": ["ICLR.cc/2026/Conference/Submission7297/Reviewer_Wupz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7297/Reviewer_Wupz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7297/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761754299954, "cdate": 1761754299954, "tmdate": 1762919416712, "mdate": 1762919416712, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a new methods for estimating potential outcomes over time for treatment sequences. The authors argue that existing methods do not properly adjust for time-varying confounding and point out that existing methods that do control for this type of confounding have some limitations. To this end, they propose a new neural network method that leverages G-computation. The authors show both theoretically and empirically that their method effectively controls for time-varying confounding."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Good theoretical background and motivation as to why a new method is needed. \n\n- The authors make clear and significant contributions.\n\n- Extensive and strong experimental results that show that IGC-Net achieves state-of-the-art performance for the datasets used."}, "weaknesses": {"value": "At some points, the notation is confusing to me, making it hard to understand all the different parts of the paper. Below, I give some examples.\n\n- $g$ can have two different meanings if I understand it correctly. $g^a_{t+\\delta}$ is used in the theory for iterative G-computation, while  $g^\\delta_{\\phi}$ is a block of the neural network architecture that uses different sub- and superscripts. It would be helpful to the reader if the notation were clarified in some way.\n\n- In Figure 1, it is not obvious to me how I should interpret $a$ and $A$ during training and inference. Is $A_t$ the treatment that is actually observed at time $t$, and $a_t$ the treatment for which you want to estimate the CAPO? Does this mean that during training, these are the same? \n\n- I find the notation $a= a_{t:t+\\tau-1}$ confusing, is this standard in the literature? If not, I would suggest a different notation that makes it clearer that $a$ is the whole treatment sequence. \n\nIf I understand correctly, you always need to decide on the forecasting horizon $\\tau$ beforehand. Does this mean that if you wanted to know the effect of a treatment sequence that is shorter than your horizon (e.g., $\\tau-2$}), you would have to train a whole new model? If so, how does this compare to the baselines? \n\nHow do the contributions of IGC-Net compare to [1]? I think the learners introduced in that paper should be discussed in the related work section. \n\n\n[1] Dennis Frauen, Konstantin Hess, and Stefan Feuerriegel. Model-agnostic meta-learners for estimating heterogeneous treatment effects over time. In International Conference on Representation Learning, 2025."}, "questions": {"value": "In addition to the question in the Weaknesses section, I have some other questions:\n\n- In my understanding, $g^{0}_\\phi$ is the only component used at inference. However, I fail to see how it can make predictions for an arbitrary treatment sequence. From Figure 1, it appears that only $a_t$ is used as input. Is this correct? If so, could you explain the intuition as to why it should not take the whole treatment sequence as input?\n\n- In Figure 3, is the biased transformer the same as Causal Tranformer (CT) used in the previous experiments? \n\n- Is it correct that for each level of confounding $\\gamma$, the treatment sequence used for evaluation is always the same for all samples? If so, could you comment on whether sampling multiple different treatment sequences and calculating your error metric over these different sequences as well would be a better or worse way to evaluate the different methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ubqa6ch0V3", "forum": "ZmhpqpKzAT", "replyto": "ZmhpqpKzAT", "signatures": ["ICLR.cc/2026/Conference/Submission7297/Reviewer_Kwm7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7297/Reviewer_Kwm7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7297/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761903373444, "cdate": 1761903373444, "tmdate": 1762919416341, "mdate": 1762919416341, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces IGC-Net (Iterative G-computation Network), a neural framework for estimating conditional average potential outcomes (CAPOs) over time from observational data. The method addresses the challenge of time-varying confounding by leveraging iterative regression-based G-computation, avoiding limitations of existing methods like inverse propensity weighting. The main contribution of the paper is around avoiding high-dimensional probability distribution estimation that were used in SOTA neural network based G-computation methods. From the presented results, IGC-Net demonstrates superior performance in experiments across synthetic, semi-synthetic, and real-world data compared to baseline methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Some of the key strengths of the paper are as follows:\n- While G-computation has already been adapted to deep learning models in literature, the authors aim to circumvent the problem of full distribution estimation, by proposing an iterative regression-based approach. Using this idea of iterated expectations the authors are able to avoid costly monte carlo sampling and problems of high-dimensional overfitting that arises in presented literature\n- Commendably, the authors provide a comprehensive evaluation across synthetic, semi-synthetic, and real-world data, showing consistent outperformance of baseline methods.\n- Finally, the authors have provided a detailed architecture and hyperparameter tuning, ensuring methodological rigor and reproducibility. The presentation is easy to follow and covers the most important aspects of the paper well"}, "weaknesses": {"value": "While the paper has made a commendable efforts, there are several key issues with the paper\n- First, the authors haven't considered some of the latest literature on this topic. For example, G-transformer [1] was already proposed by the authors of G-net as a signficant improvement by adapting the backbone from RNN to a transformer model. A similar effort has also been reported in [2]. Another paper that aims to capture the uncertainty in G-computation has been proposed in [3]\n- Second, while the authors have proposed a neat computational approach to estimating the dynamic treatment effect, it is not evident whether the estimation process is able to capture the predictive uncertainty as well as a full scale MCMC methods\n\n\n[1]: Xiong H, Wu F, Deng L, Su M, Shahn Z, Lehman LH. G-Transformer: Counterfactual Outcome Prediction under Dynamic and Time-varying Treatment Regimes. Proc Mach Learn Res. 2024 Aug;252:https://proceedings.mlr.press/v252/xiong24a.html. PMID: 40433313; PMCID: PMC12113242.  \n[2]: Hess, Konstantin, et al. \"G-transformer for conditional average potential outcome estimation over time.\" arXiv preprint arXiv:2405.21012 (2024)  \n[3]: Deng L, Xiong H, Wu F, Kapoor S, Ghosh S, Shahn Z, Lehman LH. Uncertainty Quantification for Conditional Treatment Effect Estimation under Dynamic Treatment Regimes. Proc Mach Learn Res. 2024 Dec;259:248-266. PMID: 40443560; PMCID: PMC12121963."}, "questions": {"value": "Some of the key questions for the authors are as follows:\n- How does the method scale with larger prediction windows (τ) while maintaining performance? Have the authors considered trade-offs in performance with respect to traditional G-computational methods as the prediction window changes? \n- Have the authors investigated the effect of availability of large scale datasets for G-computational methods? For example, is there an inflection point such that availability of data would allow the model to learn the join distribution instead of the first moments"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "xKTgN1AUOh", "forum": "ZmhpqpKzAT", "replyto": "ZmhpqpKzAT", "signatures": ["ICLR.cc/2026/Conference/Submission7297/Reviewer_drGZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7297/Reviewer_drGZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7297/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761950074474, "cdate": 1761950074474, "tmdate": 1762919415969, "mdate": 1762919415969, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a novel, regression-based iterative approach to integrate G-computation into neural networks to address time-varying confounding."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper proposes a method for treatment effect estimation over time, adjusting time-varying confounders.\n- The paper provides a theoretical foundation for the model.\n- An implementation code is available for review."}, "weaknesses": {"value": "- The core idea is more likely to be an engineering adaptation of the G-computation. The manuscript does not convincingly differentiate its contribution and demonstrate conceptual advances from that method. \n- The motivation behind the study problem (treatment effect estimation over time) needs to be further clarified, particularly in relation to its real-world applicability. It is not evident whether the problem is testable, whether the authors have empirically validated it in real applications, or whether the underlying assumptions commonly hold in practical settings.\n- Experiments are conducted on synthetic datasets.  Even the semi-synthetic MIMIC-III uses simulated treatments and outcomes, with no evidence of applicability to real observational data. The study does not evaluate whether estimating CATE over time provides practical benefits or is actually necessary or useful in real-world contexts. The study shows performance under a controlled scenario rather than demonstrating practical utility.\n- The baselines are outdated. The paper excludes recent baselines for CATE over time, e.g., G-Transformer [1].\n\n[1] Hess, Konstantin, Dennis Frauen, Valentyn Melnychuk, and Stefan Feuerriegel. \"G-Transformer for Conditional Average Potential Outcome Estimation over Time.\" CoRR (2024)."}, "questions": {"value": "- The method adjusts time-varying confounders. How does the model address unobserved confounders?\n- Please see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TOf5TwZVoP", "forum": "ZmhpqpKzAT", "replyto": "ZmhpqpKzAT", "signatures": ["ICLR.cc/2026/Conference/Submission7297/Reviewer_K5dA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7297/Reviewer_K5dA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7297/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969714684, "cdate": 1761969714684, "tmdate": 1762919415556, "mdate": 1762919415556, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes IGC-Net, a neural method for estimating CAPOs over time from observational data. It aims to properly adjust for time-varying confounding by operationalizing iterative G-computation as a sequence of regression problems trained end-to-end. Experiments on a pharmacokinetic tumor growth simulator and semi-synthetic MIMIC-III show lower RMSE than prior neural baselines"}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The authors identified the limitations of existing work and proposed a new framework to address them. \n\n- Experiments are thoroughly conducted on both synthetic and real-world datasets. \n\n- Code and data are available for review."}, "weaknesses": {"value": "- Missing important baselines. The paper omits several recent and competitive methods for time-varying counterfactual prediction, such as CGM [1], State-Space Counterfactual Models [2], and G-Transformer [3], that would provide a fairer and more rigorous empirical comparison.\n\n- The experiments implicitly assume correctly specified models and strong sequential ignorability and positivity. There is no investigation into the method’s robustness under violations of overlap or unmeasured confounding, nor any diagnostics for near-zero treatment probabilities, which is an issue particularly relevant for real-world EHR data.\n\n- Both synthetic environments exhibit stylized and stationary dynamics. The claim that IGC-Net is robust “especially for longer horizons” remains weakly supported; validation on scenarios with τ > 6, irregular sampling, missingness, or time-varying action spaces would provide stronger evidence.\n\n[1] Wu, Shenghao, et al. \"Counterfactual generative models for time-varying treatments.\" Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2024.\n\n[2] Wang, Haotian, et al. \"Effective and Efficient Time-Varying Counterfactual Prediction with State-Space Models.\" The Thirteenth International Conference on Learning Representations. 2025.\n\n[3] Xiong, Hong, et al. \"G-transformer: Counterfactual outcome prediction under dynamic and time-varying treatment regimes.\" Proceedings of machine learning research 252 (2024): https-proceedings."}, "questions": {"value": "- Robustness & diagnostics: add overlap diagnostics; test positivity violations by skewing treatment assignment; report how IGC-Net degrades vs. RMSNs/TMLE-like DR estimators.\n\n- There’s limited analysis of convergence, computational cost vs. G-Net/RMSNs, or memory footprint for large τ."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jE7riFQmIX", "forum": "ZmhpqpKzAT", "replyto": "ZmhpqpKzAT", "signatures": ["ICLR.cc/2026/Conference/Submission7297/Reviewer_R3mf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7297/Reviewer_R3mf"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission7297/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762108508609, "cdate": 1762108508609, "tmdate": 1762919415034, "mdate": 1762919415034, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}