{"id": "16h9c9tddO", "number": 9111, "cdate": 1758111647895, "mdate": 1759897742725, "content": {"title": "Training & Label-Free Domain Adaptation in 3D Object Detection for Autonomous Driving", "abstract": "Autonomous driving systems rely on 3D object detection for path planning and control, but it has been demonstrated that LiDAR-based 3D object detectors suffer a significant performance drop when tested on datasets from different geographic locations than their training data due to domain shift. Existing domain adaptation methods typically require access to original training data or substantial target domain data, making them impractical for resource-constrained deployments. In this work, we address this challenge by exploring how LiDAR-based 3D object detection models trained in a source domain can be reused in a data-scarce target domain without extensive fine-tuning. We propose lightweight and practical approaches for single-frame domain adaptation under three different resource-constraint settings: 1) a test-time approach that adjusts predictions using a calibration factor when only *a minimal amount of unlabeled target data* is available, 2) a lightweight adaptation technique using learnable scaling weights when  *a small amount of labeled target data* are available, while preserving original model parameters, and 3) a weakly supervised finetuning method with a novel loss function for scenarios with *larger amounts of unlabeled target domain data*.  Our results demonstrate that scalable, cross-regional deployment of 3D object detection systems is feasible under significant scarcity of data and training budget.", "tldr": "", "keywords": ["3D Object Detection", "Domain Adaptation", "Domain Generalization", "Test Time Adaptation", "Autonomous Driving"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3ac8e3759ae2f8655383f214655fb52e9d44520b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper provides a detailed review of the research status of domain adaptation in the field of 3D object detection over recent years, mainly addressing the issue of detector performance degradation caused by differences in vehicle size between the source and target domains. It proposes three domain adaptation methods suitable for different scenarios. TTSN uses only a small amount of unlabeled target domain data and vehicle size statistics information to calibrate the prediction boxes during the test inference phase. LLS uses only a small amount of labeled target domain data and calibrates the prediction boxes by training a lightweight scaling factor without changing the model parameters. WSFT fine-tunes the model using a large amount of unlabeled target domain data through the CSA loss function, thereby enhancing its generalization ability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.The three proposed methods cover different scenarios and offer high flexibility in practical applications. \n\n2.They address the issue of performance degradation caused by differences in vehicle size between different domains.\n\n3.A large number of experiments have been conducted to prove the effectiveness of the proposed three methods."}, "weaknesses": {"value": "1.The study only focuses on vehicle size deviations and does not investigate other causes that may lead to a decrease in detector performance, such as point cloud density differences.\n\n2.It only studies the vihicle task and has not verified whether it remains effective for categories with less obvious size differences, such as pedestrians and cyclists."}, "questions": {"value": "Is there enough innovation? As I understand, the TTSN method is just applying the SN method to the TTA task. And how effective are these three proposed methods for pedestrians and cyclists?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No Ethics Concerns."}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4VD2vSkLiK", "forum": "16h9c9tddO", "replyto": "16h9c9tddO", "signatures": ["ICLR.cc/2026/Conference/Submission9111/Reviewer_e7Me"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9111/Reviewer_e7Me"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9111/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761876895175, "cdate": 1761876895175, "tmdate": 1762920809542, "mdate": 1762920809542, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The research direction of this paper is domain adaptation in the 3D object detection field. To address the issue of detector performance degradation caused by significant differences in vehicle size between the source and target domains, three different resource scenarios for domain adaptation are proposed. TTSN requires only a small amount of unlabeled target domain data and average car size information to account for size variations during testing. LLS is suitable for cases with a small amount of labeled target domain data but difficulty in fine-tuning. WSFT uses a large amount of unlabeled target domain data along with their size information to calibrate the prediction box size using CSA loss."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1.Both TTSN and LLS methods use a small amount of unlabeled data from the target domain, reducing dependence on large amounts of data. \n\n2.Divide into three scenarios according to the size of data volume and whether there are constraints on labels, respectively, and provide corresponding large-scale adaptation methods with high availability."}, "weaknesses": {"value": "1.Experiments were conducted on datasets with significant differences in car size, but have you considered verifying the effectiveness of the method on smaller size difference datasets, such as from Waymo to Nuscenes? \n\n2.For categories with smaller size differences, it is necessary to verify the effectiveness of this method."}, "questions": {"value": "Is it feasible in reality to obtain statistical information about vehicles? Is the domain adaptation effective for unknown scenarios in practical applications? Where is the lightweight aspect reflected in the LLS method?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "B6jbm2Sryn", "forum": "16h9c9tddO", "replyto": "16h9c9tddO", "signatures": ["ICLR.cc/2026/Conference/Submission9111/Reviewer_9eX6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9111/Reviewer_9eX6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9111/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761877986371, "cdate": 1761877986371, "tmdate": 1762920809206, "mdate": 1762920809206, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles source-free domain adaptation for LiDAR 3D detection for autonomous driving: a test-time statistical normalization (TTSN), a tiny linear scaling layer (LLS) trained on few labeled samples, and a weakly supervised fine-tuning (WSFT) with a composite loss aligning size statistics while regularizing to source outputs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The methods are intuitive and reasonable.\n\n2. On authors' experiments, the proposed methods have proved effectiveness."}, "weaknesses": {"value": "1. Novelty is limited; methods mainly recalibrate box dimensions and extend prior SN/OT/ST3D ideas.\n\n2. Heavy reliance on car-size statistics.\n\n3. Only one model is evaluated in the experiments. The proposed method may lack generalization to other 3D detection methods."}, "questions": {"value": "Please see the weaknesses. My major concern is with the novelty of this paper. Please try to ditinguish your method with existing solutions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Y44Iuffml1", "forum": "16h9c9tddO", "replyto": "16h9c9tddO", "signatures": ["ICLR.cc/2026/Conference/Submission9111/Reviewer_9Yr3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9111/Reviewer_9Yr3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9111/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761901234126, "cdate": 1761901234126, "tmdate": 1762920808894, "mdate": 1762920808894, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes three techniques to mitigate performance degradation from domain shift in LiDAR-based 3D object detection for autonomous driving. 1. TTSN (Test-Time Statistical Normalization): At inference, normalizes box dimensions using a correction derived from the gap between the target domain’s average car sizes (height/width/length) and the model’s predicted size statistics on target data. The correction is estimated from about 1K unlabeled target samples; no parameter updates are performed. 2. LLS (Lightweight Linear Scaling): Learns lightweight scaling coefficients (e.g., h/w/l) from a small set of labeled target samples to reduce dimensional mismatch. 3. WSFT (Weakly-Supervised Fine-Tuning): Fine-tunes without target labels using a Composite Statistical Alignment (CSA) loss combining a statistical alignment term on predicted sizes and a consistency term with the source model’s predictions, optimized with standard SGD. Models trained on KITTI are evaluated under domain shifts to nuScenes, Waymo, and Argoverse."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The problem formulation and deployment scenario are realistic. The paper explicitly considers source-free access, label-free or few-shot target supervision due to the cost of point-cloud annotation, and the practical burden/risks of full fine-tuning. The staged strategy (TTSN → LLS → WSFT) is motivated by these constraints.\n\n2. The design is concise and staged. Focusing on box-dimension mismatch as the primary driver of degradation, the methods progress from inference-time calibration to lightweight scaling to weakly supervised fine-tuning, with adaptation strength and resource requirements (parameter updates, labels, target data) increasing accordingly. The prerequisites for each stage are clearly stated."}, "weaknesses": {"value": "1. Contrary to the stated “consistent improvements,” Tables 2–3 do not consistently establish superiority. Beyond DT/OT, the effectiveness of the proposed methods should be established against contemporary TTA/SFDA baselines; such comparisons are not reported. While presented as source-free/training-free, the methods rely on a target-domain prior (car-size statistics). As a second-best option for fair comparison under equivalent resource assumptions, a direct comparison to FS (e.g., 10-shot) would help contextualize the gains. In the current tables, aside from modest gains on some KITTI→nuScenes metrics, the methods are often below FS on KITTI→Waymo and KITTI→Argoverse, so the claim of consistent effectiveness is not substantiated.\n\n2. Labels and values are inconsistent across tables. Table 2 is labeled KITTI→Waymo but matches Table 3’s KITTI→nuScenes. Lines 405–408 also suggest the top panels of Table 3 are swapped—please correct captions/headers. Even after relabeling, numeric conflicts remain (e.g., TTSN AP_3D(Hard) 25.5 in Table 2 but 16.1 in Table 3, implying that Gap Closed and related statements (46.6%, 33.4%, 62.3%) should be recomputed. DT AP_BEV differs slightly (47.4/24.6/25.5 vs 47.3/24.6/25.4). Please clarify whether this is due to rounding, seed variation, or evaluation scripts.\n\n3. Dataset splits are insufficiently specified, limiting reproducibility. Although Table 1 indicates custom train/validation partitions, the paper does not provide concrete procedures. For example, Waymo is described as 26k/6k “parsed” from the full set; nuScenes and Argoverse also depart from the official splits. Selection criteria (scene/city distribution, time/weather, sensor version, log-level sampling) and reproducible identifiers (frame/log ID lists, seeds) are not provided. The selection rule for the 1K calibration set used by TTSN (random vs. stratified, scene balance, disjointness from validation) is also unspecified. As a result, fair comparison and exact reproduction are difficult.\n\n4. Ablations, analysis, and hyperparameter justifications are underdeveloped. Sec. 4.1 largely restates tables without explaining cross-shift behavior (e.g., TTSN strong on KITTI→nuScenes but behind LLS/WSFT on Waymo/Argoverse). The sole qualitative figure compares only to DT, omitting differences among TTSN/LLS/WSFT and failure/boundary cases. Key settings (WSFT’s CSA weight α, consistency IoU=0.3) lack rationale and sensitivity. Given the reliance on pseudo-label filtering, please at minimum report: (i) consistency on/off, (ii) results under different IoU thresholds (0.1/0.3/0.5), and (iii) results for different calibration-set sizes K (200/500/1k/2k). Without these, it is hard to assess whether the chosen settings are sound or if stronger configurations exist."}, "questions": {"value": "1. You note that target car-size statistics (μh/μw/μl) can be obtained from public sources, yet in the experiments μ is computed from the dataset. Do you have results using truly public statistics, and can you share a deployment-ready procedure (sources, preprocessing, validation) and sensitivity to errors in μ?\n2. Could you clarify why you did not use the official splits and provide the concrete splitting procedures for each dataset (train/val ratios, selection criteria, sampling rules, frame, seeds)?\n3. Given that better alignment to target average car size should improve performance, how do you explain the substantial 3D drop of OT vs. DT in Table 2? To aid interpretation, would you share per-class and per-distance/size-bin metrics in addition to the aggregate scores?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ezD2UHlUoE", "forum": "16h9c9tddO", "replyto": "16h9c9tddO", "signatures": ["ICLR.cc/2026/Conference/Submission9111/Reviewer_VErs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9111/Reviewer_VErs"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9111/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762051129801, "cdate": 1762051129801, "tmdate": 1762920808559, "mdate": 1762920808559, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}