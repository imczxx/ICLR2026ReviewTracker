{"id": "wyK7RH9jf5", "number": 17687, "cdate": 1758279295983, "mdate": 1759897160103, "content": {"title": "Flow Connecting Actions and Reactions: A Condition-Free Framework for Human Action-Reaction Synthesis", "abstract": "Human action-reaction synthesis, a fundamental challenge in modeling causal human interactions, plays a critical role in applications ranging from virtual reality to social robotics. While diffusion-based models have demonstrated promising performance, they exhibit two key limitations for interaction synthesis: reliance on complex noise-to-reaction generators with intricate conditional mechanisms, thus limiting to unidirectional generation, and frequent physical violations in generated motions. To address these issues, we propose Action-Reaction Flow Matching (ARFlow), a novel paradigm that establishes direct action-to-reaction mappings, eliminating the need for complex conditional mechanisms and supporting bi-directional generation. Directly applying traditional guidance algorithms tends to undermine the quality of generated reaction motion. We analyze the sampling of flow matching in depth and reveal an issue (Initial Point Deviation) which causes the sampling trajectory to ever farther from the initial action motion. Thus, we propose a reprojection guidance method, RE-GUID, to correct this deviation to enable better interaction. To further enhance the reaction diversity, we incorporate randomness into the sampling process. Extensive experiments on NTU120, Chi3D and InterHuman datasets demonstrate that ARFlow not only outperforms existing methods in terms of Fréchet Inception Distance and motion diversity but also significantly reduces body collisions, as measured by our introduced Intersection Volume and Intersection Frequency metrics.", "tldr": "", "keywords": ["Flow matching", "guidance", "human action-reaction synthesis"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cd89d5f88807ce8819d5a5ac1559633c945b585c.pdf", "supplementary_material": "/attachment/50829b04c5f347a02216112cad97f35316958112.zip"}, "replies": [{"content": {"summary": {"value": "The paper present a new method for human reaction motion generation by using flow matching adapted for action to reaction synthesis. Additionaly, a guidance module is build to correct error that can appear from using the flow matching, correcting direction and body penetration. Experiments are performed on 3 commonly used datasets and higly the stenghts of the methods especially with regard to avoiding physical impossibilities."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The use of flow matching for reaction generation is interesting to avoid issue encountered by previous method while being  faster than diffusion based methods.\n- The proposed guidance module seems to improve performance while being faster than traditional guidance.\n- The proposed methods outperforms the other approachs on the three datasets proposed in the study quantitatively and qualitatively.\n- Methods and experiments are very detailed and well explained\n- The new metrics to check for body penetration are interesting and should be of interest to the community"}, "weaknesses": {"value": "1. Some more recent are missing for the comparison [1,2], while I am not sure if they are useable in the online setting proposed by the authors it would have been interesting to have the comparison at least for the offline setting.\n2. There are two claims about the ability of the methods to deal with challenges but they are never investigated in the experiments. i.e. boxing with recursively generating the motion of both humans ([1] propose a boxing dataset), the condition signal (action motion) is stated to be replaceable by text or audio. Showing results in both scenari would really strengthen the paper.\n3. The three datasets contain only relatively simple and short interactions. It would have been interesting to see results on more complex and longer motions.\n4. The IF and IV values are much lower for the proposed method than for the GT but this is never explained\n5. Table B1 and B2 are missing the IV and IF values\n6. It would have been interesting to see the results of reverse generation for all method to highlight their limitations.\n\n\n[1] Ready-to-React: Online Reaction Policy for Two-Character Interaction Generation, ICLR 2025\n[2] REMOS: 3D Motion-Conditioned Reaction Synthesis for Two-Person Interactions, ECCV 2024"}, "questions": {"value": "questions:\n- see weaknesses. Particularly answers to 1 and 2 could make me increase my rating\n\nsuggestions:\n- Interhuman is mentionned several times in the paper but the results are only in the appendix, this should be made more clear before referencing to table B1.\n- Table 3 show the methods speed but the gpu used is only mentioned in the appendix. It should be mentionned in the main paper instead."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JfZ23rKd9k", "forum": "wyK7RH9jf5", "replyto": "wyK7RH9jf5", "signatures": ["ICLR.cc/2026/Conference/Submission17687/Reviewer_6px3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17687/Reviewer_6px3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17687/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761634954115, "cdate": 1761634954115, "tmdate": 1762927534582, "mdate": 1762927534582, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ARFlow, a human action-reaction synthesis framework that establishes direct mappings between action and reaction distributions through flow matching. ARFlow eliminates complex conditional mechanisms in traditional diffusion models and enables bidirectional motion generation while maintaining real-time capability. The framework incorporates a reprojection guidance method  that corrects initial point deviation during sampling and significantly reduces bodily inter-penetration between characters. Extensive experiments demonstrate that ARFlow achieves superior performance in motion quality, diversity and physical plausibility, outperforming existing methods in both online and unconstrained settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposal presents a novel application of flow matching to action-reaction synthesis, establishing direct mappings between action and reaction distributions. This eliminates the need for complex conditional mechanisms in diffusion-based methods and enables bidirectional generation.\n\n2. The paper accurately identifies the Initial Point Deviation issue in flow matching sampling and designs the RE-GUID reprojection guidance method. This method corrects the deviation without requiring differentiation of the neural network, balancing physical plausibility and motion generation quality while effectively reducing body penetration.\n\n3. Through extensive experiments, the proposed method is shown to outperform existing baselines on common motion metrics and drastically reduce body collisions, while also achieving simpler training and faster inference."}, "weaknesses": {"value": "1. The penetration loss function might force characters to separate in close interactions, failing to balance physical plausibility and natural interaction dynamics.\n\n2. Although the paper visualizes a failure case in Figure J.2, it lacks a systematic analysis of failure patterns, weakening the completeness of the method’s limitation discussion"}, "questions": {"value": "1. Are there specific motion categories or interaction patterns where the model exhibits significant performance degradation?\n\n2. Regarding the physical constraint guidance, could its formulation be extended to address a wider range of physical plausibility aspects, such as foot-skating? Furthermore, I am interested in seeing ARFlow's performance evaluated on more physical plausibility metrics to better understand its capabilities and limitations.\n\n3. Would the physical constraint guidance struggle to maintain consistent physical plausibility across long sequences, resulting in occasional penetration or unnatural motions in later frames?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yATbp5qVSH", "forum": "wyK7RH9jf5", "replyto": "wyK7RH9jf5", "signatures": ["ICLR.cc/2026/Conference/Submission17687/Reviewer_fcJX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17687/Reviewer_fcJX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17687/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761902885250, "cdate": 1761902885250, "tmdate": 1762927533880, "mdate": 1762927533880, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ARFlow, a flow-matching framework for human action-reaction synthesis, claiming to replace noise-conditioned diffusion models with a direct mapping between action and reaction motions. It introduces a reprojection guidance (RE-GUID) method to reduce body penetration. Experiments on NTU120-AS, Chi3D-AS, and InterHuman-AS report lower FID and fewer penetrations compared with diffusion baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Flow matching is an interesting alternative to diffusion and has potential for faster inference. This paper introduces Flow matching for reaction synthesis for two person interaction\n\nThe proposed RE-GUID physically-guided correction is simple and computationally efficient."}, "weaknesses": {"value": "The claimed “condition-free” direct mapping from action to reaction is still conditioned on the action itself. The insight over conventional conditional diffusion models is unclear. \n\nThe demo video show mostly low-dynamic, stiff interactions with limited physical realism. Motions appear collision-free but lack natural dynamics and responsiveness expected in animation paper. This undermines the claimed advantage. I think the contribution is not enough if it just shows clear depenetration between humans, a post-hoc optimization applied after generation can achieve this easily as well.\n\nImportant baselines like ReMoS [1] are omitted. The reverse-generation results are minimal and not compelling.\n\n[1] Ghosh, Anindita, et al. \"Remos: 3d motion-conditioned reaction synthesis for two-person interactions.\" European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2024."}, "questions": {"value": "The proposed RE-GUID method adjusts the predicted clean pose (`x1_hat`) using a physical gradient and feeds the corrected result into the next sampling step, avoiding backpropagation through the network. \n\nHowever, in principle, one could already do something similar in diffusion models:  `x1_hat' = x1_hat - λ * ∇ L_pene(x1_hat)` followed by `x_{t-1} = g(x_t, x1_hat')` where `g` is the usual reverse sampling update (e.g., DDPM or DDIM). \n\nCould the authors clarify why RE-GUID is novel beyond this straightforward “detached guidance” idea? Is its contribution mainly the empirical integration into flow matching, or is there a theoretical reason why direct guidance on `x1_hat` would not work equivalently in diffusion models"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QlOCpJ6Qhb", "forum": "wyK7RH9jf5", "replyto": "wyK7RH9jf5", "signatures": ["ICLR.cc/2026/Conference/Submission17687/Reviewer_EMJ3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17687/Reviewer_EMJ3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17687/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761964282584, "cdate": 1761964282584, "tmdate": 1762927533569, "mdate": 1762927533569, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of human action-reaction synthesis, which aims to generate physically plausible human reactions in response to given actions. The authors identify two key limitations in existing method of 1. Complex and unidirectional generation; 2. Physical violations. To solve these problems, this paper proposes Action-Reaction Flow matching (ARFlow), a novel framework built on flow matching, to directly model the mapping from the action distribution to the reaction distribution. The simple architecture supports bi-directional generation for reaction-to-action generation. Besides, the authors identify the issue of “Initial Point Deviation” for physical violations of human-human interactions. Then, RE-GUID is proposed as a reprojection guidance to prevent penetration. Extensive experiments on NTU120, Chi3D and InterHuman show the superiority of ARFlow."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This work is the first work to apply a flow matching framework to the human action-reaction synthesis task. This \"condition-free\" approach, which directly models the mapping from the action distribution to the reaction distribution, is an elegant departure from existing diffusion models that rely on complex conditional mechanisms. Critically, this design choice directly enables bi-directional generation (both action-to-reaction and reaction-to-action), solving a key limitation of prior unidirectional methods.\n2. The paper's method for handling body inter-penetration is highly insightful. The proposed RE-GUID method is an effective and efficient solution that corrects this deviation by re-projecting the interpolation endpoint . This method, validated by the paper's newly introduced IF and IV metrics, is shown to dramatically reduce body collisions far below the levels of prior work.\n3. The authors provide thorough experimental validation across multiple challenging datasets (NTU120-AS, Chi3D-AS, and InterHuman-AS). The results are compelling, demonstrating that ARFlow outperforms existing state-of-the-art methods on key metrics like Fréchet Inception Distance (FID) and motion diversity. Furthermore, the proposed model is significantly more efficient, with fewer parameters, faster training convergence (e.g., half the time of ReGenNet), and much lower inference latency.\n4. The paper is well-written and organized. The authors clearly motivate the problem, articulate the limitations of existing work, and present their technical contributions in a logical, easy-to-follow manner."}, "weaknesses": {"value": "1. Limited Extensibility to Conditional Generation: The paper's primary innovation is its \"condition-free\" design. The paper provides no experiments or results for the conditional setting, making its flexibility and practical utility in constrained scenarios unproven.\n2. Unclear Bi-Directionality for Dynamic Interactions: The claim of \"bi-directional generation\" is a key strength, but its practical application seems limited. Besides, for the “boxing” example, it is unclear how the current framework could support such a continuous, auto-regressive switching of roles, as this would require a different model setup not demonstrated in the paper.\n3. Insufficient Evidence for Reaction Diversity: The model claims to support diverse reaction motions for the same action by incorporating stochasticity during sampling. The paper lacks clear visualization examples for diverse reaction generation. Without this, it is difficult to assess if the model is generating truly meaningful variations or just minor, low-impact perturbations of the same motion pattern. \n4. Limited Generalizability of Physical Constraints: The RE-GUID method, while effective at reducing penetration, may not generalize well. From the visualization, current generated results still physically implausible."}, "questions": {"value": "The authors are asked to clarify:\n1. **Conditional Generation:** How can the \"condition-free\" model be extended to handle conditional inputs like text, since this was not demonstrated?\n2. **Dynamic Bi-Directionality:** How does the *static* \"reaction-to-action\" experiment support the claim of handling *dynamic*, role-switching interactions (e.g., \"boxing\") ?\n3. **Visual Evidence:** Please provide more visual results to prove:\n    - **Diversity:** Show multiple, *distinct* reactions to the *same* action.\n    - **Physical Realism:** Show that the model works for *close-contact* interactions (like handshakes) and doesn't just \"unnaturally avoid\" contact ."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dCWDUalafQ", "forum": "wyK7RH9jf5", "replyto": "wyK7RH9jf5", "signatures": ["ICLR.cc/2026/Conference/Submission17687/Reviewer_husG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17687/Reviewer_husG"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17687/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986522273, "cdate": 1761986522273, "tmdate": 1762927533055, "mdate": 1762927533055, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}