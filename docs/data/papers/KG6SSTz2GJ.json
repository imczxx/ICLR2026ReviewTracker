{"id": "KG6SSTz2GJ", "number": 19698, "cdate": 1758298516127, "mdate": 1759897024998, "content": {"title": "Amortising Inference and Meta-Learning Priors in Neural Networks", "abstract": "One of the core facets of Bayesianism is in the updating of prior beliefs in light of new evidence$\\textemdash$so how can we maintain a Bayesian approach if we have no prior beliefs in the first place? This is one of the central challenges in the field of Bayesian deep learning, where there is no clear way to translate beliefs about a prediction task into prior distributions over model parameters. Bridging the fields of Bayesian deep learning and neural processes, we propose to $\\textit{meta-learn}$ our parametric prior from data by introducing a way to perform per-dataset amortised variational inference. The model we develop can be viewed as a neural process whose latent variable is the set of weights of a BNN and whose decoder is the neural network parameterised by a sample of the latent variable itself. This unique model allows us to study the behaviour of Bayesian neural networks under well-specified priors, use Bayesian neural networks as flexible generative models, and perform desirable but previously elusive feats in neural processes such as within-task minibatching or meta-learning under extreme data-starvation.", "tldr": "", "keywords": ["neural processes", "Bayesian neural networks", "meta-learning", "priors", "variational inference"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/02d1f2f61a7fc8b8e4ed02eb20626875f7945153.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces a meta-learning model to infer better priors for Bayesian neural nets (BNNs) using a neural process (NP)-based approach, which treats the BNN's weights as latent variables.\nTo ensure scalability, it relies on layerwise factorizations and introduces within-task minibatching."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper proposes an interesting and novel combination of BNNs and NPs for an important unsolved task in the Bayesian deep learning literature.\n- The proposed objective (eq. 10) consists of interpretable and well-motivated terms.\n- The approach is scalable and seems to provide promising results across a range of experiments."}, "weaknesses": {"value": "- Proposition 1 is promising in that the objective is well-motivated but does not provide any guarantees that the vague definition of \"small\" in Definitions 1–3 is actually achievable. For example, are all three terms minimizable at the same time, or do they balance each other?\n- The empirical evaluation is promising but currently rather unusable, as it is completely devoid of any information on architectures, hyperparameters, training procedures, etc.\n- No code is provided.\n\n## Minor weaknesses\n- Hiding the definitions of the three desiderata (167–170) in the appendix makes that part of the paper feel rather handwavy, even though it isn't.\n- Details are missing from the results, e.g., over how many seeds are the error bars in Figure 6?"}, "questions": {"value": "- Q1: The paper doesn't discuss computational cost and runtime requirements. How expensive is the approach?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "H8fP2Prpmt", "forum": "KG6SSTz2GJ", "replyto": "KG6SSTz2GJ", "signatures": ["ICLR.cc/2026/Conference/Submission19698/Reviewer_xjWL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19698/Reviewer_xjWL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19698/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761144909233, "cdate": 1761144909233, "tmdate": 1762931540473, "mdate": 1762931540473, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of defining useful priors in a Bayesian deep learning setting by introducing the \nBayesian Deep Neural Process (BDNP). The central idea is to meta-learn a parametric prior for Bayesian Neural Network \n(BNN) weights, coupled with amortized variational inference, using a meta-dataset of related tasks. Conceptually, the \nBDNP can be viewed as a neural process (NP) where the latent variable represents the weights of a BNN, and the decoder \nis the BNN itself. The paper presents compelling empirical evidence demonstrating the BDNP's ability to achieve \nhigh-quality approximate inference compared to other VI methods and to learn meaningful priors effectively."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The presentation of the paper (language and structure) is well done. The theoretical section is sound and nicely concise. \nThe experimental section is comprehensive and well-executed. Presented ablation studies, particularly those evaluating the \nquality of approximate inference against other VI methods and the qualitative and quantitative analysis of learned priors, \nstrongly support for the paper's claims. The authors provide a commendably clear and realistic discussion of the \nlimitations of their approach, such as potential scalability issues for very large or complex architectures."}, "weaknesses": {"value": "- **Training Loss Justification:** The paper's core training objective, PP-AVI, deviates from standard NP-losses like NP-VI. \nWhile Appendix A.4 provides a detailed justification for this choice over NP-VI, this reasoning should be\n(at least partly) integrated into the main text. Furthermore, the PP-AVI 'loss' is formulated as a maximization \nobjective rather than a loss.\n- **Clarification on Within-Task Minibatching:** The claim that \"the ability to minibatch a forward pass over a given \ncontext set is rare in the context of neural processes\" requires more elaboration. The authors acknowledge\nthat inference in BDNP can be viewed as Bayesian context aggregation in NPs [1]. Consequently, iteratively updating the\nlatent posterior over multiple mini batches via sequential Bayesian inference is also applicable to classical NPs. \nThis also works for other context aggregation mechanisms such as mean-aggregation or max-aggregation. Only context \naggregation in the Attentive NP can not be minibatched, but the same holds for tha Attentive BDNP (AttBDNP). Furthermore, \nthe method of using gradients from a random minibatch during training (Appendix C) is a significant detail. This \napproximation introduces potential biases and its implications (e.g., impact on convergence, generalization) should be \nmore prominently discussed in the main text. Additionally, the assertion that \"our scheme maintains the ability for the \nBDNP to learn to generalize predictive inference across various context set sizes during training\" requires theoretical \nor empirical evidence to support it.\n- **Evaluation Metrics for Correlated Samples:** The per-datapoint Log Posterior Predictive Density (LPPD) is used as one\nprimary metric without a formal definition in the paper. More importantly, a key advantage of latent NPs (including BDNPs) \nover conditional NPs (CNPs) is their capacity to produce correlated function samples. LPPD, being a per-datapoint metric,\nmay not fully capture or adequately evaluate this crucial aspect of model calibration and uncertainty representation. \nIt is recommended to also evaluate the posterior predictive log-likelihood over the entire target set, i.e., \n$p(y^{1:M}_T\\mid x^{1:M}_T, D_C)$, as this metric would provide a more holistic assessment of the model's ability to \ngenerate coherent and well-calibrated correlated function samples.\n\n[1] Volpp et al., 'Bayesian Context Aggregation for Neural Processes'"}, "questions": {"value": "- In the experiments comparing BDNPs to standard NPs, did you also learn the prior for the latent variable?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ptlYan7ypE", "forum": "KG6SSTz2GJ", "replyto": "KG6SSTz2GJ", "signatures": ["ICLR.cc/2026/Conference/Submission19698/Reviewer_poex"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19698/Reviewer_poex"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19698/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761940203726, "cdate": 1761940203726, "tmdate": 1762931539600, "mdate": 1762931539600, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work aims to incorporate a meta-learning prior into the weight parameters of Bayesian Neural Networks (BNNs). In doing so, it builds BNNs that can be interpreted as a type of latent neural process model, where the latent variable is replaced by the posterior distribution of the BNN’s weights, which varies depending on the input. Specifically, it introduces an inference network that generates pseudo-labels for each linear layer and updates the layer’s posterior using these pseudo-labels and the prior. Once the parameters of the inference network and the BNN prior distribution are learned, indicating that the BNN has a well-posed prior, it evaluates the corresponding BNN's ability to perform various tasks effectively. Furthermore, it investigates the crucial role of approximate Bayesian learning under a well-posed prior."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* This work introduces an interesting idea of incorporating a meta-learning prior into BNNs and establishes a connection to neural processes.\n*  It also presents an amortized linear layer structure that enables each layer to function as a Bayesian layer with an amortized prior."}, "weaknesses": {"value": "* Although the proposed method is technically sophisticated, it is unclear what specific problem it aims to address with the proposed structure. For instance, it is not evident whether the main contribution lies in emphasizing the amortized prior for BNNs and its benefits, or in investigating approximate training for BNNs with a well-chosen prior.\n\n* The training procedure for the parameters of the inference network and the prior distribution is insufficiently described. Beyond presenting the loss objective, a pseudo-code illustration or detailed algorithmic explanation would be necessary for clarity.\n\n* Moreover, the quality of the learned prior and the corresponding posterior is likely influenced by the design of the inference network. However, this aspect appears to be underexplored in this work."}, "questions": {"value": "* It appears that the parameters of the inference network and the prior distribution are jointly trained according to Eq. (10). The ELBO term seems primarily used for training the parameters of the prior distribution, while the conditional likelihood for the target task appears to update both the inference network and the prior distribution. Is this interpretation correct? If not, could you please clarify this point further?\n\n* In this training procedure, was the inference network pre-trained, or was it trained jointly from scratch?\n\n* How is the scale of prior learnability (ranging from 0.0 to 1.0) measured in Figure 7? Moreover, if the amount of data is limited and the prior is well-posed, shouldn’t the prior be beneficial? Why does the performance of BDNP with a prior-learnability of 1.0 degrade so significantly in Figure 7(a)?\n\n* The following works seem relevant to the concept of meta-priors for BNNs and neural processes, and might be useful to include in the related work section:\n\nHierarchical Gaussian Process Priors for Bayesian Neural Network Weights, NeurIPS 2020\n\nBayesian Convolutional Deep Sets with Task-Dependent Stationary Prior, AISTATS 2023"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "oE1ifpBky7", "forum": "KG6SSTz2GJ", "replyto": "KG6SSTz2GJ", "signatures": ["ICLR.cc/2026/Conference/Submission19698/Reviewer_Kn36"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19698/Reviewer_Kn36"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19698/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762019642041, "cdate": 1762019642041, "tmdate": 1762931538728, "mdate": 1762931538728, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new model called a Bayesian deep neural process (BDNP), which combines aspects of the global inducing point variational posteriors (Ober and Aitchison 2021) and the (latent) neural process (NP) (Garnelo 2018). It is a member of the neural process family, although it differs in that the latent variable is the parameters of the decoder rather than an input to the decoder. Like Ober and Aitchison 2021, the variational posterior uses a psuedo output and a pseudo noise term to exploit the conjugacy of Bayesian linear regression per layer. Unlike Ober and Aitchison 2021, there is a psuedo output and a pseudo noise term for each data point and, instead of treating them as trainiable parameters, the BDNP uses amortization. That is, they are outputs of a trained “inference network”, which is analogous to the encoder of an NP. The model is trained by minimizing a log posterior-predictive density, as in an NP, and a ELBO term, as in VI. In the experiments, the paper shows better KL to the true posterior on a toy example, the ability to meta-learn BNN priors in 1D regression tasks, a comparison of different inference methods under the same meta-learned prior, and an experiment restricting the learned prior."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- This is an interesting paper that addresses shortcomings of Bayesian deep learning in a new way, as far as I know. The complexity of the model is both a pro and con. \n- I like the idea of amortizing the psuedo observations of Ober and Aitchison 2021\n- Figure 6 was interesting. This shows the learned prior is useful regardless of the inference method. \n- The experiments focus on meaningful questions, rather than the largest scale experiments"}, "weaknesses": {"value": "- There are a few differences with a standard NP, enough that I wonder if this is really an NP (see my questions below). \n- Overall, this is a fairly complicated model, which makes it difficult to understand what each component is doing. I appreciated the discussion of the objective function in the appendix, but I think some of this discussion should appear in the main text. The objective doesn’t feel well motivated as it’s written now. More discussion of how this differs from a standard NP would help. \n- The introduction discusses how BNNs revert to GPs in the infinite width limit but in the finite width limit considered in this paper, BNNs are not GPs. There are many criticisms to make of BNNs, but I don’t think this one is relevant. \n- Unless I missed it, the experiments seem to lack details (architectures, optimizers, etc)\n- I found figure 1 (b) a bit confusing. Is this for a one hidden layer network? \n- Definitions 1, 2, and 3 aren’t well-defined because they reference a quantity being “small”, but it’s not clear what small means. \n- There are a few statements that are too strong for me, e.g. “the impressive performance of our explicitly Bayesian meta-learning setup”, “The BDNP’s approximate posterior is a very good on”"}, "questions": {"value": "- Unlike an NP, there is no aggregation of encodings in the BDNP, to ensure permutation invariance. In an NP this is needed to ensure exchangeability of the stochastic process. Instead, the aggregation happens in the loss function. In the appendix, you write that “BDNP and BDAM exhibit this through permutation invariance with respect to the context observations and permutation equivariance with respect to the target inputs”. Can you explain how BDNP defines an exchangeable process without the aggregator? \n- This relates to the above question: I’m confused about how exactly the model meta learns the prior. In an NP, the information from the multiple datasets comes from the encoding. The global latent variable is conditioned on the encoding. My understanding is that this is the “meta” learning done in an NP. In the BDNP, the encodings are, I would argue, variational parameters (as in how they are used in Ober and Aitchison 2021). The prior parameters of the BNN are trained similarly to how they would be trained in standard VI, using the fact that the ELBO is a lower bound on the marginal likelihood, which is used for model selection. Note that in an NP, only the log predictive term is in the loss function, not the ELBO term. Can you comment on how the prior meta learning is different from a standard NP? Am I understanding the BDNP correctly? \n- You train a separate inference network $g_l$ for each layer, is that correct? This seems like it would create a lot of parameters unless each network is small.\n- Can you explain again why the BDNP scales favorably in network width? How do you get around the computation of the mean and covariance in equations 6 and 7 being cubic scaling in the width?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fbXVJ7XgkQ", "forum": "KG6SSTz2GJ", "replyto": "KG6SSTz2GJ", "signatures": ["ICLR.cc/2026/Conference/Submission19698/Reviewer_G27C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19698/Reviewer_G27C"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19698/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762148747486, "cdate": 1762148747486, "tmdate": 1762931538166, "mdate": 1762931538166, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}