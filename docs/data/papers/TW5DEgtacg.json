{"id": "TW5DEgtacg", "number": 14251, "cdate": 1758231206532, "mdate": 1763584543068, "content": {"title": "Only Large Weights (And Not Skip Connections) Can Prevent the Perils of Rank Collapse", "abstract": "Attention mechanisms lie at the heart of modern large language models (LLMs). Straightforward algorithms for forward and backward (gradient) computation take quadratic time, and a line of work initiated by [Alman and Song NeurIPS 2023] and [Alman and Song NeurIPS 2024] has shown that quadratic time is necessary unless the model weights are small, in which case almost linear time algorithms are possible. In this paper, we show that large weights are necessary to avoid a strong preclusion to representational strength we call layer collapse, which means that the entire network can be approximated well by a network with only a single layer. This means that transformers with small weights are shockingly weak, and that the quadratic running time of attention is unavoidable for expressive transformers.\n\nThe notion of layer collapse that we introduce is a variant on the notion of rank collapse from the work of [Dong, Cordonnier, and Loukas ICML 2021]. They showed that in Self Attention Networks with small weights and with skip connections, rank collapse must occur. This is typically interpreted as justifying the necessity of skip connections in expressive networks. However, our result shows that even with skip connections, if the weights are small, then layer collapse still occurs. Thus, only large weights, and not skip connections, can prevent these representational weaknesses.", "tldr": "", "keywords": ["computational complexity", "circuit complexity", "fine-grained complexity", "representational strength", "rank", "weights", "attention"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5cc592f6e924bc6ed7d6b8e52b4db3ade0653390.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces the concept of \"layer collapse\" and proves that transformers with small weights can be approximated by a single-layer network, even when skip connections are present. The work challenges the conventional interpretation that skip connections alone prevent representational weaknesses in attention-based architectures."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The theoretical contribution extends prior work on rank collapse by showing that small weights, rather than lack of skip connections, are the fundamental limitation. The introduction of layer collapse as a concept provides a new lens for understanding transformer expressivity, with the main theorem (Theorem 1.2) offering a formal bound relating weight magnitude (l∞ norm) to approximation error.\n  - The paper offers practical insights for the design of transformers, particularly regarding weight quantization and pruning strategies. By connecting theoretical results about small weights to the extensive literature on fast attention algorithms, the work bridges complexity theory and practical implementation concerns."}, "weaknesses": {"value": "- The theoretical analysis is restricted to relatively simple settings with bounded l∞ norms on weight matrices, while the main theorem assumes specific relationships between network depth, number of heads, and weight bounds. The paper would benefit from empirical validation showing when layer collapse actually occurs in practical transformer models trained on real tasks, rather than relying primarily on the theoretical framework. For instance, experiments measuring the approximation quality of single-layer networks for pre-trained language models at different quantization levels would strengthen the claims.\n  - The connection between l∞ weight bounds and the low-rank approximation assumptions used in fast attention algorithms needs clearer exposition. While the paper cites work showing that small weights enable subquadratic algorithms, it does not sufficiently explain why the specific l∞ bound (rather than other norms like l1 or Frobenius) is the relevant constraint for both computational efficiency and layer collapse. Additional analysis or experiments comparing different norm constraints would clarify this relationship.\n  - The paper's discussion of skip connections may be somewhat misleading. While the title emphasizes that \"only large weights and not skip connections\" prevent collapse, the actual theoretical result (Theorem 1.2 and its proof) applies to networks with or without skip connections under small weight constraints. The paper could more carefully distinguish between: (1) networks without skip connections that have exponentially fast rank collapse (Dong et al.), (2) networks with skip connections but small weights that have layer collapse (this work), and (3) networks with skip connections and large weights (unclear from current work). The relationship between these three regimes deserves more detailed discussion.\n  - The experimental validation focuses primarily on correlation studies between weight norms and Hessian eigenvalues in small networks, but does not directly validate the layer collapse phenomenon itself. Missing are experiments that: (1) explicitly construct the approximating single-layer network S' for a given multi-layer network S with small weights, (2) measure the actual approximation error ||S(X) - S'(X)||∞ on realistic inputs, and (3) demonstrate at what threshold of weight magnitude η the layer collapse becomes practically relevant. The GPT2 experiments in the appendix appear to be from a different paper (about Hessian spectra) and may have been included by mistake, as they do not directly address layer collapse. I will reconsider my score in the rebuttal."}, "questions": {"value": "see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MehEV7QkT3", "forum": "TW5DEgtacg", "replyto": "TW5DEgtacg", "signatures": ["ICLR.cc/2026/Conference/Submission14251/Reviewer_cfu9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14251/Reviewer_cfu9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14251/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760493933180, "cdate": 1760493933180, "tmdate": 1762924705622, "mdate": 1762924705622, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This theoretical paper aims to prove that the assumption of many previous papers approximating attention with sub-quadratic algorithms -- that the weights of the model are \"small\" -- is not realistic. Limiting the weights like this would (according to the main Theoreom in this paper) lead to rank collapse, which implies that attention with \"small\" weights is less expressible than attention without such constraints."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The main motivation of this paper is strong and -- if the main Theorem was proven properly -- this paper would make a great contribution to the field. I believe that studying the \"layer collapse\" instead of the \"rank collapse\" (as defined by the authors) makes a lot of sense and could lead to interesting discoveries in the future."}, "weaknesses": {"value": "The paper is poorly structured and full of typos and logical mistakes.\n\nRight the first Lemma 4.1 is incorrect and the proof has a mistake in the first inequality. The Lemma states that if $||A-B||\\_{\\\\infty} \\\\leq \\epsilon$, then $||Res(A) - Res(B)||\\_{\\\\infty} \\\\leq \\epsilon$. A counterexample to this is setting $A = \\\\begin{pmatrix} 2 & 0 & -2 \\\\end{pmatrix}^T$ and $B = \\\\begin{pmatrix} 1 & 1 & -3 \\\\end{pmatrix}^T$; then $Res(A) = A - 0 = A$ and $Res(B) = B - (-1) = \\\\begin{pmatrix} 2 & 2 & -2 \\\\end{pmatrix}^T$. This means that $||A-B||\\_{\\\\infty} = ||\\begin{pmatrix} 1 & -1 & 1 \\\\end{pmatrix}^T||\\_{\\\\infty} \\\\leq 1$, but $||Res(A) - Res(B)||\\_{\\\\infty} =  ||\\begin{pmatrix} 0 & -2 & 0 \\\\end{pmatrix}^T||\\_{\\\\infty} \\\\not\\\\leq 1$, which is a contradiction to the Lemma. Furthermore, the proof in the paper implies that $||Res(A) - Res(B)||\\_{\\\\infty} \\\\leq ||A-B||\\_{\\\\infty}$, which is incorrect for the same reason.\n\nThis Lemma 4.1 is then used to prove the main Lemma 5.2, it is applied on line 442 -- making the proof of the main Theorem incorrect. One inequality on this line claims $||Res(B - R\\_A) - Res(B)||\\_{\\\\infty} \\\\leq ||(B - R\\_A) - B||\\_{\\\\infty} = ||R\\_A||\\_{\\\\infty}$, but this is not always true, as shown above.\n\nThe mistakes appear in many other places, most importantly in the central Lemmas 5.2 and C.1. These Lemmas confuse the definition of $\\\\text{softm}$ (regular parameter-less softmax operator as defined in 3.1) with the definition of $\\\\text{SAtt}$ (parametrized self-attention operator defined in 3.6) -- the formulation of Lemma 5.2 talks about weights $W\\_k, W\\_q$ and $W\\_v$, but there are clearly no weights involved in $\\\\text{softm}$. In order to prove the main Theorem, we would need to prove that $||\\\\text{SAtt}(B) - \\\\text{SAtt}(X)||\\_{\\\\infty} \\\\leq \\epsilon_0$, but these Lemmas only prove that $||\\\\text{softm}(B) - \\\\text{softm}(X)||\\_{\\\\infty} \\\\leq \\epsilon_0$ and $||\\\\text{softmv}(B) - \\\\text{softmv}(X)||\\_{\\\\infty} \\\\leq \\epsilon_0$, which is not enough.\n\n____\n\nApart from this, the structure and writing of this paper also lacks; starting from the abstract that contains badly formatted citations. The Related Work section spans almost two pages and contains mostly irrelevant papers."}, "questions": {"value": "- I am open to believing that what appears as mistakes in the paper are just unfortunate typos, could you explain how can the Lemma 4.1 be true?\n- Similarly, can you prove Lemma 5.2 for $\\\\text{SAtt}$ instead of $\\\\text{softm}$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cVoHESWqLm", "forum": "TW5DEgtacg", "replyto": "TW5DEgtacg", "signatures": ["ICLR.cc/2026/Conference/Submission14251/Reviewer_G6Fb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14251/Reviewer_G6Fb"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14251/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761842342181, "cdate": 1761842342181, "tmdate": 1762924705186, "mdate": 1762924705186, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proves that self-attention networks with small weights lose depth expressivity even when skip connections are used. It shows that if weight magnitudes are bounded, an L-layer model effectively behaves like a single-layer one. This challenges the common belief that skip connections alone prevent rank collapse."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Provides a clear and rigorous theoretical result on the limits of skip connections under small-weight conditions.\n- Elegant and well-structured proofs using softmax perturbation and layer-removal arguments.\n- Corrects a major misconception in prior work (Dong et al., 2021)."}, "weaknesses": {"value": "- No empirical validation or quantitative mapping of η to realistic settings.\n- Purely theoretical, lacks visualizations or verification experiments like Dong et al. (2021).\nWhile Dong et al. provided practical insight (“skip connections are necessary”), this paper mainly corrects a misconception without offering clear actionable guidance for model design or training.\n- The paper also contains unexplained square symbols in several places."}, "questions": {"value": "I’m curious what practical contribution this paper can offer to the community beyond correcting a misconception.\nAs noted in the paper, many real-world LLMs use approximation or quantization techniques that enforce weight bounds, which can indeed be risky. However, such risks are typically addressed through validation accuracy and calibration during deployment.\nGiven that, I wonder what unique or practical value this work adds to the community beyond highlighting this theoretical limitation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "eyOL4XCbmV", "forum": "TW5DEgtacg", "replyto": "TW5DEgtacg", "signatures": ["ICLR.cc/2026/Conference/Submission14251/Reviewer_CG8P"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14251/Reviewer_CG8P"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14251/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761889915950, "cdate": 1761889915950, "tmdate": 1762924704446, "mdate": 1762924704446, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tries to show that multi-layer attention models with only small weights can be collapsed with a small error into a single-layer attention model. The authors posit that only if models contain large weights can they be safe from layer collapse (a variant of rank collapse where all layers can be collapsed into a single collapse)."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The idea of this paper is interesting and could, if shown, affect the way models are pre-trained since it posits that using only small weights can lead to layer collapse."}, "weaknesses": {"value": "Minor: The related works are quite confusing; the three paragraphs contain mostly related works (although they sometimes include works on topics that do not relate to the paper, such as privacy), but the next three paragraphs talk about works that are not related to the paper in anyway (such as diffusion or regression models when the paper is about the importance of large weights to avoid layer collapse). This adds half a page of irrelevant text to the paper.\n\nMinor/Major: Lemma 4.1 and Lemma 4.2 seem to be unused and irrelevant to the paper; it is confusing as to why they are in the main paper rather than the appendix.\n\nMajor: Most of the mathematics is wrong; the proof of Lemma 4.1 is incorrect (if you take $A = [-2,4,-2], B=[-2, 2, 2]$ then $\\Vert{A -B}\\Vert= 4$ and $\\Vert\\textrm{Res}(A) - \\textrm{Res}(B)\\Vert=5$). The important steps tend to be under-explained, while the trivial ones are detailed. Both Lemma 5.1 and 5.2 (which are the main lemmas of the paper) contain mistakes in the proof, which render the theorem of the paper unproven. Lemma 5.1 has multiple typos, missing addition signs, and incorrect order of matrix multiplication in the proof. In lines 404-406, you have the D matrix appear out of thin air without further explanation (or it coming from the previous part of the proof). You assume that you can replace $(e^D - 1)$ by $(e^{\\theta} - 1)$ when taking the infinite norm, but this however not the case since if $\\theta < 0.69$ then the infinite norm of the matrix is 1. For Lemma 5.2, in line 442-443, you state that $\\Vert \\textrm{Res}(B - R_A) - \\textrm{Res}(B)\\Vert \\leq \\Vert R_A \\Vert$. This is false; the inequality should be in the other direction by definition of the Res function. In addition, you use the function softmax for Lemma 5.2 instead of Self Attention, which does not allow you to do Equation (9)."}, "questions": {"value": "- Why were Lemmas 4.1 and 4.2 included in the paper? Are they relevant to any part of the further proofs (I could not find any references to them)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "rTRXtNcYXE", "forum": "TW5DEgtacg", "replyto": "TW5DEgtacg", "signatures": ["ICLR.cc/2026/Conference/Submission14251/Reviewer_rupd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14251/Reviewer_rupd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14251/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761953272344, "cdate": 1761953272344, "tmdate": 1762924703793, "mdate": 1762924703793, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}