{"id": "BhYqfdHLA0", "number": 9097, "cdate": 1758110774673, "mdate": 1759897743635, "content": {"title": "Physical Dynamics as Next Geometric Graph Prediction", "abstract": "Physical dynamics simulation serves as a foundational component in scientific computing and AI applications. This paper presents a novel approach that redefines the problem as autoregressive prediction of spatiotemporal graph sequences. Built upon the expressivity of Transformer, we propose an Equivariant Spatiotemporal Transformer (EST), extending conventional Transformers with specialized equivariant spatiotemporal blocks. These blocks systematically alternate between spatial and temporal modules, rigorously maintaining E(3) symmetries throughout the process. Moreover, the design incorporates a novel Temporal Difference Graph (TDG) module derived from frame-wise variations, effectively modeling global dynamics and addressing cumulative errors in autoregressive predictions. Unlike traditional graph neural networks, our EST can process variable-length historical sequences and mitigate the persistent challenge of error accumulation in autoregressive processes. Comprehensive evaluations across multiscale physical systems (molecular-, protein-, and macroscopic-scale) demonstrate that our method achieves state-of-the-art performance, thereby showcasing its robust and versatile dynamics simulation capabilities.", "tldr": "", "keywords": ["Equivariance", "Spatio-Temporal Transformer"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/74d928fbce306b375038d24b9c7d9feb108a25fd.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses the problem of simulating physical dynamics by framing it as an autoregressive prediction of spatiotemporal graph sequences. The authors propose the Equivariant Spatiotemporal Transformer (EST), a novel encoder-decoder architecture that maintains E(3) symmetries. The model incorporates specialized spatiotemporal blocks that alternate between spatial message passing and temporal self-attention. A key contribution is the Temporal Difference Graph (TDG), a module initialized from frame-wise differences that interacts with the historical trajectory to model global dynamics and mitigate cumulative error, a persistent challenge in autoregressive simulation. The authors evaluate EST on molecular, protein, and human motion dynamics datasets, demonstrating state-of-the-art performance, particularly in long-horizon predictions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The introduction of the Temporal Difference Graph (TDG) is a creative and promising approach to the critical problem of error accumulation in autoregressive models (see Sec. 1, Sec. 3.2). This moves beyond simple frame-to-frame prediction and introduces a mechanism to explicitly model system dynamics over time.\n2. The experiments are extensive, spanning three distinct and relevant physical scales—molecular (MD17), human motion (Motion Capture), and protein dynamics (Adk trajectory)—which convincingly demonstrates the model's versatility and generalizability (see Sec. 4).\n3. The ablation study presented in Table 4 systematically deconstructs the model to validate the contribution of its key components. These experiments confirm the importance of maintaining equivariance, the efficacy of the TDG, the benefit of the encoder-decoder structure, and the rationale for using causal attention in the encoder (see Sec. 4.4)."}, "weaknesses": {"value": "1. The paper claims the TDG helps circumvent cumulative errors, but the theoretical justification provided (Taylor expansion in Sec. B.6.1) is a general argument for predicting velocity rather than position. It does not fully explain why the specific implementation of the TDG—as an independent graph token that interacts with all historical frames via attention—is superior to simpler or more direct velocity prediction schemes used in prior work.\n2. The paper downplays the computational cost, stating that for short sequences the overhead is \"negligible\" (see Sec. E.4 ). However, the runtime analysis in Table 17 shows that EST-V is approximately 4 times slower than the previous SOTA (ESTAG) and 10 times slower than the fastest baseline (ST_EGNN). This is a significant trade-off that deserves a more prominent and nuanced discussion in the main text.\n3. Why is predicting the difference from the previous frame simpler than predicting the next frame directly? How can this be demonstrated?\n4. In the description of Eq. (4), please clarify whether the mean reduction term $\\overline{x}$ is computed only once based on the initial input trajectory or is dynamically recomputed at each step of the autoregressive rollout process."}, "questions": {"value": "Reference weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "4Qd28PtTpR", "forum": "BhYqfdHLA0", "replyto": "BhYqfdHLA0", "signatures": ["ICLR.cc/2026/Conference/Submission9097/Reviewer_HooZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9097/Reviewer_HooZ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9097/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760691511555, "cdate": 1760691511555, "tmdate": 1762920798677, "mdate": 1762920798677, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel approach to modeling physical dynamics by casting it as a next-step geometric graph prediction problem. Instead of representing physical systems as sequences of state vectors, the authors model each timestep as a graph and use geometric GNNs to predict the evolution of these graphs over time. The approach aims to integrate structural inductive biases with learned dynamics, leveraging the flexibility of GNNs in representing complex interactions and spatial relationships. The method is evaluated on several physical simulation tasks and is compared against existing neural and physics-based baselines."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The idea of formulating physical dynamics as a geometric graph prediction problem is conceptually interesting, and could potentially offer a unified framework for structured dynamical modeling.\n\n2. The paper leverages geometric deep learning techniques, such as equivariant GNNs, which are well-suited to modeling the symmetries inherent in physical systems."}, "weaknesses": {"value": "1. While the overall framework is promising, the technical details are somewhat underdeveloped. Key components (e.g., how graphs are constructed at each timestep, how node/edge features evolve) are described at a high level and lack sufficient mathematical clarity or justification.\n\n2. The experimental results look weak. Only a small number of benchmarks are used, and comparisons with strong recent baselines (e.g., learned simulators like GNS or differentiable physics engines) are missing.\n\n3. The model’s ability to generalize to systems with different numbers of components or interaction types is not convincingly demonstrated, which is a critical capability for physical simulation models."}, "questions": {"value": "Pls refer to weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "ivsbqoZTSQ", "forum": "BhYqfdHLA0", "replyto": "BhYqfdHLA0", "signatures": ["ICLR.cc/2026/Conference/Submission9097/Reviewer_isjy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9097/Reviewer_isjy"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9097/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761460544900, "cdate": 1761460544900, "tmdate": 1762920798224, "mdate": 1762920798224, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper reframes physical dynamics simulation—traditionally treated as predicting continuous trajectories—as a next-graph prediction problem using a Transformer-based architecture.\nIt introduces the Equivariant Spatiotemporal Transformer (EST), a model that predicts future graph states autoregressively while preserving E(3) symmetries (rotations, reflections, translations).\nThis allows EST to simulate molecular, protein, and human motion dynamics with geometric and temporal consistency."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This reframing connects sequence modeling (from NLP) with geometric dynamics, allowing the use of autoregressive Transformers for temporal evolution in physical systems.\n\nIt provides a unifying perspective that bridges graph-based physics learning, trajectory modeling, and generative dynamics under a single formalism."}, "weaknesses": {"value": "Limited Physical Grounding Beyond Equivariance\nAutoregressive Rollout Still Accumulates Error"}, "questions": {"value": "Why “next-graph prediction”? and this method is not new.\nHow does EST compare to Hamiltonian or Lagrangian neural networks that explicitly encode energy and momentum conservation?\nCan the model generalize to continuous-time prediction (e.g., irregular timesteps)?\nCan model predict rapid change unseen?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "sxJdFqn6nM", "forum": "BhYqfdHLA0", "replyto": "BhYqfdHLA0", "signatures": ["ICLR.cc/2026/Conference/Submission9097/Reviewer_Uo2G"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9097/Reviewer_Uo2G"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9097/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761589993878, "cdate": 1761589993878, "tmdate": 1762920797881, "mdate": 1762920797881, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an attention-based encoder-decoder for molecule dynamic problems. I think the key part is Equivariant Spatiotemporal Attention. I think the overall design is not complicated, but useful for the future work."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The design is simple and easy to follow. And the experiments are promising. The overall design is close to modern NLP (gpt-like), but also considers the property of the molecules."}, "weaknesses": {"value": "1. It looks like the model can not handle large molecules due to the token number (each node represents one token, not efficient.)\n2. The model seems not to consider the connection for the 3d molecules.\n3. The title is not proper. The proposed method can only handle dynamic molecule problem, not general physical dynamics."}, "questions": {"value": "1. What is the average node number for the dataset used?\n2.  10 rollout steps looks very small, is it possible to expand it?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ik3CUnJmSv", "forum": "BhYqfdHLA0", "replyto": "BhYqfdHLA0", "signatures": ["ICLR.cc/2026/Conference/Submission9097/Reviewer_Vq7q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9097/Reviewer_Vq7q"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9097/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762314725683, "cdate": 1762314725683, "tmdate": 1762920797441, "mdate": 1762920797441, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}