{"id": "e8bWf8old1", "number": 15803, "cdate": 1758255436372, "mdate": 1762926684983, "content": {"title": "Topological Alignment: A Universal Framework for Anomaly Detection", "abstract": "Zero-Shot Anomaly Detection (ZS-AD) methods based on Vision-Language Models face a critical vulnerability: a paradoxical performance collapse when trained on large-scale, diverse data. We identify this phenomenon as {Negative Transfer in Domain Generalization (NTDG)} and diagnose its root cause as a {Domain Conflict}: a fundamental structural incompatibility where a single, rigid geometric decision boundary fails to separate topologically complex data manifolds from multiple domains. To escape this trap, we propose a paradigm shift from geometric separation to robust topological separability, actualized in our {TDA-CLIP} framework. The framework introduces two general-purpose, plug-and-play topological tools: (1) a macro-level {Homology Consistency Loss ($\\mathcal{L}_{\\text{HC}}$)} that acts as a structural regularizer to enforce a globally consistent feature space, and (2) a micro-level {Topology-Guided Attention (TGA)} module that purifies features by amplifying salient local evidence. Crucially, these topological components are active only during training and are completely pruned at inference time, delivering substantial performance gains while introducing absolutely no extra cost at inference. Extensive experiments demonstrate that our framework is the first to overcome this negative transfer, consistently benefiting from large-scale Domain Generalization where all baselines fail. TDA-CLIP not only establishes a new state-of-the-art across 11 industrial and medical benchmarks but also proves its generalizability by enhancing existing SOTA methods, offering a validated and principled pathway toward building truly universal anomaly detection models.", "tldr": "", "keywords": ["Anomaly Detection", "Robustness", "Topology", "Zero-shot"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/8e8a6a2817643d2d77c3a2715fcd8608cb04941b.pdf", "supplementary_material": "/attachment/bd6ea4e2a37689e95dc190b44a46a06de758c8df.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses the issue of ‘Negative Transfer in Domain Generalization’ for zero-shot anomaly detection based on vision-language models like CLIP. The authors attribute performance degradation under large-scale, diverse-domain training to what they term a ‘Domain Conflict’, and propose TDA-CLIP, a topology-inspired training framework. Two main topological tools are introduced: Homology Consistency Loss (LHC) and Topology-Guided Attention (TGA). Experiments on 11 industrial and medical datasets show moderate improvements in zero-shot anomaly detection performance, maintaining the robustness when training data scales up, while adding no inference overhead."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe paper is well structured, includes detailed appendices and reproducibility statements.\n2.\tThe authors evaluate across multiple datasets and domain scales, achieving SOTA metrics among current CLIP-based zero-shot anomaly detection approaches."}, "weaknesses": {"value": "1.\tThe motivation of this work is somewhat puzzling. For real-world application of anomaly detection, it is incredible to fuse industrial data and medical data to train a universal model. The domain conflicts between these different types of data obvious. Mixing them together significantly increases ‘Domain Conflict’ and the difficulty of model training. In my opinion, there is no need to do so for a specialized model used in practical scenarios.\n2.\tAlthough the paper claims a paradigm shift from geometry to topology, the actual method essentially adds a pairwise cosine alignment regularizer based on selected sample pairs. The use of persistent homology to identify these pairs is incremental, and the proposed losses are not fundamentally new compared to existing contrastive or consistency-based objectives.\n3.\tThe reported improvements (typically <1% in AUROC or AUPR) are small and within the range of variance for large-scale vision models. Given the significant additional complexity during training, the performance gains do not convincingly demonstrate that topology-based regularization is the main cause of improvement.\n4.\tThe ‘Persistence-Critical Pairs’ appears to be incremental compared with other pair mining strategies. Given that the total training time is about 20% longer as stated, but the Pixel-AUROC is increase by only 0.1% as shown in Table 3.\n5.\tThe manifold evolution is difficult to understand only with Fig.1. It is hard to see that the proposed regularizer actually modifies topology as claimed. The methodology remains abstract and unverifiable from the results.\n6.\tThe authors declared that their TDA-CLIP consistently benefits from more data in Table 2. It is not very convincing because the improvements of some metrics across different datasets did not reflect consistency. Furthermore, no statistic evaluation was performed to demonstrate this statement."}, "questions": {"value": "Except for the major concerns presented above in the Weaknesses, I have another two additional questions:\n\n1.\tFig. 1 is difficult to understand. What’s the meaning of the arrows in Fig. 1? Compared with Figure 1(a) and (b), what is the finding of the proposed method?\n\n2.\tIn Fig. 1(d), the performance of image-level AUROC is inconsistent with that of the other two metrics with the increase of training data, what is the reason? Can the robustness be purely attributed to the proposed TDA-CLIP, not affected by the training data itself?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "6XUV0xnx4w", "forum": "e8bWf8old1", "replyto": "e8bWf8old1", "signatures": ["ICLR.cc/2026/Conference/Submission15803/Reviewer_296f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15803/Reviewer_296f"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15803/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761484967100, "cdate": 1761484967100, "tmdate": 1762926034673, "mdate": 1762926034673, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "PPVMecLovy", "forum": "e8bWf8old1", "replyto": "e8bWf8old1", "signatures": ["ICLR.cc/2026/Conference/Submission15803/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15803/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762926683949, "cdate": 1762926683949, "tmdate": 1762926683949, "mdate": 1762926683949, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles an important and recognized problem in ZS-AD: the severe performance collapse (termed Negative Transfer in Domain Generalization), where SOTA models like AnomalyCLIP and AA-CLIP suffer when trained on large-scale, diverse data."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper's main contribution claim is that TDA-CLIP is the first to overcome NTDG, showing robust performance gains in the S3 (large-scale, heterogeneous) setting where all baselines catastrophically fail.\n2. The authors diagnose the root cause of this failure as \"Domain Conflict\", a fundamental inability of a single, rigid geometric decision boundary to reconcile the complex topological manifolds from multiple, heterogeneous domains."}, "weaknesses": {"value": "1. The primary claim is based on a confounded and unequal comparison. The S3 setting is built by augmenting the S2 (40k annotated images) dataset with 85k \"unlabeled web images\". The paper admits in Appendix F.2.1 that all baseline methods rely on a \"segmentation loss\". For the 85k unlabeled images, this loss is invalid. The authors' strategy for the baselines was to \"automatically skips the samples that lack masks, computing the loss only on the annotated samples\". This means TDA-CLIP is designed as a semi-supervised method that can effectively leverage the entire 125k S3 dataset (using image-level labels and unsupervised topological structures). The baselines, however, are restricted to being supervised methods that are effectively still only training on the 40k S2 subset. Therefore, the performance gap observed in S3 (Table 2) does not prove that TDA-CLIP is more robust to \"Domain Conflict.\" It most likely proves that a semi-supervised method (TDA-CLIP) benefits more from an additional 85k of (partially) unlabeled data than a supervised method (the baselines) that cannot use that data at all.\n2. TGA is based on the \"Topological Outlier Hypothesis\": anomalous patch features should be \"topologically isolated\" from the \"mainland\" of normal patches. This is visually demonstrated in Figure 3 with a local defect (a single red-starred patch) on a screw . However, this hypothesis may completely fail for global or textural anomalies (e.g., \"carpet,\" \"grid,\" or \"leather\" classes in MVTec AD). In those cases, all patches may belong to the \"anomalous\" class, forming their own dense manifold, not \"topological islands.\" TGA's saliency calculation, which relies on isolation, would likely fail or provide a misleading signal for these common anomaly types.\n3. The computational cost of TGA is significantly downplayed. The module operates per-image19. It partitions the patch grid into $k^2$ disjoint subsets (where $k=4$) and then computes 0-dimensional persistent homology in parallel for each local point cloud. This means separate persistent homology computations (Algorithm 4) are required per-image, per-batch, during training. The claim that this adds only a \"modest overhead\" and that \"total training time is only about 20% longer\" seems highly optimistic for such a computationally intensive operation and lacks a rigorous FLOPs analysis. \n4. The paper claims this complex design \"avoids conflicting gradients from simultaneous optimization\". This is a generic claim. What gradients, specifically, conflict? Why would a simpler, end-to-end training with a standard (perhaps weighted) multi-task loss fail?\n5. The Stage 2 design is particularly confusing. The TGA (\"teacher\") processes patch features from the visual adapter (\"student\"), and its output $z_{tda}$ is then added back to the \"student's\" own global average pooled feature $z_{avg}$ to create a \"fused feature\" $z_{out}$. This fused feature is then used for the auxiliary losses ($L_{align}, L_{HC}$). This \"student-teacher-student\" feedback loop is non-standard and its motivation is unclear.\n6. The ablation in Table 4 only compares Baseline, +$L_{HC}$, +TGA, and +Both. It does not ablate the necessity of the two-stage decoupled strategy itself. A crucial missing experiment is a single-stage, end-to-end trained model with all components. It also fails to ablate the complex $z_{out}$ fusion mechanism in Stage 2."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rYRyNwjEMf", "forum": "e8bWf8old1", "replyto": "e8bWf8old1", "signatures": ["ICLR.cc/2026/Conference/Submission15803/Reviewer_KLbQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15803/Reviewer_KLbQ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15803/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761807121563, "cdate": 1761807121563, "tmdate": 1762926034183, "mdate": 1762926034183, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work tackles the challenging task of zero-shot anomaly detection. It identifies a source of negative transfer in domain generalization, arising from a fundamental domain conflict caused by incompatible manifold structures between normal and anomalous data. To address this issue, it introduces TDA-CLIP, which combines a homology-based global loss with topology-guided attention to enforce topological separability and improve anomaly detection performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The empirical results are strong, indicating that incorporating topological biases can effectively mitigate negative transfer in anomaly detection. \n\nAdditionally, the two-stage, adapter-based training strategy is efficient."}, "weaknesses": {"value": "The “Domain Conflict” explanation is insufficiently proven; evidence for topology as the root cause is limited and mostly conceptual.\n\nThe claim regarding large-scale cross-domain training is not convincingly supported by the presented experiments.\n\nThe title’s use of “Universal” overstates the scope; universality is not rigorously demonstrated and training domains remain limited.\n\nIn Line 96, “current methods” is vague—specific baselines and approaches should be explicitly referenced.\n\nThe paper does not cite foundational persistent homology literature, which is necessary given the central role of topological tools.\n\n“Traditional geometric hard-mining” is not clearly defined, and clearer comparison and intuition are needed to understand the improvement brought by persistent homology.\n\nFigures (e.g., Figure 3) contain text that is too small to read, which hinders clarity, and more experimental detail is required for reproducibility."}, "questions": {"value": "How sensitive is performance to hyperparameters?\n\nIt is unclear why the adapter is inserted specifically at the first layer of the encoders."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0DtkQe9MpW", "forum": "e8bWf8old1", "replyto": "e8bWf8old1", "signatures": ["ICLR.cc/2026/Conference/Submission15803/Reviewer_3JEC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15803/Reviewer_3JEC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15803/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976931910, "cdate": 1761976931910, "tmdate": 1762926033830, "mdate": 1762926033830, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper considers CLIP-based anomaly detection. The proposed approach attempts to preserve topological structure of CLIP embedding space rather than enforcing strict geometrical separability between normal and anomalous samples during finetuning, which becomes challenging once applied to mulitple domains. This is done by using by first trains the model to align the direction of vectors connecting normal and anomalous sample image embeddings with vectors that connect textual embeddings of normal and anomalous sample descriptions. A further feature space refinement is achieved by adding loss compontents that indentify most salient image patches that are most informative for anomaly detection."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "[S1] The proposed method achieves good experimental results on diverse set of anomaly detection approaches, beating previous CLIP based methods.\n\n[S2] The idea of not enforcing geometric separability, but more flexible constraints is interesting."}, "weaknesses": {"value": "[W1] I do not like the framing of the proposed approach as a universal framework for anomaly detection. This approach is specific to CLIP based methods, and is therefore limited by the capabilities of the CLIP model (e.g. is it possible to detect real anomalies with respect to CLIP training data) Furthermore, there is no comparison to methods that do not rely on CLIP, but the results could still be lagging. E.g. for MVTec the results are worse with the CLIP base approaches [a].\n\n[W2] I found the paper to be difficult to read and some of the claims are not particularly convincingly substantiated. See questions.\n\n[W3] The paper relies on existence on anomalous samples during training, which is not necessarily needed in considered area of anomaly detection.\n\n[a]  Mousakhan el al., Anomaly detection with conditioned denoising diffusion models, GCPR 2024"}, "questions": {"value": "[Q1] Figure 1 claims that it demonstrates that normal and anomalous samples are consistently separated in terms of direction. does that refer to individual datasets in the collection. Overall the colors are not clear, it is not obvious what the clusters are supposed to represent.\n\n[Q2] The paper claims that the proposed approach benefits from more data, but that is not completely true. as demonstrated by Figure 1 (e) (AP performance slighlty drops for on the largest dataset collection.\n\n[Q3] To my understanding, the anomaly detection results for larger dataset collections are calculated as means over individual dataset collections. What would happen if those datasets were really merged?\n\n[Q4] HOw were the textual embeding for normal and anomalous samples designed? How sensitive it the emthod to this design?\n\n[Q5] The method relies on balancing between different losses. How were these values chosen?\n\n[Q6] What is loss seg? What is the ground truth for it?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PbPuqhAygy", "forum": "e8bWf8old1", "replyto": "e8bWf8old1", "signatures": ["ICLR.cc/2026/Conference/Submission15803/Reviewer_6Pwd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15803/Reviewer_6Pwd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15803/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762269321190, "cdate": 1762269321190, "tmdate": 1762926033383, "mdate": 1762926033383, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}