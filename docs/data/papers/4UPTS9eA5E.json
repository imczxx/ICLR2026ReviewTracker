{"id": "4UPTS9eA5E", "number": 6354, "cdate": 1757972413367, "mdate": 1759897920169, "content": {"title": "Improving RAG Question Answering Generation with Synthetic Data", "abstract": "To improve large language models (LLMs) for question answering (QA) tasks, system architects often look to retrieval-augmented generation (RAG) or fine-tuning approaches to increase a model's performance.  In many applications, however, there is a dearth of real data of sufficient quality to support model fine-tuning to improve RAG system performance for QA tasks.  In this work, we study the degree to which synthetic data can effectively substitute real data for RAG generator fine-tuning.  Using GPT-4o, we generate a synthetic version of the HotpotQA training set and fine-tune a Llama-3 generator separately on both real and synthetic data.  We evaluate our models with a range of metrics such as token-level F1, Bertscore, and LLM-as-a-judge. Across these metrics, model performance generally increases after fine-tuning primarily due to better conformity to the style of the answer distribution and secondarily due to improved use of retrieved contexts.  We observe that relative performance depends on the quality of the retriever, emphasizing the importance of the training data distribution in improving the model's reasoning over multiple contexts.  We further show that the fine-tuned model trained on synthetic data generalizes better to similar held-out QA tasks, outperforming an LLM fine-tuned on real data by 36% in LLM-judged correctness over the RepLiQA dataset.  These findings motivate a system-level analysis of the marginal benefits of generator fine-tuning in RAG pipelines, providing practical insights on the utility of synthetic training data for the benefit of both RAG systems engineers and future researchers.", "tldr": "We study the degree to which synthetic data can effectively substitute real data for RAG generator fine-tuning.", "keywords": ["Question Answering", "Synthetic Data", "Retrieval Augmented Generation", "Natural Language Processing"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f954b48be8e44d426383b4273db785e09420e296.pdf", "supplementary_material": "/attachment/a6ad41acd5fa6e53cad0f6542b405079515544d0.zip"}, "replies": [{"content": {"summary": {"value": "This paper focuses on the core issue of \"limited fine-tuning of the generator due to the scarcity of real annotated data\" in the RAG system. Through the technical route of GPT-4o generating HotpotQA synthetic dataset, fine-tuning Llama-3 generator, and multi-dimensional evaluation, the system verifies the improvement effect of synthetic data on the performance of the RAG generator."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "This article clarifies the correlation between the quality of retrievers and fine-tuning data distribution - in the MPNet retriever scenario (with interfering documents), G-Synthetics performs better due to its stronger contextual reasoning ability (ignoring interfering information); In the GoldenRetriever scenario, G-real has a slight advantage due to its short answer style that is more in line with HotpotQA."}, "weaknesses": {"value": "1. The core differences between this study and related work have not been thoroughly compared. It is recommended to supplement quantitative comparisons with similar synthetic data studies (such as data generation costs and overall performance of the RAG system after fine-tuning) to clarify the technical increment of this study.\n\n2. Only using HotpotQA (multi hop open domain QA) as the training dataset, without extending it to other typical RAG scenarios (such as domain specific QA, long document QA, conversational QA), cannot verify the applicability of synthesized data in different tasks; The model used is only Llama-3.1 8B Instruction, and larger scale models have not been tested.\n\n3. The illusion rate of the model after fine-tuning has not been evaluated (such as whether the generated answers have support in the retrieval context), and one of the core requirements of the RAG system is to \"reduce illusions\"; Only by using LLM to indirectly measure the accuracy of facts, but without comparing the differences in \"illusion types\" (such as creating something out of nothing and misreading context) between the fine-tuning models of real and synthetic data, it is difficult to comprehensively evaluate the impact of synthetic data on the quality of generation."}, "questions": {"value": "see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wcMOvCAF4e", "forum": "4UPTS9eA5E", "replyto": "4UPTS9eA5E", "signatures": ["ICLR.cc/2026/Conference/Submission6354/Reviewer_wKA9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6354/Reviewer_wKA9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6354/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761287273045, "cdate": 1761287273045, "tmdate": 1762918645502, "mdate": 1762918645502, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to address the scarcity of high-quality real-world QA data for RAG generator fine-tuning by exploring synthetic data as a substitute. It uses GPT-4o to generate synthetic QA pairs based on the HotpotQA dataset’s context, then fine-tunes a Llama-3 generator with both real (G-real) and synthetic (G-synthetic) data. Performance is evaluated via metrics like F1, Bertscore, and LLM-as-a-judge, with additional tests on RepLiQA (same-domain) and BioASQ (cross-domain) for generalization. The paper claims synthetic data can replace real data (especially under imperfect retrievers like MPNet) and offers stronger generalization, framing this as its core contribution."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The experimental design maintains basic controllability for its core comparison: by using the same base model (Llama-3.1 8B Instruct) and fine-tuning pipeline (SFT) for both real and synthetic data, it isolates \"data type\" as the key variable, which allows for direct observation of performance differences between the two data sources. This basic rigor ensures the comparison itself is internally consistent."}, "weaknesses": {"value": "- **No Substantive Innovation**: Using synthetic data for model fine-tuning is already a common practice in industry, and the paper does not propose any new mechanism for synthetic data generation, fine-tuning optimization, or performance improvement. It merely repeats existing workflows without advancing the field.\n- **Extremely Limited Experimental Scope Undermines Conclusion Validity**: Training and core validation rely solely on the HotpotQA dataset—a single benchmark that has long been a standard testbed for multi-hop QA. For generalization testing, it only includes one additional cross-domain dataset (BioASQ) and one same-domain dataset (RepLiQA), far fewer than comprehensive RAG evaluations that cover multiple domains (e.g., CRAG’s five domains). This narrow scope makes it impossible to prove the \"generality\" of synthetic data claimed in the paper.\n- **Critical Evaluations Missing**: It ignores key RAG performance dimensions that industry and academia prioritize, such as hallucination (a core risk for real-world deployment, evaluated in frameworks like RAGEval), faithfulness to context (a focus of RAGAS), and efficiency tradeoffs. This makes the work irrelevant to practical deployment needs.\n- **Overstated Title and Weak Conclusion Support**: The title \"Improving RAG Question Answering Generation with Synthetic Data\" implies a meaningful advancement, but the limited experiments (single training dataset, sparse generalization tests) cannot support claims of \"improving\" RAG systems—let alone establishing synthetic data as a reliable solution.\n- **Neglect of Key Optimization Directions**: It does not discuss or test the role of RL in enhancing generalization—an approach widely explored for aligning LLM outputs with real-world needs—further limiting the work’s depth."}, "questions": {"value": "1. Given that synthetic data is already widely used in industry, what specific value does this work provide beyond confirming a known practice? How does it address gaps in existing industrial workflows?\n2. The paper claims synthetic data has \"strong generalization,\" but only tests two additional datasets. How would you design experiments to truly verify generality—for example, across more diverse domains (e.g., finance, sports as in CRAG) or more complex question types (e.g., counterfactual queries)?\n3. Why did you omit evaluations of hallucination and context faithfulness—criteria central to RAG reliability? Do you have preliminary data on whether synthetic data fine-tuning exacerbates or mitigates hallucinations?\n4. The title emphasizes \"improving\" RAG performance, but your results are limited to a single base model and narrow datasets. How do you justify this framing given the lack of evidence for broad applicability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "z9utNA9VuL", "forum": "4UPTS9eA5E", "replyto": "4UPTS9eA5E", "signatures": ["ICLR.cc/2026/Conference/Submission6354/Reviewer_QR7X"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6354/Reviewer_QR7X"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6354/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991800117, "cdate": 1761991800117, "tmdate": 1762918644705, "mdate": 1762918644705, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper compares synthetic datasets with real QA data in RAG settings. The key question is whether synthetic QA data can effectively replace or complement real QA data. Using HotpotQA as the seed dataset, the authors generate a synthetic version of it using GPT-4o, fine-tune separate Llama-3.1-8B models on the real and synthetic data, and evaluate their performance under two retrieval settings: an imperfect MPNet retriever and a GoldenRetriever.\n\nResults show that fine-tuning on synthetic data can match or even exceed fine-tuning on real data, particularly when retrieval is noisy or incomplete. The synthetically trained model generalizes better to new datasets such as RepLiQA and exhibits greater robustness under retrieval imperfections.\n\nOverall, the paper provides an empirical analysis of generator fine-tuning under data and retrieval constraints with practical insights for deploying RAG systems in low-data settings."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper is well written, logically structured, and easy to follow.\n\n2. At a high level, the study addresses an important and realistic scenario of how to improve RAG performance when real fine-tuning data is scarce, sensitive, or unavailable.\n\n3. The analysis of how retriever quality interacts with fine-tuning data quality is a useful and underexplored systems-level perspective.\n\n4. The results provide two clear empirical conclusions:\n\n4.1 Synthetic fine-tuning helps the generator reason more effectively under noisy retrieval.\n\n4.2 Real fine-tuning mainly improves answer style conformity (shorter, HotpotQA-like answers)."}, "weaknesses": {"value": "1. Limited experiments: The entire analysis is centered on HotPotQA (which requires at most 2 sub-queries). Although the authors test transfer on RepLiQA and BioASQ, both are relatively small and do not fully validate generalization across reasoning types or domains. The paper makes broad claims about synthetic data but only use a single seed set which does not provide enough evidence.\n\n2.  The paper does not compare against state-of-the-art fine-tuning frameworks such as Self-RAG, RQRAG, LeReT, CoRAG, or RAFT. These systems include retrieval-aware or reflection-based fine-tuning that may addresses many of the issues of imperfect retrieval. Without these comparisons, the reported gains are difficult to interpret broadly and have limited practical utility.\n\n3. The paper’s novelty is primarily empirical. Synthetic data generation, RAG fine-tuning, and LLM-as-a-judge evaluations are all established techniques. The new contribution lies in the analysis, and the conceptual and methodological novelty is limited.\n\n4. The paper quantifies embedding similarity but does not probe *why* synthetic data leads to better generalization. For example, do synthetic examples exhibit more reasoning steps, cleaner style, or reduced ambiguity? A deeper analysis would be beneficial to the community.\n\n5. The analysis done in the paper is very limited: the effect of synthetic data size, diversity, prompt construction, etc. is not explored which might play a significant role in the overall results.\n\n6. In relation to prior work: the paper mentions how their proposed analysis is different from methods like RAG-Studio, RAFT, etc. in the related works. However, it does not do justice to how similar some of these methods are to the analysis presented in the proposed work. For example RAG-Studio also uses synthetic data for domain adaptation and provides several ablations that reveal similar findings. I would request the authors to do a more comprehensive comparison with related works to establish their positioning. \n\n7. As stated in the previous point, while the authors claim novelty in analyzing performance under varying retriever quality, earlier works such as Balaguer et al. (2024) and Siriwardhana et al. (2023) already explored end-to-end retriever–generator tradeoffs. The added insight here is incremental."}, "questions": {"value": "Kindly see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fuoKNOFlSI", "forum": "4UPTS9eA5E", "replyto": "4UPTS9eA5E", "signatures": ["ICLR.cc/2026/Conference/Submission6354/Reviewer_JVib"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6354/Reviewer_JVib"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6354/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762001784885, "cdate": 1762001784885, "tmdate": 1762918643780, "mdate": 1762918643780, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies whether the synthetic data can substitute the golden data when fine-tuning the generator in a RAG system. GPT-4o is applied to generated the synthetic HotpotQA like questions based on the same golden passage pairs as the HoptpotQA training set. Llama-3.1-8B-Instruct is selected as the generator and trained on golden training set and the synthetic training set separately. Metrics, like EM, F1, BERT Score and LLM-as-a-judge are utilized to compare the performances. The author concludes that the generator fine-tuned on synthetic data outperforms the counterpart fine-tuned on golden training set with the imperfect retriever, MPNet. In addition, the generator fine-tuned on the synthetic data has better generalization than its counter-part."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The author clearly describes the experimental setup, and the Figure 1 task diagram is helpful to understand the baselines.\n2. The synthetic QA dataset is released and may be helpful for the research in this area"}, "weaknesses": {"value": "1. The synthetic questions are generated from the same golden passages as real HotpotQA, making the claims overestimated.\n2. The synthetic data generation and fine-tuning are only conducted on HotpotQA, raising the concerns about the generalization.\n3. The usefulness of synthetic data has been proved in many previous studies, and it is not supervise to observe the benefits of using the synthetic data to train the generator."}, "questions": {"value": "The primary challenge in generating multi-hop questions lies in collecting the linked passages required to answer them. This paper bypasses that difficulty by directly using the same passage pairs as the HotpotQA dataset. Why not consider a more general synthetic data generation method?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mrIF1HydDL", "forum": "4UPTS9eA5E", "replyto": "4UPTS9eA5E", "signatures": ["ICLR.cc/2026/Conference/Submission6354/Reviewer_bDWW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6354/Reviewer_bDWW"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6354/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762121965856, "cdate": 1762121965856, "tmdate": 1762918643392, "mdate": 1762918643392, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}