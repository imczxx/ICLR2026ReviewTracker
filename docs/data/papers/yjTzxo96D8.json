{"id": "yjTzxo96D8", "number": 15141, "cdate": 1758248149511, "mdate": 1759897325406, "content": {"title": "Revisiting Spectral Representations in Generative Diffusion Models", "abstract": "Diffusion models have shown remarkable performance on diverse generation tasks. Recent work finds that imposing representation alignment on the hidden states of diffusion networks can both facilitate training convergence and enhance sampling quality, yet the mechanism driving this synergy remains insufficiently understood. In this paper, we investigate the connection between self-supervised spectral representation learning and diffusion generative models through a shared perspective on perturbation kernels. On the diffusion side, samples (e.g., images, videos) are produced by reversing a stochastic noise-injection process specified by Gaussian kernels; on the spectral representation side, spectral embeddings emerge from contrasting positive and negative relations induced by random perturbation kernels. Motivated by this, we propose a self-supervised spectral representation alignment method to facilitate diffusion model training. In addition, we clarify how joint spectral learning can benefit diffusion training from a geometric perspective. Furthermore, we find that the optimization of the spectral alignment objective is in an equivalent form of diffusion score distillation in the representation space. Building on these findings, we integrate a spectral regularizer into diffusion training objectives to improve the performance of diffusion models on multiple datasets. Experiments across images and 3D point clouds show consistent gains in generation quality.", "tldr": "", "keywords": ["diffusion models", "representation learning", "spectral"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/616d4ef2c8391c66c87c7b42e61fc8b1cef53cad.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors propose a spectral regularizer for diffusion models with a projection head trained to approximate the top-K eigenfunctions of the forward-diffusion kernel. The authors link the resulting objective to score-distillation in representation space and report gains on several visual and point cloud datasets."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The method proposed is teacher-free, and the authors connect it to the forward-diffusion kernel, which is good.\nThe implementation should be fairly efficient, with a time-conditioned head. \nThe data ablations considered are reasonable for synthetic data, images, and point clouds. \nThe results seem to yield mild but consistent gains, especially on point clouds or low res images."}, "weaknesses": {"value": "The reported results are severely lacking in statistical significance. For all trend figures and tables the authors should (at the very least) report average and std/err over three or more seeds. Because of the mild improvements in some cases, and the lack of multi-run statistics, it is hard to judge significance.\n\nThe results are limited to mostly low-resolution experiments, and there seems to be a negative correlation in Table 1 between FID improvements and scale."}, "questions": {"value": "1. It is hard to judge the significance of the reported results due to the lack of reported statistics over multiple runs. Can you report mean+std error for each of the metric figure/tables in the paper?\n\n2. It would be worthwhile to understand the reason behind the diminishing FID improvements in table 1. Are these due to scale, or perhaps working with latents on ImageNet? Statistics over multiple runs could also help here, as well as additional latent diffusion experiments time allowing."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YZvqDexNs6", "forum": "yjTzxo96D8", "replyto": "yjTzxo96D8", "signatures": ["ICLR.cc/2026/Conference/Submission15141/Reviewer_A9rz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15141/Reviewer_A9rz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15141/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761746427791, "cdate": 1761746427791, "tmdate": 1762925458768, "mdate": 1762925458768, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper explores the intrinsic link between self-supervised Spectral Representation Learning (SRL) and Diffusion Models through the shared lens of time-dependent perturbation kernels. The authors propose a novel self-supervised spectral regularization loss to align the intermediate representations of the diffusion network, successfully avoiding the need for external pre-trained encoders. Empirical results consistently demonstrate that the proposed method significantly enhances the performance across both image and 3D point cloud synthesis tasks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The method offers a novel and versatile self-supervised regularization, requiring no external pre-trained encoder.\n- The proposed method is applicable across multiple modalities and resolutions.\n- Solid theoretical analysis connects the spectral loss to the mode-seeking dynamics of score distillation."}, "weaknesses": {"value": "- Sensitivity analysis for the critical regularization hyperparameter $\\lambda$ is insufficient.\n- There lacks a discussion of the specific intermediate hidden layer for alignment.\n- The improvements in FID scores, while consistent, are relatively modest."}, "questions": {"value": "1. **Ablation on simplest contrastive loss.** Despite sufficient motivation explanations and theoretical analysis, practically, I believe the proposed SRL factually acts like a consistent loss across different perturbation levels. A similar line of this work is to use the simplest contrastive loss (w/ or w/o negative samples) to align the intermediate features across different noises. Could the authors provide an ablation study on this simplest contrastive loss to compare with the proposed SRL, to better justify the effectiveness of SRL?\n\n2. **The improvement is limited.** Despite without using any external pre-trained encoder, the improvement on FID seems to be insufficient to demonstrate the effectiveness of the proposed method, especially that on CelebA. Could the authors provide more comprehensive experiments including:\n   - combining SRL with REPA and reporting the comparision\n   - similar to REPA, showing how many times can SRL boost training\n\n3. **Training curve.** Could the authors explain why the performance of SRL is worse than the baseline at the beginning of training on ImageNet-64 in Figure 2?\n\n4. **Sensitivity of $\\lambda$.** The regularization weight $\\lambda$ is critical to the final performance. Could the authors provide a sensitivity analysis on $\\lambda$ to show how it affects the final performance?  \n\n5. **Ablation on the hidden layer.** Could the authors provide an ablation study on which intermediate hidden layer to apply the proposed SRL? How does it affect the final performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WeqdOOCluU", "forum": "yjTzxo96D8", "replyto": "yjTzxo96D8", "signatures": ["ICLR.cc/2026/Conference/Submission15141/Reviewer_CYG5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15141/Reviewer_CYG5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15141/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761915797389, "cdate": 1761915797389, "tmdate": 1762925458255, "mdate": 1762925458255, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper adds an additional self supervised alignment loss to the standard denoising score matching objective, so that similar samples in the representation space are expected to be clustered while different samples are pushed apart."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Adding extra self supervised regularization to the representation space for training diffusion models is interesting."}, "weaknesses": {"value": "1. The motivation of the proposed alignment method is unclear. What is rationale behind minimizing the KL divergence term in (16)? Why do we want the score of negative samples to match the score of positive samples? Why is this beneficial?\n\n2. The performance gain from the proposed algorithm is marginal. In particular, in table 1, very often, the metrics only marginally improved. From my experience, such marginal improvement won't affect the perceptual quality of the generated samples, and I cannot find any qualitative results for image generation in the paper."}, "questions": {"value": "1. I don't understand the reasoning in line 305-310. Why minimizing the KL divergence leads to mode seeking behavior, clustering similar data while pushing apart dissimilar ones? Please explain. \n\n2. The performance gain is marginal, does your method improve image quality at all? \n\n3. Have you tried CFG? How does the model performance change when you apply CFG? Please plot the FID v.s. Inception curve for varying guidance strength for both the base model and your model."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3dJIARymtQ", "forum": "yjTzxo96D8", "replyto": "yjTzxo96D8", "signatures": ["ICLR.cc/2026/Conference/Submission15141/Reviewer_R6Ra"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15141/Reviewer_R6Ra"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15141/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761938917283, "cdate": 1761938917283, "tmdate": 1762925457780, "mdate": 1762925457780, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a method that applies spectral representation learning to diffusion models. To do this, additional MLP projection head is attached for learning spectral embedding and a spectral loss is added to train the embedding and this works as a regularizer to encourage representation alignment between perturbed samples derived from the same clean data. This can be seen as replacing the perturbation kernel used in traditional spectral representation learning with the diffusion noise kernel. Without any external model like REPA, the model could achieve better performance than baseline models on both ImageNet image generation and 3D point-cloud generation tasks."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper proposes a novel connection between spectral representation learning and diffusion models, providing new insight by viewing them under a unified framework.\n- The paper is well-written, with clear explanations of the preliminary background and methodology, which enhances readability.\n- The method appears relatively easy to implement and improves internal representations without relying on any external models.\n- The approach demonstrates noticeable performance improvements across very different domains, including ImageNet and 3D point cloud generation."}, "weaknesses": {"value": "- The comparison experiments are somewhat limited. Although REPA is included, comparisons with other feature regularization methods such as Dispersive Loss are missing.\n- While the method does not require external models, its generation quality appears lower than REPA, raising questions about its practical usefulness in real applications.\n- In Figure 2, unlike REPA, the method does not seem to converge faster or show any clear trend in training behavior. To confirm that the improvement is not due to random fluctuations, multiple runs with statistical analysis would be necessary."}, "questions": {"value": "- How much additional computational cost is introduced by adding the spectral branch?\n- Are there any visualization comparisons for the image generation results?\n- Is f in L133 a typo of h?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1j0b6I6lS6", "forum": "yjTzxo96D8", "replyto": "yjTzxo96D8", "signatures": ["ICLR.cc/2026/Conference/Submission15141/Reviewer_xxCz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15141/Reviewer_xxCz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15141/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761985721076, "cdate": 1761985721076, "tmdate": 1762925457222, "mdate": 1762925457222, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}