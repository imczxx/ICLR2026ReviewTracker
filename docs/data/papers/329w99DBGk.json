{"id": "329w99DBGk", "number": 2806, "cdate": 1757255651524, "mdate": 1759898126200, "content": {"title": "Cross-Reflect: Empowering Multi-Modal Agents with Joint Reasoning Across Trajectories", "abstract": "Despite rapid progress in vision–language models (VLMs), small VLMs still struggle to serve as effective agents capable of coherent multi-step tool use, especially in settings where fine-tuning is impractical due to data or cost constraints. \nTo address these limitations, we introduce Cross-Reflect, a training-free framework for reflection-guided trajectory optimization. \nCross-Reflect generates multiple candidate trajectories, applies structured reflection to critique and refine them, and performs cross-trajectory selection to identify the most reliable solution. \nIt is instantiated via an extension of the DSPy programming paradigm, which provides modular support for multimodal inputs. \nExtensive experiments across static and dynamic knowledge-intensive VQA benchmarks demonstrate that Cross-Reflect consistently improves small VLMs by enabling flexible tool usage and trajectory-level self-reflection, achieving average relative improvements of 10.5\\% for proprietary models and 28.1\\% for open-source models over baseline methods.\nFurther analysis shows that our approach achieves comparable performance to methods requiring model fine-tuning, and even surpasses them in certain cases.", "tldr": "", "keywords": ["MLLM agent", "programming", "self reflection"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/011313fa9c0210d334c0d595b07691da5b5b25c2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes Cross‑Reflect, a training‑free, test‑time framework for VLM agents that (i) samples multiple tool‑use trajectories, (ii) performs structured, trajectory‑level reflection after each rollout, and (iii) conducts a cross‑trajectory selection to pick the final answer. The approach is implemented by extending DSPy from language‑only to multi‑modal agent programming, and integrates a suite of tools (web/image search, Wikipedia, OCR, detection, counting)."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well motivated, pointing out the need for small VLMs to solve hard VQA problems.\n2. The proposed method, Cross-Reflect, shows performance gain compared with training-free QA baselines."}, "weaknesses": {"value": "- The paper is poorly written. The organization of the experimental section (especially Section 4.4) is confusing and lacks a clear logical flow. Figure 1 is poorly presented, making it difficult for readers to understand the content.\n\n- The method is not open-sourced. I strongly urge the authors to release their code to facilitate reproducibility and independent verification.\n\n- The experiments are insufficient and incomplete.\n\n  - The results for HAMMER and OmniSearch are incomplete. The baseline comparison is weak without a thorough evaluation of these recent methods.\n\n  - Cross-Reflect should also be tested on other open-source models. Evaluating only on Qwen-2.5-VL-7B is inadequate, as the prompt design may have been optimized specifically for the model.\n\n  - Section 4.3 (“Comparison with training-based methods”) is unconvincing, since LLaVA is a relatively weak base model compared with Qwen-2.5-VL.\n\n- The paper lacks an in-depth analysis of the proposed method.\n\n  - Does the VLM trajectory improve as more reflections are generated? Does the selector tend to favor later trajectories? How many trajectories are produced per question?\n\n  - The ablation studies are insufficient. What happens if the selector is removed and the final answer is simply taken from the last trajectory? I understand that removing the reflection module makes Cross-Reflect similar to ReAct-BoN, but what if the reflection prompt were incorporated directly into the actor VLM? This could serve as a prior for better problem solving in the “Reflection Guidance” component of the reflector prompt.\n\n- The time cost of the proposed method is unclear. Given the high token usage and computational overhead, the authors should compare it with reasoning-enhanced models of similar size (e.g., Qwen3-VL-8B)."}, "questions": {"value": "- Include the prompt used for the selector.\n\n- In Appendix A, the sentence “GPT-4o-mini was run without GPU acceleration” is unprofessional and potentially misleading. Shouldn't it specify that the model was accessed via an API instead?\n\n- I am curious whether the proposed method remains effective in a text-only setting. Are there any components in the design that are specifically tailored for VLMs?\n\n- I also wonder how large a VLM would need to be to achieve comparable performance to Reflect-Cross on 7B-scale models."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "trigMeLlVK", "forum": "329w99DBGk", "replyto": "329w99DBGk", "signatures": ["ICLR.cc/2026/Conference/Submission2806/Reviewer_7rn3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2806/Reviewer_7rn3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761701136789, "cdate": 1761701136789, "tmdate": 1762916385055, "mdate": 1762916385055, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper explores how small LLMs, which are often considered unreliable due to failures in tool selection and ineffective reasoning trajectory construction, can function as effective agents for coherent multi-step tool use. The motivation lies in their low cost and suitability for large-scale deployment.  \nPrevious methods either focus on reflection limited to final answers or chains of thought, or rely on reward models that require training on curated datasets and therefore lack generality.  \nCross-Reflect leverages DSPy with minimal manual prompting to extend to vision-language tasks. It generates multiple candidate trajectories, performs structured reflection to critique and refine them, and conducts cross-trajectory selection to identify the most reliable solution.  \nExtensive experiments across static and dynamic VQA benchmarks demonstrate that Cross-Reflect consistently improves small VLMs by enabling flexible tool usage and trajectory-level self-reflection, achieving average relative improvements of 11% for proprietary models and 28% for open-source models over baseline methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* Expands DSPy into the multimodal setting.\n* Proposes trajectory-level reflection as an in-context, training-free approach for VQA reasoning."}, "weaknesses": {"value": "* The paper is generally readable but has presentation issues that reduce clarity and make it harder for readers to grasp the main ideas.\n   * The description of DSPy in Section 3.1 should appear earlier, for example in the introduction, to help readers establish a shared foundation.\n   * Figure 1 and its reference text are too far apart, and the same applies to Table 1.\n   * The detailed procedure of cross-trajectory selection is insufficiently explained.\n\n* The set of baselines is limited. It would be valuable to include some search-based algorithms in *Zhu, K., Li, H., Wu, S., Xing, T., Ma, D., Tang, X., Liu, M., Yang, J., Liu, J., Jiang, Y. E., Zhang, C., Lin, C., Wang, J., Zhang, G., & Zhou, W. (2025). Scaling test-time compute for LLM agents. arXiv preprint arXiv:2506.12928*.\n\n* The paper lacks a detailed analysis explaining why Cross-Reflect outperforms the baselines. See the `Questions` section below for specific suggestions.\n\n* Since Cross-Reflect accumulates previous trajectory histories for subsequent planning, it represents a tradeoff between planning within a single trajectory (based on reflection on failed states) and planning across multiple trajectories (based on trajectory-level reflection). While this improves performance, it also increases computational cost. Efficiency should be discussed in more depth. Notice that Table 8 shows that moving from zero-shot to Cross-Reflect+ yields 96% and 138% performance gains, but token consumption increases nearly 1000 times, which may indicate that the method is not very efficient in terms of computational cost.\n* The generalizability of Cross-Reflect appears limited. For a new task, even within the same domain, the method requires generating new trajectory histories with corresponding reflections."}, "questions": {"value": "* Why does Cross-Reflect achieve larger performance gains on proprietary models than on open-source ones?\n\n* In Section 4.4, since the choice of the initial tool is critical, does Cross-Reflect perform better because it identifies the correct first tool with fewer trial steps?\n\n* How does Cross-Reflect handle redundant tool invocation and logical inconsistencies compared to the baselines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6igCYyN0Yu", "forum": "329w99DBGk", "replyto": "329w99DBGk", "signatures": ["ICLR.cc/2026/Conference/Submission2806/Reviewer_Lbfm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2806/Reviewer_Lbfm"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761811175714, "cdate": 1761811175714, "tmdate": 1762916384872, "mdate": 1762916384872, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Cross-Reflect, a training-free framework for optimizing reasoning trajectories in multi-modal agents. The motivation is that fine-tuning small Vision-Language Models (VLMs) can be impractical due to computational and data constraints. Cross-Reflect aims to address this by jointly reflecting on reasoning actions and thoughts across multiple trajectories to enhance performance without further training.\nThe method yields notable improvements on visual question answering (VQA) benchmarks, reportedly up to +10% for proprietary models and +28% for open-source models over baseline methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper proposes a novel and intuitive idea, a reflection-based, training-free optimization method for small VLMs.\n- The structure and presentation are overall clear and logically organized.\n- The authors provide ethics, reproducibility, and broader impact statements, demonstrating awareness of research responsibility."}, "weaknesses": {"value": "- The proposed method resembles a best-of-N search over reasoning trajectories rather than a novel optimization mechanism.\n- Although the paper claims reproducibility (see reproducibilty statement) and builds on an open-source framework (DSPy), the authors do not release code, which undermines the reproducibility claim.\n- There is no discussion of the method’s limitations, e.g., potential computational cost or failure cases.\n- Tables are difficult to read, especially Table 1, the font is too small.\n- Similarly, Figure F is blurred.\n- The authors claim that their training-free method outperforms fine-tuning in some cases and present comparison with OmniSearch to bakc up this statement.\nHowever, the comparison with OmniSearch is somewhat misleading: at lines 365–366, the paper claims that Cross-Reflect + Qwen2.5-VL-7B surpasses OmniSearch. However, if OmniSearch uses an earlier backbone (e.g., Qwen-VL), then the comparison is unfair since Qwen2.5-VL is a much stronger model. A fair comparison would require both methods to use the same backbone. I highly encourage authors to add an experiment with the same backbone for fair comparison. Otherwise the claim cannot hold."}, "questions": {"value": "- What exactly is meant by “action-thinking dual reflection” (line 148)? Please clarify how this differs from standard self-reflection or reasoning re-evaluation methods.\n- How do you define “small VLMs” in this context?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "brlSsnWNaN", "forum": "329w99DBGk", "replyto": "329w99DBGk", "signatures": ["ICLR.cc/2026/Conference/Submission2806/Reviewer_Tzbh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2806/Reviewer_Tzbh"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761922529848, "cdate": 1761922529848, "tmdate": 1762916384057, "mdate": 1762916384057, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents Cross-Reflect, a training-free framework for improving small vision-language models (VLMs) on knowledge-intensive visual question answering tasks. The approach extends DSPy to support multimodal inputs and introduces a reflection-guided mechanism that generates multiple reasoning trajectories, produces structured reflections to guide subsequent rollouts, and performs cross-trajectory selection to identify the most reliable answer. Experiments on InfoSeek, EncVQA, and Dyn-VQA demonstrate substantial improvements over baseline methods, with the framework achieving competitive performance compared to fine-tuned approaches."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses an important problem: enabling small VLMs to perform complex multi-step reasoning without fine-tuning, which has significant practical implications for resource-constrained deployments. This motivation is clear and well-articulated throughout the manuscript.\n\nThe experiments are thorough, covering multiple benchmarks (InfoSeek, EncVQA, Dyn-VQA), both proprietary and open-source models, and include detailed ablations demonstrating the contribution of key components. The experimental design allows for fair comparison across different model families and baseline methods."}, "weaknesses": {"value": "1. While the empirical results are strong, the core technical contributions appear incremental. The framework primarily combines existing concepts (ReAct-style reasoning, trajectory sampling, reflection mechanisms) rather than introducing fundamentally new techniques. The reflection mechanism, while structured and effective, resembles best-of-N sampling with LLM-based judging.\n\n2. Although the authors claim several innovations (DSPy initialization, structured reasoning, trajectory-level reflection), the relationship to ReAct and what specifically makes this more than an engineered extension remains unclear. The heavy reliance on ReAct as both a baseline and component suggests the contribution may be more incremental than presented. \n\n3. The paper provides limited insight into when and why Cross-Reflect fails, or how reflection might introduce new errors. The qualitative examples in the appendix are helpful but focus on success cases. More analysis of failure modes would strengthen the work and provide guidance for future improvements.\n\n4. The paper does not adequately address known limitations of self-reflection in LLMs. While the authors distinguish their trajectory-level reflection from answer-level reflection, concerns about self-verification capabilities remain partially unaddressed. The references provided by reviewers regarding CoT and self-reflection limitations deserve more thorough engagement."}, "questions": {"value": "1. The cross-model experiments (Planning: Qwen, Reflection: GPT-4o-mini achieving 37.4%) suggest that model alignment matters for reflection quality. Why does weak-model reflection sometimes hurt strong-model performance? This finding deserves deeper investigation as it has implications for the self-reflection paradigm.\n\n2. How does the method scale with the number of trajectories? Is there a point of diminishing returns? The paper samples 3 trajectories but does not explore this design choice systematically.\n\n3. Can you provide more details on when reflection successfully corrects errors versus when it fails or introduces new mistakes? What patterns distinguish successful reflection from unsuccessful attempts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "wHRcRebdSl", "forum": "329w99DBGk", "replyto": "329w99DBGk", "signatures": ["ICLR.cc/2026/Conference/Submission2806/Reviewer_5Bxf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2806/Reviewer_5Bxf"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761975522244, "cdate": 1761975522244, "tmdate": 1762916383739, "mdate": 1762916383739, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}