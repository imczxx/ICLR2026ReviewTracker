{"id": "o6OWfKqCcw", "number": 24298, "cdate": 1758355095063, "mdate": 1759896772171, "content": {"title": "SYN-TITAN: Synthetic Tabular Intelligence using Transformers and Adversarial Networks", "abstract": "The growing need for privacy-preserving synthetic tabular data has led to the development\nof generative models, particularly generative adversarial networks (GANs) such as CTGAN (Conditional\nGAN) and Enhanced CTGAN. While these models have demonstrated success in tabular data synthesis,\nthey suffer from mode collapse, weak rare-category representation, and limited domain adaptability,\noften requiring manual tuning for different datasets. Furthermore, GAN-based approaches lack contextual\nawareness, making them ineffective at preserving logical feature relationships and real-world constraints.\nThis paper introduces SYN-TITAN (Synthetic Tabular Intelligence using Transformers and Adversarial\nNetworks), a hybrid LLM-GAN framework that integrates large language models (LLMs) with adversarial\nlearning to enhance data fidelity, privacy compliance, and scalability. LLMs assist in feature engineering,\ndata augmentation, and evaluation, ensuring that synthetic data maintains semantic integrity. SYN-TITAN\nis benchmarked against CTGAN, Enhanced CTGAN, and other state-of-the-art synthetic data generators\nusing public datasets, demonstrating superior statistical alignment, rare-category preservation, and domain\nadaptation. Our findings indicate that LLM-guided GAN training can significantly improve synthetic tabular\ndata quality, addressing key challenges in privacy-sensitive domains such as healthcare and finance. This\nwork provides a scalable and interpretable hybrid approach to synthetic data generation, paving the way for\nmore context-aware, adaptable, and reliable synthetic data frameworks.", "tldr": "", "keywords": ["Data Augmentation", "Data Privacy", "Generative Adversarial Networks (GANs)", "Hybrid AI Models", "Imbalanced Data", "Large Language Models (LLMs)", "Machine Learning", "Synthetic Data Generation", "Tabular Data"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/78d8d5cda2f47d4e34cdd20ba0a597bcf1b4557f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper, SYN-TITAN: Synthetic Tabular Intelligence using Transformers and Adversarial Networks, proposes a hybrid framework that integrates large language models (LLMs) with generative adversarial networks (GANs) to improve synthetic tabular data generation.\nThe system uses an LLM for three stages: pre-processing, generation, and post-processing. Experiments are conducted only on the UCI Adult Census Income dataset, comparing SYN-TITAN with CTGAN and Enhanced CTGAN. The reported results suggest minor improvements in logical consistency and correlation preservation, though the evaluation remains narrow in scope."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "S1. Addresses an important problem of privacy-preserving tabular data synthesis.\n\nS2. The motivation for integrating LLM reasoning with GAN generation is conceptually interesting.\n\nS3. The paper is easy to follow."}, "weaknesses": {"value": "W1. Shallow Technical Contribution:\nThe main novelty is a heuristic prompt that asks an LLM to list key features and domain constraints, followed by a simple filtering step to remove rows that violate those rules. There is no principled algorithmic innovation—the LLM’s outputs are used as static hints rather than being integrated into the training objective. The paper lacks ablations on prompt design, alternative formulations, or theoretical justification for why the chosen prompting strategy is optimal or robust.\n\nW2. Weak Engagement with Related Work:\nThe paper positions itself mainly against CTGAN and Enhanced CTGAN, ignoring a large body of recent literature on tabular synthesis and LLM-based tabular modeling. Important works include:\n\n- Tabular Data Synthesis with Generative Adversarial Networks: Design Space and Optimizations (VLDB J., 2024).\n- Transformers for Tabular Data Representation: A Survey of Models and Applications. (Trans. Assoc. Comput. Linguistics 2023)\n- More recent models such as CTAB-GAN+ (https://arxiv.org/abs/2204.00401), TabDDPM (https://arxiv.org/abs/2209.15421), and other diffusion- or LLM-based synthesizers that already provide superior fidelity and controllability.\n\nWithout comparing against these, the claimed novelty and improvement are unsubstantiated.\n\nW3. Extremely Limited Evaluation:\nThe paper uses only one dataset (Adult Census) and one weak baseline (CTGAN). This cannot support any claim of generalization or scalability. No tests on complex or domain-specific datasets (e.g., healthcare, finance) where LLM prior knowledge may fail. No benchmarking with standard suites like SDGym or evaluation on downstream ML utility (e.g., TSTR). Privacy is mentioned but not implemented—“differential privacy” is only stated as planned.\n\nW4. Overstated Claims and Missing Analysis:\nThe results show modest or negligible gains over CTGAN, and sometimes even worse distributional metrics. Logical consistency is enforced by post-hoc deletion, not by integrated learning. No analysis of prompt sensitivity, failure cases, or computational cost is provided. The method’s reliance on LLM priors also raises questions about hallucinated or domain-biased constraints, which are not examined.\n\nW5. Overall Assessment:\nDespite an appealing idea (LLM-guided GAN synthesis), the execution is methodologically weak, empirically narrow, and not competitive with existing baselines. The work lacks depth, novelty, and convincing evidence to merit acceptance at ICLR."}, "questions": {"value": "Please see the above weaknesses W1--W4."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "v3MZsVcV6t", "forum": "o6OWfKqCcw", "replyto": "o6OWfKqCcw", "signatures": ["ICLR.cc/2026/Conference/Submission24298/Reviewer_aoDd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24298/Reviewer_aoDd"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24298/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760753212339, "cdate": 1760753212339, "tmdate": 1762943034874, "mdate": 1762943034874, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a GAN based method using LLM to generate synthetic data."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "None."}, "weaknesses": {"value": "The paper is clearly not qualified for a scientific publication. It is more like a unfinished technical report. Using bullet points throughout the presentation. There are a lot of work in this field, while the author only bechmark one of them, CTGAN in section 5.2. I suggest the author first do a carefully literature review, and try different methods before deploying yours (e.g. tabsyn, tabdppm, beGreaT, etc.)."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1XbvFzl4WY", "forum": "o6OWfKqCcw", "replyto": "o6OWfKqCcw", "signatures": ["ICLR.cc/2026/Conference/Submission24298/Reviewer_wr1n"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24298/Reviewer_wr1n"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24298/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761494055228, "cdate": 1761494055228, "tmdate": 1762943034177, "mdate": 1762943034177, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a synthetic data generative model based on a hybrid model built on LLMs and GAN. This paper uses LLM as an auxiliary tool that helps GAN for data preprocessing, enriching context, and post-processing."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "None"}, "weaknesses": {"value": "- The motivation of the study is rather generic and not specific. Unclear whether this LLM integration will directly address the limitation that motivates this study (e.g., mode collapse, rare category underrepresentation). \n- The integration of LLM is superficial. This paper lacks justification for why LLM can be a good add-on to GAN. \n- No discussion on the diffusion-based model, which has become increasingly state-of-the-art in this field. \n- Experiment is limited in scope (e.g., only one dataset, very basic metrics and no mention of further synthetic data utility)."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "buZMgquj08", "forum": "o6OWfKqCcw", "replyto": "o6OWfKqCcw", "signatures": ["ICLR.cc/2026/Conference/Submission24298/Reviewer_Zpno"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24298/Reviewer_Zpno"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24298/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761578183153, "cdate": 1761578183153, "tmdate": 1762943033823, "mdate": 1762943033823, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents SYN-TITAN, a hybrid LLM-GAN framework for synthetic tabular data generation. But it’s purely AI-generated or with a very heavy AI assistance."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "NA"}, "weaknesses": {"value": "- No figure, no method detail\n- Wrong citation format, and some references are from AI hallucinations"}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["Yes, Research integrity issues (e.g., plagiarism, dual submission)"]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2eoot5VrRS", "forum": "o6OWfKqCcw", "replyto": "o6OWfKqCcw", "signatures": ["ICLR.cc/2026/Conference/Submission24298/Reviewer_aMKx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24298/Reviewer_aMKx"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24298/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761899233124, "cdate": 1761899233124, "tmdate": 1762943033582, "mdate": 1762943033582, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}