{"id": "VAv1rrPR1A", "number": 4191, "cdate": 1757627101226, "mdate": 1759898048447, "content": {"title": "Mechanism of Task-oriented Information Removal in In-context Learning", "abstract": "In-context Learning (ICL) is an emerging few-shot learning paradigm based on modern Language Models (LMs), yet its inner mechanism remains unclear. In this paper, we investigate the mechanism through a novel perspective of information removal. Specifically, we demonstrate that in the zero-shot scenario, LMs encode queries into non-selective representations in hidden states containing information for all possible tasks, leading to arbitrary outputs without focusing on the intended task, resulting in near-zero accuracy. Meanwhile, we find that selectively removing specific information from hidden states by a low-rank filter effectively steers LMs toward the intended task. Building on these findings, by measuring the hidden states on carefully designed metrics, we observe that few-shot ICL effectively simulates such task-oriented information removal processes, selectively removing the redundant information from entangled non-selective representations, and improving the output based on the demonstrations, which constitutes a key mechanism underlying ICL. Moreover, we identify essential attention heads inducing the removal operation, termed Denoising Heads, which enables the ablation experiments blocking the information removal operation from the inference, where the ICL accuracy significantly degrades, especially when the correct label is absent from the few-shot demonstrations, confirming both the critical role of the information removal mechanism and denoising heads.", "tldr": "We propose a new perspective of the in-context learning mechanism as a task-oriented information reduction.", "keywords": ["Mechanistic Interpretability", "In-context Learning", "Large Language Model"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2afc7a40f135bfcc6c712fec7f6a748e6ef70bd2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper argues that few-shot in-context learning (ICL) works by selectively removing task-irrelevant information from query representations, steering the model toward the intended task. In zero-shot settings, injecting a low-rank \"task-verbalization\" filter that projects onto a Task-Verbalization Subspace (TVS) dramatically improves accuracy even while preserving only ~0.7% of dimensions, while in few-shot ICL the model spontaneously moves hidden states toward this TVS, as measured by geometric metrics that rise in middle-to-late layers. The paper identifies \"Denoising Heads\" (DHs)—attention heads whose ablation disrupts this removal operation—which are largely independent of induction heads and show local re-encoding patterns over query tokens; ablating DHs significantly reduces ICL accuracy and nearly collapses performance in unseen-label settings, demonstrating the causal importance of this mechanism. The authors note this mechanism applies to clustering-style classification tasks but not bijective tasks like translation, with experiments conducted across multiple text classification datasets and models including LLaMA and Qwen variants."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Task‑oriented information removal operationalized via a low‑rank subspace and two geometric metrics that correlate with accuracy and layer depth. \n\n2. identification and causal ablations of Denoising Heads, with independence from induction heads and a sensible local re‑encoding attention pattern. \n\n3. Explicit failure case on bijective tasks (translation/fact recall) and an explanation of why low‑rank removal should not help there. \n\n4. Broad, careful experiments across six datasets and three models, with appendix replications and unseen‑label analyses that stress‑test induction‑only stories."}, "weaknesses": {"value": "1. Theory is largely heuristic. The link between covariance and “information removal” is argued but not formally proved; metric choices and DH thresholds (±3.5%) are somewhat ad hoc. \n\n2. Narrow task family. The focus is single‑label classification; reasoning, chain-of‑thought, or generation settings are not studied, and the paper itself notes the mechanism likely does not apply to bijective mappings. \n\n3. Scale and generality. Only up to 8B models are used. It remains unclear whether DH distributions and metric trends stabilize for larger base or instruction‑tuned LMs."}, "questions": {"value": "1. How sensitive are results to scanning all layers/heads? Could you provide one full‑layer run on a smaller model to confirm no hidden DH clusters?\n\n2. Do your metrics or DH patterns say anything in multi‑class generative outputs (e.g., natural language rationales)? If not, what would be needed?\n\n3. Any preliminary results on larger models (e.g., 13B/34B) or instruction‑tuned variants to test whether DHs persist or shift?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HGbXFs9KV5", "forum": "VAv1rrPR1A", "replyto": "VAv1rrPR1A", "signatures": ["ICLR.cc/2026/Conference/Submission4191/Reviewer_sEGe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4191/Reviewer_sEGe"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4191/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761886484073, "cdate": 1761886484073, "tmdate": 1762917221767, "mdate": 1762917221767, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the internal mechanism of In-Context Learning (ICL) in large language models (LLMs) from a new perspective — task-oriented information removal. Instead of viewing ICL as pattern imitation or label copying via Induction Heads, the authors argue that few-shot demonstrations act as filters that suppress task-irrelevant information in the hidden representations.\n\nTo support this view, they introduce two novel probing metrics: Covariance Flux through the Task-Verbalization Subspace (TVS) and Eccentricity, which quantify how hidden-state variance aligns with task-relevant directions and how anisotropic (filtered) the representations become. Using these tools, they demonstrate that (1) LLMs spontaneously recover the TVS during ICL, (2) this process can be measured as an information-removal trajectory across layers, and (3) a new class of attention heads, Denoising Heads, drive this mechanism, overcoming the well-known limitation of Induction Heads when facing unseen labels."}, "soundness": {"value": 4}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "1. **Novel probing metrics with clear interpretability.**\nThe introduction of Covariance Flux through TVS and Eccentricity provides a fresh, quantitative lens for studying internal representation dynamics of LLMs. These metrics go beyond uncovering new ICL mechanisms and identifying denoising heads, enabling a measurable understanding of how information filtering evolves within transformer layers.\n\n2. **New mechanism of ICL: task-oriented information removal.**\nThis paper shifts the focus of ICL mechanism from token-copying to information filtering, which deepens our conceptual understanding of ICL.\n\n3. **Identification of Denoising Heads addressing the Induction-Head limitation.**\nThe discovery of Denoising Heads is an insightful contribution. These heads operate locally and semantically, filtering query representations rather than copying lexical patterns, thereby explaining why LLMs can generalize to unseen labels -- something Induction Heads cannot do.\n\n4. **Strong empirical grounding.**\nThe experiments are extensive and solid."}, "weaknesses": {"value": "**Overly dense and somewhat disorganized presentation.**\nWhile the findings are rich, the paper feels overly packed. The main sections attempt to cover TVS analysis, metric design, mechanistic ablations, and head identification all at once. The narrative flow occasionally sacrifices clarity for compactness, making it harder for readers to see the conceptual through-line."}, "questions": {"value": "Suggestion:\n\n **Center the paper on the probing methodology.** \n\nIf the authors had focused the paper around the two new metrics (Covariance Flux and Eccentricity) as a general probing framework, the contribution would appear sharper and of broader relevance. The ICL mechanism and Denoising Head discovery could then be presented as compelling applications of this framework, rather than parallel findings competing for attention. \n\n**A more layered structure** -- with detailed exposition of the probing metrics in the main text and the some extended empirical findings moved to the appendix -- would make the paper both clearer and more impactful. You can organize the paper similar to [1].\n\nMinors:\n\n1. In Figure 3, I understand that the marker represents the lower bound of information removal with a value between 0 and 1. However, please include at least one reference marker (for example, the marker size corresponding to no information removal) so that readers can intuitively gauge the approximate lower bound portion of information removed.\n\n[1] Ren, Yi, and Danica J. Sutherland. \"Learning dynamics of llm finetuning.\" arXiv preprint arXiv:2407.10490 (2024)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 10}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VOP5vIevJg", "forum": "VAv1rrPR1A", "replyto": "VAv1rrPR1A", "signatures": ["ICLR.cc/2026/Conference/Submission4191/Reviewer_5eyE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4191/Reviewer_5eyE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4191/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978792515, "cdate": 1761978792515, "tmdate": 1762917221344, "mdate": 1762917221344, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a novel interpretation of the ICL mechanism by viewing it as a process to remove redundant information in the query’s hidden states for the targeted tasks. Specifically, the paper applies a low-rank filter on the hidden states for informational removal and finds it boost the performance on the designed tasks significantly. On top of that, the paper conducts further analysis to prove that a few-shot ICL implicitly performs a similar information removal process. Finally, the paper identifies attention heads that are responsible for such removal behaviors and shows that they are crucial for the success of ICL."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper includes well-designed illustrations that well support the claims.\n- The paper provides a perspective for demystifying ICL that is novel yet aligns with many previous observations.\n- To support the claim that ICL performs information removal, the paper provides decently comprehensive analyses that dives deep into the activities of the hidden states of the model using self-crafted analysis methods.\n- The paper includes experiments and discussions to compare their newly discovered Denoysing Heads against the previous induction heads."}, "weaknesses": {"value": "The paper provides many insights on the mechanism of ICL, but the potential future directions built on these findings are less clear."}, "questions": {"value": "What are possible sources of the accuracy improvement from instruction given that instructions do not seem to contribute to the information removal process?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 10}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Tk9d93p9RA", "forum": "VAv1rrPR1A", "replyto": "VAv1rrPR1A", "signatures": ["ICLR.cc/2026/Conference/Submission4191/Reviewer_TE1T"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4191/Reviewer_TE1T"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4191/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762146553500, "cdate": 1762146553500, "tmdate": 1762917221128, "mdate": 1762917221128, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new mechanistic interpretation of in-context learning: rather than copying label tokens via induction heads, large language models perform a task-oriented information removal that compresses query hidden states toward a low-rank, task-verbalization subspace (TVS). The authors demonstrate (1) that injecting a trained low-rank filter into a layer’s residual stream converts near-zero zero-shot performance into strong task-specific outputs; (2) that few-shot demonstrations induce geometric changes in hidden states — increased eccentricity and covariance flux into the learned TVS — consistent with implicit information removal; and (3) that a subset of attention heads  causally contribute to this aligning operation: ablating them reduces covariance flux, eccentricity, and downstream accuracy. The paper thus argues DHs complement induction heads and together explain a broader range of ICL phenomena."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper’s framing of the “information removal → task-verbalization subspace” is conceptually novel and shifts the focus from mere copying to selective suppression\n\nThe paper is well-written and easy to follow. The low-rank injection experiment is simple, interpretable, and effectively demonstrates that a small learned linear filter can steer outputs.\n\n\nThe identification of Denoising Heads (DHs) and the analysis of their interaction with induction heads provide a richer mechanistic understanding of in-context learning."}, "weaknesses": {"value": "Ablating a head is a valid intervention, but zeroing a head output changes the residual stream and thus all downstream activations; the observed drops in Covariance Flux / Eccentricity / Accuracy may partly reflect these propagated network dynamics rather than a head performing a localized denoising operation.\n\nThe method appears to identify DHs only on a subset of layers. If many DHs remain unidentified, ablation results could be underestimated or misattributed. \n\n\nThe DH identification uses fixed relative-change thresholds (e.g., −3.5% / −5%). It is unclear how sensitive results are to threshold choice and whether effects are statistically significant across random seeds / datasets / prompts."}, "questions": {"value": "Can you show that amplifying DH outputs (scale >1) increases Covariance Flux/Eccentricity and improves accuracy in settings where the model is weak (e.g., few-shot with noisy labels)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "oyjwFcxNvd", "forum": "VAv1rrPR1A", "replyto": "VAv1rrPR1A", "signatures": ["ICLR.cc/2026/Conference/Submission4191/Reviewer_M6i4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4191/Reviewer_M6i4"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4191/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762199409052, "cdate": 1762199409052, "tmdate": 1762917220816, "mdate": 1762917220816, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}