{"id": "QmsqyDZKT3", "number": 21138, "cdate": 1758314156894, "mdate": 1759896940115, "content": {"title": "Distinct Computations Emerge From Compositional Curricula In-Context", "abstract": "In-context learning (ICL) research often considers learning a single class of function in-context through a uniform sample of input-output pairs. However, natural language data often has more complex structural correlations, such as the composition of information in a given context. Here, we study such compositional structure in context with a toy modular-arithmetic task and investigate how the in-context curriculum of constituent function examples may alter the computations a transformer learns to solve compositional tasks. We compare models trained with varying in-context curricula of subtasks and the composite task examples. We show that models trained with subtasks in-context generalize to unseen compositional tasks by building an inner representation of the intermediate computation of subtasks. Finally, we find that the model often exhibits a continuous spectrum of a compositional strategy, rather than discrete modes, which are modulated by curriculum design.", "tldr": "We study different strategies transformer learns to solve a compositional modular exponential task when subtasks are given in-context.", "keywords": ["In-context learning", "compositionality", "interpretability"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e6d6fb4be8423cf06dcfe5442c8daa3da2681436.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper studies the compositional ability of small-scale transformers through subtask learning. They provide insights into the mechanism by which the models learn this compositional task and how this is enhanced when given suitable subtasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "(1) The authors choose an interesting and challenging compositional task. To the best of my knowledge, this particular task has not been studied before.\n(2) The authors propose algorithms which are well-motivated from empirical observations and then supplement these hypotheses with well-designed experiments."}, "weaknesses": {"value": "(1) The authors should discuss in some detail how their task differs in complexity from other previous works. Eg. the compositional  structure already arises in learning *linear combinations of two variables* $z = a x + b y$ where the model has to learn addition and multiplication. In addition, there should be clear discussions as to the merits and demerits of the choice of this problem.\n(2) The authors only perform linear probe experiments. The analysis will be strengthened by causal interference or activation patching experiments.\n(3) Due to compute restrictions, it's understandable if the authors could only focus on P < 60. However, the distribution could be skewed for small P, which could lead to inadvertent distributional shifts between train and test sets. One way to mitigate this effect would be to present results for different P, which could give some indication for trends as a function of the modulus. However, due to time constraints, I'd understand if the authors are not able to perform this experiment."}, "questions": {"value": "(1) I suggest putting Related Works section after Introduction. \n(2) An interesting direction to take in future, would be to see if the two compositional maps are inverses of each other, is the compositional task ability hampered? Slightly more non-trivial, would be to find functions f(.) and g(.) which give f(g(x)) = ax mod P or some other easy function.\n(3) Can the authors describe the exact setting that they used for their zero-shot compositional task experiment in Section 3.1? The high accuracy for all curricula-trained model seems a little surprising.\n(4) Do the authors observe any sudden transitions in the accuracies as a function of training time?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DeW6L0A2Dk", "forum": "QmsqyDZKT3", "replyto": "QmsqyDZKT3", "signatures": ["ICLR.cc/2026/Conference/Submission21138/Reviewer_Xz7Y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21138/Reviewer_Xz7Y"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21138/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761760555714, "cdate": 1761760555714, "tmdate": 1762941486155, "mdate": 1762941486155, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies in-context curricula in a toy task (composition of two exponential functions). Experiments suggest that in-context curricula lead to two strategies: a direct one (that even emerges without presence of the curriculum) and a compositional one that first infers the two individual exponential functions and then the composed task."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- I found the paper well written and easy to follow. The figures and captions are nicely done and complement the text well. I think the authors have done a really good job here in terms of the presentation.\n- The toy task and experiment design are overall sensible."}, "weaknesses": {"value": "- What is the relevance of in-context curriculum? The standard in-context few-shot learning setup involves no curriculum. Is the curriculum setup a toy model of some specific class of phenomena in real data? The abstract hints at this, but this remains unspecific. Without such a justification, it remains unclear how interesting the results are. This paper [1] seems highly relevant, and I feel it should be cited, but even then I feel a link to one applied paper isn't necessarily enough to justify why this setup is worth studying.\n\n- The paper only reports experiments on toy models trained on a toy task. Neither theory nor experiments on real-world models nor novel analysis techniques are contributed.\n\n- [this is acknowledged by the authors as a limitations, but I nonetheless want to mention this here as a weakness] The presence of distinct computations is only argued via probing and behavioral tests. Even though there by now are standard causal intervention methods for discovering circuits inside transformers (such as path patching), these are not employed in the current paper.\n\n- line 108-110: Can the authors provide some details on how this was implemented? Were the weights adjusted on the fly based on running averages or similar of the losses? Or how was this done? This is important for replicability.\n\n\n[1] Chen et al, Skills-in-Context: Unlocking Compositionality in Large Language Models, Findings of EMNLP 2024"}, "questions": {"value": "- I'm assuming both the models themselves and the linear probes are all trained with categorical output and cross-entropy, not with a continuous output, right?\n- In lines 134-135 I'm assuming \"zero-shot setup\" means that the authors evaluate only on the *first* sample from the compositional task appearing in the prompt, right?\n- line 116: \"in-context correlations\": it's not clear to me what this term means. Is this a formal notion of correlation?\n- line 238: \"suggesting\" -- this is at best very circumstantial evidence. The causal evidence at the bottom of page 5 is more relevant, but I'd advise toning down the claim in line 238.\n\nMinor: line 316: \"...Change in which the Tasks...\" -- is \"Order\" missing after \"Change\"?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YfjiCKausy", "forum": "QmsqyDZKT3", "replyto": "QmsqyDZKT3", "signatures": ["ICLR.cc/2026/Conference/Submission21138/Reviewer_aLM4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21138/Reviewer_aLM4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21138/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761952491918, "cdate": 1761952491918, "tmdate": 1762941481867, "mdate": 1762941481867, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper explores how transformer models develop different computational strategies when trained with compositional in-context curricula. Using a modular double-exponential arithmetic task $ y = b^{a^x} \\text{mod}P $, the authors demonstrate that including subtask examples (e.g., $ a^x $, $ b^x $) before composite tasks leads models to form internal representations of intermediate computations and generalize systematically to unseen compositions. Through behavioral evaluation, causal interventions, and linear probing, the study shows that curriculum-trained models exhibit structured, compositional reasoning, unlike vanilla few-shot learners that rely on surface-level correlations. The work provides valuable insights into how *data structure* within in-context learning sequences can qualitatively shape model reasoning and supports the broader hypothesis that compositional curricula promote interpretable, modular internal computations."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The formulation of curriculum in-context learning is new and interesting. In practice, when faced with complex reasoning problems, LLMs often break them down into easier subproblems and then aggregate the results at the end. Part of this process can be viewed as curriculum in-context learning, where LLMs must (1) adapt to different subtask problems according to the context and (2) aggregate the subtask conclusions to solve more complex problems. Therefore, I believe the setting considered in the paper is not limited to the in-context learning problem and may lead to a better understanding of LLM reasoning."}, "weaknesses": {"value": "Although the formulation and motivation of this paper are interesting, I believe it would benefit from additional work to strengthen its empirical and theoretical foundations. \n\n1. the experiments are conducted under a fixed modulus $59$ and the same model size, (with limited ablations for $37$ and $41$), which makes it difficult to assess whether the observed phenomena generalize beyond this particular setup. A more systematic exploration across different modular spaces or related compositional domains would strengthen the claims. \n\n2. the analysis relies primarily on linear probing and descriptive visualization; incorporating more direct causal analyses—such as path-patching experiments—could provide stronger evidence that the proposed “subtask composition” representations are indeed functionally utilized. \n\n3. the paper lacks theoretical grounding: it would be valuable to formalize why and when curriculum-trained transformers develop distinct computations, possibly by analyzing architectural biases (e.g., depth, layer specialization) or by contrasting subtask-based and vanilla models under simplified theoretical assumptions. \n\nOverall, the paper has promise but would be substantially stronger with more comprehensive experiments and theoretical insight."}, "questions": {"value": "I feel it hard to understand some parts.\n\n1. It is important to explain why 30 is an important case in the main paper. It is quite confusing at the beginning.\n\n2. Some paraphgraphs are hard to understand: For example, the paragpraph about \"In-Context Curricula Design: Controlling In-context Task Correlations.\" The name \"correlation\" seems not matching the commonly used \"correlation\", making it hard to understand."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "YaS5XbcAlH", "forum": "QmsqyDZKT3", "replyto": "QmsqyDZKT3", "signatures": ["ICLR.cc/2026/Conference/Submission21138/Reviewer_eBqP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21138/Reviewer_eBqP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21138/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762064717520, "cdate": 1762064717520, "tmdate": 1762941417702, "mdate": 1762941417702, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies in-context learning in a compositional task. Specifically, the authors focus on the target function being $y = a^{b^x}$ ; given only $(x,y)$ pairs in-context as well as intermediate values of the form $a^x$, $b^x$. They analyze the performance in both cases with different ratio of examples from each function $a^x,b^x, a^{b^x}$ given in-context. They furthermore analyze the hidden representations of intermediate layers to identify whether the model performs the intermediate computations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is clearly written\n2. Extensive linear probing analyses that show representational differences — e.g., intermediate values can be identified in mid-layers.\n3. Causal mismatch experiments provide evidence that the model relies on subtask information."}, "weaknesses": {"value": "1. Many of the claims made in this paper have already been demonstrated in [1]. In a different but related setting, the authors consider training with 1) $(x,y)$ in-context examples, where $y$ is the output of a ReLU NN, 2) with the intermediate outputs of each layer $(x,y_i)$ also in-context and finally the 3) with also input output pairs of each layer. This setting is intuitively very similar.\n[1] also shows better zero-shot performance of 2,3 compared to 1. The authors also perform an analysis of intermediate layers (see Fig 8). \nIn addition, [2] is related, as the authors demonstrate how models trained on different compositions of functions can successfully compose them using in-context examples.\n\n2. The one shot performance considered in Fig. 2 is not a fair comparison for the baseline, since as I understand it, in the rest of the evaluations the model still sees the partial observations of $a^x$, $b^x$.\n\n3. The experimental setting is synthetic, and the paper does not include any experiments on real datasets.\n\n[1]: Li, Yingcong, et al. \"Dissecting chain-of-thought: A study on compositional in-context learning of mlps.\" arXiv preprint arXiv:2305.18869 (2023).\n\n[2]: Fan, Ying, et al. \"Transformers can learn meta-skills for task generalization in in-context learning.\" NeurIPS 2024 Workshop on Compositional Learning: Perspectives, Methods, and Paths Forward. 2024."}, "questions": {"value": "1. Could the authors compare their work with [1] and [2], and clarify the specific conceptual and technical contributions of this paper relative to those studies?\n\n2. In Fig. 2 and the subsequent evaluations, what exactly is provided as input to each of the models? It would be helpful if the authors could include a few illustrative examples for the baseline, 11-11-2, and, for instance, 6-6-12, under both zero-shot and two-shot settings."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "43GJbpdvhF", "forum": "QmsqyDZKT3", "replyto": "QmsqyDZKT3", "signatures": ["ICLR.cc/2026/Conference/Submission21138/Reviewer_yycS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21138/Reviewer_yycS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21138/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762231268723, "cdate": 1762231268723, "tmdate": 1762941415183, "mdate": 1762941415183, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}