{"id": "or767HxS42", "number": 7368, "cdate": 1758018082880, "mdate": 1759897857133, "content": {"title": "MONICA: Real-Time Monitoring and Calibration of Chain-of-Thought Sycophancy in Large Reasoning Models", "abstract": "Large Reasoning Models (LRMs) suffer from sycophantic behavior, where models tend to agree with users' incorrect beliefs and follow misinformation rather than maintain independent reasoning. This behavior undermines model reliability and poses societal risks. Mitigating LRM sycophancy requires monitoring how this sycophancy emerges during the reasoning trajectory; however, current methods mainly focus on judging based on final answers and correcting them, without understanding how sycophancy develops during reasoning processes. \nTo address this limitation, we propose MONICA, a novel Monitor-guided Calibration framework that monitors and mitigates sycophancy during model inference at the level of reasoning steps, without requiring the model to finish generating its complete answer.\nMONICA integrates a sycophantic monitor that provides real-time monitoring of sycophantic drift scores during response generation with a calibrator that dynamically suppresses sycophantic behavior when scores exceed predefined thresholds.\nExtensive experiments across 12 datasets and 3 LRMs demonstrate that our method effectively reduces sycophantic behavior in both intermediate reasoning steps and final answers, yielding robust performance improvements.", "tldr": "", "keywords": ["Chain-of-Thought", "Sycophancy", "Large Reasoning Model", "Monitorability"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/88c221354c2d614cfb62304015fbef47989c3c5c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Large Reasoning Models (LRMs) have advanced in complex reasoning tasks but exhibit sycophantic behavior by agreeing with users' incorrect beliefs, which undermines reliability and poses societal risks like amplifying misinformation. The motivation is to monitor and mitigate sycophancy during the chain-of-thought (CoT) reasoning process rather than just correcting final answers. Challenges include the subtlety of sycophancy in intermediate steps, computational expense of fine-tuning, and limitations of tuning-free methods in handling reasoning trajectories. The proposed MONICA is a monitor-guided calibration framework that constructs a synthetic dataset via induction-then-merge, trains layer-specific monitors and calibrators on activations, and uses a sycophancy drift score for real-time detection and adaptive suppression during inference, improving performance across datasets and models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Constructs a synthetic dataset tailored for reasoning tasks by extracting stage-specific patterns. Identifies sycophantic tendencies at early, intermediate, and conclusion stages using an external LLM. Enables effective training of monitors and calibrators for subtle behaviors.\n\n2. Trains reliable monitors using supervised probes on activation spaces. Achieves high accuracy in distinguishing sycophantic samples in middle and later layers. \n\n3. Demonstrates superior performance across 12 datasets and three models. Achieves top-two results in 33 out of 48 metrics. Shows positive gains in resistance rate unlike baselines that sometimes degrade performance.\n\n4. Offers computational efficiency without requiring multiple generations or full retraining. Uses activation engineering for tuning-free mitigation. Balances monitoring granularity with efficiency through segmentation and windowing.\n\n5. Provides insights into sycophancy emergence in LRMs. This work contributes to more reliable AI in high-stakes domains like healthcare."}, "weaknesses": {"value": "1. Relies on an external LLM for pattern extraction which may introduce biases. Requires manual deduplication for quality control increasing preparation effort.\n\n2. Training monitors and calibrators needs synthetic data generation for each model. Layer selection for monitoring and calibration demands validation sets.\n\n3. Evaluated on multiple-choice QA tasks limiting generalizability to open-ended reasoning. \n\n4. Uses specific cues types that may not cover all sycophancy manifestations.\n\n5. Framework increases inference latency due to real-time monitoring. Contextual window extraction adds overhead during generation. \n\n6. Some related works of the judging bias are similar to the topic of this work [1,2], which can be considered into discussion.\n\n\n[1] Assessing Judging Bias in Large Reasoning Models: An Empirical Study. In COLM 2025.\n[2] The Emperor's New Chain-of-Thought: Probing Reasoning Theater Bias in Large Reasoning Models. Arxiv 2025."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7CIk2IKIAu", "forum": "or767HxS42", "replyto": "or767HxS42", "signatures": ["ICLR.cc/2026/Conference/Submission7368/Reviewer_rZ8f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7368/Reviewer_rZ8f"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7368/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760797145731, "cdate": 1760797145731, "tmdate": 1762919498563, "mdate": 1762919498563, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MONICA, a framework to combat \"sycophancy\"—agreeing with incorrect user suggestions in Large Reasoning Models (LRMs). Unlike previous work that mitigates sycophancy by evaluating the entire final response, MONICA operates in real-time at the reasoning step level. It monitors the model's chain-of-thought process as it generates, using a trained \"monitor\" to detect sycophantic drift and a \"calibrator\" to dynamically correct the model's internal path. This approach improves the honesty of both the intermediate reasoning and the final answer."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. MONICA operates during inference by manipulating model activations, making it computationally efficient as it does not require expensive model fine-tuning.\n2. The framework is highly precise because it is trained on a specialized dataset of subtle, sentence-level sycophantic patterns, allowing it to accurately identify and correct flawed reasoning that other methods miss.\n3. Experiments show that MONICA consistently outperforms other mitigation strategies, effectively reducing sycophancy while improving task performance across various datasets and models."}, "weaknesses": {"value": "1. To see how MONICA performs under normal setting (i.e., no cue is given),  the authors should report the normal performance (e.g., accuracy) on the reasoning datasets when no cues are given with the monitoring and calibration on. \n2. When constructing the sycophancy dataset, the authors classify responses as sycophantic when the predicted answers match with the incorrect cues. However, the model could also happen to predict this answer even it is not favouring the user's cue. This rule-based classification might produce noisy datasets. In addition, since gpt-4o would be used to extract sycophantic patterns in finer granularity, what is meaning of this classification?\n3. The authors should conduct an ablation study on the impact of $\\xi$ and $\\kappa$."}, "questions": {"value": "1. How is the stage-specific extraction performed in details? There is only the prompt used to segment the repones into stages, why is the prompt used to extract sycophantic patterns missing? \n2. What is the SDS threshold for a sycophantic case? \n3. Since the monitoring process is activated when every $kappa$ segmentation token and the authors average the last $xi$ tokens for detection, what is the meaning of the Contextual Window?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UWJuh6nbrB", "forum": "or767HxS42", "replyto": "or767HxS42", "signatures": ["ICLR.cc/2026/Conference/Submission7368/Reviewer_bHi9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7368/Reviewer_bHi9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7368/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761571965803, "cdate": 1761571965803, "tmdate": 1762919498211, "mdate": 1762919498211, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MONICA, which uses monitor-guided calibration framework to mitigates sycophancy during model inference. The framework introduces sycophantic monitor to real-time monitor model behavior and trigger suppression when sycophancy is detected. Experiments show the framework effectively reduce sycophantic behavior."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed methods show improvement in reducing model's sycophantic behavior. \n2. The idea of using a monitor to control calibration is novel and makes some sense."}, "weaknesses": {"value": "The weakness of this paper mainly lies in novelty and applications:\n1. From my perspecitive, the monitor and calibrator ideas are not novel and widely used in activation engineering literature. The paper's contribution is mainly applying existing methods to large  reasoning models to reduce sycophancy. The technical difficulty of this is not well justified by the paper, limiting its novelty. \n2. Despite its ability to reduce sycophancy, I still have concern on the applicability of proposed method: is the utility (measured without cues) comparable with original model? Additional experiments on this will be helpful."}, "questions": {"value": "1. In Ln. 161-174, are these categories (supervised and unsupervised) introduced in this paper? It seems a bit strange for me as the listed \"unsupervised\" method like mean-difference still requires sample labels / contrastive pairs which is different from common understanding of unsupervised learning. \n2. In Ln 198 - 202, the sycophantic set is defined as model's prediction matches the incorrect cue answer. However, the model may give the same incorrect answer even without the incorrect cue. Is it better to check the model's answer without cue first, and define sycophantic as model changes its answer to the cue?\n3. In Ln 219-220, how is $h^l_s$ computed? Is this the mean over each token position of the trajectory $s$?\n4. In Ln 204-210, how does the segmentation $\\theta$ work in the framework? An ablation study on this part will be helpful. \n5. In Table 1, the std is calculated over how many samples? Most difference seems be not very siginificant considering the std value."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Z75aATqDpw", "forum": "or767HxS42", "replyto": "or767HxS42", "signatures": ["ICLR.cc/2026/Conference/Submission7368/Reviewer_zYZo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7368/Reviewer_zYZo"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7368/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761604149698, "cdate": 1761604149698, "tmdate": 1762919497724, "mdate": 1762919497724, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MONICA to address the issue of sycophantic behavior in Large Reasoning Models (LRMs). The authors identify that existing methods primarily focus on final answers, overlooking the emergence of sycophancy within intermediate reasoning steps. MONICA proposes an induction-then-merge scheme to construct a sycophancy dataset, followed by a monitor-calibrator pipeline that dynamically detects and mitigates sycophantic drift in real-time. Through experiments on 12 datasets and 3 LRMs, MONICA demonstrates reductions in sycophantic behavior and robust performance improvements."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The authors have identified a rather critical and often overlooked issue concerning sycophantic behavior within the intermediate chain-of-thought reasoning processes of Large Reasoning Models. \n- The motivation behind tackling this specific aspect of sycophancy is quite clear, and the proposed MONICA framework is described with good clarity. \n- The experimental evaluation is fairly extensive, covering 12 datasets and 3 different LRMs, which helps demonstrate a degree of generalizability for the method. The insights regarding reasoning-stage sycophancy supervision and mitigation also appear valuable."}, "weaknesses": {"value": "- While the authors mention using GPT-4o to identify and label sycophantic patterns in Section 2.2 with \"manual annotation for deduplication and quality control\", I would appreciate a quantitative validation of the annotation quality, such as inter-annotator agreement or comparison with human expert labels. This is important since if GPT-4o exhibits biases in identifying sycophancy, these biases would propagate throughout the entire training pipeline and the final system.\n- This paper claims \"Real-Time Monitoring\" in the title, but the implementation monitors only every κ=3 sentence delimiters. It requires contextual window accumulation, which feels more like periodic monitoring than genuine token-level real-time supervision.\n- Lack of principled layer selection. The authors manually select monitoring and calibration layers for different models (e.g., layers 21-23 for monitoring in DeepSeek as stated in Appendix A.1) without providing theoretical justification or a systematic search method, which undermines the reproducibility and generalizability of the approach.\n- This work constructs the dataset from only 500 CommonsenseQA samples, expanding to 2,000 samples across four cue types, which may be insufficient for training a robust monitor."}, "questions": {"value": "Based on the weaknesses I've outlined, here are my main questions for the authors:\n\n- Can the authors provide quantitative validation of GPT-4o's labeling reliability?\n\n- Can the authors clarify or reconsider the \"Real-Time Monitoring\" claim? \n\n- Can the authors further explain why a monitor trained on 500 CommonsenseQA samples generalizes robustly across diverse datasets? Can you give me more evidence on that?\n\n- How sensitive is the method to the manual layer selection, and is there a more principled approach?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3o1p1Cj9SA", "forum": "or767HxS42", "replyto": "or767HxS42", "signatures": ["ICLR.cc/2026/Conference/Submission7368/Reviewer_1pkF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7368/Reviewer_1pkF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7368/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761892197930, "cdate": 1761892197930, "tmdate": 1762919497360, "mdate": 1762919497360, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}