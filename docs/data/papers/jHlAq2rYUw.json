{"id": "jHlAq2rYUw", "number": 2932, "cdate": 1757302721545, "mdate": 1759898118549, "content": {"title": "FSOD-VFM: Few-Shot Object Detection with Vision Foundation Models and Graph Diffusion", "abstract": "In this paper, we present FSOD-VFM: Few-Shot Object Detectors with Vision Foundation Models, a framework that leverages vision foundation models to tackle the challenge of few-shot object detection. FSOD-VFM integrates three key components: a universal proposal network (UPN) for category-agnostic bounding box generation, SAM2 for accurate mask extraction, and DINOv2 features for efficient adaptation to new object categories. Despite the strong generalization capabilities of foundation models, the bounding boxes generated by UPN often suffer from overfragmentation, covering only partial object regions and leading to numerous small, false-positive proposals rather than accurate, complete object detections. To address this issue, we introduce a novel graph-based confidence reweighting method. In our approach, predicted bounding boxes are modeled as nodes in a directed graph, with graph diffusion operations applied to propagate confidence scores across the network. This reweighting process refines the scores of proposals, assigning higher confidence to whole objects and lower confidence to local, fragmented parts. This strategy improves detection granularity and effectively reduces the occurrence of false-positive bounding box proposals. Through extensive experiments on Pascal-5$^i$, COCO-20$^i$, and CD-FSOD datasets, we demonstrate that our method substantially outperforms existing approaches, achieving superior performance without requiring additional training. Notably, on the challenging CD-FSOD dataset, which spans multiple datasets and domains, our FSOD-VFM achieves 31.6 AP in the 10-shot setting, substantially outperforming previous training-free methods that reach only 21.4 AP. The source code will be released publicly upon publication.", "tldr": "This work presents a state-of-the-art few-shot object detection method without training. The proposed graph diffusion based score reweighting provide a novel view of few-shot object detection.", "keywords": ["Few-Shot Learning", "Foundation Models", "Object Detection"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9b9d12e36e4ccf4810c1fea7a0ed97c77a0aa555.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper addresses few-shot object detection (FSOD). It particularly focuses on training-free detectors by integrating multiple vision foundation models. It uses a universal proposal network (UPN) to detect object proposals and then SAM2 to output object masks. It uses DINOv2 to represent masked objects for matching test-time proposal and few-shot annotated images, achieving FSOD results. It evaluates on traditional benchmarks built on COCO, PASCAL and a few others. It compares against previous FSOD methods which train a base model (on significantly smaller set than foundation models' pretraining set) and finetune on few-shot novel classes. It reports superior performance than the previous FSOD methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Below are notable strengths of this paper.\n- The use of graph difussion to post-process predictions based on confidence scores is interesting.\n- Evaluation metrics are standard."}, "weaknesses": {"value": "Below are major weaknesses of this paper.\n- While the paper advocates training-free methods for FSOD, it is unclear how such training-free methods can detect objects specified by downstream tasks that require to detect non-trivial objects. For examples, if a downstream task requires amodal detection but SAM cannot output amodal segments, how training-free methods handle this discrepancy? Moreover, if a downstream task requires to detect rare objects, can the training-free detector handle this requirement?. The datasets used in experiments contain common objects (from COCO and PASCAL), which are likely learned by vision foundation models and hence disguise limitations of training-free FSOD detectors.\n\n- Images in Figure 1 are low-quality. It seems that (b) and (c) contain \"motorcycle\" predictions and some more on the cows. There are also dim bounding boxes, likely post-processed in some way. Can authors clarify?\n\n- From Figure 1, it is unclear how graph diffusion helps. From (d), (e) and (f), we can see that, even after graph diffusion which diffuses low confidence scores on x-axis, one can still set the confidence threshold as 0.5. So, it is not easy to follow what messages this figure mean to deliver.\n\n- The paper partially follows a traditional FSOD protocol which evaluates on \"novel classes\" (Line363), but it does not exploit any \"base classes\" (Line368). This is a good practice given that it leverages foundation models which can be thought of having been trained on massive \"base data\". However, it is unfair to compare the proposed method with previous ones which use a much smaller \"base data\" set to pretrain models. For fair comparison, it should run existing FSOD algorithms on foundational detectors (e.g., DINO and GroundingDINO), which are assumed to be pretrained on the same \"base data\".\n\n- The datasets used in this work are outdated and small-scale. First, Pascal and COCO were published in 2010 and 2014; but do vision foundation models see similar data to them in the pretraining dataset? Second, Pascal-5 and COCO-20 seems to mean the evaluation is on 5 and 20 classes, respectively. This is rather a small-scale and artificial setting.\n\n- Hyperparameter setting is a big concern in FSOD. The core challenge in FSOD is the lack of data: limited training data for the few-shot (novel) classes and realistically no validation set. Therefore, when reporting the numeric metrics, do the authors tune hyperparameters on the test sets? In Section 4.2, Table 4 shows that the hyperparameter lambda has a significant effect on the final performance.\n\n- In terms of the use of graph diffusion, the paper lacks intuition or rationale how to build a graph. The paper treats each detection as a node, but how to assign weights to edges? Do edges mean similarities between two detections? More important details and discussions are missing."}, "questions": {"value": "The reviewer asks the authors to address each point in weaknesses listed above and does not repeat them in this Questions box."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "qrPK0Njlft", "forum": "jHlAq2rYUw", "replyto": "jHlAq2rYUw", "signatures": ["ICLR.cc/2026/Conference/Submission2932/Reviewer_MxA8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2932/Reviewer_MxA8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2932/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761386578886, "cdate": 1761386578886, "tmdate": 1762916448657, "mdate": 1762916448657, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes FSOD-VFM, a training-free few-shot object detection method that integrates three vision foundation models (UPN for proposal generation, SAM2 for mask extraction, and DINOv2 for feature extraction) to detect novel categories using only a few annotated samples. Its core contribution is a graph diffusion-based confidence reweighting mechanism that effectively mitigates proposal over-fragmentation and enhances detection granularity. Extensive experiments on Pascal-5, COCO-20 , and CD-FSOD benchmarks demonstrate that the method significantly outperforms existing training-free approaches and even surpasses many training-based methods, offering a novel perspective for solving visual tasks in a training-free paradigm."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.  The paper introduces a graph diffusion confidence reweighting mechanism to address the prevalent issue of proposal fragmentation in training-free few-shot detection. Constructing a directed graph among proposals and simulating energy propagation to effectively distinguish between complete object proposals and partial fragment proposals, thereby significantly enhancing detection granularity.\n\n2.  It is commendable that the authors have validated the method's effectiveness across multiple benchmarks (Pascal-5, COCO-20). The notable performance improvement on the cross-domain few-shot detection benchmark (CD-FSOD) particularly underscores the method's strong generalizability and universality, demonstrating its potential to tackle real-world, complex scenarios."}, "weaknesses": {"value": "1.  The model is overly complex, employing three powerful foundation models to address a relatively specific issue (fragmented bounding boxes generated by UPN). The model complexity and computational cost are exceptionally high. SAM2 is a powerful segmentation model whose generated precise masks already contain rich structural information of objects. Why can't detection boxes be generated directly from SAM2's masks, or why can't a more streamlined pipeline be built around SAM2 as the core, rather than relegating it to an auxiliary role that merely generates masks for UPN proposals?\n\n2.  The methodological description in the paper, particularly concerning the core Figure 3, is insufficient for readers to understand the entire technical pipeline. The limited informational content of the figure creates excessive jumps between key steps like \"Feature Extraction & Matching\" and \"Graph Diffusion,\" making comprehension very difficult. To enhance the work's comprehensibility and reproducibility, it is strongly recommended to supplement the paper with more detailed flowcharts or schematic diagrams.\n\n3.  The definition and explanation of the core concept of \"Heat\" in the graph diffusion process within the paper are highly ambiguous,easily causing significant confusion for readers. As described in Section 3.2, \"Heat\" flows from low-scoring nodes to high-scoring nodes, yet the final stable energy distribution (π̂) is used to penalize nodes, which seems counterintuitive. The authors must add a clear explanation explicitly distinguishing between the \"process of energy flow\" and the \"meaning represented by the steady-state energy distribution.\"\n\n4.  The paper fails to clearly differentiate the proposed \"Graph Diffusion\" method from the classical NMS mechanism, which severely undermines the perceived innovation of the method. Superficially, both aim to eliminate redundant boxes, but the authors do not delve into explaining their fundamental differences. The authors must include a comparative discussion in the text contrasting the underlying principles of their method with those of NMS.\n\n5.  Regarding Table 3 and the CD-FSOD experimental results: the original benchmark's reported results are based on mAP (mean Average Precision), but the comparative results presented in this paper for CD-FSOD use nAP-50. This constitutes a serious methodological error in evaluation."}, "questions": {"value": "Could the functionality of graph diffusion be achieved through other forms of NMS, based on a comparison of their underlying principles?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Y4fJ6wpL1k", "forum": "jHlAq2rYUw", "replyto": "jHlAq2rYUw", "signatures": ["ICLR.cc/2026/Conference/Submission2932/Reviewer_N1W4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2932/Reviewer_N1W4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2932/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761911530634, "cdate": 1761911530634, "tmdate": 1762916448504, "mdate": 1762916448504, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes the FSOD-VFM framework for few-shot object detection by combining several powerful vision foundation models (such as DINOv2, SAM2). It proposes a graph diffusion module that treats bounding box proposals as nodes in a graph and uses graph diffusion operations to adjust the confidence of each bounding box proposals, effectively suppressing local, fragmented boxes. The method performance across multiple benchmark datasets. Experimental study on cross domain datasets show improved performance over the counterpart methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed graph diffusion method effectively suppresses the overfragmentation without training.\n\n2. The proposed method is simple and easy to follow.\n\n3. The writing of the paper is clear and fluent."}, "weaknesses": {"value": "There are issues with method:\n\na) The graph diffusion module uses Equation 3 to calculate the diffusion energy between two proposed bounding boxes. However, Equation 3 relies heavily on the confidence scores provided by UPN. If fragmented bounding box have higher confidence scores, the graph diffusion process can not improve the confidence of high-quality candidate boxes.\n\nb) The method in the paper uses SAM to segment the bounding box proposals given by UPN, in order to obtain cleaner foreground regions. However, the paper does not explain whether the method's performance would be significantly degrade if SAM fails to generate accurate masks. It would be helpful if the authors could visualize the masks provided by SAM in the cross domain tasks and conduct a comparison experiment without using SAM , to validate the necessity of incorporating SAM into the method."}, "questions": {"value": "In addition to the questions raised in the Weaknesses section it would be great to hear authors' thoughst on why the performance in the 10-shot setting is lower than in the 5-shot setting or 1-shot setting in the table 3."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "C9rvURNtjE", "forum": "jHlAq2rYUw", "replyto": "jHlAq2rYUw", "signatures": ["ICLR.cc/2026/Conference/Submission2932/Reviewer_JBSW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2932/Reviewer_JBSW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2932/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761916078334, "cdate": 1761916078334, "tmdate": 1762916448352, "mdate": 1762916448352, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposed a graph-diffusion based method for FSOD problem by integrating foundation models. The core novelty is to build a foundation model-based bounding box proposals module and a graph diffusion module.  The proposed network can achieve SOTA performance on classic FSOD dataset with significant improvement."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1. The idea of utilizing vision foundation models is novel.\n2. Formulas are very helpful to understand the core idea of graph diffusion and the motivation of the research.\n3. The proposed method also shows good generalization to cross-domain scenario, which is remarkable.\n4. The proposed method achieved SOTA performance.\n5. The limitation section provides good analysis of the proposed method, especially the part about the marginal improvement when the  annotated samples increases."}, "weaknesses": {"value": "1. In the settings of FSOD and CD-FSOD, the basic assumption is that the novel category objects are either never seen in the training set or not labeled. However, with the vision foundation model, how do the authors make sure that the novel objects is absolutely unseen? This part of statement should be more clear.\n2. The proposed network explores a very different way comparing to classic FSOD paradigms, what would be the computational overhead in  the proposed networks setting?"}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "BWa2a1ZdxX", "forum": "jHlAq2rYUw", "replyto": "jHlAq2rYUw", "signatures": ["ICLR.cc/2026/Conference/Submission2932/Reviewer_6RnX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2932/Reviewer_6RnX"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2932/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762115145157, "cdate": 1762115145157, "tmdate": 1762916448180, "mdate": 1762916448180, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}