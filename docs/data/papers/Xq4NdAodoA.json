{"id": "Xq4NdAodoA", "number": 13057, "cdate": 1758213184982, "mdate": 1759897468406, "content": {"title": "Generative Modeling with Bayesian Sample Inference", "abstract": "We derive a novel generative model from iterative Gaussian posterior inference. By treating the generated sample as an unknown variable, we can formulate the sampling process in the language of Bayesian probability. Our model uses a sequence of prediction and posterior update steps to iteratively narrow down the unknown sample starting from a broad initial belief. In addition to a rigorous theoretical analysis, we establish a connection between our model and diffusion models and show that it includes Bayesian Flow Networks (BFNs) as a special case. In our experiments, we demonstrate that our model improves sample quality on ImageNet32 over both BFNs and the closely related Variational Diffusion Models, while achieving equivalent log-likelihoods on ImageNet32 and CIFAR10.", "tldr": "Novel diffusion-like generative model based on iterative posterior inference", "keywords": ["generative", "likelihood", "probabilistic", "bayesian"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4ee07b6da7b2b77e5090eb190b11ab725d44c69c.pdf", "supplementary_material": "/attachment/061463182d93dfbd46e4adfc5e31a3cbcb7ab25e.zip"}, "replies": [{"content": {"summary": {"value": "The authors present a generative algorithm that can be framed as iterative Bayesian inference. They derive an ELBO objective for the model, and show in a series of numerical experiments that they perform competitively with related models such as Bayesian Flow Networks, or Variational Diffusion models, on ImageNet and CIFAR datasets. The appendix carefully discusses the differences with other frameworks, notably diffusion models."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well written, and technical statements are satisfyingly accompanied with explanatory discussion. The interpretation of the generative model in terms of iterative Bayesian inference is interesting, and the numerical experiments seem convincing, although I have limited expertise in evaluating the latter."}, "weaknesses": {"value": "My main concern revolves around the novelty of the theoretical generative framework, and how it relates to existing works. The authors already provide a detailed discussion in Appendix A.2 on the differences with standard diffusion models, highlighting how the noising process in their framework is non-Markovian. However, the closely related stochastic interpolant models (see e.g. Albergo et al, Stochastic Interpolants: A Unifying Framework for Flows and Diffusions, 2023) is to the best of my reading not discussed at all. The noising process in the latter seem to the best of my understanding very closely related to that considered by the authors. Notably, the denoising process (1) that involves the posterior denoiser of $x$ given the noisy observation $y$ resembles e.g. (4.3) in the provided reference, notably in the continuous limit of l.170. It is not impossible I have misunderstood some key contributions of the submission, and I am happy to raise my score after clarifications of the authors. However, I cannot be in favor of acceptance unless a detailed discussion is included to clarify differences to this line of works."}, "questions": {"value": "Please see the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "RhHULvOUsY", "forum": "Xq4NdAodoA", "replyto": "Xq4NdAodoA", "signatures": ["ICLR.cc/2026/Conference/Submission13057/Reviewer_WnXZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13057/Reviewer_WnXZ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13057/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760952488924, "cdate": 1760952488924, "tmdate": 1762923788117, "mdate": 1762923788117, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Bayesian Sample Inference (BSI), a novel generative model that frames the generation process as iterative Bayesian inference. The core idea is to treat a data sample as an unknown variable and to iteratively refine a belief about it, starting from a broad prior and updating it based on noisy measurements of model predictions. The authors derive an Evidence Lower Bound (ELBO) for both finite and infinite-step versions of this process, enabling likelihood-based training. Through this framework, they show that Bayesian Flow Networks (BFNs) are a special case of BSI, providing a new perspective on them. Experiments on ImageNet32 and CIFAR10 demonstrate that BSI achieves sample quality (FID) superior to both Variational Diffusion Models (VDM) and BFNs, while maintaining equivalent log-likelihoods (BPD). The significance of this work lies in its introduction of a conceptually simple and elegant Bayesian perspective on generative modeling that unifies existing models and proves to be empirically effective."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "*   **Novelty:** The primary strength of the paper is its novel framing of generative modeling. Viewing sample generation as the process of inferring a fixed but unknown variable via iterative posterior updates is a conceptually clean and powerful idea. This Bayesian perspective is a welcome contribution, offering a different way to think about the gradual refinement process that characterizes modern generative models.\n\n*   **Theoretical Soundness:** The paper provides a rigorous theoretical foundation for BSI. The derivation of the ELBO (Theorems 3.1 and 3.2) is solid and connects the model to the established practice of variational inference. A key contribution is showing that BFNs emerge as a special case of BSI when the initial prior is deterministic (infinite precision). This not only unifies BFNs within a more general framework but also simplifies and clarifies their connection to diffusion models. The analysis of the \"noising\" process (Section A.2) and how BSI's non-Markovian forward process differs from BFN's Markovian one is insightful.\n\n*   **Strong Empirical Results:** The experimental validation, though limited in scope, is compelling within its domain. The authors compare BSI against two highly relevant and strong baselines: VDM and BFN. On the ImageNet32 benchmark, BSI achieves a statistically significant improvement in sample quality (FID of 8.9 vs. 9.9 for VDM and 11.0 for BFN) while matching their performance on log-likelihood. This is a strong result that demonstrates a clear advantage of the proposed formulation."}, "weaknesses": {"value": "Despite its elegant formulation and promising results I still have doubts on the methodology and experimental validation, which raise several critical questions that weaken its overall contribution. The claims of novelty and superiority feel overstated upon closer inspection of the underlying algorithm and the lack of crucial ablation studies.\n\n1.  **Conflation of Re-framing with Algorithmic Novelty:** The core training algorithm (Algorithm 2) is structurally almost identical to standard denoising diffusion models. It samples a noise level (`λ`), creates a noisy input (`μ_λ`), and trains a network `f_θ` to predict the original sample `x` from `μ_λ`. While the Bayesian derivation is new, the final algorithm is not. This raises the question of whether BSI is a fundamentally new *class* of models or a well-motivated re-derivation of a specific noise schedule and prior for existing models.\n\n2.  **Lack of Ablation Studies:** The paper's central claim is that BSI's performance advantage over BFN comes from its non-deterministic prior (`p(μ₀)` with `λ₀⁻¹ > 0`). This is a critical claim that is not substantiated with sufficient evidence. The paper only compares the two extremes: BSI (`λ₀⁻¹ = 100`) and BFN (`λ₀⁻¹ = 0`). A proper scientific validation would require an ablation study showing how FID and BPD vary across a range of `λ₀⁻¹` values to demonstrate a clear trend and justify the chosen hyperparameter. The same applies to other key design choices, such as the `p(λ)` proposal distribution.\n\n3.  **Questionable Experimental Comparison:** The main empirical comparison is between BSI, BFN, and VDM using a DiT-L-2 backbone. Figure 2 clearly shows that the input distributions for these models at the highest noise levels are qualitatively different. BSI and BFN start from (near) pure noise, whereas VDM's noisiest input mean (`Np(0.08x, 1)`) still contains significant structural information about the image. The DiT architecture, with its global self-attention mechanism, is particularly well-suited to reconstructing images from unstructured noise. This setup may be unfairly biased towards BSI/BFN and confounding the architectural strengths with the merits of the generative formulation.\n\n4.  **Disconnect Between Training Objective and Sampling:** The model is trained to optimize an \"infinite-step\" ELBO, which is a continuous integral over all precision levels `λ`. However, sampling is always performed in a finite, discrete number of steps. The paper does not provide a theoretical justification for why optimizing the continuous objective is ideal for the discrete sampling task. This is particularly relevant for the low-step sampling regime, which is crucial for practical efficiency but not explored in the paper."}, "questions": {"value": "*   **Question 1:** The final training objective (optimizing `L_M`) amounts to a noise-conditioned denoising task, structurally similar to other diffusion models. Beyond the novel derivation, what is the fundamental algorithmic difference between BSI and a VDM/BFN where the noise schedule is designed to match BSI's effective `λ` distribution and a non-zero initial noise level is used?\n\n*   **Question 2:** The choice of a log-uniform proposal distribution for importance sampling is motivated by an approximation where `f_θ(μ, λ) ≈ μ`. How does the validity of this approximation vary across precision levels `λ`, and have you investigated the sensitivity of training stability and final performance to this specific choice of `p(λ)`? Could a poorly chosen `p(λ)` mask or artificially inflate the model's true performance?\n\n*   **Question 3:** The comparison with VDM is positioned as a key result. However, Figure 2 shows that the nature of the noisiest inputs for VDM and BSI are qualitatively different. Could the superior FID of BSI be an artifact of the DiT architecture being better suited to BSI's noise distribution and prior, rather than an inherent advantage of the BSI framework itself? How would the models compare with an architecture less biased towards global attention, like a pure U-Net on the same task?\n\n*   **Question 4:** The central claim for BSI's improved FID over BFN is the use of a non-deterministic initial belief (`λ₀ < ∞`). However, this is only validated by comparing the two extremes. The paper lacks a proper ablation study on the effect of the initial noise variance `λ₀⁻¹`. How does the FID score change as `λ₀⁻¹` is varied between 0 (BFN) and 100 (BSI)?\n\n*   **Question 5:** Training is performed by optimizing the infinite-step ELBO (`L_M`), which involves a continuous integral over precision `λ`. Sampling, however, is a discrete, finite-step process. What is the theoretical justification for this being the optimal training strategy for finite-step sampling, and how does this approach affect performance in the very low-step sampling regime (e.g., < 20 steps)?\n\n*   **Question 6:** The training objective, which minimizes the squared error between the true sample `x` and the model's prediction `f_θ(μ_λ, λ)`, bears a strong resemblance to the denoising score-matching objective. Can the BSI objective be formally interpreted as a form of score matching? Specifically, how does the BSI update rule relate to the updates in score-based generative modeling, and could this connection provide further insights into the model?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SxguA7usn2", "forum": "Xq4NdAodoA", "replyto": "Xq4NdAodoA", "signatures": ["ICLR.cc/2026/Conference/Submission13057/Reviewer_9kRj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13057/Reviewer_9kRj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13057/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761386316682, "cdate": 1761386316682, "tmdate": 1762923787708, "mdate": 1762923787708, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Bayesian Sample Inference (BSI), a generative modeling framework that treats generation as iterative posterior inference on an unknown sample using a sequence of prediction and Bayesian updates . The authors derive an ELBO in both finite-step and continuous limits, enabling likelihood-based training with a variance-reduced estimator via log-uniform importance sampling. They analyze relationships to Variational Diffusion Models (VDM) and Bayesian Flow Networks (BFN), showing BFN as a special case and connecting BSI to diffusion via a (generally) non-Markov forward process . Empirically, BSI matches likelihoods and improves FID on ImageNet32 vs. VDM/BFN using the same DiT backbone, with additional CIFAR-10 likelihood comparisons using a shared U-Net ."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Clear probabilistic formulation with closed-form update and a principled ELBO; continuous-limit bound is neat and intuitive.\n\n- Concrete connection to VDM/BFN; proof that BFN is a limit case and discussion of Markov vs. non-Markov forward processes add theoretical clarity.\n\n- Variance reduction via log-uniform sampling is motivated analytically and validated empirically.\n\n- Competitive or better results on ImageNet32 (lower FID at matched likelihoods) and matched BPD on CIFAR-10 with controlled architectures/seeds."}, "weaknesses": {"value": "- Empirical scope is narrow: small-resolution datasets (ImageNet32, CIFAR-10); no high-res, text-conditioned, or scaling-law study to substantiate broader quality claims.\n\n- The theoretical comparison to VDM emphasizes simplicity of the BSI/BFN update, but practical stability/accuracy trade-offs vs. VDM’s log-space parameterization are not quantified."}, "questions": {"value": "- The proposed Bayesian perspective vs. VDM/BFN: what concrete theoretical advantages does BSI deliver (e.g., tighter/cleaner ELBO, better conditioning, robustness) beyond interpretability? Please make the comparison formal.\n\n- It would be important to support the argument that BSI has higher generation quality than VDM and BFN if there are larger scales such as higher resolutions(e.g., ImageNet-256 and ImageNet-512) or experiments on scaling laws. Please provide results generated with larger resolution or text conditions, and performance trends as the model/data/number of steps increases."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ol38HkXF3R", "forum": "Xq4NdAodoA", "replyto": "Xq4NdAodoA", "signatures": ["ICLR.cc/2026/Conference/Submission13057/Reviewer_sXog"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13057/Reviewer_sXog"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13057/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992133081, "cdate": 1761992133081, "tmdate": 1762923787400, "mdate": 1762923787400, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Bayesian Sample Inference (BSI), a generative framework that reformulates sample generation as iterative Gaussian posterior updates. The proposed model uses a sequence of prediction and posterior update steps to iteratively narrow down the unknown sample starting from a broad initial belief. The paper include an extensive theoretical analysis along with empirical evaluation on the ImageNet 32x32 and CIFAR-10 datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper provides a novel perspective on generative modeling that frames sample generation as iterative Bayesian inference.\n• The proposed BSI framework is quite general, and the paper shows that BSI includes BFN (“Bayesian Flow Networks”) as a special case.\n• The includes a succinct and easy to understand comparison between the BSI and BFN / VDM frameworks."}, "weaknesses": {"value": "• The proposed BSI only leads to minor improvements over the BFN and VDM models. In fact, the loglikelihood BPD metric is nearly identical compared to the BFN and VDM models on both the ImageNet 32x32 and CIFAR-10 datasets.\n• The paper only considers a small set of baselines – BFN and VDM – on ImageNet 32x32 and CIFAR-10. The paper should also compare to state of the art models such as “Improved Denoising Diffusion Probabilistic Models, arXiv 2025”, “Neural Diffusion Models, arXiv 2024”.\n• The paper only considers the low-resolution ImageNet 32x32 and CIFAR-10 datasets. The paper should provide results on the higher resolution ImageNet 64x64 dataset, as provided in the VDM (“Variational Diffusion Models”) paper.\n• The paper does not provide any analysis of the number of steps required for convergence by the proposed BSI model compared to the BFN and VDM models. In Figure 2, the proposed BSI model requires more steps compared to the BFN and VDM models to converge.\n• The difference between the proposed BSI model compared to the BFN model is minor. The effective difference is only in the choice of the non-deterministic hyper-prior $p(\\mu_0)$ in BSI."}, "questions": {"value": "• The advantage of the proposed BSI framework over the BFN/ VDM frameworks should be described in more detail.\n• The choice of baselines should be motivated in more detail.\n• The paper should include more results on higher resolution image datasets, e.g., ImageNet 64 x 64."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5UR5Mzi81Z", "forum": "Xq4NdAodoA", "replyto": "Xq4NdAodoA", "signatures": ["ICLR.cc/2026/Conference/Submission13057/Reviewer_yESK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13057/Reviewer_yESK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13057/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762122258251, "cdate": 1762122258251, "tmdate": 1762923787141, "mdate": 1762923787141, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}