{"id": "caT0inogUr", "number": 3763, "cdate": 1757515649854, "mdate": 1759898071151, "content": {"title": "Shave Peaks, Don't Fill Valleys: Upper-Tail Risk Balancing Improves Robustness without Accuracy Loss", "abstract": "Many sequence models achieve strong average performance yet exhibit **concentrated internal dependencies**: removing just a few \"critical units/time positions\" causes disproportionate degradation. We propose **RBRL (Risk-Balanced Representation Learning)**, which applies financial risk allocation principles to neural network training by constraining **attribution concentration** through adaptive risk budgets. RBRL uses a stable attribution signal (AEC: activation × gradient with EMA normalization) and imposes upper-tail constraints via quantile budgets and soft-Top-K penalties, enabling \"peak-shaving\" without compromising main objectives through dual-only training that preserves backbone gradients.\n\nAcross S\\&P 500 and ETT datasets, RBRL **improves robustness under a tunable computational overhead while maintaining baseline-level accuracy on S\\&P 500**; on ETT, RMSE changes show mixed results across subsets; on S\\&P 500, differences are small but not statistically significant (RMSE *p* = 0.216; MAE *p* = 0.201; directional accuracy unchanged). Our comprehensive evaluation across 68 configurations demonstrates architecture-agnostic applicability to LSTM, iTransformer, and other sequence models. We position this as a **robust reliance training paradigm**: proactively dispersing dependencies during training rather than addressing brittleness post-hoc.", "tldr": "RBRL trims the upper tail of activation×gradient attribution to diffuse peak reliance in sequence models, boosting robustness to targeted occlusions and noise without degrading accuracy or inference cost.", "keywords": ["Attribution Concentration", "Risk-Balanced Representation Learning", "Robustness Training", "Upper-Tail Control", "Gradient-Based Attribution", "Time Series", "Sequence Models"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9007f8d03811ea9a9635074b8e2978e1aa3e10c8.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper aims to solve the brittleness problem in sequence models, which arises from an over-reliance on a few 'critical units' or 'specific time positions'.\n\nTo address this, the authors propose a new training paradigm called RBRL (Risk-Balanced Representation Learning), inspired by the 'risk allocation' principles from financial engineering. The core of RBRL is to use a stable attribution signal called AEC (Activation × Gradient) to suppress dependency concentration on specific units/timesteps (i.e., peak shaving) via Quantile Budgets and Soft-Top-K penalties. Furthermore, the proposed dual-only training mode allows this dependency dispersal task to be performed without interfering with the model's main prediction loss (backbone gradients)."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "(1) The approach of formulating the problem of dependency concentration within a new perspective of \"financial risk diversification\" and measuring it using established metrics like the Gini coefficient is highly original and compelling.\n\n(2) The dual-only learning mode cleverly separates the two objectives of accuracy and robustness, achieving robustness without inference overhead.\n\n(3) The introduction of Adaptive Budgets (Sec 3.2.4) is a key feature that ensures the methodology's general applicability without overfitting to specific datasets or models.\n\nHowever, the paper's core experimental results contain several significant contradictions and points that require clarification."}, "weaknesses": {"value": "(1) The experimental evidence for the paper's core claim, 'improved robustness', is fatally contradictory.\nFigure 3 (Pareto Plot) claims that RBRL's \"Robustness Score\" is slightly superior to PGD's. However, Figure 5 (Bar Plot) shows that while PGD's \"Adversarial Relative Increase\" (error rate) is 9.89%, RBRL's is 225.10%, making it overwhelmingly more vulnerable than PGD. Even considering the unclear definitions of these two metrics, these two figures provide completely contradictory answers to the core question: \"How robust is RBRL compared to PGD?\"\n\n(2) The justification for the core components of the proposed methodology is severely lacking.\nWhile the importance of AEC-Normalization was demonstrated (Sec 5.4), the superiority of the AEC signal itself was not. There is no comparative analysis to show that AEC is the optimal signal, making it difficult to accept the necessity of AEC without comparisons to simpler alternatives (e.g., simple gradients or activations). Furthermore, the claim that Quantile budgets are better than Mean budgets (Sec 5.4) only holds for RMSE (Fig 6); in terms of the paper's core goal, dependency dispersal (Fig 7), the Mean budget was actually superior to the Quantile budget.\n\n(3) Even the core precondition of 'maintaining accuracy' was not consistently demonstrated experimentally.\nAlthough the paper repeatedly claims RBRL 'maintains accuracy', as shown in Table 1, performance on the ETTh2 dataset actually degraded by 0.13% compared to the Baseline, and the improvements on the S&P 500 dataset were not statistically significant.\n\nWhile the achievement of 114x faster training efficiency (Figure 3, Sec 5.2) is a very strong and practical contribution, the completely contradictory experimental results regarding robustness compared to PGD are not a minor error. They are a critical flaw that fundamentally undermines the credibility of the paper's core contribution (improved robustness). Beyond this, there are general doubts about the reliability of several experimental analyses throughout the paper. Even considering all this, the paper's formatting is seriously flawed. The figures are extremely difficult to read, and Tables 1 and 2 are completely out of place in the paper's format."}, "questions": {"value": "- What exactly do the 'Robustness Score' (Fig 3) and the 'Adversarial Relative Increase' (Fig 5) measure, and what are their definitions?\n- Can you explain why these two metrics lead to such diametrically opposed conclusions regarding RBRL's robustness compared to PGD?\n- Can you provide a comparative experiment or theoretical rationale demonstrating that the AEC signal is more stable or superior to these alternatives?\n- This appears to imply a trade-off between RMSE and dependency dispersal. Are the authors aware of this trade-off? And please explain the rationale for prioritizing RMSE improvement over Gini coefficient improvement in concluding that 'Quantile budgets are superior'."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Z4JDOzvdhh", "forum": "caT0inogUr", "replyto": "caT0inogUr", "signatures": ["ICLR.cc/2026/Conference/Submission3763/Reviewer_Pcdp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3763/Reviewer_Pcdp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761890330543, "cdate": 1761890330543, "tmdate": 1762916973862, "mdate": 1762916973862, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors try to tackle some critical time positions in time series data to which model depend on for their performance. This over-reliance to these criitical positions is seen as a risk-concentration problem from the authors. So they propose Risk-Balanced Representation Learning (RBRL), a method to \"shave\" these positions. For that they use a risk measure calculated as Activation × Gradient, with EMA normalization, and some adaptive buckets that get \"shaved\" when they exceed a certain budget."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The paper proposes a new method for time series data to increase performance. It focuses mostly on financial data.\n-The method is kind of novel and it looks like it performsn well."}, "weaknesses": {"value": "- The paper lacks mathematical proofs and guarantees. For example the main methodology section has not provided any algorithms or proofs that the method works and generalizes (or even converges).\n- The paper has poor experiments in very small and archaic models (LSTMs) in only 2 small datasets that are not very well known.\nIn general it lacks both in the math side and the experiments side, which makes the main argument for the new method weak."}, "questions": {"value": "Havd you tried bigger architectures including attention mechanisms and more datasets?\nWhat can you say for the convergence of the method. \nI would also argue that the paper is not fit for this venue and a financial venue would be more suitable in this case."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "c7ItJlOjAk", "forum": "caT0inogUr", "replyto": "caT0inogUr", "signatures": ["ICLR.cc/2026/Conference/Submission3763/Reviewer_edAT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3763/Reviewer_edAT"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761891345640, "cdate": 1761891345640, "tmdate": 1762916973615, "mdate": 1762916973615, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Risk-Balanced Representation Learning (RBRL), a training method that applies financial risk-balancing principles to reduce neural networks’ over-reliance on a few critical units or time steps. Using an activation–gradient (AEC) attribution signal with quantile budgets and soft-Top-K penalties, the authors claim that RBRL “shaves peaks” in attribution without harming accuracy."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The idea of borrowing concepts from financial risk control is quite interesting and novel."}, "weaknesses": {"value": "The overall writing is quite confusing. The structure, title, and content feel rushed and lack clarity. On the first page, there is significant duplication between the abstract and the opening paragraph, and the introduction section does not provide a proper introduction to the problem or motivation. It is also difficult to understand what “AEC: activation × gradient with EMA normalization” means—the explanation is vague and forces the reader to guess. Regarding structure, subsections 3.2.2, 3.2.3, and 3.2.4 each contain only one or two sentences, which leaves the reader without sufficient context or continuity. Overall, the paper appears incomplete and not yet ready for publication."}, "questions": {"value": "1. The font size of the tables and figures is inconsistent—some are quite large, as shown in Fig. 2, while others are very small, as in Fig. 1. Moreover, it is quite hard to understand what “illustrative surface for intuition” means as part of the title of Fig. 1.\n\n2. Tables 1 and 2 appear to be poorly formatted and exceed the normal page layout, making them difficult to read. They should be properly resized or reformatted to fit within the page margins and maintain visual consistency with the rest of the paper. Additionally, there seems to be an error in the title of Fig. 7, which should be carefully checked and corrected. Clear and consistent formatting of tables and figures is essential for readability and professionalism.\n\n3. In the related work section, most of the cited studies are from before 2018, with only one paper from 2023. I am concerned that the literature review is insufficient and does not adequately reflect recent research developments in this area. A more comprehensive and up-to-date review would strengthen the paper’s context and relevance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "puDeUlTk8e", "forum": "caT0inogUr", "replyto": "caT0inogUr", "signatures": ["ICLR.cc/2026/Conference/Submission3763/Reviewer_sP3F"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3763/Reviewer_sP3F"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761957043455, "cdate": 1761957043455, "tmdate": 1762916973362, "mdate": 1762916973362, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes RBRL, a regularization method that reduces strong dependance on a small set of sequence positions by regularizing the upper tail of an attribution score, |gradient x activation| monitored with an EMA. The method allocates an adaptive budget for sequence positions and applies penalties in cases where the budget is exceeded. The method is evaluated on time series data to measure performance, robustness and training efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation and problem statement of the paper is well stated - mitigating high concentration on specific units/time steps.\n2. The method builds upon a simple and easy to evaluate feature AEC."}, "weaknesses": {"value": "The main weakness in my opinion is with presentation, in current form I believe readers will find it difficult to understand both the method and the results.\n\nThe method section is broken down in to several small subsections, most containing only verbal descriptions that are not formal (section 3.2) - combining those into a single section along with an algorithm or figure can be very helpful.\nThe different modes of operation are not clear, to name a few unclear terms: \"AEC is detached\", \"network sees only predicition loss\", \"trainer selects the mode per batch\".\n\nIn the experiment and result sections, what are the of phases and why are they numbered 1,2,6? throughout the result section results are not referenced to the listed tables or plots making it hard to follow."}, "questions": {"value": "1. Can you clarify the algorithm(/s) used in training for the different modes? \n2. How are you measuring robustness? I understand you report RMSE and MAE over the different metrics but as this seems to be the core contribution of the method better clarification of the evaluation protocol can be helpful"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "uPlkdVOX1s", "forum": "caT0inogUr", "replyto": "caT0inogUr", "signatures": ["ICLR.cc/2026/Conference/Submission3763/Reviewer_51Jn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3763/Reviewer_51Jn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991260040, "cdate": 1761991260040, "tmdate": 1762916973078, "mdate": 1762916973078, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}