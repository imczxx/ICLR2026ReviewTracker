{"id": "Z06LNjqU1g", "number": 18297, "cdate": 1758286107505, "mdate": 1759897113313, "content": {"title": "Scale-wise Distillation of Diffusion Models", "abstract": "Recent diffusion distillation methods have achieved remarkable progress, enabling high-quality ${\\sim}4$-step sampling for large-scale text-conditional image and video diffusion models (DMs). \nHowever, further reducing the number of sampling steps becomes more and more challenging, suggesting that efficiency gains may be better mined along other model axes. \nMotivated by this perspective, we introduce SwD, a scale-wise diffusion distillation framework that equips few-step models with progressive generation, avoiding redundant computations at intermediate diffusion timesteps. \nBeyond efficiency, SwD enriches the family of distribution matching distillation approaches by introducing a simple distillation objective based on kernel Maximum Mean Discrepancy (MMD). \nThis loss significantly improves the convergence of existing distillation methods and performs surprisingly well in isolation, offering a competitive baseline for diffusion distillation.\nApplied to state-of-the-art text-to-image/video diffusion models, SwD approaches the sampling speed of two full-resolution steps and largely outperforms alternatives under the same compute budget, as evidenced by automatic metrics and human preference studies.", "tldr": "", "keywords": ["diffusion distillation", "few-step models", "image generation", "video generation"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c2b275040eacded3d0a38c335c27d4d3bea4e177.pdf", "supplementary_material": "/attachment/aae9dd08e15f091b7f47d6c52cc5d579b937ed76.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes Scale-wise Distillation (SwD), a method that distills a diffusion model into a single model capable of progressively increasing resolution while generating images with only a few sampling steps.\n\nThe key ideas are:\n(i) Spectral analysis, which shows that in the early high-noise stages, high-frequency components are largely suppressed, thus computations can be performed at lower spatial/temporal resolutions to save cost;\n(ii) A progressive sampling and training procedure, where at each step the resolution is increased, and the previous step’s\nis upsampled → re-noised to serve as the input for the next step;\n(iii) A simple distribution matching loss that aligns teacher and student distributions in the DM feature space using Maximum Mean Discrepancy (MMD), particularly a linear-kernel variant (LMMD)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "-  **Method motivation**: Through RAPSD-based analysis, the paper convincingly demonstrates why low-resolution processing is safe during high-noise stages (Fig. 1). This motivation is appropriate as a methodological rationale; however, similar motivations have actually been used several times before from the diffusion efficiency literature. See Weakness.\n\n- **Solid experiments**: The approach is also extended to both text and video domains. The comparison of efficiency in Tables 4 and 5 is very appropriate, and the performance comparison is clearly shown in Figure 7. Under the same number of steps, SWD and the full model seem to have comparable performance, but SWD shows better efficiency."}, "weaknesses": {"value": "- Recently, many diffusion efficiency studies have discussed that it is reasonable to focus on low-frequency components at time steps close to the noise. For example, [1] uses a transformer with a larger patch size at earlier (noise-near) time steps, and [2] proposes a method to better capture low-frequency information at each time step. It would be better if the motivation of this work were discussed in connection with these findings.\n\n- My greatest concern is whether the proposed method can effectively capture high-frequency details. Since the method focuses largely on low-frequency content except at the final step, this potentially poses a limitation. Moreover, because large-resolution images are involved, it may be difficult for the metrics to properly evaluate whether the high-frequency information has been preserved. I strongly recommend incorporating the measurement of FID-Patch as used in the SDXL‑Lightning paper to comprehensively assess fine detail preservation.\n\n\n[1] (CVPR 25) FlexiDiT: Your Diffusion Transformer Can Easily Generate High-Quality Samples with Less Compute\n\n[2] (CVPR 25) Autoregressive Distillation of Diffusion Transformers\n\n[3] SDXL-Lightning: Progressive Adversarial Diffusion Distillation"}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "F6qUDAXtLe", "forum": "Z06LNjqU1g", "replyto": "Z06LNjqU1g", "signatures": ["ICLR.cc/2026/Conference/Submission18297/Reviewer_8Ahm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18297/Reviewer_8Ahm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18297/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761806155163, "cdate": 1761806155163, "tmdate": 1762928019025, "mdate": 1762928019025, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper advances diffusion distillation by introducing a scale-wise few-step diffusion model. Instead of operating entirely at a fixed resolution, the model begins at a lower scale and progressively increases to the final resolution, similar to standard few-step diffusion approaches. Additionally, the authors propose a Maximum Mean Discrepancy (MMD)-based distillation loss to complement the existing DMD and GAN losses, further improving training effectiveness. Experiments conducted on various architectures—including SD 3.5 and FLUX for image generation (evaluated on COCO2014 and MJHQ) and WAN 2.1 for video generation (evaluated on VBench 2.0)—demonstrate the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper presents a detailed spectral analysis of the latent spaces across different diffusion models, offering valuable insights that motivate the first contribution—scale-wise distillation.\n\n2. The proposed distillation framework is evaluated on multiple diffusion models, covering both image and video generation tasks. The results demonstrate the potential of scale-wise distillation to achieve higher efficiency while maintaining performance comparable to existing distillation methods.\n\n3. The paper is clearly written and well-organized, with logical section flow and well-explained experimental setups that effectively support its main conclusions."}, "weaknesses": {"value": "1. The experiment on different upsampling strategies (lines 192–212) lacks evaluations with alternative scale configurations (e.g., from/to 32, 80, or 96), which would provide a more comprehensive and reliable analysis.\n\n2. The paper does not explain why the temporal dimension of SwD does not contribute to performance improvement when applied to Wan 2.1 (lines 375–377).\n\n3. The human preference study charts in Figures 6, 7, and 8 lack sufficient descriptive captions or visual annotations, reducing interpretability.\n\n4. In Table 3, the performance of SwD on 8B- and 12B-scale models shows only marginal gains over other distilled variants—for instance, SD3.5-L-Turbo (0.71 vs. 0.70) and FLUX-Schnell (0.71 vs. 0.69). Moreover, the human preference study (Figure 6) indicates that SD3.5-L-SwD and FLUX-SwD are outperformed by Turbo-L and FLUX-Schnell in most aspects, calling into question the practical advantage of SwD at similar scales.\n\n5. The paper omits comparisons with other few-step video diffusion models, such as Video LCM [1], T2V-Turbo [2], and MagicDistillation [3], which are relevant baselines.\n\n6. There is no discussion of Jenga [4], which shares a similar conceptual idea of adjusting scale with timestep (smaller scales for larger timesteps and larger scales for smaller timesteps).\n\n7. Table 3 lacks a description of the scale schedule corresponding to each timestep, making the setup difficult to reproduce.\n \n[1] https://arxiv.org/abs/2312.09109 \n\n[2] https://arxiv.org/abs/2410.05677 \n\n[3] https://arxiv.org/abs/2503.13319 \n\n[4] https://arxiv.org/abs/2505.16864"}, "questions": {"value": "1. Why does the GenEval result for Infinity reported in this paper (0.69 in Table 3) differ from the value reported in the original Infinity paper (0.73)?\n\n2. In Equation (2), how are the two presented kernels applied in practice?\n\n3. Are the models initialized from pretrained weights or trained from scratch?\n\n4. Could the authors provide additional explanation for why the temporal dimension in SwD does not lead to performance improvements in Wan 2.1? (lines 375–377)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "1lEN22HfDZ", "forum": "Z06LNjqU1g", "replyto": "Z06LNjqU1g", "signatures": ["ICLR.cc/2026/Conference/Submission18297/Reviewer_h2GD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18297/Reviewer_h2GD"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18297/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761917588309, "cdate": 1761917588309, "tmdate": 1762928018599, "mdate": 1762928018599, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the inefficiency of few-step diffusion distillation methods, which redundantly compute all steps at full resolution. The authors propose two main contributions.First, Scale-wise Distillation (SwD), a framework where a single generator progressively increases its operating resolution during the few-step sampling process. This avoids unnecessary computation in early, noisy steps, where high-frequency detail is absent. Second, a simple and effective MMD-based distillation loss ($\\mathcal{L}_{MMD}$) that matches student and teacher feature distributions. This loss is shown to be a highly competitive baseline on its own and significantly speeds up training. Applied to SOTA models (SD3.5, FLUX, Wan2.1), SwD provides ~2-3x speedup over full-resolution models at the same step count and achieves significantly higher quality under the same computational budget"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The core idea of unifying progressive generation with few-step distillation (SwD) is novel and elegant. The motivation is strong, grounded in a solid spectral analysis (Section 3) of VAE latents for both images and video;\n2. The paper introduces a simple MMD-based loss that is surprisingly powerful. Ablations (Table 6) show it performs competitively on its own while being remarkably efficient. As it requires no extra trainable models (unlike GAN or DMD losses), it enables >7x faster training iterations (Table 5), making it a highly valuable standalone contribution;\n3. The experiments are comprehensive. The key comparison in Section 5.2 (Figure 7, Tables 7-8) clearly demonstrates SwD's superiority: at an equivalent compute cost (e.g., 4-step SwD vs. 2-step Full-res), SwD produces significantly better-quality images with fewer defects . The main results (Table 3, Figure 6) show SOTA performance, even outperforming teacher models in human preference;"}, "weaknesses": {"value": "1. The framework's performance depends on the co-design of the timestep schedule $[t_i]$ and the scale schedule $[s_i]$. While the authors provide the schedules used (Appendix D), the paper offers limited intuition on the methodology for finding these optimal schedules or the model's sensitivity to them.\n2. While the $ \\mathcal{L} _ {MMD} $ only variant is exceptionally simple, the full $ \\mathcal{L} _ {SwD} $ objective used to achieve the absolute SOTA results ($\\mathcal{L} _ {MMD}+\\mathcal{L} _ {DMD}+\\mathcal{L} _ {GAN}$) inherits the training complexity of methods like DMD2 (e.g., training a \"fake\" DM). However, the paper wisely presents the $\\mathcal{L} _ {MMD}$-only path as a highly effective, simpler alternative."}, "questions": {"value": "see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qYpTQQSy2J", "forum": "Z06LNjqU1g", "replyto": "Z06LNjqU1g", "signatures": ["ICLR.cc/2026/Conference/Submission18297/Reviewer_cK3V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18297/Reviewer_cK3V"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18297/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761924442453, "cdate": 1761924442453, "tmdate": 1762928018294, "mdate": 1762928018294, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Scale-wise Distillation (SwD), which progressively increases latent resolution during few-step diffusion distillation.\nMotivated by spectral analysis showing that high-noise latents mainly contain low-frequency content, the method reduces redundant computation at early steps.\nAn additional MMD-based distillation loss is proposed and combined with DMD, showing competitive results on SD3.5, FLUX, and Wan2.1 models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* Clear and well-motivated idea linking noise level and latent frequency spectrum.\n* Practical framework that integrates smoothly with existing distillation methods.\n* The proposed MMD loss is easy to use, and effective even alone.\n* Good results with notable speedups for both text-to-image and text-to-video generation.\n* The writing is clear and the figures (e.g., Figure 1 spectral plots) effectively communicate the intuition behind the framework."}, "weaknesses": {"value": "1. **Limited and possibly unfair baseline comparisons (SDXL case):**  \nTable 3 compares SwD results on SD3.5 and FLUX but omits SwD results on SDXL, even though Appendix B (Figure 9) shows that SDXL experiments were performed. For a fair evaluation, the authors should include SDXL-SwD and compare it directly to DMD2-SDXL and SDXL-Turbo. Moreover, other recent open-source distillation baselines such as Hyper-SD [Hyper-SD: Trajectory Segmented Consistency Model for Efficient Image Synthesis] should be incorporated.\nGiven that the paper emphasizes the synergy between MMD + DMD losses, fair quantitative evidence across identical model backbones is essential to support the claimed superiority.\n\n2. **Insufficient validation for FLUX and Wan distillations:**  \nThe comparison for FLUX and Wan 2.1 models is not convincing, as no competing baselines are provided. Stronger open-source baselines such as Hyper-FLUX, CausVid, or LightX2V (all publicly available and Wan-based distillation frameworks) should be included. Without these comparisons, it is difficult to judge the SwD’s efficiency and quality againest other distillation methods.\n\n3. **a minor issue** :  \nIn Table 3, the number of function evaluations (NFE) or diffusion steps used for each model is unclear, making speed–quality trade-offs hard to assess.\n\n\n4. **Relationship between MMD loss and prior progressive distillation methods (ADD/LADD) is not well clarified:**  \nThe MMD loss seems similar with the progressive distillation in ADD/LADD with different training objective. (constrain intermediate latent representations via feature alignment.) The paper should discuss more explicitly:\n* Whether the training procedure of “MMD-only distillation” is otherwise identical to ADD or DMD pipelines aside from the loss definition.\n* What specific advantages (e.g., stability, generalization) MMD introduces beyond computational simplicity."}, "questions": {"value": "Please see the part of Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "U8VJcvgIIG", "forum": "Z06LNjqU1g", "replyto": "Z06LNjqU1g", "signatures": ["ICLR.cc/2026/Conference/Submission18297/Reviewer_iUZm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18297/Reviewer_iUZm"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18297/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761942733632, "cdate": 1761942733632, "tmdate": 1762928017772, "mdate": 1762928017772, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}