{"id": "3e8nn8GlR7", "number": 15053, "cdate": 1758247265718, "mdate": 1763536561143, "content": {"title": "Knowledge Distillation for Semantically Inconsistent Data", "abstract": "Knowledge Distillation (KD) is a widely used technique for model compression, transferring knowledge from a large teacher model to a smaller student model. While most existing KD approaches focus on aligning outputs (logits) or intermediate features between teacher and student models, they typically overlook a key observation: not all training samples contribute equally to the knowledge transfer process. To address this limitation, this paper introduces a novel method to identify the data which exhibits semantic inconsistency between its input space and feature space. By adaptively assigning higher weights to these semantically inconsistent data during student model learning, the proposed method can refine the teacher's knowledge to better align with the student's needs, thereby improve the general knowledge distillation process. To demonstrate the general effectiveness of the proposed method, we embed it into several popular KD frameworks and extensively evaluate it on a diversity of teacher and student architectures. The experimental results prove that the proposed method can significantly boost knowledge distillation tasks, and set new state-of-the-art results on the CIFAR-100, Tiny-ImageNet, and ImageNet datasets. Code is given in the supplementary material.", "tldr": "This paper proposes a generall enhancing techiqque for the existing knowledge distillation methods.", "keywords": ["Knowledge Distillation", "Model Compression", "Data Importance", "Semantic Inconsistency", "Image Classification"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1626162126bcc01ec5f3338dd2df377a8ce73587.pdf", "supplementary_material": "/attachment/d631836a9ac7a11a58fc39f1f6ac81837e40596d.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes a new data-adaptive Knowledge Distillation (KD) method that improves how knowledge is transferred from a large teacher model to a smaller student model. Traditional KD methods align outputs or intermediate features but treat all training samples equally, ignoring that some contribute more effectively to learning.\n\nThis work identifies semantically inconsistent samples—those whose input representations and feature-space semantics differ—and assigns them higher weights during student training. By emphasizing these samples, the method refines the teacher’s knowledge to better suit the student’s learning process.\n\nIntegrated into multiple KD frameworks, the approach consistently improves performance across diverse teacher–student architectures and achieves state-of-the-art results on CIFAR-100, Tiny-ImageNet, and ImageNet, demonstrating its broad effectiveness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed KD framework addresses semantically inconsistent samples while transferring the knowledge from the teacher to the student by assigning different weights to distinct samples. The proposed framework effectively distills the knowledge learned by the teacher to the student without transferring irrelevant knowledge during the KD process.\n\n2. The proposed framework leverages strong data augmentation. i.e., Mixup, to quantify the semantic inconsistency of a data sample. By doing this, the proposed framework effectively reweights the consistency of the data samples dynamically.\n\n3. The paper demonstrates that the proposed KD framework outperforms the existing KD methods. For some pairs of teacher and student models, the student with the proposed framework also outperforms the teacher."}, "weaknesses": {"value": "1. The proposed framework increases computational complexity for model training. When computing inconsistency scores for data, the model requires additional forward passes for Mixup samples through the student. Thus, the training time for the proposed framework increases.\n\n2. The experiment includes the most essential quantitative results across different datasets and pairs of teacher and student models; however, the experiment lacks the quantitative results for pairs of the teacher and student models with heterogeneous architectures."}, "questions": {"value": "No question for this paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HAwveLJynm", "forum": "3e8nn8GlR7", "replyto": "3e8nn8GlR7", "signatures": ["ICLR.cc/2026/Conference/Submission15053/Reviewer_AMS7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15053/Reviewer_AMS7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15053/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761716716248, "cdate": 1761716716248, "tmdate": 1762925374387, "mdate": 1762925374387, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a technique to improve Knowledge Distillation (KD) by addressing the common assumption that all training samples contribute equally. The proposed method identifies \"semantically inconsistent data\" by using Mixup to check if semantic relationships from the input space are preserved in the student model's feature space. It then calculates a \"semantic inconsistency score\" to adaptively assign higher weights to these more challenging samples. This model-agnostic re-weighting strategy is easily integrated into various KD frameworks and is shown to achieve state-of-the-art (SOTA) results on the CIFAR-100, Tiny-ImageNet, and ImageNet datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**Originality:** The paper's originality lies in its creative adaptation of an existing technique (Mixup) to address a well-motivated problem in knowledge distillation (KD)—the assumption that all training samples contribute equally.  While re-weighting samples is not a new concept, the method of using semantic consistency as the heuristic for re-weighting is novel. \n\n**Quality:** The paper is supported by a comprehensive and extensive empirical evaluation. The authors validate their method across three distinct datasets, employ a wide variety of teacher-student architectures (including both homogeneous and heterogeneous pairs) , and compare against a large suite of 18 different baselines. A key strength of the evaluation is demonstrating that the proposed method is not just a standalone solution, but a general enhancer; it successfully improves the performance of several existing SOTA methods when applied on top of them. \n\n**Clarity:**  The problem is clearly motivated in the introduction . The proposed method is presented in a straightforward manner, with its pipeline clearly illustrated in Figure 1 and its implementation details summarized in Algorithm 1. The core logic—calculating an inconsistency score and using it to re-weight the standard KD loss is simple and accessible.\n\n**Significance:** The primary significance of this work lies in its practical utility. The authors have proposed a simple, model-agnostic module that can be integrated into various existing KD frameworks with minimal implementation effort (reportedly \"with several lines of codes\" )."}, "weaknesses": {"value": "First, while the method achieves consistent improvements, the performance gains over SOTA methods, as shown in Tables 1, 2, and 4, are relatively modest (often under 1.0%). Given that the approach introduces a notable increase in training complexity (around 20-30%), it is worth considering whether the performance-complexity trade-off is currently favorable.\n\nSecond, the motivation of this paper is quite intuitive, but it lacks theoretical or qualitative analysis. This makes it difficult for readers to fully trust the claims of the paper, thereby undermining its persuasiveness.\n\nFinally, while the paper positions the method as a \"general enhancing technique,\" the experimental validation, which is primarily based on traditional CNNs (e.g., ResNet, VGG) on classic image classification tasks, appears somewhat limited in its ability to fully support this broad claim. It would be greatly strengthened by future work exploring its efficacy on more modern architectures (e.g., Vision Transformers) or different domains (e.g., NLP)."}, "questions": {"value": "The paper's motivation relies on the semantic inconsistency score  being an effective proxy for sample difficulty, but this is primarily justified by an intuitive claim and a loss correlation plot (Figure 3a). \n\nHow does this specific heuristic compare against simpler, more computationally-cheap proxies for sample difficulty? For instance, what are the results if you re-weight samples based on high student baseline loss or high student prediction entropy? An ablation study comparing these alternatives is crucial to prove that the proposed Mixup-based score provides a unique and necessary signal. Could you provide qualitative examples of the images that receive high inconsistency scores versus those that receive low scores? This would provide valuable intuition about what kind of \"hard\" samples the model is focusing on (e.g., atypical views, rare classes, fine-grained details) and strengthen the paper's claims.\n\nHow does this method perform on more modern architectures, such as Vision Transformers (ViT), which have different feature space properties?  Given that the method builds upon input-space interpolation (e.g., Mixup), it would be great to clarify how the technique might be adapted for domains like NLP, where defining such operations can be challenging. A discussion on the general scope of the method would be very helpful for the reader."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MIzGrNDBgI", "forum": "3e8nn8GlR7", "replyto": "3e8nn8GlR7", "signatures": ["ICLR.cc/2026/Conference/Submission15053/Reviewer_EkYz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15053/Reviewer_EkYz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15053/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761741886134, "cdate": 1761741886134, "tmdate": 1762925373853, "mdate": 1762925373853, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors employ a data augmentation technique, i.e. Mixup, to generate an inconsistency score based on the similarity between the original data and its augmented version. This score is then used to assign adaptive weights to the distillation KD loss. It is a plug-and-play KD reweighting wrapper using Mixup-based feature “consistency” (mix(f) vs f(mix)). The experimental results demonstrate strong performance across various KD frameworks. While this approach is straightforward yet effective, the underlying theory and rationale for such improvements remain underexplored and unclear. However,  the central assumption is under-justified for nonlinear encoders. The inconsistency score is calculated from different (original and mixed) inputs within the same student network. Thus, it may not be suitable for guiding distillation between teacher and student networks. Furthermore, this inconsistency can significantly fluctuate depending on both the actual values of lambda and beta as shown in Fig. 2, and which j-th sample (x_j) is selected for mixing. Consequently, it might not accurately reflect the difficulty level of a given i-th sample (x_i)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. A notable strength of the proposed method is its plug-and-play design. The semantic inconsistency weighting module can be seamlessly integrated into various existing knowledge distillation frameworks without architectural modification or additional supervision. Despite its simplicity, the method consistently improves student performance across all evaluated frameworks and datasets, demonstrating strong generality and practical applicability.\n2. The approach requires only one additional forward pass for Mixup-augmented samples, resulting in roughly 20–30% training overhead while keeping the model architecture and loss formulation unchanged. Such a lightweight design makes it easy to adopt in real-world training pipelines without introducing complex dependencies or hyperparameter tuning."}, "weaknesses": {"value": "1. The proposed per-sample weighting score (Eq. 6) is fundamentally built on Mixup-style interpolation in the input space, and uses the inconsistency between this interpolation and the student's feature space as a proxy for sample difficulty. However, this core **f(mix) ≈ mix(f)** claim is under-theorized. In its current form, the score mainly captures a deviation from local linearity of the encoder along the Mixup path, rather than “semantic inconsistency.” This inconsistency can significantly fluctuate depending on both the mixing coefficient and which sample is selected for mixing.\n2. All experiments are conducted on image classification benchmarks (CIFAR-100, Tiny-ImageNet, ImageNet). This leaves open an important question: does emphasizing “hard” samples via the proposed weighting scheme actually translate to improvements in downstream tasks that rely on richer spatial reasoning, such as object detection and semantic segmentation? Knowledge distillation is widely used in those settings, particularly for deploying lightweight students under strict latency constraints. A demonstration on at least one detection task and one segmentation task would significantly strengthen the empirical claims. Right now, it is hard to assess how broadly applicable the method is beyond standard classification.\n3. The inconsistency score (Eq. (6)) is computed purely from student features, without considering teacher representations. This design may lead to instability in early training when the student feature space is still immature and fluctuating, potentially resulting in noisy or misleading scores. Theoretical analysis and ablation studies on the proposed metric could help clarify its stability and reliability.\n4. The paper emphasizes the importance of focusing on semantically inconsistent or ``hard'' samples, but it lacks direct comparisons with other recent hard-sample-oriented knowledge distillation methods. For example, the Adaptive Temperature Distillation (ATD) method explicitly adjusts the distillation temperature based on sample difficulty to emphasize informative examples. Including such baselines would help clarify whether the proposed semantic inconsistency score provides a more effective or complementary way of identifying hard samples. A quantitative comparison or joint ablation with ATD-like approaches could strengthen the empirical evidence for the claimed advantages.\n5. Analyzing the sensitivity of Mixup pairing is essential. It's important to examine how score distributions and downstream metrics change under various pairing strategies, such as random pairings, same-class pairings, nearest-neighbor pairings, or cross-manifold mixes.\n[1] Yang S, Yang X, Ren J, et al. Adaptive Temperature Distillation method for mining hard samples’ knowledge[J]. Neurocomputing, 2025, 636: 129745."}, "questions": {"value": "1. Please provide formal conditions/derivations of the central assumption: the self semantic inconsistency (mix(f) vs f(mix)) is effective for teacher-student distillation.\n2. In Fig. 1, it is more like CutMix and related region-level mixing strategies. They often produce qualitatively different supervision signals than Mixup, especially for localization-sensitive classes. Whether the same idea still holds, or how robust the score is, when alternative data mixing strategies are used."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "qZAYDm6ulP", "forum": "3e8nn8GlR7", "replyto": "3e8nn8GlR7", "signatures": ["ICLR.cc/2026/Conference/Submission15053/Reviewer_CvNq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15053/Reviewer_CvNq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15053/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761807348291, "cdate": 1761807348291, "tmdate": 1762925373484, "mdate": 1762925373484, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a data-driven knowledge distillation (KD) algorithm, predicated on the observation that not all training samples contribute equally to the knowledge transfer process. The method computes the feature map similarity between data-augmented and unaugmented samples, subsequently assigning negative weights within the distillation loss to refine the transfer. The authors report state-of-the-art results on the CIFAR-100, Tiny ImageNet, and ImageNet datasets.\n\nA significant concern regarding this work is its focus on a mature research area. Traditional knowledge distillation has been extensively studied, and the practical utility of incremental improvements in this domain is arguably limited. Consequently, the method's practical significance may be constrained unless it can be generalized beyond this classical setting to contemporary paradigms, such as diffusion models or large language models.\n\nOn a minor note, the manuscript requires careful proofreading; for instance, reference citations consistently lack necessary spacing."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper is clearly written and easy to follow. It presents a data-centric approach to knowledge distillation, offering a novel perspective that diverges from conventional methods focused on feature- or logit-matching. The empirical validation is comprehensive, demonstrating the effectiveness of the proposed algorithm across the CIFAR-10, Tiny-ImageNet, and ImageNet-1k benchmarks."}, "weaknesses": {"value": "1. The paper's scope remains limited to traditional knowledge distillation. However, the field's focus has increasingly shifted to large-scale generative models, such as diffusion models and large language models (LLMs). The empirical validation is confined to classical vision benchmarks (CIFAR-10, Tiny-ImageNet, and ImageNet-1k), which, while standard, represent a mature problem domain. To demonstrate broader applicability and practical significance, the authors are strongly encouraged to explore extending their method to contemporary challenges, such as image/video generation or the compression of LLMs.\n\n2. The method utilizes data augmentation and computes similarity based on the model's output. A clarification is required regarding the training dynamics: Are gradients propagated through the forward pass of the augmented images, or are these representations detached and used only to compute the similarity score?\n\n3. The paper does not provide a detailed analysis of why the proposed algorithm is effective. Specifically, the intuition behind assigning a higher weight to samples with lower similarity between augmented and original representations is not sufficiently explained. We suggest the authors add empirical analysis or ablation studies to elucidate this mechanism and justify this core design choice.\n\n4. The paper requires proofreading for minor formatting issues; for example, spaces are consistently missing in the reference citations throughout the text."}, "questions": {"value": "No"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pfvxxcxOo9", "forum": "3e8nn8GlR7", "replyto": "3e8nn8GlR7", "signatures": ["ICLR.cc/2026/Conference/Submission15053/Reviewer_Y1Ux"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15053/Reviewer_Y1Ux"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15053/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762080965290, "cdate": 1762080965290, "tmdate": 1762925373016, "mdate": 1762925373016, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}