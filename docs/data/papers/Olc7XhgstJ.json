{"id": "Olc7XhgstJ", "number": 23998, "cdate": 1758351476294, "mdate": 1759896787187, "content": {"title": "SteadyThought: Mitigating LLM Under-Thinking via Thought-Level Preference Optimization", "abstract": "Flexible switching between reasoning trajectories (i.e., thoughts switching) has significantly enhanced the reasoning capabilities of Large Reasoning Models (LRMs). However, existing models often switch excessively yet fail to sustain promising reasoning thoughts——a phenomenon termed “under-thinking”. While recent efforts suppress switching to mitigate this, such over-correction may discard valuable trajectories. To address this challenge, we propose Steady Thought (ST), a novel thought-level preference optimization framework. ST first segments model responses into thought sequences then guides the model to complete reasoning from these thoughts without further switching, generating coherent trajectories.Finally, ST performs thought-level preference optimization by treating the newly generated response as preferred and the original one as dis-preferred. Experiments across multiple models and datasets show that ST effectively mitigates under-thinking. It reduces output length by up to 39.3% while improving accuracy by up to 5.3%, with strong generalization. Further analysis confirms that ST leads to more rational switching and deeper exploration of solution thoughts.", "tldr": "", "keywords": ["LLM Reasoning", "Underthinking"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f66b2e390178aadf8e0e583757fb8a21de9e7702.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Steady Thought (ST), a thought-level preference optimization framework designed to mitigate the under-thinking phenomenon in large reasoning models (LRMs)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Experimental results are good."}, "weaknesses": {"value": "1. This work lacks significant novelty and does not offer compelling research insights. The three proposed components share similar ideas with prior studies, making the paper appear more like a compositional work built upon existing methods. Specifically, the designs in Sections 3.1 and 3.2 are rather straightforward, with many previous works employing analogous strategies; thus, the contribution in these parts can hardly be regarded as truly innovative and instead reflects a combination of existing tricks. Furthermore, the main idea of Section 3.3 is almost a direct extension of SimPO, with only minor adjustments in the level of application granularity. It lacks substantial algorithmic innovation and can be viewed as a mild variant rather than a new optimization framework. In summary, this paper represents an incremental improvement at the technical level—although the experimental results are satisfactory, the work as a whole resembles a technical report rather than a research study with strong originality;\n\n2. While threshold tuning is discussed, the paper lacks qualitative or visual evidence (e.g., example trajectories) showing clearer reasoning stabilization;\n\n3. Although the paper reports reduced token counts and small accuracy gains, these improvements could be attributed to shorter decoding or regularization effects rather than the claimed “thought-level optimization.” There is no qualitative or mechanistic evidence showing that the model truly learns a new form of reasoning persistence or gains interpretable control over its thought process."}, "questions": {"value": "No more."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3Eu8J4cEu0", "forum": "Olc7XhgstJ", "replyto": "Olc7XhgstJ", "signatures": ["ICLR.cc/2026/Conference/Submission23998/Reviewer_Knbc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23998/Reviewer_Knbc"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23998/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761032677967, "cdate": 1761032677967, "tmdate": 1762942892441, "mdate": 1762942892441, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors observe that models often discover a correct reasoning path early in inference but then perform numerous unnecessary thought switches, undermining reasoning depth and coherence. To address this \"under-thinking\" problem, they propose Steady Thought (ST), a framework that: (1) segments thoughts using entropy-based detection, (2) completes each thought without further switching, and (3) constructs thought-level preference pairs based on final correctness. Experimental results show that ST successfully mitigates under-thinking by reducing unnecessary switches, leading to more focused reasoning while maintaining or even enhancing performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Clearly identifies and formalizes \"under-thinking\" as a thought-level preference learning problem, more fine-grained than prior response-level approaches, preserving the model's flexibility to explore alternative reasoning paths when needed.  \n- The proposed ST framework combining entropy-based thought segmentation with a SimPO-inspired preference objective (STPO) that effectively mitigates length bias.  \n- Strong empirical results: consistent accuracy gains and token reductions across multiple models and datasets, including out-of-distribution generalization to code tasks despite training only on math data."}, "weaknesses": {"value": "- The reliance on predefined switch tokens (e.g., \"wait\", \"alternatively\") limits generalization, especially for models or domains that switch thoughts implicitly without explicit lexical cues. In contrast, concurrent work like SwiReasoning (arXiv:2510.05069) effectively handles implicit thought switching in latent space.  \n- Thought segmentation hinges on a tunable entropy threshold; while ablations are provided, its robustness across diverse reasoning styles or model architectures remains unclear.  \n- The computational overhead of the ST pipeline, particularly completion per response during data construction, is not adequately discussed.\n- The method assumes a correct answer can be derived by completing a single early thought, which may not hold for problems requiring genuine multi-stage exploration or backtracking.  \n- The experimental evaluation is limited in scope: only two models and three benchmarks are tested. The paper does not investigate whether the approach scales effectively to larger reasoning models."}, "questions": {"value": "See the Weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "q8VSpIi1HA", "forum": "Olc7XhgstJ", "replyto": "Olc7XhgstJ", "signatures": ["ICLR.cc/2026/Conference/Submission23998/Reviewer_QcuC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23998/Reviewer_QcuC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23998/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761902951370, "cdate": 1761902951370, "tmdate": 1762942892013, "mdate": 1762942892013, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper, “SteadyThought: Mitigating LLM Under-Thinking via Thought-Level Preference Optimization,” addresses the phenomenon of under-thinking in large reasoning models (LRMs)—a tendency to switch reasoning trajectories excessively, abandoning promising thoughts prematurely. To solve this, they propose Steady Thought (ST), which consists of thought segmentation, thought completion, and fine-grained preference optimization. Experiments on multiple reasoning models across datasets demonstrate the effectiveness of the proposed approach."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "(1) This paper addresses the frequent thought switching problem by Steady Thought, a thought-level preference optimization framework.\n\n(2) Thought segmentation and thought completion are used to construct preference pairs to optimize LLMs.\n\n(3) Experiments are tested on two large reasoning models across three datasets."}, "weaknesses": {"value": "(1) The reasonability of using entropy to segment thoughts is not well justified. \n\n(2) The technical depth and novelty of the proposed method is somewhat limited.\n\n(3) The results in Table 2 are questionable. The percentage of correct thoughts is reduced when using steady thought. To my understanding, steady thought should reduce the number of thoughts but increase the percentage of correct thoughts."}, "questions": {"value": "Is there any quantitative metric to show the effectiveness of using entropy to segment thoughts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Fgs48JU52U", "forum": "Olc7XhgstJ", "replyto": "Olc7XhgstJ", "signatures": ["ICLR.cc/2026/Conference/Submission23998/Reviewer_nhq2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23998/Reviewer_nhq2"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23998/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996421339, "cdate": 1761996421339, "tmdate": 1762942891439, "mdate": 1762942891439, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a novel framework called Steady Thought, which aims to mitigate the pervasive phenomenon of \"under-thinking\" in Large Reasoning Models during complex reasoning tasks. This phenomenon is characterized by the model's failure to persevere and fully explore a promising reasoning path, instead switching excessively and inefficiently between thought trajectories."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.The writing is clear, and the motivation is well articulated.\n\n2.Recognizing the sensitivity of DPO to length bias, the authors introduce a length-normalized STPO objective based on SimPO, which is crucial for their method since the rejected switching trajectories are typically much longer than the selected completions.\n\n3.Both accuracy and efficiency are improved."}, "weaknesses": {"value": "1.The paper states that STPO reduces the number of tokens. For very challenging problems such as AIME 2024, the model may need multiple switches to find the correct reasoning path, indicating that exploration is valuable. Does ST risk over-penalizing reasonable exploration and switching, and to what extent might this affect the model’s ability to initially explore diverse reasoning strategies?\n\n2.The core preprocessing step, thought segmentation, relies on entropy-based detection and predefined thresholds. Although the authors mention hyperparameter tuning, there is a lack of analysis on the stability and robustness of these thresholds across different model scales (1.5B vs. 8B) and task types (mathematics vs. programming).\n\n3.In the thought completion stage, the model prevents switching by directly lowering the logits of trigger words such as “wait” and “alternatively.” This heuristic intervention might contradict the goal of STPO, which aims to implicitly suppress such words through learning."}, "questions": {"value": "see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "J1KCdqpDEh", "forum": "Olc7XhgstJ", "replyto": "Olc7XhgstJ", "signatures": ["ICLR.cc/2026/Conference/Submission23998/Reviewer_YpkJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23998/Reviewer_YpkJ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23998/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762096416188, "cdate": 1762096416188, "tmdate": 1762942890865, "mdate": 1762942890865, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}