{"id": "0wJuW3snwU", "number": 25499, "cdate": 1758368670307, "mdate": 1759896718760, "content": {"title": "SD-MAD: Sign-Driven Few-shot Multi-Anomaly Detection in Medical Images", "abstract": "Medical anomaly detection (AD) is crucial for early clinical intervention, yet it faces challenges due to limited access to high-quality medical imaging data, caused by privacy concerns and data silos. Few-shot learning has emerged as a promising approach to alleviate these limitations by leveraging the large-scale prior knowledge embedded in vision-language models (VLMs). Recent advancements in few-shot medical AD have treated normal and abnormal cases as a one-class classification problem, often overlooking the distinction among multiple anomaly categories. Thus, in this paper, we propose a framework tailored for few-shot medical anomaly detection in the scenario where the identification of multiple anomaly categories is required. We propose that separating anomalies relies on distinct radiological signs, routinely used by clinicians to bridge knowledge and images. To capture the detailed radiological signs of medical anomaly categories, our framework incorporates diverse textual descriptions for each category generated by a Large-Language model, under the assumption that different anomalies in medical images may share common radiological signs in each category. Specifically, we introduce SD-MAD, a two-stage \\textbf{S}ign-\\textbf{D}riven few-shot \\textbf{M}ulti-\\textbf{A}nomaly \\textbf{D}etection framework: (i) Radiological signs are aligned with anomaly categories and distinguished by amplifying inter-anomaly discrepancy; (ii) Aligned signs are selected further to mitigate the effect of the under-fitting and uncertain-sample issue caused by limited medical data, employing an automatic sign selection strategy at inference.  Moreover, we propose two protocols to comprehensively quantify the performance of multi-anomaly detection. Extensive experiments illustrate the effectiveness of our method.", "tldr": "", "keywords": ["Anomaly Detection", "Medical Image", "Few-shot Learning"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/033ee3a2bea6c41bed5f86e4d11487a5197a556b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a method for \"few-shot\" anomaly detection in the medical domain."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Pros:\n- A notable contribution is that, beyond conventional anomaly detection, the proposed method can also identify anomaly categories.\n- The paper is well organized and generally easy to follow."}, "weaknesses": {"value": "Cons:\n- There are several unclear or conflicting notations. For instance, in Sec. 3.1, $K$ denotes the number of samples, while in Sec. 3.3, it represents the number of anomaly categories. Similarly, both $i$ and $c$ seem to denote categories. These inconsistencies significantly hinder readability.\n- If $K$ indeed refers to the number of anomaly categories, how is it determined? This is not explained in the paper. If it is empirically set, the authors should discuss how its choice influences model performance.\n- w/ SS vs. w/o SS. The paper claims that identifying anomaly categories improves performance, yet provides no clear explanation or theoretical reasoning for why this is the case. A deeper discussion or analysis would strengthen the contribution.\n- The results are without statistical measures (e.g., mean ± std over 10 trials), which is standard practice in few-shot anomaly detection. This omission weakens the reliability of the comparisons.\n- It is unclear how sensitive the model performance is to the selection of samples, which is an important practical consideration.\n- The paper lacks any discussion of computational cost or inference time, which are crucial for clinical applicability.\n- Why did the authors choose to use the general CLIP model instead of a medical-domain variant? This decision should be justified.\n- The paper's definition of \"few-shot anomaly detection\" seems problematic. In the conventional sense, few-shot anomaly detection extends unsupervised anomaly detection—training with a few normal samples and testing on unseen tasks (which is in line with few-shot learning). However, this work trains on both normal and abnormal samples, which aligns more closely with small sample image classification rather than anomaly detection. The authors should reconsider and clarify the task formulation."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "AI9O5zgsn2", "forum": "0wJuW3snwU", "replyto": "0wJuW3snwU", "signatures": ["ICLR.cc/2026/Conference/Submission25499/Reviewer_SUm2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25499/Reviewer_SUm2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25499/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761895118153, "cdate": 1761895118153, "tmdate": 1762943452943, "mdate": 1762943452943, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a CLIP-based few-shot framework for medical abnormality recognition, incorporating (1) radiological “sign prompts,” (2) an inter-anomaly contrastive loss, and (3) a sign selection mechanism at inference. The authors position the work as extending few-shot anomaly detection to multi-anomaly settings and evaluate on ChestX-ray8, OCT-17, and FastMRI+."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Incorporating radiological sign descriptions into visual-language alignment is an interesting idea.\n- The few-shot multi-label formulation is practically relevant for real-world medical datasets."}, "weaknesses": {"value": "- The work is not anomaly detection but closed-set multi-label classification. The method assumes all anomaly labels are known during training and requires per-class support images. It does not detect abnormality in an open-set or unsupervised manner, which is the central definition of anomaly detection. The title and claims are therefore misleading.\n- No open-set or unseen-class evaluation. There is no experiment for detecting unseen anomaly types. In real clinical anomaly detection, new or rare abnormalities are the norm, yet the paper never addresses this problem. The method collapses to a standard supervised multi-label classifier.\n- Pixel-level AUROC is not shown in the main paper, and the appendix combines image-level and pixel-level AUROC into a single arithmetic “average,” which is mathematically invalid and masks the fact that the method trails AnomalyCLIP and MVFA on pixel-level AUROC.\n- Strongest baselines (MVFA, AnomalyCLIP) are moved to the appendix and perform comparably or better. The main tables omit the most relevant recent methods, and the appendix shows that the proposed approach does not consistently outperform them. This selective reporting undermines the claimed contribution.\n- The radiological sign prompts are not reproducible or clinically validated. The paper does not describe how the signs were generated, who verified them, how many exist per class, or whether they will be released. This prevents scientific reproducibility.\n- Lack of evidence that the datasets actually support “multi-anomaly” detection. ChestX-ray8 contains 14 abnormality labels, OCT-17 contains 3, and FastMRI+ contains 6, but the paper provides no statistics on how many anomalies occur per image, nor how often co-occurrence happens. Without reporting label cardinality or multi-label frequency, it is unclear whether the task is truly “multi-anomaly detection” or simply multi-label classification where most samples contain only one abnormality. Since the paper’s motivation depends on co-occurring anomalies, the absence of dataset analysis leaves the main claim unsupported."}, "questions": {"value": "- How does the method behave when a novel anomaly class appears at inference time?\n- Why are MVFA and AnomalyCLIP excluded from the main comparison tables?\n- Can the authors provide localization maps?\n- What percentage of samples in each dataset actually contain more than two anomalies?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "BF5rICgCmm", "forum": "0wJuW3snwU", "replyto": "0wJuW3snwU", "signatures": ["ICLR.cc/2026/Conference/Submission25499/Reviewer_LmK7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25499/Reviewer_LmK7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25499/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762099326355, "cdate": 1762099326355, "tmdate": 1762943452700, "mdate": 1762943452700, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces SD-MAD, a framework for few-shot multi-anomaly detection (MAD) in medical images. Unlike prior methods treating anomaly detection as a one-class classification problem (normal vs. abnormal), SD-MAD targets scenarios where multiple anomaly categories coexist. The framework is evaluated on diverse datasets using new multi-anomaly metrics, showing clear gains over CLIP and MedCLIP baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.The paper is well written and organized, with clear diagrams (Fig. 1–3) and detailed appendices.\n\n2.It defines and benchmarks few-shot multi-anomaly detection in medical AD area."}, "weaknesses": {"value": "1.Only limited baseline (CLIP and MedCLIP) are compared.\n\n2.The framework relies heavily on manually designed textual signs to represent anomaly semantics. It may make the system sensitive to the quality and accuracy of these textual descriptions. In practice, such signs may contain noise, redundancy, or mismatched terminology relative to the specific medical domain or dataset. When the textual prompts do not align well with the actual imaging characteristics, the performance of SD-MAD may degrade significantly.\n\n3.The novelty of this framework is limited. The core components—prompt-based supervision, adapter tuning, and margin-based loss—are primarily adapted from existing CLIP or few-shot learning paradigms."}, "questions": {"value": "Have the authors examined performance variance across different few-shot sample sets or seeds?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "h31zbUkDMu", "forum": "0wJuW3snwU", "replyto": "0wJuW3snwU", "signatures": ["ICLR.cc/2026/Conference/Submission25499/Reviewer_7E6r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25499/Reviewer_7E6r"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25499/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762293218384, "cdate": 1762293218384, "tmdate": 1762943452405, "mdate": 1762943452405, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel framework for few-shot multi-anomaly detection in medical images. Existing one-class few-shot anomaly detection approaches struggle to distinguish between multiple anomaly categories, which is often critical in real-world clinical scenarios. The authors enhance existing few-shot AD methods by leveraging vision–language alignment, adapting them to handle multi-anomaly detection tasks, and achieving favorable experimental results."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper proposes a few-shot anomaly detection model that can inherently handle multiple anomaly classes within a single framework. By aligning radiological signs with anomaly categories, the method introduces a novel and innovative approach.\n\n2. Experiments conducted across multiple evaluation metrics demonstrate strong and consistent performance gains over baseline methods such as vanilla CLIP, highlighting the effectiveness of the proposed approach. The provided visualizations further corroborate these findings."}, "weaknesses": {"value": "1. The methodology section contains a relatively large number of mathematical formulations, yet several key equations and symbols are insufficiently explained. Clearer definitions and intuitive interpretations would improve readability and reproducibility.\n\n2. The paper devotes substantial space to the Sign Selection process during inference; however, this component appears to have a limited positive effect in certain experiments. The authors should analyze and discuss potential reasons behind this phenomenon.\n\n3. The comparisons in Tables 1–4 are not sufficiently comprehensive. It is unclear why the authors do not include comparisons with CLIP-based approaches, such as AnomalyCLIP, which represent strong and relevant baselines for this task. Incorporating such comparisons would significantly strengthen the validity and credibility of the reported results."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "AEgxeBoIdt", "forum": "0wJuW3snwU", "replyto": "0wJuW3snwU", "signatures": ["ICLR.cc/2026/Conference/Submission25499/Reviewer_k1bu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25499/Reviewer_k1bu"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25499/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762623963760, "cdate": 1762623963760, "tmdate": 1762943452189, "mdate": 1762943452189, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}