{"id": "XmULVr15E0", "number": 6783, "cdate": 1757995488498, "mdate": 1759897894249, "content": {"title": "MAVEN: A Mesh-Aware Volumetric Encoding Network for Simulating 3D Flexible Deformation", "abstract": "Deep learning-based approaches, particularly graph neural networks (GNNs), have gained prominence in simulating flexible deformations and contacts of solids, due to their ability to handle unstructured physical fields and nonlinear regression on graph structures. However, existing GNNs commonly represent meshes with graphs built solely from vertices and edges. These approaches tend to overlook higher-dimensional spatial features, e.g. 2D facets and 3D cells, from the original geometry. As a result, it is challenging to accurately capture boundary representations and volumetric characteristics, though this information is critically important for modeling contact interactions and internal physical quantity propagation, particularly under sparse mesh discretization. In this paper, we introduce MAVEN, a mesh-aware volumetric encoding network for simulating 3D flexible deformation, which explicitly models geometric mesh elements of higher dimension to achieve a more accurate and natural physical simulation. MAVEN establishes learnable mappings among 3D cells, 2D facets, and vertices, enabling flexible mutual transformations. Explicit geometric features are incorporated into the model to alleviate the burden of implicitly learning geometric patterns. Experimental results show that MAVEN consistently achieves state-of-the-art performance across established datasets and a novel metal stretch-bending task featuring large deformations and prolonged contacts.", "tldr": "", "keywords": ["Deep Learning", "Explicit modeling", "Geometric Deep Learning", "Simulation of Solid Deformation"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bf97f6440ced5d607c6900981a8f3c75588d5a6d.pdf", "supplementary_material": "/attachment/7f4377c50ae4fc2b6d72dc1854cb98a3526adf10.zip"}, "replies": [{"content": {"summary": {"value": "MAVEN explicitly models high-dimension geometric mesh elements for physical simulation.\n\n**I am not an expert in this field, so an accurate evaluation is difficult for me. I will defer to the assessment of other reviewers.**"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- It is important to utilize more diverse 3D information when performing mesh-based simulation.\n\n- The work demonstrates both accuracy and computational efficiency; despite using more information, the computational efficiency did not significantly degrade."}, "weaknesses": {"value": "- As the authors themselves mentioned in the Related Works section, existing studies have also used high-dimensional information such as Cell."}, "questions": {"value": "See Weakness section"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RPvufhb8lg", "forum": "XmULVr15E0", "replyto": "XmULVr15E0", "signatures": ["ICLR.cc/2026/Conference/Submission6783/Reviewer_3Wkt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6783/Reviewer_3Wkt"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6783/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761596258689, "cdate": 1761596258689, "tmdate": 1762919057931, "mdate": 1762919057931, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The proposed paper, MAVEN, presents a graph neural network (GNN) model for simulating physics, particularly flexible solid deformations, including contacts. The key contribution of the work is the incorporation of additional explicit geometric features (cells and faces) into mesh graph network line of simulators, which previously considered only vertices and edges. This design reduces the burden of implicitly learning geometric patterns, enabling the network to capture 3D spatial structure and behaviour better.  \n\nThe authors describe how to integrate these higher-order geometric entities using geometric aggregators and disaggregators, along with additional message passing on cell–facet graphs. MAVEN is compared against MeshGraphNets and several follow-up models in this category. It consistently achieves state-of-the-art performance across a few established datasets and on a new metal stretch–bending benchmark that features large deformations and sparse meshes."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe core idea that incorporating higher-dimensional elements, such as 2D facets and 3D cells, enables better geometric representation of volumetric solids is a strong conceptual insight. \n\n2.\tThe paper carefully explains how to integrate these geometric features, introducing geometric aggregators/disaggregators and modified message-passing schemes. The authors analyse design choices such as averaging versus learning coefficients in a local coordinate system and demonstrate where this new model is most beneficial (for coarse mesh discretisation and contact scenarios). Overall, it extends the expressive capacity of GNNs for physical simulation without much computational cost.\n\n3.\tThe draft is clearly written. It systematically and thoroughly investigates different aspects of the idea. Considering that GNN-based simulation has received qwuite a bit of traction, this work provides nice insights, valuable to this community."}, "weaknesses": {"value": "1.\tIt is unclear whether MAVEN can handle beyond volumetric solids. MeshGraphNets can model a wider range of systems, such as cloth (thin shell) or fluid dynamics, whereas MAVEN seems focused only on deformable solids. It would be useful to clarify whether MAVEN can handle surface-based or thin-shell geometries (such as cloth) and whether a version using only faces, without volumetric cells, is feasible. This would also make the comparison with surface-based GNNs such as HOOD fairer. \n\n2.\tThe discussion focuses exclusively on Lagrangian (mesh-based) systems. The authors should comment on how MAVEN could extend to or differ from Eulerian formulations. Eulerian systems are explored in the original MeshGraphNet and its variants, but MAVEN's volumetric encoding will prevent GNN simulation in such scenarios. \n\n3.\tThe paper would benefit from positioning the approach relative to Physics-Informed Neural Networks (PINNs), see [Karniadakis et al.]\n\n[Karniadakis et al.] - Karniadakis, George Em, et al. \"Physics-informed machine learning.\" Nature Reviews Physics 3.6 (2021): 422-440.\n\nMinor comments and suggestions\n\n1.\tThe term *flexible deformations* (used in the title and abstract) is somewhat vague. Consider using elastic or soft-body deformations, which more accurately describe 3D deformable solids.  \n\n2.\tThe overview figure’s caption could be expanded to explain the method flow better.\n\n3.\tThere are a few typos:  \na.\tL292 likely refers to a geometric aggregator rather than an encoder.  b.\tIn Figure 4, the label GT in the top-right should probably read FIG."}, "questions": {"value": "1.\tHow can MAVEN handle surface meshes, such as thin shells or 2D manifolds, without volume or Eulerian systems? Could the model be extended to such cases?  \n\n2.\tAround L285/L318, the paper states: “To ensure translational and permutation invariance, we sort the vertices of each facet by their distances to the facet centroid, thereby enforcing a unique representation.” It is not clear how this sorting leads to invariance. Please provide a detailed justification. \n\n3.\tWhat are the optimisable parameters in the method? In Section 3.5, a list of additional optimisable parameters or MLPs compared to the baseline method (MGN) could be added."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tsUfQrZzLQ", "forum": "XmULVr15E0", "replyto": "XmULVr15E0", "signatures": ["ICLR.cc/2026/Conference/Submission6783/Reviewer_ZTpm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6783/Reviewer_ZTpm"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6783/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761731517123, "cdate": 1761731517123, "tmdate": 1762919057599, "mdate": 1762919057599, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a model that integrates volumetric geometric information into a GNN architecture to handle dynamic deformation simulation of meshes. Instead of using only vertices, as in conventional methods, the model integrates geometric features obtained from facets and cells and proposes a method for processing these elements. By incorporating this geometric information, the model demonstrated the advantage of achieving good performance in sparse meshes compared to other baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "I agree that the existing baselines failed to adequately capture the volumetric geometric information of the mesh. It is a strength that they proposed an architecture capable of containing all information that can be extracted from all possible constituent elements of the mesh: vertex, facet, and cell.\n\nThe architecture, designed to be applicable regardless of whether the mesh is tetrahedral or hexahedral, is a good foundation for generalization."}, "weaknesses": {"value": "1. The biggest concern is that the computational cost for calculating the surface area, volume, and perimeter of cells and facet at every step seems to be vast for a fine mesh. Please provide the computational cost of the process of calculating geometric information based on the number of nodes and edges.\n\n2. It was stated that facets within the search radius r are found using BVH when searching for contact surfaces. If this is the case, there is a need to specifically explain how the problem illustrated in Figure 1(d) is solved even in a sparse mesh. This seems to be the biggest differentiator from node-based methods, but I do not clearly understand how it is resolved.\n\n3. If we assume that all facets in a sparse mesh within the radius r are in contact, a different problem from node-based methods might arise: since the model recognizes contact even when the facets overlap only slightly, wouldn't this lead to the issue of perceiving a wider contact area than the actual contact surface? A case study on how MAVEN resolves the issue shown in Figure 1(d) seems necessary.\n\n4. The ablation study is conducted at too coarse a level, making it difficult to figure out what is effective for the model's performance. That is, it is difficult to clearly confirm whether the proposed model performs better because it actually incorporates more geometric information. Is the complex aggregator utilized superior to a simpler method of merely averaging and including the surrounding cell and facet information in the node features?\n\n5. Long-range interaction is one of the important problems for GNN-based simulators. However, this methodology does not seem to include a discussion on that aspect."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jSzhvZPhPg", "forum": "XmULVr15E0", "replyto": "XmULVr15E0", "signatures": ["ICLR.cc/2026/Conference/Submission6783/Reviewer_2viX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6783/Reviewer_2viX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6783/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761824418952, "cdate": 1761824418952, "tmdate": 1762919057248, "mdate": 1762919057248, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a mesh-aware volumetric encoding network to predict physically meaningful 3D deformation. The paper shows better performance compared with alternative baseline models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The overall idea of encoding meshes at different levels is plausible.\n\nThe performance improvements compared with existing methods."}, "weaknesses": {"value": "The deformation evaluated is somewhat limited. For more diverse materials and object shapes, it would be useful to show the generalizability. \n\nThe proposed method essentially relies on volumetric information, but it is unclear whether the compared methods are surface or volume based. This leads to questions regarding whether the evaluation is fair."}, "questions": {"value": "As all the examples shown have limited variations for the geometry, does the method generalize to more flexible shapes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "C1YZvSL3TF", "forum": "XmULVr15E0", "replyto": "XmULVr15E0", "signatures": ["ICLR.cc/2026/Conference/Submission6783/Reviewer_31zk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6783/Reviewer_31zk"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6783/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762306186333, "cdate": 1762306186333, "tmdate": 1762919056897, "mdate": 1762919056897, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}