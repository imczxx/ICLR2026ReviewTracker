{"id": "Lmqs7qBpzk", "number": 13754, "cdate": 1758222082538, "mdate": 1759897415481, "content": {"title": "Constrained Linear Best Arm Identification with Covariate Selection", "abstract": "This paper studies a constrained linear best arm identification problem with covariate selection in the fixed-confidence setting, where each arm is evaluated across multiple performance metrics. The mean performance of each metric depends linearly on the feature vectors of both arms and covariates. The goal is to identify the arm with the highest expected value of one targeted metric while ensuring that the means of the remaining metrics stay below specified thresholds for each covariate. We first establish an instance-dependent lower bound on the sample complexity, formulated as a multi-level optimization problem that captures both feasibility and optimality. We then prove that this bound is tight by designing an algorithm that asymptotically matches it. Since the original algorithm is computationally intensive, we develop a relaxed version of the bound through a surrogate optimization problem and derive its convex dual. Using this bound, we propose a duality-based decomposition algorithm that is computationally efficient, updating only two coordinates and performing a single gradient step per iteration. We further show that the algorithm achieves the relaxed bound in theory and demonstrates its practical effectiveness through numerical experiments.", "tldr": "", "keywords": ["Constrained Best Arm Identification", "Covariate Selection", "Fixed-Confidence", "Sample Complexity"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8aad03757ddac5c94a4ab5f884e45fbe341f5bff.pdf", "supplementary_material": "/attachment/9d8bb8e784c42db7a260dbc5f7ca4fa23fe65efc.zip"}, "replies": [{"content": {"summary": {"value": "The paper addresses fixed-confidence constrained best-arm identification (BAI) with active covariate selection in a discrete contextual linear bandit setting: each arm-covariate pair $(x_i,c_j)$ yields Gaussian observations with means linear in $\\phi(x_i, c_j)$ optimizing $f = \\phi^{\\top}\\theta$ subject to $g = \\phi^\\top\\beta < b$. It derives an instance-dependent lower bound and a track and stop (TaS) procedure to match the allocations according to the proposed lower bound. Furthermore, it relaxes the primal sampling allocation to a dual program over simplex weights $\\lambda$ with objective $-\\sum_h \\sqrt{\\sum_{I,j}\\lambda_{ij}\\kappa_h(x_i,c_j)}$ and recovers the optimal static ratio corresponding to a surrogate complexity measure. A duality-based sampler (DSR) implements these ideas and, on synthetic tasks, outperforms uniform/greedy baselines in sample complexity."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **Interesting setting.** Studies fixed-confidence constrained BAI with active covariate selection. To the best of my knowledge, this problem has not been looked at in the BAI context for pure strategies, even though there is some work in mixed-strategy setting.\n- **Novel dual formulation & algorithm design.** Provides a TaS-based solution based on the problem complexity, and then relaxes to a surrogate complexity and a one-step gradient descent based strategy that ensures the convergence of the arm visitation fractions to the optimal solution of the surrogate problem."}, "weaknesses": {"value": "(1) **Title/motivation (“covariate selection”):** The paper never exhibits a concrete instance where active covariate choice reduces sample complexity relative to a passive/contextual baseline while holding everything else fixed. Given the title, this is a material gap. A targeted experiment (same problem, (i) covariates passively sampled; (ii) agent forced to a fixed covariate; (iii) agent allowed to choose covariates) would resolve the ambiguity.\n\n(2) **Setup/Assumption 1:** The model is essentially a discrete contextual linear bandit (transductive flavor), but Assumption 1 excludes the tight-constraint case. That case is exactly when feasibility and optimality trade off most sharply and is the main motivation for constraints. The paper should include the boundary regime in statements/proofs. Furthermore, the paper states that this “can be relaxed by identifying $\\varepsilon$-optimal and feasible arms, as discussed in Degenne & Koolen (2019),” but no modification of the lower bound, GLRT, or proofs is given for the boundary case. \n\n(3) There are some technical inconsistencies -- see \"questions\".\n\n(4) Given the reference to “Fast pure exploration via Frank–Wolfe” (Wang–Tzeng–Proutière 2021), it is natural to ask whether FWS (which is computationally attractive and has optimality guarantees for linear BAI) can be adapted to your constrained + covariate-active setting. The paper neither discusses obstacles nor provides negative/positive results or experiments. If TaS is retained only to bridge to your dual relaxation, please articulate why FWS is inadequate (computationally or statistically) here, or provide a minimal comparison/ablation. As it stands, the algorithmic motivation is incomplete."}, "questions": {"value": "There are some core technical inconsistencies. Here are my major concerns:\n\n(1) I think that in (37), the RHS of the constraint should be $b$, not $0$. If that is the case, it is not obvious to me me how (38) follows from (37) -- can the authors provide the detailed steps?\n\n(2) There is a discrepancy between the definition of $\\chi_h$ in Theorem 2 and in (72) -- which one is correct?\n\nMinor point:\n\nProposition 1 is inaccurate as is. It should be asymptotically optimal *up to $\\alpha$*."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tmihF5Cifw", "forum": "Lmqs7qBpzk", "replyto": "Lmqs7qBpzk", "signatures": ["ICLR.cc/2026/Conference/Submission13754/Reviewer_Ey3L"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13754/Reviewer_Ey3L"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13754/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761319621638, "cdate": 1761319621638, "tmdate": 1762924288609, "mdate": 1762924288609, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies fixed-confidence best arm identification (BAI) with both constraints and active covariate selection in a linear setting. The goal is to return, for every covariate, the feasible arm with maximal expected objective while keeping the constraint mean below a threshold. The authors derive an instance-dependent lower bound on sample complexity via a multi-level optimization and proves asymptotic tightness by a Track-and-Stop style algorithm. The paper then introduces a surrogate objective and proves an upper bound with a constant relaxation gap. To overcome the high computational complexity in original algorithm, a duality-based decomposition algorithm that is computationally efficient is proposed and proven to be $\\delta$-PAC and achieves the relaxed complexity with supportive synthetic experiments and an application example."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Novel setting: The constrained, covariate-selective linear BAI captures realistic decision problems (e.g., treatment efficacy vs. side effects per patient group; inventory trade-offs) and differs materially from classical BAI and contextual bandits.\n2. The information-theoretic derivation leads to a closed-form that decomposes feasibility and optimality contributions per covariate; the multi-constraint extension is spelled out.\n3. The adaptation of Track-and-Stop to this setting (with an estimator-driven sampling ratio and generalized likelihood ratio stopping rule) matches the lower bound -> Asymptotically optimal. Proof for this adaption is sound and correct (with the right set of assumptions)\n4. On synthetic problems (2 covariates, 4 arms, one constraint), DSR shows lower sample complexity than uniform and greedy baselines (USR/GOSR/GFSR) and a modified Best Challenger (BCSR), while achieving the target PCI; an application example appears in the appendix.\n5. Algorithm novelty is clear and justified: The dual formulation (Theorem 2) and the resulting DSR updates are neat; the per-iteration complexity advantages over a direct Track-and-Stop implementation are explained."}, "weaknesses": {"value": "1. Tightness of the relaxed bound in practice. While Lemma 1 and the appendix give a constant-factor relaxation $U^{\\ast}\\le CH^{\\ast}$, the paper does not quantify the _empirical_ gap between $U^{\\ast}$ and $H^{\\ast}$ (e.g., as a function of geometry, noise, or constraints). Since DSR targets $U^{\\ast}$, understanding when $U^{\\ast}\\approx H^{\\ast}$ is critical to interpreting the practical optimality of DSR. A plot of $U^{\\ast}/H^{\\ast}$ over instances would strengthen the story.\n2. The main text evaluates only a small synthetic instance (K=4 arms, M=2 covariates, one constraint), with heavier experiments relegated to the appendix and limited discussion of ablations (e.g., scaling in K, M, D; multiple constraints; noise levels).\n3. The results hinge on linearity and Gaussian noise; Assumption 1 excludes ties and arms on the constraint boundary. While common in theory, it would help to show robustness to mild misspecification (e.g., sub-Gaussian noises)."}, "questions": {"value": "1. In large arm–covariate spaces, how do you construct the fixed set (Z) of size (D)? Any principled scheme (e.g., D-optimal design) or adaptive refinement? How sensitive is DSR to suboptimal choices of (Z)?\n2. Do the proofs or algorithms extend to sub-Gaussian noise, and do your empirical conclusions persist when the linear model is slightly misspecified?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "nvJJyKG86l", "forum": "Lmqs7qBpzk", "replyto": "Lmqs7qBpzk", "signatures": ["ICLR.cc/2026/Conference/Submission13754/Reviewer_pghX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13754/Reviewer_pghX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13754/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761432272818, "cdate": 1761432272818, "tmdate": 1762924288212, "mdate": 1762924288212, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the constrained linear best arm identification (BAI) problem under the fixed-confidence setting. It proves an instance-dependent sample-complexity lower bound and argues that a Track-and-Stop–based algorithm achieves asymptotically optimal performance. The authors introduce a surrogate optimization problem for the lower bound, propose an algorithm that solves this surrogate, and provide performance guarantees. Experiments are used to demonstrate the method's effectiveness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Presents an effective approach to the constrained linear BAI problem.\n- Shows strong empirical performance on both synthetic and real datasets.\n- Most of the proof was sound (though I don't see that much novelty) for me."}, "weaknesses": {"value": "The design points are assumed to be fixed and finite, which can be a limitation for practical applications.\n\nThe main weakness, in my view, is that the significance of the duality-based decomposition algorithm (the paper's primary contribution) may not be clearly established. In particular, its advantage over the Track-and-Stop–based approach may not be clear.\n- In Appendix A.4, the authors states that the optimal sampling ratio set $\\mathcal{M}^*$ is convex. Is there a proof for this statement? \n- Is there evidence that $\\Gamma$ is non-convex? If $\\Gamma$ were convex, using standard convex optimization, one could then execute a Track-and-Stop procedure in polynomial time. \n- (If above is the case) how much computational savings does the proposed method actually deliver? Since the proposed duality-based method also relies on convex optimization, the paper should report the trade-off between statistical performance and computational cost.\n- Lemma 1 states an upper bound on $\\mathcal{H}^* $ by $\\mathcal{U}^*$, but the tightness of this bound is not clarified. \n\nThe paper mentions that it proves $ \\mathcal{U}^* \\le C \\mathcal{H}^*$ for some constant $C > 0$ (around line329); however, the proof in Appendix A.6 appears to be for a surrogate $\\tilde{U}$, and the relationship between $\\tilde{U}$ and $U$ is not clearly specified, making the claim a bit imprecise."}, "questions": {"value": "1) Appendix A.4 says the optimal sampling ratio can be non-unique. Could you provide a concrete example and intuition for when non-uniqueness arises?\n\nSee also Weaknesses. I’m happy to update my score based on the rebuttal/clarifications."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DxbS4yXNJM", "forum": "Lmqs7qBpzk", "replyto": "Lmqs7qBpzk", "signatures": ["ICLR.cc/2026/Conference/Submission13754/Reviewer_3yJn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13754/Reviewer_3yJn"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13754/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761660468122, "cdate": 1761660468122, "tmdate": 1762924287828, "mdate": 1762924287828, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies a $\\delta$-PAC, constrained best arm identification (BAI) algorithm that identifies the best arm across multiple covariates simultaneously. The authors formulate a problem-specific lower bound and devise a track-and-stop algorithm that tracks this lower bound. However, since the bound is computationally intractable, they introduce a convex dual and a corresponding decomposition algorithm, which substantially improves computational efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "If the claim that this problem has not been studied before is correct, computing a problem-specific lower bound itself constitutes a nontrivial contribution. Consequently, the naturally arising track-and-stop algorithm is an excellent algorithm that, from the perspective of existing BAI methods, is asymptotically optimal. Furthermore, in this line of work, many track-and-stop methods submit even when the optimal ratio is intractable, citing only theoretical value. This paper goes further by considering the dual form and achieving substantial numerical improvements in computational capability."}, "weaknesses": {"value": "Weaknesses:\n\n1) About the problem setting itself: In the main text, covariates become, effectively, another action that a learning agent can control. Although one cannot freely select $x_i$, if one can choose among a list of pairs $(x_i, c_j)$, then the somewhat lengthy and complex $\\phi(x_i, c_j)$ could simply be used as a vector in the form $a_h$ (the authors abbreviate this as $z_h$). From this perspective, even with Assumption 2, the problem seems to collapse into a relatively ordinary linear BAI with linear constraints. While the fact that the constraint changes per $z_h$ (more precisely per covariate $c_j$) is annoying, it is not difficult to imagine that the results would be derived as incremental changes on the linear BAI foundation.\n\n1-1) (Minor) In that light, I would appreciate if the authors could modify the phrase before Eq. (1) that starts with “given a covariate $c_j$ ...”. As a reader, this phrasing leads me to intuit covariates observed passively and drawn randomly, as mentioned in the related works under covariate selection, which caused some confusion when reading the latter parts.\n\n1-2) In fact, up to Section 3.2 there is not much that I find surprising. The work increasingly feels multi-objective with constraints appearing and disappearing, a linear BAI flavored pattern that is hard to shake off."}, "questions": {"value": "0) About sample complexity: is there any aspect worth mentioning as a technical novelty? Are there analytical difficulties arising from partitioning the sets into $D_1, D_2, D_3$?\n\n1) If there is an interesting part, it is the dual section. As a reviewer, I currently view this paper through the lens of linear BAI, and I am curious about the scalability of this result.\n\n1-1) In canonical settings, an efficient ratio-computation method is known. But is the dual form and the associated efficient computation feasible in a covariate-passive, linear BAI environment? Does the constraint help or hinder computing the optimal ratio more efficiently than baseline methods?\n\n1-2) Is this method reducible to existing approaches? For example, can it be applied to linear BAI with a single covariate (i.e., standard linear BAI) to compute the ratio efficiently?\n\n2) Do the constraint and reward variance $\\sigma_{ij}$ need to be equal always (e.g., Assumption 3, Eq. (8))? Are there properties that can be derived using this specific property? Also, must the distributions be Gaussian? If there are any Gaussian-specific lemmas leveraged, please mention them.\n\nIf possible during the discussion period, I will try to understand the value of the dual form more deeply; as of now, my score is slightly above the threshold."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1Z9QSsWwXo", "forum": "Lmqs7qBpzk", "replyto": "Lmqs7qBpzk", "signatures": ["ICLR.cc/2026/Conference/Submission13754/Reviewer_6UNn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13754/Reviewer_6UNn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13754/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761983658231, "cdate": 1761983658231, "tmdate": 1762924287459, "mdate": 1762924287459, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}