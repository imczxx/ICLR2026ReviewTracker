{"id": "FWEGmkHTJX", "number": 18407, "cdate": 1758287375389, "mdate": 1759897105288, "content": {"title": "Learning frequency domain codes for semantic vision", "abstract": "Visually semantic concepts such as objects and categories provide a natural foundation for structured reasoning, yet models like convolutional neural networks (CNNs) and transformers routinely extract and aggregate features using homogeneous stacks of spatial layers. These entangle feature extraction and reasoning, rendering decision-making processes opaque and difficult to interpret. Psychovisual processing provides a way to mimic how the brain encodes and interprets visual information that produces higher abstractions from low-level processing. In this paper, we propose Semantic Visual Coding (SVC), a learnt frequency domain representation that introduces explicit psychovisual abstraction into CNNs. Inspired by psychovisual codes from the 1990s, SVC learns band-limited filters that encode task-relevant semantics as distinct regions of the Discrete Fourier Transform (DFT). These converge towards sparse (data-driven) coronal patterns, suggesting a natural representation scheme for high-level features. We also introduce PsychoNet, a framework that adapts CNNs to make them psychovisually aware by combining traditional low-level feature extraction with frequency domain abstraction and reasoning via SVC. Salience analyses show that PsychoNet’s spatial layers extract highly interpretable object parts and morphological features, unlike blob-like regions produced by standard CNNs. Through tracing gradient flow, we find SVC likely leverages these parts to form abstract representations of semantic features of image categories, highlighting frequency domain abstraction as a compelling direction for interpretable model reasoning and semantic-based decision making.", "tldr": "We design a frequency-domain representation module for high-level semantic abstraction, enabling psychovisual processing in vision models.", "keywords": ["psychovisual", "visual codes", "frequency domain", "Fourier transform", "representation learning", "deep learning", "vision", "human vision"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0f27c5056d5cef52f0c350a0b4c81c158cd9714d.pdf", "supplementary_material": "/attachment/23d793d367d2efeedca93ee99bc1062fa4a20284.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces Semantic Visual Coding (SVC), a learned frequency domain representation for encoding high-level visual features in convolutional neural networks. The authors develop PsychoNet, an architectural framework that adapts ResNet and ConvNeXt models to operate in both spatial and frequency domains, inspired by psychovisual processing concepts from Saadane et al. (1998). PsychoNet employs spatial layers for low-level feature extraction and frequency domain processing via SVC for high-level abstraction and reasoning. The framework is evaluated on CIFAR-10, CIFAR-100, ImageNet-100, and ImageNet-1K classification tasks, where it achieves comparable or slightly improved performance relative to baseline ResNet models, though it underperforms slightly against ConvNeXt-S on ImageNet benchmarks. Analysis of learned representations reveals that SVC converges to sparse, data-driven frequency patterns, while spatial layers extract interpretable object parts."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**Novel architectural contributions:** The paper introduces a dual-domain processing framework that separates low-level image features extraction from high-level frequency domain abstraction through what they name the PsychoNet architecture.\n\n**Comprehensive background and contextualization:** The introduction provides thorough coverage of related work, effectively positioning the contributions within the existing literature.\n\n**Detailed architectural exposition:** Substantial space is dedicated to explaining the components of PsychoNet.\n\n**Reproducibility commitment:** The authors commit to releasing code including training scripts, model weights, and instructions."}, "weaknesses": {"value": "**Unclear practical motivation and overstated contributions:** The domain or application that would benefit from this work remains unclear throughout the paper. The introduction overstates contributions by claiming:\n- PsychoNet \"maintains or improves the performance of common and state-of-the-art CNNs\" (line 86), when performance improvements are limited to ResNet baselines and the model performs on par with ConvNeXt-S.\n- \"SVC performs abstraction and reasoning in the frequency domain\" (line 88) contradicting the limitations section acknowledgment that \"it is not clear how these representations are used for reasoning, which remains an important direction for future work\" (line 430).\n\n**Weak foundational work:** Saadane et al. (1998), the foundational psychovisual work upon which this paper builds, has only 8 citations, with 5 from the same authors. This raises questions about the influence and validation of the underlying psychovisual framework.\n\n**Limited comparison with related work:** Lin et al. (2023), identified as \"the closest work to ours\" (line 138), applies Deep Frequency Filtering (DFF) to achieve state-of-the-art results on multiple domain generalization tasks including closed-set classification and open-set retrieval. In contrast, this paper only demonstrates improvements over the obsolete ResNet architecture on a single task (classification), making its contributions appear more limited in scope and impact.\n\n**Imbalanced architectural focus:** Phasor Blocks are introduced to replace a subset of RestNet's spatial layers to break the symmetry of the Fourier Transform (FT). Specifically, Phasor Blocks augment real-valued spatial features with complementary complex-valued ones. They receive disproportionate attention in the main text. Meanwhile, DWConv Blocks used for ConvNeXt adaptation are entirely absent from the main paper discussion. The emphasis on ResNet, rather than modern networks like ConvNeXt, further limits the work's relevance.\n\n**Incomplete resolution of stated objectives:** The limitations section explicitly states: \"The key limitation of our work is that though we show SVC organises and encodes selections of object components, it is not clear how these representations are used for reasoning\". Since understanding how frequency domain representations enable reasoning was presented as a primary motivation (lines 88, 92), the core contributions remain ambiguous.\n\n**Minor:**\n- Emphasis is put on the number of layers in PsychoNet models being lower than their respective baselines, yet parameter counts remain similar.\n- Line 451's claim that \"This pipeline mimics intermediate abstractions used by the brain to separate feature extraction from higher cognition\" requires neuroscience citations to support the biological plausibility."}, "questions": {"value": "See weaknesses section above. Also:\n\n- ResNet270 shows worse performance than ResNet152 on the same datasets, which is unexpected. Do you have a possible explanation?\n- Figure 7 lacks interpretation of why imaginary features activate on whole objects rather than object parts like real features."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6Gcv7L4CJe", "forum": "FWEGmkHTJX", "replyto": "FWEGmkHTJX", "signatures": ["ICLR.cc/2026/Conference/Submission18407/Reviewer_oc5W"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18407/Reviewer_oc5W"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18407/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761556673204, "cdate": 1761556673204, "tmdate": 1762928111631, "mdate": 1762928111631, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new biologically-inspired algorithm for augmenting existing CNN-based vision models — PsychoNet. Briefly, this method enables models to translate low-level spatial information into high-level semantic information in the frequency domains using a suite of tools primarily based on 2-dimensional FFT. One key promise of this approach is the ability to represent semantic information in a more global, biologically-rooted way, in the frequency domain.\nIn general, I quite enjoyed this paper and felt like it was quite ‘dense’ in many respects. While the authors do a good job of laying out the core ideas, I think the ICLR audience would benefit from more scaffolding particularly on the human vision topics. Another consequence of the density of information is that several key ideas and details are bundled in the supplemental information section rather than the main text. \nOverall, I think with some more scaffolded exploration of the background literature with some additional analyses I suggest below. This has the potential to be a strong contribution to ICLR."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* A clear novel architecture deeply grounded in studies on biological vision\n* Clear technical explanations of the modeling choices, consequences of ablations, and also some cost-benefit tradeoffs w.r.t. compute in the supplementary materials.\n* I appreciate the focus on building better models that aren't primarily based on scaling datasets and using standard transformer-based models.\n* Potentially useful for downstream applications in the realm of human/primate vision."}, "weaknesses": {"value": "* While I generally find the saliency map-based findings compelling in showing that PsychoNets acquire semantic information more efficiently and earlier relative to CNNs, I found the lack of non-accuracy based empirical comparisons lacking.  For example, if a key claim is that PsychoNet is more aligned with human vision, we should expect it to be more aligned with humans on key failure cases for CNNs including shape bias judgements, and the actual frequency code representations should also be predictive of human neural responses (say on open fMRI datasets like THINGS, etc.) I think some experiments clearly laying out the contributions of this modeling approach beyond visualizations and accuracy is needed for this to be a valuable contribution for the field.\nOne could imagine reporting the effects of the ablations currently presented (Fig 6) on these related benchmarks.\n* There needs to be more background on psychovisual codes, not just on metrics used to capture these codes, especially given the audience. I think unpacking some of the ideas from Saadane et al., 1998 might be sufficient.\n* Figure 5 a should be presented in a larger resolution with clearer font\n* While from visual inspection it does appear that models do learn to recognize semantic parts, again having grounded metrics, with respect to annotations might be valuable."}, "questions": {"value": "N/A. Refer to earlier sections!"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "WY2IMJc06h", "forum": "FWEGmkHTJX", "replyto": "FWEGmkHTJX", "signatures": ["ICLR.cc/2026/Conference/Submission18407/Reviewer_vJ9D"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18407/Reviewer_vJ9D"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18407/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761784678053, "cdate": 1761784678053, "tmdate": 1762928111212, "mdate": 1762928111212, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work introduces Semantic Visual Coding (SVC), a learn frequency domain representation that introduces explicit psychovisual abstraction into CNNs The introduction of SVC is motivated from the perspective of producing disentangled representations to provide a more natural foundation for structured reasoning. SVC works by learning band-limited filters that encode semantics as distinct regions of the Discrete Fourier Transform. SVC is incrporated into some well-known CNN architectures and compared to its standard counter part. Activation maps and filter are visualized."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Nice illustration that visualize the methodology and results\n2. Interesting link to biologically inspired vision."}, "weaknesses": {"value": "1. The contribution of the work is unclear. There seems to exist a great deal of works that focus on transforming latent representations into the frequency domain [1, 2, 3, 4]. Some of these works are mentioned, other are not. However, the difference between SVC and existing works is not properly explained, and it is unclear what the methodological contributions are.\n\n2. The experiments are poorly motivated and not properly evaluated. \n\n(a) It is unclear what the purpose of the image classification experiments in Table 1 is. I interpret this sentence \"Since we hypothesise that SVC should handle high-level processing, we stop increasing Phasor Blocks depth after Psycho-B/ResNet-101 to see if it can replace the role of late spatial layers (the width of existing layers are increased to compensate for parameter size.)\" as the motivation for the reduction in layers. But the the motivation for the chosen baseline networks is unclear. The ResNet152 and 270 are rarely used, the ResNet18 and and resNet50 are much more common. The poor performance of ResNet152 and 270 on CIFAR10 is most likely due to low amount of samples compared to parameters. For the ConvNext-S, the performance difference is unclear.\n\n(b) The activation maps and filter visualization are nice, but the analysis is highly qualitative. Without any baselines to compare against or quantitative measures, it is unclear what these results are actually demonstrating.\n\n3. Comparison to existing works is missing. Without any comparison to other works, it it is difficult to asses the usefulness of SVC. There seems to be many alternatives that could be used or adapted for comparison [1, 2, 3, 4]. \n\n- [1] Lin et al., Deep Frequency Filtering for Domain Generalization, CVPR 2023\n- [2] Chi et al., Fast Fourier Convolution, NeurIPS 2020\n- [3] Rao et al., Global Filter Networks for Image Classification, Neurips 2021\n- [4] Huang et al., Adaptive Frequency Filters As Efficient Global Token Mixers, ICCV 2023"}, "questions": {"value": "1. Concretely, in what ways does SVC differ from existing works in the literature like [1, 2, 3, 4]?\n2. What benefits does SVC bring compared to existing works?\n3. What quantitative measure can illustrate these benefits?\n4. Can these benefits be shown experimentally?\n\n- [1] Lin et al., Deep Frequency Filtering for Domain Generalization, CVPR 2023\n- [2] Chi et al., Fast Fourier Convolution, NeurIPS 2020\n- [3] Rao et al., Global Filter Networks for Image Classification, Neurips 2021\n- [4] Huang et al., Adaptive Frequency Filters As Efficient Global Token Mixers, ICCV 2023"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3gQtiArDwm", "forum": "FWEGmkHTJX", "replyto": "FWEGmkHTJX", "signatures": ["ICLR.cc/2026/Conference/Submission18407/Reviewer_1AWe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18407/Reviewer_1AWe"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18407/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761852733601, "cdate": 1761852733601, "tmdate": 1762928110832, "mdate": 1762928110832, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a two-stage hybrid architecture for computer vision that separates low-level feature extraction from high-level abstract reasoning. The first stage employs spatial layers to identify semantically meaningful object parts, augmenting real-valued features with complex-valued counterparts. The second stage transforms these features into the frequency domain using a Fast Fourier Transform, where a dedicated module performs the final classification using learned, sparse, band-limited filters. This architectural approach differs from some prior works that use the frequency domain to improve the efficiency of spatial convolutions or as an integrated global mixer. Here, the frequency domain is used as a distinct final stage to replace the deep spatial layers typically responsible for high-level reasoning. The entire framework is end-to-end differentiable, as all its components, including the Fourier transform and complex-valued convolutions, have well-defined gradients that allow for standard backpropagation-based training. According to the results, the model demonstrates improved interpretability and a reduced dependency on layer depth, though these benefits are accompanied by marginal performance gains over established baselines and a significantly higher computational cost. The work's contribution is therefore positioned as an exploration of an alternative, more transparent model design that bridges spatial feature extraction with frequency-domain abstraction."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The strengths of this work are centered on its architectural design, which aims to improve model interpretability, and the systematic experiments conducted to support its claims. The paper provides qualitative evidence through activation map visualizations suggesting that the framework successfully separates processing stages: early spatial layers learn to identify distinct, semantically meaningful object parts, while the subsequent frequency-domain module performs abstraction and reasoning on these parts. This separation is presented as a more transparent alternative to the entangled computations in deep, homogeneous CNNs.\n\nI think:\n1. The framework is explicitly designed to create a more interpretable processing pipeline by separating low-level feature extraction in the spatial domain from high-level reasoning in the frequency domain.\n\n2. The results indicate that the proposed models can achieve comparable or slightly improved performance with significantly fewer layers than their deep ResNet baselines, suggesting that the frequency-domain module effectively handles the high-level processing that would otherwise require additional spatial layers.\n\n3. The paper introduces the Phasor Block, a component whose design can be considered a notable contribution. Instead of adopting a computationally expensive, fully complex-valued network, the Phasor Block serves as a lightweight module that uses standard real-valued operations to generate complementary imaginary features just before they are needed for the Fourier transform. This represents a practical engineering solution to enable more expressive frequency-domain filtering without the full overhead of a complex-valued architecture.\n4. The architecture is somewhat grounded in principles of psychovisual processing, providing a clear theoretical motivation for its design choices, particularly the use of coronal frequency bands for semantic abstraction.\n5. The authors conduct extensive ablation studies to isolate and validate the contributions of their proposed components, such as the Phasor Blocks and Spectral Branches, adding rigor to their architectural claims.\n\nI think the interpretability is pretty cool, albeit only justified qualitatively."}, "weaknesses": {"value": "Despite its strengths in interpretability and design, the work has several weaknesses, primarily related to practical applicability and architectural complexity. The most significant drawback is the trade-off between computational cost and performance. The proposed models incur a substantial increase in computational overhead (FLOPs) compared to their baseline counterparts, yet the resulting improvements in classification accuracy are marginal at best, and in some cases, performance slightly degrades. This unfavorable trade-off makes the framework less compelling for applications where efficiency and predictive power are the primary concerns.\n\n1. The models require significantly more FLOPs than the baselines they are compared against. The authors attribute this to the need for higher-resolution feature maps to support the frequency analysis and the use of complex-valued operations that are not highly optimized in current deep learning libraries, which poses a serious barrier to practical deployment.\n2. The reported improvements in top-1 accuracy on benchmark datasets like ImageNet are minimal, often less than half a percentage point. Given the large increase in computational requirements, these small gains do not present a strong case for adopting the architecture based on performance alone.\n3. Unlike modern architectures such as ResNet and Vision Transformers, which benefit from the simplicity and scalability of stacking homogenous blocks, the proposed framework is a heterogeneous, multi-stage pipeline. This design introduces significant architectural complexity by combining standard convolutional layers, specialized Phasor Blocks, a non-parametric FFT step, and frequency-domain filtering modules. This complexity makes the model less straightforward to scale and modify compared to simply adding more identical blocks.\n4. The core concepts leveraged in the paper, such as frequency-domain analysis, complex-valued networks, and biologically-inspired architectures, are all pre-existing areas of research. The contribution can therefore be viewed as a specific and thoughtful synthesis of these ideas rather than the introduction of a fundamentally new technique, which may limit its perceived impact in a crowded field.\n5. The framework is exclusively evaluated on image classification tasks. Its effectiveness on other critical computer vision tasks that require dense spatial predictions, such as object detection or semantic segmentation, remains unevaluated. It is unclear how the proposed abstraction in the frequency domain would perform on tasks where preserving precise spatial information is paramount.\n\nOverall, my concerns can be broadly divided into two classes -- first being the improvement relative to FLOP, the second being novelty. Hopefully the authors can provide a more extensive justification."}, "questions": {"value": "1. You propose the Phasor Blocks for introducing complex-valued features from real-valued inputs. However, their specific internal architecture is not fully justified.\n\n-- What was the design process for the Phasor Blocks? Did you experiment with alternative, perhaps simpler, methods for generating imaginary components, such as a basic 1x1 convolution to project features into a complex space?\n\n-- Why was the specific combination of depthwise and pointwise convolutions chosen? The paper states it's to encourage cross-channel interactions without interfering with spatial relationships, but it would be helpful to see an ablation study comparing this design to other methods.\n\n2. The framework replaces the later stages of a CNN with the frequency-domain pipeline. This choice seems critical to the entire hypothesis but is based on empirical results. Is there a more principled way to determine the optimal depth for this transition, or is it purely a hyperparameter to be tuned for each base architecture?\n\n3. The SVC module partitions the frequency spectrum into three fixed, disjoint radial bands. This seems to contradict the goal of a fully data-driven representation. Would a learnable partitioning scheme, where the model could adapt the frequency band boundaries, lead to better performance or even more specialized filters?\n\n4. The paper repeatedly claims that the SVC module performs \"high-level processing and reasoning.\" However, the evidence shows that it learns to encode selections of object parts. What reasoning is there?\n\n5. The evaluation is confined to image classification on ResNet and ConvNeXt backbones. How do you expect this architecture to perform on dense prediction tasks like semantic segmentation or object detection, where precise, high-resolution spatial information is crucial for the final output? The frequency-domain abstraction inherently discards some spatial localization."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SzpYEN1PSu", "forum": "FWEGmkHTJX", "replyto": "FWEGmkHTJX", "signatures": ["ICLR.cc/2026/Conference/Submission18407/Reviewer_XNzN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18407/Reviewer_XNzN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18407/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761985350024, "cdate": 1761985350024, "tmdate": 1762928109555, "mdate": 1762928109555, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}