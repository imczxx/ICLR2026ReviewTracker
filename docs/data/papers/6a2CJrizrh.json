{"id": "6a2CJrizrh", "number": 15, "cdate": 1756728099165, "mdate": 1759898278624, "content": {"title": "BALROG: Contextual Bandits meets Active Learning for Online Generative Model Selection", "abstract": "The rapid proliferation of open-platform text-to-image generative models has made prompt-wise model selection essential for producing high-quality and semantically accurate images, yet it remains a challenging problem. Existing approaches, including contextual bandit algorithms, often converge slowly and fail to exploit the semantic relationships across prompts. We introduce BALROG, a non-parametric, neighbor-based bandit framework that directly addresses these issues by transferring information across similar prompts to speed up convergence and improve generalization. By leveraging similarities between prompts, BALROG achieves faster learning and comes with strong theoretical guarantees through a sub-linear regret bound. In addition, we incorporate an active learning strategy that selectively queries ground-truth model rankings on ambiguous prompts, where ambiguity is quantified by the gap between the estimated rewards of the top two candidate models. This simple yet effective uncertainty measure substantially improves convergence and robustness. Extensive experiments on four datasets with six image generative models show that BALROG reduces regret by up to 60% compared to state-of-the-art baselines, enabling more accurate prompt-wise model selection in practice.", "tldr": "We propose a new method for online generative model selection based on Nearest Neighbors bandits and active learning.", "keywords": ["Generative models", "Online model selection", "Contextual bandits"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/54c87e6d7725a7415b0cb0d69f045032dce69826.pdf", "supplementary_material": "/attachment/98f2aa81b8d04ee560ab457d2b6b09b7fd7dc1b0.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes BALROG, a non-parametric, neighbor-based contextual bandit framework for online generative model selection. The key idea is to exploit similarities between prompts so that information can be transferred across semantically related queries, speeding up convergence. The method integrates a lightweight active-learning component that queries human feedback when model rankings are uncertain. Experiments across several text-to-image datasets and six generative models report up to 60 % regret reduction over existing bandit baselines, supported by a sub-linear theoretical regret bound."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.Addresses a practically relevant and under-explored problem: online model selection for generative models.\n\n2.The non-parametric neighbor transfer idea adds useful inductive bias without requiring deep model retraining.\n\n3.Incorporates an interpretable active-learning strategy to reduce annotation cost.\n\n4.Provides both theoretical analysis (regret bound) and empirical validation across several datasets."}, "weaknesses": {"value": "1.Motivation and methodological clarity.\nThe motivation for adopting a non-parametric, neighbor-based framework is not sufficiently articulated. While the idea of transferring information across similar prompts is intuitive, the paper would benefit from clearer justification or empirical evidence demonstrating when this approach substantially outperforms parametric alternatives. Concrete examples or ablation results could help clarify the design rationale.\n\n2.Limited evaluation scope.\nThe experimental evaluation is conducted on a relatively small number of datasets and prompt sets, which may not capture the true diversity of user intents or prompt semantics in open-domain scenarios. This restricts the generalizability of the claims regarding real-world model selection.\n\n3.Insufficient experimental rigor.\nIt is unclear whether all baselines were tuned equivalently. The paper also lacks ablation studies on key design choices such as the number of neighbors and the reward-gap threshold, making it difficult to assess the robustness and sensitivity of the proposed framework.\n\n4.Evaluation methodology and interpretability.\nFigure 1 appears to suggest that CLIPScore differences alone can effectively rank models, raising doubts about the incremental benefit of BALROG beyond such baselines. Moreover, since both OtB and OPR rely on CLIPScore, these metrics may not fully capture user-perceived or aesthetic quality. Including qualitative visualizations or limited human evaluations would help substantiate the practical value of the method."}, "questions": {"value": "Could BALROG be applied to multimodal tasks (e.g., text-to-audio)?\nWhat is the computational complexity of maintaining neighbor graphs online?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "aSyR73kBGM", "forum": "6a2CJrizrh", "replyto": "6a2CJrizrh", "signatures": ["ICLR.cc/2026/Conference/Submission15/Reviewer_D92a"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15/Reviewer_D92a"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761468133509, "cdate": 1761468133509, "tmdate": 1762915437130, "mdate": 1762915437130, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces BALROG, a contextual bandit algorithm with an integrated active learning mechanism for online selection among text-to-image generative models.\nThe method extends prior bandit approaches (e.g., PAK-UCB) by replacing parametric reward estimation with a non-parametric k-nearest-neighbor scheme and by adding an active querying rule that requests full feedback when the top-two model estimates are close.\n\nThe paper provides a theoretical poly-logarithmic regret bound under smoothness and margin assumptions, and presents experiments on four prompt datasets and six diffusion models.\nEmpirically, BALROG shows improved CLIPScore-based performance over existing bandit baselines.\n\nWhile the problem setting is interesting, the overall contribution is incremental—the algorithm mainly adapts existing kNN-UCB and active-learning ideas to the generative model selection context, and the practical impact and scalability of the approach remain unclear."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "This paper introduces BALROG, a contextual bandit algorithm with an integrated active learning mechanism for online selection among text-to-image generative models.\nThe method extends prior bandit approaches (e.g., PAK-UCB) by replacing parametric reward estimation with a non-parametric k-nearest-neighbor scheme and by adding an active querying rule that requests full feedback when the top-two model estimates are close.\n\nThe paper provides a theoretical poly-logarithmic regret bound under smoothness and margin assumptions, and presents experiments on four prompt datasets and six diffusion models.\nEmpirically, BALROG shows improved CLIPScore-based performance over existing bandit baselines."}, "weaknesses": {"value": "The main limitation of this work lies in its lack of conceptual novelty and unclear practical significance.\nThe proposed BALROG framework essentially combines two well-known ideas—non-parametric contextual bandits (e.g., kNN-UCB, Reeve et al., 2018) and active learning based on uncertainty sampling (Settles, 2009)—and applies them to the relatively superficial task of selecting among a small set of pretrained text-to-image models.\nThis setup makes the contribution appear mostly an adaptation rather than a new algorithmic insight.\n\nFrom an application standpoint, the problem definition itself is questionable in utility: choosing between existing generative models for each prompt does not necessarily advance the understanding or improvement of generative modeling. In practice, such “model routing” could be implemented with a simple ensemble or ranking heuristic without the need for a bandit formulation.\nAs a result, the proposed method risks being trivial in motivation, offering little theoretical or empirical insight beyond existing contextual-bandit literature."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fM46ZnJAXf", "forum": "6a2CJrizrh", "replyto": "6a2CJrizrh", "signatures": ["ICLR.cc/2026/Conference/Submission15/Reviewer_vtNg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15/Reviewer_vtNg"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761857796587, "cdate": 1761857796587, "tmdate": 1762915436966, "mdate": 1762915436966, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces BALROG, a non-parametric, neighbor-based contextual bandit framework designed for the online model selection problem in text-to-image generative models. BALROG addresses these limitations by transferring information between similar prompts. It also utilize active learning method to enhance the algorithm performance. Also, this paper provides strong theoretical guarantees for BALROG algorithm, which including upper regret bound derivation as well as time and space complexity derivation."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- BALROG employs a non-parametric k-Nearest Neighbor approach for reward estimation. The core innovation is the incorporation of a finite-budget active learning strategy.The proposed Delta rule is a simple yet highly effective measure of uncertainty, and the utilization of active learning is quite impressive.\n- The math derivation of this paper is clear and concise. The question formulation as well as the pseudocode part were written clearly. \n- With many text-to-image models coexisting, automatically selecting the best model for each prompt is a very practical problem – the paper clearly illustrates this practical scenario and gives a solution BALROG."}, "weaknesses": {"value": "- Lack of ablation study is the biggest problem for this paper. First, the algorithm involves many hyperparameters. If these hyperparameters are fixed, whether there is a significant impact on the performance of the algorithm should be shown in the paper. Secondly, the paper mentions that active learning can \"reduce ambiguity, accelerate the convergence of neighborhood estimates, and uncover correlations between models.\" I hope there will be ablation experiments to illustrate this.\n- The experiments focus mainly on contextual bandit baselines. Missing are more LLM-based adaptive routing or meta-learning approaches that could serve as stronger recent baselines.\n- It is unclear how sensitive BALROG’s performance is to the choice of reward metric. CLIPScore mainly focus on prompt-image alignment, but it cannot measure the quality of image itself. \n- Insufficient sensitivity explanation for active query policy thresholds. Delta, UCB-threshold, variance-threshold, and other strategies all require thresholds. Although there is a section in the appendix on threshold selection (B.2), the text should report more clearly on the sensitivity analysis of thresholds.\n- Insufficient reporting of runtime/GPU costs in the experiment. Given that the method actually performs a large number of model inferences (especially in the query step), it is recommended to report the actual GPU hours or the total computing resources per experiment to facilitate the review and judgment of the method's feasibility in the real world (the recommended inference steps for each model are given in the appendix, but the overall computational cost statistics are missing).\n- Minor problem, 148-149, $\\mu$ is a redundant definition. Better remove this."}, "questions": {"value": "- How does the algorithm perform when the embedding space is noisy or high-dimensional?\n- Does the performance depend heavily on δ, or is it robust? A sensitivity analysis could clarify stability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "- How does the algorithm perform when the embedding space is noisy or high-dimensional?\n- Does the performance depend heavily on δ, or is it robust? A sensitivity analysis could clarify stability."}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vjEJXzhIRd", "forum": "6a2CJrizrh", "replyto": "6a2CJrizrh", "signatures": ["ICLR.cc/2026/Conference/Submission15/Reviewer_GLzJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15/Reviewer_GLzJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761886484207, "cdate": 1761886484207, "tmdate": 1762915436676, "mdate": 1762915436676, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes BALROG, a contextual bandit framework for online selection of text-to-image generative models. The method addresses the challenge of selecting the best generative model for each input prompt by leveraging semantic similarities between prompts and strategically querying full model feedback when uncertainty is high. BALROG achieves faster convergence and improved generalization compared to existing bandit approaches."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is clearly written and well organized. The motivation for prompt-wise selection is compelling and illustrated visually.\n2. It creatively combines non-parametric neighbor-based bandits (kNN-UCB) with budgeted active learning, using a simple but effective top-two gap trigger to allocate full-feedback queries at decision boundaries. This synthesis removes key limitations of prior contextual bandits that assume fixed parametric form or neglect cross-prompt structure.\n3. Theoretical analysis is nontrivial and well-structured, with careful assumptions and supporting lemmas. The improvement over passive non-parametric baselines is clearly articulated."}, "weaknesses": {"value": "1. Tha paper’s comparison of active learning strategies is primarily focused on different triggers within its own framework (Delta, UCB-threshold, etc.) and a single external baseline. This is insufficient to fully establish the superiority of the proposed “on-the-fence” querying approach. A critical missing strategy would be a simple, nonadaptive budget allocation strategy. For instance, distributing the query budget uniformly at random across the entire horizon could serve as a powerful sanity check. If such a simple strategy performs comparably, it might suggest that the benefit comes more from having access to full feedback itself, rather than the timing of the queries.\n2. The geometric uncertainty weight, which is set to log(t) in practice. The paper dose not provide a strong theoretical or empirical rationale for this specific choice over other non-decreasing functions (e.g., a constant, sqrt(log(t)), or t). It is unclear how robust the algorithm’s performance is to this hyperparameter.\n3. The paper exclusively uses one type of embedding and one metric. However, the quality and the geometric properties of text embeddings can vary significantly. Similarly, other distance metrics(e.g. L2 distance) could alter the neighborhood structure. It is unclear whether the strong results are specific to the CLIP embedding and CLIPScore or genuinely robust to the choice of representation and metric."}, "questions": {"value": "1. Could the authors provide a comparison against a simple yet important baseline, such as allocating the active query budget uniformly at random across the entire horizon? How does your proposed method perform against such a non-adaptive strategy?\n2. Could you provide a more detailed justification for the setting phi(t)=log(t)? How sensitive is BALROG’s performance to different phi(t)?\n3. The paper’s results are based solely on CLIP embeddings and cosine distance. Have you experimented with other text embedding models(e.g., BLIP) or alternative distance metrics?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZVwbj9nLk4", "forum": "6a2CJrizrh", "replyto": "6a2CJrizrh", "signatures": ["ICLR.cc/2026/Conference/Submission15/Reviewer_eFn4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15/Reviewer_eFn4"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761967700262, "cdate": 1761967700262, "tmdate": 1762915436527, "mdate": 1762915436527, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}