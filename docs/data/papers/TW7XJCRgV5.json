{"id": "TW7XJCRgV5", "number": 22847, "cdate": 1758336289761, "mdate": 1759896843054, "content": {"title": "Image-POSER: Reflective RL for Multi-Expert Image Generation and Editing", "abstract": "Recent advances in text-to-image generation have produced strong single-shot models, yet no individual system reliably executes the long, compositional prompts typical of creative workflows.\nWe introduce Image-POSER, a reflective reinforcement learning framework that (i) orchestrates a diverse registry of pretrained text-to-image and image-to-image experts, (ii) handles long-form prompts end-to-end through dynamic task decomposition, and (iii) supervises alignment at each step via structured feedback from a vision–language model critic. By casting image synthesis and editing as a Markov Decision Process, we learn non-trivial expert pipelines that adaptively combine strengths across models. Experiments show that Image-POSER outperforms baselines, including frontier models, across industry-standard and custom benchmarks in alignment, fidelity, and aesthetics, and is consistently preferred in human evaluations. These results highlight that reinforcement learning can endow AI systems with the capacity to autonomously decompose, reorder, and combine visual models, moving towards general-purpose visual assistants.", "tldr": "", "keywords": ["Text-image alignment", "image generation", "image editing", "reinforcement learning", "reflection", "orchestration"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ca5f7b5e85cca86c59baba993920689f9352999d.pdf", "supplementary_material": "/attachment/00441cd2957366fe9185547c24cc8d5624d8431a.zip"}, "replies": [{"content": {"summary": {"value": "This work proposes Image-POSER, an RL framework that orchestrates multiple pretrained visual experts through a reflective decision process. The system decomposes long prompts into sub-tasks and dynamically selects the most suitable generator. The method demonstrates state-of-the-art performance on complex T2I/I2I benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The method achieves strong quantitative and user-study results.\n2. It proposes an insightful analysis of expert complementarity.\n3. It proposes a formulation of sequential editing."}, "weaknesses": {"value": "1. GPT-o3 is both a rewarder and an evaluator, which may bring self-evaluation bias.\n2. It reports high latency. What is the underlying rationale for this computation, and which specific procedures are encompassed within each step?\n3. Limited evaluation metrics. What about GenEval, DPG-Bench, MM-RewardBench?\n4. The user-study sample is small (30 prompts and 14 participants). Besides, more details about the user study should be introduced.\n5. No ablation on critic or command-extraction modules.\n6. Does the system incorporate a reflection mechanism to address potential inaccuracies from API-based experts or even fundamental network errors?"}, "questions": {"value": "Please refer to Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "G79Y1AIjY5", "forum": "TW7XJCRgV5", "replyto": "TW7XJCRgV5", "signatures": ["ICLR.cc/2026/Conference/Submission22847/Reviewer_cka1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22847/Reviewer_cka1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22847/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761576036639, "cdate": 1761576036639, "tmdate": 1762942412066, "mdate": 1762942412066, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a well-motivated framework that unifies multi-expert orchestration, reflection, and reinforcement learning for image generation. By viewing the coordination of expert models as a reflective RL problem, it provides a clear conceptual advancement beyond simple ensemble or prompt-routing schemes. The proposed Image-POSER system consistently outperforms both open-source and closed commercial models on compositional and instruction-following tasks, according to CLIP/BLIP metrics, VLM-based assessments, and human preference studies."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The method trains only a lightweight DQN controller and keeps all experts fixed, requiring no retraining of large vision–language models. This modular structure makes it cost-efficient, flexible, and potentially useful as a plug-in layer for real-world multimodal systems.\n\n* The proposed Image-POSER system consistently outperforms both open-source and closed commercial models (e.g., GPT-Image-1, Gemini) on compositional and instruction-following tasks."}, "weaknesses": {"value": "* The reliance on GPT-o3 as both the critic in training and the automatic evaluator introduces potential bias and circularity. Since the same model family judges the system it helps train, it is unclear whether improvements reflect genuine quality gains or alignment with that evaluator’s preferences.\n\n* The experiments are conducted on a relatively small computational scale, using short RL episodes and a limited replay buffer on a single T4 GPU. This raises concerns about policy stability, generalization, and whether the reported gains depend on specific prompt distributions or stochastic behavior of API-based experts.\n\n* Human evaluations involve only 14 participants and focus narrowly on technical alignment and aesthetic fidelity. Broader aspects such as diversity, creativity, latency, and cost-efficiency are not deeply analyzed. Without a comprehensive user study or robustness tests, claims about real-world deployment remain tentative."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "iyg7fnMsrc", "forum": "TW7XJCRgV5", "replyto": "TW7XJCRgV5", "signatures": ["ICLR.cc/2026/Conference/Submission22847/Reviewer_X2RP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22847/Reviewer_X2RP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22847/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931720022, "cdate": 1761931720022, "tmdate": 1762942411699, "mdate": 1762942411699, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a system that casts multi-step image generation and editing as an RL problem. An agent selects among the pretrained expert models to execute sub-steps of a complex prompt. A vision-language model critic provides dense rewards and reflective feedback, guiding the system to decompose the original prompt into successive instructions. According to the authors, Image-POSER outperforms several baselines on compositional benchmarks and human evaluations."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper addresses an important challenge in text-to-image generation: following long, compositional prompts with sequential edits. Casting this as an RL task that orchestrates multiple specialized models is an interesting angle.\n\n2. The approach leverages existing high-quality models (e.g., diffusion models, editors) without retraining them. As noted by the authors, the only learnable part is a lightweight DQN with a 3-layer MLP, making the system relatively plug-and-play.\n\n3. According to the reported metrics, Image-POSER achieves higher alignment and attribute-binding scores than all compared baselines. In the user study, annotators preferred Image-POSER’s outputs over baselines in the majority of cases. These results suggest the approach has merit."}, "weaknesses": {"value": "1. Limited analysis of VLM choice. The paper lacks experiments on selecting the VLM as a judge or a critic.\n\n2. Missing efficiency analysis. The method involves multiple iterative steps, which may be less efficient than alternatives. Please provide a clear efficiency study compared with baselines under matched settings, and analyze scaling.\n\n3. The DQN’s state is just the current instruction and the remaining task list embedded as text, which means the agent has very limited information. In essence, the DQN is simply learning to pick the most generally capable expert for each kind of instruction, rather than truly reasoning.\n\n4. The custom prompts for training and evaluation were all generated or guided by large LMs. This synthetic data may not reflect real user queries. The evaluation metrics also depend on the same GPT-based critic, risking overfitting to the critic’s biases.\n\n5. The human study is quite small (14 annotators over 30 prompts) and reports only win rates; statistical significance of preferences is not discussed."}, "questions": {"value": "1. The DQN formulation seems quite simple (3-layer MLP, 12 discrete actions). Why did you choose a DQN over simpler non-learning strategies (e.g., heuristic or LLM-based planners)? Do you have ablations showing that RL actually improves performance?\n\n2. The paper treats image synthesis as a sequential MDP with reflective feedback. Could you formalize the state transition and reward function more rigorously? How do you ensure that the Markov assumption holds when the environment is partly determined by opaque pretrained models?\n\n3. You limit each episode to 6 steps and drop commands after 3 failed attempts. How were these thresholds chosen? Did you experiment with different maximum step lengths or retry counts, and what was their impact on convergence or quality?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "The paper has an ethical statement in the supplementary materials."}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "tQGq5RDxpX", "forum": "TW7XJCRgV5", "replyto": "TW7XJCRgV5", "signatures": ["ICLR.cc/2026/Conference/Submission22847/Reviewer_fcCe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22847/Reviewer_fcCe"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22847/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761937636647, "cdate": 1761937636647, "tmdate": 1762942410591, "mdate": 1762942410591, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents Image-POSER , a reflective reinforcement learning framework designed to enhance multi-expert image generation and editing by effectively managing long-form prompts through dynamic task decomposition and expert orchestration.\n\nThe presented work addresses limitations of current text-to-image models that struggle with complex prompts. In particular it deals with long, compositional prompts that consist of multiple objects, spatial relations, or sequential edits. \n\nAn exhaustive evaluation is presented, demonstrating superior performance than baselines on spatial reasoning. The framework demonstrates the advantages of reflective orchestration in achieving high-quality outputs outperforming single generators on complex compositional tasks."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The work proposes a novel formulation of image generation and editing. It proposes a different approach than traditional ones that predefine a sequence of subtasks. The novelty of this work is to formulate image generation as a sequential decision-making problem. This formulation allows for dynamic and adaptive orchestration, with the use of a reflective reinforcement learning environment. In this way, commands are incrementally created and the outputs validated.\n\nBy orchestrating multiple pretrained models, the proposed method  leverages existing strengths of specialized systems, potentially achieving higher quality and versatility than single-model approaches.\n\nThe proposed architecture outperforms baselines (both single-model and agentic) on compositional benchmarks, indicating robust performance in complex scenarios. Additionally, user studies are reported, with superior acceptance regarding the state of the art."}, "weaknesses": {"value": "There is a dependence on pretrained models. The orchestration relies on pretrained models. There is a risk of introducing inconsistencies, redundancies or conflicts. How the system deals with it?\n\nA drawback of the proposed approach is its high computational cost, as the reflective steps introduce significant latency which poses challenges for practical deployment and real-time applications."}, "questions": {"value": "The framework is described as moving toward “generalist visual agents,” but it’s unclear how well it generalizes across diverse domains, image types, or prompt complexities, beyond the tested benchmarks. It would be good to provide further discussion on this vision.\n\nThe user study is interesting. Can you provide more details on the user profiles. Are they graphical designers? Computer scientists? … Do their profile influence in the assessment they provide?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 10}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2z6vznmIVn", "forum": "TW7XJCRgV5", "replyto": "TW7XJCRgV5", "signatures": ["ICLR.cc/2026/Conference/Submission22847/Reviewer_VoMS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22847/Reviewer_VoMS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22847/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762029575573, "cdate": 1762029575573, "tmdate": 1762942409819, "mdate": 1762942409819, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}