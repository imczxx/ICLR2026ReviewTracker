{"id": "EQLcuMSy8b", "number": 4016, "cdate": 1757584577294, "mdate": 1759898057842, "content": {"title": "ROPA : Robust parallel diffusion sampling", "abstract": "Recent years have witnessed significant progress in developing effective diffusion models. Parallel sampling is a promising recent approach that reformulates the sequential denoising process as solving a system of nonlinear equations, and it can be combined with other acceleration techniques. However, current progress is limited by the trade-off between high fidelity and computational efficiency.\nThis paper addresses the challenge of scaling to high-dimensional, multi-modal generation. Specifically, we present ROPA (Robust Parallel Diffusion Sampling), which takes into account the properties of the denoising process and solves the linear system using adaptive local sparsity to achieve stable parallel sampling.\nExtensive experiments demonstrate ROPA’s effectiveness: it significantly accelerates sampling across diverse image and video diffusion models, achieving up to $2.9\\times$ speedup with eight core, an improvement of 52\\% over baselines without sacrificing sample quality. ROPA enables parallel sampling methods to provide a solid foundation for real-time, high-fidelity diffusion generation.", "tldr": "", "keywords": ["Generative models", "Parallel diffusion sampling"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a58248a5f854b2c26bd4bf0b3d8547bd599c2c5c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes the ROPA framework, which improves the stability and efficiency of parallel diffusion sampling through geometry-aware adaptive Jacobian sparsity control. The authors analyze instability from a data manifold perspective and introduce adaptive damping and sparsity control to balance numerical stability and computational cost. Experiments on image and video generation tasks show around 2.9× speedup without quality loss."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "（1）The paper establishes a relatively systematic geometric–numerical stability analysis framework, which is theoretically solid and insightful.\n\n（2）The experiments cover a wide range of models including image and video diffusion models, giving the results good practical credibility."}, "weaknesses": {"value": "(1) The key idea of adaptive Jacobian sparsity is conceptually close to previous works such as ParaSolver  and ParaTAA . The novelty seems incremental, focusing on dynamic sparsity adjustment rather than a fundamentally new mathematical mechanism.\n\n(2) The dense mathematical presentation and logical jumps, such as in Corollary 2.5, make it difficult to follow how the theoretical curvature concepts directly translate into practical bandwidth control thresholds.\n\n(3) It is unclear how the curvature-based damping term λ_damp is selected in practice."}, "questions": {"value": "(1) Could the authors explain more concretely how λ_damp is determined during sampling?\n\n(2) How sensitive is the performance to the choice of curvature thresholds?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5N0gOD3BGc", "forum": "EQLcuMSy8b", "replyto": "EQLcuMSy8b", "signatures": ["ICLR.cc/2026/Conference/Submission4016/Reviewer_RszZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4016/Reviewer_RszZ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4016/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761789452008, "cdate": 1761789452008, "tmdate": 1762917137312, "mdate": 1762917137312, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ROPA (Robust Parallel Diffusion Sampling). The authors claim that they take into account the properties of the denoising process and solves the linear system by using geometry aware adaptive Jacobian Sparsity Control that is generated from\ngeometric curvature signals. They claim that this allows them to achieve stable parallel sampling. Their experiments\ndemonstrate ROPA accelerates sampling by achieving up to 2.9× speedup with eight core.\nquality"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The authors claim that they take into account the properties of the denoising process and solves the linear system by using geometry aware adaptive Jacobian Sparsity Control that is generated from geometric curvature signals."}, "weaknesses": {"value": "While I recognize the effort the authors has put towards this manuscript, I believe the paper is not yet ready for publication in its current format. Although the author stated they started from the stochastic differential equation for the diffusion model, I feel like they actually solved a system of differential equations. Further they used the Numerical Analysis theory to regularize the solutions. However, the assumption that $r_{\\theta}$ is twice continuously differentiable sounds too strong in my view.\n\nThe introduction of the concept of a manifold feels abrupt and lacks sufficient explanation. Additionally, the notion of curvature used in the paper appears to pertain to shape of the probability density function. More importantly, I am concerned that there might be some fundamental issues that need to be addressed. Furthermore, there are some errors throughout the manuscript that should be carefully reviewed and corrected."}, "questions": {"value": "1.P2, eqn(5), inside $ (,,,x_{t+i})$ or $ (,,,x_{t-i})$? In line 071, it says $ (,,,x_{t-i})$.\n2. This paper based upon the curvature, characterized by the Hessian $H(x)$, defined in term of $p(x)$. However, what is the intuition/motivation behind this?   \n3. The paper contains descripts that lack clear explanation, for example, P2, line 106, the authors stated that:  \"data curvature magnifies score function stiffness, which discretization gaps dynamically amplify, ultimately causing severe Jacobian ill-conditioning that violates diagonal dominance. This creates divergence from the data manifold into low-density regions.\" This seems like some conclusion without support.  Especially what does the sentence \"data manifold curvature magnifies score function stiffness,\" mean? \n4. It seems like there is an indexing error in Eqn. (6) in P2, and thus in the definition of the Jacobian matrix. The authors should check carefully if this affects their results.\n5. P19, line 1020. This seems like a mistake: $\\lambda_{min}(−H(x)) = −\\lambda_{max}(H(x))$.\n6. Also, the authors use $\\lambda$ to refer to different concepts, and they use  $\\sigma$ to represent different notations as well. It seems to me they use both to refer to eigenvalues.\n7. In P21, Corollary D.1. In the proof, by the backward error theorem for Newton’s method, ... there exist an exact solution x* to a perturb system. However, somehow this x* is set to equal to $Proj_M (\\hat{x})$ without proof.\n8. In Section C IMPLEMENTATION AND ALGORITHM DETAILS, the provided Algorithms 1 and 2 are for existing algorithms, then python code was provided. Could you provide your own algorithm like the existing algorithms?\n9. The proof of Theorem 2.1 is unclear. Please elaborate or clarify the key steps.\n10. P9, Table ??"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "O6uFtmWU93", "forum": "EQLcuMSy8b", "replyto": "EQLcuMSy8b", "signatures": ["ICLR.cc/2026/Conference/Submission4016/Reviewer_gWjg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4016/Reviewer_gWjg"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4016/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761878711010, "cdate": 1761878711010, "tmdate": 1762917136987, "mdate": 1762917136987, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper first identify data manifold curvature and score function stiffness as mechanisms potentially causing inconsistency in existing parallel diffusion samplers. It then proposes using adaptive Jacobian sparsity and curvature correction to alleviate this problem, leading to faster and more accurate parallel diffusion samplers, evaluated on large-scale image and video generation models."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The proposed parallel sampling method outperforms other similar methods, providing a substantial speedup for parallel diffusion sampling on a variety of large image and video diffusion models while maintaining generation quality."}, "weaknesses": {"value": "1. There is little to no experimental evidence to validate the hypothesis that manifold curvature or score function stiffness is the cause of parallel sampling instability. These claims made in the paper would be strengthened with some targeted experiments demonstrating that the instabilities cause trajectories to deviate from the data manifold or to lose mode consistency.\n2. It is unclear what the exact proposed algorithm is, as parts of it are described in Section 3, but it is not explicitly stated how they fit together. It would help to have the ROPA algorithm clearly stated in the main paper with the main contributions highlighted."}, "questions": {"value": "1. In Tables 2 and 3, it would also help to highlight the best RMSE and quality scores among all the parallel samplers\n2. On line 475/476, ROPA is stated to be 2.8x faster than baseline, but this does not seem to be reflected in Table 3."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "CeXY2PJl0y", "forum": "EQLcuMSy8b", "replyto": "EQLcuMSy8b", "signatures": ["ICLR.cc/2026/Conference/Submission4016/Reviewer_1hrZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4016/Reviewer_1hrZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4016/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761963167240, "cdate": 1761963167240, "tmdate": 1762917136619, "mdate": 1762917136619, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the author proposed a numerically robust approach for parallel generation tasks that addresses the numerical stability and scaling under parallelization for larger scale generation. The ROPA regulates the Jacobian condition number throughout sampling by combining damped Newton steps, adaptive banded Jacobian structure, and low-rank curvature correction, countering the \"curvature stiffness $\\to$ discretization\" gap instability that causes collapse/divergence in parallel diffusion. This method limits the growth of jacobian condition numbers and reduces the instability from the discretization error, and enabling faster convergence in generation tasks of video and images."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed method and the problems are interesting. Stability is a core concern in parallel generation tasks, and the proposed method of this paper seems to have solid strategy on ensure robustness of generation.\n\n2. The method is ubiquitious and adaptive to modalities beyond the image generation, and the empirical results show solid gain above the prior parallel generation methods."}, "weaknesses": {"value": "1. limited generation quality analysis: this paper lacks reporting some important metrics (i.e. FID, LPIPS, IS) and comparing with the sequential generation schemes. Please included these experiment results on COCO2017 dataset.\n\n2. While the paper claims that this parallel method can be adapted with other acceleration techniques, there lacks any empirical evidences to support this claim. Without adapting some popular diffusion acceleration methods (i.e., TeaCache, DeepCache, TaylorSeer, SADA etc.) along with parallel generation weaken the claim.\n\n3. The emerging one-/few-step generation methods (i.e. consistency models) is not adaptable with current method. Author should acknowledge this limitation.\n\n4. The generation tasks in paper are mostly short, (i.e., 378.6s sequentially around 6 minutes), but recent video generation models, such as WAN 2.2, can easily push generation over 20 minutes sequentially, especially if resolution and frames are large. Furthermore, this method is limited up to 8 cores scale, can this method extendable to more than 8 cores (say 128 cores)? \n\n[1] Timestep Embedding Tells: It's Time to Cache for Video Diffusion Model. CVPR 2025.\n[2] Deepcache: Accelerating diffusion models for free. CVPR 2024.\n[3] From reusing to forecasting: Accelerating diffusion models with taylorseers. ICCV 2025.\n[4] Sada: Stability-guided adaptive diffusion acceleration. ICML 2025."}, "questions": {"value": "1. for Theorem 2.2, the $\\epsilon$ is not defined, is that an arbitrary small difference or it is the latent noise? \n\n2. in higher resolution, is this jacobian matrix be memory dominating? If yes, I wonder how to mitigate the memory issue? Also, what is the computation & memory complexity of this jacobian matrix (please provide asymptotic (big-O) analysis and empirical results)?\n\n3. the paper claims (line 158-159) the locally Lipschitz assumption on support M, is there any numerical evidences for a reasonable size of the liptschitz constant (ensure there is no explosion of constant size in most models)? \n\n4. Is there any general settings that the ROPA is likely failing to converge? \n\n5. Some of the settings (i.e., resolution, frame count, batch size, guidance scale, scheduler type) are not provided, could author state these hyperparameters here?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wfWCEK2xGM", "forum": "EQLcuMSy8b", "replyto": "EQLcuMSy8b", "signatures": ["ICLR.cc/2026/Conference/Submission4016/Reviewer_4yww"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4016/Reviewer_4yww"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4016/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968127100, "cdate": 1761968127100, "tmdate": 1762917135829, "mdate": 1762917135829, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}