{"id": "57THeGgNAN", "number": 8374, "cdate": 1758080559268, "mdate": 1763704689269, "content": {"title": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "abstract": "Diffusion models generate high-quality, diverse images with great generalizability, yet when overfit to the training objective, they may memorize training samples. We analyze memorization and generalization of diffusion models through the lens of representation learning. Using a two-layer ReLU denoising autoencoder (DAE) parameterization, we show that memorization corresponds to the model learning the raw data matrix for encoding and decoding, yielding spiky representations; in contrast, generalization arises when the model captures local data statistics, producing balanced representations. We validate these insights by investigating representation spaces in real-world unconditional and text-to-image diffusion models, where the same distinctions emerge. Practically, we propose a representation-based memorization detection method and a simple representation-steering method that enables controllable editing of generalized samples. Together, our results underscore that *learning good representations is central to novel and meaningful generation*.", "tldr": "Learning good representations is central to novel and meaningful generation.", "keywords": ["diffusion models", "representation learning", "generalization", "memorization", "denoising autoencoders"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/eb8c7bb1f80994813b681bc72b06fc38f248086c.pdf", "supplementary_material": "/attachment/1bf43c2a458bc38dd9d01c437bfe298db71a4381.zip"}, "replies": [{"content": {"summary": {"value": "In this work, authors study the representation space of diffusion models, showing especially for simplified scenario with 2-layered DAE that memorization can be attributed to the spikiness of activations. In particular, authors show that for overparameterized models examples are encoded in single neurons, while this is not the case for generalized underparametrized scenario."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- Insightful formulation with ReLU DAE which clearly introduces the main claims of the paper\n- The theoretical contribution of the paper is clear and sound"}, "weaknesses": {"value": "- The paper's central observation—that memorization is linked to \"spiky\" neural activations—appears to be a rediscovery of the main finding from [1]. The authors propose using \"the standard deviation of intermediate features\" as a proxy for this spikiness. This metric is functionally identical to the z-score introduced in [1], which also identifies memorized examples by measuring the number of standard deviations an individual neuron's activation is from the mean.\n- The analysis is restricted to a comparison between two well-understood extremes: an overparameterized model that memorizes and an underparameterized model that generalizes. This setup does not address the more complex and realistic scenario where a single, large-scale model simultaneously memorizes some training examples while generalizing others.\n- In Section 3.1 there is an interesting example of memorization in overparametrized setup, where authors show that small DAE with large enough latent space (bigger than the dataset) can be optimized by memorizing individual samples (following block-wise structure). While this is a viable example, I am not sure that the conclusions are rigorous enough. I agree with comments presented in the first dot, but given the fact that the analysed solution is only the one of many local minimas, we cannot be sure that other minimas do not promote some generalization via neurons entanglement. \n- The paper makes the strong claim that “our findings show that the representation space is not a byproduct but a determining factor for generation.” This implies a causal relationship that the experiments do not support.\n- The conclusions on steering and editing representations are drawn from an insufficient sample size of just 8 qualitative examples. There is no quantitative evaluation to validate these claims."}, "questions": {"value": "-"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XKWzQeNWbE", "forum": "57THeGgNAN", "replyto": "57THeGgNAN", "signatures": ["ICLR.cc/2026/Conference/Submission8374/Reviewer_6mi7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8374/Reviewer_6mi7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8374/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761664358617, "cdate": 1761664358617, "tmdate": 1762920282774, "mdate": 1762920282774, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present a study on diffusion model generalization. They use a two-layer Relu network in a denoising autoencoder framework. In this framework, and assuming a type of cluster-separability, the authors present a theorem relates the optimal weights to the data clusters. They then proceed to derive properties for the low and high data limits, demonstrating they relate to memoization and generalization, and explain how these two domains have different weight properties. The authors then demonstrate these properties exist in pretrained diffusion models and how they can explain limitations of \"steering\" where the data is sparse."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "Overall I very much enjoyed reading this paper, here are some specific points of strength:\n- The paper is clearly organized, and concepts are well explained and presented.\n- I very much like the paper is centered around rigorous theory, but makes it approachable in presentation, and demonstrates the strengths and downstream applications their theory through practical experiments with real datasets and models.\n- This is a paper that makes a strong contribution toward understanding diffusion model generalization fundamentals, which is still quite poorly understood. The authors not only deliver great insight for people working on understanding this generaliation, but also make it approachable for practitioners working on downstream tasks"}, "weaknesses": {"value": "- There are a few things about definition 3.1 that seem odd to me. What 3.1 says is that the cluster means must be separated by at least some angle related to beta. This seems like a very specific type of clustering. It excludes for example clustering in the same direction (imagine a multi-modal gaussian with a sequence of modes in one dimension). Perhaps this is a common assumption I am not aware of. Could the authors defend this choice? Is it necessary for the theorems?\n- It seems to me that depending on beta, the assumption the authors use sets some limitations on the ratio between the number of clusters and the data dimension. When I think about such clusters and data dimension in the image space, I would argue that the number of clusters is much larger than the data dimension. This would limit beta for such datasets, and because of that make theorem 3.1 less applicable since it assumes beta < 1. Can the authors comment?\n- A small comment here is that the \"margin\" gamma (line 184) does not seem to be defined in the text.\n- It seems surprising to me that the \"spikiness\" observation from Cor. 3.2 holds in more complex networks than two-layer Relu networks. While it seems like a perfectly reasonalbe intermediate state for the two-layer net, for more complex networks it seems like that would be much more complex. Beyond empirical results, can the authors give some intuition for why this would hold?"}, "questions": {"value": "- (see also weaknesses)\n- Do the authors use sigma in the denoiser network? It is common practice for sigma to be part of the denoising representation. Would adding versus omitting it change any results?\n- Can the authors confirm that in the low data case, the network's output matches the optimal empirical denoiser? It seems like this would be the case, but I did not find that back in the paper. It would be useful to the reader to make a statement about that. \n- Related to the last question: is the reason that the under-parametrized networks do not output the optimal empirical denoiser that the network does not have enough capacity to learn it?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "i8FxEA4D8j", "forum": "57THeGgNAN", "replyto": "57THeGgNAN", "signatures": ["ICLR.cc/2026/Conference/Submission8374/Reviewer_jzL9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8374/Reviewer_jzL9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8374/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761885789474, "cdate": 1761885789474, "tmdate": 1762920282258, "mdate": 1762920282258, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to understand memorisation and generalisation of diffusion models from the representation perspective. Specifically, the authors built a theoretical framework in a two-layer ReLU diffusion model, which is more manageable in the theoretical sense. Firstly, the authors analysed the optimal solution of the above simplified diffusion model, which is over-parameterized. Through the analysis, they found that spiky representations happened, which are a a signal of memorisation. Secondly, the authors analysed the scenario of under-parameterisation, and showed that balanced representation as a signature of generalisation. Finally, the authors demonstrate the theoretical analysis can result in real-world impact, such as better memorisation detection metric and a steering approach for image editing."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This paper benefits from both theoretical analysis and further empirical impact. Especially, through the theoretical analysis, the authors showed that data representations (spikiness or balance) could be signals for memorisation/generalisation. Such signals could be used for memorisation detection, and have high accuracy than previous metrics and meanwhile is prompt-free."}, "weaknesses": {"value": "I have the following concerns or questions, which may need authors' clarifications. Also please correct me if  I am wrong.\n\n1. In case 1 of over-parameterisation, the authors found that with the optimal solution, the representations of a **single training sample** exhibits spikiness (in line 269). I am wondering if we input a different sample (not in training data) to such a neural network, whether the learned representations become a zero vector. \n\n2. In case 2 of under-parameterisation, the authors found that with the optimal solutions, the representations of a **single training sample** exhibits balance (in line 369), hence smaller std. I am also wondering what would happen if we input a different sample (not in training data, or a generalised sample). \n\n3. It seems that the authors consider two neural networks, one could memorise all samples, one could generalise new samples. However, for a trained diffusion model, it could both memorise and generalise. Why is the spikiness in representations an indicator for memorisation? \n\n4. The authors mainly discuss about optimal solutions for diffusion model. However, [1,2,3] show that as long as the number of training samples is finite, whether diffusion model is over-parameterised or not, there exists a theoretical optimum which could always generate memorised training data. Can you clarify the connection between such a theoretical optimum and the optimal solution shown in this paper? Is this because the model family of two-layer ReLU network cannot represent the theoretical optimum?\n\nReferences:\\\n[1] Yi et al. On the generalization of diffusion model. 2023.\\\n[2] Gu et al. On memorization in diffusion models. 2023.\\\n[3] Kamb et al. An analytic theory of creativity in convolutional diffusion models. ICML 2025."}, "questions": {"value": "See the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Sh7TjqvyuR", "forum": "57THeGgNAN", "replyto": "57THeGgNAN", "signatures": ["ICLR.cc/2026/Conference/Submission8374/Reviewer_NqY1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8374/Reviewer_NqY1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8374/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927266583, "cdate": 1761927266583, "tmdate": 1762920281907, "mdate": 1762920281907, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the mechanisms of memorization and generalization in diffusion models, starting with a theoretical analysis based on a two-layer ReLU denoising autoencoder.\n\nThe claim is that mem. or gen. is determined by the learned representations: (1) memorization corresponds to learning spiky, sample-specific representations and weights that store the training data sparsely, when model parameters $p$ are larger than data size $n$ ($p\\geq n$), and (2) generalization arises when the model learns balanced representations that capture local data statistics, when it is under-parameterized ($p \\ll n$).\n\nBased on the analysis, the authors introduce two practical applications: a highly efficient and effective method for detecting memorized content by measuring the spikiness of representations, and a training-free image editing technique based on representation steering, which demonstrates that generalized samples are more editable than memorized ones. The paper also validates these methods on some real-world models, including EDM, DiT and SD1.4."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper presents a valuable contribution by proposing a more fundamental, representation-centric framework to explain the behaviors of memorization and generalization in diffusion models.\n- The quality of the theoretical analysis is high, and the findings are shown to be consistent with observations in real-world models, as validated through two practical applications.\n- The memorization detection method demonstrates high performance and broad applicability across different models and datasets.\n- The observation that generalized samples are more steerable, while memorized samples exhibit brittle editing behavior, provides a novel and interesting insight."}, "weaknesses": {"value": "- The theoretical framework is built upon a two-layer DAE. While empirical results suggest the conclusions hold more broadly, I do not think it is very clear why the findings based on the linear projection dimension $p$ vs. data size $n$ ($p\\geq n$ or $p \\ll n$) should transfer to deep, multi-layered UNet / DiT.\n- The image editing experiments are limited in scope and somewhat unclear in their details.\n  - The representation steering method is only demonstrated on Stable Diffusion 1.4, which is somewhat old in this area. Its effectiveness and the observed behavior have not been tested on more recent models like DiT / MM-DiT based text-to-image models.\n  - The paper lacks a justification for how the \"encoder\" $g_\\theta$ and \"decoder\" $h_\\theta$ are determined (Line 461, Lines 990-992). The appendix specifies that features are extracted from 6 distinct layers in up_blocks.0 and up_blocks.1, but how these specific layers are selected is not provided. Additionally, I assume they form a collection of features with the size $100\\times C\\times H\\times W \\times 6$. Are these features averaged, or is the steering performed on 6 layers in parallel?\n- The image editing approach requires generating 100 reference images to compute a mean representation for the target concept, which makes it inapplicable to image-guided editing scenarios using a few (<10) provided reference images. Furthermore, will the reference image generation procedure affect the editing quality? For example, how the editing process would be affected if the generated reference samples were themselves memorized or of low quality."}, "questions": {"value": "Please refer to the weaknesses regarding the image editing approach and experiments."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MU4BT4MiEz", "forum": "57THeGgNAN", "replyto": "57THeGgNAN", "signatures": ["ICLR.cc/2026/Conference/Submission8374/Reviewer_Eg8y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8374/Reviewer_Eg8y"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8374/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986328655, "cdate": 1761986328655, "tmdate": 1762920281297, "mdate": 1762920281297, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Overall Response"}, "comment": {"value": "We thank all reviewers for their thoughtful and constructive feedback and are encouraged by the positive assessments of our work. In particular, the reviewers highlighted the quality of our theoretical analysis (all reviewers), the formulation of the ReLU-DAE model (6mi7), the strong connection between our theory and the practical behavior of diffusion models (jzL9, Eg8y), and the effectiveness of our two practical methods for memorization detection and image editing (NqY1, jzL9, Eg8y). During the rebuttal period, we have carefully addressed all questions raised by the reviewers and made corresponding revisions and additions to the manuscript; all changes are highlighted in blue. A recurring theme in the reviews concerns the relationship between our ReLU-DAE analysis and real diffusion models (EDM, DiT, SD1.4). We provide a clarification below:\n\n1. **Role of the simplified model.** Many existing works analyze the generalization of diffusion models under strong simplifications, such as random feature models [1, 2] or fully linear models [3], which can only partially capture either memorization or generalization, but not both. In contrast, we study a nonlinear two-layer ReLU-DAE model that provides a unified framework characterizing both memorization and generalization across different ratios of model capacity to training data size. Moreover, our results reveal distinct structures in the representation space (spiky versus balanced) in these regimes, which are consistently observed in practical diffusion models and thus support the intuition developed by our theoretical analysis.\n\n2. **Connection to real diffusion models via local linearization.** Modern diffusion networks are approximately piecewise linear [4, 5, 6], so their behavior around a given input can locally be captured by a piecewise-linear model (ReLU-DAE). This means real models can be considered as a collection of local ReLU-DAEs. In our framework, the spikiness of representations on practical diffusion models confirms this claim, that either Cor. 3.2 (memorization, spiky representation) or Cor. 3.3 (generalization, balanced representation) holds locally, and thus whether the real model memorizes or generalizes locally.  \n\n   Specifically, we compute the Jacobians of the denoisers in EDM and SD1.4 and analyze their SVDs (see Appendix C.1). Around generalized samples, the Jacobian exhibits slowly decaying singular values, and its singular vectors align with data statistics in practice (as predicted by Cor. 3.3). In contrast, around memorized samples, the Jacobian becomes very low-rank: the dominant singular vector corresponds closely to training samples, confirming that the model is effectively storing and denoising along the direction of specific training examples in practice (consistent with our theoretical findings in Cor. 3.2).\n\n3. **Coexistence of memorization and generalization.** Our theory can capture the co-existence that happens in real-world diffusion models. To demonstrate this, we have added Corollary 3.4 Page 8 of the main text in the revised paper. This corollary shows that a single ReLU-DAE already captures the co-existence phenomenon: the optimal weight memorizes training samples from clusters with limited data while learning the underlying statistics for clusters with sufficient data. This is consistent with what we observe in large-scale diffusion models, where memorization and novel generation coexist in different regions of the image space [7, 8].\n\nWe hope these clarifications make the conceptual bridge between our theoretical framework and practical diffusion models more explicit and address the reviewers’ main concerns. In the following, we address each reviewer’s other questions one by one.\n\nReferences:  \n[1] Bonnaire, Tony, et al. *Why Diffusion Models Don't Memorize: The Role of Implicit Dynamical Regularization in Training.* NeurIPS 2025  \n[2] George, Anand Jerry, Rodrigo Veiga, and Nicolas Macris. *Denoising score matching with random features: Insights on diffusion models from precise learning curves.* arXiv preprint 2025  \n[3] Li, Xiang, et al. *Understanding generalizability of diffusion models requires rethinking the hidden gaussian structure.* NeurIPS 2024  \n[4] Lukoianov, Artem, et al. *Locality in image diffusion models emerges from data statistics.* NeurIPS 2025  \n[5] Wang, Binxu. *An analytical theory of power law spectral bias in the learning dynamics of diffusion models.* NeurIPS 2025  \n[6] Wang, Binxu, and John J. Vastola. *The unreasonable effectiveness of gaussian score approximation for diffusion models and its applications.* TMLR  \n[7] Somepalli, Gowthami, et al. *Understanding and mitigating copying in diffusion models.* NeurIPS 2023  \n[8] Ross, Brendan Leigh, et al. *A geometric framework for understanding memorization in generative models.* ICLR 2025"}}, "id": "wqUUT2isRa", "forum": "57THeGgNAN", "replyto": "57THeGgNAN", "signatures": ["ICLR.cc/2026/Conference/Submission8374/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8374/Authors"], "number": 7, "invitations": ["ICLR.cc/2026/Conference/Submission8374/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763707118277, "cdate": 1763707118277, "tmdate": 1763707300636, "mdate": 1763707300636, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Overall Response"}, "comment": {"value": "We thank all reviewers for their thoughtful and constructive feedback and are encouraged by the positive assessments of our work. In particular, the reviewers highlighted the quality of our theoretical analysis (all reviewers), the formulation of the ReLU-DAE model (6mi7), the strong connection between our theory and the practical behavior of diffusion models (jzL9, Eg8y), and the effectiveness of our two practical methods for memorization detection and image editing (NqY1, jzL9, Eg8y). During the rebuttal period, we have carefully addressed all questions raised by the reviewers and made corresponding revisions and additions to the manuscript; all changes are highlighted in blue. A recurring theme in the reviews concerns the relationship between our ReLU-DAE analysis and real diffusion models (EDM, DiT, SD1.4). We provide a clarification below:\n\n1. **Role of the simplified model.** Many existing works analyze the generalization of diffusion models under strong simplifications, such as random feature models [1, 2] or fully linear models [3], which provide valuable but more idealized insights. In contrast, we study a more complex nonlinear two-layer ReLU-DAE model that provides a unified framework characterizing both memorization and generalization across different ratios of model capacity to training data size. Moreover, our results reveal distinct structures in the representation space (spiky versus balanced) in these regimes, which are consistently observed in practical diffusion models and thus support the intuition developed by our theoretical analysis.\n\n2. **Connection to real diffusion models via local linearization.** Modern diffusion networks are approximately piecewise linear [4, 5, 6], so their behavior around a given input can locally be captured by a piecewise-linear model (ReLU-DAE). This means real models can be considered as a collection of local ReLU-DAEs. In our framework, the spikiness of representations on practical diffusion models confirms this claim, that either Cor. 3.2 (memorization, spiky representation) or Cor. 3.3 (generalization, balanced representation) holds locally, and thus whether the real model memorizes or generalizes locally.  \n\n   Specifically, we compute the Jacobians of the denoisers in EDM and SD1.4 and analyze their SVDs (see Appendix C.1). Around generalized samples, the Jacobian exhibits slowly decaying singular values, and its singular vectors align with data statistics in practice (as predicted by Cor. 3.3). In contrast, around memorized samples, the Jacobian becomes very low-rank: the dominant singular vector corresponds closely to training samples, confirming that the model is effectively storing and denoising along the direction of specific training examples in practice (consistent with our theoretical findings in Cor. 3.2).\n\n3. **Coexistence of memorization and generalization.** Our theory can capture the co-existence that happens in real-world diffusion models. To demonstrate this, we have added Corollary 3.4 Page 8 of the main text in the revised paper. This corollary shows that a single ReLU-DAE already captures the co-existence phenomenon: the optimal weight memorizes training samples from clusters with limited data while learning the underlying statistics for clusters with sufficient data. This is consistent with what we observe in large-scale diffusion models, where memorization and novel generation coexist in different regions of the image space [7, 8].\n\nWe hope these clarifications make the conceptual bridge between our theoretical framework and practical diffusion models more explicit and address the reviewers’ main concerns. In the following, we address each reviewer’s other questions one by one.\n\nReferences:  \n[1] Bonnaire, Tony, et al. *Why Diffusion Models Don't Memorize: The Role of Implicit Dynamical Regularization in Training.* NeurIPS 2025  \n[2] George, Anand Jerry, Rodrigo Veiga, and Nicolas Macris. *Denoising score matching with random features: Insights on diffusion models from precise learning curves.* arXiv preprint 2025  \n[3] Li, Xiang, et al. *Understanding generalizability of diffusion models requires rethinking the hidden gaussian structure.* NeurIPS 2024  \n[4] Lukoianov, Artem, et al. *Locality in image diffusion models emerges from data statistics.* NeurIPS 2025  \n[5] Wang, Binxu. *An analytical theory of power law spectral bias in the learning dynamics of diffusion models.* NeurIPS 2025  \n[6] Wang, Binxu, and John J. Vastola. *The unreasonable effectiveness of gaussian score approximation for diffusion models and its applications.* TMLR  \n[7] Somepalli, Gowthami, et al. *Understanding and mitigating copying in diffusion models.* NeurIPS 2023  \n[8] Ross, Brendan Leigh, et al. *A geometric framework for understanding memorization in generative models.* ICLR 2025"}}, "id": "wqUUT2isRa", "forum": "57THeGgNAN", "replyto": "57THeGgNAN", "signatures": ["ICLR.cc/2026/Conference/Submission8374/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8374/Authors"], "number": 7, "invitations": ["ICLR.cc/2026/Conference/Submission8374/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763707118277, "cdate": 1763707118277, "tmdate": 1763743248837, "mdate": 1763743248837, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}