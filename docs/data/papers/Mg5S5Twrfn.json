{"id": "Mg5S5Twrfn", "number": 521, "cdate": 1756743639168, "mdate": 1763059641793, "content": {"title": "Multi-Resolution Fusion: An Effective Approach to Anomaly Detection", "abstract": "Unsupervised anomaly detection has been profoundly impacted by the advent of large-scale Vision Foundation Models (VFMs). The prevailing paradigm leverages features from a pre-trained encoder, where anomalies manifest as statistical outliers. However, a fundamental challenge persists: industrial defects vary dramatically in scale, making it difficult for a single model to detect them all effectively. This paper introduces a critical insight: a \"division of labor\" exists between different input resolutions. We find that low-resolution inputs excel at robustly recognizing the presence of anomalies by capturing global context, while high-resolution inputs are essential for refining their segmentation boundaries with precision. To harness this synergy, we propose Multi-Resolution Fusion (MRF), a simple yet powerful training-free strategy. MRF constructs a feature pyramid from the input space by processing an image at multiple resolutions. By fusing features from this pyramid, our method, MRF-AD, effectively combines the recognition capabilities of low-resolution views with the refinement capabilities of high-resolution ones. Extensive experiments show that MRF-AD achieves highly competitive, and in several cases state-of-the-art, results on challenging benchmarks like MVTec AD 2, proving the efficacy of our multi-resolution approach.", "tldr": "", "keywords": ["anomaly detection", "anomaly localization", "unsupervised learning", "DinoV2"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/2f3717c95f0c5860f1b3628eca61db8c91ab0acf.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a training-free anomaly detection method that leverages multi-scale DINOv2 features as a database. During inference, the method performs nearest-neighbor search to localize anomalies in industrial images. The reported results show comparable performance to prior works."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The approach is conceptually simple and easy to follow.\n\n2. The paper provides initial analyses on the visual and statistical effects of multi-scale inputs, which effectively convey the motivation."}, "weaknesses": {"value": "1. The work lacks sufficient novelty and insight. Building databases from multi-layer encoder features has been extensively explored in previous studies since 2020. Feeding images at multiple resolutions alone does not constitute a substantial technical advance for ICLR.\n\n2. Using multiple resolutions increases memory requirements and inference cost due to heavier nearest-neighbor search operations.\n\n3. The results in Table 1 show only marginal improvements and do not demonstrate a clear advantage over existing methods."}, "questions": {"value": "1. The method can highlight the anomalous regions. How is its segmentation performance on the detected anomaly areas and the classification accuracy on whether an image contains anomalies?\n\n2. How about the storage cost (e.g., database size) and the inference speed of the proposed method?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vNoaa10H7M", "forum": "Mg5S5Twrfn", "replyto": "Mg5S5Twrfn", "signatures": ["ICLR.cc/2026/Conference/Submission521/Reviewer_KLGT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission521/Reviewer_KLGT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission521/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761530567935, "cdate": 1761530567935, "tmdate": 1762915537425, "mdate": 1762915537425, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "p6w4yh5jsX", "forum": "Mg5S5Twrfn", "replyto": "Mg5S5Twrfn", "signatures": ["ICLR.cc/2026/Conference/Submission521/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission521/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763059641132, "cdate": 1763059641132, "tmdate": 1763059641132, "mdate": 1763059641132, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper indicates that low-resolution views provide a better overall context, which helps in identifying when something is wrong. In contrast, high-resolution views offer more detailed boundary refinement, aiding in precisely locating where a defect exists. To take advantage of both perspectives, they proposed a multi-resolution fusion (MRF) strategy. This approach involves processing the image at multiple scales (resolutions), extracting features from each scale, and fusing them to combine the strengths of both low and high resolutions. They implemented this as a training-free method, named MRF-AD, meaning it does not require additional anomaly supervision. The method has shown competitive results on  MVTec AD 2."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. It addresses the issue of scale sensitivity, that is, anomalies of varying sizes can be detected more effectively by considering multiple resolutions.  \n2. The fusion approach is straightforward conceptually and can easily be integrated with existing fundamental feature extractors."}, "weaknesses": {"value": "1. Figure 1 does not effectively convey the motivation behind integrating recognition and refinement from different input resolutions. \n2. Processing inputs at multiple resolutions and layers increases both computation and memory usage in direct proportion to the number of scales. The method may not be ideal for low-latency or resource-constrained settings. \n3. The method depends on a high-quality pretrained encoder from a vision foundation model. If the features provided by the encoder are poor or not suitable for the anomaly domain, performance could decline clearly. \n4. The claim of being ‚Äútraining-free‚Äù is somewhat overstated. Although the authors describe their approach as ‚Äútraining-free,‚Äù creating a memory bank from normal instances essentially involves modeling normality. There remains significant unsupervised processing and hyperparameter tuning involved. \n5. Although fusion enhances results in their benchmarks, the paper focuses on specific scales and a particular backbone (DINOv2). The general applicability to all encoders and datasets is not fully demonstrated."}, "questions": {"value": "1. Could the method be able to validated on non-industrial datasets, such as medical, satellite, or natural scene anomalies?\n2. How sensitive is the method to the choice of resolution scales? Is there a systematic approach for selecting them for each dataset?\n3. Can ablation study results directly demonstrate that low resolution contributes to recognition, while high resolution aids in boundary refinement?\n4. Are there situations where multi-resolution fusion does not provide any advantages over single-resolution processing? If so, what do those situations look like?\n5. How much does latency increase with each additional resolution scale? Is the method deployable on edge or embedded systems without GPU acceleration?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "th3oHYeouc", "forum": "Mg5S5Twrfn", "replyto": "Mg5S5Twrfn", "signatures": ["ICLR.cc/2026/Conference/Submission521/Reviewer_V7K2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission521/Reviewer_V7K2"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission521/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989598915, "cdate": 1761989598915, "tmdate": 1762915537325, "mdate": 1762915537325, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces **MRF-AD**, a training-free method for unsupervised anomaly detection using features from a frozen DINOv2 encoder. The proposed method is motivated by that input resolution affects the model‚Äôs ability to detect and localize anomalies: 1) low-resolution inputs capture global context and improve recognition of anomalous regions; and 2) high-resolution inputs refine boundaries but may miss global coherence. Based on these two observations, MRF-AD builds multiple input-space views of each image at different resolutions and extracts features from several DINOv2 layers. For every (layer, resolution) pair, a memory bank of normal features is created. At test time, each feature is compared to its nearest neighbor in the corresponding bank, producing per-scale anomaly maps that are averaged into a final prediction. Experiments on MVTec AD v2 show competitive results, especially on the challenging $\\mathrm{Test}_{priv,mix}$ split."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The ‚Äúrecognition vs. refinement‚Äù observation is intuitive and reasonable. \n2. The proposed training-free approach is simple and shows good experimental results.\n3. The ablation studies are comprehensive, evaluating layer fusion, resolution fusion, and background removal to verify each component‚Äôs contribution.\n4. Implementation details appear to be sufficient for reproducibility."}, "weaknesses": {"value": "1. The paper did not cite a highly relevant paper, **LogSAD** (CVPR 2025), which is also a training-free approach exploring multi-granularity fusion for anomaly detection.\n2. The technical novelty is incremental. The proposed method integrates known elements, including training-free DINOv2 features, nearest-neighbor scoring, and score fusion, whereas it does not introduce a fundamentally new algorithmic idea. The contribution lies mainly in combining input-space multi-resolution fusion with multi-layer features. Relevant and similar ideas can be found in the LogSAD paper.\n3. The presentation does not clearly describe whether the class label information is required at inference time. In particular, the description of memory-bank construction (Section 4.3) is ambiguous, and it is unclear if the memory banks are class-specific. \n4. The presentation about the experimental results should clearly specify whether all baselines were evaluated under the same resizing protocol (i.e., 5 M pixels per image). Also, a runtime or memory-usage table is not provided, while dependence on BEN2 background removal slightly weakens the ‚Äútraining-free‚Äù narrative.\n5. The description in the caption of Figure 1 does not match the four images."}, "questions": {"value": "The authors are suggested to respond to those raised in **Weaknesses.**\n\n**Additional questions**: \n1. What are the total feature bank sizes and inference time for 1-, 3-, and 5-resolution settings?\n2. How sensitive are results to the choice of resolution set (e.g., {0.3, 0.5, 0.7} vs. {0.4, 0.6})?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0gw9gkJJJf", "forum": "Mg5S5Twrfn", "replyto": "Mg5S5Twrfn", "signatures": ["ICLR.cc/2026/Conference/Submission521/Reviewer_EGPJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission521/Reviewer_EGPJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission521/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998044388, "cdate": 1761998044388, "tmdate": 1762915537222, "mdate": 1762915537222, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Multi-Resolution Fusion (MRF) for training-free anomaly segmentation. The key idea is a ‚Äúdivision of labor‚Äù: low-resolution inputs help with robust anomaly recognition by capturing global context, while high-resolution inputs sharpen boundaries with local detail. The method (MRF-AD) uses a frozen encoder, builds memory banks per layer and resolution, scores each view with nearest neighbors, then upsamples and averages the score maps to produce a scale-robust mask. On MVTec AD v2, it is competitive and achieves the best mean AU-PRO at threshold 0.05 on the challenging TEST-priv,mix split. The paper also offers clear ablations for layer fusion, resolution fusion, and background removal."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Clear, testable hypothesis about how low and high resolutions contribute differently, backed by intuitive visuals and ablation studies.\nSolid empirical performance across splits, including the best mean AU-PRO (threshold 0.05) on TEST-priv,mix, with category-level wins and consistent improvements.\nTraining-free and easy to adopt in practice: no parameter learning beyond memory banks, compatible with standard approximate nearest-neighbor search and multi-layer fusion.\nClean presentation: the pipeline diagram aligns with the scoring procedure, labels and tables are easy to read, and the narrative is coherent for practitioners."}, "weaknesses": {"value": "Multi-resolution/multi-layer fusion is standard; the advance is mainly a training-free packaging and careful eval, not a new objective/architecture.\nNo per-image latency/peak memory or accuracy‚Äìlatency trade-offs; add a small profiling table and ANN sensitivity.\nRelies on an external segmenter; show robustness with simple masks and at least one alternative segmenter (plus a few failure cases).\nEvidence is concentrated on MVTec AD v2; even partial results on v1/VisA/BTAD/MPDD would help.\nNo defect-size stratification, and the drop with a larger backbone isn‚Äôt diagnosed; try basic normalization/cosine/PCA checks."}, "questions": {"value": "1. Could you report per-image wall-clock latency and peak GPU memory for full fusion versus single-scale baselines, with a breakdown by ‚à£ùëÜ_res‚à£and ‚à£ùëÜ_layer‚à£, and include a small ùëõ_list / ùëõ_probe study to show accuracy‚Äìlatency trade-offs?\n2. Using your appendix distributions, can you report AU-PRO_0.05 for small/medium/large defects and indicate which resolutions contribute most in each regime?\n3. If the external segmenter is replaced with a lightweight heuristic mask or an alternative pretrained segmenter, how does performance change, and can you provide a mosaic of failure cases?\n4. For DINOv2-L, do cosine distance, feature whitening, or PCA compression prior to kNN mitigate the observed drop, and which factor appears causal?\n5. How sensitive are results to ùëÜ_res = {0.3, ... , 0.7}, and can a 2‚Äì3 scale subset recover most of the gains?\n6. Please include results on MVTec v1/VisA?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dFXaxtMa9L", "forum": "Mg5S5Twrfn", "replyto": "Mg5S5Twrfn", "signatures": ["ICLR.cc/2026/Conference/Submission521/Reviewer_6zgn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission521/Reviewer_6zgn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission521/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761999445715, "cdate": 1761999445715, "tmdate": 1762915537115, "mdate": 1762915537115, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}