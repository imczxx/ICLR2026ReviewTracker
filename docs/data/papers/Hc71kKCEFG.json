{"id": "Hc71kKCEFG", "number": 8533, "cdate": 1758089981291, "mdate": 1763573840467, "content": {"title": "Naming to Learn: Class Incremental Learning for Vision-Language Model with Unlabeled Data", "abstract": "Class Incremental Learning (CIL) enables models to adapt to evolving data distributions by learning new classes over time without revisiting previous data. While recent methods utilizing pre-trained models have shown promising results, they often assume access to fully labeled data for each incremental task, which is often impractical. In this paper, we instead tackle a more realistic scenario in which only unlabeled data and the class-name set are available for each new class. Although one could generate pseudo labels with a vision-language model and apply existing CIL methods, the inevitable noise in these pseudo labels tends to aggravate catastrophic forgetting. To overcome this challenge, we propose a method named N2L employing a regression objective with mean squared error loss, which can be solved in a recursive manner. To refine the pseudo labels, N2L applies feature dimensionality reduction to the extracted image features and iteratively updates the labels using a classifier trained on these reduced features. Furthermore, a bi-level weight adjustment strategy is proposed to downweight low-confidence pseudo labels via intra-class adjustment and compensate for pseudo-label class imbalance through inter-class adjustment. This incremental learning with adjustment can be solved recursively, yielding identical performance to joint training with unlabeled data and thereby mitigating forgetting. Our theoretical analysis supports the effectiveness of the pseudo label refinement process, and experiments on various datasets demonstrate that our proposed method outperforms SOTA methods. Code is provided in the appendix.", "tldr": "", "keywords": ["continual learning", "incremental learning", "vision-language model"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/49902848db509eaabbb81360f7d33c07db9212e4.pdf", "supplementary_material": "/attachment/b390d310b46ea436ef15f39ad5ad64ff3644320e.zip"}, "replies": [{"content": {"title": {"value": "Response to Reviewers"}, "comment": {"value": "Dear Area Chairs and Reviewers,\n\nWe sincerely thank the reviewers for their time, constructive feedback, and insightful suggestions. We appreciate the comments that helped enhance the clarity of our work, and we are especially grateful for the positive recognition of the paper’s contributions:\n\n1. **Presentation (Reviewers gGDh, S9dK)** : The paper is well written, with clear motivation and clear illustrations.\n\n2. **Soundness**\n\n\n    **2.1 Theoretical Soundness (Reviewers o5Et, S9dK, YoKW, gGDh)**: To refine the pseudo labels, we apply feature dimensionality reduction to the extracted image features and iteratively update the labels using a classifier trained on the reduced features. We provide a theoretical guarantee for the effectiveness of this feature-reduction-based refinement method.\n\n    **2.2 Strong Experimental Results (Reviewers o5Et, k1FB, YoKW, gGDh)**: We conduct experiments on six datasets, each with two evaluation settings, and additionally validate all twelve configurations using both the LAION-400M and OpenAI pretrained backbones. Our method consistently outperforms existing approaches across all scenarios. Notably, on datasets with large distribution shifts from CLIP’s pre-training data (e.g., Aircraft and ObjectNet), our method surpasses the second-best baseline by a substantial margin of 2.75%–8.46%.\n\n3. Contributions\n    \n    **3.1 A Practical CIL Setting (Reviewers o5Et, k1FB, S9dK, YoKW)**: The reviewers recognized that our proposed CIL setting, where unlabeled data and class-name sets are available at each task, is practical.\n\n    **3.2 Innovative Label Refinement and Weight Adjustment Mechanism (Reviewer o5Et)**: We propose a pseudo-label refinement method that iteratively improves the initial pseudo labels, supported by theoretical guarantees. In addition, we introduce a bi-level weight adjustment strategy that assigns sample weights based on prediction confidence and per-class sample counts.\n\n    **3.3 Adoption of MSE Loss (Reviewer YoKW)**: The adoption of MSE loss reduces the training time of ENGINE to roughly one-third, improving computational efficiency. Moreover, CIL with MSE loss admits a recursive formulation that helps mitigate forgetting. Our proposed MSE-based label refinement also demonstrates strong empirical effectiveness."}}, "id": "zPRMQjkeFu", "forum": "Hc71kKCEFG", "replyto": "Hc71kKCEFG", "signatures": ["ICLR.cc/2026/Conference/Submission8533/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8533/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8533/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763573017611, "cdate": 1763573017611, "tmdate": 1763573017611, "mdate": 1763573017611, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new scenario in which only unlabeled data and the corresponding class names are available for each new class. The authors propose N2L to address the noise in the pseudo labels generated by vision-language model."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe illustration is clear.\n2.\tThe method and the theoretical analysis seem solid."}, "weaknesses": {"value": "1.\tThe proposed scenario seems to be unrealistic. At each incremental task, the unlabeled samples are from several specific classes, but if the samples are unlabeled, there is no guarantee that the samples are constrained in these classes. Please give an example in real world where such scenario happens.\n2.\tThe experiments are mainly on standard datasets, the task boundary and definition are perfectly designed, lacking sufficient performance guarantee on real world scenarios where this paper is focusing on.\n3.\tThere are no experiments to evaluate the robustness under different quality of the pseudo labels. How does the performance be affected with more noisy pseudo labels? There should be an experiment under different accuracy level of pseudo labels.\n4.\tThe comparing methods are for CIL. No baseline methods for the newly proposed scenario is compared with, making it hard to support the superiority of N2L on tackling the noise of the pseudo labels."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rvyKoNexjm", "forum": "Hc71kKCEFG", "replyto": "Hc71kKCEFG", "signatures": ["ICLR.cc/2026/Conference/Submission8533/Reviewer_gGDh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8533/Reviewer_gGDh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8533/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761052504739, "cdate": 1761052504739, "tmdate": 1762920393073, "mdate": 1762920393073, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a realistic scenario: only unlabeled data and class names for new classes. Pseudo labels from vision-language models have noise that worsens catastrophic forgetting. Thus, the authors propose N2L: it uses MSE regression (matching joint-training results), refines pseudo labels via feature dimensionality reduction and iterative updates, and adopts bi-level weight adjustment (downweight low-confidence labels, balance class imbalance). The method mitigates forgetting, matches joint-training performance, outperforms SOTA in experiments (theoretically supported)"}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper works on a realistic CIL problem.\n- Adopting MSE loss works better than the CE loss.\n- Very good to have theoretical support.\n- Strong empirical support"}, "weaknesses": {"value": "- The line of work in analytic CIL often offers a very large advance in training speed. Is the proposed method also share this merit?\n- In Eq 5, not very clear how to obtain new labels. Y prime obtain through LS? and replace Y prime with Y tilda to do iteration?\n- Eq 11-13 should be of stronger role in this paper, but it seems not very highlighted.\n- Need to dicuss the difference from the existing analytic CIL, including ACIL and RAIL, etc.\n- 3.6 too short. Need to be self-contained with details.\n- In implementation details, how to determine these hyperparameters?\n- Lack of legends in figure 5.\n- In main context, where are the claimed 6 datasets? They should be taken into the main text, not in the appendix, also the different split scenarios."}, "questions": {"value": "see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "sMFOyhw4sf", "forum": "Hc71kKCEFG", "replyto": "Hc71kKCEFG", "signatures": ["ICLR.cc/2026/Conference/Submission8533/Reviewer_YoKW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8533/Reviewer_YoKW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8533/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761621699379, "cdate": 1761621699379, "tmdate": 1762920392763, "mdate": 1762920392763, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes the N2L, a method for continual learning based on CLIP with not fully labeled data. This paper specifies the problem of continual learning with tasks containing image and corresponding texts and the noisy generated pseudo-label. A progessive label refinement process is proposed to address the noisy label problem and a bi-level weight adjustment to reduce the imbalance within existing analytic continual learning method. Several experiments are conducted to validate the effectiveness of N2L and its components."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper concentrate on the continual learning of vision-language models with unlabeled data, which rare in the realm of continual learning. \n2. Overall, this paper is well wirtten with clear motivation.\n3. Theoretical analysis in this paper is sound."}, "weaknesses": {"value": "1. The setting of unlabeled data in this paper seems not fully obeying the unlabeled constrain. In the task t, the text label of the learning samples are provided. Since the CLIP has good zero-shot performance, annotating the samples within a limited set of text labels can be much more easier. For a fully unlabeled constrain, the samples within a task should not be accompanied with the text labels. Searching labels in the vocabulary of CLIP might be a better setting when claiming \"continual learning with unlabled data\". \n2. The presentation of algorithm pipeline and details is somehow not clear. For example, what is the pipeline of utilizing the progressive label refinement? In the Figure 2, is the refine classier the same as the classification head for the continual learning? This paper should illustrate the details clearer. Also, a psedo-code of the proposed method is needed to better understand this algorithm. \n3. Lack of statistical results of the experiments. The comparative study has only the average results, and results like standard deviations should be provided to validate the robustness of the methods.\n4. The ablation study is not sufficient. Although this paper provides the results with/without the three components of the proposed N2L, the direct effect of progress label refinement and inter-class adjustment on the performance are not provided. What is the performance degradation when progessive label refinement and inter-class adjustment is not appied? Since they are the major contribution upon the RAIL, the contribution of this paper is narrowed if not demonstrating their superiority. \n5. Lack of comparative study with different imbalance adjustment techniques. In this paper, the inter-class imbalance is adjusted via applying weighting coefficients in the training of classier, which is simple and similar to that in AIR [1]. \n \n[1] Di Fang, et al. AIR: Analytic Imbalance Rectifier for Continual Learning. arXiv:2408.10349."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "X0vqmqdwkl", "forum": "Hc71kKCEFG", "replyto": "Hc71kKCEFG", "signatures": ["ICLR.cc/2026/Conference/Submission8533/Reviewer_S9dK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8533/Reviewer_S9dK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8533/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761738360431, "cdate": 1761738360431, "tmdate": 1762920392452, "mdate": 1762920392452, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a new class-incremental learning paradigm where only unlabeled images and the corresponding set of class names are provided at each training stage. To this end, the authors introduce N2L consisting of four steps: (1) pseudo label generation; (2) progressive label refinement; (3) bi-level weight adjustment; (4) learning a classifier. Specifically, they introduce a feature dimension reduction strategy at step 2, and present intra- and inter-class adjustment schemes at step 3. Experimental results on various datasets demonstrate the effectiveness of N2L for image classification."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed problem setting, i.e., class-incremental learning with unlabeled data, seems practical.\n- The proposed method, N2L, achieves state-of-the-art performance on standard benchmarks."}, "weaknesses": {"value": "My major concerns are Originality and Clarity. The detailed questions are listed below.\n- Although there have been several works on semi-supervised [A,B] and unsupervised continual learning [C], the manuscript is missing any discussion on them. Thus, I would recommend adding a discussion on the similarities/differences between the proposed setting and these prior works. In particular, it would be helpful if the authors could also provide a quantitative comparison with them.\n- Although the authors provide Table 3, it remains unclear why the Gaussian distribution is more beneficial than the uniform distribution. It would be better if the authors provided a more detailed explanation.\n- Figure 7 shows that increasing the number of epochs required for label refinement beyond 3 is sub-optimal. While performance saturation is expected, it is unclear why the performance decreases. Could the authors provide a plausible explanation?\n- The authors frequently use the term 'identical' (e.g., Lines 22, 28, 65, 75, 414 etc). However, considering that the proposed method still performs much worse than 'Label' in Table 1, clarification would be helpful.\n\n[A] ORDisCo: Effective and Efficient Usage of Incremental Unlabeled Data for Semi-supervised Continual Learning, CVPR 2021\n\n[B] Divide-and-Conquer for Enhancing Unlabeled Learning, Stability, and Plasticity in Semi-supervised Continual Learning, ICCV 2025\n\n[C] Representational Continuity for Unsupervised Continual Learning, ICLR 2022"}, "questions": {"value": "Please refer to the Weaknesses section. Minor questions are as follows:\n- It would be interesting to explore the scalability of the proposed method to dense prediction tasks, given that several methods have already adapted CLIP for detection and/or segmentation. How do the authors expect their method to perform in such scenarios?\n- While the proposed method consistently outperforms other baselines, Figure 9(5) shows that it performs worse than ENGINE during the first three incremental stages. Could the authors provide a plausible reason?\n- Line 138-139: I recommend explaining the notation 'n_t' here.\n- Line 188: it seems that the opening double-quotation mark is incorrect.\n- Line 217-218: it would be helpful if there is an explicit explanation of the notation 'd'.\n- Line 219: ‘above’ might be appropriate (not ‘below’).\n- Line 232: the hyperparameter '\\lambda' should be explained here rather than Line 243-244.\n- It would be helpful if there was an explanation in Figure 5 (left) like 'different tasks are marked in different colors'."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1bmtkzIzPN", "forum": "Hc71kKCEFG", "replyto": "Hc71kKCEFG", "signatures": ["ICLR.cc/2026/Conference/Submission8533/Reviewer_k1FB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8533/Reviewer_k1FB"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission8533/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986967206, "cdate": 1761986967206, "tmdate": 1762920391904, "mdate": 1762920391904, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes N2L (Naming-to-Learn), a class-incremental learning framework for vision-language models when only unlabeled data and class-name sets are available at each task. The method combines pseudo-label generation via zero-shot CLIP, progressive label refinement, bi-level weight adjustment, and analytic recursive learning. The approach is theoretically supported and achieves strong results on multiple benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This paper proposes N2L (Naming-to-Learn), a class-incremental learning framework for vision-language models when only unlabeled data and class-name sets are available at each task. The method combines pseudo-label generation via zero-shot CLIP, progressive label refinement, bi-level weight adjustment, and analytic recursive learning. The approach is theoretically supported and achieves strong results on multiple benchmarks."}, "weaknesses": {"value": "(1) Terminology ambiguity\nThe phrase “unlabeled data and the corresponding class names” is conceptually imprecise. At each task, the model receives a class-name set rather than per-sample labels; this wording conflates label sets with labels and may mislead readers about the supervision form.\n(2) Definition of pseudo-label noise\nThe paper mentions “noise in pseudo labels” many times without clear definition. Does it refer to misclassification errors produced by the pretrained VLM when assigning zero-shot pseudo labels.\n(3) Baseline adaptation fairness\nReplacing ground-truth labels with pseudo labels for fully supervised baselines may conflict with their design and amplify CLIP prediction errors. Reporting their supervised results would help isolate the effect of pseudo-label noise from methodological differences.\n(4) Overly restrictive pseudo-label assumption\nPseudo labels in each task t are generated only from new-class candidates CtC_tCt. This closed-set assumption simplifies the problem. To align with standard CIL inference, the authors should test or discuss a more realistic case where pseudo labels are drawn from the union of all seen classes (C₁:ₜ), reflecting data sampled from previously observed distributions.\n(5) Why not conduct experiments on MTIL or X-TAIL benchmark?"}, "questions": {"value": "Please see the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Y9V2dBLWq5", "forum": "Hc71kKCEFG", "replyto": "Hc71kKCEFG", "signatures": ["ICLR.cc/2026/Conference/Submission8533/Reviewer_o5Et"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8533/Reviewer_o5Et"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission8533/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992171309, "cdate": 1761992171309, "tmdate": 1762920391337, "mdate": 1762920391337, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}