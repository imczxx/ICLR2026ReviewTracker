{"id": "ciiKoeM206", "number": 15044, "cdate": 1758247155247, "mdate": 1759897333611, "content": {"title": "Latent Reasoning in LLMs as a Vocabulary-Space Superposition", "abstract": "Large language models (LLMs) demonstrate strong reasoning abilities with chain-of-thought prompting, but explicit reasoning introduces substantial computational overhead. Recent work on latent reasoning reduces this cost by reasoning in latent space without explicit supervision, but performance drops significantly. Our preliminary experiments suggest that this degradation stems from the unstructured latent space, which makes fitting latent tokens difficult. To address this, we restrict the latent space to the column space of the LLM vocabulary, treating latent reasoning as a superposition over vocabulary probabilities. Once latent reasoning concludes, it collapses into an eigenstate of explicit reasoning to yield the final answer. Based on this idea, we propose Latent-SFT, a two-stage learning framework. In the first stage, we design two specialized attention masks to guide the Latent Token Encoder in generating latent tokens, allowing the LLM to produce the correct answer conditioned on them. In the second stage, the Latent Token Encoder is discarded, and the LLM is directly trained to generate these latent tokens autonomously for latent reasoning, optimized with KL and CE losses. Latent-SFT sets a new state of the art on GSM8k, matching explicit SFT performance while cutting reasoning chains by up to 4× and outperforming prior latent methods. On Math500 and AIME24, lexical probability–based latent reasoning also clearly surpasses hidden-state–based approaches. Our metrics of effective compression rate and effective global parallelism further show that latent reasoning is both the compression of a single path and the superposition of multiple paths.", "tldr": "", "keywords": ["Large Language Model", "Latent Reasoning"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/84e76f8321e2b2e52b4ab770071112e5efe311f6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a novel framework for latent reasoning that compresses explicit chain-of-thought reasoning into a small number of latent tokens operating in the vocabulary embedding space. Empirically, the method achieves comparable or even better reasoning accuracy than explicit CoT while using 2× fewer tokens on low-difficulty tasks, but performance is still much lower than normal sft on difficult tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The paper is clearly written and easy to follow, with detailed experimental setups\n* It proposes a complete and conceptually coherent system for compressing reasoning chains into latent tokens, unifying several ideas\n* The evaluation includes both positive and negative results across multiple reasoning benchmarks, offering an honest and nuanced view of when latent reasoning helps and where it still struggles."}, "weaknesses": {"value": "* The experimental design appears somewhat inconsistent: the authors evaluate low-difficulty tasks using LLaMA-3.2-1B-Instruct, while high-difficulty tasks are run on DeepSeek-Distill-Qwen-7B . Results on overlapping datasets or difficulty tiers using the same model would make the claims more convincing. (add low-diff tasks on deepseek and high-diff on llama)\n* The separation of low- and high-difficulty evaluations raises questions about transferability of the learned reasoning-compression patterns. If the latent reasoning mechanism cannot generalize across tasks or difficulty levels, the approach’s practical benefit diminishes\n* On challenging datasets such as Math500 and AIME24, performance lags behind normal sft. This weakens the practical significance of the method, as it seems most effective only for simpler reasoning tasks."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vC4LoEj4JY", "forum": "ciiKoeM206", "replyto": "ciiKoeM206", "signatures": ["ICLR.cc/2026/Conference/Submission15044/Reviewer_uoyr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15044/Reviewer_uoyr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15044/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761373478715, "cdate": 1761373478715, "tmdate": 1762925368562, "mdate": 1762925368562, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a method for latent reasoning that makes use of the finding that it is easier to make latent vectors which are \"soft embeddings\" (mixtures of token embeddings), or at least continuous vectors close to these in the latent space. These hidden states can then be further optimized by training to directly generate these tokens with a combination of losses. This results in performance close to (slightly above or below) CoT on easier tasks, and below on harder tasks, but using less tokens."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The results are superior to a number of latent reasoning approaches which are the baselines compared to such as COT-SFT (Wei et al., 2022), iCOT (Deng et al., 2024), COCONUT (Hao et al., 2024), CODI (reproduced) (Tan et al., 2025), and CoLaR.\nPerformance is close to (slightly above or below) CoT on easier tasks (although I think this was similar on related papers, see weaknesses)."}, "weaknesses": {"value": "Overall, it seems a very complicated system (and hence also a bit hard to understand), and achieves minor gains over standard CoT, although I appreciate a number of latent reasoning methods are significantly worse than CoT. \nWhile it is admirable to try to make latent reasoning work, I also have a feeling that tying it too much to standard CoT inevitably makes the performance similar to standard CoT, as also shown in the Soft Thinking and Mixture-of-Input papers I think. I note you cite but do not compare to those (although they are also pretty recent)? I think they also showed marginal gains over text CoT, so a similar story, but less complicated...\n\nWhile the number of latent tokens is less, it’s also worse on harder tasks (Table 2), so I guess you’d have to compare to conventional CoT with less thought tokens, and see how that compares to really understand a bit more the difference.\n\nThe performance of COCONUT seems lower than even reported in the original paper, although I suppose this is a different setting? But still, seems a backwards step to put it in a lower performance setting (smaller model, or..?).\n\ngrammar:\n“To gain a deeper understanding ofing of the latent reasoning process,”\n“Latent tokens are designed to be: (1) semantic compactness, ..”"}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "9aLxpMhSKr", "forum": "ciiKoeM206", "replyto": "ciiKoeM206", "signatures": ["ICLR.cc/2026/Conference/Submission15044/Reviewer_YNHm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15044/Reviewer_YNHm"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15044/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761834279781, "cdate": 1761834279781, "tmdate": 1762925368145, "mdate": 1762925368145, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents Latent-SFT, a two-stage learning framework to enable latent reasoning in LLMs. This approach restricts the latent space to the column space of the LLM vocabulary and treats latent reasoning as a superposition over vocabulary probabilities.  The first stage of training involves generating latent tokens with an encoder-decoder architecture using the same LLM. In stage-2, the LLM is directly trained to generate these latent tokens for reasoning."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The Latent-SFT approach achieves new SoTA numbers on GSM8k and matches the CoT-SFT performance for low-difficulty tasks.  \n\n2. Unlike existing approaches, restricting the latent reasoning to the column space of the LLM vocabulary directly addresses the misalignment between latent and token spaces.  \n\n3 The paper provides extensive analysis and offers valuable insights into the latent reasoning process."}, "weaknesses": {"value": "1. There is still a significant gap for Latent-SFT compared to CoT-SFT on high difficulty tasks like MATH500 or AIME24.  \n\n2. The paper lacks results on other reasoning tasks such as GPQA and LiveCodeBench.  \n\n3. The paper mainly demonstrates results on 1B for low-difficulty tasks. Demonstrating results on a larger model can help with showing scalability.  \n\n4. How does the proposed approach compare with training free approaches like Soft Thinking in terms of both accuracy and efficiency? \n\n5. The paper lacks training and inference compute efficiency numbers compared to other approaches and the overhead of Stage-1 of learning is not specified.  \n\n6. Presentation of results can be improved. Table-1 captions are unclear."}, "questions": {"value": "What is the additional compute cost involved in generating the latent tokens, i.e. stage-1?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "aHFtBdtV9C", "forum": "ciiKoeM206", "replyto": "ciiKoeM206", "signatures": ["ICLR.cc/2026/Conference/Submission15044/Reviewer_Yykd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15044/Reviewer_Yykd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15044/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761973484707, "cdate": 1761973484707, "tmdate": 1762925367675, "mdate": 1762925367675, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the problem that latent reasoning in large language models—reasoning without explicit chain-of-thought tokens—suffers from performance loss due to the unstructured and misaligned nature of latent spaces. To solve this, it proposes Latent-SFT, a two-stage training framework that constrains latent reasoning to the vocabulary embedding space, treating each latent token as a soft superposition of vocabulary vectors. This alignment allows models to reason efficiently and semantically consistently. Experiments show that Latent-SFT achieves explicit-level reasoning accuracy on benchmarks like GSM8K while reducing reasoning chain length by up to 4×, establishing a new state of the art for latent reasoning."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* **Originality:** The work defines latent reasoning as a *vocabulary-space superposition*, offering a fundamentally new and interpretable view of how LLMs reason internally.\n* **Quality:** The work proposes a well-justified two-stage **Latent-SFT** framework that effectively aligns latent tokens with the LLM’s vocabulary manifold.\n* **Significance:** The work demonstrates explicit-level reasoning accuracy with up to **4× shorter reasoning chains**, improving both efficiency and interpretability."}, "weaknesses": {"value": "* **Limited evaluation scope:** Experiments are primarily focused on mathematical reasoning datasets (e.g., GSM8K, Math500, AIME24), leaving uncertainty about generalization to other reasoning domains such as commonsense, symbolic, or multi-modal reasoning. Including ARC may be helpful.\n* **High-difficulty performance gap:** Latent-SFT shows substantial accuracy degradation on long-chain datasets like AIME24, suggesting the method struggles to maintain semantic integrity under extended reasoning or limited training lengths; further scaling or curriculum-based training could help.\n* **Limited interpretability validation:** Although the paper claims interpretability via “vocabulary-space superposition,” the analysis (ECR@K and N_eff) remains indirect; more qualitative visualization or alignment studies between latent and explicit reasoning paths could make the claim more convincing.\n* **Ablation and baseline breadth:** The ablations mostly vary internal components (e.g., LTIM, LTSuM, hidden-state variants) but do not compare against broader compression or distillation methods (e.g., TokenSkip, LoRA-compressed CoT), limiting the contextual strength of performance claims."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "KxkQcjxd50", "forum": "ciiKoeM206", "replyto": "ciiKoeM206", "signatures": ["ICLR.cc/2026/Conference/Submission15044/Reviewer_Q6oS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15044/Reviewer_Q6oS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15044/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976364001, "cdate": 1761976364001, "tmdate": 1762925367307, "mdate": 1762925367307, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}