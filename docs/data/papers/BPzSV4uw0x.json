{"id": "BPzSV4uw0x", "number": 5382, "cdate": 1757906107615, "mdate": 1759897978720, "content": {"title": "Rethinking LoRA for Privacy-Preserving Federated Learning in Large Models", "abstract": "Fine-tuning large vision models (LVMs) and large language models (LLMs) under differentially private federated learning (DPFL) is hindered by a fundamental privacy-utility trade-off. Low-Rank Adaptation (LoRA), a promising parameter-efficient fine-tuning (PEFT) method, reduces computational and communication costs by introducing two trainable low-rank matrices while freezing pre-trained weights. However, directly applying LoRA in DPFL settings leads to performance degradation, especially in LVMs. Our analysis reveals three previously underexplored challenges: (1) gradient coupling caused by the simultaneous update of two asymmetric low-rank matrices, (2) compounded noise amplification under differential privacy, and (3) sharpness of the global aggregated model in the parameter space. To address these issues, we propose LA-LoRA (\\textbf{L}ocal \\textbf{A}lternating \\textbf{LoRA}), a novel approach that decouples gradient interactions and aligns update directions across clients to enhance robustness under stringent privacy constraints. Theoretically, LA-LoRA strengthens convergence guarantees in noisy federated environments. Extensive experiments demonstrate that LA-LoRA achieves state-of-the-art (SOTA) performance on Swin Transformer and RoBERTa models, showcasing robustness to DP noise and broad applicability across both LVMs and LLMs. For example, when fine-tuning the Swin-B model on the Tiny-ImageNet dataset under a strict privacy budget ($\\epsilon = 1$), LA-LoRA outperforms the best baseline, RoLoRA, by 16.83\\% in test accuracy. Code is provided in the Appendix.", "tldr": "", "keywords": ["Federated Learning", "Differential Privacy", "LoRA."], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cbf8afeb0b2e7db0e8bca19989200efaaed1b314.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses three key challenges in federated DP-LoRA: gradient coupling, noise amplification, and loss sharpness. The authors propose LA-LORA, which employs two components: a local alternating update strategy to tackle gradient coupling and noise amplification, and a low-pass smoothing filter applied pre-aggregation to mitigate solution sharpness. Theoretically, the paper's analysis demonstrates that this alternating update avoids a destabilizing \"across term\" inherent in standard joint updates, leading to more stable optimization. Experimentally, LA-LORA outperforms existing methods like DP-LORA and RoLoRA on both vision and language benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper's presentation is clear and the writing flow is well-organized. Also a clear reproducibility statement is supported with codes."}, "weaknesses": {"value": "1. The theoretical analysis convincingly argues for alternating updates vs. joint updates but fails to differentiate LA-LORA from other alternating baselines such as FFA-LORA, RoLoRA. \n2. The analysis lacks a deep discussion on the relative importance of the three identified challenges. It remains unclear which challenge contributes most to performance degradation or how their respective impacts differ across vision versus language tasks.\n3. The paper re-frames the aggregation challenge as \"sharpness\" but fails to address the underlying mathematical \"aggregation bias\"( $\\mathbb{E}[\\bar{B}]\\mathbb{E}[\\bar{A}] \\neq \\mathbb{E}[\\overline{BA}]$), and it is unclear how the low-pass filter resolves this fundamental discrepancy."}, "questions": {"value": "1. What explains LA-LORA's empirical gains over FFA-LORA and RoLoRA?\n2. Why is LA-LORA's performance gain dramatically larger in vision (+16.83% on Swin-B) than in language (+2.48% on QNLI)? \n3. How does the algorithm perform (the final test accuracy) against other baselines in the non-private setting?\n4. How sensitive is LA-LORA to the choice of local steps K?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ln9HLDGwg0", "forum": "BPzSV4uw0x", "replyto": "BPzSV4uw0x", "signatures": ["ICLR.cc/2026/Conference/Submission5382/Reviewer_cWrF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5382/Reviewer_cWrF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5382/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761207545638, "cdate": 1761207545638, "tmdate": 1762918032055, "mdate": 1762918032055, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes LA-LoRA (Local Alternating LoRA), a new variant of LoRA for fine-tuning models under differentially private federated learning (DPFL). The authors identify three key challenges in applying conventional Low-Rank Adaptation (LoRA) to DPFL: 1)gradient coupling 2) noise amplification, and 3) sharpness of aggregated solutions, which degrade model performance under privacy constraints. To address these, LA-LoRA introduces a local alternating update strategy, where LoRA’s two low-rank matrices are updated sequentially rather than simultaneously with a low-pass filter. Some experimental results are presented to demonstrate the effectiveness of the proposed algorithm, compared to DP-LoRA, FFA-LoRA and RoLoRA."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1) The paper presents clear problem identification and the potential reasons of the problems.\n2) The proposed algorithm is elegant, clear and effective.\n3) Some analysis about the stability is presented to demonstrate the effectiveness of the proposed algorithm."}, "weaknesses": {"value": "1) It is unclear how the 1D Gaussian kernel filter can be justified from the optimization perspective. A potential issue is that such a filter can be model-dependent and/or data-dependent, as shown in the ablation study that vision models benefit significantly more than the language model. \n2) Theorems 2 and 3 seem superficial. They only present an ideal case; but they do not consider DP noise, the federated learning distributed nature, or the 1D Gaussian kernel filter.\n3) The LLM-related experiments can be extended to more recent tasks with more recently published models."}, "questions": {"value": "1) What is the intuition and theoretical justification for the 1D Gaussian kernel filter? Why can the adjacent element row/columns-wise be used to smoothing?\n2) How can Theorems 2 and 3  explain the utility of the proposed method?\n3) Does the proposed LA-LoRA method have different utility depending on the model and data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CNWDKBJrpJ", "forum": "BPzSV4uw0x", "replyto": "BPzSV4uw0x", "signatures": ["ICLR.cc/2026/Conference/Submission5382/Reviewer_gf7V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5382/Reviewer_gf7V"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5382/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761454810202, "cdate": 1761454810202, "tmdate": 1762918031802, "mdate": 1762918031802, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the limitations of directly applying Low-Rank Adaptation (LoRA) in differentially private federated learning (DPFL). The authors identify three intrinsic challenges that arise when LoRA is used under DP constraints: (1) gradient coupling between asymmetric matrices, (2) structural amplification of DP noise due to multiplicative interactions between noise terms, and (3) sharpness in global aggregation that leads to unstable convergence and poor generalization.\n\nTo mitigate these issues, they propose LA-LoRA, a simple yet effective modification that alternates updates between LoRA’s two low-rank matrices within each local round and applies an optional Gaussian low-pass filter to smooth noisy gradients. Theoretical analysis establishes convergence stability and privacy guarantees. Experiments on both vision and language models show consistent improvements across multiple privacy budgets, achieving state-of-the-art accuracy while maintaining formal DP guarantees.\n\nOverall, the paper is well-written, methodologically sound, and provides both theoretical and empirical support. Its main contribution lies in identifying the underexplored failure modes of LoRA under DPFL and offering an elegant yet practical fix."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. **Clear problem identification.**\nThe authors provide an intuitive and thorough analysis of why existing DP-LoRA methods fail, including gradient coupling, multiplicative noise amplification, and curvature-related instability after aggregation — each well-motivated and demonstrated through figures and equations.\n\n2. **Sound theoretical grounding.**\nThe paper presents convergence and privacy guarantees with clear mathematical derivations and ties them directly to the algorithmic design. This theoretical foundation strengthens the credibility of the proposed solution.\n\n3. **Comprehensive experiments.**\nThe work evaluates both language and vision tasks using multiple baselines under varying ε-budgets. The improvements are consistent and substantial.\n\n4. **Simple yet effective modification.**\nThe proposed alternating update and Gaussian filter are computationally lightweight, easy to integrate, and yield significant utility gains without sacrificing privacy guarantees."}, "weaknesses": {"value": "1. Based on your deduction, the identified issues (gradient coupling, DP-noise amplification, sharpness) seem to arise from LoRA’s intrinsic structure rather than federated communication. Do these problems persist even in centralized DP-LoRA? The paper should clarify that. If so, the research should focus on centralized DP-LoRA, instead of the federated setting.\n\n2. While LA-LoRA achieves higher cosine similarity, it is unclear whether this causally leads to better accuracy or is merely correlated. Including a non-DP Fed-LoRA baseline could help isolate whether high similarity is inherent and thus beneficial.\n\n3. While the low-pass filter idea is interesting, the paper should better differentiate it from recent filtered gradient mechanisms such as [1], which also employ noise smoothing for DP stability.\n\n4. Although LA-LoRA is efficient, it adds alternation and filtering. A detailed breakdown of time/memory cost versus baselines (beyond Table 6) would strengthen the practical claim.\n\n**Reference**\n\n[1] *Doppler: Differentially private optimizers with low-pass filter for privacy noise reduction. Neurips 2024*"}, "questions": {"value": "1. Are the three limitations (gradient coupling, noise amplification, sharpness) unique to the federated setup, or do they also appear in centralized DP-LoRA? If they appear in both, could LA-LoRA also enhance centralized DP-LoRA performance?\n\n2. Figure 2 compares DP-LoRA and LA-LoRA, but not Fed-LoRA (non-DP). Does higher gradient-similarity appear in the non-DP case? This would clarify whether cosine alignment is indeed the key to improved performance.\n\n3. What is the theoretical justification for the specific kernel? Have the authors considered learned or adaptive filters, or tested sensitivity to the kernel width?\n\nI would raise my score if the above questions are addressed properly."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jmrD7JXLOY", "forum": "BPzSV4uw0x", "replyto": "BPzSV4uw0x", "signatures": ["ICLR.cc/2026/Conference/Submission5382/Reviewer_kNbJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5382/Reviewer_kNbJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5382/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761771746236, "cdate": 1761771746236, "tmdate": 1762918031594, "mdate": 1762918031594, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper revisits the role of LoRA within the context of privacy-aware FL. The method introduces a local alternating update scheme where the two LoRA matrices are updated in turn during local training to decouple gradients and reduce noise amplification. Additionally, a low-pass Gaussian smoothing filter is applied to suppress high-frequency noise before aggregation, improving stability and generalization."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "1. Strong Empirical Performance: Extensive experiments demonstrates high accuracy while achieving better privacy–utility balance than baseline defenses.\n\n2. Incorporation of Low-Pass Smoothing Filter: Uses a Gaussian low-pass filter before aggregation to smooth high-frequency DP noise, improving stability of the algorithm."}, "weaknesses": {"value": "1. Lack of studies on different local alternating strategies: The current method fixes the local alternating update pattern to update matrix A on odd iterations and matrix B on even iterations, effectively using a one-step inner loop. It would strengthen the work to explore and experiment with other strategies such as updating A for several consecutive steps before switching to update B, or vice versa. Moreover, analysis of how different alternating schedules affect performance under various degrees of data heterogeneity would provide deeper insights.\n\n2. Incomplete Theoretical Convergence Analysis: Theorems 2 and 3 provide structural insights into projected gradients and stability but fall short of delivering explicit convergence rates or optimization behavior under privacy noise. Deriving explicit convergence rates, possibly for both convex and non-convex settings, and clarifying the trade-off between differential privacy noise injection and optimization accuracy, would provide a more comprehensive understanding of algorithm performance.\n\n3. Unclear Privacy Guarantees Regarding the Smoothing Filter: The privacy guarantee in Theorem 1 appears to ignore the effect of the low-pass Gaussian smoothing filter applied to the gradients before aggregation. It raises the question of whether the differential privacy guarantee strictly holds when the smoothing filter is included. Since the filter alters the noise characteristics, a clear discussion or proof of how these impacts or preserves privacy guarantees would strengthen the claim. Without this, the smoothing filter may be viewed as a redundant or questionable design that could be alternatively addressed by carefully tuning the privacy budgets."}, "questions": {"value": "1. The word \"update\" is spelled incorrectly in the beginning of section 4.1."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No concerns."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yyDkndfRFB", "forum": "BPzSV4uw0x", "replyto": "BPzSV4uw0x", "signatures": ["ICLR.cc/2026/Conference/Submission5382/Reviewer_fjPf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5382/Reviewer_fjPf"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5382/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761779696593, "cdate": 1761779696593, "tmdate": 1762918031300, "mdate": 1762918031300, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}