{"id": "NnMcIU99DA", "number": 9114, "cdate": 1758111757197, "mdate": 1759897742575, "content": {"title": "Neurosymbolic Theory Revision through Predicate Invention", "abstract": "Neurosymbolic AI approaches typically assume perfect and complete symbolic knowledge. This assumption limits their usability, as it is unrealistic in dynamic, real-world environments, particularly in domains that require both structured reasoning and perception. To address this issue, we propose a novel methodology that iteratively revises an initial imperfect logical background theory. Our approach, termed NeTheR, performs a limited number of high-impact modifications to improve the model's performance while maintaining the integrity of the original symbolic structure. Historically, theory revision has been achieved by adding or removing symbolic features to improve logical models. In contrast, NeTheR achieves this by leveraging predicate invention to introduce new neural concepts, allowing us to learn and use concepts beyond those available in the symbolic data. These high-impact modifications, like the insertion of a new neural concept into a specific part of the model, are identified using a variant of the Sharpe ratio, which measures the potential performance gains. Empirical evaluation shows that NeTheR outperforms its baseline competitors.", "tldr": "NeTheR is a neurosymbolic AI method that improves imperfect logical theories by making high-impact, structure-preserving revisions using learned neural concepts, enabling better performance in dynamic, real-world settings.", "keywords": ["Neurosymbolic AI", "Theory Revision", "Predicate Invention"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/38bf5081329e47925b265a95d7af62b67b9ce7ed.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes NeTheR (Neurosymbolic Theory Revision), which revises an imperfect propositional theory by inventing neural predicates (“neural concepts”) and making a small number of high-impact edits to an initial logic circuit M’. Candidate edits include removing literals/concepts or replacing a circuit node with a conjunction/disjunction that inserts a new neural concept. After each edit, the circuit is compiled to d-DNNF and converted to an arithmetic circuit, enabling end-to-end training of the inserted concept via backpropagation through the circuit. A dynamic Sharpe-ratio heuristic ranks edits using bounds on best/worst-case F1 improvement, with a data-driven update of \\alpha to balance risk/reward. Experiments across nine datasets (images, time series, music) show consistent gains over baselines in both biased (initial M’ close to target) and unbiased (decision-tree M’) regimes, with ablations for the selection heuristic and concept-freezing choice."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Originality (neural predicate invention for theory revision). Combines classic theory revision with modern NeSy by learning and inserting neural concepts at targeted locations, rather than only tuning predefined concepts; the dynamic Sharpe-ratio edit selection is a simple, risk-aware idea that works well in practice.\n- Quality (clear algorithm + solid evaluation). The pipeline is explicit (Algorithm 1), uses d-DNNF to enable differentiable arithmetic circuits, and includes ablations (dynamic vs. static Sharpe; freeze vs. no-freeze), critical-difference plots, and timing breakdowns.\n- Clarity (figures & examples). Fig. 1 illustrates the “insert–compile–train–rescore” loop; Fig. 2 clarifies arithmetic-circuit evaluation with neural concepts; appendices detail datasets and protocols.\n- Significance (data-efficient revisions). NeTheR improves over M’ and concept-based baselines in both biased/unbiased regimes and is robust in low-data settings; a derm7pt study with real labels shows additional promise."}, "weaknesses": {"value": "- Ecological validity of M’/targets. Main setups synthesize M^* and derive M’ by variable removal; more human-authored imperfect theories (beyond derm7pt) would strengthen real-world relevance.\n- Scalability/complexity. Each edit requires d-DNNF compilation and (often) training; search enumerates O(|\\text{circuit}|) placements. Provide scaling curves/failure cases for larger circuits and feature vocabularies.\n- Heuristic grounding. Dynamic Sharpe is effective but lacks theoretical guarantees; analyze sensitivity to \\alpha, compare with alternative acquisition rules (e.g., UCB/Thompson), and discuss robustness to mis-specification. \n- Expressivity & scope. Propositional setting and the restriction against direct nc∧nc / nc∨nc insertions may limit interactions; discuss paths to relational theories and richer compositions."}, "questions": {"value": "1. Construction/generalization of M’. Beyond derm7pt, can you include more expert-written imperfect theories? How does NeTheR handle structural mismatch (wrong connectives) vs. predicate omission?\n1. Search/compile scaling. What are typical candidate-edit counts and compilation/training times as circuit size grows? Any compile failures or memory limits? A size-vs-latency plot would help.\n1. Heuristic details. How is \\alpha_t derived from trained-concept performance, and how often is \\alpha updated before convergence? Results for alternative acquisition functions?\n1. Concept freezing. Would a final joint fine-tuning pass of all learned concepts offer further gains at reasonable cost?\n1. Interpretability. Do invented concepts admit post-hoc grounding (saliency/prototypes/symbolic correlates) on real datasets? Provide qualitative examples.\n1. Expressivity/relational lift. What is required to support first-order theories (lifted compilation, predicate sharing) while keeping search tractable?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5SeyYJFKjZ", "forum": "NnMcIU99DA", "replyto": "NnMcIU99DA", "signatures": ["ICLR.cc/2026/Conference/Submission9114/Reviewer_KUoG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9114/Reviewer_KUoG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9114/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761518476901, "cdate": 1761518476901, "tmdate": 1762920811125, "mdate": 1762920811125, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents NeTheR, a neurosymbolic framework that automatically revises imperfect symbolic knowledge by introducing learned neural concepts. Unlike existing neurosymbolic systems that assume complete and correct background theories, NeTheR iteratively modifies a given logical circuit by inserting or removing neural concepts to improve predictive performance while preserving the symbolic structure. The method formalizes three types of circuit modifications (removal, conjunction, and disjunction with neural concepts) and uses a dynamically adjusted Sharpe ratio heuristic to estimate the performance gain and risk of each modification without fully training all candidates. Through iterative selection, compilation to arithmetic circuits, and end-to-end differentiable training, NeTheR efficiently identifies high-impact refinements. Experiments on nine multimodal benchmarks demonstrate that NeTheR consistently outperforms concept-based and neural baselines in both biased and unbiased settings, showing higher F1 scores and stronger robustness in low-data regimes."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "The main strength of this paper is that it fills an important gap in the neurosymbolic learning literature by relaxing the common yet somewhat unrealistic assumption of perfect symbolic knowledge. Instead of treating background theories as fixed, NeTheR provides a principled way to revise and improve them through data-driven neural predicate invention. Although the proposed method seems relatively simple, this contribution is nonetheless meaningful and valuable. \n\nMore specifically, the method is conceptually clear and technically grounded, integrating symbolic structures with subsymbolic representations in a coherent manner. The use of a dynamic Sharpe ratio heuristic for modification selection is a sensible and interpretable design choice that balances performance improvement and reliability. The experiments are comprehensive, covering multiple modalities and settings, and consistently show that the proposed approach outperforms both symbolic and neural baselines."}, "weaknesses": {"value": "The proposed framework is conceptually clear and practical, but the method itself appears somewhat procedural and heuristic-driven. The process of iteratively modifying a logic circuit and retraining is reasonable, yet the mechanism for inserting neural concepts through conjunction or disjunction could be discussed in greater theoretical depth. The dynamic Sharpe ratio heuristic, while intuitive and empirically effective, relies on heuristic estimations of best- and worst-case performance and on an empirically updated parameter $α$, without formal analysis of its behavior. Overall, the approach is sound and well-motivated but would benefit from stronger theoretical justification and more systematic evaluation of its heuristic components."}, "questions": {"value": "Overall, I find the paper interesting but have several questions about the proposed method that may influence my final score if clarified:\n\n1. How interpretable are the neural concepts invented during the revision process, and do they correspond to meaningful properties that can be understood or verified by humans, or are they merely latent constructs optimized for prediction?\n\n2. To what extent does the revised theory differ semantically from the original one, and does this modification lead to genuinely improved reasoning quality rather than simply higher predictive accuracy?\n\n3. How stable and repeatable are the learned revisions—if the algorithm is run multiple times with the same initial theory and dataset, will it converge to similar modifications or produce highly variable outcomes?\n\n4. How does NeTheR ensure that the insertion of neural concepts does not compromise the logical consistency or interpretability of the resulting theory, especially when revisions accumulate over multiple iterations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OmpU3RsN3t", "forum": "NnMcIU99DA", "replyto": "NnMcIU99DA", "signatures": ["ICLR.cc/2026/Conference/Submission9114/Reviewer_m7zW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9114/Reviewer_m7zW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9114/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761582064630, "cdate": 1761582064630, "tmdate": 1762920809686, "mdate": 1762920809686, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors tackle the problem of neurosymbolic learning under incomplete/imperfect knowledge. They use a DeepProbLog-like setup where leaves in an arithmetic circuit are neural networks. The new idea is that the method can create and insert new neural networks into the circuit to overcome its incompleteness."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "- The task tackled is very challenging and important, and the idea of neural predicate invention is pretty novel\n- Decently positioned in existing work\n- Experimentally, the method works well on 9 datasets"}, "weaknesses": {"value": "- Unclear description of datasets and algorithms. In particular the generation of logic circuits to provide the classification task, and the  Sharpe ratio, which currently seems a bit ad hoc. \n- Missing qualitative analysis of learned circuits/neural concepts\n- If I understand correctly, the experimental setup is quite artificial, and the task may actually be quite easy. In practice it only invents 1.5 new neural concepts."}, "questions": {"value": "Major clarification requests:\n- A lot of neurosymbolic learning, like DeepProbLog, assumes no supervision on all features. Do I understand correctly that all relevant inputs are given during training? Eg, in the ATH dataset, the model gets the images and relevant attributes? \n- The 'number of modification steps to obtain $M$ from $M'$' is not tractable to compute as there might be multiple paths to obtain it. This should be changed to just the number of updates, right? I don't think this distance metric is well-defined.\n- Does every new neural concept get an entirely new neural network with the same inputs? What is to prevent the model from just learning an end-to-end classifier?\n- Data generation process: Appendix B states that for each dataset, logic circuits $M^*$ are generated which provide the output label. This process is not sufficiently explained. \n    - What are the features this logic circuit can use? Can they use also subsymbolic inputs (images)? In which case, what neural network is applied there?\n        - If they also use subsymbolic inputs: does Nether use this neural network already at initialisation? (If so, that would make the task here quite easy)\n    - How are these logic circuits generated? What is the size? \n    - The authors remove nodes from the circuit $M^*$ to generate the incomplete circuit $M'$. How is this done? Especially the algorithm for without the structural bias?\n- Please motivate the use of the critical difference diagram and cite the authors. I had to Google what these are, and they're the main experimental result.\n- The Sharpe ratio part was very hard to follow and requires more details. \n    - How is the expectation over $X_{nc}$ defined? How are $W$ and $B$ computed? \n    - How is the risk-free rate computed? How is this best modification computed?\n   - The derivation of equation 4 should be expanded (eg in the appendix). \n- Some missing references of neurosymbolic methods with rule updating (no predicate invention, I think, or applied to theory revision). \n\n\nQuestions\n- A common motivation of neurosymbolic is interpretability. What are the authors' thoughts on the interpretability of Nether?\n- Are there any qualitative results? What do these circuits look like? \n\n1. Daniele, Alessandro, et al. \"Simple and Effective Transfer Learning for Neuro-Symbolic Integration.\" International Conference on Neural-Symbolic Learning and Reasoning. Cham: Springer Nature Switzerland, 2024.\n2. Daniele, Alessandro, et al. \"Deep symbolic learning: Discovering symbols and rules from perceptions.\" arXiv preprint arXiv:2208.11561 (2022).\n3. Li, Zenan, et al. \"Neuro-symbolic learning yielding logical constraints.\" Advances in Neural Information Processing Systems 36 (2023): 21635-21657."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "N1gAVeuxIX", "forum": "NnMcIU99DA", "replyto": "NnMcIU99DA", "signatures": ["ICLR.cc/2026/Conference/Submission9114/Reviewer_5svH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9114/Reviewer_5svH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9114/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923499153, "cdate": 1761923499153, "tmdate": 1762920809096, "mdate": 1762920809096, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors tackle the problem of neurosymbolic learning under incomplete/imperfect knowledge. They use a DeepProbLog-like setup where leaves in an arithmetic circuit are neural networks. The new idea is that the method can create and insert new neural networks into the circuit to overcome its incompleteness."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "- The task tackled is very challenging and important, and the idea of neural predicate invention is pretty novel\n- Decently positioned in existing work\n- Experimentally, the method works well on 9 datasets"}, "weaknesses": {"value": "- Unclear description of datasets and algorithms. In particular the generation of logic circuits to provide the classification task, and the  Sharpe ratio, which currently seems a bit ad hoc. \n- Missing qualitative analysis of learned circuits/neural concepts\n- If I understand correctly, the experimental setup is quite artificial, and the task may actually be quite easy. In practice it only invents 1.5 new neural concepts."}, "questions": {"value": "Major clarification requests:\n- A lot of neurosymbolic learning, like DeepProbLog, assumes no supervision on all features. Do I understand correctly that all relevant inputs are given during training? Eg, in the ATH dataset, the model gets the images and relevant attributes? \n- The 'number of modification steps to obtain $M$ from $M'$' is not tractable to compute as there might be multiple paths to obtain it. This should be changed to just the number of updates, right? I don't think this distance metric is well-defined.\n- Does every new neural concept get an entirely new neural network with the same inputs? What is to prevent the model from just learning an end-to-end classifier?\n- Data generation process: Appendix B states that for each dataset, logic circuits $M^*$ are generated which provide the output label. This process is not sufficiently explained. \n    - What are the features this logic circuit can use? Can they use also subsymbolic inputs (images)? In which case, what neural network is applied there?\n        - If they also use subsymbolic inputs: does Nether use this neural network already at initialisation? (If so, that would make the task here quite easy)\n    - How are these logic circuits generated? What is the size? \n    - The authors remove nodes from the circuit $M^*$ to generate the incomplete circuit $M'$. How is this done? Especially the algorithm for without the structural bias?\n- Please motivate the use of the critical difference diagram and cite the authors. I had to Google what these are, and they're the main experimental result.\n- The Sharpe ratio part was very hard to follow and requires more details. \n    - How is the expectation over $X_{nc}$ defined? How are $W$ and $B$ computed? \n    - How is the risk-free rate computed? How is this best modification computed?\n   - The derivation of equation 4 should be expanded (eg in the appendix). \n- Some missing references of neurosymbolic methods with rule updating (no predicate invention, I think, or applied to theory revision). [1-3]\n\n\nQuestions\n- A common motivation of neurosymbolic is interpretability. What are the authors' thoughts on the interpretability of Nether?\n- Are there any qualitative results? What do these circuits look like? \n\n1. Daniele, Alessandro, et al. \"Simple and Effective Transfer Learning for Neuro-Symbolic Integration.\" International Conference on Neural-Symbolic Learning and Reasoning. Cham: Springer Nature Switzerland, 2024.\n2. Daniele, Alessandro, et al. \"Deep symbolic learning: Discovering symbols and rules from perceptions.\" arXiv preprint arXiv:2208.11561 (2022).\n3. Li, Zenan, et al. \"Neuro-symbolic learning yielding logical constraints.\" Advances in Neural Information Processing Systems 36 (2023): 21635-21657."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "N1gAVeuxIX", "forum": "NnMcIU99DA", "replyto": "NnMcIU99DA", "signatures": ["ICLR.cc/2026/Conference/Submission9114/Reviewer_5svH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9114/Reviewer_5svH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9114/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923499153, "cdate": 1761923499153, "tmdate": 1763124676669, "mdate": 1763124676669, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes NeTheR (Neurosymbolic Theory Revision) to address the common assumption in neurosymbolic AI that symbolic knowledge is perfect. NeTheR iteratively revises an initial, imperfect logical theory. Its key trick is leveraging predicate invention to introduce new neural concepts, which can learn from subsymbolic data (like images) to compensate for incomplete symbolic information. To guide this process, NeTheR uses a variant of the Sharpe ratio as a heuristic to identify and apply a limited number of high-impact modifications. The revised logic is compiled into a differentiable arithmetic circuit for end-to-end training. Empirical evaluations demonstrate that NeTheR outperforms its baseline competitors in this theory revision task."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper deals with a core limitation of Neurosymbolic (NeSy) AI, which typically assumes perfect and complete symbolic knowledge. By focusing on revising imperfect theories, the work is more applicable to real-world, dynamic environments.\n- Given the computationally impractical nature of training every possible modification, the paper proposes a novel heuristic based on a variant of the Sharpe ratio. This allows the model to efficiently identify high-impact modifications by estimating their risk-adjusted performance.\n- The experimental results show that NeTheR clearly outperforms baselines."}, "weaknesses": {"value": "- The NeTheR algorithm (Algorithm 1) relies on hyperparameter $d_{max}$. In the experimental setup, it is set to the number of systematic removals from M' to M*. However, in any real-world application, M* is not known, making it impossible to know how many removals were made to create. This method for setting $d_{max}$ is not practical, and the paper does not seem to offer a more reasonable alternative (such as setting it via cross-validation or using a performance-based early stopping criterion). \n- I am not sure if the neural concepts found via the proposed performance-driven modification method actually have real-world meaning. Do they truly correspond to concepts that are interpretable to humans (like the paper's example of learning \"whether an animal is white\"), or do they just become another uninterpretable black-box feature that is simply \"useful for classification\"?"}, "questions": {"value": "- Why does the approach focus exclusively on introducing new neural concepts? The paper dismisses inserting single symbolic concepts (\"insertion of a logical variable\") as being \"covered by traditional theory revision methods\", but it does not justify why it avoids constructing new, complex symbolic concepts from logical combinations of existing symbolic variables.\n- Does this preference for neural concepts imply that NeTheR's core value is solely in its ability to connect to subsymbolic data? If a task has no subsymbolic data (only symbolic data), is NeTheR's revision method still superior to traditional symbolic theory revision methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dwEmslmEOr", "forum": "NnMcIU99DA", "replyto": "NnMcIU99DA", "signatures": ["ICLR.cc/2026/Conference/Submission9114/Reviewer_CmQ6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9114/Reviewer_CmQ6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9114/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761929126269, "cdate": 1761929126269, "tmdate": 1762920808742, "mdate": 1762920808742, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}