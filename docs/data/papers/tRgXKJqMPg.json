{"id": "tRgXKJqMPg", "number": 12604, "cdate": 1758208916476, "mdate": 1759897499345, "content": {"title": "OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft", "abstract": "A critical challenge in developing capable AI agents is defining their \"action space''—the set of possible actions they can take. These spaces can range widely, from generating code and using language skills to operating on latent representations or raw joystick controls.\nThrough a large-scale study in Minecraft, we discovered a major dilemma: no single action space is universally best. The most effective action space is highly task-dependent, which complicates the goal of building one generalist agent that can handle everything. To solve this, we introduce Chain-of-Action (CoA), a novel framework that unifies high-level abstracted actions and low-level control actions within a single model. With CoA, an abstract goal is not just a final command; instead, it serves as an intermediate reasoning step that guides the model to generate the precise, executable actions needed to complete the task. Furthermore, we show that an \"All-in-One\" agent, trained on a diverse mix of action spaces using CoA, learns a more generalizable policy. This unified agent achieves a new state-of-the-art, outperforming strong, specialized baselines. To support the research community, we are releasing the OpenHA (Open Hierarchical Agents) suite, which includes our benchmark of over 800 tasks, curated datasets, source code, and all model checkpoints at: \\url{https://anonymous.4open.science/anonymize/OpenHA-ACFE}.", "tldr": "", "keywords": ["Hierarchical Agents", "Minecraft"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/44510fd6561745ac338f9b9ed8fba9286bc40241.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Chain-of-Action is a unified framework that integrates high-level abstract reasoning with low-level control through an intermediate “thinking” step, allowing agents to translate abstract goals into precise executable actions. Large-scale experiments in Minecraft across 1,000 tasks demonstrate that CoA enhances generalization and decision-making, outperforming specialized baselines. The authors further develop an agent trained on mixed action spaces and release the OpenHA suite to facilitate future research on hierarchical and generalizable action learning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper introduces the Chain-of-Action framework, that unifies high-level reasoning and low-level control through intermediate abstract actions. \n2. The paper presents experiments across over 1,000 Minecraft tasks and ablation analyses that convincingly demonstrate the effectiveness of CoA and the proposed All-in-One agent.\n3. The work makes a substantial contribution to the field of generalist AI agents by revealing the task-dependent nature of action spaces. The public release of the OpenHA benchmark suite further enhances the paper’s long-term impact and reproducibility."}, "weaknesses": {"value": "1. The model is still fundamentally based on Qwen2-VL, without introducing substantial architectural innovation or new pretraining strategies.\n2. From Figure 1, the proposed method shows little difference from standard VLA architectures and does not demonstrate a clear performance advantage in practice, despite its claimed end-to-end design."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GTaSYDbvCq", "forum": "tRgXKJqMPg", "replyto": "tRgXKJqMPg", "signatures": ["ICLR.cc/2026/Conference/Submission12604/Reviewer_TBv5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12604/Reviewer_TBv5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12604/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761601814656, "cdate": 1761601814656, "tmdate": 1762923451952, "mdate": 1762923451952, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents OpenHA, a family of hierarchical embodied agents in Minecraft, unified under a proposed Chain-of-Action (CoA) framework. CoA models abstract actions as intermediate “thought” tokens before producing low-level primitives, supporting both fast and slow inference modes. The authors also construct a large-scale benchmark (~800 tasks) covering embodied, GUI, and combat settings. Experiments across multiple action spaces (Skill, Grounding, Motion, Latent, Text) and an All-in-One training setup show promising transfer and efficiency benefits."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Addresses a timely and meaningful problem: unifying multiple action spaces for embodied agents.\n2. CoA offers a clear and flexible framework connecting high-level planning with low-level execution.\n3. The openness of the system (800 tasks, public code, and checkpoints promised) can benefit the community."}, "weaknesses": {"value": "1. CoA is mainly a token-level decomposition inspired by Chain-of-Thought, no new loss, optimization, or theoretical insight.\n2. The number of baselines is relatively small, causing concern about the real performance of the work.\n3. If there may exist programmatic labeling bias: the rule-based pipeline may leak structural information from expert trajectories (App. B.2).\n4. Lack of analysis of why CoA improves reasoning, and fast/slow mode trade-offs lack quantitative modeling.\n5. It is not fully clarified whether the same level of retraining or data preprocessing was applied to them. If baselines merely reuse results from the original paper (under different training conditions), comparisons may be biased.\n6. Experiments are limited to Qwen2-VL-7B, raising questions about generalizability to other LLM architectures."}, "questions": {"value": "Please refer to the Weakness for more details."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "soweRDfWZV", "forum": "tRgXKJqMPg", "replyto": "tRgXKJqMPg", "signatures": ["ICLR.cc/2026/Conference/Submission12604/Reviewer_QHFk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12604/Reviewer_QHFk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12604/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761740788060, "cdate": 1761740788060, "tmdate": 1762923451683, "mdate": 1762923451683, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper, OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft, presents a thorough investigation into the problem of action space design for agentic models. The authors propose a Chain-of-Action (CoA) framework that unifies high-level abstracted actions and low-level environmental actions under a single end-to-end formulation. Built atop this, they introduce OpenHA, a family of hierarchical agents trained and evaluated across over 800 Minecraft tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "High significance and scope – The paper tackles a fundamental but underexplored question: how should an agent’s action space be represented and unified across abstraction levels? The results have strong implications for both foundation models for agents and future generalist VLA research.\n\nChain-of-Action (CoA) formulation – The idea of modeling abstracted actions as intermediate reasoning tokens in a single autoregressive process is elegant and novel. It unifies hierarchical decomposition with the reasoning paradigm of LLMs and avoids multi-stage training limitations of classical hierarchical architectures.\n\nLarge-scale, fair evaluation – The benchmark (≈1000 tasks) and ablations (Tables 2–4) are impressively comprehensive. The authors control for token counts, use consistent pretrained backbones (Qwen2-VL-7B), and evaluate across multiple domains (embodied, GUI, combat), providing strong empirical support for their claims.\n\nOpen-source contribution – The planned release of code, data, and checkpoints is a major community contribution, filling an urgent need for reproducible baselines in embodied agent research."}, "weaknesses": {"value": "Computational cost – The unified CoA (slow mode) inference trades speed for accuracy (Table 3), but there is no discussion of scalability for real-world or multi-agent settings. Some estimate of inference-time compute (e.g., tokens/sec, cost per step) would strengthen the practicality discussion.\n\nMinecraft-centric evaluation – Although Minecraft is a flexible testbed, validation on at least one different embodiment domain (e.g., GUI interaction or robotic control) would make the generality claim more robust.\n\nLimited analysis of latent actions – The latent-action baselines are mentioned but not deeply analyzed; a closer look at learned latent embeddings and their interpretability could have further enriched the findings."}, "questions": {"value": "How sensitive is CoA’s performance to the format and tokenization of abstracted actions? Could it generalize to non-text-based or vector-quantized action codes?\n\nCould the All-in-One training be seen as a form of multi-action-space alignment analogous to multi-modal pretraining? If so, have you examined shared representations?\n\nHow are hierarchical inference modes switched dynamically at runtime? Can the agent adaptively select between fast/slow reasoning based on task complexity?\n\nHow does the CoA formulation interact with memory or trajectory length limits (e.g., 15-step working memory in Sec. C)? Does truncation degrade reasoning?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "w3cwm6vTSF", "forum": "tRgXKJqMPg", "replyto": "tRgXKJqMPg", "signatures": ["ICLR.cc/2026/Conference/Submission12604/Reviewer_tsFD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12604/Reviewer_tsFD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12604/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761846183732, "cdate": 1761846183732, "tmdate": 1762923451441, "mdate": 1762923451441, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the critical challenge of defining an effective \"action space\" for generalist AI agents in complex environments, particularly in the game of Miinecraft. The authors' finding is that no single abstracted action space is universally optimal; the most effective action representation is highly task-dependent, and they propose CoA (unifying high-level abstract actions and low-level control actions within a single, end-to-end autoregressive model) and OpenHA (grounding all diverse, high-level abstractions in the same primitive, low-level action space). The author validate them on a benchmark of over 800 tasks in Minecraft, which they also plan to release as part of their contributions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. The paper tackles a fundamental problem in agent development. The finding that \"the optimal action space is task-dependent\" is demonstrated through the large-scale experiments, which motivates the two methods proposed.\n2. In Table 4, the demonstrated fact that a single agent (OpenHA) trained on a mixture of action spaces can outperform all specialist agents is a significant result.\n3. The benchmark the author plans to release, given that it is broad and manually-verified, which includes all the codes, datasets, and model checkpoints, is a solid contribution."}, "weaknesses": {"value": "1. Only the Minecraft environment is considered. How does this method generalize to other environments? Like GUI automations or other complex games?\n2. No human evaluation of the interpretability / reasoning transparency of the “thought\" step. This remains unverified."}, "questions": {"value": "1. Why was TA chosen as the primitive representation, among others like RA?\n2. The experiments on CoA and OpenHA focus only on Motion (MotionCoA) and Grounding (GroundingCoA) actions. Skills actions like gathering wood, crafting a pickaxe, and mining stone seem like a very natural fit for the high-level \"thought\" step in the CoA framework. What are their performances on these tasks?\n3. Does the CoA framework, which requires data triplets $\\{(o_t​,A_t​,a_t​)\\}$, require more data and training to converge compared to a standard VLA model trained only on data pairs $\\{(o_t​,a_t​)\\}$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "iv7y9bDwc8", "forum": "tRgXKJqMPg", "replyto": "tRgXKJqMPg", "signatures": ["ICLR.cc/2026/Conference/Submission12604/Reviewer_gRtX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12604/Reviewer_gRtX"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12604/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761862413557, "cdate": 1761862413557, "tmdate": 1762923451134, "mdate": 1762923451134, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}