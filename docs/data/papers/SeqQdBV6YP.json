{"id": "SeqQdBV6YP", "number": 10683, "cdate": 1758179505417, "mdate": 1759897635564, "content": {"title": "InstEmb: Instruction-Following Embeddings through Look-Ahead Token Distillation", "abstract": "Recent advances have empowered large language models (LLMs) with remarkable fine-grained instruction-following capabilities in text generation tasks. However, embedding methods typically rely solely on the hidden state of the input's last token, limiting their ability to capture complete semantic signals distributed across the full output tokens. Moreover, existing discrete-to-continuous re-encoding approaches introduce semantic discontinuity. To address these limitations, we propose $\\textbf{InstEmb}$, a novel instruction following embedding framework. InstEmb jointly optimizes two key aspects: (1) primary semantic information, achieved by employing contrastive learning focused on the representation of the last input token, and (2) complementary semantic information, captured through representation distillation leveraging learnable look-ahead tokens without introducing additional decoding latency. Additionally, we introduce $\\textbf{Dual-Anchor Alignment Pooling (DAAP)}$, explicitly aligned with our dual training objectives.  Extensive experiments demonstrate that InstEmb achieves state-of-the-art performance across multiple instruction following benchmarks without benchmark-specific supervised data.", "tldr": "InstEmb enhances instruction following embeddings by jointly learning primary semantics and complementary semantics via distillation between look-ahead tokens and golden output.", "keywords": ["instruction following embedding", "representation distillation", "Contrastive Learning", "Representation Learning", "large language model"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ab8ff1784375b01fa795a4bfc16d1cf6b6198f36.pdf", "supplementary_material": "/attachment/eb38a873406a7296d6eb19850741faccd0acc003.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces and assesses a new method, InstEmb, for aligning instruction following models, using teacher-based latent representations. InstEmb uses both cumulative (last token) and granular single-token representations to capture semantic information without additional decoding steps from the teacher models."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Well scoped methodology and contribution that combines existing methods for token alignment and soft-prompting to improve instruction tuning\n- Offers clear benefits of efficiency and performance improvements on the QA datsets, and evidence for generalization across new datasets"}, "weaknesses": {"value": "Most of my concerns are around the presentation and claims of semantic information types: \n\n- Grounding of \"primary\" and \"complementary\" semantics claims \n    - It's unclear how these notions are operationalized or captured in the methodology -- there are no clear experiments of qualitative assessments that these correspond to distinct, measurable factors in the latent space;  and, \n    - The work states these two are \"jointly\" optimized but doesn't fully quantify what information is captured by each representation (e.g., L450 shows that the lookup tokens align with the answer tokens; but this to me is a bit obvious given the alignment objective) \n\n- The figures are difficult to read (see suggestions in the Questions section), and the scoring methods are unclear. I see that the authors' method excel on these metrics, but it is unclear to me what these metrics capture and how this supports the conclusion of better aligned semantics. \n    - E.g., missing explanation of nDCG@5"}, "questions": {"value": "1. What is the overlap (i.e., Fig. 2) of the look-ahead token with the last token? With the original instruction? \n2. What is the benefit of using the same model as the student and teacher? Is there a performance difference when using a stronger teacher model to distill?\n3. (Suggestion) A qualitative case study on which instructions perhaps benefit the most from the \"semantic\" information captured with this methodology.\n\nBelow are presentation suggestions and references to typos: \n- L54: \"sampling during decode\" --> decoding?\n- L260: \"strongity\" --> strength? \n- L278: Please elaborate on \"nDCG@5\" in this section\n- Fig. 1: The caption does not explain \"view1/view2\", font size on text is small and difficult to read \n- Fig. 2: The values and titles are way too small to read, please increase the font size"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "HVG6tfPjzg", "forum": "SeqQdBV6YP", "replyto": "SeqQdBV6YP", "signatures": ["ICLR.cc/2026/Conference/Submission10683/Reviewer_GAWy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10683/Reviewer_GAWy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10683/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761486928210, "cdate": 1761486928210, "tmdate": 1762921931510, "mdate": 1762921931510, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes InstEmb, a new instruction-following embedding framework that captures both primary and complementary semantics through representation distillation and supervised contrastive learning. The method introduces learnable look-ahead tokens to distill output-related semantic signals. This paper also introduces a new pooling strategy to explicitly combine both semantic signals."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper addresses the critical and timely problem of building fine-grained, instruction-adaptive embeddings for modern retrieval systems.\n\n2. The core technical approach is sound. The use of learnable look-ahead tokens coupled with representation distillation offers an elegant and efficient solution."}, "weaknesses": {"value": "1. **Incremental Conceptual Novelty:**\nWhile the proposed framework is neatly integrated, its constituent components—knowledge distillation, contrastive learning, and soft prompt-like tokens—are all well-established techniques. The contribution of InstEmb lies primarily in their combination rather than in introducing fundamentally new algorithmic or theoretical insights. As a result, the conceptual novelty may be viewed as incremental rather than groundbreaking.\n\n2. **Unclear Definition of Core Concepts:**\nThe key notions of primary semantics and complementary semantics are introduced in Section 1 without adequate clarification. This lack of explicit definition may confuse readers, as the distinction underpins much of the subsequent methodology. It appears that primary semantics correspond to the semantics derived from the input and instruction, while complementary semantics relate to the output or response information. If this interpretation is inaccurate, the authors should clarify the terminology and provide an intuitive explanation early in the paper.\n\n3. **Insufficient Justification for the Joint-Usage Hypothesis:**\nThe central claim that “both primary and complementary semantics need to be used simultaneously” is not sufficiently supported. Prior work, such as InBedder, already demonstrates the benefit of modeling complementary (output-related) semantics over primary-only embeddings (e.g., Instructor). However, the paper does not provide clear empirical evidence that combining both types yields synergistic improvements beyond using complementary semantics alone. A dedicated ablation study or comparative experiment would be necessary to substantiate this key hypothesis.\n\n4. **Missing Comparison with a Highly Relevant Baseline:**\nThe related work and experimental sections overlook an important recent study, “*Don’t Reinvent the Wheel: Efficient Instruction-Following Text Embedding based on Guided Space Transformation*” (ACL 2025), which also targets instruction-aware embedding optimization. Since that work addresses a conceptually similar problem using a geometric transformation approach, a comparison—either qualitative or empirical—would help position InstEmb more precisely within the current research landscape and highlight its distinct contributions."}, "questions": {"value": "1. Given that InstEmb primarily combines known techniques (knowledge distillation, contrastive learning, and soft prompt tuning), what aspects of the framework should be considered conceptually new beyond this integration?\n\n2. Could the authors provide a clearer and more formal definition of primary semantics and complementary semantics, ideally with illustrative examples, to help readers understand how these two components differ and interact?\n\n3. Are there specific ablation studies or quantitative results demonstrating that using both primary and complementary semantics jointly leads to better performance than using either alone?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dyyGtAN1I8", "forum": "SeqQdBV6YP", "replyto": "SeqQdBV6YP", "signatures": ["ICLR.cc/2026/Conference/Submission10683/Reviewer_BmMX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10683/Reviewer_BmMX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10683/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761844040370, "cdate": 1761844040370, "tmdate": 1762921931084, "mdate": 1762921931084, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes InstEmb, an instruction-following embedding framework designed to enhance semantic adaptability in text embeddings derived from large language models (LLMs). The framework jointly optimize primary semantics via contrastive learning focused on the final input token and complementary semantics via representation distillation from a frozen teacher model, using learnable look-ahead tokens that emulate future output semantics without incurring decoding latency. The framework also fuses the last-input-token and look-ahead-token representations to better align training objectives with inference-time embeddings.\n\nExpriments on instruction-following benchmarks (FollowIR, Inst.STSb, IntentEmotion, NYTCluster) and generic sentence embedding tasks (MTEB subset) show that InstEmb achieves strong results compared to baselines such as InBedder, FollowIR, and Promptriever. The paper also includes ablations on distillation methods, contrastive views, pooling strategies, and training datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe paper proposes an efficient framework that trains an instruction-following embedding model in a single LLM pass, offering a clean and practical solution.\n2.\tThe experimental section is extensive, covering both instruction-following and generic embedding benchmarks with strong baselines. The ablation studies provide insights into design choices.\n3.\tThe motivation to bridge the gap between instruction-following generation and embedding representation is well articulated and timely. The authors clearly identify two limitations of existing embedding methods and directly address them through an well-designed framework."}, "weaknesses": {"value": "1.\tThe current ablation studies on contrastive learning (§5.2) are conducted on top of the representation distillation module, without providing clear comparisons between the two modules individually. A proper factorial ablation (e.g., SFT + Distillation vs. SFT + Contrastive) would better reveal which component contributes more to the overall gain.\n\n2.\tTeacher–student configuration not sufficiently explored. As described in Appendix A.1, both the teacher and one student model share the same base architecture (LLaMA-3-8B-Instruct). No experiments are conducted with a larger or more capable teacher model, making it unclear whether the observed improvements stem from the proposed framework or from the inherent capacity of the backbone model.\n\n3.\tThe number of look-ahead tokens is fixed to 8 throughout all experiments, without any sensitivity or scaling study. It is therefore uncertain how this hyperparameter affects model performance, training stability, or inference efficiency.\n\n4.\tSection 5.5 mentions training with the MS-MARCO dataset, which lacks explicit instruction fields. It remains ambiguous how instruction semantics are preserved — is the question field treated directly as the instruction? \n\n5.\tSome related works are missing which should be discussed, used as baseline or evaluation [1-7].\n\n[1] Oh, Hanseok, et al. \"Instructir: A benchmark for instruction following of information retrieval models.\" arXiv preprint arXiv:2402.14334 (2024).\n\n[2] Yoo, Young Hyun, et al. \"Hyper-CL: Conditioning Sentence Representations with Hypernetworks.\" Proceedings of the Annual Meeting of the Association for Computational Linguistics. Vol. 1. Association for Computational Linguistics (ACL), 2024.\n\n[3] Sun, Weiwei, et al. \"MAIR: A Massive Benchmark for Evaluating Instructed Retrieval.\" Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. 2024.\n\n[4] Zhou, Jianqun, et al. \"Beyond Content Relevance: Evaluating Instruction Following in Retrieval Models.\" The Thirteenth International Conference on Learning Representations.\n\n[5] Feng, Yingchaojie, et al. \"Don't Reinvent the Wheel: Efficient Instruction-Following Text Embedding based on Guided Space Transformation.\" arXiv preprint arXiv:2505.24754 (2025).\n\n[6] Yamada, Kosuke, and Peinan Zhang. \"Out-of-the-Box Conditional Text Embeddings from Large Language Models.\" arXiv preprint arXiv:2504.16411 (2025).\n\n[7] Zhang, Gaifan, Yi Zhou, and Danushka Bollegala. \"CASE--Condition-Aware Sentence Embeddings for Conditional Semantic Textual Similarity Measurement.\" arXiv preprint arXiv:2503.17279 (2025)."}, "questions": {"value": "1.\tCould you provide results comparing SFT + Distillation and SFT + Contrastive training separately, to determine which module contributes most to the improvements?\n\n2.\tWhy was the teacher model kept similar in scale to the student? Have you tried a larger teacher, or could you comment on how performance might scale with teacher capacity?\n\n3.\tHave you explored varying the number of look-ahead tokens (e.g., 4, 8, 16)? Does the performance plateau or degrade as this number changes?\n\n4.\tRegarding the MS-MARCO experiments (§5.5), since the dataset lacks explicit instructions, do you treat the query text as the instruction itself? If so, how can the model still learn genuine instruction-following behavior rather than mere query encoding?\n\n5.\tWould combining datasets with and without explicit instruction fields affect the generalization ability of InstEmb?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JBCUVfBxFF", "forum": "SeqQdBV6YP", "replyto": "SeqQdBV6YP", "signatures": ["ICLR.cc/2026/Conference/Submission10683/Reviewer_xd92"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10683/Reviewer_xd92"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10683/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761925164644, "cdate": 1761925164644, "tmdate": 1762921929946, "mdate": 1762921929946, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}