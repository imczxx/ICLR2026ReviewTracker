{"id": "QobJeymX6Z", "number": 9765, "cdate": 1758139049958, "mdate": 1759897699738, "content": {"title": "HERON: Human-robot collaboration with Efficient and Resilient OptimizatioN for Long-horizon planning", "abstract": "The integration of humans into long-horizon planning introduces unique challenges that extend beyond conventional robotic task planning. Unlike robots, humans exhibit inherent uncertainty in task execution, including variable performance, unexpected interruptions, and dynamic goal changes, all of which complicate efficient collaboration. To address these challenges, we propose Human-robot collaboration with Efficient and Resilient OptimizatioN for Long-horizon planning (HERON), a novel framework that combines large language models (LLMs), physics-guided reasoning, and optimization techniques. HERON leverages LLMs in two complementary roles: (i) decomposing natural language task descriptions into structured sub-tasks with agent assignments, and (ii) generating physics-guided execution time estimates and determining sub-task assignments for both human and robot agents based on physical constraints and complementarities. These outputs are incorporated into a mixed-integer linear programming scheduler, which dynamically re-schedules based on observed human uncertainties. This integration ensures that scheduling is not only feasible with respect to physical limitations but also robust to human unpredictability while maintaining efficiency in resource and time allocation. Experiments demonstrate that HERON enables resilient and adaptive human-robot collaboration, achieving more efficient scheduling and higher task success rates compared to existing LLM-based planning frameworks. Website at https://sites.google.com/view/heron-planner.", "tldr": "A framework that combines LLM-based task decomposition, physics-guided estimation, and MILP optimization to enable efficient and resilient human–robot collaboration under uncertainty.", "keywords": ["Human-Robot Collaboration", "Long-Horizon Planning", "Task Scheduling"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8483342904149ee147decbb3006104fe5f6a291f.pdf", "supplementary_material": "/attachment/c0fa68634bf257dcd3b192ea6841103bcf745ee8.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces HERON which is a framework to create efficient and robust long-horizon schedules for human robot collaboration by explicitly accounting for human uncertainty. The framework consists of three sequential modules operating in an iterative loop: \n\n1. Task Decompostion LLM: This translates natural language goal into a structured task graph of sub-tasks and dependencies.\n2. Physics-guided LLM: Augments each sub-task with an estimated execution time and an optimal agent assignment, reasoning over physical constraints and cost.\n3. MILP Optimizer: Generates an optimal schedule by solving a Mixed-Integer Linear Program that minimizes cost over makespan and workload distribution, while enforcing all temporal and resource constraints.\n\nA continuous Verifying Stage monitors execution, detects human uncertainty events, and triggers dynamic re-planning by re-entering the planning loop. Experiments across four complex kitchen tasks in the AI2-THOR simulation demonstrate that HERON achieves a 45% higher success rate and a 13% reduction in schedule timespan compared to existing LLM-based planning baselines (SMART-LLM, LiP-LLM, LLaMAR)"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The framework is fundamentally designed to be resilient and uncertainty-aware, explicitly modeling and dynamically re-scheduling in response to three categories of human stochasticity: performance variability ($\\xi_1$), interruptions ($\\xi_2$), and dynamic goal changes ($\\xi_3$) which makes it more realistic.\n\n2. The overall quality of the evaluation is strong, rigorously comparing HERON against multiple relevant LLM-based planning baselines (SMART-LLM, LiP-LLM, LLaMAR) and validating performance across four task structures (parallel, sequential, hybrid).\n\n3. Ablation studies clearly demonstrate the necessity of both the Physics-guided LLM (although the validity of a physics-guided LLM in this paper is questionable, see weaknesses+questions) and the MILP Optimizer for sustaining high success rates and achieving temporal efficiency, confirming that dynamic planning alone is insufficient."}, "weaknesses": {"value": "major weaknesses:\n\n1. The paper acknowledges that the execution time estimates ($\\hat{t}_i$) generated by the physics-guided LLM were not quantitatively benchmarked against realistic human or robot measurements. Without this quantitative validation, the claim that the LLM generates \"realistic\" times remains qualitative. Since the entire MILP optimization relies on these $\\hat{t}_i$ values to minimize makespan, errors in the LLM's time estimates could lead the optimizer to generate a schedule that is optimal mathematically but suboptimal in reality.\n2. The qualitative failure modes note that the Task Decomposition LLM sometimes produces unnecessarily strict or redundant dependency constraints. This forces parallelizable tasks to execute sequentially, which is likely the core reason why the total timespan (TI) for HERON in some complex tasks (like Task 3) is still quite long compared to the makespan of the purely symbolic LLM baselines (though the Success Rate is higher). This highlights an unaddressed brittleness in the initial LLM parsing step."}, "questions": {"value": "1. Could the authors provide a simulation experiment where the $\\hat{t}_i$ values generated by the Physics-guided LLM are replaced with values drawn from a Uniform distribution or a simpler analytical model (like the ones used in the prompts, $t=s/(2a)$ for robot travel), and compare the resulting metrics? This would quantitatively isolate the benefit provided by the LLM's \"common-sense\" time estimation from the pure benefit of the MILP solver.\n2. How does the complexity of solving the MILP scale with the number of sub-tasks ($N$)? Since HERON performs dynamic re-planning based on perceived human behavior, the solver must return a new optimal schedule almost instantaneously. Could the authors provide re-planning time vs. $N$ plots to assure the real-time feasibility of the approach, or state the average and max computation times observed during dynamic re-planning?\n3. The paper mentions that VLM-based monitoring to automatically detect performance Variability ($\\xi_1$) lies beyond the current scope but is a future direction. Given that the human only provides feedback on actual completion time $t^{act}_i$ after the robot completes its first task, why not use a simpler form of VLM integration now? For instance, a VLM could visually monitor the human's progress on an assigned task (e.g., slicing a vegetable) to determine if they are currently engaged in the task, allowing for more proactive detection of a slow down $\\xi_1$ *before* the robot completes its step.\n4. While the $C(\\mathcal{S})$ objective function includes a workload distribution term ($\\lambda_{2} \\cdot \\sum \\sum x_{i,a} \\hat{t}_i(a)$), and the failure cases mention scenarios where the robot is idle, the resulting Balance (B) metric for HERON is often lower than LLaMAR's (e.g., Task 3: HERON is 0.56 vs. LLaMAR is 0.80). Please elaborate on the choice of weighting parameters $\\lambda_1$ and $\\lambda_2$. Were these chosen to strictly prioritize minimizing the makespan ($\\lambda_1$) over achieving a balanced workload ($\\lambda_2$), and would altering this trade-off significantly impact the overall success rate?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "W36xAi89Uw", "forum": "QobJeymX6Z", "replyto": "QobJeymX6Z", "signatures": ["ICLR.cc/2026/Conference/Submission9765/Reviewer_Qpzk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9765/Reviewer_Qpzk"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9765/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761858294121, "cdate": 1761858294121, "tmdate": 1762921257002, "mdate": 1762921257002, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenges of long-horizon planning in human-robot collaboration (HRC), specifically focusing on the inherent uncertainty of human partners, such as variable performance, unexpected interruptions, and dynamic goal changes. The authors propose HERON (Human-robot collaboration with Efficient and Resilient Optimization for Long-horizon planning), a novel framework that integrates LLMs with formal optimization techniques.\n\nThe HERON framework operates in a continuous loop: 1. Task Decomposition LLM first translates a human's natural language instruction into a set of structured sub-tasks with temporal dependencies. 2. Physics-guided LLM then enriches this plan by estimating execution times (EETs) and assigning each sub-task to either the human or robot, based on physical constraints, kinematics, and agent capabilities. 3. Mixed-Integer Linear Programming (MILP) Optimizer takes this enriched plan and generates a schedule that is optimized for efficiency.\n4.  A Verifying Stage monitors execution. When it detects a human uncertainty event—either through verbal feedback from the human or by comparing EETs—it triggers a dynamic re-planning step, feeding updated information back to the optimizer to generate a new, resilient schedule.\n\nExperiments conducted in the AI2-THOR simulator on complex, multi-step kitchen tasks demonstrate that HERON achieves higher success rates and more efficient scheduling (shorter timespans) compared to other LLM-based planning baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "A major strength is the framework's hybrid architecture. It intelligently leverages LLMs for their semantic understanding and decomposition capabilities (Stage 1) , while offloading the formal scheduling and constraint satisfaction to a classical MILP optimizer (Stage 3). This approach avoids the common pitfalls of pure-LLM planners, which often struggle with physical constraints, resource optimization, and efficiency . The ablation study (w/o-MILP) confirms that the optimizer is essential for achieving efficient schedules.\n\nThe concept of the \"Physics-guided LLM\" is a novel and powerful contribution. By forcing the LLM to reason about kinematics, actuation limits, and navigation costs before assigning tasks, the system generates plans that are physically feasible. The ablation (w/o-pLLM) strongly supports this, showing that a naive LLM assigns infeasible tasks to the robot (e.g., slicing, using fire), leading to a sharp decline in success rate.\n\nThe framework is not a static, one-shot planner. The verifying stage and re-planning loop make the system adaptive. The qualitative example in Figure 2, which shows the system gracefully handling both a performance deviation and an interruption   by re-scheduling the plan, is a compelling demonstration of the system's resilience ."}, "weaknesses": {"value": "The paper's most significant weakness is its evaluation. Despite being a paper on Human-Robot Collaboration, the framework was never tested with an actual human. The \"human\" is a stochastic simulation whose behavior is modeled by simple probability distributions (Normal, Bernoulli, Uniform) . The paper acknowledges this limitation in the appendix, stating, \"Validation is limited to simulation: no human-in-the-loop user studies\". This makes all claims about \"resilience to human unpredictability\" purely theoretical, as the simulated human is far less complex and more predictable than a real person.\n\nThe \"Verifying Stage\" is not an autonomous monitoring system. The paper's methodology reveals that detection of all three uncertainty types relies entirely on the human verbally communicating them to the robot.\n\nThe paper claims superior efficiency (Timespan) over baselines like SMART-LLM and LLaMAR. However, HERON is the only framework that incorporates a MILP optimizer specifically designed to \"minimize makespan\". The baselines are primarily LLM-driven planners that do not perform such rigorous optimization. The \"w/o-MILP\" ablation confirms this, showing that removing the optimizer significantly increases the Timespan. Therefore, the efficiency gains may not stem from a superior planning approach but simply from the fact that HERON uses an optimizer while the baselines do not."}, "questions": {"value": "1. The current verifying stage seems entirely passive, requiring the human to verbally report all performance deviations, interruptions, and goal changes. How does this reliance on explicit human self-reporting scale to real-world scenarios where a human might be distracted, forget to report a delay, or not know how to quantify their own performance deviation?\n\n2. This module estimates execution times by reasoning over physical constraints. Is the LLM performing symbolic calculations based on the provided physics formulas, or is it making \"common-sense\" estimations informed by those specs? If it's performing calculations, how do you ensure the LLM's numerical and physical reasoning is accurate and reliable?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LezubAQEed", "forum": "QobJeymX6Z", "replyto": "QobJeymX6Z", "signatures": ["ICLR.cc/2026/Conference/Submission9765/Reviewer_tXeB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9765/Reviewer_tXeB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9765/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959009140, "cdate": 1761959009140, "tmdate": 1762921256613, "mdate": 1762921256613, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents HERON, a framework for long-horizon human–robot collaboration (HRC) that integrates large language models (LLMs), physics-based reasoning, and mixed-integer linear programming (MILP). HERON decomposes a natural language task into structured sub-tasks via an LLM-based task graph generator, estimates execution time and agent assignment using a physics-guided LLM, and computes an optimized task schedule with MILP. The system further monitors execution to handle human uncertainties such as performance variability, interruptions, and dynamic goal changes through re-planning. Experiments in simulated household tasks show improved task success rate and efficiency compared to existing LLM-based planners."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper formalizes LLM-based task decomposition into a structured graph representation, bridging natural language reasoning and symbolic planning.\n\n2. The physics-guided time estimation and MILP optimization provide a principled way to achieve physically feasible and efficient task allocation between humans and robots.\n\n3. The system’s ability to handle failures, interruptions, and goal changes through iterative re-planning is a meaningful advancement toward resilient HRC."}, "weaknesses": {"value": "1. The task decomposition LLM relies on structured scene descriptions (object lists, coordinates) that must be provided explicitly. This limits HERON’s applicability to simulators or digital twins, since real-world visual perception rarely yields such clean symbolic input.\n\n2. The time estimation (EET) module’s accuracy and reliability are not evaluated. There is no ablation or comparison between predicted and actual execution times, making it unclear how critical or accurate this module is to system performance.\n\n3. The experiments are limited to simulation (AI2-THOR) with synthetic human models. The real-world robustness of HERON, especially given its reliance on structured metadata rather than sensory input, remains unproven."}, "questions": {"value": "1. How robust is HERON if the environment description \\$\\mathcal{E}\\$ is noisy or incomplete — for instance, if certain object attributes or coordinates are missing? Could the Task Decomposition LLM still produce usable task graphs?\n\n2. Have you quantitatively evaluated the EET predictions against measured execution times in simulation? \n\n3. How costly is each re-planning cycle?\n\n4. Do you envision extending HERON to handle raw visual or multimodal inputs (e.g., VLM-based grounding) to overcome dependence on symbolic scene JSONs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "C3tCxF49mi", "forum": "QobJeymX6Z", "replyto": "QobJeymX6Z", "signatures": ["ICLR.cc/2026/Conference/Submission9765/Reviewer_Gs3j"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9765/Reviewer_Gs3j"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9765/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762237323056, "cdate": 1762237323056, "tmdate": 1762921256284, "mdate": 1762921256284, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a framework called HERON (Human-Robot Collaboration with Efficient and Resilient Optimization for Long-Horizon Planning) for long-horizon human-robot collaboration. The framework uses an LLM to decompose natural language task descriptions into subtasks and agent assignments, and another LLM to generate physics-guided execution time estimates and determine task assignments for the human and robot. The framework then uses a mixed integer linear programming (MILP) scheduler to dynamically reschedule task allocation based on observed human uncertainties in the form of variable performance, unexpected interruptions, and dynamic goal changes. The authors evaluate their framework on a set of human-robot collaboration settings by comparing performance with various LLM-based baselines and performing ablation studies."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "(i) The paper focuses on the important problem of long-duration planning in human-robot collaboration, particularly in the context of multiple sources of uncertainty.\n\n(ii) The framework considers various (kinematic, actuation, task dependency, feasibility) constraints in computing the initial ordering the tasks and an updated schedule when needed."}, "weaknesses": {"value": "(i) The paper makes claims that are incorrect or unsubstantiated. For example, the paper identifies three sources of uncertainty associated with the human (variable performance, unexpected interruptions, and dynamic goal changes), but robots also exhibit these uncertainties. Also, there is a rich literature of prior work in robot planning that considers models of such uncertainties and replans as needed. Another example is the discussion of related work, where authors highlight the limitations of using LLMs to predict long-horizon plans but then do not consider the decades of research in robotics on generating such plans for robots collaborating with humans. In addition, the authors' approach to identifying uncertainty is essentially outcome monitoring and rescheduling, capabilities that are supported by many existing planners.  \n\n(ii) The justification for the design choices (made in this paper) is unclear; the approach seems to be to use LLMs for every possible component of the framework even when this is not really the correct choice. For example, the framework uses considerable prior knowledge of environment state and dynamics in the task decomposition LLM; if such prior knowledge exists, why use an LLM for the task decomposition instead of the many existing methods in classical planning that do not have the limitation displayed by LLMs in long-duration planning? The use of the physics-guided LLM makes even less sense; when the estimated execution time (EET) is based on kinematic and actuation constraints, why not use simple functions and probabilistic models of uncertainty instead of an LLM? In particular, the use of an LLM to compute values of parameters of various distributions is rather strange. \n\n(iii) Following up on previous point, given the cost function used in this paper for the MILP scheduler, a classical/probabilistic AI planner could have been used instead of the framework described in this paper. Such a planner would have supported all the capabilities of the proposed framework while also providing performance guarantees and requiring much less resources (time, computation, storage etc).\n\n(iv) The experimental evaluation is limited to LLM-based systems developed in the last couple of years; there is no attempt to compare performance with other ways in which the target problem could have been addressed."}, "questions": {"value": "Please address questions and comments in the \"Weaknesses\" section above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ZKi35uTmjY", "forum": "QobJeymX6Z", "replyto": "QobJeymX6Z", "signatures": ["ICLR.cc/2026/Conference/Submission9765/Reviewer_KGwg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9765/Reviewer_KGwg"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9765/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762916789567, "cdate": 1762916789567, "tmdate": 1762921255976, "mdate": 1762921255976, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}