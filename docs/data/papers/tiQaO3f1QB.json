{"id": "tiQaO3f1QB", "number": 1720, "cdate": 1756911954724, "mdate": 1763112575195, "content": {"title": "PRISM: A Paradigm for Controllable 3D Generation Driven by Structural Concept Prior", "abstract": "The generation of high-quality 3D assets is essential for applications in virtual reality, robotics, and industrial systems. \nExisting methods can be sorted into three categories based on different priors. \nThe first lines\nlift 2D diffusion as priors into 3D representations.\nThe second lines adopt ground truth multi-view images as priors to directly regress 3D assets.\nThe third lines tend to model the probabilistic distribution of 3D assets,\nwhich adopt 3D distribution as their priors.\nHowever, those three types of priors are in semantic level. \nThey can represent semantic information but ignore the structural concept (describing the topological structures), which is crucial in the physical world applications.\nTo address this limitation, we propose a novel 3D generation paradigm, called \nPrism (a paradigm driven by structural concept), which leverages structural concept as priors.\nFirst, our method encodes structural concept which is fused with real-world images to form prior representations, enabling the model to integrate high-level structural concept priors while guaranteeing shape details from real-world images.\nThen we adopt a pre-trained VAE encoder to provide embeddings of real 3D models.\nAfter that, we employ consistency loss in the latent space to align our priors with real 3D models to achieve mapping between concept space and 3D space, ensuring the generated 3D assets are structurally coherent, aligned with affordance, and visually realistic.\nPrism provides a high shape quality and structure controllable solution for 3D synthesis.\nWe validate our method on both vision and robotics aspects with state-of-the-art algorithms.\nOur code will be public available.", "tldr": "", "keywords": ["Controllable 3D generation", "Structural Concept", "DiT"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/82c5fbd29c421455b78e9d8a1cdd205162f51a5b.pdf", "supplementary_material": "/attachment/357a27436e5c5b0060af81b52967e0551ec6c1fe.zip"}, "replies": [{"content": {"summary": {"value": "PRISM: A Paradigm for Controllable 3D Generation Driven by Structural Concept Prior introduces a novel 3D generation framework that prioritizes structural concept prior over traditional semantic priors. The authors argue that existing methods—which rely on 2D diffusion lifting, multi-view image regression, or native 3D distribution modeling—excel in visual realism but fail to offer precise control over an object's topological structure and affordance (i.e., how it can be interacted with). To address this, PRISM leverages Analytic Concept, a procedural language that describes objects in terms of their geometric primitives, topological relationships, and functional affordances."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Introduction of a Novel and Meaningful Prior: The \"Structural Concept\"\n\nThe most significant contribution of PRISM is its conceptual shift from purely appearance-driven priors to a structural and functional prior.\n\nBeyond Semantics: Existing priors answer \"what is this?\" (a chair) or \"what does it look like?\". The structural concept prior answers \"how is this built?\" and \"how is it used?\". It encodes topological constraints (e.g., a chair must have a back support connected to a seat) and affordance knowledge (e.g., a mug handle is graspable). The paper operationalizes this abstract prior through Analytic Concept (Sun et al.), which uses a procedural, mathematical language to define objects. For example, a bucket is not just a cylinder; it is defined as a cylindrical_body connected to a regular_handle with specific spatial constraints. This provides a formal, computable representation of structure.\n\n2. Effective Fusion of Heterogeneous Priors for Multi-Faceted Control\n\nDual Control Mechanism: The framework is designed to control two distinct aspects simultaneously:Topological Structure: Governed by the Analytic Concept (via conceptual images C_i and text descriptions C_t). Shape Details & Realism: Governed by real-world images R_i, which provide rich, realistic textural and stylistic information. This multi-modal fusion is the key to why PRISM works. The ablation study in Figure 7 shows that removing either the real-world image (resulting in a bland, overly schematic output) or the structural concept (resulting in a structurally incorrect output) leads to failure. Only their combination produces high-fidelity, structurally correct assets."}, "weaknesses": {"value": "1. Limited Scope and Scalability: A Method for Simple, Structured Objects\n\nThe most significant limitation of PRISM is its confinement to a domain of relatively simple, parametric, and part-based objects, which raises questions about its generalizability.\n\nNarrow Dataset (PartNet): The model is trained and evaluated exclusively on the PartNet dataset, which contains categories like chair, table, mug, and trash can. These objects are inherently decomposable into a small set of geometric primitives (cuboids, cylinders) and are well-suited for description via Analytic Concept.\n\nStruggle with Organic and Complex Geometry: The paradigm appears ill-suited for a vast array of real-world objects that lack a clear, hierarchical part structure. How would PRISM handle:\n\nOrganic Forms: A human face, a sculpted statue, a tree, or a crumpled piece of paper.\n\nComplex Topology: A intricate piece of jewelry, a bike chain, or a tangled set of cables.\n\nNon-Rigid Objects: A cloth, a plush toy, or a liquid.\nThe Analytic Concept library would be incredibly difficult, if not impossible, to define for such categories. The paper's approach is fundamentally tied to a procedural modeling mindset, which breaks down for highly complex or organic shapes.\n\n2. Insufficient Demonstration on Complex Categories\n\nThe experiments, while showing clear improvements on simple objects, do not convincingly prove that the method handles \"complex\" cases within its own domain.\n\n\"Complex\" is Relative: The paper claims to use a \"complex test dataset,\" but this is self-collected and still consists of the same PartNet categories (e.g., storage furniture, refrigerators). A truly complex example for this method would be a multi-drawer cabinet with intricate handles, a multi-functional tool, or a complex mechanical assembly.\n\nLack of Testing on complex objects: The qualitative results (e.g., Figures 4, 11-15) primarily showcase success on objects with low part-count. There is no demonstration of its performance on the most structurally dense objects within PartNet (e.g., a detailed lamp with many arms or a complex workstation). The failure cases of PRISM itself are not shown, making it difficult to assess its true boundaries.\n\nComparison is Unfair to More General Models: PRISM is compared against general-purpose 3D generators (InstantMesh, TRELLIS) that are not designed for structural control. A more telling comparison would be against other structure-aware or CAD-generation methods (e.g., those in neurosymbolic synthesis). Dominating general models on a structured-object-specific task is expected, not revolutionary.\n\n3. Heavy Reliance on a Niche and Costly Annotation System\n\nThe entire paradigm is dependent on the existence of Analytic Concept annotations.\n\nBottleneck for Scalability: Creating Analytic Concept descriptions for a 3D model is a highly specialized and labor-intensive task, requiring expert knowledge to define the procedural rules, primitives, and constraints. This severely limits the potential to scale the training set to internet-scale datasets like Objaverse.\n\nThe \"Automation\" Claim is Weak: The paper mentions using an LLM (GPT-4o) to convert procedures into language descriptions"}, "questions": {"value": "1. Limited Scope and Scalability: A Method for Simple, Structured Objects\n2. Insufficient Demonstration on Complex Categories\n3. Heavy Reliance on a Niche and Costly Annotation System"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "6Jh4ay0zym", "forum": "tiQaO3f1QB", "replyto": "tiQaO3f1QB", "signatures": ["ICLR.cc/2026/Conference/Submission1720/Reviewer_QicA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1720/Reviewer_QicA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1720/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760458174697, "cdate": 1760458174697, "tmdate": 1762915867602, "mdate": 1762915867602, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "uAT2xIYDgc", "forum": "tiQaO3f1QB", "replyto": "tiQaO3f1QB", "signatures": ["ICLR.cc/2026/Conference/Submission1720/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1720/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763112574399, "cdate": 1763112574399, "tmdate": 1763112574399, "mdate": 1763112574399, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper claims to present a new paradigm for controllable 3d generation driven by Analytic Concept prior. The Analytic Concept scripts are encoded together with their corresponding real-world and rendering images to condition a 3D DiT generation process. Experiments on PartNet shows better metrics in terms of reconstruction and generation, in comparison with image-to-3D generation baseline methods like Trellis, InstantMesh and Craftsman."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "N/A"}, "weaknesses": {"value": "- Overall, I think this paper is poorly written, see typos below. And there exist many vague and imprecise descriptions. For example, \"a novel prior representation ... one-to-one correspondence\" as mentioned in the last paragraph of Section 1 is quite confusing. First of all, what is a \"prior representation\"? Is it the training pairs mentioned in Line 256 or is it the DiT? Moreover, the training pairs are not one-to-one corresponded since it is an ill-posed monocular image reconstruction task.\n- The claimed \"topological structure\" ability is not proved anywhere in the experiments. The metrics FID, CD, and Uni3D are general reconstruction/generation metrics. Moreover, I do not see much topological error for trellis results. These all weaken the contribution and importance of the proposed method.\n- The claimed affordance knowledge is brought by the Analytic Concept scripts, not something embedded in the 3d generation process.\n- The applicability of the proposed method is questionable, since it requires very complex Analytic Concept scripts and their renderings as input. These are generally not accessible to real world use cases.\n- The experiment scale is too small, only on PartNet. There could be serious overfitting issues considering the similarity inside each category of PartNet. And are baselines also trained on the PartNet training set or authors just inference their pretrained weights?\n- Only rigid objects can be generated. The articulation is not explored, for example, the microwave in Figure 2 has a door that can be manipulated. But the proposed method fails to consider this. In Figure 4, it seems like the door of the microwave is not even separable from the main body. How is this considered as topologically correct, considering the fact that very detailed Analytic Concept scripts are used as inputs?\n\nTypos:\n- Line 30: will be public\"ly\" available\n- Line 124: duplicate \"in procedures\"\n- Line 124: \"And can render ...\" no subject in this sentence\n- Misuse of \\citet and \\citep, e.g., line 204, 291, section 4.1, and many more...\n- Line 368, 5e-5 => 5\\times{}10^{-5}"}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ChOSE33VJt", "forum": "tiQaO3f1QB", "replyto": "tiQaO3f1QB", "signatures": ["ICLR.cc/2026/Conference/Submission1720/Reviewer_22LA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1720/Reviewer_22LA"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1720/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761458149590, "cdate": 1761458149590, "tmdate": 1762915867458, "mdate": 1762915867458, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "PRISM introduces a new paradigm for controllable 3D generation that uses structural concept priors—derived from Analytic Concept—to generate 3D assets that are both visually realistic and structurally coherent. Unlike existing 3D generation methods that rely on semantic or appearance priors, PRISM emphasizes topological structure control and affordance knowledge, aiming to make generated objects more interpretable and functionally grounded for downstream applications such as robotics or simulation. The proposed framework integrates three main components: Prior Representation Construction, Shape Encoding, and 3D Space Mapping."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper introduces a formalized structural concept prior derived from Analytic Concept is innovative. It extends the representation of 3D generation beyond appearance or semantics to include procedural topology and affordance reasoning. The usage of a diffusion transformer for latent alignment to learn a one-to-one mapping from symbolic concept space to geometric 3D latent space is also interesting.\n2. The paper validates both visual realism and physical interpretability (robotic manipulation in simulation), covering both perceptual and functional dimensions.\n3. PRISM achieves SOTA quantitative scores and visibly improved topology consistency compared to InstantMesh, CraftsMan, and Trellis."}, "weaknesses": {"value": "1. The author should use \\citep{} rather than \\cite{} in many places, for example in “Neural Radiance Fields (NeRF) Mildenhall et al. (2021)”. The incorrect citation format leads to inconsistent and unprofessional typesetting.\n2. The experiments focus on PartNet and small-scale manipulation scenes. How about the generalization to more complex 3D objects, such as the teaser objects in Trellis?\n3. Given that Analytic Concept annotations are handcrafted, how scalable is PRISM to diverse object categories lacking such procedural definitions?\n4. Can PRISM-generated models be directly integrated into embodied policy learning frameworks (e.g., manipulation or grasp planning) beyond visualization-level simulation?"}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "C1m7i8fNQZ", "forum": "tiQaO3f1QB", "replyto": "tiQaO3f1QB", "signatures": ["ICLR.cc/2026/Conference/Submission1720/Reviewer_1Bqb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1720/Reviewer_1Bqb"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1720/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761887065115, "cdate": 1761887065115, "tmdate": 1762915867308, "mdate": 1762915867308, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}