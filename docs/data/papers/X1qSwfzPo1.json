{"id": "X1qSwfzPo1", "number": 14593, "cdate": 1758239605013, "mdate": 1759897360551, "content": {"title": "Achieving Fairness-Utility Trade-offs through Decoupling Direct and Indirect Bias", "abstract": "Fairness in regression tasks is critical in high-stakes domains such as healthcare, finance, and criminal justice, where biased predictions can lead to unequal treatment. Bias can arise both directly, when sensitive attributes explicitly influence predictions and indirectly, when predictors correlated with sensitive attributes act as proxies. Existing fairness-aware regression methods often fail to address both forms of bias simultaneously, or sacrifice predictive performance. We propose Fair Envelope Regression Models (FERM), a novel framework that brings structure-aware subspace decomposition techniques from envelope regression into fairness-aware learning. FERM decomposes the predictor space into four orthogonal components: variation uniquely informative about the response, variation associated with sensitive attributes, shared variation, and residual noise. By penalizing only the sensitive component, FERM provides explicit and interpretable control over the fairness-utility trade-off. Unlike black-box approaches, FERM offers interpretable estimators with statistical efficiency guarantees under a fully parametric linear model. We validate FERM through extensive simulations and real-world experiments, showing improved fairness and predictive accuracy compared to prior work. Our results highlight envelope-based decomposition as a principled and powerful tool for building fair, efficient, and interpretable regression models.", "tldr": "We propose a novel approach to achieve fairness-utility tradeoffs in regression models by decomposing the predictor space .", "keywords": ["fairness", "regression", "bias", "subspace", "efficiency"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/facb3696e0e9dced62474be69f5b9edd2a63502e.pdf", "supplementary_material": "/attachment/97b3c309163d5a257bd4469789f7dd03191e2bb7.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a method to improve fairness in regression through decomposing the input space into components that vary with the label Y and/or a sensitive attribute S. Theoretically they show how this can be estimated consistently and show it is a variance-reducing projection. Empirically, they demonstrate some wins on simulated and real data in some combination of predictive MSE and fairness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- believe there is novelty in the algorithm, in the application of envelope regression to fair regression, and seems like a good fit of techniques\n- synthetic experiment is compelling, showing a nice win in predictive MSE that one doesn't usually see in fairness papers\n- theoretical results seems sound, and the interpolation/decomposition result in 5.4 seems intuitive and useful"}, "weaknesses": {"value": "- framing: authors introduce the idea of this paper as decomposing direct/indirect bias and I'm not quite sure that the method actually touches on that. For instance, indirect bias could be present in either XS or XSY as either can contain proxy variables.\n- related work: it would be nice to see more discussion of + comparison to a) work from the causal literature that claims to do direct/indirect bias decomposition (are these the same/different ideas?) b) work from the fair representation learning literature that aims to learn de-correlated predictors through pre-processing\n- some lack of clarity around (1) and (2) in the Limitations section in L185 - I don't think the rest of the paper really demonstrates how we get efficiency or interpretability gains with this method; certainly there isn't an empirical demonstration\n- background: it would be great to get more background on envelope regression in the main body, given that it's the central technical tool in this paper. What does it do, and how should I think about it?\n- Alg 2: not clear to me why if we have r=1, we wouldn't be fitting just normal OLS on all of X (given that the XS-estimation process is probably noisy, doing the unconstrained thing may be better)\n- in Sec 6, should give more clarification on the difference in the two FERM methods: is one on XY + XSY and the other on XY only? something else?\n- In general in the experiments, would be good to have more comments on what I should be looking for here - better MSE? better fairness? both? for instance in the Fig 3, we don't see an MSE improvement, or much of an unfairness improvement - would be helpful to communicate better what in the graph I should be taking away\n\n\nsmaller points:\n- Fig 1 is more confusing than helpful I think - I'd recommend visualizing X as a vector rather than a space \n- “re Γ spans directions of X associated with S and Γ0 its invariant complement; Φ spans predictive directions for Y and Φ0 the immaterial ones.” - not sure why the authors use different terminology for Y and S? Are the concepts different? (eg associated/predictive, invariant/immaterial)\n- L313: would be good to get more clarity on what it means to \"exploit the envelope structure\",  as well as the difference between the approaches outlines in equations on L313 and L315\n-"}, "questions": {"value": "what is the exact relationship of the method  to direct/indirect bias decomposition?\nhow does the method improve on the 2 limitations from L185?\nwhat does envelope regression do, and how?\nwhat should the reader be looking for in the experiments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GlEV6ZrFey", "forum": "X1qSwfzPo1", "replyto": "X1qSwfzPo1", "signatures": ["ICLR.cc/2026/Conference/Submission14593/Reviewer_w8Fb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14593/Reviewer_w8Fb"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14593/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761768315343, "cdate": 1761768315343, "tmdate": 1762924977839, "mdate": 1762924977839, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a framework for using subspace decomposition using envelope regression to improve the fairness in regression algorithms. By decomposing a predictor space into four components and isolating the part that corresponds to sensitive attributes, this provides a way to distinguish direct and indirect bias. The model introduces a ridge penalty to the sensitive components, which theoretical and empirical results show a way to trade-off between accuracy and fairness that improves on prior methods."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "S1) The paper presents a novel and principled decomposition to address an important problem.\n\nS2) Theoretical results are strong and show smaller asymptotic variance. \n\nS3) Empirical results are clear and compelling"}, "weaknesses": {"value": "W1) The framework relies on linear subscape decompositions. Further discussion about this assumption and the prevalence in real-world settings would be helpful."}, "questions": {"value": "Other clarification questions:\nQ1) I can't find additional implementation details about the baselines including hyperparameter tuning, and that would be helpful for understanding the experiments better."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZeUhQobTfr", "forum": "X1qSwfzPo1", "replyto": "X1qSwfzPo1", "signatures": ["ICLR.cc/2026/Conference/Submission14593/Reviewer_wL7E"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14593/Reviewer_wL7E"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14593/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980381523, "cdate": 1761980381523, "tmdate": 1762924977181, "mdate": 1762924977181, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors consider fairness in regression and state the importance of fairness. They introduce a fairness framework that adapts subspace decomposition techniques from envelope regression. The predictor space is decomposed into four orthogonal components: response-specific variation, sensitive variation, shared variation, and residual noise. This angle is good. Moreover, this decomposition makes it more interpretable in fairness regression."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The decomposition is good, which makes it more interpretable in fairness learning.\n- This paper provides numerical experiments on simulated and real datasets."}, "weaknesses": {"value": "- Only consider the linear relationship between response and feature $X$.\n- The authors should give the full names when they use at the first time."}, "questions": {"value": "- Only consider the linear relationship between response and feature $X$. My main concern is about non-linearity. When we evaluate on tubular datasets (real datasets), 3-layer or 4-layer fully connected neural networks are used. In this paper, the author decompose the predictor space into 4 parts and consider linear regression on 2 of them.\n- ``Envelope'', what is the meaning of this word?\n- Lines 318-319, is it a definition of asymptotic variance matrix? Also, $T$ is a random variance? $\\theta$ is a mean value? I am not sure my guess is right or wrong?\n- Line 161, there is a mistake about $Cov(S,\\hat U)=0$, it should be $S\\perp\\hat U$, since you need to subtract the mean values when calculating covariance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Uen0zznSTK", "forum": "X1qSwfzPo1", "replyto": "X1qSwfzPo1", "signatures": ["ICLR.cc/2026/Conference/Submission14593/Reviewer_eWet"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14593/Reviewer_eWet"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14593/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980741524, "cdate": 1761980741524, "tmdate": 1762924976564, "mdate": 1762924976564, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes FERM, a fairness-aware regression method which decomposes the predictor space into response-specific, sensitive, shared and residual variations using envelope regression, in order to disentangle direct and indirect biases. FERM applies Ridge penalty only to the sensitive subspace to yield fine-grained, interpretable control over how sensitive attributes influence prediction. Authors provide theoretical results about consistency and efficiency of estimation with provable reductions in asymptotic variance relative to OLS and provide a closed-form characterization of fairness and utility. While the theory is sound, empirical validations are limited as they provide only one baseline, which is not consistently inferior to proposed method (example for smaller sample size or larger threshold $r$). I believe the paper could benefit from more extensive experiments to (i) validate theoretical claims about consistency and nonlinear robustness, (2) consider additional baselines and real datasets, and (iii) identify conditions under which the proposed method is superior to existing ones. The presentation of the paper could improve."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Envelope estimation enables more statistically efficient (lower-variance) estimators and grounded understanding of model components.\n\n- Applying a ridge penalty only to the shared (sensitive + response) subspace permits continuous interpolation between full fairness (no sensitive influence) and unconstrained prediction (maximum utility); assign Eq (6). \n\n- The proposed decomposition is structured for a multivariate setting, which permits handling multiple sensitive attributes, which could generalize better than pairwise or moment constraints. \n\n- Theoretical guarantees of efficiency and consistency, as well as closed-form for fairness-accuracy tradeoff, are provided in Section 5."}, "weaknesses": {"value": "- Empirical validation is very limited--testing on only one real dataset and comparing against a single baseline--leaving method's generalization questionable and limiting strength of conclusions. Including a broader range of conceptually aligned fair regression methods and more real datasets will improve validation. \n\n- In the real-data experiment, FERM and the baseline FRRM exhibit \"somewhat\" comparable performance, with FRRM occasionally outperforming FERM at some unfairness thresholds (levels). This suggests that FERM’s practical benefits may diminish outside controlled settings. Further validation is needed. \n\n- While the experiments validate improved efficiency and some fairness–accuracy trade-off, they fall short of evaluating other theoretical claims such as estimator convergence and asymptotic fairness as established in Proposition 5.2 and Lemma 5.3.\n\n- The synthetic experiment design at beginning of Sec 6 is confusing (not aligned with regression models in Eqns (4)-(6)). Both FERM-decorrelated and FERM-predictive sound different than the interpolated model, yet both apply a Ridge penalty which according to theory, should be on shared subspace. Also, both perform somewhat similarly. \n\n- Wouldn't the controlled linear dependence in data generation imply separable predictive & sensitive subspaces, hence the penalty could be unnecessary. Evaluating results without the penalty may clarify whether fairness arises from the decomposition itself or from regularization."}, "questions": {"value": "Please see weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FonBKjyzx5", "forum": "X1qSwfzPo1", "replyto": "X1qSwfzPo1", "signatures": ["ICLR.cc/2026/Conference/Submission14593/Reviewer_WTmm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14593/Reviewer_WTmm"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14593/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986328899, "cdate": 1761986328899, "tmdate": 1762924975670, "mdate": 1762924975670, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}