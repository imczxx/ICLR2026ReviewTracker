{"id": "zZNYUkBS77", "number": 11690, "cdate": 1758203101802, "mdate": 1763502685082, "content": {"title": "Debugging Concept Bottleneck Models through Removal and Retraining", "abstract": "Concept Bottleneck Models (CBMs) use a set of human-interpretable concepts to predict the final task label, enabling domain experts to not only validate the CBM's predictions, but also intervene on incorrect concepts at test time. However, these interventions fail to address systemic misalignment between the CBM and the expert's reasoning, such as when the model learns shortcuts from biased data. To address this, we present a general interpretable debugging framework for CBMs that follows a two-step process of *Removal* and *Retraining*. In the *Removal* step, experts use concept explanations to identify and remove any undesired concepts. In the *Retraining* step, we introduce **CBDebug**, a novel method that leverages the interpretability of CBMs as a bridge for converting concept-level user feedback into sample-level auxiliary labels. These labels are then used to apply supervised bias mitigation and targeted augmentation, reducing the model’s reliance on undesired concepts. We evaluate our framework with both real and automated expert feedback, and find that **CBDebug** significantly outperforms prior retraining methods across multiple CBM architectures (PIP-Net, Post-hoc CBM) and benchmarks with known spurious correlations.", "tldr": "Human debugging of interpretable concept bottlenecks", "keywords": ["concept bottleneck", "prototypical part network", "interpretability", "human debugging"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b48a7f43e9dd3f028b69b563f7eb0d9e8063c37f.pdf", "supplementary_material": "/attachment/10a8c7aeea49c810088f04c395ae223f9515ad22.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces a framework to analyze and mitigate interpretability failures in Concept Bottleneck Models (CBMs). The authors observe that CBMs can behave unreliably even when concept predictors achieve high accuracy, due to a misalignment between concept representations and their intended semantics. To address this, the paper proposes a _debugging_ process that diagnoses which concepts lead to faulty predictions and retrains or replaces them. The analysis combines synthetic and real datasets to demonstrate that concept-level reliability does not guarantee faithful concept use by the model."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper addresses an important limitation in CBMs (i.e., the gap between interpretability claims and true concept usage). This is timely and relevant given the increasing adoption of CBMs in interpretable ML research.\n- The diagnostic method proposed is systematic and empirically supported by several experiments. The experiments convincingly show that high concept accuracy does not imply semantic reliability, which is an important insight."}, "weaknesses": {"value": "- (W1) While the framing of _debugging_ CBMs is conceptually appealing, the proposed methodology appears closely related to existing approaches on causal or concept-level editing in CBMs (e.g., [1], [2]). It would be helpful if the authors could elaborate on the specific algorithmic contributions that distinguish their method from these prior studies. The originality claim would be more convincing if the paper introduced novel theoretical insights.\n- (W2) Several technical terms (e.g., permutation weighting, worst-group accuracy) are mentioned without formal definitions. Providing clearer descriptions or mathematical formulations would help readers understand how these quantities are computed and how they contribute to the experimental evaluation.\n\n**References**\\\n[1] Chauhan, K., Tiwari, R., Freyberg, J., Shenoy, P., & Dvijotham, K. (2023, June). Interactive concept bottleneck models. In Proceedings of the aaai conference on artificial intelligence (Vol. 37, No. 5, pp. 5948-5955).\\\n[2] Hu, L., Ren, C., Hu, Z., Lin, H., Wang, C. L., Xiong, H., ... & Wang, D. (2024). Editable concept bottleneck models. arXiv preprint arXiv:2405.15476."}, "questions": {"value": "1. Related to W1, could the authors clarify in more concrete terms how their approach differs from prior works on causal or concept-editing methods in CBMs?\n\n2. How do the authors expect their findings to generalize to other modalities or model families, such as large language models that incorporate concept bottlenecks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VEbRoEZaQK", "forum": "zZNYUkBS77", "replyto": "zZNYUkBS77", "signatures": ["ICLR.cc/2026/Conference/Submission11690/Reviewer_jWmY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11690/Reviewer_jWmY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11690/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761110272315, "cdate": 1761110272315, "tmdate": 1762922741534, "mdate": 1762922741534, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces CBDebug, a human-in-the-loop debugging pipeline to improve the underrepresented generalization of interpretable concept-based models (e.g., CBMs). CBDebug is a general framework in which human experts first identify concepts that a CBM spurious uses for downstream predictions (removal step). The model is then retrained by removing these effects through causal rebalancing and data augmentation (retraining step). The work’s evaluation suggests that CBDebug improves worst-group accuracy and helps models avoid spurious shortcuts across different baselines and underlying architectures."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Thank you so much for submitting this work! I enjoyed reading this paper, learned a lot from it, and appreciate the time taken to write it up and submit it to ICLR. Below are what I believe are this paper’s main strengths:\n\n1. **[Significance, Critical]** This work lies at the intersection of fairness, interpretability, and human-in-the-loop AI. It achieves its goals by introducing a new interactive debugging pipeline that can be applied to **any** unsupervised concept-based model (and can be fully automated using foundation models as arbitrers). Hence, I believe this work may be of importance to a large fraction of the ICLR community and can have a potentially large impact, laying the groundwork for further papers on interactive debugging and concept-based interpretability.\n2. **[Quality, Critical]** The overall method is very well motivated and sound. Moreover, the evaluation includes automated and human-driven experiments, both key to fully understanding the proposed pipeline, along with quantitative and qualitative results. Considering all of this, the paper’s methodology and evaluation are strong.\n3. **[Originality, Major]** Overall, the authors do a great job at identifying a key gap in the literature, that of lacking a general interactive debugging method for any unsupervised CBM, and proposing a working approach for that gap. This is certainly potentially impactful and novel. \n4. **[Clarity, Major]** The paper is very well-written and easy to navigate. On top of that, the figures are easy to follow, clear, and helpful in understanding the overall contribution and results."}, "weaknesses": {"value": "In contrast, I believe the following are some of this work’s limitations:\n\n1. **[Quality, Major]** My primary concern is that the results in Table 1 seem to be extremely noisy (some standard deviations are very large). More importantly, notice that this is also evident in Table 2, so it may not be just due to the human aspect of some of this evaluation, as those results are based on the foundation-model-based selection. Therefore, it is very difficult to judge the significance of the observed differences, and the lack of discussion of this key limitation anywhere in the paper is a bit troublesome, as it omits a clear potential issue in the results.\n2. **[Clarity, Minor]** Although the appendix has several empirical studies, none of the key results of these appendices are discussed in the main body of the paper (meaning people will likely never see them). For example, the takeaways from Appendix C.4, which would be of interest for the fairness community, are not even mentioned in the main paper.\n3. **[Novelty, Minor]** The only reason why I didn’t mark the novelty above as critical is that the methodological aspect of the proposed pipeline, although very sensible and interesting, does not introduce any new methodological elements. Instead, it (very sensibly) builds on work in other areas (e.g., permutation weighting, CutMix, MixUp, etc.). Nevertheless, in my opinion, this is not a severe limitation, and it shouldn’t significantly diminish the novelty of the proposed pipeline, as it has novelty in its own right by combining diverse methodologies to achieve a specific goal."}, "questions": {"value": "Balancing the strengths and weaknesses of this work, I am leaning towards accepting this work. However, below I include some questions identifying minor concerns/aspects that I think, if appropriately addressed, could improve this submission:\n\n1. **[Critical]** Could you please elaborate on my concern regarding the significance of the observed results? Why is this not discussed anywhere or, at the very least, acknowledged?\n2. **[Minor]** Could it be possible that the “Retraining” baseline is affected by being exposed to the spurious concepts in its original training? If so, then using a baseline model trained from scratch without any of the identified spurious concepts may give us a good sense of how much the second step of CBDebug matters compared to what one would see if the concepts were removed from the start.\n3. **[Major]** Could you please discuss why the results of Appendix C.4 are not discussed anywhere in the main body of the paper? I believe they are both interesting and insightful results (particularly for those coming from the fairness community). Therefore, at the very least, I would suggest discussing their takeaways in the main body of the paper. More generally, I would recommend at least summarizing the main takeaways of any experimental appendix you include in your paper in the main body (otherwise, people may not learn their importance unless they go the extra mile of reading the entirety of the appendix).\n4. **[Major]** How do augmentation-specific hyperparameters affect the observed results (e.g., $\\gamma$, $k$, the use of top-*ten* activated patches for ProtoPNets, text-to-image model for VLM-CBMs)? Appendix C.3 very superficially touches upon $\\gamma$, but there are no other ablations on these hyperparameters elsewhere. \n\n### Minor Suggestions and Typos\n\nI found the following potential minor issues/typos, which may be helpful when preparing a new version of this manuscript:\n\n1. **[Missing References, Minor]** I would suggest adding relevant references/citations for the introduction claim that “This capability is crucial in high-stakes domains, such as healthcare or scientific analysis, where errors are costly and expert validation is essential.”\n2. **[Potential Typo, Nit]** The reference “Ross et al. (2017)” in line 73 is dangling. It likely needs to be “(Ross et al., 2017)” instead. A similar comment applies to the reference of “Zhou et al. (2016)” in line 113."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FxqMzmJ3fM", "forum": "zZNYUkBS77", "replyto": "zZNYUkBS77", "signatures": ["ICLR.cc/2026/Conference/Submission11690/Reviewer_AMnB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11690/Reviewer_AMnB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11690/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761406344897, "cdate": 1761406344897, "tmdate": 1762922741061, "mdate": 1762922741061, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces CBDebug, a methodology designed to leverage expert (or automated) feedback about concepts that are spuriously correlated with the target task. The goal is to debias the model and promote learning of the correct relationships between concepts and labels. The approach involves three main steps: (i) collecting feedback to identify spuriously correlated concepts, (ii) reweighting samples based on the activation of those concepts, and (iii) augmenting the dataset according to these weights to reduce the influence of spurious correlations. The model is then retrained on the augmented and reweighted dataset. Through experiments on four datasets and across two model architectures, the authors demonstrate performance gains, particularly for the most challenging (worst-performing) classes."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The authors address an important problem (debiasing and aligning Concept Bottleneck Models (CBMs)) from a dataset-centric perspective. By leveraging expert or automated feedback, their approach moves toward the goal of making models \"right for the right reasons\". Although the experiments are not extensive in terms of model diversity, the results are promising and supported by strong qualitative analyses."}, "weaknesses": {"value": "- The paper is somewhat difficult to follow, as it draws upon multiple research areas and alternates between them several times, particularly in the first part of the paper. A clearer narrative structure would help the reader grasp the main contributions more easily.\n- The proposed approach is evaluated on only two models (one CBM and one prototype-based), limiting the scope of the empirical validation. It would strengthen the paper to include additional CBM-like baselines (e.g., CBM, CEM, Probabilistic CBM). This would better demonstrate the generality of the proposed method. Moreover, it should be clarified whether the Post-hoc CBM was used with the residual setting (which leverages side information) or in its standard form, as the latter is conceptually equivalent to a CBM and thus a reasonable baseline."}, "questions": {"value": "- Why was the evaluation limited to the Post-hoc CBM architecture? It would be valuable to test the proposed method on additional CBM variants such as CEM or Probabilistic CBM. This could further demonstrate the general applicability and robustness of the approach, especially if similar improvements are observed.\n- Could the authors clarify how the Remove baselines were implemented? If the spurious concepts were simply removed without further fine-tuning, how was the predictor adjusted to handle the missing concepts?\n- As I understand it, the core idea of the proposed method is to reweight samples containing spurious correlations and further perturb them through data augmentation to reduce the bias. However, this process may also downweight correctly predicted concepts present in the same samples. Could the authors comment on this potential side effect and its practical implications?\n- How would the proposed approach compare to a simpler baseline that removes all samples with weights below a given threshold, rather than reweighting or augmenting them?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "21u0snV5AK", "forum": "zZNYUkBS77", "replyto": "zZNYUkBS77", "signatures": ["ICLR.cc/2026/Conference/Submission11690/Reviewer_SPzc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11690/Reviewer_SPzc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11690/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761817487176, "cdate": 1761817487176, "tmdate": 1762922740590, "mdate": 1762922740590, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce an interactive debugging algorithm designed for concept-based neural networks. In essence, a user provides a list of concepts that they think should not be used for prediction, the algorithm applies two strategies for updating the model so that it does not rely on said concepts anymore. The strategies include permutation reweighting to identify likely affected examples, and augmentation (either CutMix or Mixup, based on the architecture). Experiments compare the proposed technique against naive baselines and ProtoPDebug on four datasets."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "**Originality**: the idea of debugging concept-based models is not novel, as readily acknowledge by the authors, and neither are the individual deconfounding strategies.  The specific mix proposed here is however novel.  This is good enough for me.\n\n**Quality**: A benefit of relying on pre-existing strategies is that we know that they have been validated empirically already, which is good. Regardless, the algorithm as a whole is intuitively appealing.  The experimental setup is also good: four confounded datasets and a reasonable selection of competitors.  The research is empirical in nature.\n\n**Clarity**: The text is well written, well structured, and easy to follow.  The related work is quite comprehensive.\n\n**Significance**: This work contributes to ongoing efforts for making self-explainable models more reliable, and as such it is significant.\n\nOverall, I like this paper."}, "weaknesses": {"value": "**Clarity**:  Some aspects of the work should be described in more detail in the main text, chiefly the augmentation strategies.  Right no, Section 4.3 doesn't tell the reader how augmentations are obtained exactly.  This unnecessarily complicates understanding.\n\nFurthermore, the main competitor (ProtoPDebug) is designed for interactive usage, in the sense that it actively seeks cheap supervision that can quickly correct the model after few interaction rounds. Here the experiments consider a passive setup instead: there are not explicit interaction rounds. As such, it is unclear how much supervision the proposed method requires to \"beat\" ProtoPDebug.\n\n**Significance**: If I understand correctly, the proposed method works under the assumption that the same set of spurious concepts applies to all inputs and labels. This is not necessarily the case. (I don't think ProtoPDebug makes this assumption.) This limits applicability."}, "questions": {"value": "Please feel free to comment on the weaknesses I pointed out."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6sTEN49wnS", "forum": "zZNYUkBS77", "replyto": "zZNYUkBS77", "signatures": ["ICLR.cc/2026/Conference/Submission11690/Reviewer_16NR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11690/Reviewer_16NR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11690/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761899535788, "cdate": 1761899535788, "tmdate": 1762922739430, "mdate": 1762922739430, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce an interactive debugging algorithm designed for concept-based neural networks. In essence, a user provides a list of concepts that they think should not be used for prediction, the algorithm applies two strategies for updating the model so that it does not rely on said concepts anymore. The strategies include permutation reweighting to identify likely affected examples, and augmentation (either CutMix or Mixup, based on the architecture). Experiments compare the proposed technique against naive baselines and ProtoPDebug on four datasets.\n\n----\nPost-rebuttal update: The authors did address my main concerns with the paper. I've increase the score accordingly."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "**Originality**: the idea of debugging concept-based models is not novel, as readily acknowledge by the authors, and neither are the individual deconfounding strategies.  The specific mix proposed here is however novel.  This is good enough for me.\n\n**Quality**: A benefit of relying on pre-existing strategies is that we know that they have been validated empirically already, which is good. Regardless, the algorithm as a whole is intuitively appealing.  The experimental setup is also good: four confounded datasets and a reasonable selection of competitors.  The research is empirical in nature.\n\n**Clarity**: The text is well written, well structured, and easy to follow.  The related work is quite comprehensive.\n\n**Significance**: This work contributes to ongoing efforts for making self-explainable models more reliable, and as such it is significant.\n\nOverall, I like this paper."}, "weaknesses": {"value": "**Clarity**:  Some aspects of the work should be described in more detail in the main text, chiefly the augmentation strategies.  Right no, Section 4.3 doesn't tell the reader how augmentations are obtained exactly.  This unnecessarily complicates understanding.\n\nFurthermore, the main competitor (ProtoPDebug) is designed for interactive usage, in the sense that it actively seeks cheap supervision that can quickly correct the model after few interaction rounds. Here the experiments consider a passive setup instead: there are not explicit interaction rounds. As such, it is unclear how much supervision the proposed method requires to \"beat\" ProtoPDebug.\n\n**Significance**: If I understand correctly, the proposed method works under the assumption that the same set of spurious concepts applies to all inputs and labels. This is not necessarily the case. (I don't think ProtoPDebug makes this assumption.) This limits applicability."}, "questions": {"value": "Please feel free to comment on the weaknesses I pointed out."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6sTEN49wnS", "forum": "zZNYUkBS77", "replyto": "zZNYUkBS77", "signatures": ["ICLR.cc/2026/Conference/Submission11690/Reviewer_16NR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11690/Reviewer_16NR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11690/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761899535788, "cdate": 1761899535788, "tmdate": 1763719381982, "mdate": 1763719381982, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}