{"id": "pc3ZW7lmaV", "number": 19686, "cdate": 1758298382400, "mdate": 1763656352180, "content": {"title": "How hard is learning to cut? Trade-offs and sample complexity", "abstract": "In the recent years, branch-and-cut algorithms  have been the target of data-driven approaches designed  to enhance the decision making in different phases of the algorithm such as branching, or the choice of cutting planes (cuts). In particular, for cutting plane selection two score functions have been proposed in the literature to evaluate the quality of a cut: branch-and-cut tree size and gap closed.  In this paper, we present new sample complexity lower bounds, valid for both scores. We show that for a wide family of classes $\\mathcal{F}$ that maps an instance to a cut, learning over an unknown distribution of the instances to minimize those scores requires at least (up to multiplicative constants) as many samples as learning from the same class function $\\mathcal{F}$ any generic target function (using square loss). Our results also extend to the case of learning from a restricted set of cuts, namely those from the Simplex tableau. To the best of our knowledge, these  constitute the first lower bounds for the learning-to-cut framework. We compare our bounds to known upper bounds in the case of neural networks and show they are nearly tight, suggesting that both scores (gap closed and tree size) are of comparable difficulty from a learning standpoint. Guided by this insight, we provide empirical evidence -- by using a  graph neural network cut selection evaluated on various integer programming problems -- that gap closed is a practical and effective proxy for minimizing the tree size. Although the gap closed score has been extensively used in the integer programming literature, this is the first principled analysis discussing both scores simultaneously both theoretically and computationally.", "tldr": "", "keywords": ["Integer programming", "branch-and-cut", "branch-and-bound", "sample complexity", "learning theory"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2bc7b7e4be29431409a5ca1e86353523e55ca58b.pdf", "supplementary_material": "/attachment/1de69daee65ba689de9f0bb153a82cdf11b7873c.zip"}, "replies": [{"content": {"summary": {"value": "The paper provides the first sample-complexity lower bounds for the “learning-to-cut” framework in branch-and-cut MILP solvers. It proves that, for neural-network policies mapping an ILP instance to a Chvátal–Gomory cut, minimising either tree-size or gap-closed requires  \nΩ(VCdim(F)/ε) samples, i.e. as many samples as learning any generic real-valued target with squared loss. The bounds are shown tight up to log factors for ReLU nets. Complementary experiments on four NP-hard problems indicate that a GNN trained on the cheap “gap-closed” proxy achieves tree-size reductions close to the expensive oracle, corroborating the theoretical insight that the two scores are equally learnable."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Theoretically pioneering: First distribution-free lower bounds for learning-to-cut; closes the loop with recent upper bounds [Balcan et al. 2021, Cheng et al. 2024].  \n2. Generality: Results hold for any encoder–network family that satisfies minimal closure assumptions; not restricted to CG or tableau cuts.  \n3. Tightness: Lower bound Ω(WL log(W/L)/ε) matches the best-known upper bound Õ(WL/ε²) for ReLU nets, showing no exponential gap.  \n4. Empirical validation: Carefully designed GNN experiments demonstrate that gap-closed is a practical surrogate for tree-size, bridging theory–practice.  \n5. Clarity: Proof roadmap and supplementary document are rigorous and well written."}, "weaknesses": {"value": "1. Restricted concept class: The lower bounds are proved only for single-cut selection, whereas modern solvers add batches (rounds) of cuts. It remains unclear whether the lower bound still holds when the learner outputs a *set* of cuts.\n2. CG-only cutting regime: The lower bounds rely exclusively on Chvátal–Gomory (CG) cuts. Extending the results to more general cut families such as split cuts, GMI cuts, or knapsack cuts would significantly strengthen the theoretical claims.\n3. Instance distribution: overly general setting: The lower bounds are worst-case over all possible distributions, without considering structured or parametric families (e.g., IPs generated from stochastic block models or Gaussian-distributed `A, b`). This may lead to overly pessimistic bounds.\n4. No information-theoretic upper bound for gap-closed: While the authors conjecture that only cuts separating the fractional solution matter, they do not provide a distribution-dependent upper bound based on this insight. Thus, the sample complexity of gap-closed remains only partially characterized.\n5. Limited empirical scope: Experiments are conducted only on small synthetic instances (≤ 50 variables). There is no validation on medium-scale realistic benchmarks such as the “easy” subset of MIPLIB 2017, leaving open whether the proxy quality degrades on real-world IPs.\n6. Missing baselines: The empirical evaluation lacks comparison with recent learning-based cut selectors, such as LLM-guided methods (LIFT-FE, TransGPT-FE) or imitation learning with tree-size experts (Paulus et al., 2022), making it hard to assess the relative strength of the proposed approach."}, "questions": {"value": "1. Do the lower bounds hold for batch cut selection?  \n   If the learner outputs a set of cuts instead of a single one, does the sample complexity lower bound still apply? Is a new theoretical framework needed?\n2. Can the bounds be extended to general cut families?  \n   Is it possible to generalize the lower bounds beyond CG cuts to split cuts, GMI cuts, or other stronger cut classes?\n3. Can tighter bounds be obtained under structured distributions?  \n   If instances are drawn from structured generative models (e.g., stochastic block-model IPs or Gaussian `A, b`), can we prove tighter sample complexity bounds?\n4. Can we derive a distribution-dependent upper bound for gap-closed?  \n   Can the conjecture — that only cuts separating the fractional solution matter — be leveraged to derive a tighter, distribution-dependent upper bound on the sample complexity of learning with gap-closed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6y2GBuHy21", "forum": "pc3ZW7lmaV", "replyto": "pc3ZW7lmaV", "signatures": ["ICLR.cc/2026/Conference/Submission19686/Reviewer_hSqs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19686/Reviewer_hSqs"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19686/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761796102832, "cdate": 1761796102832, "tmdate": 1762931529228, "mdate": 1762931529228, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies lower bounds on the sample complexity of learning cut policies for Branch and Cut solvers for integer linear programs.\nA key step in the Branch and Cut framework is adding a cutting plane, which is an additional constraint that tighten the constraint set without eliminating any integral solutions.\nThere are many valid cutting planes to choose from, so traditional B&C implementations have a collection of hand-crafted heuristics designed to choose cuts that lead to fast solution times.\nRecently a line of work has explored the idea of learning cutting plane selection policies from data: given a training collection of ILP instances sampled from some distribution, each instance is solved and the resulting B&C trees are used to train cut selection policies that optimize a utility metric attempting to capture the running time required to solve the problem after the cut is applied.\nThe two most commonly considered metrics are tree-size (the actual size of the resulting B&C tree, which is strongly predictive of the runtime), and the gap-closed metric, which measures the reduction in the optimality gap after introducing the cut.\nSome prior work has provided upper bounds on the sample complexity of learning such cutting policies when the utility metric is the size of the resulting tree (but the authors claim that it can be generalized to the gap-reduction metric straight forwardly).\n\nThis paper has two main high-level contributions:\n1. The authors derive sample complexity lower bounds for learning cut selection policies from data under fairly realistic assumptions. In particular, together with the upper bounds from prior work, they establish that the sample complexity is comparable for both the the gap-closed and tree-size metrics.\n2. The authors empirically find that the gap-closed metric is a suitable proxy for the tree-size metric. This is useful because the gap-closed metric is much more computationally efficient to evaluate when generating training data.\n\nTaken together, these results support the use of gap-closed for learning cut selection policies. It is not harder to learn than the tree-size metric from a sample complexity point of view, still provides a reasonable proxy for solution time, and is easier to calculate."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The problem of learning cut selection policies for the branch and cut framework is interesting and very practical, and this paper provides the first lower bounds on sample complexity for this problem.\nThe findings that the gap-reduction metric is a suitable approximation to tree-size also useful.\nOverall I found the paper well written and feel like the main contributions were clearly communicated."}, "weaknesses": {"value": "I would have liked for more of the key sample complexity lower bound argument to be sketched in the main body of the paper.\nFor example, in the discussion of Proposition 3.4, it is stated that the approach ignores $n \\times m + m$ of the inputs, and I was curious to understand why.\nThere are also a number of minor typos throughout the paper, and a few significant ones in the experimental results (unless I have misunderstood something).\n\nI think at the beginning of Section 2.2, the authors could include a little bit more detail about the notation. At first I had some trouble identifying the role played by the functions $f$ and $h$ in equation (2).\n\nA few of the minor typos I noticed:\n- Line 120: \"Ou results\" -> \"Our results\"\n- Line 169: \"that can derived at any iteration\" -> \"that can be...\"?\n- Line 181: Maybe \"so this motivates the idea of learning such a score\"?"}, "questions": {"value": "- On line 308, should it say \"returns a vector in $[0,1]^m$\" instead of $[0-1]^m$?\n- On line 309, should it say that the function is \"continuous at 1/2\"?\n- Table 2 seems to be missing some results for Facility Location compared to Table 3 in the appendix (i.e., the first column is all dashes instead of having an entry for GNN).\n- In both Table 2 and Table 3, should the second column be \"gap closed\" and the third column be \"B&C tree\". The titles aren't consistent, but if I understand what is being reported, it seems like the dashes should always appear in the \"gap closed\" column.\n- In Tables 2 and 3, since only GNN has a gap-closed variant, I wonder if it would make sense to have a single column and just include two versions of GNN: \"GNN-Tree-Size\" and \"GNN-Gap-Closed\"."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Vnz8Z6cvb6", "forum": "pc3ZW7lmaV", "replyto": "pc3ZW7lmaV", "signatures": ["ICLR.cc/2026/Conference/Submission19686/Reviewer_dRbm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19686/Reviewer_dRbm"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19686/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959861012, "cdate": 1761959861012, "tmdate": 1762931528673, "mdate": 1762931528673, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper provides the first sample complexity lower bounds for learning to select cutting planes in integer programming. The bounds apply to two performance scores: branch-and-cut tree size and gap closed. The authors show these lower bounds are nearly tight with known upper bounds for neural networks, indicating both scores have comparable learning difficulty. Empirical results demonstrate that gap closed serves as a practical proxy for tree size reduction when training graph neural networks on tableau Chvatal-Gomory cuts."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. First sample complexity lower bounds for learning-to-cut, establishing theoretical foundations\n2. Lower bounds hold for wide function classes and are nearly tight with upper bounds up to logarithmic factors\n3. Theoretical equivalence between scores provides formal justification for using gap closed as proxy\n4. Proof construction for shattering ILP instances is non-trivial and well-executed\n5. Experiments directly test the core thesis about proxy effectiveness"}, "weaknesses": {"value": "1. Gap between $\\Omega(1/\\epsilon)$ lower bound and $\\Omega(1/\\epsilon^2)$ upper bound for tableau case\n2. Assumptions 1 and 2 restrict generality of theoretical claims\n3. Empirical validation uses small-scale problems in controlled environment and restricted solver configuration\n4. Performance varies: on Facility Location, Efficacy heuristic (123.63) outperforms GNN (134.61)\n5. Experimental setup disables key solver components (presolve, heuristics, default cuts)\n6. Theoretical analysis confined to Chvatal-Gomory cuts from simplex tableau\n7. Learned policy selects single cut at root node, not dynamic cut selection\n8. Worst-case bounds do not leverage structure in real-world MILP distributions\n9. Computational cost of obtaining training samples not addressed theoretically"}, "questions": {"value": "1. Can the $\\epsilon$-dependence gap be closed? Is the true sample complexity $\\Theta(1/\\epsilon)$ or $\\Theta(1/\\epsilon^2)$?\n2. How would sample complexity scale for learning policies that select multiple rounds of cuts?\n3. Would results transfer to production solver configurations with presolve and heuristics enabled?\n4. Do similar lower bounds hold for other cut families beyond Chvatal-Gomory cuts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MkbMhe4rOY", "forum": "pc3ZW7lmaV", "replyto": "pc3ZW7lmaV", "signatures": ["ICLR.cc/2026/Conference/Submission19686/Reviewer_Fk2R"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19686/Reviewer_Fk2R"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19686/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762043621168, "cdate": 1762043621168, "tmdate": 1762931528058, "mdate": 1762931528058, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proves sample complexity bounds in the setting of learning to cut for solving integer programs. The bounds are for two different scores, branch and cut tree size and gap closed. The theoretical results show that both scores are similarly difficult to learn. Additionally, the paper provides"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is well written: it illustrates its core ideas through intuitive examples and explanations without sacrificing technical details.\n- The bounds derived don't seem to be vacuous/uninformative. The proofs are also relying on (as far as I can tell) novel constructions that are specific to the problem.\n- To the best of my knowledge, these are the best known nontrivial bounds for this learning problem.\n- The paper also provides an experimental comparison of the learned cuts of a GNN compared to well known heuristics and shows that the GNN can learn to generate cuts that are on par or better compared to those heuristics."}, "weaknesses": {"value": "- In the proof of 3.2 (Around line 600), you set $a = \\epsilon$ and use the Transfer Lemma. \nDoesn't that mean you take $$\\text{fat} _{\\mathcal{F} _{s,\\sigma'}} (\\frac{\\epsilon}{\\epsilon}) \\geq \\text{VCdim}(\\mathcal{F}[n]) ?$$\nHowever the transfer lemma holds for $\\gamma \\in (0,1/2)$ so I'm not sure you want to do it this way. Maybe set $a=c\\epsilon$ for c at least 2?\n- How necessary is assumption 2 for your result? Are there any architectures that don't qualify? That's perhaps one part I'm a little unclear about and I woud like to see some more comments on.\n- There are a bunch of typos in the document so more careful proofreading is required. For example see lines: 120, 224, 459-460, \n- I am not sure how the experimental section ties into the overall contribution here. I guess it's good to see that GNNs can learn a practically viable heuristic by training on gap closed but it is a bit unclear how that connects to the theoretical findings of the paper.\n\nOverall this is a good paper that I lean towards accepting. There are some (I think minor) issues with the proof and I'm a bit unclear about assumption 2 so I start with a tentative score that I will reconsider after the rebuttal."}, "questions": {"value": "see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dnKxQYyhFC", "forum": "pc3ZW7lmaV", "replyto": "pc3ZW7lmaV", "signatures": ["ICLR.cc/2026/Conference/Submission19686/Reviewer_BtH5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19686/Reviewer_BtH5"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19686/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762237862918, "cdate": 1762237862918, "tmdate": 1762931527574, "mdate": 1762931527574, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}