{"id": "BsY20r9FOM", "number": 5899, "cdate": 1757944542337, "mdate": 1759897946263, "content": {"title": "Continual Unlearning for Text-to-Image Diffusion Models: A Regularization Perspective", "abstract": "Machine unlearning—the ability to remove designated concepts from a pre-trained\nmodel—has advanced rapidly, particularly for text-to-image diffusion models.\nHowever, existing methods typically assume that unlearning requests arrive all\nat once, whereas in practice they often arrive sequentially. We present the first\nsystematic study of continual unlearning in text-to-image diffusion models and\nshow that popular unlearning methods suffer from rapid utility collapse: after only\na few requests, models forget retained knowledge and generate degraded images.\nWe trace this failure to cumulative parameter drift from the pre-training weights\nand argue that regularization is crucial to addressing it. To this end, we study a\nsuite of add-on regularizers that (1) mitigate drift and (2) remain compatible with\nexisting unlearning methods. Beyond generic regularizers, we show that semantic\nawareness is essential for preserving concepts close to the unlearning target, and\npropose a gradient-projection method that constrains parameter drift orthogonal\nto their subspace. This substantially improves continual unlearning performance\nand is complementary to other regularizers for further gains. Taken together, our\nstudy establishes continual unlearning as a fundamental challenge in text-to-image\ngeneration and provides insights, baselines, and open directions for advancing safe\nand accountable generative AI.", "tldr": "", "keywords": ["Continual Unlearning", "Diffusion Model", "Image Generation", "Machine Unlearning"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/03c83c93496b7fb0480effe43285e7571a4de01d.pdf", "supplementary_material": "/attachment/2cc18f562fd5d774a2560f139c170c55f78ef172.pdf"}, "replies": [{"content": {"summary": {"value": "This paper introduces the problem of continual unlearning for text-to-image diffusion models, where forgetting requests are handled sequentally. The paper shows that popular unlearning frameworks suffer from degraded performance in the continual setting. The paper shows that the problem is due to cumulative parameter drift, where the model weights progressively drift from the original weights. To address this, the paper proposes several methods: regularization, selective fine-tuning, model merging and gradient projection. Experiments show that these methods significantly improve the model's ability to retain performance in the continual unlearning setting."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The continual unlearning setting is a practical and important problem in the field of text-to-image unlearning.\n- While the root cause being cumulative parameter drift is unsurprising, the paper provides clear empirical evidence and analysis of the phenomenon.\n- Though tested on only two baselines (see weaknesses), I find that the experiments and results are thorough and provide good evidence of the author's claims.\n- Proposed methods like regularization and gradient projection are simple yet general, making them easy to integrate with existing unlearning pipelines.\n- Overall, the paper is clear, concise and well-structured."}, "weaknesses": {"value": "- In itself, the proposed methods are not novel (regularization, gradient projection etc. are certainly not new), but applied to the setting of continual unlearning. \n\n- The experiments are conducted on two methods, ConAbl and EraseDiff. While these are representative, it is unclear how the findings of the proposed methods would generalize to other classes of unlearning algorithms. \n\n- The authors claim simultaneous unlearning is costly, but their proposed model merging is also costly given independent copies have to be unlearned. Have the authors compared the computational costs and whether model merging is more efficient than simultaneous unlearning?\n\n- On the Taylor expansion of the loss in Sec 5.2, the loss is *upper-bounded* by $||\\theta^* - \\theta^\\dagger||$, thus even if the RHS grows, it does not guarantee the retention loss grows. Hence the conclusion that \"loss grows proportionally (up to a constant) to $||\\theta^* - \\theta^\\dagger||$\" seems somewhat inaccurate."}, "questions": {"value": "- Given the combined results in Fig 8, what end-to-end 'default' recipe do the authors recommend for sequential unlearning? A short set of takeaways for practitioners would help solidify the insights.\n- Have the authors considered a Fisher-weighted regularization approach from continual learning like in [1]? This would lie between full L2 regularization and Selective fine-tuning.\n- How sensitive is performance of gradient projection to the auxiliary set of semantically similar concepts? Could a poorly chosen set harm retention or unlearning?\n- Have the authors investigated the effect of the order of unlearning requests? For example, does unlearning a broad concept (e.g. \"photorealism\") early in the sequence have a different impact than unlearning a more specific one (e.g. \"Van Gogh\")?\n- How do results differ on concepts that can be referenced explicitly (like objects) versus indirectly (e.g., styles by prompting for artist names, or using synonyms)?\n\n[1] Heng, Alvin, and Harold Soh. \"Selective amnesia: A continual learning approach to forgetting in deep generative models.\" Advances in Neural Information Processing Systems 36 (2023): 17170-17194."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jlMQ0c1rPc", "forum": "BsY20r9FOM", "replyto": "BsY20r9FOM", "signatures": ["ICLR.cc/2026/Conference/Submission5899/Reviewer_oE7J"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5899/Reviewer_oE7J"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5899/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761477395090, "cdate": 1761477395090, "tmdate": 1762918335624, "mdate": 1762918335624, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work conducts the first systematic investigation of continual unlearning in text-to-image diffusion models, revealing that existing unlearning methods suffer from severe utility collapse due to cumulative parameter drift. To address this, the authors propose a set of regularization-based strategies that mitigate drift while remaining compatible with existing methods. They further introduce a semantic-aware gradient projection technique that constrains parameter updates to directions orthogonal to the target concept’s subspace, preserving related knowledge. Overall, these methods substantially improve continual unlearning stability and establish strong baselines for safe, accountable generative AI."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper presents an interesting and valuable study on continual unlearning in text-to-image diffusion models.\n2. This paper is very well presented.\n3. The paper conducts a detailed analysis of the challenges faced by continual unlearning in text-to-image diffusion models through a series of experiments."}, "weaknesses": {"value": "The author emphasizes that this paper does not propose new algorithms but focuses on the analysis of continual unlearning. I have the following questions about this paper:\n\n1. Compared to regular continual learning, what are the additional challenges of continual unlearning? Parameter drift and conceptual confusion have been extensively studied in continual learning. Results in figure 3 separate the unleaning target from the retention target, but can also be interpreted as follows: as the number of requests increases, the model forgets the required targets, leading to indiscriminate unleaning of all concepts.\n2. Experimental findings indicate that object retention and style retention exhibit distinct patterns of forgetting, though further analysis of this phenomenon is lacking.\n3. In the experiment shown in Figure 4, for sequential learning, is the sum of the update iterations for multiple requests the same as the update iterations for simultaneous learning?\n4. What insights does this paper offer for future research on continual unlearning in text-to-image diffusion models. Given that the methods combined in this paper have long been applied in continual learning, does this imply that regularization techniques and model merging approaches designed to address continual learning issues can effectively tackle continual unlearning in text-to-image diffusion models?"}, "questions": {"value": "Minor concerns:\n\n- The colors in Figure 3 are too similar, resulting in poor readability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "I2wxVidNBf", "forum": "BsY20r9FOM", "replyto": "BsY20r9FOM", "signatures": ["ICLR.cc/2026/Conference/Submission5899/Reviewer_xbNs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5899/Reviewer_xbNs"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5899/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761664648713, "cdate": 1761664648713, "tmdate": 1762918335127, "mdate": 1762918335127, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces continual unlearning for text-to-image diffusion models where removal requests arrive sequentially. It shows that popular methods degrade quickly in this setting due to cumulative parameter drift away from the pretrained weights, then proposes simple add-on remedies such as L1 or L2 update penalties, selective fine-tuning, model merging, and a semantic-aware gradient projection on cross-attention projections to protect nearby concepts. Experiments on an UNLEARNCANVAS-based benchmark report strong improvements in retention while maintaining unlearning effectiveness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Clear problem definition of continual unlearning with precise requirements for erasing targets, preserving prior removals, and retaining unrelated capabilities, plus explicit metrics for unlearning accuracy and retention accuracy split into in-domain and cross-domain.\n\n2.  Practical plug-and-play remedies that integrate with existing unlearning methods, including L1 or L2 update penalties, selective fine-tuning, and model merging via TIES, which reduce drift and improve retention. \n\n3. The gradient projection idea operates on cross-attention projections to protect nearby concepts and combines well with other regularizers for further improvements."}, "weaknesses": {"value": "1. Sensitivity to choices such as the strength of L1 or L2 penalties, the top k percent for selective updates, and the number and selection rule for auxiliary concepts in gradient projection is not fully characterized.\n\n2. Limited cost analysis for independent unlearning plus merging and for importance computation in selective tuning.\n\n3. The paper does not discuss several closely related recent works that address multi-concept and efficient forgetting, such as Sculpting Memory: Multi-Concept Forgetting in Diffusion Models via Dynamic Mask and Concept-Aware Optimization (ICCV 2025) and ConceptPrune: Concept Editing in Diffusion Models via Skilled Neuron Pruning (ICLR 2025). These studies provide complementary perspectives on dynamic masking and pruning-based forgetting, and should be compared for completeness."}, "questions": {"value": "1. How sensitive are the results to the regularization coefficient and top k selection used in selective fine-tuning and merging?\n\n2. How are auxiliary concepts selected for gradient projection, and how many are required for stable performance?\n\n3. The evaluation primarily relies on EraseDiff as the base method, which limits the generality of the findings. Incorporating other representative approaches such as ESD, SalUN, and AC (Ablating Concepts in Text-to-Image Diffusion Models) would provide a more comprehensive and convincing demonstration of continual unlearning behavior across different unlearning paradigms.\n\n4. While the paper mentions that continual unlearning may degrade the model’s general generative ability, the current evaluation mainly tests unrelated or random objects and styles to measure retention. A more informative evaluation would consider semantically related concepts to the forgotten target. For instance, when unlearning the concept “cat,” it would be more revealing to measure how well the model retains the ability to generate “tiger,” “lion,” or “leopard,” which are close in the embedding or visual space. Moreover, the paper lacks a broader assessment of general generation ability on a large-scale benchmark such as MS-COCO using metrics like CLIP Score or FID, which are standard in diffusion model evaluation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Z7RxjAd5wL", "forum": "BsY20r9FOM", "replyto": "BsY20r9FOM", "signatures": ["ICLR.cc/2026/Conference/Submission5899/Reviewer_6PKG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5899/Reviewer_6PKG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5899/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761861926287, "cdate": 1761861926287, "tmdate": 1762918334712, "mdate": 1762918334712, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Current machine unlearning methods typically assume that all deletion requests arrive simultaneously. However, in real-world scenarios, deletion requests are often sequential, a setting referred to as continual unlearning.\nExisting approaches suffer from severe performance degradation under this setting, leading to both ineffective unlearning and the collapse of unrelated generation quality.\nTo address this, the authors systematically study continual unlearning for text-to-image diffusion models and propose three regularization-based strategies (update norm regularization, selective fine-tuning, and model merging), along with a semantic-aware unlearning method (gradient projection). These methods aim to mitigate parameter drift, improve retention of unrelated concepts, and minimize interference among semantically similar concepts.\nExperimental results demonstrate that the regularization methods effectively alleviate the performance collapse problem, while the semantic-aware unlearning method achieves the most significant improvement in in-domain retention. Furthermore, it can be combined with other regularization techniques to achieve a better trade-off between unlearning effectiveness and image quality."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Formally define and analyze continual unlearning in the text-to-image setting.\n- Provides both theoretical and empirical insights into performance collapse due to parameter drift.\n- Proposes modular regularization and semantic-aware techniques that can easily integrate with existing unlearning methods.\n- Gradient Projection method effectively improves in-domain retention and reduces collateral forgetting."}, "weaknesses": {"value": "- The study is limited to style and object deletions; it does not evaluate more practically relevant concepts such as NSFW, copyrighted, or identity-based content as previous works.\n- All experiments are conducted on a single diffusion model within the UnlearnCanvas benchmark. The paper does not assess whether the proposed regularizers and gradient projection method generalize to other architectures or larger-scale diffusion models\n- The benchmark setup relies on a limited base model and a relatively small, templated set of prompts for generation. This constrained setting—previously identified as a limitation of existing unlearning evaluation [1], which may not fully capture the diversity and complexity of real-world unlearning scenarios.\n- While the proposed techniques (regularization, model merging, gradient projection) are well-motivated, they are largely adaptations or combinations of existing ideas.\n\n[1] Ko, Myeongseob, et al. \"Boosting alignment for post-unlearning text-to-image generative models.\" Advances in Neural Information Processing Systems 37 (2024): 85131-85154."}, "questions": {"value": "In addition to the weaknesses,\n- What's the computational overhead of different unlearning methods evaluated in the paper?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MI1RbjWTE1", "forum": "BsY20r9FOM", "replyto": "BsY20r9FOM", "signatures": ["ICLR.cc/2026/Conference/Submission5899/Reviewer_N1oH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5899/Reviewer_N1oH"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5899/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761985150112, "cdate": 1761985150112, "tmdate": 1762918334479, "mdate": 1762918334479, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}