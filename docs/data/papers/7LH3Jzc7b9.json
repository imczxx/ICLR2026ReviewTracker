{"id": "7LH3Jzc7b9", "number": 1610, "cdate": 1756897038575, "mdate": 1763047399604, "content": {"title": "PhotoArtAgent: Intelligent Photo Retouching with Language Model-based Artist Agent", "abstract": "Photo retouching is integral to photographic art, extending far beyond simple technical fixes to heighten emotional expression and narrative depth. While artists leverage expertise to create unique visual effects through deliberate adjustments, non-professional users often rely on automated tools that produce visually pleasing results but lack interpretative depth and interactive transparency. In this paper, we introduce PhotoArtAgent, an intelligent system that combines Vision-Language Models (VLMs) with advanced natural language reasoning to emulate the creative process of a professional artist. The agent performs explicit artistic analysis, plans retouching strategies, and outputs precise parameters to Lightroom through an API. It then evaluates the resulting images and iteratively refines them until the desired artistic vision is achieved. Throughout this process, PhotoArtAgent provides transparent, text-based explanations of its creative rationale, fostering meaningful interaction and user control. Experimental results show that PhotoArtAgent not only surpasses existing automated tools in user studies but also achieves results comparable to professional human artists.", "tldr": "", "keywords": ["Agent", "Photo Retouching", "Multi-Modal Language Model"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/95d3338495f16ff6db063a102e803efb3b83f5bc.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes an VLM based system for photo editing. The editing mechanism relies on Adobe Lightroom to apply the edit. In particular, given an input photo, and a user request of a text edit, the VLM outputs the Lightroom editing parameters that can match the user's request. As an additional step, the authors allow re-processing the edited image with a VLM to evaluate the edit quality, and iteratively edit the photo until it reaches a satisfactory state. Evaluation is done through a user study, comparing the VLM based methods to humans and existing baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The method uses existing VLMs without any fine-tuning requirements, making it easy to implement\n- Showcases that existing VLMs/LLMs can produce image editing parameters that are reasonable\n- The method allows using a reference image as a guideline for the edit, which can be easier for the user to provide instead of providing a detailed description of the desired edit"}, "weaknesses": {"value": "- The logic of the paper is: There are two paradigms for editing. 1- direct editing with text-based models like Google Nano-Banana for example, or 2- editing in an interpretable way by producing editing parameters that can be used with off-the-shelf software like Lightroom. The argument of the authors is, (2) is preferred as it can be interpreted easily by the user. But the premise of the paper is editing for users with no editing background, and in that case, providing them with interpretable parameters is not very meaningful. So logically, it seems like choice 1 (direct editing) is more expressive and would be capable of producing better results.\n\n- The fact that the VLM approach was preferred to users over human \"experts\" is questionable. Why did the humans perform not as well? were they too time restricted?\n\n- The standard Lightroom auto is highly competitive with the proposed method in the user study, despite being significantly faster and cheaper. It is not clear if the cost and runtime of the method is justifiable.\n\n- The user studies evaluate the quality of the edit, but there is no experiment evaluating whether the text edit provided by the user matches the produced output or not."}, "questions": {"value": "- How are the human experts who were used as a baseline were selected? What credentials did they have? Also it seems that they are labeled as Expert A and Expert C, which makes me wonder was \"Expert B\" simply not included in the comparison?\n\n- Is the contribution of the paper effectively a \"prompt\" for VLMs? It is unclear to me why a prompt is a sufficient contribution for a full research paper\n\n- I can see the paper to be a plausible feature added in Lightroom or an editing software, but what makes it valuable to the research community? That remains unclear to me\n\n- How is the communication between the VLM and Lightroom implemented? and why does it take at least a minute for the communication to occur? Does that mean that in cases where the model needs to re-iterate on the edit, the runtime can be as high as 14 minutes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3Yxm7RBrYD", "forum": "7LH3Jzc7b9", "replyto": "7LH3Jzc7b9", "signatures": ["ICLR.cc/2026/Conference/Submission1610/Reviewer_e4Tv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1610/Reviewer_e4Tv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1610/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761782024582, "cdate": 1761782024582, "tmdate": 1762915832403, "mdate": 1762915832403, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "SDvF5CI7ke", "forum": "7LH3Jzc7b9", "replyto": "7LH3Jzc7b9", "signatures": ["ICLR.cc/2026/Conference/Submission1610/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1610/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763047398925, "cdate": 1763047398925, "tmdate": 1763047398925, "mdate": 1763047398925, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents PhotoArtAgent, an intelligent photo retouching system that employs large Vision-Language Models to analyze images and emulate a human artist’s workflow. The agent explicitly reasons about artistic intent, proposes retouching strategies, generates concrete Lightroom parameters via an API, applies these parameters, and iteratively refines the results while providing reflective, text-based explanations. The workflow supports multimodal user input (text, reference images, retouching cases) and operates without model training. In both user studies and automatic evaluations, PhotoArtAgent matches or surpasses state-of-the-art automated tools and, in some cases, professional human artists."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper introduces an agentic, cognitive workflow for photo retouching based on VLM reasoning.\n2. It also proposes a modular system supporting iterative reflection and multimodal user interaction.\n3. This paper demonstrates parameter-level, interpretable editing via direct control of Lightroom.\n4. Through quantitative and qualitative results, it shows that the proposed method achieve comparable results with human experts and deep-learning models."}, "weaknesses": {"value": "1. From my perspective, this paper lacks sufficient novelty with a simple agentic framework for photo retouching.\n2. The histogram based analysis may not be generalizable, also this paper heavily rely on Lightroom-style global adjustment, limiting its application.\n3. Aesthetic evaluations based on VLM may not align with human perception."}, "questions": {"value": "1. How to deal with the hallucination in VLM.\n2. How to align VLM-based aesthetic evaluation with human value.\n3. Can your agentic workflow generalized to other software and deep-learning based methods."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pHEl2rLSlE", "forum": "7LH3Jzc7b9", "replyto": "7LH3Jzc7b9", "signatures": ["ICLR.cc/2026/Conference/Submission1610/Reviewer_ThQY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1610/Reviewer_ThQY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1610/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761842523251, "cdate": 1761842523251, "tmdate": 1762915832259, "mdate": 1762915832259, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "PhotoArtAgent is an end-to-end image retouching system that uses top-performing LLMs to itertaively suggest image editing instructions, which are fed to image editing tools such as Lightroom. The entire pipeline of image analysis, initial proposal and iterative refinement mimicks human professionals. Using this system, the authors match human experts in an extensive user study."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. Core technical details, such as detailed prompts, are provided in the paper, making it a good contribution for practitioners. \n\n2. This work provides an end-to-end system, a good engineering effort.\n\n3. There is a justification for iterative refinement, as 76.2% of the edited images required multiple iterations(fig 5b)."}, "weaknesses": {"value": "Major\n1. Wrong venue for the contribution made: This work appears to be more of a systems demonstration than a meaningful submission to the ICLR main conference. There are no advances made or indicated in the paper, in image retouching, evaluation of image aesthetics, reasoning or general abilities of LMMs. L197(\"all these steps are performed by the same VLM with different prompts\") effecitvety indicate prompt engineering, which cannot be a scientific contribution.\n\n2. PhotoArtAgent is entirely training-free, effectively just an API call to top LLMs. The work can be condensed into:  LMMs with sufficient prompt engineering + Lightroom API can do photo retouching.\n\n3. There are very limited technical contribution compared to MonetGPT[1], both of which perform the same task. While PhotoArtAgent proposes a system engineering + prompt design framework, MonetGPT has a novel training pipeline. This work depends on commerical APIs while MonetGPT is reproducible. This work incurs continuous costs through API calls while MonetGPT has a one-time training cost. This work relies on a single user study as evaluation whereas MonetGPT is tested on many benchmarks, with considerable ablations. While iterative refinement with reasoning is done by this work, it is already well studied in NLP. \n\n4. There is no engagement with Image Quality Assesment works, which is an essential baseline to have. For example, testing LMMs on Q-Bench would indicate which one to finally choose.\n\nMinor\n1. The submission is formatted to ICLR 2025. While not grounds for desk rejection, the formatting should be fixed. \n\n[1] Dutt et al. MonetGPT: Solving Puzzles Enhances MLLMs’ Image Retouching Skills, SIGGRAPH 2025"}, "questions": {"value": "1. Is 0 (noticeable flaws) to 10 (creative and satisfying) the best set of proxies to use? One checks technical quality and the other artisitic creativitiy.\n\n2. This work uses GPT-4V to judge the aesthetic quality of suggestions made by another GPT4 model (GPT4-o). Is this reliable? GPT models will have inherent aesthetic preferences within themselves.\n\n3. Is there an intuitive reason why a separate histogram benefits the final result, when this information is already inferrable by the VLM from the image itself?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5RskDly309", "forum": "7LH3Jzc7b9", "replyto": "7LH3Jzc7b9", "signatures": ["ICLR.cc/2026/Conference/Submission1610/Reviewer_u4LX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1610/Reviewer_u4LX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1610/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761930557499, "cdate": 1761930557499, "tmdate": 1762915832119, "mdate": 1762915832119, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes PhotoArtAgent, an agent that uses existing multimodal large language models such as GPT-4o to understand and edit photos through interaction with users. The agent adjusts photo parameters in Adobe Lightroom, including color, lighting, and tone, according to user requests. The authors evaluate the system through user studies and GPT-4V evaluation scores, with the main experiments conducted on the MIT-Adobe FiveK dataset."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is clearly written and well explained. The figures effectively illustrate the workflow and are visually appealing, showing a good graphical style. Overall, it is easy to understand.\n\n2. Photo editing itself is an interesting task, and using powerful large language models to control professional tools such as Lightroom for editing is an appealing and interesting application direction."}, "weaknesses": {"value": "This topic itself is quite interesting, but the current submission has several issues:\n\n1. The paper’s GPT-based agent and the designed workflow, in the context of today’s agent research, show limited insight therefore the contribution is relatively limited. The overall agent and workflow design are quite straightforward. The explanation and reflection mechanisms are common in current agent or workflow studies.\n\n2. Using Lightroom (Lr) for editing with agents is an interesting task. However, if the highlights in agent or workflow design are relatively weak, I would expect some unique findings in this specific setting (Lr agent for editing) compared to other popular agent application scenarios. Yet, in Section 3, the analysis remains rather general. For example, the subsection on Effects of the Reflection Mechanism is a bit trivial, in most cases, we would see better results with multiple intuitive trials/reflections.\n\n3. Experimental setup. I noticed that the parameters adjusted include light, tone (temperature, tint, etc.), and color. These are relatively simple and fundamental parameters, available in almost all mainstream editing apps, and default phone editing tools. On one hand, this shows that these parameters are fundamental; on the other hand, it also means the editing tasks are quite basic. Some examples in the paper (e.g., Fig. 7 and 8) and those in the MIT-Adobe FiveK dataset are actually simple, mostly involving global technical adjustments (such as exposure and color correction), without expressive or stylized editing, or local editing. This also explains why in Table 1, user study shows that, Lightroom Auto performs quite well. This largely reduces the contribution of the paper. Has the author attempted more localized adjustments, such as using masks, gradient filters? Or some more practical adjustments like curve adjustment? That would make the work more interesting and practical, given that authors choose the powerful Lightroom as the tool."}, "questions": {"value": "1. Most adjustment in MIT-Adobe FiveK are quite simple, related to global technical adjustments (such as exposure and color correction). Lightroom Auto is good at such adjustments (Figure 7 shows comparisons. PhotoArtAgent seems to involve overexposure in certain areas ). Given that authors showed some stylized editing examples, would you consider doing some related evaluation?\n\n2. If we just consider the basic adjustments related to technical correlation, like the main evaluation in the submission on MIT-Adove FiveK, I wonder if PhotoArtAgent can show obvious advantages over Lightroom Auto? The LLM based workflow can be very time-inefficient, considering CoT, reflection, etc. While Lightroom Auto is done in one second. In this case, I wonder how authors would explain the advantage of PhotoArtAgent? From user study and examples in Fig. 7, they are very close, and in fig. 7, Lightroom Auto may be even a little better in some cases.\n\n3. Have authors considered more editing? Given the powerful features in Lightroom, and the image understanding capibility of GPT, performing simple global edits in light/tone/color can be trivial. Have you tried local edits or curve edits, which are also practical and frequently used in post-processing?\n\nOverall I think the topic is interesting. But the contributions of the current version is limited. Details are available in Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CVXYp3DNje", "forum": "7LH3Jzc7b9", "replyto": "7LH3Jzc7b9", "signatures": ["ICLR.cc/2026/Conference/Submission1610/Reviewer_9PLW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1610/Reviewer_9PLW"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1610/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761934424992, "cdate": 1761934424992, "tmdate": 1762915831964, "mdate": 1762915831964, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}