{"id": "DsS3xRPSs5", "number": 20745, "cdate": 1758309596957, "mdate": 1763685009881, "content": {"title": "Test-Time Alignment for Large Language Models via Textual Model Predictive Control", "abstract": "Aligning Large Language Models (LLMs) with human preferences through finetuning is resource-intensive, motivating lightweight alternatives at test time. We address test-time alignment through the lens of sequential decision making, a perspective that reveals two fundamental challenges. When actions are defined at the token level, as in guided decoding, alignment suffers from the curse of horizon. Conversely, when actions are at the response level, as in traditional iterative refinement, the curse of dimensionality emerges. To resolve this trade-off, we draw inspiration from Model Predictive Control (MPC) in control theory to propose Textual Model Predictive Control (TMPC), a novel predictive planning framework adapted for aligning LLMs at inference time. A key limitation of standard MPC is its reliance on predefined, hard segment boundaries, which are often absent in text generation. TMPC overcomes this by introducing two principles inspired by hierarchical reinforcement learning: (1) Hindsight Subgoal Identification, where TMPC analyzes generation subgoals to retrospectively identify high-reward intermediate outputs as subgoals. This allows the framework to discover meaningful, task-specific planning steps (e.g., a sentence in machine translation or a bug fix in code generation.). (2) Subgoal-Conditioned Re-Generation, where these identified subgoals are used to guide subsequent planning iterations. By conditioning on these proven, high-quality subgoals, TMPC ensures stable improvement by building upon previously validated successes. TMPC is evaluated on three tasks with distinct segmentation properties: discourse-level translation, long-form response generation, and program synthesis. The results demonstrate that TMPC consistently improves performance, highlighting the generality.", "tldr": "Test-time preference alignment, Large Language Models, Machine translation", "keywords": ["Test-time preference alignment", "Large Language Models", "Machine translation"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/756e31509c684a22f6d8786c580625eff6b90301.pdf", "supplementary_material": "/attachment/3e9bffbf52972d8445bb049007c30b7ec9d11382.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents Textual Model Predictive Control (TMPC), a novel framework for test-time LLM alignment. It insightfully frames the problem as a trade-off between the 'curse of horizon' in token-level optimization and the 'curse of dimensionality' in response-level optimization. TMPC introduces a middle ground by first identifying meaningful \"subgoals\" from generated text and then optimizing generation conditioned on these discovered segments. The framework uses two core principles: Hindsight Subgoal Identification to find high-reward text segments, and Subgoal-Conditioned Re-Generation to build upon them, achieving strong results without updating model parameters.\n\nThis is a very good paper with a highly promising and original core idea. The conceptual framing is excellent, and the initial results are strong. However, its claims of novelty rest on an unsubstantiated comparison, and the paper writing to clarity of its core mechanisms and analysis needs improvement. With the addition of a crucial heuristic baseline comparison and a clearer analysis of its mechanics, this paper has the potential to be a top-tier."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "* The paper's primary strength is its excellent framing of the alignment problem as a trade-off between token-level and response-level, providing a clear motivation for a new class of solutions. The central concept of planning via subgoals is elegant. Figure 1 is a great illustration.\n* The method is designed to be task-agnostic, discovering subgoals automatically rather than relying on pre-defined structures. This is a significant advantage over methods that require task-specific engineering.\n* Bringing ideas from control theory is interesting."}, "weaknesses": {"value": "* The paper's central claim is that its hindsight identification of subgoals is a key innovation. However, given this is for test-time alignment, users can easily use a cheap, task-specific heuristic (e.g., sentence boundaries for translation) for their own task. So, I think task-specific handmade subgoal is a very strong and obvious baseline. Without showing that TMPC's discovered subgoals outperform these simple heuristics, the true value of the complex discovery mechanism is questionable.\n* The paper's idea is good but a better writing may improve the quality and make it easier to follow. The central concepts of \"subgoal\" and \"re-generation\" remain abstract due to a lack of concrete examples, and the results are not deeply explored maybe due to limited space. We strongly suggest  maybe a better use of appendix and a concise revision on the methods background and literature to using the space to provide the essential examples and analysis needed to fully validate the framework's contribution."}, "questions": {"value": "* To justify the core novelty of hindsight identification, is TMPC demonstrably better than using simple, human-curated subgoals? For instance, in the paragraph-level MT task, how does TMPC's performance compare against a version that uses pre-defined sentence boundaries as the subgoals? This single experiment is critical to proving the value of your proposed mechanism over cheaper, task-specific alternatives.\n* Figure 2 suggests subgoals from different rollouts are composed as conditioning for the next generation step. How does the model ensure narrative and logical coherence when concatenating these segments, which may originate from conflicting generation paths? Can you provide analysis showing this composition does not harm the fluency and continuity of the output?\n* The concept of a \"subgoal\" remains abstract. Could you provide concrete examples of the subgoals TMPC actually identifies across the three tasks? For program synthesis, what does an \"abstract\" subgoal that resolves a single test case look like in the generated text? This is essential for understanding what the model is learning to value as a planning step.\n* The subgoal buffer B is a finite resource. In very long generation tasks, what prevents the buffer from being filled with early, locally-optimal subgoals, thus hindering exploration in later stages of generation? Is there a mechanism to manage the buffer's contents beyond a simple capacity limit, such as diversity promotion or aging out older subgoals?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GtGOnPWDNI", "forum": "DsS3xRPSs5", "replyto": "DsS3xRPSs5", "signatures": ["ICLR.cc/2026/Conference/Submission20745/Reviewer_SBgL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20745/Reviewer_SBgL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20745/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969784726, "cdate": 1761969784726, "tmdate": 1762934170095, "mdate": 1762934170095, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper formulates LLM-generated subgoals as a model predictive control problem (TMPC). They identify subgoals via hindsight replay and use the identified subgoals to regenerate the final answer. The have extensive results on against many baseline methods on various datasets."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "-Figure 1 clearly shows the high-level idea of the approach compared to traditional methods. The caption is also descriptive and clear to reinforce the ideas in the Figure and introduction\n\n-The paper is easy to follow and mythology is clear\n\n-The proposed approach outperforms baselines in various tasks. I specifically appreciate the failure cases in baselines such as in L406."}, "weaknesses": {"value": "The related works discussion lacks a discussion on subgoal generation for LLM/VLM-based tasks, where prior work already exists [1, 2]. I do think there is novelty in formulating this as a test-time model predictive control problem.\n\n[1] Logeswaran, Lajanugen, et al. \"Few-shot Subgoal Planning with Language Models.\"¬†Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2022.\n\n[2] Wang, Jiawei, et al. \"Discovering intrinsic subgoals for vision-and-language navigation via hierarchical reinforcement learning.\" IEEE Transactions on Neural Networks and Learning Systems 36.4 (2024): 6516-6528."}, "questions": {"value": "Minor Suggestion:\n-There is an extra comma on L28\n-Maybe move the legend of Figure 1 to the top or bottom and spanning across all three methods to make it more clear it applies to all three"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7bEfoVb4Db", "forum": "DsS3xRPSs5", "replyto": "DsS3xRPSs5", "signatures": ["ICLR.cc/2026/Conference/Submission20745/Reviewer_FkBi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20745/Reviewer_FkBi"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20745/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997242485, "cdate": 1761997242485, "tmdate": 1762934168940, "mdate": 1762934168940, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Textual Model Predictive Control (TMPC), a novel framework for aligning large language models (LLMs) with human preferences at test time by casting the generation process as a sequential decision-making problem. TMPC draws inspiration from model predictive control (MPC), incorporating Hindsight Subgoal Identification to automatically detect useful intermediate subgoals and Subgoal-Conditioned Re-Generation to iteratively refine generations. The framework is evaluated on long-form machine translation, long-form response generation, and program synthesis, demonstrating improvements over several training-time and test-time baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. TMPC elegantly adapts concepts from control theory (specifically model predictive control) to the LLM test-time alignment setting, innovating with subgoal identification and iterative planning, as detailed in the mathematical framework of Section 4 and illustrated in Figure 2.\n\n2. The methodology is general: TMPC is applied to tasks with both natural and abstract segment boundaries (e.g., machine translation sentences, code unit tests, long-form response chunks), supporting claims about its versatility.\n\n3. Empirical results cover multiple domains using both automatic and large-model-based human-proxy metrics. On WMT'24 translation (Table 1), TMPC outperforms both test-time and competitive training-time alignment baselines; for example, it achieves state-of-the-art SEGALE scores and minimal NA Ratios across several language directions, substantially exceeding methods like ARGS and GenARM."}, "weaknesses": {"value": "1. Reward-model dependence / shared-judge bias. Long-form tasks use similar reward models for both alignment and evaluation, inviting bias and potential reward gaming; despite noise-robustness tests, evidence for agreement with human preferences and cross-evaluator consistency is limited.\n\n2. Underspecified subgoal & buffer aggregation. The threshold Œ±, buffer ùìë update/size policy, and aggregation function ùí¢ (composition of non-contiguous subgoals, overlap limits, length control) are not concretely specified; scalability as buffer/search grow is untested.\n\n3. Unquantified compute/latency cost. Multi-round rollouts and rewrites likely incur higher cost than token-level guidance (e.g., ARGS, GenARM), but per-task wall-clock time, GPU-hours, and throughput/latency are not reported.\n\n4. **Missing comparisons to sequence-level rewriting baselines.** No direct comparison against sequence-level rewriters (e.g., **aligner**, **sentence aligner**), leaving TMPC‚Äôs advantage over these methods unclear."}, "questions": {"value": "1. Can the authors provide more formal analysis or empirical ablation regarding the impact and tuning sensitivity of the buffer threshold $\\alpha$ and the aggregation function $\\mathcal{G}$? For example, does increasing $\\alpha$ risk filtering out necessary diversity or causing premature convergence?\n\n2. What explicit strategies does TMPC employ to avoid redundancy or incoherence when assembling non-contiguous subgoals in the generation process? Are there failure cases where the compositionality breaks down?\n\n3. Can you include more thorough ablation on the contributions of Hindsight Subgoal Identification versus Subgoal-Conditioned Re-Generation? A demonstration on at least one benchmark of removing or varying each component in isolation would help clarify this."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "P0UIYWremX", "forum": "DsS3xRPSs5", "replyto": "DsS3xRPSs5", "signatures": ["ICLR.cc/2026/Conference/Submission20745/Reviewer_1rTe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20745/Reviewer_1rTe"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20745/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762004444048, "cdate": 1762004444048, "tmdate": 1762934167758, "mdate": 1762934167758, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper considers the problem of test-time alignment of a fixed large language model (LLM) with a given reward function that encodes externally specified preferences. The paper proposes an iterative improvement method, called Textual Model Predictive Control (TMPC), that combines (i) identification of promising, high-reward subgoals (tokens, sections of text, etc.) within a response with (ii) aggregation of promising subgoals into subsequent prompts. The proposed method is loosely based on the standard model predictive control (MPC) formulation, with the MPC-based formulation of Section 4.1 serving as the point of departure; Principles 1 and 2 of Section 4.2 are the core components of the approach, however, and these are not clearly MPC-based. Experimental evaluation of TPMC against relevant baselines on machine translation, long-form response generation, and program synthesis problems is provided. The experimental evaluation indicates that TMPC outperforms baselines on two-thirds of the machine learning tasks, outperforms all baselines on the long-form response generation task, and achieves higher pass rates than all baselines on the program synthesis tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The test-time alignment problem has seen immense interest from the community in recent years, so the topic of the paper is timely. The proposed TMPC approach is an intuitively appealing and natural approach to this problem, so the paper is likely of interest to the community. Drawing inspiration from MPC through the formulation given in Section 4.1 provides motivation and technical clarity for the (non-MPC) specifics of the proposed approach described in Section 4.2. The experiments consider three well-known benchmark problems and compare the proposed approach with a good variety of appropriately chosen, well-known baseline methods. The experimental results support the effectiveness of the proposed TMPC approach."}, "weaknesses": {"value": "1. The connection to MPC feels somewhat overstated. Section 4.1 provides enough context to justify describing the approach as loosely MPC-inspired. However, since the main elements of the method are the non-MPC components outlined in Principles 1 and 2 (Section 4.2), framing as an MPC-based approach may be a bit strong.\n2. The experimental results, though promising, contain some drawbacks that are not adequately discussed. First, though it is claimed on lines 401-402 that \"TMPC consistently outperforms all test-time alignment baselines\" on the machine translation tasks, Table 1 shows that TMPC is in fact outperformed by TPO on the Chinese-to-Russian translation task. In addition, as mentioned in footnote 3 on page 8, on the long-form response task TPO was stopped after two iterations instead of the four iterations used elsewhere due to implementation and/or hardware issues, not problems inherent to TPO. For this reason, the comparison results presented in Figure 3 are incomplete with respect to TPO; it is especially important to have an accurate picture of TPO's performance given that TPO was a top competitor on the machine translation tasks."}, "questions": {"value": "1. In what way is the formulation of the test-time alignment problem as a sequential decision-making problem (lines 97-98) novel?\n2. By what mechanism does the does the design of TMPC \"achieve a better balance between accurate credit assignment and the size of the search space\" (lines 240-241)?\n3. Is it true that Principles 1 and 2 on page 5 are not clearly related to MPC?\n4. Can you elaborate on the fact that GPT-4o outperforms or is highly competitive with TMPC in the experiments presented in Table 1?\n5. Can you comment on the fact that on lines 401-402 it is stated that \"TMPC consistently outperforms all test-time alignment baselines\" on the machine translation tasks, yet Table 1 shows that TMPC is outperformed by TPO on one of the three tasks?\n6. As mentioned in footnote 3 on page 8, on the long-form response task TPO was stopped after two iterations instead of four iterations; does this negatively impact the fairness of the comparison between TPO and TMPC in Figure 3?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dShQntiin8", "forum": "DsS3xRPSs5", "replyto": "DsS3xRPSs5", "signatures": ["ICLR.cc/2026/Conference/Submission20745/Reviewer_UYVg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20745/Reviewer_UYVg"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20745/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762208471199, "cdate": 1762208471199, "tmdate": 1762934166785, "mdate": 1762934166785, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Response to All Reviewers"}, "comment": {"value": "We thank all reviewers for the thoughtful and constructive feedback. We have updated our manuscript to address the points raised, with modifications highlighted in blue. Below, we further highlight the responses to the key concerns.\n\n---\n\n### **(1) Additional empirical analyses**\n\nReviewer 1rTe suggested evaluating the sensitivity and robustness of TMPC. In response, we added:\n\n**Threshold sensitivity (Table 2(c); Section 5.5).**\nWe examine how the buffer threshold ( \\alpha ) influences performance. Results show that TMPC remains stable across a wide range of values. We also explain the behavior when ( \\alpha ) is too low (early admission of weak segments) or too high (reduced diversity approaching Best-of-(N)). Reviewers also asked how ( \\mathcal{G} ) affects outcomes. We clarify its role and report the result.\n\n**Ablation of TMPC‚Äôs two principles (Table 2(d); Section 5.5).**\nFor TMPC's two principles contribution, we ablate (i) hindsight subgoal identification and (ii) subgoal-conditioned rewriting. Both contribute meaningfully, and the full TMPC design performs best.\n\n**Compute and latency (Appendix D.3).**\nWe added wall-clock latency and throughput comparisons across all guided decoding, TPO (2 iterations and 4 iterations) and TMPC.\n\n### **(2) Concrete subgoal examples and coherence analysis (Appendix G)**\n\nReviewer SBgL and Reviewer 1rTe suggested providing clearer examples of the subgoals that TMPC identifies, as well as illustrating how coherence is preserved when these subgoals originate from different rollouts\n\nWe now include real examples from MT, HH-RLHF, and program synthesis, showing buffer construction and subgoal retention.\nTo keep the main text concise, we illustrate the mechanism with compact, hand-selected responses, while appendix contains the full long-form outputs.\n\nWe also clarify that TMPC do not concatenate subgoals: TMPC generates a fresh full response conditioned on high-reward segments. Even when sampled subgoals conflict, outputs remain coherent.\n\n### **(3) Paragraph-Level MT Heuristic Ablation (Appendix D.2)**\n\nWe added the heuristic method (fixed sentence boundaries) suggested by Reviewer FkBi, showing that even with natural boundaries, hindsight identification yields better translations.\n\n### **(4) Expanded related work on subgoal planning (Section 2.3)**\n\nReviewer FkBi noted missing connections to prior subgoal-based methods. We now discuss some subgoal generation work for LLM/VLM-based tasks, and hindsight goal-generation in RL, and contrast them with TMPC's test-time, frozen-LLM setting and fixible subgoal formulation."}}, "id": "2OquaA7Mo5", "forum": "DsS3xRPSs5", "replyto": "DsS3xRPSs5", "signatures": ["ICLR.cc/2026/Conference/Submission20745/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20745/Authors"], "number": 11, "invitations": ["ICLR.cc/2026/Conference/Submission20745/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763679791198, "cdate": 1763679791198, "tmdate": 1763679791198, "mdate": 1763679791198, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}