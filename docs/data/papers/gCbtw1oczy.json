{"id": "gCbtw1oczy", "number": 13915, "cdate": 1758224940969, "mdate": 1759897403817, "content": {"title": "Reinforcement Learning for Clinical Reasoning: Aligning LLMs with ACR Imaging Criteria", "abstract": "Medical imaging has revolutionized diagnosis, yet unnecessary procedures are rising, exposing patients to radiation and stress, limiting equitable access, and straining healthcare systems. The American College of Radiology Appropriateness Criteria\\textsuperscript{\\tiny\\textregistered}, developed through extensive multidisciplinary review, provide evidence-based guidance but remain underutilized. Leveraging advances in LLM reasoning, we introduce a Reasoning Agent trained with Reinforcement Learning (RL), specifically Group Relative Policy Optimization (GRPO), to replicate expert clinical reasoning from the ACR Criteria. We present a novel RL approach for structured medical reasoning, systematically comparing reasoning-focused reward functions and evidence integration strategies. Our lightweight 8B model, \\textit{MedReason-Embed}, improves macro F1 by 18\\% over baseline, shows stronger reasoning alignment, and outperforms both larger and alternatively trained models, showing that reasoning-based supervision enables efficient, trustworthy clinical AI. Building on this, we design a modular end-to-end agentic architecture that automates imaging referrals: mapping diagnoses to ICD codes, retrieving PubMed evidence, and recommending optimal procedures. Crucially, the ability to generalize beyond static ACR guidelines not only enables clinicians to handle out-of-distribution cases, but also supports scaling the guideline development process itself, potentially reducing the significant effort required to create and update them. This work shows the potential of reasoning-focused RL within agentic architectures to deliver transparent, scalable, and reliable clinical decision support. Our code is available at: \\url{https://anonymous.4open.science/r/agentic-imaging-recommender-iclr-877D}", "tldr": "This paper introduces MedReason-Embed, an RL-trained reasoning agent that outperforms larger models in imaging guideline adherence, enabling accurate, scalable, and trustworthy clinical decision support.", "keywords": ["Medical Imaging", "Reasoning", "ACR Appropriateness Criteria", "GRPO"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8190396c785c8f7df002fc6ae40a50be171ccf7c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a modular, agent-based system for supporting clinical imaging recommendations by aligning large language models (LLMs) with American College of Radiology Appropriateness Criteria (ACR-AC). The approach centers on training a Reasoning Agent using Group Relative Policy Optimization (GRPO) and designing custom, reasoning-focused reward functions to encourage expert-like intermediate reasoning steps, rather than simply optimizing for correct final answers. The pipeline includes ICD-9 coding, multi-step retrieval and filtering of medical literature, and an end-to-end evaluation framework to test robustness, generalization, and scalability. Experiments demonstrate that the reasoning-augmented RL model (MedReason-Embed) delivers significant macro F1 improvements over standard supervised training and even outperforms much larger models, with added transparency and potential for generalization beyond static guideline scenarios."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Holistic Agentic Design: The modular, agent-oriented pipeline is thoughtfully engineered for practical and scalable deployment in real-world clinical imaging workflows. The inclusion of ICD coding and PubMed-based retrieval tightly integrates with established clinical data and processes, addressing both interoperability and evidence curation bottlenecks. Figure 2 is highly effective in illustrating system flow; it clarifies how outputs of each agent (e.g., ICD Coding Agent, Criteria Checker, Post-Filtering Agent) are chained, and what justifications pass through the system.\n2. Originality in Reward Formulation: The exploration and systematic comparison of reasoning-focused reward functions, especially the “joint reasoning” cosine similarity-based MedReason-Embed reward (Eq. on Page 6 and Section 3.3), fills a prominent gap in medical AI, where prior work often settles for simple answer and format rewards. The linking of reasoning quality directly to outcomes represents a creative step toward more trustworthy AI in clinical domains.\n3. Comprehensive Experimental Evaluation: The technical rigor of experimental protocol is commendable. The authors conduct extensive quantitative benchmarking (Tables 2–6), with well-chosen metrics (macro/weighted F1, LLM-alignscore, NER Embedding F1), fair baselines, ablations, and out-of-distribution tests on “generalization conditions.\" The side-by-side performance with SFT models and much larger models (LLaMA-3.1-405B) is transparently reported.\n4. Methodological Rigor in Mathematical Details: The implementation of the GRPO objective is clearly stated, including the group relative advantage calculation and explicit KL penalty term in the loss (Equation in Section 3.3).\nImpact and Reproducibility: Code availability and detailed hyperparameter settings (Appendix A), along with dataset statistics and pipeline explanations, support future reproducibility and foster open-source research.\n5. Strong Use of Figures and Tables: Figures are well-integrated and informative. For instance, Figure 3 (Page 16) and Figure 4 (Page 16) provide clear, concrete examples of reasoning traces and how different model outputs are assessed and rewarded—this lends transparency to the reward formulation. Table 3 and Table 4 document the quantitative performance improvements across model variants and reasoning alignment scores, underpinning key claims.\n6. Meaningful Generalization Experiments: The effort to test on conditions outside of the ACR-AC training set and compare pipeline-retrieved citations with gold-standard ACR references (Tables 5 and 6) is excellent and directly tied to the primary motivation for scalable, guideline-independent AI.\n7. Interpretability and Clinical Trust: The stepwise, tag-structured outputs (<think>, <answer>), and ablation results detailing improvements in qualitative alignment, are likely to be of interest to clinicians seeking interpretable AI."}, "weaknesses": {"value": "1. Several directly relevant recent works are not cited or compared—especially those advancing lightweight clinical reasoning LLMs, rule-based reward alignment, or multimodal decision support in radiology.\n2. The core experimental dataset is limited to 1,800 triplets from just 30 ACR-AC conditions, with only 4 “unseen” generalization conditions for OOD evaluation. This is a very limited slice of the clinical imaging space (out of the 257+ topics available). As such, the demonstrated generalization is suggestive but not conclusively established. Broader or more diverse generalization studies (e.g., multiple medical centers, complex/ambiguous notes, higher ICD code diversity) are needed to make strong claims about real-world robustness.\n3. Absence of In-Depth Theoretical Analysis of Reward Behaviors.\n4. For evidence retrieval and filtering, the pipeline depends solely on PubMed abstracts and metadata, rather than utilizing full-text papers. This choice, though practical, risks missing nuanced evidence, study limitations, or trial context, which may undermine the strength of retrieved recommendations. While acknowledged under “Limitations,” no systematic impact analysis is performed—in particular, there are no ablation studies quantifying the performance drop or hallucination risk versus using full articles.\n5. Although Macro F1 and Weighted F1 are appropriately reported in Tables 3–6, the manuscript does not present class confusion matrices or a deeper breakdown (e.g., per-condition or per-procedure breakdowns), which would help clarify error modes and class imbalance effects.\n6. There is no user study or assessment of utility or trust by practicing clinicians, and therefore, while the approach is clinically motivated and outputs are interpretable, user acceptance is merely speculative at this point."}, "questions": {"value": "1. How does the model handle ambiguous, multi-diagnosis clinical notes? Most of the ICD coding experiments are run on short, unambiguous cases (Table 2, Figure 7). How would the pipeline perform on real-world hospital notes with several possible ICD codes per case, and what adaptation strategies are envisioned for deployment?\n2. What are the error modes of the MedReason-Embed reward? Can the authors provide failure examples where reasoning trace cosine similarity aligns with expert annotations but the underlying logic is flawed or leads to clinically invalid recommendations? Is there empirical evidence of the frequency and clinical significance of such cases?\n3. Impact of Using Full-Text Evidence: Abstract-level reasoning may miss nuance and introduce bias. Have the authors tested retrieval or reasoning using full articles instead of only abstracts? If so, how do performance and hallucination risk change?\n4. Generalization to Other Modalities or Guidelines: Since the approach is modular and claims extension potential, did the authors conduct any preliminary testing (even qualitative) on non-imaging guidelines, or is generalization purely hypothetical?\n5. Training Stability and Efficiency: Table 4 and Figure 5 suggest differences in training efficiency (esp. LLM-Eval vs. MedReason-Embed). Can the authors share absolute wall times/hardware specs for main runs, and elaborate on bottlenecks or instability encountered, especially for larger batch/group sizes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A."}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "M5vcIeYp4Y", "forum": "gCbtw1oczy", "replyto": "gCbtw1oczy", "signatures": ["ICLR.cc/2026/Conference/Submission13915/Reviewer_wbkT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13915/Reviewer_wbkT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761575938336, "cdate": 1761575938336, "tmdate": 1762924422335, "mdate": 1762924422335, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper offers a multi-agent system designed to help LLMs adhere to the American College of Radiology's imaging guidelines. The authors are tackling a significant real-world problem. these evidence-based guidelines are widely underutilized by clinicians. The proposed system automates the entire imaging referral workflow, starting from interpreting a clinical note and assigning an ICD code, then retrieving relevant evidence, and finally producing a reasoned recommendation. The core of this work is the Reasoning Agent, a lightweight 8B model trained using GRPO. The key innovation is its process-oriented reward function, which simultaneously optimizes for a correct final answer and for semantic alignment with expert-derived reasoning steps. The results show that MedReason-Embed model can outperform both standard supervised fine-tuning and even a much larger 405B parameter model."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- This work addresses a highly significant and practical clinical problem. Reducing the overuse of low-value imaging has direct, positive implications for both patient safety (e.g., lower radiation exposure) and healthcare costs.\n\n- The modular, multi-agent architecture is a very sound engineering choice. It intelligently decomposes an extremely complex clinical workflow into distinct, inspectable components (coding, filtering, reasoning), which is a practical approach for future development and real-world integration.\n\n- The paper’s focus on process-supervised reinforcement learning is a valuable methodological contribution. Moving beyond simply rewarding the final correct answer to instead scrutinize the intermediate reasoning steps is a crucial direction for building more transparent and trustworthy medical AI.\n\n- Showing that a carefully tuned 8B model can achieve stronger results than a massive 405B model is a powerful finding. It clearly demonstrates the high value of sophisticated, domain-specific reward engineering over a brute-force approach of simply scaling up model size."}, "weaknesses": {"value": "- My primary concern is the claim of generalization, which I find to be critically underdeveloped. The entire claim of robustness to out-of-distribution cases rests on a test set of only four unseen conditions. This is simply not a large enough sample to draw any meaningful conclusions or to support such a broad claim.\n\n- The paper is missing the single most important validation step, an evaluation by human clinical experts. This is a system built for clinical decision support, yet no radiologists or physicians were brought in to review the final recommendations. As a result, we have no data on the clinical validity, safety, or real-world utility of its outputs.\n\n- The reasoning-focused reward feels superficial. It relies on semantic similarity (cosine similarity) to a gold trace, which is not a reliable proxy for logical or clinical correctness. It seems entirely possible for this metric to reward a model for generating text that sounds correct but is clinically flawed or even dangerous.\n\n- The evidence-gathering pipeline relies exclusively on abstracts, not full-text articles. This is a significant flaw, as abstracts are summaries and frequently omit the critical methodological limitations, data nuances, or contraindications that are essential for making a sound medical judgment.\n\n- The presentation quality of the figures and tables also detracts from the paper. Several key visuals intended to clarify the methodology, such as the system architecture diagram, are instead vague and fail to clearly illustrate the complex data flow between agents. Furthermore, some crucial tables reporting main results and features suffer from poor formatting, making them difficult to read and forcing the reviewer to hunt for the information."}, "questions": {"value": "- Could you provide a much stronger justification for your generalization claims? For instance, what was the clinical heterogeneity of those four test conditions, and how do they represent a wider class of problems?\n\n- Were any human clinicians or radiologists involved at any stage, either in validating the \"gold\" reasoning traces you extracted or, more importantly, in reviewing the final recommendations from your MedReason-Embed agent?\n\n- How does your embedding-based reward function penalize reasoning that is semantically similar to the gold trace but contains a critical logical flaw or clinical error?\n\n- Given the system's reliance on abstracts, how do you propose to handle the inevitable cases where the critical piece of information (e.g., a key limitation, a specific patient subgroup) is only mentioned in the full text of a study?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PzTOxBfTOl", "forum": "gCbtw1oczy", "replyto": "gCbtw1oczy", "signatures": ["ICLR.cc/2026/Conference/Submission13915/Reviewer_hJMK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13915/Reviewer_hJMK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761702323514, "cdate": 1761702323514, "tmdate": 1762924421732, "mdate": 1762924421732, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an **agentic clinical decision-support pipeline** that aligns LLM reasoning with the **ACR Appropriateness Criteria (ACR-AC)** via **reinforcement learning**. The system comprises: (i) an **ICD coding agent** that maps clinical notes to ICD-9-CM codes; (ii) a **Reasoning Agent** trained with **Group Relative Policy Optimization (GRPO)**; (iii) a **medical evidence retriever** (DeepRetrieval-PubMed-3B) with a **post-filtering module** approximating GRADE-style strength-of-evidence scoring; and (iv) an end-to-end controller that mirrors ACR guideline workflow.\n\nKey technical ideas:\n- **Reasoning-aligned RL**: multiple reward designs compare generated “reasoning traces” against expert rationales distilled from ACR-AC (“Baseline”, “Citations”, “LLM Eval”, and **MedReason-Embed** joint reward). (*Section 3.3; Table 1 on p.6*).\n- **Modular agent architecture** grounded in guideline workflow. (*Figure 2 on p.4*).\n- **Evaluation** on ~1,800 triplets from 30 ACR conditions (70/30 split), plus **four unseen conditions** for generalization; metrics include **Macro/Weighted F1**, an **LLM-based alignment score**, and **NER-based F1** for reasoning overlap. (*Section 4; Tables 3–6 on pp.7–8*).\n\nMain results:\n- **MedReason-Embed** and **LLM Eval** outperform SFT and a larger unfine-tuned LLaMA-3.1-405B on Macro/Weighted F1 and reasoning alignment, at lower or comparable compute than LLM-as-judge rewards. (*Tables 3–4*).\n- The ICD agent achieves **Top-1 80.45%** and **Hierarchical Top-1 91.47%** accuracy on a synthetic/curated dataset. (*Table 2 on p.7*).\n- Under distribution shift (unseen conditions) and with non-ACR citations, performance degrades modestly, preserving model ranking. (*Tables 5–6 on p.8*).\n\nOverall, the paper argues that **process-supervised RL** (reasoning rewards) plus **retrieval grounding** yields **more trustworthy** and **generalizable** clinical imaging recommendations than SFT alone. :contentReference[oaicite:0]{index=0}"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. **Well-aligned system design** that mirrors real guideline workflows; compelling **architecture** with clean module boundaries.\n2. **Reasoning-first RL**: clear comparison of **answer-only vs. reasoning-linked** rewards; the **MedReason-Embed** joint reward is simple and effective. \n3. **Grounded retrieval and filtering**: DeepRetrieval query rewrites and GRADE-inspired post-filtering with interpretable features. \n4. **Transparent reporting** of training config, reward examples, and trajectories (suggestive “aha” phase).\n5. **Practical ICD mapping pipeline** with decent accuracy and a sensible metric suite (Top-k, hierarchical, MRR)."}, "weaknesses": {"value": "1. **Limited scale & diversity**: 30 training conditions and 4 unseen conditions are **too narrow** to support strong generalization claims across ACR’s 257 topics; add ≥50–80 unseen scenarios across multiple body systems.\n2. **Reasoning metric fidelity**: LLM-as-judge and NER-overlap can reward fluent but shallow chains or penalize correct-but-paraphrased reasoning. Consider **expert rubric scoring** and **counterfactual tests** (e.g., sensitivity to omitted risk factors).  \n3. **Potential leakage**: since rewards and test rationales both derive from ACR artifacts, the setup may favor **template-matching**; adopt **held-out authoring** or **cross-guideline** transfer (e.g., NICE/ESR) to evidence real reasoning transfer.  \n4. **Safety & governance**: no human evaluation by radiologists here; prospective trials or **reader studies** are needed before clinical claims.  \n5. **ICD-9 reliance**: demonstrate portability to **ICD-10/ICD-11** and non-English clinical notes beyond the curated Italian dataset; quantify effects of mapping errors on downstream decisions.\n6. **Statistical reporting**: while McNemar’s test is noted, the paper should provide **per-class F1**, **confidence intervals**, and **multiple-run variance** (seeds) for RL models."}, "questions": {"value": "1. **Generalization breadth**: Can you expand the unseen-condition set to ≥50 topics spanning trauma, oncology, pediatrics, and cardiovascular domains? What is the expected performance drop vs. in-domain?  \n2. **Robustness tests**: How do models behave under **evidence ablation** (remove key trials) or **contradictory abstracts**? Does MedReason-Embed still choose safe imaging?  \n3. **Reward analysis**: For MedReason-Embed, how sensitive are results to sentence segmentation and embedding choices? Any **failure cases** where correct answers get down-weighted for paraphrases?  \n4. **Human evaluation**: Any preliminary **radiologist blinded review** (appropriateness + justification) on a random stratified sample?  \n5. **Cross-guideline transfer**: If trained on ACR, how well does the system perform on **NICE/ESR** topics without retraining?\n6. **Coding standards**: What is required to migrate to ICD-10/ICD-11, and how does coding accuracy affect end recommendation error rates?  \n7. **Safety guardrails**: Are there hard constraints (e.g., always down-weight CT for pregnancy unless specific red flags) to prevent reward gaming or hallucinated justifications?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "H3j6OP8hc9", "forum": "gCbtw1oczy", "replyto": "gCbtw1oczy", "signatures": ["ICLR.cc/2026/Conference/Submission13915/Reviewer_kSxk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13915/Reviewer_kSxk"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966148227, "cdate": 1761966148227, "tmdate": 1762924421359, "mdate": 1762924421359, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The manuscript presents a reinforcement learning (RL) approach for clinical reasoning, aiming to align large language models (LLMs) with the ACR Imaging Appropriateness Criteria. The authors propose an end-to-end agentic architecture that integrates ICD coding, evidence retrieval, and a reasoning agent trained with Group Relative Policy Optimization (GRPO). While the topic is relevant and the proposed method has potential, the manuscript suffers from significant issues in presentation and coherence that hinder its readability and academic rigor."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The work aims to address a significant clinical problem—the reduction of unnecessary medical imaging—by leveraging AI to implement evidence-based guidelines. This alignment with a real-world healthcare challenge is a clear strength."}, "weaknesses": {"value": "1. The manuscript reads as a collection of loosely connected sections. Key components—such as the ICD Coding Agent, Reasoning Agent, and evidence retrieval—are described in isolation, with insufficient transitions to tie them together.\n2. The methodology section lacks a clear motivation. For instance, the choice of GRPO over other RL methods is not adequately justified, and the relationship between different reward functions and their impact on clinical reasoning remains unclear.\n3. The results are presented in a fragmented manner, making it difficult to draw meaningful conclusions about the overall effectiveness of the proposed system.\n4. The description of the reasoning trace extraction process is vague. The use of `LLaMA-4-Scout-17B-16E-Instruct` is mentioned, but the rationale for selecting this model and the steps taken to prevent hallucinations are not sufficiently detailed.\n5. The reward functions (e.g., `MedReason-Embed`) are introduced without a strong theoretical or empirical justification. The link between reasoning quality and clinical validity is assumed but not thoroughly argued.\n\nMinor issues:\n\n1. Figures such as Fig. 1 and Fig. 2 are pixelated and blurry when enlarged, making it difficult to interpret key components of the proposed system architecture and guideline development process. High-resolution, vector-based figures are essential for clarity and reproducibility.\n\n2. The writing contains informal phrases and ambiguous terminology (e.g., “reasoning-focused rewards,” “lightweight model”), which should be replaced with more precise language."}, "questions": {"value": "see above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jTcZWlfewR", "forum": "gCbtw1oczy", "replyto": "gCbtw1oczy", "signatures": ["ICLR.cc/2026/Conference/Submission13915/Reviewer_3vg1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13915/Reviewer_3vg1"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978604279, "cdate": 1761978604279, "tmdate": 1762924420970, "mdate": 1762924420970, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}