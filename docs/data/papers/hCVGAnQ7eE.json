{"id": "hCVGAnQ7eE", "number": 2334, "cdate": 1757059214842, "mdate": 1759898155275, "content": {"title": "Specializing Large Models for Oracle Bone Script Interpretation via Agent-Driven Multimodal Knowledge Augmentation", "abstract": "Deciphering oracle bone script, which originated over 3,000 years ago and represents the earliest known mature writing system in China, is fascinating and highly challenging. Vision language models (VLMs) offer strong capabilities in perception, understanding, and reasoning, presenting opportunities for cross-disciplinary research. However, their lack of domain-specific knowledge often results in suboptimal performance. Existing approaches largely frame decipherment as an image recognition task, overlooking the hieroglyphic nature of oracle bone script and the structural and semantic information embedded in its component-based design.\nTo address these challenges, we propose an agent-driven multimodal retrieval-augmented generation (RAG) framework that enables large models to act as domain experts for oracle bone research. We also introduce OB-Radix, a component-level oracle bone script dataset annotated by domain experts, which provides essential structural and semantic information absent from prior datasets. Furthermore, guided by expert knowledge, we design three benchmark tasks to systematically evaluate the ability of VLMs in oracle bone decipherment. Experimental results demonstrate that our framework produces more detailed and accurate interpretations than baseline methods.\nBeyond oracle bone script, our framework establishes a methodological foundation for applying large models to the decipherment of other logographic writing systems.", "tldr": "We design an agent-driven multimodal pipeline for Oracle Bone Script interpretation, support it with a novel expert-annotated component dataset, and enable large models to generate accurate interpretations.", "keywords": ["Oracle bone script;Graph RAG;AI-Assisted Archaeological Research;Multimodal Large Models"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3d58390eabcabe3810db5a637d60c6e43fab256b.pdf", "supplementary_material": "/attachment/e733a57cf15ecf94345f092662991542c4699249.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes an agent-driven RAG framework for large models to enhance its capabilities in OBI interpretation. The authors also introduce a component-level oracle bone script dataset, OB-Radix, together with a knowledge graph covering relationships among components, characters, and explanations. Experiments show that the proposed RAG-enhanced framework offers better interpretation that aligns human expert’s reasoning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. A novel RAG framework proposed for OBI interpretation.\n2. OB-Radix, a new component-level oracle bone script dataset."}, "weaknesses": {"value": "1. Lack some references and comparisons between current component-level dataset, such as OBI component 20 [1], OracleSem [2], and the proposed OB-Radix, to highlight the main contributions.\n2. Line 104: HUST-OBC and what? There are only references without detailed dataset names. Besides, several representative character-level OBI datasets, such as OBC306 [3], Oracle-50k [4], HWOBC [5], should also be included in the related work.\n3. The font size in all figures should be increased for better readability. Specifically, the logical chain depicted in Fig. 3 is somewhat unclear, especially in the right half, which needs to be further optimized.\n4. The query image used for verification has a similar form to the oracle characters in the constructed knowledge graph. There may be a risk of domain leakage, which leads to vulnerabilities in the robustness of component identification. Further verification is necessary for the cross-domain matching or component identification results.\n5. The success of the entire system is highly dependent on the constructed knowledge graph dataset, which limits its generalization ability.\n6. The scale of OB-Radix is relatively small compared to existing datasets. And the test set is relatively small (30% of 478 components for Tab. 2)\n7. Lack of experimental verification on open-source models\n\n[1] Hu, Zhikai, et al. \"Component-level oracle bone inscription retrieval.\" *Proceedings of the 2024 International Conference on Multimedia Retrieval*. 2024.\n\n[2] Jiang, Hanqi, et al. \"Oraclesage: Towards unified visual-linguistic understanding of oracle bone scripts through cross-modal knowledge fusion.\" *arXiv preprint arXiv:2411.17837* (2024).\n\n[3] Shuangping Huang, Haobin Wang, Yongge Liu, Xiaosong Shi, and Lianwen Jin. 2019. OBC306: A large-scale oracle bone character recognition dataset. In 2019 International Conference on Document Analysis and Recognition (ICDAR). IEEE, 681–688.\n\n[4] Wenhui Han, Xinlin Ren, Hangyu Lin, Yanwei Fu, and Xiangyang Xue. 2020. Self-supervised learning of Orc-Bert augmentator for recognizing few-shot oracle characters. In Proceedings of the Asian Conference on Computer Vision.\n\n[5] Bang Li, Qianwen Dai, Feng Gao, Weiye Zhu, Qiang Li, and Yongge Liu. 2020. HWOBC-a handwriting oracle bone character recognition database. In Journal of Physics: Conference Series, Vol. 1651. IOP Publishing, 012050."}, "questions": {"value": "1. There is no need to capitalize the first letter in Line 101-102 “Knowledge Graphs”.\n2. The current method is mainly designed for handwritten oracle bone script. I would like to know how this solution performs on the original oracle bone script, such as rubbings or other noisy oracle bone scripts, in order to demonstrate its applicability.\n3. What are the advantages of using Dinov2 as the visual encoder? Lack of comparison with other visual backbones.\n4. In Eq. 1, there is a lack of definition for the symbol \"d( , )\".\n5. Section 3.2: Compared to the main described retrieval process, the construction of the knowledge graph shown in Figure 5 is not as crucial. The former can be illustrated with diagrams to enhance readability.\n6. Section 3.2: Why is the discovery of variants taken as the first step? Wouldn't Exact Matching lead to a direct conclusion? If no exact match is found, then search for variants and radical levels next. What is the reason for setting it up like this at present? Furthermore, in this step, an LLM agent was used to perform such a complex series of operations. Specific descriptions of the implementation details such as prompts, the used model, etc, are missing.  The discussion on the stability of the used agent, and the analysis of failure cases are also lacking.\n7. Section 3.3 is lacking many details, including the designed modules and the classification process carried out by VLM. The current description is too vague. It is suggested to use Figure or formulas to present the entire process in a more logical manner.\n8. Line 215: Using a multi-agent architecture to perform Knowledge Retrieval and Semantic Reasoning is more prone to errors. Considering the instability of the interaction, it is necessary to verify whether this approach is truly necessary. Compared to a single agent sequentially performing these steps?\n9. Section 4: The dataset construction lacks a series of information: Was the source of the images in OB-RADIX sampled from the existing handwritten dataset, and was there a visual comparison with the existing dataset?\n10. Can the challenges related to variant identification be addressed by constructing a more comprehensive knowledge graph? (Tab. 8)\n11. Reorganize the sentence structure in line 247-249 “Even for xxxx,  xxxx linguistic functions.”\n12. The weighted ROUGE and the rationality of weighting need to be proven through methods such as public subjective experiments.\n13. Baselines in line 267-269: As far as I know, Qwen3 and Deepseek-v3 are pure language models and not VLMs.\n14. Settings of the Questionnaire in Figure 12: Based on the given case, the length of the output may potentially affect people's judgment and lead to bias, especially in this 5-level rating scenario.\n15. Lack of baseline comparisons in Tab. 2.\n16. Regarding the OBS ROUGE-1 metric, could there be an explanation or example regarding a perfect performance score, so as to more intuitively reflect the performance of the model in Tab.3,4,5,6,7? Currently, there is only a relative concept, and the absolute performance is unknown.\n17. Regarding the case displayed in Tab. 8, what is the query prompt? Considering fairness, are the definitions of each classification given to baseline models in advance before reasoning?\n18. Which task does Table 6 represent?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "nRowNi80L7", "forum": "hCVGAnQ7eE", "replyto": "hCVGAnQ7eE", "signatures": ["ICLR.cc/2026/Conference/Submission2334/Reviewer_DLmN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2334/Reviewer_DLmN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2334/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760980501527, "cdate": 1760980501527, "tmdate": 1762916197404, "mdate": 1762916197404, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an agent-driven multimodal retrieval-augmented generation (RAG) framework, which implements three major tasks: component retrieval, component relationship inference, and oracle bone script interpretation, and supports both VLM inference and multi-agent inference modes. It also constructs a component-level dataset OB-Radix, including 934 unique oracle bone script characters, 478 components, a total of 1022 character images and 1853 component images, with semantic annotations, filling the gap in component-level information in existing datasets. Additionally, the authors also introduce OBS ROUGE-1 metrix to evaluate the interpretation performance more accurately."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper breaks through the traditional image recognition approach, taking the component structure of oracle bone script as the core entry point. By combining knowledge graphs and agent mechanisms, it realizes the integration of visual analysis and structured knowledge reasoning, improving the accuracy and interpretability of interpretation.\n2. The OB-Radix dataset provides component-level annotations for the first time. Constructed with the participation of archaeology experts, it addresses the issue that existing datasets (such as HUST-OBC and EVOBC) only focus on complete characters and lack structural information, laying a key data foundation for subsequent AI research on oracle bone script.\n3. Besides conventional metrics like BERTScore and MoverScore, a weighted OBS ROUGE-1 metric is designed according to the characteristics of the oracle bone script field to distinguish the importance of different parts of speech (e.g., nouns, verbs). Meanwhile, human expert evaluation is introduced to ensure the reliability and practicality of the results."}, "weaknesses": {"value": "1. The component identification accuracy remains unsatisfactory, achieving only a Top-1 accuracy of 77.95%. This limitation significantly undermines the reliability of the subsequent interpretation pipeline. When deployed in real-world scenarios—where images are often severely degraded by noise—the performance is likely to deteriorate further.\n2. The construction and evaluation of the dataset highly rely on archaeology experts, resulting in high labor costs. Moreover, some oracle bone characters do not have widely accepted interpretations, which limits the reliability of automated analysis to existing academic consensus and makes it difficult to handle controversial characters."}, "questions": {"value": "1. When constructing the OB-Radix dataset, the paper states that more than 5,000 OBS images are collected and then selected to 1,022 character images and 1,853 component images. What are the specific filtering criteria? And how did these criteria ensure the dataset's representativeness of common OBS characters and components?\n2. The component recognition module in the framework adopts a prototype classifier based on DINOv2, which performs well in low-data regime. However, in the face of real-world scenario, where the amount and complexity of data have increased significantly, are there further optimization schemes?\n3. The update mechanism of the knowledge graph is not mentioned. With new discoveries in oracle bone script research (e.g., newly deciphered characters or revisions of old interpretations), how to efficiently update the content of the knowledge graph to ensure that the interpretation results of the framework are synchronized with the latest academic progress?\n4. The paper mentions that some oracle bone characters do not have widely accepted interpretations. How does the framework handle such characters with \"no standard answers\"? Is there a mechanism to output \"possible interpretations and confidence levels\" instead of a single definite result to adapt to controversial scenarios in academic research?\n5. The interpretation generation module of the framework supports two modes: VLM inference and multi-agent inference. Experiments show that the multi-agent mode has better performance, but the computational costs (such as inference time and memory usage) of the two modes were not compared. In practical application scenarios (e.g., portable oracle bone script interpretation devices), if there is a need to balance performance and cost, how to define the applicable boundaries of the two modes?\n6. This paper lacks discussions about ligature, which consists of several independent character but is regarded as a single semantic unit. It remains unclear whether the model interprets such ligature as unified components or processes each constituent character separately.\n7. Overstatement of \"Expert-Level\" Capabilities: The paper frequently claims the framework achieves \"expert-level quality\" or \"near-expert proficiency.\" However, in the human expert evaluation, the best multi-agent model only scored 3.433 out of 5. This score is closer to the midpoint between \"Uncertain\" and \"Basically Agree,\" rather than the \"Completely Agree\" (5) expected of true experts, suggesting the claim may be exaggerated.\n8. Extremely Weak Variant Character Recognition: Supplementary experiments tested the model's ability to recognize variant characters (a core challenge in paleography) and showed very poor performance, with a Top-10 accuracy of only 5.13% (just 2 out of 39 samples correct). This severely limits the system's practical value in real-world ancient script research where glyph variations are rampant.\n9. Limited Scale and Representativeness of Human Evaluation: The human evaluation was conducted by only two Ph.D. students on just 10% of the held-out test set. The small number of evaluators and limited sample size may lead to incidental results and lack statistical robustness.\n10. Opaque Agent Decision Logic: The paper mentions agents \"adaptively\" choose retrieval pathways (e.g., prioritizing variant search before exact matching). It is unclear if this is based on hardcoded rules or a learned policy, making it difficult to assess the true \"intelligence\" and generalizability of the agent's decision-making.\n11. Relatively Small Dataset Scale: The OB-Radix dataset includes only 1,022 character images and 1,853 component images. Compared to the total of over 4,500 known OBS characters, this coverage is limited, raising questions about the model's ability to generalize to the vast number of unassigned or undeciphered characters.\n12. Significant Degradation in Cross-Lingual Performance: Experiments show that performance drops significantly when generating interpretations in English compared to Chinese. This reveals a heavy reliance on Chinese-language knowledge bases and training corpora, limiting its claimed \"cross-lingual robustness\" and international applicability.\n13. Potential Inadequacy in Handling Phono-Semantic Compounds: The framework heavily emphasizes structural and semantic component analysis. However, it may underrepresent the crucial role of phonetic components in phono-semantic characters, which form a significant portion of later OBS and Chinese characters."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "eU1bru63Zu", "forum": "hCVGAnQ7eE", "replyto": "hCVGAnQ7eE", "signatures": ["ICLR.cc/2026/Conference/Submission2334/Reviewer_HTSP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2334/Reviewer_HTSP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2334/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761535597559, "cdate": 1761535597559, "tmdate": 1762916197184, "mdate": 1762916197184, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of deciphering Oracle Bone Script (OBS) by proposing an agent-driven multimodal Retrieval-Augmented Generation (RAG) framework to enhance Vision-Language Models (VLMs) with domain-specific expertise. \nExisting approaches often frame OBS decipherment as a single-modal image recognition task, neglecting OBS’s hieroglyphic structure and component-based semantic information.\nKey contributions include: (1) A framework integrating component-level visual cues and a knowledge graph (KG) via agent orchestration, supporting three core tasks: component retrieval, component relationship inference, and OBS interpretation; (2) OB-Radix, a component-level OBS dataset, which fills the gap of component-level structural/semantic annotations in existing datasets; (3) Comprehensive evaluations showing the framework outperforms baseline VLMs in accuracy and interpretability. The multi-agent extension, which separates knowledge retrieval and semantic reasoning, achieves near-expert proficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper emphasizes OBS’s intrinsic component-based structure, which is critical for capturing semantic relationships between character parts. By integrating component-level knowledge into VLMs via RAG, it resolves information loss and interpretive biases in traditional approaches.\n2. OB-Radix is curated with paleographic experts and includes fine-grained component annotations and semantic explanations. The accompanying KG, which models relationships between components, characters, and meanings, provides structured domain knowledge that VLMs lack.\n3. Separating knowledge retrieval and semantic reasoning into specialized agents improves both robustness and interpretability. This design aligns with expert reasoning practices, as shown by human evaluations where the multi-agent pipeline outperformed single-agent RAG and baselines."}, "weaknesses": {"value": "1. The framework relies on OB-Radix’s expert-curated knowledge graph, which may not cover all undeciphered characters. The scalability to larger unannotated corpora remains unverified.\n2. The prototype-based classifier, while efficient in low-data regimes, may introduce spurious elements or miss fine-grained components."}, "questions": {"value": "1. How does the LLM agent in the retrieval module balance efficiency and accuracy when choosing query pathways? Are there safeguards against erroneous tool invocation?\n2. How might this framework handle fragmented or eroded OBS inscriptions where component boundaries are ambiguous?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "y2uBpbVBME", "forum": "hCVGAnQ7eE", "replyto": "hCVGAnQ7eE", "signatures": ["ICLR.cc/2026/Conference/Submission2334/Reviewer_PkeV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2334/Reviewer_PkeV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2334/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761579503796, "cdate": 1761579503796, "tmdate": 1762916196387, "mdate": 1762916196387, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles oracle bone script (OBS) interpretation with a component-based pipeline: first detect radicals/components, then retrieve structured knowledge, and finally generate an interpretation. The authors introduce a component-level dataset OB-Radix, and report improvements over vanilla prompting, especially when retrieval is enabled."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The problem is interesting. Interpreting OBS is a meaningful and challenging task with cultural/linguistic value.\n- The component-based design plus RAG is a natural fit and seems effective for the problem.\n- The authors introduce the OB-Radix dataset, which is a helpful resource for future work."}, "weaknesses": {"value": "- Motivation/role of LLMs is unclear. Why do we need a language model here? Are we using the LLM for QA, for multi-step reasoning, or just to paraphrase retrieved text? The paper could stand on component identification + knowledge retrieval alone, but it does not clearly justify why an LLM is necessary, how it is prompted, or what unique capability it contributes beyond templated retrieval.\n- The task “Interpretation” is not formally defined. The output looks like paraphrasing retrieved entries rather than reasoned synthesis from components. The author didn’t define the success criteria, what counts as correct/partially correct and why.\n- Although the retrieval is described as “agent-driven,” the toolset appears to be a streamlined, fixed sequence of procedures. There is no convincing intuition or evidence that an agent architecture is needed here. Tbh I don’t think this is a problem to be solved by an agent. It is not a good practice to simply incorporating a trending technique into the problem you are solving, without having an intuition why it will help for your problem.\n- While the results show improvements, there is no surprise that VLMs will perform better with component identified and RAG. The paper lacks deeper analysis about where the method truly helps (e.g., variants, rare components) versus where it still fails."}, "questions": {"value": "1. Can the authors provide concrete details of the tools and example reasoning traces (successful and failed), and explain how, if at all, the agent framework is optimized or tuned?\n2. Page 1, line 51: “we employ advanced VLMs ….” Who is “we”? Are Liu et al., 2023 and Caffagni et al., 2024 the authors’ prior works, or external references?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "2tIdxFl2lA", "forum": "hCVGAnQ7eE", "replyto": "hCVGAnQ7eE", "signatures": ["ICLR.cc/2026/Conference/Submission2334/Reviewer_VtNx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2334/Reviewer_VtNx"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2334/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762831352457, "cdate": 1762831352457, "tmdate": 1762916196189, "mdate": 1762916196189, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}