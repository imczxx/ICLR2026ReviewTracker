{"id": "68M8vHVH8j", "number": 5552, "cdate": 1757919886510, "mdate": 1763105909714, "content": {"title": "ControlSwap: Controllable Personalized Subject Swapping", "abstract": "Personalized subject swapping aims to replace a source concept in a source image with a user-specified target concept while preserving the rest of the scene. Despite recent advances, two key controllability issues persist: (1) object-agnostic foreground processing impedes identity transfer under pose and context changes; and (2) background regions that should remain unchanged are unintentionally altered. This lack of controllability profoundly curtails expressivity and narrows real-world editing applicability. We introduce ControlSwap, an SDXL-based framework that redesigns the refiner into an identity-preserving Identifiner. In contrast to prior approaches that apply a uniform, object-agnostic loss across the entire image, ControlLoss decomposes optimization into object-specific and nonobject-specific objectives, enabling fine-grained, region-aware control. Experiments demonstrate improved controllability and background preservation across diverse personalization scenarios. Code and models will be released to support reproducibility and future research.", "tldr": "To address existing limitations of personalized subject swapping, ControlSwap achieves controllability—defined as foreground personalization and background preservation—via region-aware ControlLoss and an SDXL-based identity-preserving Identifiner.", "keywords": ["diffusion models", "image editing", "personalized subject swapping"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/73664e06275c781a107f8ff0a9647e1bf352ba12.pdf", "supplementary_material": "/attachment/eebaae67e7231b81b566c90ee249576d9e5a855b.zip"}, "replies": [{"content": {"summary": {"value": "An SDXL-based editing pipeline for subject swapping. The refiner is turned into an “Identifiner” for identity preservation, and a region-aware ControlLoss separates object vs. non-object optimization to avoid background drift. Shown on DreamBooth identities and SwapBench images."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. Addresses a real failure mode (background changes).\n2. Compatible with SDXL stack."}, "weaknesses": {"value": "1. Minimal algorithmic innovation.\n2. Lacks strong quantitative comparisons (e.g., InstantID, recent swap/edit methods).\n3. No discussion of safety or misuse."}, "questions": {"value": "1. How are masks obtained (SAM? manual?) and how robust is the method to mask errors?\n2. Can it handle multi-subject scenes or video sequences?\n3. Any quantitative metric for identity preservation vs. background fidelity?"}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety"]}, "details_of_ethics_concerns": {"value": "No discussion of safety or misuse."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5FHQtldu17", "forum": "68M8vHVH8j", "replyto": "68M8vHVH8j", "signatures": ["ICLR.cc/2026/Conference/Submission5552/Reviewer_8yfP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5552/Reviewer_8yfP"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5552/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760803118525, "cdate": 1760803118525, "tmdate": 1762918132376, "mdate": 1762918132376, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "aTDoqPlXSW", "forum": "68M8vHVH8j", "replyto": "68M8vHVH8j", "signatures": ["ICLR.cc/2026/Conference/Submission5552/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5552/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763105908547, "cdate": 1763105908547, "tmdate": 1763105908547, "mdate": 1763105908547, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents ControlSwap, which is a controllable framework for personalized subject swapping built on Stable Diffusion XL. It replaces the subject in an image with a target identity while keeping the background intact. The model uses an Identifiner to preserve identity and a region-aware loss to balance subject editing with background protection. Experiments show clear improvements in controllability and visual fidelity over prior methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The qualitative and quantitative results demonstrate consistent gains in identity fidelity and background realism across multiple benchmarks.\n2. The ControlLoss divides the image into object, surrounding, and background areas, allowing the model to edit the subject more precisely without disturbing the surrounding scene.\n3. The paper is easy to follow with clear presentation."}, "weaknesses": {"value": "1. The core idea builds upon existing diffusion and inpainting-based editing frameworks. While the Identifiner is well implemented, it is not a novel method, which has appeared in many previous works.\n2. he paper relies mainly on automatic metrics like CLIP similarity and PSNR, which may not fully reflect perceptual quality or realism. A human study would provide stronger evidence for visual improvement."}, "questions": {"value": "Since controllability and realism are perceptual qualities, have the authors conducted or considered user studies to validate the quantitative metrics? If not, how confident are they that CLIP-based metrics correlate well with human perception?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "W5nxd4CIl5", "forum": "68M8vHVH8j", "replyto": "68M8vHVH8j", "signatures": ["ICLR.cc/2026/Conference/Submission5552/Reviewer_FKMM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5552/Reviewer_FKMM"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5552/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761828716697, "cdate": 1761828716697, "tmdate": 1762918131605, "mdate": 1762918131605, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ControlSwap, an SD-XL framework for image editing, especially object swap. It proposes ControlLoss for optimizing the foreground and background separately."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. The motivation for ControlLoss is sound, as it optimizes the foreground and background separately. The experiments also validate its effectiveness.\n\n2. The two-phase pipeline seems intuitive: it first identifies the editing and unedited areas, then integrates the subject."}, "weaknesses": {"value": "1. The paper's writing quality is extremely poor. Figure 2,3 is not a vector graphic and cannot be zoomed in on (or \"cannot be viewed at a larger size\"). Additionally, there is an obvious typo on line 199 after the word \"background\". This level of writing is not suitable for submission to ICLR.\n\n2. The base model is SD-XL and it uses DDPM sampling, which is outdated. Commonly, in T2I generation, researchers now use models like FLUX with flow matching. The proposed ControlSwap method is not applicable to these more recent T2I models."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "kbvD2a36zI", "forum": "68M8vHVH8j", "replyto": "68M8vHVH8j", "signatures": ["ICLR.cc/2026/Conference/Submission5552/Reviewer_Taes"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5552/Reviewer_Taes"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5552/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761897969446, "cdate": 1761897969446, "tmdate": 1762918130872, "mdate": 1762918130872, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}