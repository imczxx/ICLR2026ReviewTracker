{"id": "hQZQVLJrH9", "number": 5327, "cdate": 1757900914436, "mdate": 1759897981218, "content": {"title": "A Unified First‑Order Framework for Activation Steering and Data Influence", "abstract": "Activation steering adds a low‑dimensional vector to an intermediate layer of a neural network to elicit or suppress behaviors, whereas influence functions trace the effect of infinitesimally re‑weighting training examples on model outputs.  We prove that, to first order, these techniques are provably equivalent: any steering vector can be represented as an influence weighting over training data\nand vice versa. This duality yields: (i) a constructive algorithm for mapping undesired behaviors back to causal training examples; (ii) an\noptimal‐control perspective on steering that reveals its regularization properties; and (iii) generalization bounds for low‑rank steering\ninterventions.  Our analysis adds theoretical clarity to two popular but previously disconnected strands of interpretability research.", "tldr": "Activation steering and data influence are first‑order equivalent; we give constructive mappings, a feasibility test, and spectral directions for practical control and provenance.", "keywords": ["activation steering", "influence function", "large language models"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/068ea6e8a3bed2cb32a2e0d5e09f8bafa9f9aa45.pdf", "supplementary_material": "/attachment/db0902193ef0b6586c0c74ca05e728839dfd4ec1.pdf"}, "replies": [{"content": {"summary": {"value": "The authors present a mathematical connection between influence functions (data influences on model outputs) and activation steering vectors (vectors added to activations to encourage behavioral characteristics). The authors use this mathematical connection as a bridge between two seemingly different fields of interpretability research. In addition to presenting a mathematical equivalence between the two and where the equivalence holds, they provide practical results showing how to evaluate when the bridge exists and empirical results on gpt2 medium to verify their theory."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- bridging two important areas of mech interp under one theory is a profound contribution even if the bridge does not always hold\n- they provide an analysis of cases where the equivalence holds and where it breaks down\n- they defend their theory with empirical simulations\n- they provide practical insight (how to practically determine when steering and influence functions have an equivalence and how to use their results to make steering vectors)"}, "weaknesses": {"value": "Overall, my main concerns with this paper is that the claims in the abstract are not supported by their findings, and the paper is difficult to follow mathematically (although that may be a shortcoming of my own).\n\nAdditional specific suggestions/concerns:\n- would be good to be explicit about the approximate nature of equations 1 and 2 when they are introduced. I believe those equations only hold if $f_\\theta(x)$ is linear or if $\\alpha s$ and $\\Delta \\theta$ are very small, neither of which are true for your settings. The equation that you are approximating is an integration along a path from $h$ to $\\alpha s$ (and the equivalent for $\\Delta t$)\n- no justification for gpt2 medium and layer 8\n- the claims in the abstract and claim 1 in the intro need to be toned down. As written, it sounds like a perfect equivalence always holds, which is not true, as you claim in claim 2 in the intro.\n- the spectral optimality finding is not useful in cases where you do not know the precise logits that you want to influence but rather a high-level concept/function (e.g. toxicity)\n- in general, I believe many of the analyses rest on the assumption that the goal of steering is to change the logits by a specific amount with well defined inputs, which is not always true. Another goal of steering is to affect higher level behaviors under novel inputs. I could be misunderstanding some of the ideas presented in the paper, but this needs to be addressed."}, "questions": {"value": "- What is contrastive activation addition (CAA) in Section 7.1?\n- if I'm understanding correctly, the math is all performed for a single data input? Does everything hold for a batch of samples? I do not believe it does, because $(W1+W2)x \\neq Wx+s$ for multiple vectors x. So, the equivalence does not hold for multiple, individual inputs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "h9ecj7v9m1", "forum": "hQZQVLJrH9", "replyto": "hQZQVLJrH9", "signatures": ["ICLR.cc/2026/Conference/Submission5327/Reviewer_a5Ni"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5327/Reviewer_a5Ni"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5327/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761772268586, "cdate": 1761772268586, "tmdate": 1762918011031, "mdate": 1762918011031, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Influence-Aligned Steering (IAS), a method that connects activation steering with influence functions. The authors argue that any activation steering direction can be interpreted as an influence-weighted combination of training examples, and conversely, that influence functions can generate effective steering vectors. This theoretical bridge is used to unify activation editing, weight editing, and data attribution under a single conceptual framework. The paper further proposes practical guidelines on choosing between activation-level and weight-level interventions based on this connection."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- Presents an interesting idea that connects activation editing to weight editing, and further to training data attribution.\n- Proposes a unifying first-order perspective that links steering, Jacobians, feasibility, and spectral structure. If validated, this framework could help standardize diagnostics for \"steerability.\""}, "weaknesses": {"value": "- The main text and appendix do not provide proofs for core claims, making it impossible to verify correctness. At a minimum, the paper should include complete statements with assumptions and provide proof sketches in the main paper and full proofs in the appendix. Otherwise, results should be clearly labeled as conjectural.\n- Several symbols are undefined or ambiguous. For example, in line 86, $\\mathbf{h}(x)$ is referred to as “pre-activations,” but it is unclear what this means—does $\\mathbf{h}$ represent the concatenated pre-activations across all layers or a specific layer? The meaning of $y$ is also undefined. A concise notation table would improve clarity.\n- There are several issues with the equations. For example: $H_\\theta$ in line 101 doesn’t appear to account for $\\epsilon$; $\\Delta \\mathbf{h}^*$ in line 147 is missing a minus sign; and equation numbering is inconsistent (e.g., 1, 2, P, 2, 4, 3, 4).\n-  The inclusion $Im(J_{\\theta \\to y}) \\subseteq Im(J_{h \\to y})$ is a strong and currently unjustified claim. Please provide the conditions under which this inclusion holds, or offer counterexamples where it fails.\n- The experimental section only evaluates GPT-2 Medium, which is insufficient to support claims about modern large language models. At least one contemporary 7B-scale model, such as from the LLaMA or Gemma families, should be included.\n- In Table 1, the proposed method performs worse than CAA, a simpler technique. This discrepancy should be addressed with analysis or discussion.\n- The paper only explores a limited form of activation steering: vector addition at a single layer. It’s unclear how the proposed method generalizes to more complex settings, such as steering at multiple layers or using more advanced steering methods like directional ablation [1,2] or rotational transformations [3,4].\n- A more thorough review of the activation steering and data attribution literature is recommended.\n\n[1] Refusal in Language Models Is Mediated by a Single Direction\n\n[2] Representation Engineering: A Top-Down Approach to AI Transparency\n\n[3] Angular Steering: Behavior Control via Rotation in Activation Space\n\n[4] Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective"}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vWvz8aH9sJ", "forum": "hQZQVLJrH9", "replyto": "hQZQVLJrH9", "signatures": ["ICLR.cc/2026/Conference/Submission5327/Reviewer_FR5K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5327/Reviewer_FR5K"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5327/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761914867804, "cdate": 1761914867804, "tmdate": 1762918010725, "mdate": 1762918010725, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes a first order mapping between activation steering and influence functions, demonstrating the equivalence between two prominently used methods in model controllability. They propose an Influence-Aligned Steering vector to reproduce the same first order logit shift as any influence reweighting, and additionally prove the converse mapping holds. The empirical results across multiple datasets demonstrate consistency with the proposed theory."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The work provides a clean mathematical bridge between action space and data level influence, offering a closed form mapping that is novel accelerates the field of model controllability.\n2. The intuition, implication and practicality paragraphs in section 4 were very beneficial in understanding the practical meaning of the work.\n3. The empirical results covered multiple data modalities demonstrating cross-domain applicability."}, "weaknesses": {"value": "1. The equivalence hinges on the assumption of feasibility, local smoothness and affine independence, yet there is no discussion regarding the feasibility of these assumptions.\n2. Empirical results consider only one language model and vision model, so it unclear how well their theory adapts beyond model types.\n3. As pseudoinverses and SVDs can be unstable, confidence metrics for their results taken over multiple seeds and parameters is necessary but missing."}, "questions": {"value": "1. How sensitive is IAS to the choices of pseudoinverse regularization?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "hRr9GuIKNJ", "forum": "hQZQVLJrH9", "replyto": "hQZQVLJrH9", "signatures": ["ICLR.cc/2026/Conference/Submission5327/Reviewer_h1dP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5327/Reviewer_h1dP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5327/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761945777583, "cdate": 1761945777583, "tmdate": 1762918010360, "mdate": 1762918010360, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework connecting two major strands of interpretability research: activation steering (adding low-dimensional vectors to intermediate activations to modify behavior) and influence functions (tracing output sensitivity to infinitesimal changes in training-data weights). The authors show that, to first order, these are mathematically equivalent. Empirically, they demonstrate these relationships on GPT-2 Medium (for language-model detoxification) and ResNet-50 (for spectral optimality), showing strong correspondence between predicted and realized logit shifts."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. **Practical implications**. The unified view leads to a clear, actionable workflow for practitioners (use steering first, diagnose feasibility, and only then resort to weight-level editing). Practical payoffs and intuitions are made clear throughout. \n2. **Clarity and intuition**. The prose is concise and continuously ties theoretical constructs back to practical goals.\n3. **Empirical grounding**. The paper validates its claims on real models (GPT-2, ResNet-50).\n4. **Potentially impactful**. Could influence both interpretability and alignment communities by offering a shared geometric language.\n5. **Conceptual unification**. Provides a theoretical bridge between two previously separate interpretability techniques (steering and influence), deepening our understanding of both."}, "weaknesses": {"value": "1. **Limited empirical scope**. Experiments are minimal and rely on older models (GPT-2 Medium, ResNet-50) with small datasets; stronger validation on current architectures would bolster credibility.\n2. **Thin empirical discussion**. Section 7 largely reports numbers and figures without much narrative interpretation.\n3. **First-order limitation**. While explicitly acknowledged, the framework’s reliance on the linear regime may limit applicability."}, "questions": {"value": "1. How stable is the first-order equivalence empirically as the steering magnitude grows? Is there a quantified threshold beyond which the linear assumption breaks down?\n2. Given the practical workflow (steer, trace, edit), can the authors share or describe a real-world debugging example?\n3. Did the authors consider models beyond GPT-2 and ResNet-50?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "yvzGuYRZJT", "forum": "hQZQVLJrH9", "replyto": "hQZQVLJrH9", "signatures": ["ICLR.cc/2026/Conference/Submission5327/Reviewer_RXbW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5327/Reviewer_RXbW"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5327/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761961287250, "cdate": 1761961287250, "tmdate": 1762918010045, "mdate": 1762918010045, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}