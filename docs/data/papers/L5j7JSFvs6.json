{"id": "L5j7JSFvs6", "number": 20500, "cdate": 1758306857602, "mdate": 1763698321815, "content": {"title": "PIFE: Progressive Insight driven Feature Engineering via Multimodal Reasoning", "abstract": "Despite significant advances in Automated Machine Learning (AutoML), one of its persistent blind spots remains the automation of data-centric tasks such as exploratory data analysis (EDA), contextual insight extraction, and feature engineering. These steps-often more critical than model selection itself-are still largely manual, domain-specific, and reliant on human intuition. Existing automated feature engineering (AutoFE) techniques either rely on rigid transformation sets or complex optimization strategies that struggle with interpretability and fail to leverage the rich, visual cues that guide human decision-making. In this work, we introduce PIFE: Progressive Insight driven Feature Engineering via Multimodal Reasoning; a novel AutoFE framework that employs multimodal language models as collaborative agents in an iterative pipeline. PIFE systematically performs automated EDA, generating statistical summaries and visualizations that are jointly interpreted through text–vision reasoning. These multimodal insights inform the synthesis of candidate transformations, represented as symbolic programs in executable Python code to ensure interpretability and reproducibility. By coupling iterative insight extraction with validation-driven refinement, PIFE produces high-quality, interpretable features that consistently enhance the performance of diverse predictive models, outperforming existing AutoFE baselines. Extensive experiments across diverse tabular datasets demonstrate the effectiveness and adaptability of our approach, paving the way for a new class of human-aligned, insight-aware AutoFE systems.", "tldr": "We introduce PIFE, an AutoFE framework that leverages iterative EDA with multimodal language models and symbolic synthesis to generate interpretable, high-quality features that improve tabular prediction.", "keywords": ["Representation Learning", "Multimodal Reasoning", "Symbolic Program Synthesis", "Exploratory Data Analysis"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7054514a706b67a751948debccb9b1e48d8d6bdb.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes an automated feature engineering framework that involves iteratively performing exploratory feature analysis and feature generation, guided by large language models. The method is evaluated in a number of tabular datasets, and ablation studies are performed."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- The approach is interesting, the idea that LLMs can guide EDA and extract features that are more effective at downstream tasks is explained well.\n- The paper is written well and easy to follow."}, "weaknesses": {"value": "- The use of a VLM is questionable to me, I think the method tries to mimic how a human would go about the process of exploratory data analysis and feature engineering. However, if the goal is to improve performance on downstream tasks, (which most of the evaluation focuses on) the benefit of using large models is their ability to understand complex relationships within the data, where generating plots would be unnecessary.\n- Table 2 shows that in the experiments performed, the explanatory data analysis step provides little benefit, despite what I imagine is a large computational cost. Table 4 shows that the benefit of using such features in deep learning models is minimal.\n- I feel that human in the loop feedback could benefit the method - allow a human to guide each iteration with insights gained from the automatic EDA. Additionally, insights from EDA are often not with the goal of improving classification, but understanding where the model will make mistakes or visualizing and comparing distributions of certain features.\n- The claim that the model is more human-aligned than others is not proven, I believe human experiments would be necessary to say that this model is more human-aligned than others.\n- I believe the evaluation focuses on the wrong aspect. In terms of EDA, if the authors could show that the data analysis produced is more human-like or more informative to humans than other methods, this would be a benefit of the proposed method."}, "questions": {"value": "- What are the additional computational costs of each module in the method? I imagine that the cost is large compared to the very minimal performance gain."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Mzeyr8o2qE", "forum": "L5j7JSFvs6", "replyto": "L5j7JSFvs6", "signatures": ["ICLR.cc/2026/Conference/Submission20500/Reviewer_96TH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20500/Reviewer_96TH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20500/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761861146596, "cdate": 1761861146596, "tmdate": 1762933930728, "mdate": 1762933930728, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes PIFE (Progressive Insight Driven Feature Engineering), which selects features by iteratively doing EDA (exploratory data analysis), making plots and analyzing the plots with LLM and VLM and code execution. Their method takes advatange of human-like reasoning process where humans look at data analaysis plots to decide about the results. Each iteration, they use feature importance from the random forest to decide which features to keep. They are the first to propose automated feature engineering framework that integrates textual and visual exploratory data insights into a unified, iterative pipeline. They compared with a comprehensive set of baselines and show that their method selects better features. They also show the effectiveness of EDA in an ablation comparing with removing EDA from their pipeline. Although it doesn't help two datasets with EDA, it helps most. They also tried to further use OpenFE on the end outputting features from PIFE, and find there only to be a small improvement, showing the effectiveness of PIFE."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. The paper proposes a very nice and intuitive method (using insights from data exploratory phrase, and using an VLM to achieve that) to improve auto feature engineering.\n2. The results show that PIFE is better than other methods.\n3. The paper has comprehensive results to isolate effects of EDA and also how combining their method with OpenFE works."}, "weaknesses": {"value": "1. The method replies on the model being an inherently interpretable model that exposes feature importance, which would not be true for deep learning models, although we could use some post-hoc methods to approximate the feature importance."}, "questions": {"value": "1. How would the proposed method work if the underlying predictive model is not random forest but a neural network?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fwZhjGqNYw", "forum": "L5j7JSFvs6", "replyto": "L5j7JSFvs6", "signatures": ["ICLR.cc/2026/Conference/Submission20500/Reviewer_mHis"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20500/Reviewer_mHis"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20500/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761864327864, "cdate": 1761864327864, "tmdate": 1762933930209, "mdate": 1762933930209, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents PIFE, an AutoFE framework that leverages multimodal reasoning (LLMs + VLMs) to automate EDA, insight extraction, and feature generation for tabular datasets. PIFE iteratively generates statistical summaries and visualizations, interprets them, and synthesizes candidate features as executable Python code. Downstream model feedback is used to refine feature generation. Experiments across 22 datasets show PIFE outperforms existing AutoFE baselines in interpretability and context-awareness."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Novelty: First to tightly integrate textual and visual EDA insights in an iterative, feedback-driven AutoFE pipeline.\nInterpretability: Features are generated as symbolic programs, ensuring transparency and reproducibility.\nEmpirical Rigor: Evaluated on diverse datasets, with fair comparisons and ablation studies.\nPerformance: Consistently outperforms baselines in both classification and regression tasks.\nGeneralization: Features transfer well to different downstream models and unseen datasets.\nOpen Science: Code and datasets are released for reproducibility."}, "weaknesses": {"value": "Scope and Robustness of EDA\n- The EDA routines in PIFE are primarily statistical and visual, focusing on distributions, correlations, and categorical/temporal trends. This scope is well-suited for standard tabular data, but may not generalize to domains requiring specialized EDA (e.g., time series, graphs, or highly unstructured data).\n- Robustness of the approach depends on the diversity and quality of EDA routines. If the EDA is limited or misses important patterns, the generated features may be suboptimal.\n- The paper notes that in some datasets, EDA-driven features do not improve performance, especially when original features are already strong or datasets are small.\n\nSupported Visualizations\n- PIFE supports common tabular visualizations: histograms, scatter plots, heatmaps, LOWESS curves, binned means, and categorical plots (bar, boxplots).\n- The framework does not appear to support more advanced or domain-specific visualizations (e.g., time series plots, network diagrams).\n- The quality and diversity of insights are limited by the types of visualizations produced and interpreted.\n\nLLM Hallucinations and Reliability\n- LLMs may generate plausible but incorrect or ungrounded features, especially if the EDA context is noisy or incomplete.\n- The framework mitigates hallucinations via downstream validation (feature importance feedback, cross-validation, feature selection), but does not provide explicit mechanisms for detecting or correcting hallucinations at the insight or feature generation stage.\n- No formal guarantees are provided against hallucinations; robustness is empirically assessed via multiple seeds and ablation studies.\n- There is a risk of overfitting to spurious patterns or memorized solutions from prior competitions."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YC0qXpQWgY", "forum": "L5j7JSFvs6", "replyto": "L5j7JSFvs6", "signatures": ["ICLR.cc/2026/Conference/Submission20500/Reviewer_2ZXd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20500/Reviewer_2ZXd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20500/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995014050, "cdate": 1761995014050, "tmdate": 1762933929827, "mdate": 1762933929827, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces an AutoFE framework that incorporates automatic data analysis like EDA, leveraging LLMs and VLMs. A VLM generates statistical summaries of features from EDA plots that are used as the context in the LLM-based AutoFE process. The paper also explores the effects of different feature selection methods."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "This paper suggests a good direction of incorporating the visual information of datasets in AutoFE. The paper presents comprehensive experimental results involving both traditional and deep learning downstream models. The experimental setup is explained clearly."}, "weaknesses": {"value": "While it is beneficial to enrich the context information of LLM-based AutoFE, I do not think the automatic data analysis process has been well integrated. Algorithm 1 suggests that the process starts from scratch at each iteration, which is quite inefficient. The data analysis process also seems quite random, and there is no feedback mechanism to guide it. From the ablation study, the performance gain is limited. \n\nThe presentation of the paper is not very clear in some parts especially Section 3. More detailed explanations may help. Algorithm 1 is a bit hard to follow and not positioned appropriately.\n\nIn the experimental section, the statistical significance of results is not reported. It would be great to also include a cost study of the framework."}, "questions": {"value": "Does the framework represent feature transformations in code or RPN? Listing 3 seems to suggest that both are adopted. I think this is unnecessary and may create inconsistencies.\n\nWhat VLM has been used in experiments?\n\nIn A.5.2, why are the parameters presented as ranges, different from A.5.1? \n\nSomehow the repository shows “the requested file is not found”  and the code is inaccessible."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8U7ksinRsB", "forum": "L5j7JSFvs6", "replyto": "L5j7JSFvs6", "signatures": ["ICLR.cc/2026/Conference/Submission20500/Reviewer_zXFD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20500/Reviewer_zXFD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20500/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762220531362, "cdate": 1762220531362, "tmdate": 1762933929454, "mdate": 1762933929454, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}