{"id": "kq2P8JTXQB", "number": 2419, "cdate": 1757079028408, "mdate": 1759898149484, "content": {"title": "Inference-Time Diffusion Model Alignment via Random Ordinary Equations", "abstract": "Existing diffusion model (DM) alignment methods necessitate intensive training, differentiable rewards, and suffer from sparse rewards. We proposes a parameter-efficient inference-time scaling framework to align DMs to any reward function. We aim to fully exploit the potential of a fixed pre-trained DM and a fixed initial noise, achieving DM alignment solely by altering the denoising trajectories. We first extract a random ordinary differential equation (RODE) sampling from DDIM for controllable and low-variance randomness. Then, we model the inference process of DMs as a Markov decision process with a low-dimensional action space and dense rewards.  Finally, we formulate the inference-time DM alignment as a max-reward optimal control problem, and solve it using a value-based Monte Carlo tree search with augmented RODE-based scaling and Beta policies. Experiments show that our method successfully aligns pre-trained DMs with reward functions defined on clean image domains, such as aesthetics and semantics. Our method outperforms traditional inference-step scaling, and achieves significantly higher parameter efficiency than existing approaches adopting high-dimensional action spaces. Our approach does not necessitate differentiable rewards and can be plug-and-play integrated into any multi-step inference DMs.", "tldr": "We scale low-dimensional actions with random ordinary equations to achieve inference-time diffusion model alignment.", "keywords": ["Diffusion Models", "Inference-Time Scaling", "Diffusion Model Alignment", "Random Ordinary Equations"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b1c8d1dd2ee6cc873e18a264b7a9647eb9f4652c.pdf", "supplementary_material": "/attachment/4856520124e879e2fe8ea56f2c6d043ecd6f7799.zip"}, "replies": [{"content": {"summary": {"value": "- This paper proposes a novel diffusion alignment method that operates efficiently at inference time.  \n- The approach is based on Monte Carlo Tree Search (MCTS), with the key originality lying in the combination of RODE sampling, a one-dimensional action space, and a max-reward control strategy.  \n- The proposed method is validated through extensive experiments, demonstrating that  \n  (a) it efficiently and actively searches for high-reward trajectories, and  \n  (b) its sampling process is both stable and diversity-controllable owing to the RODE formulation.  \n- The method is applicable to non-differentiable rewards, since it operates in a gradient-free manner.  \n- The authors also provide theoretical guarantees regarding sampling stability and score estimation error bounds.\n\nNote: I used ChatGPT for minor language editing and phrasing assistance; all technical assessments are my own."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- This paper presents a novel diffusion-alignment method that operates efficiently at inference time.  \n- The proposed method is supported by extensive experiments, evaluated in terms of \"Best Reward\" and \"Parameter Efficiency\".  \n- The experiments also provide useful insights into the behavior of the proposed alignment method:  \n  (a) Proposition 1 and the experimental result on sample diversity (measured by the mean pairwise distance) are well connected, as discussed around line 405.  \n  (b) The visualization of the denoising path on the data manifold (Figure 4) effectively illustrates the exploration capability of the proposed approach.  \n- The authors also provide theoretical guarantees regarding the stability of the method and the bound on score-estimation error.\n\nNote: I used ChatGPT for minor language editing and phrasing assistance; all technical assessments are my own."}, "weaknesses": {"value": "- The theoretical argument, especially Proposition 2, needs to be clarified.  \n- It is not entirely clear whether the authors can rigorously justify the following conclusions based on their propositions:  \n  (1) that $p^{(R)}$ approximates the true data distribution as well as $p^{(S)}$; and  \n  (2) that using an SDE-trained score network within RODE sampling does not significantly increase the score-estimation error.  \n- See Question (2) below for more detailed comments.\n\nNote: I used ChatGPT for minor language editing and phrasing assistance; all technical assessments are my own."}, "questions": {"value": "1. **On the max-reward control strategy**  \n   Can the authors provide a more detailed explanation of why the proposed max-reward control strategy performs better compared to FK steering [1] (which is also cited in the paper)?  \n   This kind of approach seems natural since the intermediate reward is explicitly defined (see the theoretical discussions in, e.g., [2]).\n\n2. **On Proposition 2 and its interpretation**  \n   (a) Was $M_{t_{k+1}}$ introduced before Proposition 2?  \n   It might be helpful if the authors explicitly describe all quantities appearing on the right-hand side.  \n   Also, is $M_{t_{k+1}}$ exponential in the number of steps?  \n   (b) It seems that the right-hand side does not vanish even if $\\Delta t \\to 0 $.  \n   Can the authors still claim that $p^{(S)}$ and $p^{(R)}$ are sufficiently close under some limiting regime?\n\n3. **On Assumption 8**  \n   Is Assumption 8—stating that the mapping $\\Psi_t$ is twice continuously differentiable—reasonable or realistic in practice?  \n   One of the main strengths of your work is that the proposed MCTS framework can handle **non-differentiable rewards**.  \n   Therefore, it would be desirable if the underlying diffusion dynamics (and the mapping $\\Psi_t$ ) could also relax the differentiability requirement, so that both the diffusion model and the reward function may be non-differentiable.\n\n\n---\n\n**References**\n\n[1] Raghav Singhal, Zachary Horvitz, Ryan Teehan, Mengye Ren, Zhou Yu, Kathleen McKeown, and Rajesh Ranganath. *A general framework for inference-time scaling and steering of diffusion models.* arXiv preprint arXiv:2501.06848, 2025.  \n\n[2] Uehara, M., Zhao, Y., Black, K., Hajiramezanali, E., Scalia, G., Diamant, N. L., ... & Levine, S. (2024). *Fine-tuning of continuous-time diffusion models as entropy-regularized control.* arXiv preprint arXiv:2402.15194.\n\nNote: I used ChatGPT for minor language editing and phrasing assistance; all technical assessments are my own."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "MHE6D7pJMX", "forum": "kq2P8JTXQB", "replyto": "kq2P8JTXQB", "signatures": ["ICLR.cc/2026/Conference/Submission2419/Reviewer_cCHK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2419/Reviewer_cCHK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2419/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761378396826, "cdate": 1761378396826, "tmdate": 1762916230446, "mdate": 1762916230446, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies inference-time alignment of diffusion models with respect to general reward functions. The key idea is to fix the process noise and treat the interpolation coefficients between ODE and SDE updates as optimization variables, a scheme we term RODE sampling. These coefficients form a low-dimensional vector that we optimize using Monte Carlo tree search. Experiments first confirm that RODE sampling provides sufficient sample diversity for effective exploration, and then demonstrate strong performance on several text-to-image diffusion alignment tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Framing the ODE–SDE interpolation factors as optimization variables is an elegant idea. This parameterization is inherently low-dimensional and parameter-efficient, making it a natural fit for bandit-style algorithms such as MCTS.\n2. The authors validate the method’s effectiveness across diffusion models with diverse architectures."}, "weaknesses": {"value": "1. Baseline comparisons are limited. It’s unclear how RODE fares against simple baselines, especially best-of-n sampling under pure ODE or pure SDE trajectories. Since the process noise is fixed, the method largely behaves like a local search (though augmented RODE partially mitigates this), raising doubts about its advantage over global search strategies such as best-of-N.\n2. The paper lacks an analysis of optimization time, which is critical for assessing practicality. Reporting wall-clock runtime, the number of reward evaluations, MCTS budgets, and how costs scale with image resolution and model size would greatly clarify the method’s efficiency."}, "questions": {"value": "Some works like DNO explore gradient-estimation optimization approach for non-differentaible reward. How do you compare the bandit-type algorithm like MTCS to those gradient-estimation based optimization approach?\n\nDNO: Tang, Zhiwei, et al. \"Inference-Time Alignment of Diffusion Models with Direct Noise Optimization.\" Forty-second International Conference on Machine Learning."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sqhf1gaXkm", "forum": "kq2P8JTXQB", "replyto": "kq2P8JTXQB", "signatures": ["ICLR.cc/2026/Conference/Submission2419/Reviewer_67PD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2419/Reviewer_67PD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2419/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761901304358, "cdate": 1761901304358, "tmdate": 1762916230235, "mdate": 1762916230235, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper developed a randomised ordinary differential equation (RODE) serving as value estimation for the MCTS algorithm. The theoretical guarantee ensures that the Lipschitz constant bounds the mean of the distribution between SDE and RODE."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "## Presentation: ~45th percentile\n\nThe mathematical writing and explanation are intelligible, but they have some issues (see below).\n\n## Soundness: 30th-70th percentile\n\nThis paper provides a theoretical guarantee for RODE to estimate the MCTS value, offering a transparent analysis with mathematical arguments.\n\n## Contribution: 40th~75th percentile\n\nThe formulation of RODE is new to me and may be useful for further work other than alignment tasks. \n\n## Note:\n\nI hope the AC is aware that the rating is calibrated using estimation of percentiles to reduce evaluation noise effectively.\nThe rating is simply the mean of the three aspects."}, "weaknesses": {"value": "## Presentation\n\n### Writing\n\nMy reading flow was sometimes interrupted due to the lack of connection between sentences/paragraphs. For example, your abstract reads like a list of bullet points without a strong hierarchical presentation; the structure of the first introduction paragraph is\n\n```\nfor work from a list of literature:\n\n  Introduce literature\n\n  Explain the weakness of the literature, compared to your method.\n\nfor work from a list of literature:\n\n  Suggest your solution to address the weakness you mentioned earlier.\n```\n\nYou can save your readers' effort by putting the weakness and the solution together so that they don’t need to frequently move their pointer while consuming a paragraph of 20 lines.\n\nSuch writing is pervasive throughout the manuscript, but I only list the abstract and introduction as they are the most important.\n\n### Literature survey\n**Citing Wikipedia** is not considered standard academic practice (and you did it five times). As an encyclopedia, it is a tertiary source that summarises information and is the last type of citation source. You must conduct a thorough literature review and replace this citation with the original peer-reviewed sources that contain the foundational knowledge. I have to admit that these citations leave a terrible impression when reviewing this paper, although I have to make it independent of judgement of other aspects.\n\n### Minors\n1. I suggest using Big-O/littel-O notation in equation 10.\n2. In Equation 8, it would be better if you juxtapose the original SDE induced by DDIM and the RODE, so your reader can compare them.\n3. If your work does not involve a reward encountered during the process (despite the reward at t=0), it is a bad idea to introduce them in Section 3.1 and throughout your entire paper, as I feel confused and effortful when reading the paragraphs from lines 160-179.\n\n\n## Soundness\n**ODE-based baseline:** It is known that DDPM, DDIM, and any score-based SDE can be reformulated as Karra’s SDE [1] bidirectionally. Therefore, these formulations are theoretically equivalent, although the conversion in practice is not very trivial. Assuming the equivalence, you state\n\n> We are the first to extract an RODE sampling from the DDIMs\n\n> To the best of our knowledge, we are the first to model DM alignment as a max-reward control/RL problem.\n\nI expect you to clarify the difference between your and ODE-based value estimation baselines [2, 3] in your paper, and the experimental comparison of them is also missing. I raise a doubt about your performance because the figures in [3] are significantly larger than yours.\n\n[1] Karras, Tero, et al. \"Elucidating the design space of diffusion-based generative models\"\n\n[2] Ma, Nanye, et al. \"Inference-time scaling for diffusion models beyond scaling denoising steps\"\n\n[3] PH, Yeh et al. “Training-free Diffusion Model Alignment with Sampling Demons”"}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BoVyMucuS6", "forum": "kq2P8JTXQB", "replyto": "kq2P8JTXQB", "signatures": ["ICLR.cc/2026/Conference/Submission2419/Reviewer_8dAj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2419/Reviewer_8dAj"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2419/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761909950662, "cdate": 1761909950662, "tmdate": 1762916229969, "mdate": 1762916229969, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel inference-time scaling method for diffusion model alignment via modifying the denoising trajectory with the strength of the added noise as the exploration action (while the added noise is fixed). Compared to the commonly used noise/eps as action (which is high-dimensional), the proposed method adopts such a low-dimensional action that can be easily integrated into UCB-based Monte Carlo Tree Search (MCTS) for efficient online exploration. The authors show (both theoretically and empirically) that this new action space admits less variance than the noise/eps as actions paradigm. This method is plug-and-play for various reward signals (including non-differentiable ones)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "+ The formulation of using the perturbation strength as an action while fixing the added noise is novel and intriguing. I like the explanation and the visualization of the reduced variance. \n+ I am a bit surprised the method, while simple conceptually, can do inference-time scaling pretty well. A major challenge in visual diffusion model fine-tuning is the high-dimensional action space. Since the action space is low-dimensional, it might open up a door for other online tuning methods, such as policy optimization (also optimizing the diffusion model itself)."}, "weaknesses": {"value": "+ I am not particularly impressed by the claimed advantage of parameter efficiency. Can the authors point out scenarios where it is critical, given that eps-based action space still performs better in some cases (maybe not for MCTS)?\n+ I am curious if the authors can provide more evidence that the proposed method alleviates reward hacking compared to eps-action alternatives. This will make the contribution of this work significant.\n\nI am willing to raise my score after seeing the authors' response."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "myNtOfphW3", "forum": "kq2P8JTXQB", "replyto": "kq2P8JTXQB", "signatures": ["ICLR.cc/2026/Conference/Submission2419/Reviewer_Rs8u"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2419/Reviewer_Rs8u"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission2419/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762368061865, "cdate": 1762368061865, "tmdate": 1762916229737, "mdate": 1762916229737, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}