{"id": "y6piOp5MSO", "number": 19045, "cdate": 1758293101336, "mdate": 1759897064101, "content": {"title": "GeoPE:A Unified Geometric Positional  Embedding for Structured Tensors", "abstract": "Rotary Positional Embedding (RoPE) excels at encoding relative positions in 1D sequences, but its generalization to higher-dimensional structured data like images and videos remains a challenge. Existing approaches often treat spatial axes independently or combine them heuristically, failing to capture their geometric coupling in a symmetric and consistent manner. To address this, we introduce Geometric Positional Embedding (GeoPE), a framework that extends rotations to 3D Euclidean space using quaternions. To overcome the non-commutativity of quaternion multiplication and ensure symmetry, GeoPE constructs a unified rotational operator by computing the geometric mean of rotations within the corresponding Lie algebra. We also propose a linear variant that preserves the strict relative positional encoding of 1D RoPE, offering superior extrapolation. Extensive experiments on image classification, object detection, and 3D semantic segmentation demonstrate that GeoPE consistently outperforms standard baselines and existing 2D RoPE variants, while retaining the strong extrapolation properties of its 1D predecessor.", "tldr": "This paper introduces GeoPE, which extends 1D RoPE to higher dimensions using quaternions and Lie algebra, achieving consistently strong performance on various 2D and 3D vision tasks while maintaining excellent generalization to unseen resolutions.", "keywords": ["Positional Embedding", "Vision Transformer", "RoPE"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/38defb238c2bbc7af7e6084ff9dc4a9861c26bcb.pdf", "supplementary_material": "/attachment/b38ce6e86c0afe081fbedeaacd52d577cbea7ff5.zip"}, "replies": [{"content": {"summary": {"value": "This paper builds on rotary positional embedding, extending rotations to 3D Euclidean space using quaternions. The authors developed a method to avoid the quaternion multiplication non-commutativity, and test the method in various benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The idea of defining positional embedding with quaternions and Lie algebra is interesting and valuable.\n\nThe method to avoid the non-commutativity of the Hamilton product is also a good idea, appreciated.\n\nAlso, it would be good to study the problem in terms of shape bias relation, even though this point is not properly developed."}, "weaknesses": {"value": "W1) Results are not convincing. Results in plots in fig.3 and 5 do not favor the proposed method over previous methods. While, for results in tables, the improvement is marginal and no standard deviation is reported, so it is difficult to evaluate the performance.\n\nW2) Figure 6 is unclear and the explanation in sec 5.4 does not help. It would be interesting to better develop this point.\n\nW3) Results in figure 4 are interesting, as it is clear that GeoPE activates more patches wrt previous methods that mainly activates the diagonal. However, diagonal elements are not activated as the diagonal is mainly darker. Why? How does it impact the performance? \n\nW4) Figure 1 is not clear (and of low quality).\n\nW5) in realted works, especially in the shape bias, some discussion on previous methods involving quaternions, lie algebra, or biases due to algebraic representations should be included, such as:\n1) Demystifying the Hypercomplex: Inductive biases in hypercomplex deep learning, Signal Processing Magazine\n2) Fast Quaternion Product Units for Learning Disentangled Representations in SO(3), Transactions on Pattern Analysis and Machine Intelligence\n\nW6) in Sec 3.1, it is actually not recommended to build a quaternion by simply splitting a vector v as v/3, since quaternions represent precise Mathematical entities and they better work when correlations/relations between the dimensionalities exist. Indeed, quaternions better work in the case of multimodal/multichannel etc data. If we simply split a vector, this is not guaranteed."}, "questions": {"value": "Q1) I guess that the colors for the plot in figure 3 are wrong? If not, results are inconsistent across the dimensions.\n\nQ2) Same in figure 5?\n\nQ3) Can the authors report standard deviation results over three runs for tables results?\n\nQ4) Can the aauthors provide computational time comparisons among the models? Especially since they mention it talking about Linear GeoPE."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "yIhvCnSdpD", "forum": "y6piOp5MSO", "replyto": "y6piOp5MSO", "signatures": ["ICLR.cc/2026/Conference/Submission19045/Reviewer_z8fm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19045/Reviewer_z8fm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19045/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760966962722, "cdate": 1760966962722, "tmdate": 1762931082685, "mdate": 1762931082685, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces GeoPE, a positional encoding for transformers operating on 2D or 3D data. \nThe presented approach offers an extension of the rotary positional embedding (RoPE) widely used in transformers that operate on 1D sequences.\nIt combines 3D rotations around different axes (each axis encodes one spatial dimension) into one 3D rotation by log-exp averaging. The resulting 3D rotations of different frequencies are applied on 3D-subvectors to apply a positional encoding to keys, queries and values in the attention mechanism. The authors develop a “linear” version of GeoPE that applies a single matrix between key and query subvectors that depends only on the relative position.\n(Linear) GeoPE is compared against the competitor RoPE-Mixed and other baseline methods on 2D image classification and object detection. GeoPE is compared against a simple baseline for semantic segmentation of 3D point clouds."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The idea of GeoPE is straightforward and offers a possibility to address positional encodings for transformers operating on 2D or 3D data.\nGeoPE can be easily implemented."}, "weaknesses": {"value": "The presented method lacks motivation and experimental comparison against related work. The overall presentation is not well structured and in several places unclear. The design choices in GeoPE are in my opinion not sufficiently ablated.\n\n**Comparison against related work:**  \nOverall, GeoPE is not consistently compared against competitors such as RoPE-Mixed [1]. The comparisons in Table 1 seem unsystematic and arbitrary. Furthermore, GeoPE should be benchmarked against LieRE [2]. LieRE is applicable to 2D and 3D data and seems to consistently outperform RoPE-Mixed. All together, the presented (incomplete) comparison (e.g. Tab. 1 and Fig. 5) does not make a convincing case that GeoPE “consinstently outperforms standard baselines and existing 3D RoPE variants” as claimed in the abstract (l. 022). For instance, l. 411 claims “exceptional zero-shot inference capabilities across multiple resolutions’’ but RoPE-Mixed seems to be superior (cf. Fig. 5).\n\nWhat are the conceptual differences and advantages of GeoPE over RoPE-Mixed and LieRE?\nThe authors state that “these approaches remain essentially 1D ROPE, as axes are treated independently, and mixed-frequency schemes only partially capture diagonal dependencies” (l. 046).  To me it is not clear why treating axes individually is inferior. An explanation based on formulae could make the differentiation more precise.\nFurthermore, the authors state that LieRE [2] is “computationally expensive” (l. 056). A runtime comparison against LieRE could help to support this statement.\n\n[1] Byeongho Heo, Song Park, Dongyoon Han, and Sangdoo Yun. Rotary position embedding for vision transformer. In European Conference on Computer Vision, pp. 289–305. Springer, 2024.\n\n[2] Sophie Ostmeier, Brian Axelrod, Maya Varma, Michael Moseley, Akshay S Chaudhari, and Curtis Langlotz. Liere: Lie rotational positional encodings. In Forty-second International Conference on Machine Learning.\n\n**Motivation and ablations:**  \nThe authors claim that averaging 3D rotations around different axes (each axis encoding the position w.r.t. one spatial dimension) is a “natural choice” (l. 158) and “geometrically sound” (l. 255). This claim seems not sufficiently supported by theory or ablation experiments. 1) Why are rotations around different axes a geometrically meaningful way to couple positional encodings from different dimensions? 2) Why is the average of the rotations around different axes geometrically more meaningful than e.g. the composition or e.g. an average of the separately rotated (sub-)features? \n\nThe text claims that a positional encoding that is non-commutative in height and width encodings (for 2D images) is problematic (l. 183) but the authors do not support this claim experimentally. In particular for video data, it might actually be desirable to distinguish between spatial and temporal embeddings. An ablation that compares the averaged rotations against the composition of rotations would help to justify this claim.\n\nThe effectiveness and importance of the linear GeoPE is not sufficiently ablated (it seems to appear only partially in Table 1 and in none of the other tables).\n\n**Limitations (of GeoPE) are missing:**  \nAppendix F only discusses limitations of linear GeoPE. Limitations seem to be that GeoPE is only applicable for geometric data in Euclidean space up to dimension 3. Furthermore, the feature dimension must be divisible by 3. Are there other limitations of GeoPE?\n\n**Structure of text and presentation:**  \n* A background section on RoPE to introduce the reader to the topic and the notation is missing and would really improve the presentation.\n* The term “diagonal interactions” in l. 088 is not clearly defined/introduced.\n* When reading from top to bottom, the relation of GeoPE to the Shape Bias paragraph in the related work is unclear.\n* The captions of Fig. 1 is rather uninformative. Given that figure aims to explain the main method, a more detailed caption would be helpful.\n* Adding an appendix on quaternions, the quaterion product, and the relation to rotation matrices would be helpful and could be reference in Sec. 3.1.\n* The caption of Fig. 2 is vague. Fig. 2b should rather be placed much later in the text where it is referenced.\n* The statement that “GeoPE keep[s] long distance decay” (l. 215) is unclear. If this is a unique selling point of your method, please elaborate more in the main text. \n* The notion of “mean attention distance” (Fig. 3) is not introduced. (I suppose it is the attention-weighted average of distances?)\n* In the caption of Fig. 3 the authors state that RoPE-Mixed and GeoPE apply a “more structured” strategy but it is unclear whether this is the “right” structure. For instance, the curve of GeoPE for the resolution of 128x128 looks very similar to the curve of APE for 224x224.\n* In Fig. 4 it is unclear which model is used and on which task it has been trained. Please explain in the text why one can see substructure in patches.\n* In Fig. 5 it says “training resolution” on top which seems to be a typo. The caption says that the training resolution was fixed to 224x224. Please clarify.\n* How are shape vs. texture decisions defined in Figure 6? Please explain this in the text.\n\n**Minor points:**  \n* Please give a reference for the following statement:\n“A strong shape bias, which prioritizes object structure over texture, is often correlated with better robustness and generalization.” (l. 465)\n* “discussed” typo in l. 214"}, "questions": {"value": "* Do other generalizations of RoPE like RoPE-Mixed or LieRE also preserve the “long distance decay” of attention scores over distance or is this a specific feature of GeoPE?\n* For 3D point clouds (in particular molecular data), rotational equivariance is very popular. Can GeoPE be modified to satisfy rotational equivariance?\n* The caption of Table 2 says that models with GeoPE are “pre-trained on ImageNet-1K”. Is this also the case for the other models? Does that hinder a fair comparison?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8HOcF3fRVA", "forum": "y6piOp5MSO", "replyto": "y6piOp5MSO", "signatures": ["ICLR.cc/2026/Conference/Submission19045/Reviewer_FpAf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19045/Reviewer_FpAf"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19045/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761138733819, "cdate": 1761138733819, "tmdate": 1762931082113, "mdate": 1762931082113, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Geometric Positional Embedding (GeoPE), a method that extends Rotary Positional Embeddingfrom 1D to higher-dimensional structured data by using quaternions to represent coupled rotations in 3D space. GeoPE constructs a symmetric rotational operator, ensuring consistent multi-axis encoding and offering a linear variant that preserves strict relative positional relationships. Experiments on image classification, object detection, and 3D segmentation show that GeoPE improves performance a tiny bit and enhances models’ spatial reasoning and shape bias"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Evaluation on a diverse set of tasks like image classification, object detection, and 3D semantic segmentation"}, "weaknesses": {"value": "- The extension of RoPE to 3D has been proposed by several other works already like VideoRoPE. Therefore the motivation and novelty could be made clearer. \n- The experimental results are missing statistical significance shown by confidence intervals for example. Words like \"significant performance gains\" or \"exceptional zero-shot inferencecapabilities\" are not backed with statistical meaning or quantitativ results. \n- The experimental comparison to prior work in the 2D and 3D space is incomplete. Here only Rope-Mixed and absolute is compared to where other works like STRING, VideoRope or LieRE works have already shown strong performance. How does GeoPE compare to just the 3D version of Rope-Mixed? A 3D version of Rope-Mixed would also have commutativity.\n- Missing description of theoretical guarantees. Why is commutativity important in theory and how does that directly translate to practice? Ablations are missing."}, "questions": {"value": "- Would it be possible to add confidence intervals?\n- Would it be possible to add more SOTA baselines? What is LinGeoPE? Why did you choose CPE and not STRING, VideoRoPE idea or LieRE or recent baselines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "1ige3sAsbS", "forum": "y6piOp5MSO", "replyto": "y6piOp5MSO", "signatures": ["ICLR.cc/2026/Conference/Submission19045/Reviewer_P5o7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19045/Reviewer_P5o7"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19045/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761598384245, "cdate": 1761598384245, "tmdate": 1762931081718, "mdate": 1762931081718, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Geometric Positional Embedding (GeoPE), a generalization of Rotary Positional Embedding (RoPE) designed for higher-dimensional structured data, specifically demonstrated on 2D and 3D tasks. The core motivation is the challenge of extending RoPE to higher dimensions: direct generalization requires modeling coupled multi-axis rotations, a problem often bypassed in existing work by assuming axis independence or using heuristic methods. The authors propose using quaternions to formulate 3D rotations. To address the issue of non-commutativity in quaternion multiplication (where rotation order affects the result), they leverage Lie Algebra principles and take the geometric mean of rotations in log space, which retains the desirable property of commutativity. A variant, Linear GeoPE, is also proposed. It aims to reintroduce the relative position encoding capability of 1D RoPE by enforcing a linear relationship within the Lie algebra, by approximating rotational composition with vector addition. This comes at the cost of higher memory complexity. The authors evaluate GeoPE and Linear GeoPE on image classification, object detection, and 3D semantic segmentation across various backbones, and compare them to existing positional encoding baselines and 2D rotational embeddings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- The paper presents a novel generalization of RoPE to higher dimensions that explicitly models coupled multi-axis rotations, addressing a key limitation in existing methods\n- The proposed method achieves superior performance across multiple backbones and 2D/3D tasks compared to competing positional encoding methods\n- The paper introduces two variants (GeoPE and Linear GeoPE), offering a practical trade-off between enforcing linear inductive bias (relative position encoding) and computational efficiency\n- The authors present an interesting analysis on shape-texture bias, showing that GeoPE increases the model’s shape bias, with the motivation of observed correlation between shape bias and better generalization and robustness"}, "weaknesses": {"value": "The acknowledged limitations of GeoPE (does not inherently enforce the desired linear relationship in the parameter space)  and Linear GeoPE (incurring significant memory overhead)"}, "questions": {"value": "A table comparing the runtime (FLOPs) and memory requirements of GeoPE, Linear GeoPE, and all other compared encoding methods would help readers precisely position the two GeoPE variants in terms of the performance/resource trade-off"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JjwEZ2CDG8", "forum": "y6piOp5MSO", "replyto": "y6piOp5MSO", "signatures": ["ICLR.cc/2026/Conference/Submission19045/Reviewer_wJBk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19045/Reviewer_wJBk"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19045/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761770824888, "cdate": 1761770824888, "tmdate": 1762931081040, "mdate": 1762931081040, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}