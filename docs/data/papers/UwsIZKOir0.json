{"id": "UwsIZKOir0", "number": 11516, "cdate": 1758200742748, "mdate": 1759897570935, "content": {"title": "Provable Benefit of Curriculum in Transformer Tree-Reasoning Post-Training", "abstract": "Recent curriculum techniques in the post-training stage of LLMs have been widely observed to outperform non-curriculum approaches in enhancing reasoning performance, yet a principled understanding of why and to what extent they work remains elusive. To address this gap, we develop a theoretical framework grounded in the intuition that progressively learning through manageable steps is more efficient than directly tackling a hard reasoning task, provided each stage stays within the model’s effective competence. Under mild complexity conditions linking consecutive curriculum stages, we show that curriculum post-training avoids the exponential complexity bottleneck.  \nTo substantiate this result, drawing insights from the Chain-of-Thoughts (CoTs) solving mathematical problems such as Countdown and parity, we model CoT generation as a states-conditioned autoregressive reasoning tree, define a uniform-branching base model to capture pretrained behavior, and formalize curriculum stages as either depth-increasing (longer reasoning chains) or hint-decreasing (shorter prefixes) subtasks. Our analysis shows that, under outcome-only reward signals, reinforcement learning finetuning achieve high accuracy with polynomial sample complexity, whereas direct learning suffers from an exponential bottleneck. We further establish analogous guarantees for test-time scaling, where curriculum-aware querying reduces both reward oracle calls and sampling cost from exponential to polynomial order.", "tldr": "", "keywords": ["Post-training; Curriculum"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6835bb62a4dce05fb2f2c84771d9505c96417730.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Proposes a framework to prove that curriculum training is provably good for post-training chain-of-thought generation."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Unable to identify or validate the strengths of the paper due to the opaque presentation."}, "weaknesses": {"value": "The paper is poorly written all through.  The introduction states the problem in mathematical terms using symbols that are undefined. The notation section re-introduces the symbols but refers to the introduction for their significance.    Some specific examples below.\n\nThe problem statement and the assumptions in the introduction (lines 57-79) launch into formulaic equations without any supporting definitions of the quantities involved.   This makes it impossible to decipher the problem being addressed.\n\nPreliminaries and notation (lines 125)  \"For each prompt $x$, policies are conditional probability measures $\\pi(. | x)$ on the output space.\"    \n\nWhat does the subscript $k$ of $\\pi_k$ mean in line 126?\n\nAssuming the inputs $x$ and the outputs are embedding vectors of real numbers, $\\pi$ is a probability density function.   In which case what does the derivative of one probability density function with respect to another (line 127) mean?  And the variable $o$ of line 127 is entirely undefined.\n\nLines 132-134:  The definition of pass-rate is circular in that it refers to the introduction section which in turn requires the notations to extract meaning.  \n\nTheorem 1 of line 135 is meaningless in light of the opaque notation and definitions.  The important notions of a task $k$, and a curriculum of tasks $K$ are undefined.\nWhat is assumed to be \"absolute continuous\"  in the theorem, line 137?\n\nlines 143-146 of Theorem 1:  Difficult to understand what this means.\n\"Further assume a complexity–mismatch alignment ...up to harmless logarithmic factors in a confidence parameter\"\n\nFigure 2 caption and elsewhere. \"secret index\" is used but never defined."}, "questions": {"value": "None at this time"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "EMAnVfnFBY", "forum": "UwsIZKOir0", "replyto": "UwsIZKOir0", "signatures": ["ICLR.cc/2026/Conference/Submission11516/Reviewer_7hYf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11516/Reviewer_7hYf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11516/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760967955123, "cdate": 1760967955123, "tmdate": 1762922615406, "mdate": 1762922615406, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a theoretical analysis framework to explain the benefit of curriculum learning during LLM post-training. The framework treats CoT generation as a State-Conditioned Autoregressive Reasoning Tree (2S-ART).  The paper show step-wise curriculum post-training can reduce exponential depth dependence into polynomial order. The exponential-to-polynomial from curriculum learning explains why curriculum learning empirically outperforms non-curriculum approaches."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-motivated by addressing a key open question of principled post-training explanation.\n2. The proposed 2S-ART framework abstracts the curriculum learning process into a mathematically analyzable tree structure, providing a way to measure the complexity of reasoning.\n3. The paper theoretically indicates directions for future research, namely that curriculum learning can reduce the difficulty for models to learn complex tasks."}, "weaknesses": {"value": "1. The paper relies on an exponential complexity assumption, but the source of this exponential growth is unclear: is it due to decoding search (e.g., CoT tree expansion) or the intrinsic difficulty of reasoning tasks? Moreover, there is no empirical evidence that solving harder reasoning problems actually requires exponentially more reasoning steps.\n2. The paper provides no empirical results to support the theory — even a small-scale experiment demonstrating that curriculum learning achieves a task with exponentially fewer training steps would greatly strengthen the claim. Without such evidence, the work remains largely theoretical and its practical significance to real LLM training remains unclear."}, "questions": {"value": "Can the authors provide even small-scale experiments showing that curriculum learning reduces training complexity as predicted by the theory?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "BEiDIFMlMt", "forum": "UwsIZKOir0", "replyto": "UwsIZKOir0", "signatures": ["ICLR.cc/2026/Conference/Submission11516/Reviewer_PGDS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11516/Reviewer_PGDS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11516/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761894815757, "cdate": 1761894815757, "tmdate": 1762922615052, "mdate": 1762922615052, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper gives a learning‑theoretic account of why curriculum‑style post‑training can help LLM reasoning. It models chain‑of‑thought generation as a two‑states conditioned autoregressive reasoning tree (2S‑ART) and posits a uniform‑branching “base” model that spreads probability over legal next steps. Curriculum stages are formalized as (i) depth‑increasing (longer CoTs) or (ii) hint‑decreasing (shorter prefixes). Under outcome‑only (binary) rewards, the analysis shows curriculum avoids an exponential bottleneck, achieving polynomial sample complexity, while analogous guarantees hold for test‑time scaling by reducing both reward‑oracle calls and sampling cost from exponential to polynomial. Canonical tasks (Parity, Countdown) and a representation theorem connect the 2S‑ART abstraction to transformers."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "2S‑ART captures stepwise CoT reasoning with legal action sets and state updates, making “prefix curriculum” and “hint curriculum” precise. The paper also establishes exponential‑to‑polynomial separations for both RL fine‑tuning under outcome‑only rewards and for test‑time scaling via curriculum‑aware querying."}, "weaknesses": {"value": "1. Strong base‑model assumptions. The uniform‑branching coverage (“base model assigns comparable mass across legal children”) is convenient for proofs but unrealistic for modern LLMs whose next‑token distributions are highly skewed and prompt‑dependent. The main theorems hinge on this coverage/complexity alignment. \n2. Idealized task/trace structure. The framework assumes a single “correct” index path with a known legal‑set policy; many real problems have multiple near‑equivalent paths and context‑dependent constraints. The parity/countdown focus limits external validity.\n3. Missing empirical calibration. The theory predicts polynomial scaling benefits; a small empirical study with real RLHF/RFT post‑training on diverse reasoning sets would strengthen the practical relevance."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "3yc4OnmYkt", "forum": "UwsIZKOir0", "replyto": "UwsIZKOir0", "signatures": ["ICLR.cc/2026/Conference/Submission11516/Reviewer_GLjV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11516/Reviewer_GLjV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11516/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762049123045, "cdate": 1762049123045, "tmdate": 1762922614448, "mdate": 1762922614448, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a theoretical framework to prove that curriculum post-training can avoid exponential sample-complexity bottlenecks in both RL fine-tuning and test-time scaling."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The notion of 2S-ART provides a unifying abstraction that captures a broad class of reasoning behaviors.\n- Theoretically characterizing when and why curriculum is more effective in post-training is an interesting question. This paper presents a general framework as well as analyzes a concrete synthetic task of parity."}, "weaknesses": {"value": "- The writing quality hinders comprehension. Below are several points that substantially obstruct my understanding:\n  - In Theorem 1, the notation $\\mathcal C(\\pi_{k'}^\\star | \\pi_{k}^\\star )$ seems undefined. It is unclear what training algorithm is used, and why $\\|\\frac{\\pi^\\star }{\\pi_{\\mathrm{ref}}}\\|_{\\infty}$  is an appropriate proxy for difficulty.\n  - For Theorem 3, I could not locate a full proof in the appendix. It would help to provide a clear pointer and a proof sketch in the main text.\n\n- The proof of Theorem 1 becomes straightforward once the assumptions (1,2,3) are imposed. Thus, it is crucial to justify that these assumptions hold for the reasoning tasks studied, but the paper does not provide a clear validation. It is also unclear how the concrete examples of parity satisfy the assumptions and how they connect back to the general theorem.\n- The theoretical novelty appears limited, and the results may not have substantial interest to the broader community.\n  - For theorem 1, the core idea that $\\mathcal C(\\pi_{k'}^\\star | \\pi_{k}^\\star )$  surves as a proxy of difficulty is studied in previous works [1]. \n  - The benefit of curriculum used in Theorem 3 looks similar to existing analyses of CoT training [2, 3]. It would be helpful if the authors could clarify on the difference in setup and proof techniques compared to these work."}, "questions": {"value": "- Is the $\\Omega(d^{ k^\\star+1})$ in Theorem 3.1 derived via an statistical query-style argument? If so, how does this lower bound relate to the general complexity measure in Theorem 1?\n- Why is $\\|\\frac{\\pi^\\star }{\\pi_{\\mathrm{ref}}}\\|_{\\infty}$ an appropriate proxy for difficulty? (If I understand correctly, [1] only justified it under linear softmax model parameterization.) It would be helpful if the authors can provide a formal statement establishing its relationship to statistical or computational complexity.\n\nPlease also refer to the weaknesses. I am open to adjusting my score based on the authors’ responses and the discussion with other reviewers."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "K47CgJBNCm", "forum": "UwsIZKOir0", "replyto": "UwsIZKOir0", "signatures": ["ICLR.cc/2026/Conference/Submission11516/Reviewer_vyLJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11516/Reviewer_vyLJ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11516/-/Official_Review"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763480778245, "cdate": 1763480778245, "tmdate": 1763480778245, "mdate": 1763480778245, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}