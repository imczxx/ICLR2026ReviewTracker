{"id": "80YSL3oy7z", "number": 3542, "cdate": 1757470338301, "mdate": 1759898082212, "content": {"title": "MASC: Boosting Autoregressive Image Generation with a Manifold-Aligned Semantic Clustering", "abstract": "Autoregressive (AR) models have shown great promise in image generation, yet they face a fundamental inefficiency stemming from their core component: a vast, unstructured vocabulary of visual tokens. This conventional approach treats tokens as a flat vocabulary, disregarding the intrinsic structure of the token embedding space where proximity often correlates with semantic similarity. This oversight results in a highly complex prediction task, which hinders training efficiency and limits final generation quality. \nTo resolve this, we propose **M**anifold-**A**ligned **S**emantic **C**lustering (MASC), a principled framework that constructs a hierarchical semantic tree directly from the codebook's intrinsic structure. MASC employs a novel geometry-aware distance metric and a density-driven agglomerative construction to model the underlying manifold of the token embeddings. By transforming the flat, high-dimensional prediction task into a structured, hierarchical one, MASC introduces a beneficial inductive bias that significantly simplifies the learning problem for the AR model. MASC is designed as a plug-and-play module, and our extensive experiments validate its effectiveness: it accelerates training by up to 57\\% and significantly improves generation quality, reducing the FID of LlamaGen-XL from 2.87 to 2.58. MASC elevates existing AR frameworks to be highly competitive with state-of-the-art methods, establishing that structuring the prediction space is as crucial as architectural innovation for scalable generative modeling. Our code is open-sourced via \\url{https://anonymous.4open.science/r/anonymous_MASC-F3D2/}.", "tldr": "MASC resolves a core inefficiency in autoregressive image generation by transforming flat visual vocabulary into a semantic hierarchy, simplifying the prediction task to accelerate training and improve generation quality.", "keywords": ["Autoregressive Image Generation", "Representation Learning", "Hierarchical Clustering", "Semantic Manifold", "Plug-and-Play Module"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8f7f44d1d2dc7aec0a396f00e5b4386f9ea185b2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors propose MASC, a principled method that aims to construct a hierarchical, geometry-aware prior from the codebook of token embeddings. \nMASC replaces the Euclidean clustering with a new cluster based distance and then use a density-driven, manifold-aligned procedure to get the clustering for the tokens.\nExperiment on LlamaGen and its variants show that MASC improves training efficiency (up to +57%) and FID (e.g., from 2.87→2.58 for LlamaGen-XL), making AR models competitive."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. this work is well motivated and has solid formulation for the problem\n2. MASC shows strong empirical results with consistent and significant improvements in convergence speed and generation quality across multiple architectures with LlamaGen tokenizer.\n3. The method is deterministic, lightweight, and easy to integrate, making it a plug and play module for many tokenizers."}, "weaknesses": {"value": "1. The paper focuses on quantitative metrics; more visualizations of cluster semantics and failure cases would strengthen the argument. Especially that while this work aims to address the discarded info of semantic relationship between tokens, is it possible to provide some empirical evidence to support this contribution.\n2. The versatility of this proposed method for different tokenizer is not well supported. The authors provide experiments for different tokenizer, GigaTok-L, where the MASC is worse than the vanilla baseline. This put the effectiveness of the proposed method into question.\n3. Entropy metric: In tab 1, why lower entropy means better generation? This metric is missed in Tab 2 and Tab 3. In addition, for baseline and +MASC, the vocab size is different, is it fair to compare the entropy in this case?"}, "questions": {"value": "4. It's not clear to me how the clusters have semantic meaning. As they are calculated using the token embedding, which itself does not contain semantic meaning. The illustrations in Fig3 and Fig5 do not help for my understanding as the position of the vectors are different at different scenarios. \n\nTypos:\n1. the caption of figure 4 is not updated --> IS on the left; FID in the middle (arrow down); Entropy on the right (arrow down)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "abkJzrbgqa", "forum": "80YSL3oy7z", "replyto": "80YSL3oy7z", "signatures": ["ICLR.cc/2026/Conference/Submission3542/Reviewer_enMQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3542/Reviewer_enMQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3542/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760892076278, "cdate": 1760892076278, "tmdate": 1762916808404, "mdate": 1762916808404, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Conventional image generation methods based on autoregressive (AR) models typically follow a two-stage pipeline. First, an off-the-shelf tokenizer is used to map continuous image representations into a set of discrete codes, or tokens. Then, given these tokens for each image, an AR model is trained to model their joint probability distribution. The authors argue that this formulation treats tokens as elements of a flat vocabulary, thereby ignoring the intrinsic structure of the token embedding space and leading to a suboptimal use of the AR model’s capacity when learning the joint distribution."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1 - The work presents a potentially promising (see questions section) direction for improving image generation with discrete autoregressive models.\n\n2 - I particularly appreciate the use of centroid-free hierarchical clustering, which effectively addresses the limitations of conventional K-Means-based approaches.\n\n3 - The evaluation across three different scales of AR models further demonstrates the scalability and robustness of the proposed method."}, "weaknesses": {"value": "My comments are intended more as questions than as criticisms, so I will include them in the “Questions” section."}, "questions": {"value": "First of all, I disagree with the authors’ claim that autoregressive models treat tokens as elements of a flat vocabulary. All transformer-based AR models incorporate some form of positional encoding that provides explicit information about token positions. In particular, LlamaGen, which is the authors’ default AR model, employs 2D RoPE.\n\nBut for the sake of argument, let’s assume that positional embeddings alone are insufficient to capture the intrinsic structure of tokens. The authors argue that without such intrinsic structure, the AR model must devote significant capacity to learning the semantic landscape from scratch. However, this would only be true if the tokenizer had learned suboptimal codebooks. In fact, their proposed method overlooks fine-grained distinctions within each codebook and collapses them into a single cluster during training. While this may simplify optimization—allowing the AR model to learn the joint distribution over fewer codebooks—it effectively imposes a hard limit on the model’s representational capacity, preventing it from discriminating between truly distinct tokens.\n\nThere is empirical evidence supporting this view. Prior studies [1, 2] show that increasing the token vocabulary size can indeed reduce reconstruction loss when learning codebooks, but without proper regularization, this does not necessarily improve generation quality [1]. For example, MaskGIT [3] tokenizer with a 1k codebook achieves better generation performance than the LlamaGen tokenizer with 16k tokens [2]. Even in this paper, Table 2 shows that when switching to stronger tokenizers such as GigaTok, the so-called “naive” approach surpasses their proposed method by a notable margin (3.39 vs. 3.86).\n\nTogether, these findings suggest that the core issue is not that AR models fail to learn from a flat vocabulary, but rather that the tokenizers used are suboptimally trained. With a well-trained tokenizer, the authors’ approach may, in fact, limit the learning potential of AR models.\n\nOf course, I would be happy to be proven wrong, and I would greatly appreciate it if the authors could include additional experiments using state-of-the-art tokenizers such as MaskGIT or GigaTok to further validate their claim.\n\n[1] Tianwei Xiong et al, ” Gigatok: Scaling visual tokenizers to 3 billion parameters for autoregressive image generation”, ICCV 2025.\n\n[2] Qihang Yu et al, “Randomized autoregressive visual generation”.\n\n[3] Huiwen Chang et al, \"Maskgit: Masked generative image transformer\" CVPR 2022."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Tj4swvX5Th", "forum": "80YSL3oy7z", "replyto": "80YSL3oy7z", "signatures": ["ICLR.cc/2026/Conference/Submission3542/Reviewer_4Xsx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3542/Reviewer_4Xsx"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3542/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761319877894, "cdate": 1761319877894, "tmdate": 1762916805896, "mdate": 1762916805896, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MASC, a manifold-aligned hierarchical clustering method for visual token codebooks in autoregressive image generation. By replacing k-means with a geometry-aware clustering pre-processing step, MASC restructures the prediction space into semantically-aligned groups, enabling more efficient token prediction. The approach requires no change to model architecture and demonstrates improved training stability and competitive performance on ImageNet class-conditional generation."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The approach introduces a principled geometry-aware clustering mechanism that is conceptually simple and grounded in the structure of the codebook embedding space.\n2. MASC is architecture-agnostic and can be incorporated into existing autoregressive pipelines without modifying model structure."}, "weaknesses": {"value": "1.\tAlthough Table 2 claims that MASC elevates existing AR frameworks (e.g., IAR, CTF) to be highly competitive with top-tier generative models, the results still fall short of current SOTA performance. Therefore, the practical utility of MASC remains unconvincing, as it does not clearly demonstrate superiority or meaningful gains when compared to the strongest existing AR systems.\n2.\tAll experiments are conducted on ImageNet with class-conditional generation, where semantic supervision is relatively simple. The paper does not evaluate MASC in text-to-image settings, leaving it unclear whether the proposed clustering strategy can effectively scale to more complex semantic conditioning.\n3.\tThe paper does not provide qualitative or quantitative analysis of the cluster semantics. Visualizing cluster assignments or evaluating semantic coherence would strengthen the claim that MASC achieves meaningful manifold-aligned grouping rather than merely reducing prediction space."}, "questions": {"value": "Can the proposed MASC method be directly applied to stronger AR models, such as VAR, to further improve generation quality?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "R9jvvG677N", "forum": "80YSL3oy7z", "replyto": "80YSL3oy7z", "signatures": ["ICLR.cc/2026/Conference/Submission3542/Reviewer_VzZW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3542/Reviewer_VzZW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3542/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761859695286, "cdate": 1761859695286, "tmdate": 1762916805308, "mdate": 1762916805308, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In autoregressive image generation tasks, visual tokens are typically treated as a flat vocabulary, which overlooks the intrinsic structural features of the token embedding space. To address this issue, this paper proposes a novel method that models token embeddings using a geometry-aware distance metric and density-driven agglomerative construction. This method transforms the flat, high-dimensional prediction task into a structured, hierarchical one, significantly simplifying the learning problem of autoregressive (AR) models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "+ The overall writing logic of the paper is coherent. The analysis of the problem and the solution approach form a well-closed loop, and the introduction to the method is also reasonable.\n+ The structure of figures and tables is clear, which effectively supports reading and understanding of the content."}, "weaknesses": {"value": "- The paper achieves a significant improvement in FID when applying MASC. However, it lacks visual comparisons of generation results between different methods—such as comparisons among the baseline, baseline + k-means, and baseline + MASC. This makes it difficult to determine whether the better generation performance stems from the proposed method or the inherent effectiveness of the baseline itself.\n- The paper lacks experimental evidence to verify that the intra-class features of the new clustering method are semantically consistent, and relevant experiments need to be supplemented."}, "questions": {"value": "- The paper mentions that k << N. However, the experiment states that k is set to 8192 while N is 16,384, which seems inaccurate.\n- The paper analyzes that the optimal k for the MASC method is 8192, and the comparative experiment with the k-means method also uses 8192 as the default k. Nevertheless, it lacks a comparison of the performance between k-means and MASC under other k values (e.g., smaller k)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jWlBk0CHf6", "forum": "80YSL3oy7z", "replyto": "80YSL3oy7z", "signatures": ["ICLR.cc/2026/Conference/Submission3542/Reviewer_T1kK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3542/Reviewer_T1kK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3542/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762131820519, "cdate": 1762131820519, "tmdate": 1762916803627, "mdate": 1762916803627, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}