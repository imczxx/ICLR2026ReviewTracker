{"id": "csD5GiGGFc", "number": 730, "cdate": 1756777988658, "mdate": 1759898245042, "content": {"title": "Differentially Private Synthetic Data Generation with Diversity via APIs", "abstract": "Synthetic data has emerged as a key solution for preserving the privacy of original data in fields dealing with sensitive information, such as healthcare and finance. Recent advancements in foundation models have significantly improved the quality of synthetic data. However, most high-performance foundation models are only available as black-box APIs, limiting fine-tuning capabilities and requiring private data containing sensitive information to be transmitted to external servers. To address this issue, PE was introduced as a privacy-preserving synthetic data generation method that leverages genetic algorithms with black-box foundation models.\nNevertheless, due to its evolutionary process, PE tends to repeatedly focus on a limited subset of samples, leading to a significant reduction in the diversity of the generated synthetic dataset. Since diversity is a crucial factor for enhancing the utility of synthetic data and ensuring robustness across various scenarios, we propose Div-PE, an improved approach that overcomes the diversity limitations of PE through a sample-variant two-stage voting mechanism. This method enhances data diversity and yields a 17.2\\% gain in FID and an 11.0\\% increase in downstream accuracy on ResNet-18, averaged over ImageNet, Camelyon17, and UTKFace. Furthermore, Div-PE demonstrates its versatility by delivering strong experimental results not only on image data but also across other modalities, including tabular and text data, validating its applicability to a wide range of data types.", "tldr": "Differential private synthetic data generation with black box access to foundation models", "keywords": ["Differential privacy", "synthetic data generation", "foundation models"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7d697f55a35e88f01a6669a6ffb1f1207b8753e1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper identifies that previous DP data synthesis method PE tends to repeatedly focus on a limited subset of samples, leading to a significant reduction in the diversity of the generated synthetic dataset. To solve this challenge, Div-PE is proposed by keeping an additional sample for each class. Privacy analysis and converge analysis is all considered. Dataset of multiple modality is included."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThis paper observes a very important drawback of PE, i.e. the decrease of synthetic data diversity with the use of VARIATE_API on the top-voted synthetic sample within each class. Another sample “non-winning” sample that is not selected by PE is selected and preserved to the next generation round to increase diversity.\n2.\tVariation prompts are carefully designed to further increase the diversity.\n3.\tExperiment on 3 modality is included, including image, text and tabular."}, "weaknesses": {"value": "1.\tLack of baseline for tabular data. In Table 1, no baseline method is included for tabular datasets. As GreaT is applied to serialize table rows into natural language, Aug-PE is a direct baseline that can be compared. I would like to see the comparison.\n2.\tLack of hyper-parameter selection study. As this is a paper considering differential privacy, one very important hyper-parameter is the differentially privacy budget $\\epsilon$. The robustness of the proposed Div-PE under different $\\epsilon$ should be studied but is currently missing in the main paper (please move it into the main paper), and lacks the comparison with baselines.\n3.\tLack of in-depth study of the proposed Div-PE. Many hyper-parameters are selected without given a logic, i.e. it’s impact on the final performance is not studied. For example, $T, N_{can}$.\n\nI think the overall idea is good and the proposed solution is interesting, but given the lack of experiments and mistakes (see Questions) contained in the paper, I cannot give a positive score for the current version which is not ready for being accepted as a top-tier conference paper. I will increase my score if the revison is good."}, "questions": {"value": "1.\tIf I understand correctly, in Algorithm 1, each $S_t$ contains $2N_{syn}$ samples as 2 step voting each contribute $N_{syn}$ samples. Therefore, within each iteration, should the number of total candidates for step-1 voting be $2\\times N_{syn}\\times N_{can}$ but not $N_{syn}\\times N_{can}$?\n2.\tThe paper mentioned that, the second voting uses the selected synthetic data instead of private data to avoid privacy budget increasement. Is there any experimental comparison results on this? \n3.\tI am curious, do you have any more detailed explanation on why removing adaptive variation (in Table 2) results in a sharp increase in FID and a dramatic decrease in Recall? The current analysis is too brief for me to understand.\n4.\tSee weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5vS0GuU7FB", "forum": "csD5GiGGFc", "replyto": "csD5GiGGFc", "signatures": ["ICLR.cc/2026/Conference/Submission730/Reviewer_U31U"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission730/Reviewer_U31U"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission730/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760515653332, "cdate": 1760515653332, "tmdate": 1762915592107, "mdate": 1762915592107, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Div-PE, a privacy-preserving framework for generating synthetic data using black-box foundation model APIs (e.g., Stable Diffusion for images, Llama-2 for text/tabular). It builds on PE, which uses evolutionary algorithms to guide synthetic data toward private distributions without fine-tuning or exposing raw data. However, PE suffers from diversity collapse, where generations converge to variations of a few high-fitness samples, reducing utility in downstream tasks. Div-PE addresses this via a two-stage voting mechanism that promotes balanced selection, ensuring broader ancestral lineages survive while maintaining DP guarantees."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The diversity of synthetic images is important in the DP image synthesis area.\n\n- The paper is easy to follow and well-written."}, "weaknesses": {"value": "- Enhancing prompts to improve generative diversity is still fundamentally constrained by the model's inherent capabilities. This approach does not fundamentally overcome the limitations of the model's generative power. If the model lacks the ability to produce images similar to sensitive ones, such methods will not perform well. The author is encouraged to provide a more in-depth discussion and investigate how Div-PE performs in scenarios where the model's generative capacity is limited.\n\n- The benefits and motivation behind the two-stage generation approach are not clearly articulated. Why does it work? In fact, the quality of synthetic images is generally low compared to real sensitive images, and using synthetic images for voting inherently introduces a lot of noise, which can negatively impact the voting results.\n\n- The method relies on LLMs to generate a diverse prompt set. However, if the public information ($I_pub$ is insufficient or the LLM exhibits bias (e.g., cultural bias), the initial synthetic dataset ($S_0$) may lack diversity, potentially hindering convergence in subsequent iterations. The paper does not provide robustness evaluations, such as performance under noisy public information. Furthermore, both the adaptive mutation (Eq. 3) and demonstration-based mutation (Eq. 2) depend on the voting score ($V^{(1)}$), which may be unstable under noise ($\\sigma$), leading to misleading guidance—where superior samples incorrectly influence inferior ones. The paper does not demonstrate the stability of these mechanisms under high noise (i.e., low $\\epsilon$) conditions.\n\n- The first stage assumes that each private sample contributes only one vote (i.e., sensitivity = 1). However, in multi-class settings, cross-class interference may increase the actual sensitivity, which is not addressed in the paper.\n\n- Although the method draws inspiration from “natural ecology” to prevent monopolization, it does not model realistic evolutionary dynamics—such as mutation rate decay—which may lead to collapse over long-term iterations.\n\n- This paper does not discuss or compare the approach of using public data for pretraining combined with DP-SGD-based differentially private image synthesis. I’m curious how Div-PE performs relative to such methods.\n\n- The authors did not investigate how different APIs affect the quality of generation.\n\n- Although the authors claim that Div-PE improves the diversity of the generated dataset, the results in Table 1 suggest otherwise. In fact, the recall is lower than the baseline, and the best value is incorrectly marked. Recall is a metric where higher values indicate better performance.\n\n- Moreover, it is unclear how Camelyon17 achieves an accuracy close to 86.1% despite having a very high FID. The same concern applies to ImageNet. These experimental results are not convincing."}, "questions": {"value": "Please refer to the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "xqSiM30gA4", "forum": "csD5GiGGFc", "replyto": "csD5GiGGFc", "signatures": ["ICLR.cc/2026/Conference/Submission730/Reviewer_o6x3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission730/Reviewer_o6x3"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission730/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760910701430, "cdate": 1760910701430, "tmdate": 1762915591909, "mdate": 1762915591909, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Div-PE, a framework for DP synthetic data generation using Private Evolution (PE). Div-PE introduces a two-stage voting mechanism that aims to mitigate the diversity collapse observed in prior PE methods where dominant samples monopolize the final synthetic dataset reducing the overall diversity. This sampling procedure relies on the post-processing property of DP and has no additional privacy cost. Empricially, the authors show Div-PE strengthens both utility and diversity across various modalities including image, text and tabular benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is well-presented and clearly written.\n- The paper highlights and solves a key limitation of PE regarding diverse data generation and proposes a well-motivated approach to fix this problem.\n- The empirical results cover three different modalities (text, image and tabular) across multiple benchmark datasets and show the proposed method consistently improves utility and diversity over standard PE."}, "weaknesses": {"value": "- Comparisons compare only against other PE baselines and existing DP synthetic data baselines are missing (particularly for the tabular setting), making it difficult to contextualize results against the broader DP synthetic data literature.\n- While Div-PE claims similar overhead to standard PE, there is no direct measurement of overhead, particularly for the two-stage sampling procedure or the Auto-Prompt generation.\n- The role of Auto-Prompt appears dominant in improving diversity, as suggested by Table 2. The contribution of the new two-stage voting seems unclear."}, "questions": {"value": "1. The ablation in Table 2 suggests Auto-Prompt contributes most to diversity improvement. Is this ablation with BISTAGE for every option? I would have preferred to have seen a more detailed ablation across multiple datasets to really understand the contribution of each component. How does PE+Auto compare with just BISTAGE?\n2. Related, how does auto-prompt work for tabular data generation? How exactly do you modify the GReaT encoding in this setting?\n3. Could the authors provide more detailed runtime results? Specifically, what is the actual overhead of BISTAGE+auto?\n4. How does the method perform across different DP budgets? Are diversity gains consistent under stronger privacy?\n5. What accounts for the discrepancy between Table 2 and Figure 6 in coverage scores? I can't seem to find what the exact experimental setup (dataset etc.) was used for Figure 6? The Figure 6 ablation seems to imply that auto-prompt gets you most of the way in terms of best FID/coverage trade-off?\n6. For the tabular setting, have the authors thought about comparing against existing tabular DP-SDG methods such as DP-CTGAN or SOTA marginal-based methods like AIM?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZXAO94aedx", "forum": "csD5GiGGFc", "replyto": "csD5GiGGFc", "signatures": ["ICLR.cc/2026/Conference/Submission730/Reviewer_yTep"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission730/Reviewer_yTep"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission730/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761654385941, "cdate": 1761654385941, "tmdate": 1762915591766, "mdate": 1762915591766, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an improvement to a previous private evolution (PE) method to generate DP synthetic data using a foundation model API, with the aim of improving the diversity of the generated samples. The issue with the existing method is that all of the generated samples become very similar with many iterations of the algorithm, since they all become variations of a single example. The paper's solution, called Div-PE, is to ensure that variations of all initial examples are kept throughout the process. This is done by adding an additional step on top of the selection step of PE where poorly-performing examples are selected based on their similarity to well-performing examples. The second step uses the same DP statistics than PE, so it does not bring extra privacy cost. Div-PE is compared against PE and another variant of it on 7 datasets of image, text and tabular data. Div-PE outperforms the others in almost all settings."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 4}, "strengths": {"value": "The paper identifies a clear weakness in PE and provides a novel solution, which is demonstrated to solve the problem. Synthetic data generation with DP is an important problem, and algorithms effectively using API-only foundation models are especially useful due to the prevalence of these foundation models. Previous works in this area have not generated tabular data, which is a welcome addition in this paper."}, "weaknesses": {"value": "The paper is missing many important explanations that are needed to fully understand the results. There are also many minor issues that together significantly reduce the clarity of the paper. In particular, Section 3 should explain SEED_API, VARIATION_API, the distance function $d$ and how different degrees of variation can be obtained from VARIATION_API in practice. Also, many important experimental details are missing. These are critical for reproducing the experiments and fully understanding their significance:\n- Foundation model for tabular data is not specified.\n- Not clear whether precision and recall in Table 1 are classification metrics or synthetic data evaluation metrics.\n- It is not clear how SEED_API, VARIATION_API and the distance function are implemented in the experiments, or how different degrees of variation are obtained from VARIATION_API.\n- Results do not have uncertainty estimates.\n\nThe paper is also missing comparisons with two recently published baselines improving the original PE: Tan et al. (2025) and Zhang et al. (2025). Another baseline that should be included is a conventional DP tabular data generator such as AIM (McKenna et al. 2022) for the tabular datasets.\n\nMinor points:\n- Figure 1: text is too small, and panel (a) is smaller than the others for some reason.\n- Not clear why only one lineage surviving is important based on Figure 1. The synthetic data in panel (b) seems to have slightly better diversity than in panel (c). Figure 2 does a much better job of communicating the issue.\n- Lines 147-148: \"differ by at most one individual\" is ambiguous. It could mean that one individual is added or removed, or that one individual is changed.\n- Algorithm 2, line 14: should $u$ be used instead of $j$? Also, $S\\_{syn}$ is not defined.\n- Line 256: I don't understand what \"vote within their own groups\" means. Based on Algorithm 2, it looks like all the selected samples just vote together.\n- Algorithm 1, line 13: the arguments are in a different order than the parameters of Algorithm 2. Also, the distance function is missing.\n- Equations (2) and (3) are not reflected in Algorithms 1 and 2.\n- Table 1: not all best values are bolded, for example recall on ImageNet.\n- The proposed algorithm is called \"DPSDivA\" in Appendix C.2.\n\nReferences:\n- R. McKenna, B. Mullins, D. Sheldon, G. Miklau (2022) \"AIM: an Adaptive and Iterative Mechanism for Differentially Private Synthetic Data\" Proceedings of the VLDB Endowment\n- B. Tan, Z. Xu, E. P. Xing, Z. Hu, S. Wu. (2025) \"Synthesizing Privacy-Preserving Text Data via Finetuning *without* Finetuning Billion-Scale LLMs\" ICML\n- J. Zhang, Y. Liu, J. Fu, Y. Hua, T. Zou, J. Cao, Q. Yang (2025) \"PCEvolve: Private Contrastive Evolution for Synthetic Dataset Generation via Few-Shot Private Data and Generative APIs\" ICML"}, "questions": {"value": "- Why does Private-PE degenerate into generating variants of a single example? Intuitively, candidates from more than one example should always get selected, since variants of a single example can only be nearest to a subset of training samples, while variants of another example would be nearest to another subset."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OuGmn7eZYC", "forum": "csD5GiGGFc", "replyto": "csD5GiGGFc", "signatures": ["ICLR.cc/2026/Conference/Submission730/Reviewer_5dWP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission730/Reviewer_5dWP"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission730/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761838499380, "cdate": 1761838499380, "tmdate": 1762915591342, "mdate": 1762915591342, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}