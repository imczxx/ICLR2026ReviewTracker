{"id": "JGIYfwaNpT", "number": 13725, "cdate": 1758221649539, "mdate": 1759897417197, "content": {"title": "Concepts' Information Bottleneck Models", "abstract": "Concept Bottleneck Models (CBMs) aim to deliver interpretable predictions by routing decisions through a human-understandable concept layer, yet they often suffer reduced accuracy and concept leakage that undermines faithfulness. We introduce an explicit Information Bottleneck regularizer on the concept layer that penalizes $I(X;C)$ while preserving task-relevant information in $I(C;Y)$, encouraging minimal-sufficient concept representations. We derive two practical variants (a variational objective and an entropy-based surrogate) and integrate them into standard CBM training without architectural changes or additional supervision. Evaluated across six CBM families and three benchmarks, the IB-regularized models consistently outperform their vanilla counterparts. Information-plane analyses further corroborate the intended behavior. These results indicate that enforcing a minimal-sufficient concept bottleneck improves both predictive performance and the reliability of concept-level interventions. The proposed regularizer offers a theoretic-grounded, architecture-agnostic path to more faithful and intervenable CBMs, resolving prior evaluation inconsistencies by aligning training protocols and demonstrating robust gains across model families and datasets.", "tldr": "Enhances Concept Bottleneck Models by integrating the Information Bottleneck principle to reduce concept leakage and improve performance", "keywords": ["Concept bottleneck models", "Information bottleneck", "Variational Inference"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6b4340aa3c0a4766b49c12bb6917e4be2f349f5d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces Concept Information Bottleneck Models, which incorporate a loss term aimed at reducing concept leakage in Concept Bottleneck Models. The objective is to maximise task-relevant information encoded in the concepts while suppressing task-irrelevant information present in the input X. The proposed regulariser is applied on top of standard CBM-like architectures. Through a series of experiments, the authors demonstrate that this additional term mitigates leakage."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The authors address a key limitation of CBMs (concept leakage) through a loss-based approach rather than architectural modifications. This design choice enhances the applicability of the proposed method, allowing it to be integrated with existing CBM variants. Notably, the models most susceptible to leakage (e.g., CEM) show the greatest improvement, further validating the effectiveness of the approach. The paper presents extensive experiments on standard benchmarks, applying the proposed regularisation to several widely used CBM-like models. Moreover, the paper is well written and easy to follow."}, "weaknesses": {"value": "- The authors evaluate their method on datasets where the set of concepts is extensive and highly representative of both the task and the concept space. However, it would be interesting to assess how the approach performs in scenarios where some degree of leakage is necessary to solve the task. Such a setting could be simulated by systematically removing a subset of concepts (e.g., half) from the training set. This would better reflect real-world conditions, where annotating a complete set of concepts is often infeasible.\n- The proposed metrics (AUC and NAUC) do not appear to represent a clear novelty. They essentially quantify what prior works have already assessed qualitatively (CBM responsiveness to concept interventions) by expressing it numerically rather than through visual plots.\n- The claim of improved accuracy (Section 4.1) seems somewhat overstated. The observed gains are marginal and, arguably, accuracy should not be the primary focus of this work. It would be more appropriate to emphasise that the proposed regularisation maintains task performance while effectively reducing concept leakage, rather than suggesting accuracy improvements."}, "questions": {"value": "- It would be interesting to explore how the proposed method behaves when the concept set is substantially reduced or incomplete (i.e., in cases where some degree of concept leakage becomes necessary to achieve good task performance). Such a setting would better approximate real-world conditions, where not all relevant concepts can be fully annotated.\n- While the paper focuses on minimising information leakage from the input to the output, it does not address intra-concept leakage. Prior works [1,2] have shown that certain concepts can be predicted from others, which may undermine the independence assumption among concepts. It would be valuable to investigate whether the proposed method can also mitigate this form of leakage, thereby further improving intervention responsiveness.\n\n---------------------------\n\n[1] Gabriele Dominici, Pietro Barbiero, Mateo Espinosa Zarlenga, Alberto Termine, Martin Gjoreski, Giuseppe Marra, & Marc Langheinrich (2025). Causal Concept Graph Models: Beyond Causal Opacity in Deep Learning. In The Thirteenth International Conference on Learning Representations.\n\n[2] Moritz Vandenhirtz, Sonia Laguna, Ričards Marcinkevi\\vcs, & Julia E Vogt (2024). Stochastic Concept Bottleneck Models. In The Thirty-eighth Annual Conference on Neural Information Processing Systems."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2OWWElvNzO", "forum": "JGIYfwaNpT", "replyto": "JGIYfwaNpT", "signatures": ["ICLR.cc/2026/Conference/Submission13725/Reviewer_L5tE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13725/Reviewer_L5tE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13725/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761809716357, "cdate": 1761809716357, "tmdate": 1762924268306, "mdate": 1762924268306, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this work, the authors propose CIBMs which utilize an Information Bottleneck regularizer on the concept layer to reduce concept leakage for a base CBM. Evaluating their approach on different CBMs (CBM, CEM, ProbCBM, AR-CBM), the authors show strong accuracy, concept leakage, and intervention capabilities."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Concept leakage is an important problem within CBMs, undermining faithfulness and intervention guarantees. The authors present a simple approach for mitigating leakage, utilizing an Information Bottleneck regularizer.\n- Experimental details are verbose and the approach can be easily attached to prior works."}, "weaknesses": {"value": "- Figure 3 does not really convey any information. The expanded results in the Appendix are useful but perhaps a table at different points along the x-axis would help for the main text?\n- Accuracy and intervention results both show minimal improvement. Concept leakage results seem like the strongest result, but are not explored in much detail. What does the improved OIS/NIS mean downstream if the intervention performance is not improved? Is there an interpretation of these two metrics that better quantifies the improvement of CIBMs?"}, "questions": {"value": "- What dataset is Table 2 for? Why is this run on only one dataset?\n- use beta=.5 for all experiments?\n- \"We also compare against more recent CBM variants such as ... intervention-aware CEM (Espinosa Zarlenga et al., 2022)\" - is this CEM or IntCEM [1]? Why evaluate on one but not both?\n- The motivation for the selected baselines in general is unclear, why is more recent work looking at intervention/leakage not included?\n- Some typos throughout the main text and appendix.\n\n[1] Espinosa Zarlenga, Mateo, et al. \"Learning to receive help: Intervention-aware concept embedding models.\" Advances in Neural Information Processing Systems 36 (2023): 37849-37875."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HCNTKtX1u4", "forum": "JGIYfwaNpT", "replyto": "JGIYfwaNpT", "signatures": ["ICLR.cc/2026/Conference/Submission13725/Reviewer_urBx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13725/Reviewer_urBx"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13725/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761850794407, "cdate": 1761850794407, "tmdate": 1762924267799, "mdate": 1762924267799, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes to enhance the interpretability of Concept Bottleneck Models (CBMs) by applying an explicit information-bottleneck (IB) regularizer to the concept layer. It argues that traditional CBMs suffer from concept leakage (i.e., unintended information flowing into concept activations) and that minimizing I(X;C) while maximizing I(C;Y) and I(Z;C) yields cleaner and more faithful concept representations. They introduce two practical methods, integrate them into multiple CBM families and evaluate on three benchmark datasets. Experimental results suggest reductions in leakage metrics, modest improvements in classification accuracy, and more reliable concept-level interventions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper improve target accuracy, reduce concept leakage, and enhance intervention effectiveness.\n2. The information-theoretic framing is conceptually sound: targeting I(X;C) aligns well with the desired minimal-sufficient concept representation.\n3. The proposed methods are modular and broadly applicable: the regularizer is applied across many CBM variants without altering the architecture radically.\n4. Empirical evaluations are relatively comprehensive: multiple methods, datasets, metrics (leakage, concept accuracy, task accuracy, intervention AUC) are reported."}, "weaknesses": {"value": "1. Stability of empirical results.\nThe empirical performance of different regularizers across datasets is not consistently positive.\nIn Table 1, certain variants of the proposed CIB regularizers improve accuracy or interpretability metrics on some datasets, but degrade or show negligible effects on others (e.g., AwA2).\nThis inconsistency suggests that the approach may be sensitive to dataset characteristics or model initialization, raising questions about its stability and generalization.\n2. Missing theoretical justification of guaranteed improvement.\nThe paper introduces the modified information-bottleneck objective\n$I(Z;C) + I(C;Y) - \\beta I(X;C)$,\nyet provides no theoretical guarantee, such as an error-bound or generalization-bound proof, showing that adding this IB term will necessarily improve the performance or faithfulness of existing CBMs.\n3. Overstated claims: The paper suggests that CIBMs “close the accuracy gap to black-box models without sacrificing\ninterpretability,” yet in many experiments the black-box baseline still significantly outperforms the IB-regularized CBMs. The practical significance of the interpretability-performance trade-off remains underexplored."}, "questions": {"value": "1. Could the authors provide more detailed explanation or proof of under what conditions minimizing I(X;C) while maximizing I(C;Y) ensures minimal-sufficient concept representations (i.e., no leakage)? Are there assumptions (e.g., about concept annotation completeness, model capacity, independence among concepts) required for the theory to hold?\n2. In Table 1, for certain model-dataset combinations the accuracy difference between vanilla CBM and CBM+IBB/IBE is very small (e.g., <0.5%) and within one standard deviation. \n3. In Eq. (5) and (7), the paper includes an entropy term H(C).\nHow is this quantity computed or approximated when C is continuous or high-dimensional?\nDoes this require batch-level estimation or additional variance reduction techniques?\n4. What is the computational overhead of including IB regularization, in terms of runtime or memory?\nHave the authors observed any optimization instability due to the extra MI term?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PNwmX2cyrc", "forum": "JGIYfwaNpT", "replyto": "JGIYfwaNpT", "signatures": ["ICLR.cc/2026/Conference/Submission13725/Reviewer_zMXB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13725/Reviewer_zMXB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13725/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761928323266, "cdate": 1761928323266, "tmdate": 1762924267375, "mdate": 1762924267375, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Motivated by the information bottleneck principle, the paper proposes concepts’ information bottleneck model (CIBM), which uses an information bottleneck regularizer (IB regularizer) for training concept bottleneck models (CBMs) to mitigate the problem of concept leakage while preserving prediction accuracy. Based on theoretical observations, the authors give two types of regularizers, bounded and estimator based, for training CBMs. Through experiments, it is shown that IB regularizers maintain or improve prediction performance while mitigating concept leakage. Moreover, using CIBM, the authors propose a measure to quantify the quality of concept sets."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The motivation for using information bottleneck principle to tackle concept leakage looks valid and interesting.\n2. The experiment results suggest that IB regularizers are indeed helpful to mitigate concept leakage while preserving final prediction accuracy."}, "weaknesses": {"value": "1. As authors frame CIBM as theoretically principled integration of IB principle to CBM, examining the validity of the estimators is important. However, theoretical analysis for deriving the bounded CIB (section 3.1, section 3.2, appendix B) seems to have fatal errors.\n- The paper claims to upper bound the L_{UB-CIB}, but in eq (A.1), -\\beta H(C|X) should be +\\beta H(C|X), and in equations from (A.2a) to (A.4l), the minus sign should be added to all the right hand sides (definition of entropy). These errors seem to make the CIB upper bound in eq (3) or (A.5) completely wrong. \n- Also, due to above observations, equation (6) seems to be wrong.\n2. If the goal of the paper is to address concept leakage, comparing with previous works that address concept leakage would be a valuable addition. Also, these works do not seem to be addressed properly in the related work section.\n3. At section 4.3, using only random intervention seems insufficient. The authors should include experiment that uses more effective intervention strategies explored in [1] such as UCP.\n\nReference\n\n[1] Shin et al., A Closer Look at the Intervention Procedure of Concept Bottleneck Models, ICML 2023."}, "questions": {"value": "1. Can the usage of two estimators (bounded CIB and estimator-based CIB) be theoretically justified, given that the theoretical analysis seems to be wrong?\n2. How does the IB-regularizer compare against other methods that mitigate leakage?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Dxg8F7JO6D", "forum": "JGIYfwaNpT", "replyto": "JGIYfwaNpT", "signatures": ["ICLR.cc/2026/Conference/Submission13725/Reviewer_DEB8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13725/Reviewer_DEB8"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13725/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761951328336, "cdate": 1761951328336, "tmdate": 1762924267007, "mdate": 1762924267007, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}