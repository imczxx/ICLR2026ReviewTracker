{"id": "7G0L4cj452", "number": 13625, "cdate": 1758220006969, "mdate": 1759897424078, "content": {"title": "$\\boldsymbol{\\partial^\\infty}$-Grid: Differentiable Grid Representations for Fast and Accurate Solutions to Differential Equations", "abstract": "We present a novel differentiable grid-based representation for efficiently solving differential equations (DEs). Widely used architectures for neural solvers, such as sinusoidal neural networks, are coordinate-based MLPs that are, both, computationally intensive and slow to train. Although grid-based alternatives for implicit representations (e.g., Instant-NGP and K-Planes) offer faster training, their reliance on linear interpolation restricts their ability to compute higher-order derivatives, rendering them unsuitable for solving DEs. In contrast, our approach overcomes these limitations by combining the efficiency of feature grids with radial basis function interpolation, which is infinitely often differentiable. To effectively capture high-frequency solutions and enable stable and faster computation of global gradients, we introduce a multi-resolution decomposition with co-located grids. Our proposed representation, $\\boldsymbol{\\partial^\\infty}$-Grid, is trained implicitly using the differential equations as loss functions, enabling accurate modeling of physical fields. We validate $\\boldsymbol{\\partial^\\infty}$-Grid on a variety of tasks, including Poisson equation for image reconstruction, the Helmholtz equation for wave fields, and the Kirchhoff-Love boundary value problem for cloth simulation. Our results demonstrate a 5–20× speed-up over coordinate-based MLP-based methods, solving differential equations in seconds or minutes while maintaining comparable accuracy and compactness.", "tldr": "We propose the first feature-grid method for representing signals and solving PDEs, with differentiable interpolation and multiscale design. This enables accurate solutions unlike prior feature grids while outperforming neural solvers in efficiency.", "keywords": ["Differentiable Equations; Neural Field and Representations; Feature Grid; RBF Interpolation"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/269db6f194584622c9226cb8e93f53917e56773a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The submission introduces ∂∞-Grid, a differentiable grid-based neural representation for solving partial differential equations (PDEs).Unlike coordinate-based multilayer perceptrons (MLPs) such as PINNs, ∂∞-Grid employs Radial Basis Function (RBF) interpolation over learned feature grids, resulting in an infinitely differentiable representation that supports analytic computation of spatial derivatives.\nThe framework further integrates multi-resolution, co-located grids to facilitate gradient propagation across scales.\n\nEmpirical evaluations encompass a range of PDE problems including gradient-based reconstruction, Helmholtz, Kirchhoff–Love plate deformation, Eikonal, and advection equations and demonstrate 5–20× faster convergence than coordinate-based baselines, with comparable or improved accuracy.\nThe approach aims to unify the strengths of grid-based representations, efficient yet non-differentiable, and coordinate-based networks, which are flexible but computationally slower."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe combination of feature grids with Gaussian RBF interpolation is intersting, technically sound and conceptually straightforward. Since Gaussian RBFs are $C^{\\infty}$, the method inherently supports analytic higher-order derivative computation, which is important for PDE solvers.\n2.\tThe experiments report significant improvements in convergence rate and accuracy, achieving 5–20x faster training compared to SIREN and K-Planes. These speedups represent a substantial computational gain, reducing training time from hours to minutes or even seconds, and demonstrate the method’s scalability and efficiency across diverse PDE formulations.\n3.\tThe presentation is clear, and the methodology is described in a structured and coherent manner.\n4.\tThe experimental evaluation across multiple classes of PDEs suggests that the proposed approach is broadly applicable rather than tailored to a specific problem type."}, "weaknesses": {"value": "1.\tThe formulation assumes a Cartesian grid. In contrast to coordinate-based PINNs, ∂∞-Grid cannot directly address irregular geometries or complex boundary conditions without additional coordinate transformations or masking procedures, limiting its applicability to structured domains.\n2.\tThe comparisons focus mainly on SIREN and K-Planes. Incorporating recent operator-learning approaches such as the Fourier Neural Operator or DeepONet would strengthen the evaluation, as the proposed framework requires solving each new boundary condition or PDE configuration from scratch, unlike operator-based methods that generalize across parameter variations.\n3.\tThe comparison to K-Planes may not be entirely fair for derivative-based tasks, as K-Planes relies on non-differentiable piecewise linear interpolation. \n4.\tThe paper lacks an analysis of how the solver’s performance varies with grid resolution, the number of multi-resolution levels, and the dimensionality of the feature vectors. It is also unclear how these parameters are selected.\n5.\tWhile the paper presents interesting empirical results, a more formal treatment of aspects such as convergence, stability, or error bounds relative to classical numerical solvers or PINNs could strengthen the contribution. Clarifying the underlying functional space (e.g., RKHS, $C^2$) would also enhance the theoretical grounding.\n\nMinor comments\n\n1.\tThe symbol f is used for different quantities in Eqs. (1) and (2). Although boldface differentiates the latter, this overlap could cause ambiguity.\n2.\tThe “Poisson” experiment corresponds to a gradient or Laplacian-based reconstruction task rather than a direct PDE solution; clearer terminology would help prevent confusion."}, "questions": {"value": "1.\tCan ∂∞-Grid be extended to non-rectangular or manifold domains?\n2.\tCould the framework be combined with coordinate-based PINNs to handle complex geometries while preserving grid efficiency?\n3.\tCould the authors clarify the implementation details for both K-Planes and Instant-NGP? For example, whether K-Planes is formulated as\n$u(x) = \\mathrm{MLP}(\\mathrm{linear_interpolation}(F, x))$.\n\n5.\tCould the authors evaluate or discuss the sensitivity of the proposed approach to grid resolution, the number of scales, and the dimensionality of the feature vectors?\n\n6.\tFigure 5: Could the authors include an image illustrating the difference between SIREN and the proposed method?\n7.\tWhat specific classes of PDEs can the method address effectively, and under what assumptions regarding smoothness or boundary conditions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vNwtL6M1T9", "forum": "7G0L4cj452", "replyto": "7G0L4cj452", "signatures": ["ICLR.cc/2026/Conference/Submission13625/Reviewer_mShH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13625/Reviewer_mShH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13625/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761038189551, "cdate": 1761038189551, "tmdate": 1762924203385, "mdate": 1762924203385, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a differentiable grid-based representation for solving differential equations. By combining multi-resolution feature grids with smooth radial basis function (RBF) interpolation, the method enables higher-order differentiability, allowing it to learn continuous fields whose derivatives satisfy physical constraints. The approach is applied to a variety of PDE problems, including the Poisson equation, the Helmholtz equation, and the Kirchhoff–Love model, achieving faster convergence than coordinate-based neural solvers such as SIREN."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is written with clarity, organization, and completeness. Overall, the derivation is straightforward and easy to follow.\n\n- The paper includes a comprehensive and thorough list of experiments, including Poisson Equation, Helmholtz Equation, Cloth Simulation, Eikonal Equation, and Advection and Heat Equations, and with both qualitative and quantitative results. \n\n- I appreciated the numerous experiments the authors supplement in the Appendix, especially the section on Eikonal Equations.\n\n- The method achieves comparable or better accuracy than MLP-based PINNs and SIREN while providing 5–20× faster training and inference."}, "weaknesses": {"value": "- The use of RBF interpolation in feature grids is conceptually similar to prior work such as NeuRBF (Chen et al., ICCV 2023). Both frameworks ultimately learn continuous fields under differentiable consistency constraints, and while the authors claim NeuRBF \"adapts to known target signals,\" this is not the case for NeRF-style trainings where the supervision comes from images and the ground truth 3D field is also unknown. I would sincerely suggest that the authors acknowledge this part and limit their contribution to \"applying existing RBF feature grid to PDEs.\"\n\nThis is my main assessment of the concerns of the paper, but from a \"solving PDEs\" perspective, there is still merit in having this paper published."}, "questions": {"value": "- How does the accuracy or convergence rate scale? Have the authors attempted any PDEs that require actual 3D fields (as opposed to the 2D-to-3D mapping in the cloth simulation)?\n\n- Can the method handle PDEs with non-smooth solutions or discontinuous coefficients, where RBF smoothness may become a drawback?\n\n- In the Eikonal equation experiment in the Appendix, how is the proposed method now different from NeuRBF? Would the authors be able to supplement a comparison with NeuRBF regarding this specific setup?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "eqvpFBR1UY", "forum": "7G0L4cj452", "replyto": "7G0L4cj452", "signatures": ["ICLR.cc/2026/Conference/Submission13625/Reviewer_qdmK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13625/Reviewer_qdmK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13625/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761688588340, "cdate": 1761688588340, "tmdate": 1762924203064, "mdate": 1762924203064, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a fast neural PDE solver based on grid-based neural fields like Instant NGP. Traditional grid-based neural fields are neural fields with features on a grid that are modulated by a small MLP. For arbitrary query points, these fields compute the feature by using d-linear interpolation. However, relying on d-linear interpolation means that these networks do not yield meaningful high-order derivatives. The authors propose to mitigate this by proposing a differentiable RBF-based interpolation that can yield accurate higher-order derivatives. The authors use a Gaussian RBF kernel to compute interpolation weights for the grid points surrounding a query point. \n\nThe authors apply their method to solving a variety of PDEs, ranging from the Helmholtz equation, the Advection and Heat Equation, Eikonal Equation, etc, showing increased accuracy over contemporary grid-based neural field architectures like Instant NGP and increased efficiency as compared to MLP-based architectures like SIREN."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The problem of obtaining accurate higher-order derivatives from grid-based neural fields is an important one, and the authors' differentiable interpolation scheme is a great step in this direction.\n2. The authors have done a rigorous evaluation across a broad range of PDEs."}, "weaknesses": {"value": "Weaknesses\n\n1. Writing can be improved: \n\t- Some of the authors' claims about their contributions seem a bit exaggerated. For instance, multi-resolution grids were an idea that was proposed in both Instant NGP and K-planes. While the authors have applied this idea to a novel setting of PDE-solvers, claiming the idea itself as a contribution seems misleading to me.\n\t- Notational issue: it seems that $r$ is both a parameter (input to the RBF kernel) and a hyper-parameter (extent of neighborhood considered for kernel) - this should be either resolved or the explanation of the $r$ hyper-parameter should be improved.\n\t- For 2D Advection, the authors claim that their approach shows no numerical dissipation. However, the change in the peak value on the colorbar between the initial value and the final state shows that there has been some dissipation. The authors have also not shown quantitative results for 1D and 2D advection\n2. Missing Results?: Could not find results for the heat equation in the supplementary material. (Appendix G)"}, "questions": {"value": "1. Appreciate the comparison to NeuRBF, but could the authors shed some light on how NeuRBF's formulation differs from their approach, which makes it possible for their approach to be used as an effective neural solver? The current explanation is unclear.\n\t- As per the authors' explanation it seems that NeuRBF's design makes it suitable to fit zeroth-order signals but not gradient-/derivative-based residuals like the losses described by the authors in their experiments which makes it difficult to use NeuRBF as a neural solver, but I am still not convinced by the author's explanation of on what specific design detail of NeuRBF makes it infeasible to use it as a neural solver.\n\t- Currently, the authors point to the requirement of ground-truth signals by NeuRBF as an issue, but that is because NeuRBF has been floated as a signal representation. Even if the authors' proposed architecture were to be used as a signal representation, for instance, to learn the initial conditions of a PDE, they would require the ground-truth signal for training.\n2. Can the author's architecture be used for overfitting to any input signal as well? This could increase the scope of their contribution. \n\t- Asking because Instant NGP reported that moving to higher-order interpolation approaches hurt performance on reconstruction \n\t- If the authors' proposed approach can do better would be a great contribution to the community. Even if not, it would be something useful for the community to know.\n\nI am generally leaning towards accepting this work. If the authors can address the weaknesses and provide an explanation for the above questions, I think that would make this work worthy of being accepted."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Lmho9Uxl2n", "forum": "7G0L4cj452", "replyto": "7G0L4cj452", "signatures": ["ICLR.cc/2026/Conference/Submission13625/Reviewer_ai8J"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13625/Reviewer_ai8J"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13625/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761788609378, "cdate": 1761788609378, "tmdate": 1762924202484, "mdate": 1762924202484, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}