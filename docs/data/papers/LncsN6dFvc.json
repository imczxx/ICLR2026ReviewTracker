{"id": "LncsN6dFvc", "number": 22807, "cdate": 1758335706614, "mdate": 1763032633968, "content": {"title": "Spectrum-aware Spiking Dynamics for Graph Contrastive Learning", "abstract": "Graph Contrastive Learning (GCL) typically relies on Graph Neural Networks (GNNs) for full-precision representation learning, which results in high computational overhead and energy consumption. Recently, integrating Spiking Neural Networks (SNNs) with GNNs has emerged as a promising energy-efficient alternative. However, existing approaches often treat spiking neurons merely as binary encoders to produce 1-bit representations, ignoring the rich structural information inherent in graph data. Also, the usage of a fixed initial membrane potential (IMP), which is usually set to 0, restricts the diversity of spiking patterns and limits the expressive power of spiking neurons.  To address these issues, we propose a novel Spectrum-enhanced Spiking Graph Contrastive Learning (S$^2$GCL) framework by integrating graph spectral information into spiking dynamics. Specifically, we first develop a novel Spectrum-aware Membrane Potential (SaMP) mechanism for SNNs by injecting eigenvalue-based biases into membrane potential learning to capture global graph structure and enhance SNN's expressive power. Then, we introduce an Overlapped Channel Grouping (OCG) strategy to construct sequence spikes for the graph and simultaneously reinforce correlations in spike trains based on overlapped feature channels. Finally, we adopt the dual-level contrastive objective to achieve both node-wise and channel-wise alignments. Extensive experiments on several benchmark datasets show the effectiveness of our proposed S$^2$GCL. The code of our method will be released upon acceptance.", "tldr": "", "keywords": ["Graph Contrastive Learning", "Graph Spectral Information", "Spiking Neural Networks", "Membrane Learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/a60c67e683382fb3ed567fa1741730115a085f04.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The study identifies two main limitations of existing spiking graph neural networks: the failure to capture intrinsic graph properties and the limited diversity of spike firing patterns. To address the above challenges, it proposes a Spectrum-inspired Spiking Graph Contrastive Learning ($S^2GCL$) framework which effectively introduces graph information into spiking neural dynamics. It consists of spectrum-aware membrane potential (SaMP) and overlapped channel grouping (OCG) modules. In addition, the framework constructs a dual-level contrastive loss to align both node-wise and channel-wise representations. Experiments on six benchmark datasets demonstrate that $S^2GCL$ achieves improved accuracy and promising energy efficiency compared to full-precision, binary and spiking GNN baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed SaMP mechanism is intuitive, which explores the diversity of spike patterns induced by initial membrane potential variations.\n2. The experimental evaluation encompasses multiple datasets and a broad range of baselines including binary, spiking, and unsupervised GNNs. The experimental results show that $S^2GCL$ consistently outperforms prior methods in terms of accuracy.\n3. The parameter analysis and energy consumption comparisons provide empirical evidence supporting the feasibility of this work for some resource-constrained applications."}, "weaknesses": {"value": "1. $S^2GCL$ appears to offer an incremental improvement compared with existing studies. The grouped subgraphs in OCG are largely derived from the paradigm proposed in SpikeGCL. SaMP, which incorporates positional/structural information into membrane potential, is closely related to the GNNs with positional/structural embeddings. \n2. In Equation 14, the design of Learnable IMP aims at adding positional/structural information to initial membrane potentials, $u_i=\\frac{1}{\\tau}h_i+(1-\\frac{1}{\\tau})\\tilde{v}_{pe/se}$. It seems to just transfer the widely used PE/SE into the spiking neurons as the initial membrane potential, without introducing a fundamentally new mechanism for dynamic membrane updating. A clearer distinction from existing PE/SE-based GNNs would strengthen the novelty claim.\n3. The paper lacks a detailed discussion of the computational cost associated with graph spectral information. Since eigenvalue computation can be expensive for large graphs, this operation may become a major bottleneck. The experiments are limited to small-to-medium graphs. It raises my concern whether the spectrum-aware spiking neurons hinder the scalability of $S^2GCL$ to large-scale graphs (e.g., OGB datasets)."}, "questions": {"value": "1. Could the authors provide more experimental results on large-scale graph datasets to verify the scalability of the proposed framework?\n2. The spectrum-aware spiking neurons are built upon LIF rather than spiking variants with learnable threshold potentials. Given that the initial membrane potential is influenced by graph information, how sensitive is the proposed model to the choice of threshold membrane potentials?\n3. In the efficiency analysis, is the computational overhead of pre-calculating graph spectral information considered? It would be helpful to include a more detailed complexity analysis or a formulated energy consumption estimation to better quantify the energy gaps among different baselines."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Rmgl2w66HH", "forum": "LncsN6dFvc", "replyto": "LncsN6dFvc", "signatures": ["ICLR.cc/2026/Conference/Submission22807/Reviewer_S6tV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22807/Reviewer_S6tV"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22807/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761922810609, "cdate": 1761922810609, "tmdate": 1762942394627, "mdate": 1762942394627, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "3Fjs8b9Qmc", "forum": "LncsN6dFvc", "replyto": "LncsN6dFvc", "signatures": ["ICLR.cc/2026/Conference/Submission22807/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22807/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763032633230, "cdate": 1763032633230, "tmdate": 1763032633230, "mdate": 1763032633230, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes S^2GCL, a spiking graph contrastive learning framework that aims to reduce computational energy while preserving representation quality. To enhance the expressive power of spike learning, the paper introduces Overlapped Channel Grouping (OCG) for sequential aspects and Spectrum-aware Membrane Potential (SaMP) for graph structural aspects. On six small to medium benchmarks (citation datasets and Amazon datasets), S^GCL reports accuracy improvements over full-precision GCL baselines, binary GNNs, and prior spiking GNN/GCL approaches, while also demonstrating energy reductions compared with ANN baselines."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "A substantive assessment of the strengths of the paper, touching on each of the following dimensions: originality, quality, clarity, and significance. We encourage reviewers to be broad in their definitions of originality and significance. For example, originality may arise from a new definition or problem formulation, creative combinations of existing ideas, application to a new domain, or removing limitations from prior results.\n\n[1] Conceptual link between spectrum and spiking dynamics.\nSince prior SGNNs treat SNNs as binarizers or inject positional features at the input, directly biasing membrane states with graph structure is a novel idea that could broaden the design space for spiking GNNs. The paper establishes a clear conceptual link between the graph’s spectral perspective and spiking dynamics.\n\n[2] Practical procedure for building spike sequences on static graphs.\nThe proposed Overlapped Channel Grouping (OCG) with a sliding-window mechanism provides a pragmatic alternative to feature repetition or non-overlapped grouping. Moreover, it naturally aligns with channel-wise contrastive learning, enabling the use of a channel contrastive loss. The paper empirically demonstrates the effectiveness of OCG across several benchmarks.\n\n[3] Rich empirical results and ablations.\nOn six commonly used datasets, S²GCL achieves competitive performance not only against other spike-based models but also against strong ANN baselines. The ablation and parameter studies (in Figs. 3–4) are informative and well aligned with the stated motivations."}, "weaknesses": {"value": "[W1] Limited scope of evaluations and unclear experimental settings.\nAll datasets are small to medium in size and cannot effectively validate the proposed method. Since the overall architecture follows SpikeGCL [1], the paper should at least include results on the OGBN-Arxiv and OGBN-MAG datasets. SaMP claims global structure awareness and robustness to node re-indexing, spectral sign flips, and graph perturbations; these should be explicitly demonstrated.\nThe main concern is that baseline experimental settings are not clearly specified, and the main configuration of S²GCL remains ambiguous. For instance, in MSG, there exist several settings such as the manifold choice (e.g., Lorentz) and the learning rate. Because the reported performance gap is nearly identical to the second-best results (Table 1), the experimental settings should be clearly described. The authors should explicitly explain how the baseline results were obtained, at least in the appendix.\nIn addition, GNN performance is highly sensitive to the learning rate. The authors should explore multiple learning rate configurations. Currently, the main results appear to be evaluated using only a single learning rate (1e-3) across all datasets, as stated in line 355. Such unclear experimental settings make it difficult to assess the effectiveness of the proposed method.\n\n[W2] The main effectiveness of the method is not clear.\nIn line 254, the spectrum-guided spiking GNN appears to combine several elements from prior works. Specifically, line 264 references adaptive threshold methods, and in the experimental setup, line 256 indicates substitution with PLIF neurons, which already yield significant improvements compared to the original LIF or IF neurons. For these reasons, the learnable IMP component seems incremental, mainly adding more parameters to enhance positional encoding.\nIt is not clear whether the observed improvements stem primarily from the learnable IMP or from a combination of previously established techniques (e.g., adaptive threshold + PLIF).\n\n[W3] Lack of efficiency and overhead analysis \nThe paper lacks a detailed analysis of computational efficiency and overhead. Compared to prior work, S^2GCL, which uses T sequential GNNs, appears to incur substantial memory overhead. Additionally, the description of efficiency calculation (line 447) is unclear. At least, the paper should explain how the theoretical energy was computed in the appendix. Including metrics such as MAC/SOP and FLOPs for energy computation would provide a clearer and more quantitative understanding of efficiency.\n\n[1] Li, Jintang, et al. \"A Graph is Worth 1-bit Spikes: When Graph Contrastive Learning Meets Spiking Neural Networks.\" The Twelfth International Conference on Learning Representations."}, "questions": {"value": "1.\tHow was the energy consumption in Figure 5 calculated for the S^2GCL? Are there any additional computational overheads in S^2GCL, or does Figure 5 already account for these overheads? \n2.\tThe experimental settings are not clearly described. All baseline configurations and experimental details used to obtain the results in Table 1 should be fully elaborated.\n3.\tWhy do the authors bias using IMP rather than appending spectral positional encodings (as in SAN-style methods) to the input features before the spiking neuron? Please compare with an otherwise identical model that adds spectral PEs to X and keeps $v^(0)=0$.\n4.\tCould the authors discuss the difference between the learnable threshold and IMP methods? Since the effectiveness of firing in SNNs depends on the difference between the threshold and membrane potential, learnable threshold methods could clarify the issue illustrated in Fig. 1(b).\n5.\tHow exactly is energy computed (e.g., based on MAC vs. AC counts or scaling constants)? Please provide detailed information on the energy estimation procedure.\n6.\tIs S^2GCL feasible for deployment on neuromorphic chips? A discussion of the modifications required for neuromorphic implementation would strengthen the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "IczLOQ2DSU", "forum": "LncsN6dFvc", "replyto": "LncsN6dFvc", "signatures": ["ICLR.cc/2026/Conference/Submission22807/Reviewer_3Pop"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22807/Reviewer_3Pop"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22807/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761963233814, "cdate": 1761963233814, "tmdate": 1762942394357, "mdate": 1762942394357, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes S2GCL, a graph contrastive learning (GCL) framework that couples a spectrum‑aware spiking encoder with dual‑level contrast. The key mechanisms are Spectrum‑aware Membrane Potential (SaMP), Overlapped Channel Grouping (OCG), and a dual contrastive objective. The authors validate the effectiveness of the propose approach on various datasets, such as Cora, CiteSeer, PubMed, Photo, Computers, and CS. According to their experimental results they achieved superior accuracy on those datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Strong average performance across diverse benchmarks. In Table 1 (p. 8), S2GCL outperforms prior SNN‑GCL (e.g., SPIKEGCL) and supervised/unsupervised GNN baselines on all six datasets.\n2. SaMP is easy to plug in. The learnable projection that maps eigenvalue features to initial membrane potential is simple and compatible with standard message‑passing layers and LIF neurons."}, "weaknesses": {"value": "1. Time‑step dependence of SaMP is not analyzed. SaMP only changes the initial membrane potential. Thus, as T grows and multiple integrate‑fire‑reset cycles occur, SaMP’s effect may diminish. The paper studies T vs. accuracy and runtime globally (Fig. 4) but does not isolate how SaMP’s contribution scales with T.\n2. Ablation granularity is limited. Figure 3 ablates SaMP, OCG, and channel contrast, but it does not specify the time‑step T, window w, or stride used for those ablations; nor does it examine the role of the node‑wise contrast term independently (Eq. 16) or the data‑augmentation choices Tstruc and Tfeat (Eqs. 7–8). Without these, it is hard to attribute gains cleanly among SaMP, OCG, node contrast, channel contrast, and augmentation.\n3. Marginal improvements over other graph information in SaMP. Table 2 compares multiple graph information. The absolute deltas are modest (e.g., Cora: 87.83→88.12; Photo: 94.24→94.79; Citeseer: 76.33→76.63; Computers: 91.25→91.29). The paper does not explain why spectrum is superior beyond small, dataset‑specific gains, nor whether SaMP’s benefit is statistically significant relative to other graph signals.\n4. Limited analysis of the proposed methods (SaMP, OCG, and dual contrast). The paper argues SaMP improves spike pattern diversity, but there is no quantitative analysis of spiking dynamics on the benchmark datasets to show how spectrum alters dynamics beyond initialization. OCG is motivated as preserving cross‑channel dependencies, yet there is no measurement of inter‑channel correlation before/after OCG or how channel‑wise contrast capitalizes on those correlations.\n5. “Spectrum‑guided spiking dynamics” may overstate the scope. Since spectrum is only used to form the IMP and not to adjust thresholds or currents over time (Eq. 14), it is debatable whether the spiking dynamics themselves are spectrum‑aware beyond initialization. \n6. Neuromorphic feasibility and overhead are under‑discussed. Computing Laplacian eigenvalues at scale can be expensive; the authors did not quantify the cost of eigenvalue computation. Figure 5’s energy comparison aggregates methods but omits spike‑rate, step‑count T, overlap ratio π, and OCG windowing specifics driving energy per sample on each dataset.\n7. Dataset‑dependent energy behavior is unexplained. In Figure 5, relative energy rankings differ between Photo and Computers. \n8. Claims of SNN specificity to GCL are not disentangled from initialization. Since the authors note other graph signals can be injected instead of eigenvalues, it is unclear whether the core benefit is “spectrum‑aware dynamics” or simply “non‑zero, structured IMP”."}, "questions": {"value": "Please refer to Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8JDlnMWYw5", "forum": "LncsN6dFvc", "replyto": "LncsN6dFvc", "signatures": ["ICLR.cc/2026/Conference/Submission22807/Reviewer_kSp5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22807/Reviewer_kSp5"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22807/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761999291063, "cdate": 1761999291063, "tmdate": 1762953736240, "mdate": 1762953736240, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}