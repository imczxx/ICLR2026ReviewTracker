{"id": "RClKXngVN8", "number": 19296, "cdate": 1758295153728, "mdate": 1763676361695, "content": {"title": "Tackling the XAI Disagreement Problem with Adaptive Feature Grouping", "abstract": "Post-hoc explanations aim at understanding which input features (or groups thereof) are the most impactful toward certain model decisions. \nMany such methods have been proposed (ArchAttribute, Occlusion, SHAP, RISE, LIME, Integrated Gradient) and it is hard for practitioners\nto understand the differences between them. Even worse, faithfulness metrics, often used to quantitatively compare explanation methods,\nalso exhibit inconsistencies. To address these issues, recent work has unified explanation methods \nthrough the lens of Functional Decomposition. We extend such work to scenarios where input features are partitioned into groups \n(e.g. pixel patches) and prove that disagreements between explanation methods and faithfulness metrics are caused by between-group \ninteractions. Crucially, getting rid of between-group interactions would lead to a single explanation that is optimal according to all faithfulness metrics.  We finally show how to reduce the disagreements by adaptively grouping features/pixels on tabular/image data.", "tldr": "We consider feature as groups in order to increase agreement among post-hoc explainability methods.", "keywords": ["Explainability", "Disagreements", "Functional Decomposition", "Feature Groups"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fc969b36d7a6b5391e61b906c751bd58c7c7dda1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper addresses disagreement problem in explainable ai, where different post-hoc explanation methods and metric often produce inconsistent results. The paper extend the framework of functional decomposition to analyze explanations over groups of features. It has the theoretical contribution to prove that the disagreement between various group-based explainers and high scores on common metrics share a common root cause. Therefore the paper proposes AGREED, an algorithm that adaptively finds feature partitions that minimize these interactions."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well written and easy to follow.\n2. The paper has rigorous theoretical contribution.\n3. The paper clearly demonstrates that both disagreements between explanation method and (un)faithfulness as measured by standard metric are functions of the same underlying between-group interaction terms.\n4. The paper validated the theoretical claims in diverse modalities both synthetic and real world dataset."}, "weaknesses": {"value": "1. The problem statement in the introduction is very broad. The described challenge is fundamental to almost all xai research.\n2. The readability of the figures are poor, also the main text needs to provide guidance on how to interpret the results in the figure (e.g., what the takeaway is).\n3. Need to cite all the explanation methods that are introduced in the paper (e.g., arch, occ).\n4. The paper's argument appears to equate 'faithfulness' with 'agreement/consistency' between explainers. While the theory links common (un)faithfulness metric to interaction-driven disagreement, the author should specify the definition of 'faithfulness'.\n5. The vision experiments rely on VGG16 and ResNet18, which are architectures from 2014 and 2015 which is outdated.\n6. The proposed algorithm does not optimize the true interaction loss, which captures all interactions."}, "questions": {"value": "Look at the weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "p800rDUXE6", "forum": "RClKXngVN8", "replyto": "RClKXngVN8", "signatures": ["ICLR.cc/2026/Conference/Submission19296/Reviewer_Dpg6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19296/Reviewer_Dpg6"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19296/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761886324773, "cdate": 1761886324773, "tmdate": 1762931250065, "mdate": 1762931250065, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper aims to address the problem of XAI disagreement. The aauthors extend Functional Decomposition and parition the input features/pixels into groups and prove that the primary reason of disagreement between different explanation methods is the between-group interactions.Further, they advocate eliminating between-group interactions and show that the disagreements can be reduced by adaptively grouping features/pixel."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1) The paper deals with an important aspects of XAI: disagreement between explanation methods and the unreliability of fidelity metrics\n\n2) The theoretical sections are formally presented, with clear conditions, properties, and proofs.\n\n3) The proposed method was shown to work in tabular data as well as images."}, "weaknesses": {"value": "1)  The authors use L2 disagreement between attribution vectors to define their partition loss. While this choice yields a differentiable and additive objective but it emphasizes only magnitude alignment and misses out on rank alignment. Rank-based measures such as Spearman, Kendall correlation etc could capture rank consistency between explanations but are non-differentiable for the groupwise optimization. A brief justification of this design choice would enable the readers to understand the paper clearly.\n\n2) The partition loss formulation is conceptually appealing but it requires computing multiple attribution maps per input, severely limiting scalability. This limitation should be discussed more explicitly as it constrains the applicability of the proposed framework to high-dimensional or real-time settings.\n\n3) The authors provide the algorithm details of AGREED in supplementary and also the computation cost of O(d^2N^2). The paper would benefit from a detailed analysis of this computation cost.\n\n4) AGREED seems to be prohibitively expensive as the cost O(d^2N^2) increases rapidly with number of features and samples. Even for 100 features and 1000 samples the number of model  inferences would be too high. Hence, there is limited scope of appying AGREED on high dimensional and real-world settings. I request the authors to clarify this limitation in the paper."}, "questions": {"value": "I request the authors to address the weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UtI7BLwanl", "forum": "RClKXngVN8", "replyto": "RClKXngVN8", "signatures": ["ICLR.cc/2026/Conference/Submission19296/Reviewer_5SdD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19296/Reviewer_5SdD"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19296/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761964818814, "cdate": 1761964818814, "tmdate": 1762931249630, "mdate": 1762931249630, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Summary\nThis paper addresses the disagreement problem among post-hoc explanations in explainable AI by proposing an adaptive feature grouping method (AGREED) that reduces interactions between feature groups, aiming to bring explanation methods into agreement. The work builds on prior frameworks of functional decomposition and attribution methods, extending them to disjoint feature groupings. Empirical validation on tabular and image datasets shows improvements in explanation consistency and faithfulness metrics.\n\nSoundness\nThe methodology is mathematically sound and supported by formal proofs linking disagreement to between-group interactions. The algorithm is intuitive and empirically demonstrated to reduce disagreement. Results are robust on multiple datasets, though assumptions like groupwise additivity in regions and sampling baselines could affect results in practice.\n\nPresentation\nThe paper is well-organized but the presentation is somewhat standard and occasionally dense. Some of the core ideas could be clarified with more intuitive or visual illustrations, especially around interpretation of grouped attributions. The empirical section is comprehensive yet could better emphasize practical significance. Comparisons to prior grouping methods on images are limited by scalability and implementation constraints, leading to incomplete benchmarking in some cases.\n\nLiterature review\nLiterature review is a bit outdated, check these e.g. for attributions methods such as IG and SHAP with stronger mathematical content:\n\nA General Feature Attribution Framework under a Black-box Setting\n\n-Y. Cai, A. Thibaud, G.Wunder, International Conference on Machine Learning (ICML'25), Vancouver, Canada, 2025\n\n-On Gradient-like Explanation under a Black-box Setting: When Black-box Explanations Become as Good as White-box\nY. Cai, G. Wunder, International Conference on Machine Learning (ICML'24)\n\nContribution\n-Proposes a practical adaptive grouping algorithm to reduce disagreement in feature attributions\n-Unifies explanation methods under a functional decomposition framework for groups\n-Extends interpretability to handle feature group interactions explicitly\n-Demonstrates empirical gains on tabular and image data\n-Provides theoretical insights into when explanation agreements are possible"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "-Sound theoretical grounding\n-Addresses a key challenge limiting trust in explainability\n-Novel focus on attributing disagreement to feature interaction"}, "weaknesses": {"value": "-Novelty incremental given prior functional decomposition frameworks; core insight of grouping to minimize interactions is expected\n-Presentation could benefit from more accessible examples and clearer motivation for practitioner\n-Limited direct comparisons with some existing grouping algorithms on images\n-Interpretation of grouped attributions remains difficult without actionable visualization\n-Image domain grouping requires per-sample runs, limiting real-world scalability"}, "questions": {"value": "-How does AGREED compare to prior grouping methods that are not feasible for images, when run on smaller image subsets?\n-How practically interpretable are grouped attributions for non-expert users, especially with large feature clusters?\n-Can the algorithm support global grouping for an entire dataset rather than per-sample in images?\n-Would integrating semantic/region-based features improve grouping and interpretability further?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1Tsj9gANog", "forum": "RClKXngVN8", "replyto": "RClKXngVN8", "signatures": ["ICLR.cc/2026/Conference/Submission19296/Reviewer_MwSX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19296/Reviewer_MwSX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19296/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988190057, "cdate": 1761988190057, "tmdate": 1762931249237, "mdate": 1762931249237, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the issue that many explanation methods often disagree with each other. They formally prove that when the model is group-wise additive, using the ground truth groupings, then unfaithfulness metrics will all reduce to 0. They then prove that if we minimize the difference between Arch and Occlusion, then this will minimize the disagreement between all groups. And they achieve it by iteratively merging groups with the highest pairwise interactions. They repeat until the disagreement falls below a threshold. They conduct experiments to show that when they merge the groups progressively, the difference between different explanation methods consistently decreases, and that each method is changing to become more agreed as the loss decreases, and that the proposed method AGREED can get much lower disagreement when merging not many groups than other methods, meaning that it is merging the groups that will reduce disagreement the most."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper proves a novel and important theorem that if we reduce the disagreement between Arch and Occlusion, it will reduce the disagreement for all methods.\n2. Their proposed method empirically finds better groups than other methods.\n3. The authors conducted comprehensive experiments to demonstrate their advantage in different aspects."}, "weaknesses": {"value": "1. Some of the empirical figures (e.g., Figures 4 and 5) are not very intuitive\nin their current presentation, and the takeaways are not made explicit in the\ncaptions. Clarifying the intended interpretation in the captions or main text\nwould significantly improve readability for non-expert readers.\n\n2. One prior work also proves how one can achieve zero unfaithfulness when using the correct grouping structure. It would be helpful to cite this work to situate the current contribution within a more comprehensive body of related theory [1].\n\n3. The paper considers only non-overlapping partitions, while there could be cases where groups overlap with each other a lot and only considering non-overlapping groups could make it less expressive.\n\n[1] You et al. \"Sum-of-Parts: Self-Attributing Neural Networks with End-to-End Learning of Feature Groups\" ICML 2025"}, "questions": {"value": "1. You et al. 2025 also considers group-based attributions and categorizes insertion and deletion style errors (Definition 2.2 of Sum-of-Parts is similar to Equation (10) in this paper, and Definition A.1 is similar to Equation (9)), although they compute differences with respect to the prediction contributed by a group, rather than differences in attribution scores produced by two methods for that group. They show that when there are between-group interactions (e.g., polynomial correlations), these errors can grow exponentially (Theorem 2.3), while using the correct grouping drives the error to zero (Theorem 2.4). The theoretical results here (e.g., Theorem 3.2) appear closely related, as both hinge on the vanishing of between-group interaction terms. It would be helpful for the authors to explicitly discuss the similarities and differences with You et al. 2025, including the choice of disjoint partitions in this paper vs. allowing overlapping groups in You et al 2025.\n\n2. In Section 5.2.1 and Figure 7, only Arch and Occlusion are shown. Since the paper's claims concern reduced disagreement across a broad set of methods, could you clarify whether the qualitative improvements also generalize to other methods like LIME/SHAP etc.? Including additional visual examples in the appendix would strengthen the qualitative evidence.\n\n3. In functions with overlapping interaction structure (e.g., where a feature participates in multiple strongly interacting cliques), disjoint partitions may not be expressive enough. In such cases, the optimization may be forced to merge many features together, reducing interpretability. It would be helpful if the authors could comment on this tradeoff and whether and how overlapping or hierarchical groupings could be supported in future work.\n\n[1] You et al. \"Sum-of-Parts: Self-Attributing Neural Networks with End-to-End Learning of Feature Groups\" ICML 2025"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7r9OoQwezs", "forum": "RClKXngVN8", "replyto": "RClKXngVN8", "signatures": ["ICLR.cc/2026/Conference/Submission19296/Reviewer_EP8L"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19296/Reviewer_EP8L"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19296/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992142281, "cdate": 1761992142281, "tmdate": 1762931248815, "mdate": 1762931248815, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Official Comments by the Author"}, "comment": {"value": "Dear reviewers,\n\nwe would like to thank all of you for taking the time to review our work, for highlighting the quality of our contributions, and for proposing means of improving the paper. Taking your feedback into account, we have updated the manuscript and highlighted all changes in blue. \n\nWhile we respond to your questions directly as comments on openreview, we encourage you take a look at the manuscript to see the full changes. Any change in the manuscript that you need to look at is referenced in our response."}}, "id": "6qjjwHkAiu", "forum": "RClKXngVN8", "replyto": "RClKXngVN8", "signatures": ["ICLR.cc/2026/Conference/Submission19296/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19296/Authors"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission19296/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763679512514, "cdate": 1763679512514, "tmdate": 1763679512514, "mdate": 1763679512514, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}