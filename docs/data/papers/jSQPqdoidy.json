{"id": "jSQPqdoidy", "number": 23451, "cdate": 1758343986081, "mdate": 1759896813938, "content": {"title": "SK2Decompile: LLM-based Two-Phase Binary Decompilation from Skeleton to Skin", "abstract": "Large Language Models (LLMs) have emerged as a promising approach for binary decompilation. However, the existing LLM-based decompilers still are somewhat limited in effectively presenting a program's source-level structure with its original identifiers.\nTo mitigate this, we introduce SK2Decompile, a novel two-phase approach to decompile from the skeleton (semantic structure) to the skin (identifier) of programs. Specifically, we first apply a Structure Recovery model to translate a program's binary code to an Intermediate Representation (IR) as deriving the program's \"skeleton\", i.e., preserving control flow and data structures while obfuscating all identifiers with generic placeholders. We also apply reinforcement learning to reward the model for producing program structures that adhere to the syntactic and semantic rules expected by compilers. Second, we apply an Identifier Naming model to produce meaningful identifiers which reflect actual program semantics as deriving the program's \"skin\". We train the Identifier Naming model with a separate reinforcement learning objective that rewards the semantic similarity between its predictions and the reference code. Such a two-phase decompilation process facilitates advancing the correctness and readability of decompilation independently.\nOur evaluations indicate that SK2Decompile, significantly outperforms the SOTA baselines, achieving 21.6% average re-executability rate gain over GPT-5-mini on the HumanEval dataset and 29.4% average R2I improvement over Idioms on the GitHub2025 benchmark.", "tldr": "", "keywords": ["decompilation", "binary analysis"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f9511c133f566d9060e05193e8699cfa0a0af74e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "SK2Decompile proposes a two-phase LLM-based decompilation framework that separately reconstructs:\n\n1. Program structure (skeleton) via Structure Recovery from binary to IR.\n\n2. Identifier semantics (skin) via Identifier Naming from IR to human-readable source code.\n\nBoth phases are fine-tuned with reinforcement learning (RL):\n\n1. Structure Recovery RL uses compiler feedback and placeholder accuracy.\n\n2. Identifier Naming RL uses semantic cosine similarity between generated and reference code embeddings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Originality\n\n* Two-phase “skeleton→skin” formulation reduces a monolithic task to two focused ones. \n* IR defined as obfuscated source, motivated by the Information Bottleneck (compression vs relevance). \n* Phase-specific RL: compiler/placeholder Jaccard for structure; embedding cosine for naming/readability. \n\nQuality\n\n* Clear IR generation algorithm and training details (SFT→GRPO RL).\n* Strong, multi-metric benchmarks (re-executability, R2I, GPT-Judge) across diverse suites. \n* SOTA gains (e.g., +21.6% re-exec on HumanEval; +29.4% R2I on GitHub2025) with solid ablations isolating where gains come from. \n\n Clarity\n\n* Effective figures (motivation, framework, case study) and precise math/rewards. \n* Reproducibility statement and artifact release. \n\nSignificance\n\n* Practical impact: higher re-executability/readability; paradigm likely transferable to other program-recovery tasks."}, "weaknesses": {"value": "Experimental coverage\n\n1. Architecture/compiler diversity is narrow. All binaries are x86/Linux; no ARM/MIPS, MSVC/Windows, or ICC variants. This limits generalization. Action: add cross-architecture (ARM64) and cross-compiler (MSVC) evaluations; report deltas by ISA/ABI and OS. \n2. Language scope is mostly C/C-like. No results for Rust/Go/C++ templates where type systems and naming semantics differ. Action: evaluate at least one non-C family (Rust, Go) and modern C++ (templates/RAII) to test Identifier Naming generality. \n\nBaselines & fairness\n\nNo head-to-head with classic de-compilers. Action: add side-by-side comparisons (functional pass rate, R2I, blinded human readability) using Ghidra/Hex-Rays outputs to contextualize LLM gains."}, "questions": {"value": "- RL reward design & potential leakage:\nYou “provide the compiler with the header of the ground-truth IR” to check compilability and grant reward.\n• Can you quantify how much this leaks structure/type information compared to a realistic setting?\n• Please add an ablation with no ground truth headers and report re-executability/R2I deltas.\n\n- RL stability, sensitivity, and cost:\nYou apply GRPO on 50k samples due to compute limits but report no convergence/variance details.\n• Please provide training curves (reward, validation re-exec/R2I) and GPU hours, and batch/length constraints.\n• Any reward hacking observed?\n\n- Naming reward via a single embedding model: Identifier Naming uses cosine similarity with qwen-embedding-0.6B\n• How sensitive are results to the embedding choice? Please compare against alternative code/text-code embeddings and report correlation with identifier-level F1 and human ratings."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1rZFnCQjCx", "forum": "jSQPqdoidy", "replyto": "jSQPqdoidy", "signatures": ["ICLR.cc/2026/Conference/Submission23451/Reviewer_v9Us"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23451/Reviewer_v9Us"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23451/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761937814827, "cdate": 1761937814827, "tmdate": 1762942667991, "mdate": 1762942667991, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles binary decompilation. Traditional tools like Ghidra or IDA produce code that works but is hard to read. LLM-based decompilers make code readable but often wrong.\n\nSK2Decompile proposes a 2-phase approach:\n- Structure Recovery (“skeleton”): translate binary into IR that keeps control flow but with placeholder symbols. \n- Identifier Naming (“skin”): fills in meaningful names for the symbols.\n\nBoth phases use RL. The reward of the phase 1 is IR compilability + structural corectness. Phase 2 is rewarded if the predicted identifiers are semantically similar)\n\nThe method improves both functional correctness and readability independently. Results show large gains over prior systems (GPT-5-mini, LLM4Decompile)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Reproducibility effort.\n- Clever and clear conceptual decomposition in 2 different parts. Well-motivated.\n- Interesting and well-principled use of the information bottleneck principle.\n- Comprehensive evaluations, and ablation study. Different optimization levels evaluated, diverse benchmarks.\n- Very strong quantitative results."}, "weaknesses": {"value": "- The 2-level decomposition of decompilation is not novel. The particular implementation is. I don't think the paper itself makes a good job at clarifying these 2 levels. E.g., https://arxiv.org/abs/2103.12801,\n- Limited scope in languages and targets.\n- Algorithm 1 could better specify how “names to preserve” FP are determined automatically.\n- Minor: the paper could greatly improve in clarity with the help of some diagrams.\n\nNits: \n- some citations are incorrectly formatted. \n- Incorrect spacing in some footnote marks.\n- “find out it achieves” → “find that it achieves.”\n-  “we analogize … to the human body” -> “we draw an analogy.”\n- Inconsistencies in capitalization of “Re-Executability” vs “Re-executability.”"}, "questions": {"value": "Do you have any intuition on how GPT-Judge works for decompilation? What criteria does the model seem to be using?\n\nHow robust is SK2Decompile to compiler obfuscations or optimizations beyond O3?\n\nCan the same IR concept be used cross-language (e.g., C++, Rust)? And with other assembly yargets?\n\nHow much of the gain comes from RL versus just having a cleaner IR target?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gPZ7jQivql", "forum": "jSQPqdoidy", "replyto": "jSQPqdoidy", "signatures": ["ICLR.cc/2026/Conference/Submission23451/Reviewer_e7pk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23451/Reviewer_e7pk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23451/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761939598043, "cdate": 1761939598043, "tmdate": 1762942667663, "mdate": 1762942667663, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces SK2Decompile, a two phase binary decompilation strategy for binary lifting. The first phase focuses on lifting to the \"skeleton\" of the code, at the IR level, followed by the second phase which aims to provide structured recovery of meaningful identifiers in the actual program semantics. The authors employ both language models and RL for their approach, and the tool is evaluated on multiple benchmarks, and compared to other LLM lifters."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "+ Important, established problem, with lots of headroom for innovation\n+ The 2-phase approach is quite interesting, and I appreciated that contribution"}, "weaknesses": {"value": "- The baseline is not strong: none of the proposed benchmarks are \"realistic\" in their complexity nor size, which makes me question the feasibility of this technique to generalize beyond the studied benchmarks.\n- There are no rule-based tools being compared. In particular, McToll is a well respected tool for decompilation, and I'd be very curious to see how it performs relative to SK2Decompile. This is important, because while LLMs are useful tools, rule-based tools should really be considered state-of-the-art here (as that is what they are replacing), not just other LLM lifters.\n- No true analysis on what fails and what doesn't fail in the decompilation process (some explainability). The ablation study helps explain where some of the performance improvements arise, but does not give practical description of what programs failed to lift, and why that was the case."}, "questions": {"value": "While the idea is good, the baseline for evaluation is quite underwhelming to this reviewer. Instead of a \"basic\" benchmark suite such as HumanEval and others, how would such a tool perform on a larger and more realistic codebase, such as BringUpBench?\n\nAdditionally, modern rule-based lifters actually perform quite well on \"simple\" benchmarks such as HE, but struggle against more complex benchmarks. This is true for McToll and a few others. That said, McToll does surprisingly well HumanEval-like benchmarks, which to me indicates that should be the best baseline available, not GPT-5-Mini. If SK2Decompile (or other LLM-based lifters for that matter) do not match McToll level accuracy, then their contribution is questionable.\n\nOn the flip side, BringUpBench is also challenging from a rule-based approach: how does SK2Decompile (and other lifters) perform on such a benchmark suite?\n\nTo summarize:\n- The idea is quite interesting (splitting the decompilation into two phases); however, the evaluation is not well executed given the comparison points (there was no rule-based technique), and the benchmarks are simple.\n- If the authors are able to generate results on BringUpBench-level complexity with their tool, I would increase my score. \n- How does this tool fare compared to rule-based tools, such as McToll, when it comes to re-compilation. \n\nI will say that the R2I and GPT-Judge results are interesting; but practically speaking the recompilation is what is very interesting to this reviewer, as that opens the door for lots of future directions in binary modifications and optimizations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "aTe4WPMJ7H", "forum": "jSQPqdoidy", "replyto": "jSQPqdoidy", "signatures": ["ICLR.cc/2026/Conference/Submission23451/Reviewer_CTua"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23451/Reviewer_CTua"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23451/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982683407, "cdate": 1761982683407, "tmdate": 1762942667395, "mdate": 1762942667395, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SK2Decompile, an LLM-based binary decompilation approach.\n\nSection 2 discusses existing decompilation approaches, and provides a motivational example.\n\nSection 3 proposes SK2Decompile. It consists of (1) structure recovery yielding an intermediate representation (IR); and (2) identifier naming. Each phase uses a model that has been subjected to supervised fine-tuning and reinforcement learning. The design of the intermediate representation is cast as an \"Information Bottleneck\" optimization task. The IR produced traverses an abstract syntax tree to determine names and types of identifiers. The identifier naming process employs sequence-to-sequence training followed by reinforcement learning to aligh the outputs with compiler preference and type constraints.\n\nSection 4 covers the evaluation. Exebench is used as training data. The evaluation compares against three other decompilers: GPT5-mini, LLM4Decompile, and Idioms. The evaluation benchmarks used are HumanEval and MBPP. The evaluation metrics used include re-executability rate, the relative readability metric for decompiled code R2I, and GPT-Judge, a score between 1 and 5 reflecting the meaningfulness of variable names. The results mark SK2Decompile as winner in almost all cases. An abblation study illustrates the need for all components (src, ir, and rl). Lastly, the naming benefits are illustrated on a dedicated case."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- LLM4Decompile and Idioms are adequate baselines to compare against\n- The results show good performance\n- The abblation illustrates the need of the various components\n- Meaningful ethics statement"}, "weaknesses": {"value": "- Unclear why re-executability results are limited to just two benchmarks\n- HumanEval is a dataset that is not representative for actual decompilation problems -- the only justification can be that it is used in earlier studies.\n- I would expect a feedback loop trying to fix errors could improve reproducibility. This could be separately discussed\n- The 'case study' is not a case study in a methodological meaning of the word. Is a useful illustration, but not a critical qualitative assessment of the capabilities of the approach proposed.\n- I would like to see a more critical (qualitative) assessments of cases not properly handled by SK2Decompile, in order to identify challenges the research community should focus on next"}, "questions": {"value": "- Why are there no re-executability results for exebench? Doesn't it come with a test suite? I don't understand the remark about stripping blocking this on p.6.\n- Nova (and other models) are easily dismissed as they do not \"provide details about their data preprocessing approaches or do not release their models\" -- but I'm not convinced by this -- what is the best you can do?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Xcqd73MLo6", "forum": "jSQPqdoidy", "replyto": "jSQPqdoidy", "signatures": ["ICLR.cc/2026/Conference/Submission23451/Reviewer_564f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23451/Reviewer_564f"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23451/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762082911055, "cdate": 1762082911055, "tmdate": 1762942667027, "mdate": 1762942667027, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}