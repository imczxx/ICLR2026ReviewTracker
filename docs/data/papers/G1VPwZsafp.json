{"id": "G1VPwZsafp", "number": 12389, "cdate": 1758207518382, "mdate": 1759897513067, "content": {"title": "CITED: A Decision Boundary-Aware Signature for GNNs Towards Model Extraction Defense", "abstract": "Graph neural networks (GNNs) have demonstrated superior performance in various applications, such as recommendation systems and financial risk management. However, deploying large-scale GNN models locally is particularly challenging for users, as it requires significant computational resources and extensive property data. Consequently, Machine Learning as a Service (MLaaS) has become increasingly popular, offering a convenient way to deploy and access various models, including GNNs. However, an emerging threat known as Model Extraction Attacks (MEAs) presents significant risks, as adversaries can readily obtain surrogate GNN models exhibiting similar functionality. Specifically, attackers repeatedly query the target model using subgraph inputs to collect corresponding responses. These input-output pairs are subsequently utilized to train their own surrogate models at minimal cost. Many techniques have been proposed to defend against MEAs, but most are limited to specific output levels (e.g., embedding or label) and suffer from inherent technical drawbacks. To address these limitations, we propose a novel ownership verification framework CITED which is a first-of-its-kind method to achieve ownership verification on both embedding and label levels. \nMoreover, CITED is a novel signature-based method that neither harms downstream performance nor introduces auxiliary models that reduce efficiency, while still outperforming all watermarking and fingerprinting approaches. Extensive experiments demonstrate the effectiveness and robustness of our CITED framework. Code is available at: \\url{https://anonymous.4open.science/r/CITED}.", "tldr": "", "keywords": ["Graph Machine Learning", "Model Extraction Defense"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7d64d61b24fe8dad293187b37bc0a0b506109192.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes CITED, a unified framework for defending against GNN model extraction attacks (MEAs) via decision boundary-aware signatures. It enables ownership verification at both embedding and label levels, addressing limitations of existing watermarking (label-level only) and fingerprinting (embedding-level only) methods. CITED generates signatures from boundary sensitive nodes, uses Wasserstein distance and prediction accuracy for verification, and achieves good performance across seven datasets and five GNN backbones without harming downstream utility or requiring auxiliary models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Avoids task-irrelevant triggers, maintaining or even improving model performance on node classification tasks.\n\n2. Eliminates auxiliary model training, reducing computational overhead, and retains effectiveness under MEAs and removal attacks (pruning, fine-tuning).\n\n2. Provides probabilistic bounds for embedding similarity and prediction agreement."}, "weaknesses": {"value": "1. Regarding the necessity of integrating the embedding and label levels, this seems more like a technical assumption. Could the authors provide some insight into why this integration is necessary? Watermarking or fingerprinting methods, for example, do not usually focus on both embedding and label levels. Moreover, labels can be viewed as embeddings passed through a classifier, so the nature of embeddings and labels may not differ significantly.\n\n2. In line 245, the authors claim that “as the decision boundary captures the most distinctive and model-specific behavior.” However, nodes near the decision boundary are typically hard to distinguish. The repeated assumption in the paper seems questionable and may be hard to justify.\n\n3. Can this method be extended to regression models or graph classification datasets? The current approach appears to be limited to node classification.\n\n4. In line 157, the authors mention real-world applications, citing citation networks. However, MEA attacks are not particularly relevant for citation networks. In contrast, fields like molecular structure prediction are more common MLaaS scenarios, as mentioned in the paper. The authors should provide experiments on such datasets; For now, the practical applicability seems limited.\n\n5. The theoretical conclusions appear to have issues. In Theorem 1, when $\\lambda = \\Delta G$, substituting into Equation 8 gives $\\Pr(D_p < \\lambda) \\geq 0$ instead of 1. This raises concerns about the validity of the derivation and why there seems to be this truncation effect."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OnrWnTStT2", "forum": "G1VPwZsafp", "replyto": "G1VPwZsafp", "signatures": ["ICLR.cc/2026/Conference/Submission12389/Reviewer_KmxL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12389/Reviewer_KmxL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12389/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761807661151, "cdate": 1761807661151, "tmdate": 1762923290517, "mdate": 1762923290517, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a decision boundary-aware signature framework, CITED, for defending graph neural networks against model extraction attacks. The paper introduces a method for extracting task-relevant signatures from nodes near the model's decision boundary, enabling unified embedding/label-level verification without the need for auxiliary models. Experiments demonstrate improved performance of verification over standard watermarking and fingerprinting methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper proposes a novel signature-based ownership verification mechanism that operates at both embedding and label levels, addressing a limitation in prior work.  \n- This paper presents an efficient verification framework, improving scalability over conventional fingerprinting methods.  \n- The proposed method achieves good verification performance  across various datasets and GNN architectures while providing probabilistic guarantees on signature preservation."}, "weaknesses": {"value": "- The framework's experimental validation is confined to a single threat model; testing it across multiple MEA scenarios would more effectively demonstrate its robustness.  \n- While the method shows efficiency advantages, its scalability to graphs with millions of nodes remains unverified; its signature generation (involving boundary node identification and multi-metric scoring) and verification workflows may face computational or memory bottlenecks in such scenarios.  \n- The framework’s reliance on the target model’s decision boundaries for signature generation may potentially lead to instability or diminished distinguishability when the model undergoes fine-tuning or domain adaptation."}, "questions": {"value": "I have the following questions regarding the practicality of CITED:  \n\n- Is the signature mechanism applicable in real-world settings with noisy labels or significant class imbalance, and does its reliance on the decision boundaries maintain robustness under such scenarios?  \n- Can the signature set be compressed or structurally optimized to reduce storage or computational demands without compromising verification reliability?  \n- Is there a minimum number of signature nodes required to ensure verification confidence, and how does this threshold vary with graph scale or model capacity?  \n- The rating will be adjusted accordingly if the above concerns are properly addressed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "This paper does not involve ethical issues."}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "OR0J3Mgg3Z", "forum": "G1VPwZsafp", "replyto": "G1VPwZsafp", "signatures": ["ICLR.cc/2026/Conference/Submission12389/Reviewer_iPrN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12389/Reviewer_iPrN"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12389/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761839327684, "cdate": 1761839327684, "tmdate": 1762923289846, "mdate": 1762923289846, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of protecting proprietary GNNs deployed under the Graph Machine Learning as a Service paradigm, where models are accessed through APIs but are vulnerable to model extraction attacks (MEAs). Existing defenses, such as watermarking and fingerprinting, are limited because they operate only at either the label level or the embedding level, making them ineffective when attackers extract models through different output interfaces. \n\nTo overcome this limitation: \n\n* The paper proposes **CITED**, a unified ownership verification framework based on a decision boundary–aware signature that functions across both embedding-level and label-level outputs. The signature arises naturally from the model’s decision boundary and can be transferred to surrogate models through extraction, allowing ownership to be verified without inserting task-irrelevant triggers. \n* The framework also introduces an efficient verification protocol that avoids training additional auxiliary models by extending the ARUC metric with the Wasserstein distance.\n* Experiments demonstrate that CITED consistently outperforms existing MEA defense methods and enables robust ownership verification across diverse output settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The technical contribution of this paper is solid. The proposed signature effectively addresses the challenge of achieving unified ownership verification at both the embedding level and the label level under model extraction attacks. Moreover, the theoretical analyses provided in the paper are generally sound and offer clear justification for using the 2-Wasserstein distance as the metric for verification."}, "weaknesses": {"value": "The experimental evaluation in this paper is somewhat limited. For example, only one model extraction attack (GNNStealing) is adopted as the threat model, and the study focuses solely on the classical node classification task. Additionally, I suggest improving the presentation by introducing an overview figure to provide a clearer illustration of the CITED framework."}, "questions": {"value": "Here are some questions:\n\n* In Section 5.2, how is the defense model trained? The current description lacks sufficient detail.\n\n* The performance of CITED on the Photo dataset appears noticeably weaker compared to other datasets. Could you provide an explanation for this discrepancy?\n\n* I don’t quite understand the motivation for introducing **Heterogeneity**, and it does not seem to provide clear benefits (as shown in Table 3)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "a3rOyEowtm", "forum": "G1VPwZsafp", "replyto": "G1VPwZsafp", "signatures": ["ICLR.cc/2026/Conference/Submission12389/Reviewer_X94K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12389/Reviewer_X94K"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12389/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762337387501, "cdate": 1762337387501, "tmdate": 1762923289548, "mdate": 1762923289548, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}