{"id": "AcDx2tUZPb", "number": 2498, "cdate": 1757126281432, "mdate": 1759898144433, "content": {"title": "DecompGAIL: Learning Realistic Traffic Behaviors with Decomposed Multi-Agent Generative Adversarial Imitation Learning", "abstract": "Realistic traffic simulation is critical for the development of autonomous driving systems and urban mobility planning, yet existing imitation learning approaches often fail to model realistic traffic behaviors. Behavior cloning suffers from covariate shift, while Generative Adversarial Imitation Learning (GAIL) is notoriously unstable in multi-agent settings. We identify a key source of this instability—irrelevant interaction misguidance—where a discriminator penalizes an ego vehicle’s realistic behavior due to unrealistic interactions among its neighbors. To address this, we propose Decomposed Multi-agent GAIL (DecompGAIL), which explicitly decomposes realism into ego–map and ego–neighbor components, filtering out misleading neighbor–neighbor and neighbor–map interactions. We further introduce a social PPO objective that augments ego rewards with distance-weighted neighborhood rewards, encouraging overall realism across agents. Integrated into a lightweight SMART-based backbone, DecompGAIL achieves state-of-the-art performance on the WOMD Sim Agents 2025 benchmark.", "tldr": "", "keywords": ["traffic simulation", "multi-agent imitation learning", "generative adversarial imitation learning"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/37348a6bd84809757e74e139639060f69ce9c148.pdf", "supplementary_material": "/attachment/27905cfe53df506b18d0b4d9006bba2e36a9faed.zip"}, "replies": [{"content": {"summary": {"value": "* This paper addresses the problem of training instability in multi-agent GAIL for realistic traffic simulation.\n* It identifies irrelevant interaction misguidance as a key issue, where the discriminator incorrectly penalizes a realistic ego agent because of unrealistic interactions among its neighbors.\n* The proposed solution DecompGAIL introduces a decomposed discriminator architecture that explicitly separates realism into (1) ego-map realism and (2) pairwise ego-neighbor realism.\n* This decomposed design structurally filters out the misleading neighbor-neighbor and neighbor-map interaction signals that cause instability.\n* The method is enhanced with a social PPO objective that augments the agent’s reward with a distance-weighted sum of its neighbors' rewards, promoting overall population realism.\n* The method achieves SOTA on WOSAC."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "* DecompGAIL achieves state-of-the-art results on WOMD sim agents and demonstrates significantly improved training stability.\n* Irrelevant interaction misguidance is a novel problem that the authors discovered. GAIL has been notoriously difficult to train.\n* The authors show strong empirical validation that the proposed approach significantly improves training stability and in addition achieves strong results on WOSAC.\n* The ablation study validates that each proposed component contributes to the strong results."}, "weaknesses": {"value": "* While the solution of decomposing the discriminator is sound it is engineered and strongly dependent on the input features that are used by the sim agent model. For example, it’s unclear how this approach could be applied to a simulator model that leverages images and sensor sim."}, "questions": {"value": "* Are there failure cases or poor quality examples that could be included?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dXCFpYwafK", "forum": "AcDx2tUZPb", "replyto": "AcDx2tUZPb", "signatures": ["ICLR.cc/2026/Conference/Submission2498/Reviewer_dJoy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2498/Reviewer_dJoy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2498/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761522655597, "cdate": 1761522655597, "tmdate": 1762916257162, "mdate": 1762916257162, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes DecompGAIL, which aim to address the instability of the Generative Adversarial imitation Learning. The authors proposes to decomposes the realism to ego-map and ego-neighbor to avoid weakly relevant neighbor–neighbor interactions. Alghough it shows better training stability, the model is built upon a very strong pretrained backbone, and the results are saturated (only minimal gain) on the overall realism. The authors should conduct a more comprehensive study of why do we need Generative Imitlation Learning framework, and highlight how this GAIL-finetuning provided a different aspects, dimensions of traffic simulation"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well-written and the proposed Decomposed GAIL method is more stable than prior GAIL baselines.\n- DecompGAIL achieves competitive results on the Sim Agent Challenge 2025, though the gain is very small.\n- The main potential of this work is the discriminator, which can provide a useful realism signal compared to prior metrics (see weakness section)"}, "weaknesses": {"value": "- Qualitative results are not interesting and are very similar to previous works\n- Overall, DecompGAIL’s advantage compared to prior works is unclear, given that the performance improvements are very small (± 0.01 realism score).\n- The pretrained backbone already attains a high discriminator score (~0.5) from Figure 3, which suggests the added GAIL module provides minimal gain.\n- I suggest the authors to start with a underperformed backbone w/ GAIL finetuning, and the main potential of this work is to  showcase the discriminator:whether it provides a uesful realism signal, compared to prior metrics such as Waymo Sim Agents Challenge\n- In Sec 5.4, the authors claimed that BC suffers from a covariate shift problem by mentioning higher collision likelihood and very minimal gain on realism. This may not hold true as the Sim Agent Challenge measures distributional realsim instead of rule satisfaction; see [1].\n\n\n[1] Wang M., Wang J., Ye T., Chen J., Yu K. (2025). Do LLM Modules Generalize? A Study on Motion Generation for Autonomous Driving. CoRL."}, "questions": {"value": "- How does this work compared to supervised fine-tuning, what are the advantages of using GAIL, given that the gain is very minimal  compared to the original SMART 0.05 \n- The definition and handling of “ego” vs “neighbor” agents is unclear: during training, are all agents’ policies updated simultaneously, or is only the ego agent’s policy learned while neighbors remain fixed? How does this affect memory usage and training dynamics (especially when using a decomposed discriminator)?\n- Please address the weakness sections"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "5I0ctljUFn", "forum": "AcDx2tUZPb", "replyto": "AcDx2tUZPb", "signatures": ["ICLR.cc/2026/Conference/Submission2498/Reviewer_sEmo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2498/Reviewer_sEmo"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2498/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761784987472, "cdate": 1761784987472, "tmdate": 1762916256643, "mdate": 1762916256643, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a key limitation in multi-agent Generative Adversarial Imitation Learning (GAIL) for traffic simulation, where existing discriminators penalize realistic agents simply because other nearby agents behave unrealistically. The authors call this phenomenon irrelevant interaction misguidance.\nTo solve this, they propose DecompGAIL, which decomposes the discriminator into two terms: ego–map realism (how the ego vehicle interacts with the static environment) and ego–neighbor realism (how it interacts with relevant nearby agents). Irrelevant neighbor–neighbor or distant-agent interactions are filtered out through distance-weighted aggregation. In addition, a social PPO reward encourages coherent scene-level realism by adding distance-weighted neighbor rewards to each agent’s objective. Experiments on the WOMD Sim Agents 2025 benchmark show that DecompGAIL improves realism metrics and training stability compared with prior multi-agent GAIL baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Clearly identifies and mitigates the irrelevant interaction misguidance problem.\n\n- The decomposition is simple, computationally efficient, and compatible with existing frameworks.\n\n- Demonstrates improved realism and stability on public benchmarks with comprehensive ablations.\n\n- Offers a general recipe that can transfer to other multi-agent imitation settings."}, "weaknesses": {"value": "- Comparisons omit Wasserstein or gradient-penalized discriminators, making it unclear whether decomposition alone drives the gains.\n\n- The social reward could unintentionally amplify correlated neighbor behaviors.\n\n- The related work section omits several closely related papers:\n\nA. Kuefler, J. Morton, T. Wheeler, and M. J. Kochenderfer, “Imitating Driver Behavior with Generative Adversarial Networks,” IEEE Intelligent Vehicles Symposium (IV), 2017, pp. 204–211.\n\nR. P. Bhattacharyya, B. Wulfe, D. J. Phillips, A. Kuefler, J. Morton, R. Senanayake, and M. J. Kochenderfer, “Modeling Human Driving Behavior through Generative Adversarial Imitation Learning,” CoRR, 2020.\n\nH. Chen, T. Ji, S. Liu, and K. Driggs-Campbell, “Combining Model-Based Controllers and Generative Adversarial Imitation Learning for Traffic Simulation,” IEEE ITSC 2022, pp. 1698–1704.\n\nK. Brown, K. Driggs-Campbell, and M. J. Kochenderfer, “Modeling and Prediction of Human Driver Behavior: A Survey,” arXiv:2006.08832, 2020."}, "questions": {"value": "How sensitive is performance to the decay parameters $\\alpha$ and $\\beta$ for interaction weighting and social rewards?\n\nWhen freezing or fine-tuning the map encoder during discriminator training, how does stability or realism change?\n\nCould the social reward cause feedback loops where agents learn to exploit mutual rewards without improving realism?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "R0rYHg8V88", "forum": "AcDx2tUZPb", "replyto": "AcDx2tUZPb", "signatures": ["ICLR.cc/2026/Conference/Submission2498/Reviewer_bk4B"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2498/Reviewer_bk4B"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2498/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761930491509, "cdate": 1761930491509, "tmdate": 1762916256088, "mdate": 1762916256088, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}