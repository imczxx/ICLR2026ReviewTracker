{"id": "lUkqy21EBB", "number": 12664, "cdate": 1758209366686, "mdate": 1759897495201, "content": {"title": "Pushing LLMs to Their Logical Reasoning Bound: The Role of Data Reasoning Intensity", "abstract": "Recent advances in large language models (LLMs) highlight the importance of training data structure and quality in shaping reasoning behavior. However, most existing approaches focus on transforming data formats while neglecting the internal reasoning complexity of training samples, leaving the reasoning potential of data underexplored and underutilized. In this work, we posit that LLM logical reasoning performance is jointly constrained by the potential of the training data and the cognitive capacity of the model. To make this relationship measurable, we introduce Data Reasoning Intensity (DRI), a novel metric that quantifies the latent logical reasoning complexity of samples by decomposing and aggregating their logical structures. This allows us to analyze how well current LLMs utilize logical reasoning signals and identify performance gaps relative to data potential. Based on this insight, we introduce a re-cognizing optimization strategy that systematically enhances the logical reasoning intensity of training data. Rather than increasing data volume, our method re-optimizes existing samples to better align with the LLM’s logical reasoning bounder. Extensive experiments show that our approach significantly improves performance and generalization over data-centric strategies. We further validate our method under a reinforcement learning framework. Our results indicate that prioritizing reasoning complexity in data rather than sheer scale or superficial form is essential to realizing LLMs' full cognitive potential. Our code is available in the supplementary file.", "tldr": "", "keywords": ["large language model", "logical reasoning", "data reasoning intensity"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f8facb547716f8953265129e86e1516fbac32982.pdf", "supplementary_material": "/attachment/3927b654b92226ae5e0e34dbca946a86b7058068.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduce Data Reasoning Intensity (DRI), a novel metric that quantifies the latent logical reasoning complexity of samples by decomposing and aggregating their logical structures.\nBased on this, the authors introduce a re-cognizing optimization strategy that systematically enhances the logical reasoning intensity of training data. \nExperiments show that the proposed approaches improves performance and generalization over data-centric strategies."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper develops a quantitative metric for the reasoning complexity of training data.\n2. The authors draw on established theories like  Sweller’s cognitive load optimization principle to propose the re-cognizing optimization strategy."}, "weaknesses": {"value": "1. Although the paper introduces a quantitative metric for data reasoning potential, the rationale behind the specific formulations (e.g., Equations 1, 5, 6, and 7) is unclear: why are they defined in their current forms rather than other possible ones (linear, polynomial, exponential, logarithmic, etc.)? The paper lacks sufficient theoretical justification, intuitive explanation, or empirical validation for these choices.\n2. The definition in Equation 1 is somewhat confusing. It is unclear why it is termed effective reasoning capability: it seems the authors may intend to express the model’s efficiency or learning ability in utilizing data per parameter unit. Moreover, since model architectures may naturally exhibit different sensitivities to various data types, it is not clear how the coupling between C(M) and E(D) is considered.\n3. The notations used in Sections 3.1 and 3.2 are also difficult to follow. It would be helpful if the authors could include concrete examples to illustrate the meaning or numerical form of these symbols.\n4. Figure 1 lacks sufficient explanation. The meaning of the horizontal gray dashed line and the definition of the ideal state are unclear. According to the intended meaning of Equation 1, shouldn’t the line be linear? (Though I may have misunderstood the authors’ intention.)\n5. Beyond natural-language-based logical reasoning, mathematics and code are important components of reasoning tasks today. The generalization and applicability of the proposed metric to these domains require further validation."}, "questions": {"value": "see Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mcGpTh9JJB", "forum": "lUkqy21EBB", "replyto": "lUkqy21EBB", "signatures": ["ICLR.cc/2026/Conference/Submission12664/Reviewer_JAg8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12664/Reviewer_JAg8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12664/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761734697707, "cdate": 1761734697707, "tmdate": 1762923502176, "mdate": 1762923502176, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors suppose that the LLM's reasoning ability is constrained by the potential of the training data. Therefore, the authors design a metric, named data reasoning intensity, to re-order the training datasets. In this way, the LLMs are trained on re-ordered datasets from low DRI samples to high DRI samples. Experiment results prove the effectiveness of the proposed method. The DRI depends on the Logical Intensity Quantification and Reasoning Intensity Quantification."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper proposes a new metric to re-range the training samples of reasoning tasks.\n2. The re-range dataset is balanced. According the Figure 3 (c), a high DRI score also means a higher error rate, which is consistent.\n3. The fine-tuned models show better performance on reasoning tasks."}, "weaknesses": {"value": "1. The improvements are not significant compared to baselines.\n2. In Figure 1, the 8b-our method is closed to the 30b-base. However, there are no related experiments and results in Section 4."}, "questions": {"value": "Does this method improve an 8B model to achieve 32B-level performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2JFqnLQMWg", "forum": "lUkqy21EBB", "replyto": "lUkqy21EBB", "signatures": ["ICLR.cc/2026/Conference/Submission12664/Reviewer_MCeZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12664/Reviewer_MCeZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12664/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761961225706, "cdate": 1761961225706, "tmdate": 1762923501790, "mdate": 1762923501790, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Data Reasoning Intensity (DRI), a novel metric for quantifying the latent logical reasoning complexity of training samples for large language models. The authors posit that LLM reasoning performance is jointly constrained by training data potential and model cognitive capacity. DRI decomposes samples into logical elements (predicates, constants, expressions) and aggregates them via a scoring function that accounts for structural complexity, nesting depth, and reasoning steps. Based on empirical analysis showing current LLMs underutilize available reasoning data, the authors propose a re-cognizing optimization strategy: Phase I reshapes model cognition through uniform data exposure, while Phase II emphasizes high-DRI samples via probability-weighted sampling. Experiments on four logical reasoning benchmarks (Reclor, LogicBench, LogiQA, LogiQA2.0) using LLaMA3.1-8B and Qwen2.5-7B demonstrate consistent improvements over curriculum learning and bin-based progressive learning baselines in both supervised fine-tuning and reinforcement learning settings."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper includes extensive experiments across multiple datasets, model architectures, and training paradigms (SFT and RL), with careful construction of balanced test sets to avoid evaluation bias.\n- The analysis reveals three important and clear observations: (1) low-DRI data can be pruned, (2) high-DRI data catalyzes improvements, and (3) diversity across DRI spectrum is necessary—providing actionable guidance for data curation.\n- The connection to the Roofline Model and cognitive load theory provides intuitive motivation, even if the formalization could be strengthened."}, "weaknesses": {"value": "- The quantity DRI well supports the data selection given the model complexity. However, this is how E(D) part works. If the author wants to advocate that DRI works as the ratio of E(D) / C(M), as the key contribution, the C(M) part should also be demonstrated.\n- The E(D) quantity is defined on logical problems, specifically, a well defined first order language. This aligns well with the scope of this paper. However, one potential limitation is that if we work on a first order language where $|C_i|$ is particularly large, say a database on all athletics in Olympic games from 1900. where the |C_i| term dominate the calculation so that the DRI score can be biased. This can happen if LLM is given a question about athletics and a full list of their names are input in the context. How will you define the E(D) score for the sample?"}, "questions": {"value": "- Can we say that, the DRI ratio E(D) / C(M) means that more parameters of LLM leads to lower DRI score given the same dataset. So can we say, for a 30B model and a 8B model, if we train it on the same dataset D, the 30B model should perform worse than the 8B one because its DRI is low?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YoHD1Z2476", "forum": "lUkqy21EBB", "replyto": "lUkqy21EBB", "signatures": ["ICLR.cc/2026/Conference/Submission12664/Reviewer_uzRr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12664/Reviewer_uzRr"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12664/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762184213147, "cdate": 1762184213147, "tmdate": 1762923501488, "mdate": 1762923501488, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}