{"id": "pBz9imKi56", "number": 3005, "cdate": 1757315203513, "mdate": 1759898114118, "content": {"title": "A Gain for Reconstruction, A Pain for Generation: Exploiting Representation in Visual Tokenization", "abstract": "Discrete visual tokenization is a cornerstone of modern auto-regressive (AR) image generation, yet current methods are fundamentally constrained by a trade-off between reconstruction fidelity and semantic expressivity. In this work, we first propose a principled framework for token representation learning based on three pillars: feature alignment with foundation models, structural diversification of the codebook into specialized subspaces, and explicit disentanglement to enforce semantic independence. We materialize these principles in a novel tokenizer, Semantic Subspace Quantization (SSQ), which achieves state-of-the-art image reconstruction. However, this success reveals a critical and previously overlooked paradox: the semantically rich, structured representations that excel at reconstruction cause a significant performance collapse in standard AR generative models. To resolve this Reconstruction-Generation Discrepancy, we introduce a novel tokenizer-generator co-design methodology, systematically adapting the AR model's architecture and training curriculum to harness the multi-faceted nature of SSQ's tokens. Our final, synergistic system effectively alleviates this discrepancy, achieving state-of-the-art performance on high-fidelity reconstruction and generation, demonstrating a new path forward for discrete visual modeling.", "tldr": "We investigate the representation of visual tokenizers.", "keywords": ["Visual Tokenizer", "Visual Generation", "Multimodal"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/45f08f80942615f7c77de854fe8d544e81ca95d9.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a new visual tokenizer, Semantic Subspace Quantization (SSQ), built on a principled framework of three pillars: 1) Structural Diversification, which uses multiple factorized codebooks (subspaces) instead of a monolithic one; 2) Explicit Disentanglement, which enforces orthogonality between these subspaces to ensure they learn complementary features; and 3) Feature Alignment, which guides subspaces to learn semantic information by aligning them with features from foundation models like DINOv2 and CLIP."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed SSQ tokenizer is built on a well-motivated and principled framework. The three pillars of diversification, disentanglement, and alignment provide a systematic way to create a semantically rich and structured token representation, and the results convincingly demonstrate its state-of-the-art reconstruction capabilities.\n- This paper throughly investigated the impact of different components in the design, making insightful observations to the community."}, "weaknesses": {"value": "- In Table 3, the structure divergence seems to lack of a fair baseline with 32768 setting regarding gFID?\n- Ablation about hyperparam in noisy training?"}, "questions": {"value": "see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yeh8cKUhUF", "forum": "pBz9imKi56", "replyto": "pBz9imKi56", "signatures": ["ICLR.cc/2026/Conference/Submission3005/Reviewer_1WzQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3005/Reviewer_1WzQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3005/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761883467922, "cdate": 1761883467922, "tmdate": 1762916492340, "mdate": 1762916492340, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the often-overlooked relationship between visual tokenization quality and autoregressive (AR) image generation performance.  \nThe authors introduce **Semantic Subspace Quantization (SSQ)**, a tokenizer built on three principles: **feature alignment**, **structural diversification**, and **explicit disentanglement**.  \nWhile SSQ achieves state-of-the-art image reconstruction, it surprisingly worsens AR generation — a paradox termed the **Reconstruction–Generation Discrepancy**.  \nTo address this, the paper proposes a **tokenizer–generator co-design** strategy, including a **factorized AR head**, **two-stage training**, and **noisy sub-token regularization**, which together restore generation quality and surpass prior AR baselines such as LlamaGen."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **Novel and well-articulated problem framing.**  \n  Identifying the Reconstruction–Generation Discrepancy is a meaningful conceptual contribution that clarifies why better reconstruction can hurt AR generation.\n\n- **Principled and interpretable tokenizer design.**  \n  The three-pillar SSQ framework (alignment, diversification, disentanglement) provides a clear structure for improving representation quality.\n\n- **Effective AR co-design.**  \n  The proposed factorized AR head and staged training curriculum directly address architectural mismatch and optimization instability, leading to strong empirical gains.\n\n- **Solid empirical performance.**  \n  On ImageNet 256×256, SSQ-LlamaGen achieves FID 2.61 vs 3.80 for LlamaGen-L and Inception Score 313.9 vs 248.3, showing both quantitative and qualitative improvements.\n\n- **Comprehensive ablations and honest discussion.**  \n  The paper presents negative results (e.g., naïve multi-head classifiers fail) and openly discusses remaining gaps and scalability limits.\n\n- **Readable and well-motivated.**  \n  The writing is clear, with good intuition on why semantic alignment helps reconstruction and how disentanglement works."}, "weaknesses": {"value": "- **Incremental tokenizer innovation.**  \n  SSQ combines known techniques (multi-codebook, VFM alignment, orthogonality regularization) into one framework; the novelty lies more in framing than in algorithmic breakthrough.\n\n- **Limited scope of experiments.**  \n  Evaluations are confined to ImageNet 256×256 class-conditional AR. The generality to other datasets, text-to-image generation, or diffusion-based methods remains untested.\n\n- **Disentanglement is simplistic.**  \n  The squared dot-product loss enforces orthogonality but not true independence between subspaces.\n\n- **Efficiency and scalability not measured.**  \n  The factorized AR head increases computation per patch, yet runtime and throughput are not reported.\n\n- **Residual gap persists.**  \n  Even after co-design, SSQ-Triple still reconstructs better but generates worse than SSQ-Dual, indicating that the discrepancy is only partially resolved."}, "questions": {"value": "1. How does SSQ perform when integrated into non-autoregressive or diffusion-based generators?  \n   Would the same reconstruction–generation discrepancy appear?\n2. What is the computational overhead (training time, inference speed) of the factorized AR head compared to a standard linear head?\n3. Have the authors tested robustness or generalization to out-of-domain datasets, given the heavy reliance on DINOv2/CLIP alignment?\n4. Could stronger disentanglement measures (e.g., mutual-information-based losses) further improve subspace independence and generation stability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TjltPdoqoq", "forum": "pBz9imKi56", "replyto": "pBz9imKi56", "signatures": ["ICLR.cc/2026/Conference/Submission3005/Reviewer_Co8j"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3005/Reviewer_Co8j"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3005/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761893433773, "cdate": 1761893433773, "tmdate": 1762916491767, "mdate": 1762916491767, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the long-standing trade-off between reconstruction fidelity and semantic expressivity in discrete visual tokenizers, a crucial component of auto-regressive (AR) image generation. The authors introduce Semantic Subspace Quantization (SSQ), a novel tokenizer built on three principles: Feature Alignment with Foundation Models (e.g., DINOv2, CLIP), Structural Diversification via factorized quantization, and Explicit Disentanglement using an orthogonality loss. SSQ achieves state-of-the-art reconstruction fidelity."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The proposed framework is highly systematic and clearly articulated. The paper provides detailed ablation studies (Tables 3, 4, 5) to validate each component of the SSQ tokenizer and the co-design strategies. The in-depth analysis of the SSQ feature space in the Appendix (Figures 5, 6, 7), demonstrating specialization, affinity, and orthogonality, is well-executed and adds compelling evidence to the paper's claims about representation learning. Quality (Reconstruction Performance): The SSQ tokenizer indisputably sets a new state-of-the-art in reconstruction fidelity (Table 1), beating strong multi-codebook baselines like ImageFolder and TokenFlow."}, "weaknesses": {"value": "While the paper presents the SSQ framework as a \"principled framework,\" the individual technical components are incremental and have been extensively explored in prior work, diminishing the originality claim:\n* Factorized/multi-codebooks are a well-established concept (e.g., RQ-VAE (Lee et al., 2022), ImageFolder (Li et al., 2024b), TokenFlow (Qu et al., 2024)). The paper claims systematization but the concept is not new.\n* Aligning VQ codes with features from foundation models (CLIP, DINO) is directly implemented in concurrent works like VA-VAE (Yao et al., 2025), MAETok (Chen et al., 2025), and VQGAN-LC (Zhu et al., 2024b) to enhance semantic content.\n\nThe core thesis is that the co-design methodology resolves the Reconstruction-Generation Discrepancy. However, the experimental results contradict this claim:\n* Table 6 shows that the SSQ-Triple model, which achieves the lowest reconstruction rFID (best \"Gain\"), still results in a worse generation FID (3.31) than the SSQ-Dual model (3.11). \n* The gap persists even after applying all co-design strategies (Appendix A.3, L754-758). If the model with the best token representation still yields inferior generation results, the paper has only mitigated the pain, not resolved the fundamental tension. This incomplete resolution fundamentally weakens the central claim and contribution."}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "PeheVOfQnJ", "forum": "pBz9imKi56", "replyto": "pBz9imKi56", "signatures": ["ICLR.cc/2026/Conference/Submission3005/Reviewer_7BEo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3005/Reviewer_7BEo"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3005/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762022318299, "cdate": 1762022318299, "tmdate": 1762916491341, "mdate": 1762916491341, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}