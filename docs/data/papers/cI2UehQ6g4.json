{"id": "cI2UehQ6g4", "number": 18929, "cdate": 1758292076718, "mdate": 1759897072442, "content": {"title": "Growing Networks by Folding Manifolds at Mistakes", "abstract": "Modern deep learning paradigms heavily rely on over-parameterized models, leading to excessive costs and limited interpretability. While growing neural networks (GrowNNs) offer a biologically inspired alternative by incrementally expanding architectures, existing methods lack theoretical grounding and often result in unstable, heuristic-driven growth. This paper proposes a novel geometric framework that interprets neural network growth as folding the learned representation manifolds to enhance model capacity. We theoretically establish that strategically adding neurons—equivalent to introducing geometric folds—at locations corresponding to systematic prediction mistakes optimally increases expressivity. Our method introduces: (1) A manifold-based strategy for effective network growth by identifying ``typical mistakes'' via clustering of mis-predictions and targeted folding; (2) A stable fine-tuning solution using gradient-aligned initialization and folding hyperplane regularization to ensure targeted correction of mistakes; (3) Ante-hoc instance-level interpretability, where each grown neuron can be justified and explained by a specific mis-predicted data instance representing a model deficiency. Experiments on synthetic manifolds, MNIST, and CIFAR-10 demonstrate controlled capacity expansion, competitive parameter efficiency, and inherent explainability throughout the growth process.", "tldr": "", "keywords": ["Growing Neural Networks", "Explainable Deep Learning", "Representation Geometry", "Manifold Folding", "Ante-Hoc Interpretability", "Parameter Efficiency"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/31829eab9adb34fb49da837955f1f21212e37457.pdf", "supplementary_material": "/attachment/6779442d0c02e07998a6ad4dad1abbc7f038e8ed.zip"}, "replies": [{"content": {"summary": {"value": "Current Growing Neural Networks (GrowNNs) lack interpretability. The authors argue that the performance improvement observed in each growth step of GrowNNs arises from a process of geometrically folding a learned representation manifold. They further propose that the most effective growth occurs when the folding takes place in manifold regions associated with the model’s typical mistakes. The authors systematically apply this manifold-based perspective to the growth mechanism and strategy of GrowNNs, providing formal definitions and theoretical proofs. Finally, experiments conducted on the MNIST and CIFAR-10 datasets demonstrate the effectiveness of their proposed growth strategy."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper introduces the concept of a manifold and provides an innovative geometric interpretation of the GrowNNs growing process, effectively addressing the lack of ante-hoc interpretability in this field.\n  \n2. The authors propose a complete ante-hoc execution strategy for GrowNNs, covering the questions of when, where, and how to grow. Each component is formally defined and theoretically proven, lending strong credibility to the framework.\n  \n3. The paper is well organized and logically progressive. It first presents the manifold perspective (Theorem 1), then introduces the definitions and theorems of Learned Manifold, Folding, and Growing a Neuron (Definition 1–3, Theorem 2–3), and finally proposes the strategy of folding at typical mistake regions."}, "weaknesses": {"value": "1. The experimental section appears relatively limited compared to the theoretical part. For example:\n  \n    - The paper lacks comparisons with other growth strategies, making it difficult to determine whether performing growth at \"typical mistake\" regions is superior to alternative growth approaches.\n    \n    - Subsection 3.4 reads more like a theoretical explanation rather than empirical validation. Ablation studies would be valuable to clarify why the proposed method is effective. Specifically, the growth strategy involves carefully designed components for typical-mistake selection, loss and folding regularization, and initialization of new parameters, yet there are no ablation experiments to quantify the independent and combined contributions of these components to overall effectiveness.\n    \n2. The experiments and interpretability analyses focus only on the neuron growth process within an MLP, without extending the framework to other types of neurons such as convolutional neurons. Nevertheless, this paper remains a strong contribution to the GrowNNs field.\n  \n3. Most figures and tables are not explicitly referenced or discussed within the relevant text, which may make it difficult for readers to understand. In addition, several typos were found in Appendix B2.2."}, "questions": {"value": "1. In Figure 3, the changes in the decision boundary before and after growth are not clearly visible. Is this figure merely an illustration, rather than a visualization of actual experimental results?\n  \n2. According to Table 1, when comparing networks with the same number of neurons, the performance improvement of the grown network over the initialized network appears limited. However, Figure 2 shows that before the network grows to 50 neurons, its performance already surpasses that of a statically initialized 50-neuron model. Does this imply that under this growth strategy, better performance can be achieved with fewer neurons? A more detailed presentation of such phenomena, as in Figure 2, might be what readers would most expect to see."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VSLnnG7v3B", "forum": "cI2UehQ6g4", "replyto": "cI2UehQ6g4", "signatures": ["ICLR.cc/2026/Conference/Submission18929/Reviewer_Njy8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18929/Reviewer_Njy8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18929/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761640726286, "cdate": 1761640726286, "tmdate": 1762930917294, "mdate": 1762930917294, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new method for growing single-layer ReLU networks: It interprets adding a neuron as a \"folding\" of the decision boundary, and then aims to introduce these folds close to points that are misclassified by the network (adding capacity exactly where needed). The resulting algorithm performs well compared to a static (non-growing) network."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* Novel approach to growing\n* The resulting algorithm has nice interpretability results: Each growth operation can be directly linked to a cluster of misclassified examples and a single representative example of this cluster whose misclassification this new neuron aims to address."}, "weaknesses": {"value": "* Experiments do not compare against other growing methods (GradMax, Firefly, random growth, etc.)\n* Theory and algorithm only apply to single-layer ReLU networks. No trivial extension to other more complex (real-world) networks such as multi-layer MLPs, convolutions, etc. This is worrisome because in the deep network case it becomes non-trivial to find examples that lie closest to the decision boundary.\n* Scaling issues: Each growth operation requires embedding the full training set, clustering a large dataset (of potentially high-dimensional points, depending on the input space--this also assumes that the input space is amenable to clustering) and then solving the complicated problem of finding the closest point to the decision boundary."}, "questions": {"value": "Do the authors have a path in mind towards adapting this method to actual real-world applications: multi-layer networks/CNNs/RNNs/etc., activation functions other than ReLUs, high-dimensional inputs, etc. And do you have any intuition as to whether this would actually be practical?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9rMbqpy3y2", "forum": "cI2UehQ6g4", "replyto": "cI2UehQ6g4", "signatures": ["ICLR.cc/2026/Conference/Submission18929/Reviewer_6oUo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18929/Reviewer_6oUo"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18929/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761929088581, "cdate": 1761929088581, "tmdate": 1762930916605, "mdate": 1762930916605, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes a framework for training GrowNNs, neural networks that increase their representational capacity by adding neural progressively. This is in contrast to existing approaches that make networks as large as possible, then potentially prune them. The proposed approach works by identifying points that are mispredicted, then \"folding\" the learned manifold nearest to these points by adding a new neuron, then fine-tuning the new parameters."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea of progressively growing networks, though not novel, is important for building efficient models.\n2. The algorithm is rigorously defined and supported by theory.\n3. Though not emphasized in the text, the potential savings in terms of parameters in Figure 2 is significant."}, "weaknesses": {"value": "1. Limited evaluation focused on toy models and datasets.\n2. Missing comparisons to other \"grow\" frameworks."}, "questions": {"value": "Q1: How do you compare in terms of final performance and size of network to other GrowNN frameworks (e.g. GradMax or [1])?\n\nQ2: The approach detailed (especially in the 2-layer MLP case) seems related to prior work on spine theory for NNs [2]. Could you comment on the connection, and potentially cite if it is relevant?\n\nMinor comments:\n- Theorem 1: definition of Y is missing\n- Line 197: typo \"constrain\" --> \"constraint\"\n- Definition 4: should it be x_{mistake} \\not \\in M ?\n- Figure 1 is never cited in the text\n\n[1] : https://proceedings.neurips.cc/paper/2020/hash/fdbe012e2e11314b96402b32c0df26b7-Abstract.html\n[2] : https://www.arxiv.org/abs/1910.02333v1"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "r1284tw8PC", "forum": "cI2UehQ6g4", "replyto": "cI2UehQ6g4", "signatures": ["ICLR.cc/2026/Conference/Submission18929/Reviewer_5VtH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18929/Reviewer_5VtH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18929/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761946371654, "cdate": 1761946371654, "tmdate": 1762930916033, "mdate": 1762930916033, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}