{"id": "t1HJAbv7Bs", "number": 12788, "cdate": 1758210311788, "mdate": 1763587114763, "content": {"title": "Exploring Nonlinear Pathway in Parameter Space for Machine Unlearning", "abstract": "Machine Unlearning (MU) aims to remove the information of specific training data from a trained model, ensuring compliance with privacy regulations and user requests. While one line of existing MU methods relies on linear parameter updates via task arithmetic, they suffer from weight entanglement. In this work, we propose a novel MU framework called Mode Connectivity Unlearning (MCU) that leverages mode connectivity to find an unlearning pathway in a nonlinear manner. To further enhance performance and efficiency, we introduce a parameter mask strategy that not only improves unlearning effectiveness but also reduces computational overhead. Moreover, we propose an adaptive adjustment strategy for our unlearning penalty coefficient to adaptively balance forgetting quality and predictive performance during training, eliminating the need for empirical hyperparameter tuning. Unlike traditional MU methods that identify only a single unlearning model, MCU uncovers a spectrum of unlearning models along the pathway. Overall, MCU serves as a plug-and-play framework that seamlessly integrates with any existing MU methods, consistently improving unlearning efficacy. Extensive experiments on the image classification task demonstrate that MCU achieves superior performance. The codes are available at https://anonymous.4open.science/r/MCU-1E36.", "tldr": "", "keywords": ["Machine Unlearning", "Mode Connectivity", "Model Forgetting"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c9ece11279c3d82946d41faedcc198005b029378.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes an unlearning refinement algorithm that leverages mode connectivity between a pre-unlearned model and the original model to achieve a better balance between the forget and retain datasets. The method needs training a control model that satisfies a Bézier curve constraint, enabling smooth interpolation between model parameters to guide the unlearning process. Additionally, the authors introduce a simple masking heuristic to reduce the search space of the control model, improving efficiency. Experimental results on benchmark datasets and models demonstrate that the proposed approach produces unlearned models whose behavior closely matches that of models retrained from scratch."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is fairly well written with detailed description of the proposed method and necessary background literature\n2. The proposed method is quite novel and interesting, while its design lack evidence to support. Speaking about the mode connectivity, why is it important in the proposed approach? can we simply train a scalar as ratio to interpolate original model and unlearned model?\n3. Experiments seems quite comprehensive where the control flexibility of the proposed method is well demonstrated."}, "weaknesses": {"value": "1. The proposed method rely on a pre-unlearned model (or could be a retrained model). But if one has already have the unlearned model, why would they need the proposed approach. What if the pre-unlearned model is not good? The paper should provide more evidence to show how sensitive the proposed method conditioned on the selection of pre-unlearned model. Indeed, in practice, existing unlearning algorithms often struggle on producing consistent unlearning quality.\n2. While the introduction of mode connectivity is an interesting idea, the paper does not clearly justify why this framework is necessary. It appears that similar interpolation behavior could be achieved through a simpler linear combination, e.g., \n$$\\alpha \\times \\theta_{o} + (1-\\alpha)\\times \\theta_{p}$$ where $\\alpha$ is a learnable scalar. The added complexity of training a control model along a Bézier curve requires stronger motivation or empirical evidence to demonstrate clear advantages. Without such justification, the connection to mode connectivity feels more like an interpretive framing than a necessary component of the method."}, "questions": {"value": "My questions are included in the above comments."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ihvqSBlAMj", "forum": "t1HJAbv7Bs", "replyto": "t1HJAbv7Bs", "signatures": ["ICLR.cc/2026/Conference/Submission12788/Reviewer_VMwa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12788/Reviewer_VMwa"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12788/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761872225224, "cdate": 1761872225224, "tmdate": 1762923597631, "mdate": 1762923597631, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MU framework based on the model connectivity to find the unlearning pathway. The idea is from exploiting the arithmetic negation to linearly subtract the parameters of the task vectors corresponding to the forgetting data. The paper mentioned that the linear task arithmetic suffers from weight entanglement and the. so the authors investigated the idea of mode connectivity to obtain the unlearned parameters by constructing a pathway from the original model to pre unlearned model using the quadratic Bezier curve."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is well written. The idea is clearly stated and the background on the topic is well discussed. \nThe motivation of the paper based on the weight entanglement is comprehensively discussed in the appendix. \nThe paper has a comprehensive experimental evaluation."}, "weaknesses": {"value": "The reliance of method on the on a pre-unlearned (specially using the unlearning approximation methods for obtaining the ) model would bound the performance of the model. For example, the GradAscent is notorious for showing high variance and causing damage to the model's parameters, this can cause the pre-defined model to be underperforming and model's utility to be severed damaged. \n\nAlso the choice of Accuracy for adjusting the coefficient of unlearning may not be reliable. For example, in the cases that model's prediction confidence on samples of the forget set very drops significantly and the predictive confidence looks similar to the uniform, but the prediction of the model on the original class remains slightly higher other than the rest of classes. Therefore the accuracy on the forget set remains 100%. This is just an example that the accuracy may not be reliable metric for finding the best coefficient."}, "questions": {"value": "line 146 // Inspired by... :\n\nI encourage authors to provide the motivation on choosing the quadratic Berizer Curve for exploiting the non-linear pathway between the original model and the pre-unlearned model. They said that the work is inspired with the Garipov work but the motivation for choosing this method is unclear.\n\nLine 155 // it represents: \n\nWhy we would be interested in a spectrum of potential unlearning models? what would be the advantage over a single unlearned model that performs well?\n\nline 231 // we preliminary.. :\n\nsince masking reduces the number of parameters it was expected to reduce the time complexity of backprop, but the issue that arises is why those parameters that are more sensitive to the forget data are those ones that should be considered more influential in the prediction of the model for the forget set? How you can be sure that your heuristic for the back-propagated gradient is the best one to choose the most effective weights for the prediction of forget and retain set?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "eJccXmJ0WL", "forum": "t1HJAbv7Bs", "replyto": "t1HJAbv7Bs", "signatures": ["ICLR.cc/2026/Conference/Submission12788/Reviewer_6eer"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12788/Reviewer_6eer"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12788/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968197507, "cdate": 1761968197507, "tmdate": 1762923597332, "mdate": 1762923597332, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The goal of machine unlearning is to remove a subset of data from a pretrained model, while preserving performance on the remaining data. This paper proposes Mode Connectivity Unlearning (MCU), a plug-and-play framework designed to address the weight entanglement problem in existing linear unlearning approaches. This method aims to find a nonlinear pathway between the original and the pre-unlearning model using mode connectivity. The authors introduce a masking strategy to improve efficiency and performance, and further propose an adaptive mechanism for hyperparameter tuning. Experiments on image classification tasks shows improvement over multiple baselines with the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The paper is written clearly and is well-structured. The authors propose a novel method to explore nonlinearity and mode connectivity in machine unlearning, which remains unexplored in the literature. \n* The experimental and ablation sections are extensive, including multiple datasets, architectures, and unlearning baselines. The addition of MCU consistently improves performance across different settings."}, "weaknesses": {"value": "* One of the paper’s main motivations is to “identify a spectrum of effective MU models”. It is mentioned that the priorities could change over time, such as samples becoming higher-risk over time. However, the paper does not present a practical use case where this ability would be useful.\n* Based on the RTE metric, MCU causes some runtime overhead compared to some of the baseline models, which is a trade-off with performance improvement. \n* All experiments are done on image classification, so it is unclear how MCU would perform on other modalities such as language models.\n\nMinor issues: The tables can be difficult to interpret. It would help to use arrows to represent which metric should ideally be higher or lower."}, "questions": {"value": "Can this method be extended to other domains such as language models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "bQVA1weX6B", "forum": "t1HJAbv7Bs", "replyto": "t1HJAbv7Bs", "signatures": ["ICLR.cc/2026/Conference/Submission12788/Reviewer_VviV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12788/Reviewer_VviV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12788/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761985184280, "cdate": 1761985184280, "tmdate": 1762923596799, "mdate": 1762923596799, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Mode Connectivity Unlearning (MCU), a plug-and-play framework that searches a nonlinear Bezier path in parameter space between the original model and a pre-unlearning model. By optimizing only a single control model, MCU yields a continuum of candidate models along the path, enabling selection to balance forgetting and utility. The method adds (i) a parameter-masking strategy at the tensor level to improve speed/targeting and (ii) an adaptive penalty \\beta that adjusts forgetting pressure batch-wise based on calibration targets for retaining/forgetting sets. On image-classification tasks (CIFAR-10, Tiny-ImageNet, ImageNet-100; ResNet/ViT/VGG), MCU and MCU-\\beta outperform several baselines (Retrain, Finetune, Random Label, Gradient Ascent, NegGrad+, SFRon, SalUn, NegTV) on aggregate gaps to a retrain reference, and expose an \"effective region\" of strong candidates along the curve"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Conceptual novelty: Moving beyond linear \"task arithmetic\", the paper makes a clear case that nonlinear pathways can mitigate weight entanglement and provide a spectrum of solutions rather than a single point. \n\n2. Simple optimization: Optimizing only is elegant and makes path search computationally tractable; sampling, t~U(0,1) keeps the procedure lightweight. \n\n3. Plug-and-play with baselines: MCU wraps around strong/weak pre-unlearning models (e.g., RL, GA, NegGrad+) and consistently improves them, including both under- and over-forgetting regimes. \n\n4. Parameter-masking at tensor level: The two-stage mask (retain-filter + forget-reserve) is pragmatic; authors show ~75% epoch-time speedup at 10% mask in a CIFAR-10 setting while preserving accuracy better than a random mask. \n\n5. Effective-region selection: Empirical evidence that many points on the path outperform provides practical flexibility for utility vs. forgetting trade-offs"}, "weaknesses": {"value": "1. Assumption on endpoints: MCU’s success critically depends on the quality of is poorly chosen or adversarially brittle, the curve might inherit those flaws; the paper does not explore how to construct/validate robust endpoints beyond standard baselines. \n\n2. Forgetting metric and objectives: The work largely operationalizes \"unlearning\" via accuracy on D_f (UA) and \"gap to retrain\" plus an MIA score alignment to RT. This is not a guarantee of removal nor robust to adaptive attacks; the paper does not evaluate certified removal or causality-based tests (e.g., data influence measures) beyond Fisher-style references. \n\n3. Security/privacy framing: The argument that matching RT on MIA is desirable is plausible, but insufficient - one can match RT on summary privacy metrics yet still memorize or leak shards of D_f. No evaluation with stronger attacks (e.g., calibrated confidence extraction, influence-function-guided MIAs) is shown. \n\n4. Theory clarity: Theorem 1 (impossibility of a single model to optimally unlearn all points, requiring an astronomical number of models) is informal in the main text; assumptions, randomness model, and notion of \"optimal unlearning\" are not crisply stated. The result risks over-claiming without clear operational meaning for practitioners. \n\n5. Scalability scope: Experiments cover vision classification with moderate-scale models/datasets. There is no evidence for LLMs, multimodal systems, or class-imbalanced/continual scenarios where path geometry may differ. \n\n6. Heuristic choices:\n\n6.1 Adaptive \\beta relies on piecewise thresholds and calibration targets (e.g., Cal(D_f) = 0 for class-wise forgetting). This is reasonable but ad hoc; stability under noise/domain shift is unclear.\n\n6.2 t-sampling is uniform; curvature-aware or loss-aware sampling might be more efficient, yet not explored. \n\n7. Runtime trade-offs: Although the mask speeds epochs, total RTE is sometimes higher than simple baselines due to path training/inference sweeps; a wall-clock cost-benefit analysis (vs. a well-tuned single-point method) is not fully quantified.\n\n8. Cost and practical overheads:\n\n8.1 Extra training phase (control-point optimization). MCU adds a dedicated optimization of the control weights on top of whatever pre-unlearning you already did to obtain. Even with masking, this is a non-trivial number of epochs and can rival or exceed a well-tuned single-point unlearning run.\n\n8.2 Quadratic Bezier path requires more curvature and cost to fit. A quadratic curve (vs. a linear interpolation) can better navigate loss valleys, but it also increases the burden on optimization to “shape” the curve so that many sampled points behave well. You often need more path samples (larger K) during training/validation to ensure the curve is genuinely useful across t \\in [0, 1].\n\n8.3 Path-sweep selection cost.\nIn practice, you don’t deploy the whole curve - you sweep multiple t values to pick an operating point that balances forgetting and utility. That means repeated evaluation on retain/forget/RT sets (and sometimes MIA audits), which adds wall-clock time and evaluation compute. If you re-select t per deployment/domain shift, you pay this cost repeatedly.\n\n8.4 Memory and checkpoint management.\n\nIf you cache candidates along the path, you either store multiple checkpoints or re-materialize them on the fly. The former consumes storage; the latter adds latency and requires synchronized versioning of \\theta_o, \\theta_p, \\theta_c.\n\n8.5 Masked training is not free\n\nTensor-level masking reduces per-step FLOPs, but it introduces implementation complexity, potential instability (mask schedule, layer sensitivity), and can require careful tuning to avoid accuracy collapse—especially on larger/backbone-heavy models.\n\n8.6 Sensitivity to endpoint quality.\n\nPoor \\theta_p forces the curve to \"work harder\", often increasing both epochs and samples K needed to find a satisfactory region. That compounds overall cost and can narrow the effective region, reducing the payoff from the path.\n\n8.7 Comparative value vs. strong single-point baselines.\n\nA well-engineered single-point method (e.g., with regularization, early stopping, and privacy-attack tuning) can be much cheaper end-to-end. MCU must clear that cost bar after adding control-point training and t-sweep selection to justify its complexity.\n\n9. Missing reference.\n\nA closely related work is not mentioned. The paper should compare to this work (https://arxiv.org/abs/2504.06407):\n\nUnderstanding Machine Unlearning Through the Lens of Mode Connectivity, Cheng and Amiri, 2025"}, "questions": {"value": "1. Endpoint construction & robustness: How sensitive are outcomes to the choice of \\theta_p? Have you tried multiple pre-unlearning procedures per dataset and measured variance in the effective region’s width/position? \n\n2. Adversarial privacy tests: Can you evaluate MCU against adaptive MIAs, extraction attacks, and counterfactual tests that condition on access to \\theta_o, \\theta_p and points along the path? How does the effective region hold up? \n\n3. Certified perspectives: Could MCU be combined with certified removal (e.g., DP-based or audit-based certificates) to bound residual influence of D_f along the curve? \n\n4. Path geometry & sampling: Why uniform t? Would loss-aware sampling or Bezier-surface control (not just a single control point) improve efficiency or robustness? Any negative results worth sharing? \n\n5. Generalization beyond vision: What breaks (or changes) when moving to text/LLMs (catastrophic interference, optimizer states, longer pretraining)? Any preliminary signs MCU scales? \n\n6. Masking granularity: Tensor-level masking is efficient; do you observe layer-type patterns (e.g., attention projections vs. MLPs) that systematically contribute to forgetting vs. retention? Could a structured mask (heads, channels) help? \n\n7. Selection at inference: The heuristic that the optimum lies in t \\in [0.75,1] is empirical. How often is it violated? Could a small active search over t with early stopping outperform cubic interpolation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jvGbPDFI3L", "forum": "t1HJAbv7Bs", "replyto": "t1HJAbv7Bs", "signatures": ["ICLR.cc/2026/Conference/Submission12788/Reviewer_me3w"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12788/Reviewer_me3w"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12788/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762185305337, "cdate": 1762185305337, "tmdate": 1762923595999, "mdate": 1762923595999, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}