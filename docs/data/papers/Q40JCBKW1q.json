{"id": "Q40JCBKW1q", "number": 25563, "cdate": 1758369103152, "mdate": 1759896715604, "content": {"title": "Curriculum-Based Termination Critic for Scalable Program Decomposition in Hierarchical Reinforcement Learning", "abstract": "We introduce a Curriculum-Based Termination Critic (CBTC) for hierarchical reinforcement learning (HRL) to solve the problem of program decomposition for scaleable programming in complex task environments. Traditional termination critics yet make some static heuristics on the other side that have difficulties to cope with different tasks in complexity and prevents the agent to learn right hierarchy abstractions effectively. The CBTC presents a dynamic curriculum-driven framework that selects the difficulty of the tasks on the fly and incrementally adjusts the difficulty according to the agent's learning progress, in order to make programs decomposition into manageable subtasks more efficient. Our strategy combines three components: a module of difficulty progression to autonomously adjust the complexity of the tasks, a termination critic based on reward to stabilize the decisions for the completion of the subtasks and an option-critic hybrid controller to orchestrate the switching strategy between decomposition methods. The termination critic makes use of a transformer-based framework to operate on program states and the curriculum descriptor, while the high-level policy utilizes graph neural networks to reason on abstract syntax trees. Experiments show that the CBTB performs better than traditional HRL techniques both in terms of success rate and time efficiency, especially in those cases where the programs contain many stages to be synthesized. The proposed approach is entirely differentiable and compatible with existing architectures for HRL and is a principled answer for scaling program decomposition in real-world applications.", "tldr": "", "keywords": ["Hierarchical Reinforcement Learning"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/54ae6daa233231f1215b7aed36aa928be86ecc13.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a curriculum learning-based approach to use reinforcement learning to learn to solve program decomposition tasks. The proposed method learns options to acquire skills by solving easier programs, and progressively learns how to solve more complex problems."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The proposed approach sounds reasonable in the high level, as it is possible to build a progressively more difficult set of tasks for program decompensition, and the domain seems to fit well a hierarquical RL modeling."}, "weaknesses": {"value": "- The paper is really unclear on exactly what and how the probem is being solved. There is no clear description of how the program decomposition problem is modeled as an MDP, as well as there is no description of how the SOTA approaches solve program decomposition. Furthermore, there is not even an algorithm of the proposed method, and while there are high level descriptions for the steps executed it's virtually impossible for the reader to figure out what the approach is doing step by step.\n\n- The baselines are all simple RL. algorithms that the authors claim are \"State of the Art\". I really doubt the state of the art approach for program decomposition at the moment uses RL, and I am absolutely sure that even if that's the case, the vanilla Option-Critic doesn't get close to be the hihgest performing approach. The authors have to re-execute the experimentation adding also the real SOTA methods even if those are non-RL based. The wall-clock time for solving the problem should also be added as an additional metric. The non-RL approaches won't have \"number of episodes\" to compare against, and also just the number of steps is very unclear by itself considering the different approaches might have very different update times."}, "questions": {"value": "Why were only RL-based approaches added to the experimental evaluation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "u9bSDyAtul", "forum": "Q40JCBKW1q", "replyto": "Q40JCBKW1q", "signatures": ["ICLR.cc/2026/Conference/Submission25563/Reviewer_e415"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25563/Reviewer_e415"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25563/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760763037090, "cdate": 1760763037090, "tmdate": 1762943476284, "mdate": 1762943476284, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Curriculum-Based Termination Critic (CBTC) to help Hierarchical Reinforcement Learning (HRL) agents automatically break down complex program decomposition tasks. Standard HRL methods often struggle to decide when a sub-task (part of the program decomposition) should end, especially as tasks get harder. CBTC uses a curriculum that automatically adjusts the task difficulty based on how well the agent is learning. It trains a special termination critic (or multiple critics) that learns when to end a sub-task, considering the current difficulty level. The goal is to make learning more efficient and scalable for complex program decomposition. Experiments suggest CBTC performs better than older HRL techniques on programming tasks."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. Applying the concept of curriculum learning specifically to the termination signal, and adapting it based on task difficulty or agent progress is a novel contribution.\n2. The research is explicitly motivated by the need to improve scalability for program decomposition tasks, a practically relevant direction within automated software engineering and AI. This is good."}, "weaknesses": {"value": "1. Unfortunately, the entire paper is not easy to follow, especially for those who are not familiar with the program decomposition and its connection to HRL. What is program decomposition problem? Do you have a running example? How it is connected to HRL, and why HRL is helpful in such a setting? What are the issues of not using HRL, and what are the problems of current HRL algorithms applied to program decomposition problems? I believe answers to some of these questions presents in the paper, but it is difficult for most reader to follow.\n2. Again, some of the concepts, definitions and equations are presented abruptly. I would suggest the background section should be revised throughly and carefully. Also, section 4.1 and 4.2 nearly prevents us readers from understanding your real contributions to this community. Readers who unfamiliar with program decomposition are unlikely to investigate the contributions under a sequences of equations.\n3. This is minor, line 255 formatting issue.\n4. Figure 3, name of other baselines.\n5. As mentioned in the paper, the current framework does not generalize to other program domains."}, "questions": {"value": "1. Can you please briefly describe each task environments with *examples*?  \n2. Can you please briefly describe some success and failed cases of program decomposition with *examples*?\n3. As mentioned in the paper, the current framework does not generalize to other program domains. Can you have more analysis on this, and propose some potential solutions or insights?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zbgqxryt3C", "forum": "Q40JCBKW1q", "replyto": "Q40JCBKW1q", "signatures": ["ICLR.cc/2026/Conference/Submission25563/Reviewer_HWuj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25563/Reviewer_HWuj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25563/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761472581021, "cdate": 1761472581021, "tmdate": 1762943475965, "mdate": 1762943475965, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a Curriculum-Based Termination Critic for improving program decomposition in hierarchical reinforcement learning. It combines three components: (i) a difficulty progression module that adaptively adjusts task complexity, (ii) a transformer-based termination critic that uses curriculum descriptors and program states to decide when to end subtasks, and (iii) a graph neural network based high-level policy that reasons over abstract syntax trees to guide option selection. The method is evaluated on three synthetic program decomposition benchmarks and compared against four HRL baselines, showing improvements in success rate and decomposition quality, especially in complex tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. CBTC consistently outperforms presented HRL baselines by large margins with fewer training steps;\n2. A detailed ablation shows that both the curriculum progression mechanism and the termination critic are critical, with respective drops of 22.7% and 18.3% in success rate when removed."}, "weaknesses": {"value": "1. Curriculum adaptation via performance thresholds and exponential moving averages is a standard heuristic;\n2. Metrics rely on AST similarity to a single “expert” decomposition; this may penalize semantically equivalent but structurally different solutions—no human study or functional-correctness tests (unit tests, program equivalence) are reported."}, "questions": {"value": "1. How would CBTC perform against very recent code-generation models (e.g., CodeT5+, CodeLlama) fine-tuned for decomposition, or against HRL agents that use pretrained code LMs?\n2. Does CBTC degrade when scaling to real-world projects?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "xJ73pXUgyn", "forum": "Q40JCBKW1q", "replyto": "Q40JCBKW1q", "signatures": ["ICLR.cc/2026/Conference/Submission25563/Reviewer_7B1L"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25563/Reviewer_7B1L"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25563/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761547403767, "cdate": 1761547403767, "tmdate": 1762943475509, "mdate": 1762943475509, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents curriculum-learning approach in a hierarchical reinforcement learning framework, applied to the domain of program decomposition. The proposed method features (a) a dynamic curriculum-progression module (b) a transformer-based termination critic and (c) GNN-based high-level (option) controller. The method is evaluated on three program decomposition benchmarks, showing better performance than existing baselines."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The idea of learning a termination critic, to decide when to stop an active policy should stop, is interesting."}, "weaknesses": {"value": "- Missing symbol definitions. The paper uses symbols such as $Q_\\omega$ or $\\pi$, which are never formally defined.  \n- The paper lacks a formal problem (and background) section, leaving the core methodology and mathematical symbols very opaque. For example, Section 3.2 reasons about \"tasks $\\{M_1, M_2, \\dots\\}$\". I assume these are supposed to be MDPs, but due to the lack of a formal background section, this remains unclear.  \n- Even at first glance, the paper is ridden with typos and formatting issues, and is written in an extremely colloquial style. Figures are not properly referenced via LaTeX; instead, the references appear to have been typed out by hand and are off by one (starting at 2 instead of 1). Thus, the textual descriptions do not match the referenced images.  \n- The core method remains unclear. No pseudocode for the algorithm is presented, and no losses or optimization targets are specified.  \n- The authors do not share (or promise to share) code for reproducing the experiments. This, together with the aforementioned lack of clarity, makes reproducing the paper very difficult.  \n- The single sentence presented as a conclusion falls short of what should be conveyed in a concluding statement of a scientific paper."}, "questions": {"value": "X"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YYuWlZT62N", "forum": "Q40JCBKW1q", "replyto": "Q40JCBKW1q", "signatures": ["ICLR.cc/2026/Conference/Submission25563/Reviewer_TBPh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25563/Reviewer_TBPh"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25563/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761553017393, "cdate": 1761553017393, "tmdate": 1762943475226, "mdate": 1762943475226, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a curriculum learning approach for program decomposition in hierarchical RL. The proposed method, CBTC, adaptively adjusts task difficulty based on an agent's learning progress through three components: a difficulty progression module, a reward-shaped termination critic, and an option-critic controller. Experiments on program decomposition benchmarks demonstrate that CBTC can achieve higher success rates and faster convergence than some HRL baselines."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well-structured and has a detailed related work on HRL and program decomposition.\n- The proposed way of integrating curriculum learning for hierarchical program decomposition is technically sound.\n- Experiments cover various program decomposition benchmarks and compare the proposed approach against some HRL benchmarks."}, "weaknesses": {"value": "- The use of notation is messy, e.g., \\mathcal{T} appears out of nowhere. There are formatting errors, e.g., line 255.\n- The discussion about related works on curriculum learning does not cover any recent works at all.\n- The proposed approach relies on heuristic difficulty metrics that may be difficult to generalize to other domains.\n- The figures in the experimental results do not show the variance of reported metrics across independent runs.\n- The studied benchmarks seem synthetic and small, even though the title of the paper claims scalability."}, "questions": {"value": "- Did you run your experiments using various seeds? If so, what's the variance on reported results?\n- What kind of privileged information is needed to form the curriculum stages before training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nOwWGJ74kS", "forum": "Q40JCBKW1q", "replyto": "Q40JCBKW1q", "signatures": ["ICLR.cc/2026/Conference/Submission25563/Reviewer_LPVL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25563/Reviewer_LPVL"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission25563/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761957202160, "cdate": 1761957202160, "tmdate": 1762943474414, "mdate": 1762943474414, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}