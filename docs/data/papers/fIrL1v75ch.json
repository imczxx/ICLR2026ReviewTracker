{"id": "fIrL1v75ch", "number": 2104, "cdate": 1756989212855, "mdate": 1759898169253, "content": {"title": "ExGS: Extreme 3D Gaussian Compression with Diffusion Priors", "abstract": "Neural scene representations, such as 3D Gaussian Splatting (3DGS), have enabled high-quality neural rendering; however, their large storage and transmission costs hinder deployment in resource-constrained environments. Existing compression methods either rely on costly optimization, which is slow and scene-specific, or adopt training-free pruning and quantization, which degrade rendering quality under high compression ratios.\nIn contrast, recent data-driven approaches provide a promising direction to overcome this trade-off, enabling efficient compression while preserving high rendering quality.\nWe introduce \\textbf{ExGS}, a novel feed-forward framework that unifies \\textbf{Universal Gaussian Compression} (UGC) with \\textbf{GaussPainter} for \\textbf{Ex}treme 3D\\textbf{GS} compression. \\textbf{UGC} performs re-optimization-free pruning to aggressively reduce Gaussian primitives while retaining only essential information, whereas \\textbf{GaussPainter} leverages powerful diffusion priors with mask-guided refinement to restore high-quality renderings from heavily pruned Gaussian scenes.\nUnlike conventional inpainting, GaussPainter not only fills in missing regions but also enhances visible pixels, yielding substantial improvements in degraded renderings. To ensure practicality, it adopts a lightweight VAE and a one-step diffusion design, enabling real-time restoration.\nOur framework can even achieve over $100\\times$ compression (reducing a typical 354.77 MB model to about 3.31 MB) while preserving fidelity and significantly improving image quality under challenging conditions. These results highlight the central role of diffusion priors in bridging the gap between extreme compression and high-quality neural rendering.", "tldr": "", "keywords": ["Neural rendering", "3D Gaussian Splatting", "Compression", "Diffusion models"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5b4b8c5b0cd4c16d890b7e7ce15b893dee8da9ff.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents a framework for compressing 3DGS using a voxel-based pruning strategy combined with a diffusion model to guide reconstruction. Empirical results demonstrate that ExGS achieves high compression ratios with minimal loss of rendering quality, outperforming existing baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper introduces an effective framework that combines voxel-based pruning with diffusion-based priors for 3DGS compression.\n2. It demonstrates superior performance over existing baselines on both indoor and outdoor scenes."}, "weaknesses": {"value": "1. The Global Significance Score in Eq. 7 requires computing the intersection between camera rays and Gaussian primitives. Does this mean that the input images or at least their camera parameters are needed for 3DGS compression? If so, this limit the method’s applicability. Additionally, the computation seems to involve all pixels and all primitives, raising concerns about efficiency. The exact formulation of the intersection between a Gaussian distribution and a ray is also unclear.\n\n2. The use of high-order omission and FP16 precision appears to significantly aid compression. An ablation study is needed to quantify the contribution of these techniques relative to the GS score and voxel-based pruning.\n\n3. The paper claims improved efficiency, so a test-time experiment evaluating the compression process itself (not just the diffusion-based reconstruction) is necessary to substantiate this claim.\n\n4. Quantitative comparisons with the optimization-based compression methods discussed in the introduction should also be provided."}, "questions": {"value": "The neural predictor in Eq. 10 is not clearly defined. Does it require additional training, and if so, how is it trained?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Wq83yOmHDZ", "forum": "fIrL1v75ch", "replyto": "fIrL1v75ch", "signatures": ["ICLR.cc/2026/Conference/Submission2104/Reviewer_WcrA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2104/Reviewer_WcrA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2104/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760510029683, "cdate": 1760510029683, "tmdate": 1762916030086, "mdate": 1762916030086, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "ExGS introduces a feed-forward 3D Gaussian Splatting compression pipeline that combines a training-free Universal Gaussian Compression (UGC) stage with a diffusion-prior restorer, GaussPainter. UGC prunes and compacts Gaussian primitives using global significance scoring and voxel-aware selection (with lightweight amplification and SH simplification). GaussPainter then performs mask-guided, one-step diffusion in a VAE latent space—using latent supervision—to both complete missing content and refine preserved regions.\n\nMain contributions：\nUGC (training-free) compression: Global significance scoring + voxel-aware selection with adaptive amplification; simplifies appearance (e.g., SH) and packs parameters for compact storage.\nGaussPainter (efficient generative restoration): Mask guidance from 3DGS opacity and latent supervision enable one-step diffusion that jointly inpaints and enhances results.\nValidated pipeline design: Ablations show each component’s effect and the combined benefits of UGC + GaussPainter across diverse scenes."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "### Originality\n* Frames 3DGS compression as a hybrid “compress + generative restore” paradigm; the UGC (training-free) + GaussPainter (diffusion prior) pairing is novel.\n* Uses opacity-guided one-step diffusion with latent-space supervision to curb hallucinations while keeping decoding efficient.\n* Voxel-aware significance scoring with adaptive amplification preserves structure under aggressive pruning.\n### Quality\n* Clear modular pipeline; ablations disentangle contributions of UGC, mask guidance, and latent supervision.\n### Clarity\n* Straightforward narrative with effective figures; two-stage roles and I/O are easy to follow.\n* Clearly separates geometry/opacity from appearance, defining where the generative prior should and shouldn’t act.\n### Significance\n* Direct practical value for 3DGS storage/streaming: smaller footprint with fast decode.\n* Provides a general recipe—“compact representation + learned restoration”—that can transfer to other scene formats (including 4D).\n* Offers a more controllable quality–compression trade-off, maintaining usable quality even at extreme compression."}, "weaknesses": {"value": "Missing information. Please clarify the training data sources and splits for UGC and GaussPainter (did each dataset participate in training? train/val/test splits? combined training?), and whether TAESD / the diffusion backbone were pretrained on generic image corpora and then fine-tuned for this task, including the fine-tuning ratio and freezing strategy.\n\nGeneralization validations needed:\nOut-of-Domain (OOD) evaluation: Choose sampling protocols/scenes absent from training (e.g., Tanks&Temples, LLFF, KITTI-360, or self-captured data). Report PSNR/SSIM/LPIPS and show failure cases.\n\nOne-line summary: As of now, the paper has not demonstrated generalization under train–test isolation across datasets; we recommend adding LODO/OOD and distribution-shift evaluations to upgrade empirical stability into reproducible evidence of generalization."}, "questions": {"value": "Question:\nCan you add Leave-One-Dataset-Out (LODO) results—train on A+B and evaluate zero-shot on C—and Out-of-Domain (OOD) results on datasets not seen during training (e.g., Tanks&Temples, LLFF, KITTI-360, or self-captured scenes)?\n\nWhy it matters (Importance):\nThis directly tests cross-domain robustness and guards against overfitting to the evaluation domains.\n\nExpected evidence:\nPSNR/SSIM/LPIPS curves across compression levels or pruning strengths.\nA gallery of failure cases with brief diagnostics.\nQualitative comparisons under extreme sampling/texture/geometry shifts to illustrate robustness (or lack thereof)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dmAtaf6tEx", "forum": "fIrL1v75ch", "replyto": "fIrL1v75ch", "signatures": ["ICLR.cc/2026/Conference/Submission2104/Reviewer_YHsN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2104/Reviewer_YHsN"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2104/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761816411243, "cdate": 1761816411243, "tmdate": 1762916029435, "mdate": 1762916029435, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ExGS, a novel framework for extreme compression of 3D Gaussian Splatting by combining a pruning-based compression module (UGC) with a diffusion-based refinement module (GaussPainter). The method achieves compression ratios exceeding 100× while maintaining high rendering quality. Unlike prior optimization-based or training-free compression methods, ExGS leverages generative diffusion priors to restore and enhance heavily pruned scenes, enabling robust performance across indoor and outdoor benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Novel Integration of Compression and Generative Modeling: The combination of UGC for aggressive pruning and GaussPainter for diffusion-based restoration is innovative and effectively bridges the gap between extreme compression and high-quality rendering.\n\n2. Impressive Compression Ratios: The method achieves impressive compression levels while preserving visual fidelity.\n\n3. Comprehensive Evaluation: The paper provides thorough experiments across multiple datasets, compression ratios, and metrics, including ablation studies that validate the contribution of each component."}, "weaknesses": {"value": "1. While the diffusion-based refinement module significantly improves rendering quality, this process substantially increases rendering complexity compared to the original Gaussian Splatting overhead, limiting its applicability in real-world scenarios.\n\n2. The experimental data still needs to be supplemented. For example, the main experimental results and ablation studies (especially Table 4(a)) should ideally include rate-distortion curves. Additionally, as a feed-forward method, the paper lacks discussion on encoding speed and decoding speed."}, "questions": {"value": "1. How does the UGC module perform compared to other models, particularly feed-forward models (such as FCGS)? A related question is: what would be the effect of applying the GaussPainter to other compression models?\n\n2. What datasets were used during training?\n\n3. The results of LightGS on Mip-NeRF360 are significantly lower than those reported in the original paper. What differences exist in the experimental setup?\n\n4. How large is the neural predictor in Section Adaptive Amplification?\n\nIf these issues are addressed, will consider increasing the score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "u0XAlsRx9E", "forum": "fIrL1v75ch", "replyto": "fIrL1v75ch", "signatures": ["ICLR.cc/2026/Conference/Submission2104/Reviewer_cbmy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2104/Reviewer_cbmy"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2104/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761897934680, "cdate": 1761897934680, "tmdate": 1762916028626, "mdate": 1762916028626, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}