{"id": "3vIe5pNiUN", "number": 2367, "cdate": 1757064827451, "mdate": 1763748854989, "content": {"title": "Joint Distribution–Informed Shapley Values for Sparse Counterfactual Explanations", "abstract": "Counterfactual explanations (CE) aim to reveal how small input changes flip a model’s prediction, yet many methods modify more features than necessary, reducing clarity and actionability. We introduce COLA, a model- and generator-agnostic post-hoc framework that refines any given CE by computing a coupling via optimal transport (OT) between factual and counterfactual sets and using it to drive a Shapley-based attribution p-SHAP that selects a minimal set of edits while preserving the target effect. Theoretically, OT minimizes an upper bound on the $W_1$ divergence between factual and counterfactual outcomes and that, under mild conditions, refined counterfactuals are guaranteed not to move farther from the factuals than the originals. Empirically, across four datasets, twelve models, and five CE generators, COLA achieves the same target effects with only 26–45% of the original feature edits. On a small-scale benchmark, COLA shows near-optimality.", "tldr": "", "keywords": ["Counterfactual Explanations", "Shapley Values", "Optimization", "Explainable Machine Learning"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3a0f551f45f87f62aba67b9a65a8d61229bc70ba.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces COLA (COunterfactuals with Limited Actions), a post-hoc framework that refines existing counterfactual explanations to use fewer feature modifications while maintaining the desired outcome. The key innovation is p-SHAP, a generalized Shapley value method that uses optimal transport (OT) to compute a coupling between factual and counterfactual instances, then leverages this coupling to identify which features are most critical to modify. Existing counterfactual explanation methods often modify more features than necessary to flip a model's prediction."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper provides a rigorous theoretical foundation for its approach with three well-formulated theorems. Theorem 4.1 establishes an important connection between optimal transport and counterfactual effect, proving that the OT-derived coupling minimizes an upper bound on the W₁ divergence between model outputs. This provides principled justification for why OT is the right tool for aligning factual and counterfactual instances. Theorem 4.2 demonstrates that p-SHAP captures genuine interventional effects, showing that the value function represents the causal impact of intervening on feature subsets. Theorem 5.1 offers proximity guarantees, proving that under certain conditions, the refined counterfactuals stay at least as close to the factuals as the original counterfactuals. These theoretical contributions are properly formalized with complete proofs in the appendices, demonstrating mathematical rigor and providing confidence in the method's foundations beyond purely empirical validation."}, "weaknesses": {"value": "Weaknesses:\n\nTheory-practice gap: The main theoretical results assume Lipschitz continuity (Theorem 4.1) and deterministic OT matching with n=m (Theorem 5.1). These conditions are restrictive and don't hold generally. The paper doesn't adequately discuss when these assumptions are violated in practice.\nNP-hardness result (Theorem B.1) undermines the approach: If the problem is NP-hard even for d=1 linear models, why should we expect good approximations from the proposed heuristic? No approximation guarantees are provided.\nLimited theoretical justification for OT choice: While Theorem 4.1 shows OT minimizes an upper bound, it doesn't prove this leads to optimal feature selection for the discrete action problem in Eq. 1.\nExperimental methodology concerns:\n- Standard deviations in Table 3 are very small (±0.02-0.09), suggesting possibly limited diversity in runs\n- The \"near-optimal\" claim in Result III is based only on German Credit dataset - too limited to generalize\n- Figure 4 shows significant gaps between CF-pOT/CF-pEct and optimal, contradicting \"near-optimal\" claims"}, "questions": {"value": "The paper's theoretical contributions rest on restrictive assumptions that may not hold in practice. Theorem 4.1 requires Lipschitz continuity of the model f, yet many of the 12 tested models (particularly DNNs with ReLU activations) are not globally Lipschitz continuous. The authors do not verify which models satisfy this assumption or report how tight the theoretical bound is empirically. Theorem 5.1 only applies when n=m and ε=0 (deterministic matching), yet most experimental scenarios violate these conditions. Furthermore, while Theorem B.1 proves the problem is NP-hard even for simple cases, the paper provides no approximation guarantees or worst-case bounds for the proposed heuristic solution, leaving a significant gap between the hardness result and the practical algorithm's performance guarantees.\n\nSeveral core design choices in Algorithm 1 lack adequate justification. The probabilistic sampling mechanism in Line 7 introduces unnecessary randomness when deterministic top-C selection would be simpler and potentially more stable—no ablation study compares these approaches. The specific formulation of p-SHAP in Equation 7 is presented without explaining why this particular way of incorporating the coupling p into Shapley values is optimal compared to alternatives like weighted Shapley methods. Most puzzling is the observation in Figure 4 where CF-pOT sometimes outperforms CF-pEct despite the latter using the \"true\" alignment from the CE generator—this counterintuitive result demands deeper investigation as it questions fundamental assumptions about what constitutes the \"correct\" factual-counterfactual pairing. Additionally, the choice between A^max_Value and A^avg_Value appears arbitrary across datasets without clear selection criteria.\n\nThe experimental evaluation, while broad in scope (4 datasets, 12 models, 5 CE methods), lacks critical depth in several dimensions. Most notably, there is no computational cost analysis despite complexity bounds being provided in Appendix F—readers cannot assess whether COLA's sparsity improvements justify its computational overhead. The \"near-optimal\" claim relies solely on the German Credit dataset, where Figure 4 actually shows 20-40% gaps to optimality undermining this assertion. No statistical significance tests are provided, making it unclear whether observed improvements are meaningful or due to random variation. The extremely small standard deviations in Table 3 (±0.02-0.09) are suspicious given the sampling process and warrant verification. Crucially, the paper lacks comparisons to methods explicitly designed for sparse counterfactual generation, such as L1-regularized CE methods, sparse regression approaches, or greedy feature selection baselines—the current baselines only compare different Shapley variants within COLA."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No significant ethics issue is identified."}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "VRYRt8rzty", "forum": "3vIe5pNiUN", "replyto": "3vIe5pNiUN", "signatures": ["ICLR.cc/2026/Conference/Submission2367/Reviewer_2QKe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2367/Reviewer_2QKe"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2367/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761400739038, "cdate": 1761400739038, "tmdate": 1762916210609, "mdate": 1762916210609, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of sparse counterfactual explanations: how to achieve a desired model prediction with minimal feature modifications. The authors propose COLA, a general post-hoc framework applicable to any model and counterfactual generator. The method introduces a novel joint distribution–informed Shapley attribution (p-SHAP), which uses an optimal transport coupling between factual and counterfactual samples to guide feature selection. Theoretical results show that OT minimizes an upper bound on the Wasserstein distance between model outputs and targets."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper tackles a meaningful and practical issue in explainable AI: generating concise and actionable counterfactual explanations.\n2. The problem and algorithmic design are mathematically well-structured.\n3. Experiments across several datasets and models show consistent improvements in sparsity and performance.\n4. The writing is generally clear and organized; the figures and tables support understanding of the method."}, "weaknesses": {"value": "1. The proposed p-SHAP is largely a recombination of existing ideas (Optimal Transport + Shapley values). The conceptual contribution beyond combining these two paradigms remains limited. It is unclear what fundamentally new insight p-SHAP provides.\n2. The theorems mainly show that OT minimizes a Wasserstein upper bound, but this does not directly imply minimal feature edits in the discrete action space. The theoretical link between Theorem 4.1/5.1 and the claimed “minimal action” property is not convincingly established.\n3. All experiments are on small-scale tabular datasets. There is no evidence that the approach scales to more complex or high-dimensional data, nor comparison to recent counterfactual sparsity benchmarks.\n4. Since COLA may select arbitrary feature edits, how does it ensure the modifications are feasible or ethically valid (e.g., immutable features like age or gender)? The authors briefly mention this in the ethics statement but do not model it in the algorithm."}, "questions": {"value": "1. Can the authors clearly articulate the new theoretical or methodological insight that distinguishes p-SHAP from prior Shapley-based counterfactual attribution methods?\n2. How does Theorem 4.1 translate into sparse modification guarantees in practice? Please provide an intuitive or empirical justification of this link.\n3. What is the computational complexity and runtime overhead of COLA compared to direct CE methods？\n4. Can COLA handle mixed data types (categorical + continuous) and feasibility constraints in real applications？"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1dAOklLITA", "forum": "3vIe5pNiUN", "replyto": "3vIe5pNiUN", "signatures": ["ICLR.cc/2026/Conference/Submission2367/Reviewer_2t4Y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2367/Reviewer_2t4Y"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2367/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761478380564, "cdate": 1761478380564, "tmdate": 1762916210227, "mdate": 1762916210227, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces COLA, a post-hoc framework for refining counterfactual explanations by leveraging optimal transport (OT)-induced joint distributions to guide a novel p-SHAP attribution method. The key innovation lies in using OT to model the alignment between factual and counterfactual instances, which then informs Shapley-based feature attribution to select the minimal set of actionable edits that preserve the desired counterfactual outcome. Theoretically, the authors prove that OT minimizes an upper bound on the W₁ divergence between factual and counterfactual predictions under Lipschitz continuity, and that refined counterfactuals remain no farther from the original facts than the original CEs. Empirically, COLA achieves 26–45% fewer feature edits than baseline CEs across 4 datasets, 12 models, and 5 CE generators, with p-SHAP consistently outperforming other Shapley variants."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "## Novelty and Theoretical Depth:\nThe integration of OT as a coupling mechanism to inform Shapley values is a fresh and well-justified approach. It moves beyond ad-hoc or model-specific alignments and provides a principled way to define meaningful contrastive references.\nThe p-SHAP framework generalizes B-SHAP, RB-SHAP, and CF-SHAP under a unified probabilistic coupling, offering a modular and flexible interface for attribution.\n\n## Strong Theoretical Guarantees:\nTheorem 4.1 is compelling: it establishes that OT minimizes an upper bound on the $W_1$ divergence between $f(x)$ and $y*$, linking the cost of feature modification directly to prediction fidelity. This is a non-trivial theoretical contribution.\nTheorem 5.1 provides a provable guarantee that refined CEs do not move farther from the factuals than the originals (in Frobenius norm).\n\n## Comprehensive Empirical Evaluation:\nThe experiments are rigorous and well-designed: 4 datasets, 12 models, 5 CE generators, multiple divergence metrics (OT, MMD, MeanD, MedianD), and ablations across different Shapley methods. The use of CF-$p_{OT}$ as the proposed method is clearly contrasted with baselines, demonstrating that alignment matters more than mere use of counterfactuals. The MILP-based optimality benchmark adds significant credibility, showing COLA’s near-optimality in a controlled setting.\n\n## Clear Motivation and Problem Framing:\nThe paper correctly identifies the de-coupling problem: standard FA methods (like Shapley) ignore the specific path to counterfactual outcomes, leading to suboptimal or even counterproductive edits. COLA addresses this by grounding attribution in the factual-counterfactual alignment."}, "weaknesses": {"value": "## Ambiguity in the Role of OT in p-SHAP:\nThe paper frames OT as a means to define a joint distribution p, which is then used in p-SHAP. However, OT is not directly used in the Shapley computation.\n\n## Assumption of Known Counterfactuals:\nThe framework assumes that a counterfactual set r is already available via some CE method. While this is standard in post-hoc refinement, the paper does not discuss how errors in the initial CE propagate into the final refinement. A sensitivity analysis to noisy or suboptimal CEs would strengthen the claim.\n\n## Limited Discussion on Scalability:\nWhile computational complexity is analyzed, authors do not discuss practical bottlenecks: OT with entropic regularization is expensive for high dimensionality. Solving OT on 1,000 × 1,000 matrices might be feasible but slow. Authors assume OT is \"cheap\" via Sinkhorn, but does not report scalability limits.\n\n## Averaging Across Datasets/Models May Mask Heterogeneity:\nThe results are averaged across scenarios. While this is standard, it could obscure cases where COLA fails (like with highly non-linear models or sparse features). A per-scenario analysis (e.g., worst-case performance) would help assess robustness."}, "questions": {"value": "Is the OT coupling used only to define the joint distribution p for p-SHAP, or does it also influence the actual value of the Shapley contributions beyond the reference distribution? Could you provide a small example where $p_{OT}$ leads to different attribution than $p_{Uni}$ or $p_{Rnd}$?\n\nHow does COLA perform when the initial CE is poor (high divergence from factuals, or incorrect predictions)? Could the refinement process amplify errors?\n\nWhat are the practical limits of the OT step in terms of n (number of instances) and d (features)? Have you tested COLA on larger datasets (>10k instances)?\n\nWhy not use the OT plan directly for edit selection? Instead of using $p_{OT}$ to compute p-SHAP, could one directly use the OT plan to select which features to modify by summing $p_{ij}$ over $j$)? How does this compare to p-SHAP?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ufgcePI1FH", "forum": "3vIe5pNiUN", "replyto": "3vIe5pNiUN", "signatures": ["ICLR.cc/2026/Conference/Submission2367/Reviewer_Myko"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2367/Reviewer_Myko"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2367/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761675018170, "cdate": 1761675018170, "tmdate": 1762916210016, "mdate": 1762916210016, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a method for obtaining sparse counterfactual explanations titled COunterfactuals with Limited Actions (COLA). The main novelty resides on the one side of it being a post-hoc method that refines existing counterfactuals to reduce their cardinality while minimizing the impact on the counterfactual's performance, and secondly to apply an Optimal Transport setting for guiding the refinement of the counterfactuals using Shapley attributions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper's main strength is its combinaton of theory-guided framework with its extensive experimental setup and computational experiments. Another major strength of the work is the source code provided by the authors, which allows for reproducibility of the results end-to-end. The appendices are not used merely as extension of the paper but provide extensive theoretical and practical background about the study."}, "weaknesses": {"value": "At times, the theoretical exposition remains a bit obscure, mainly due to the fact that the authors frame the problem around the group setting (generating a group of counterfactuals for a given group of factual instances) instead of in my opinion much common framing of the problem where a set of counterfactuals is generated for a specific factual instance. This makes the exposition harder for non-specialists. It is worth asking if the benefit (more generalizability) overweights the cost (clarity of exposition)."}, "questions": {"value": "- In the problem formulation (1a)-(1e), the authors state their model without but decide not to include the flipping of the target as an additional constraint. In fact, model (1a)-(1e) would by itself not produce any counterfactuals but merely minimum-distance synthetic samples. I think that should be included in the model.\n- In Section 4, it remains unclear to me what the authors mean with an i <-> j alignment for any x_i, r_j (line 145). I guess it refers to the matching step in Algorithm 1, but the paper would benefit from a clear definition of what alignment means in this case. In the subsequent line, it is also unclear what it means for an algorithm to be \"independent of CE\". Can the authors clarify this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "e2MEtNHf3E", "forum": "3vIe5pNiUN", "replyto": "3vIe5pNiUN", "signatures": ["ICLR.cc/2026/Conference/Submission2367/Reviewer_Puot"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2367/Reviewer_Puot"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2367/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761944828269, "cdate": 1761944828269, "tmdate": 1762916209822, "mdate": 1762916209822, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}