{"id": "ZYJ2kjcAMr", "number": 17874, "cdate": 1758281512300, "mdate": 1759897148466, "content": {"title": "A Kernel Distribution Closeness Testing", "abstract": "The distribution closeness testing (DCT) assesses whether the distance between a distribution pair is at least $\\epsilon$-far. Existing DCT methods mainly measure discrepancies between a distribution pair defined on discrete one-dimensional spaces (e.g., using total variation), which limits their applications to complex data (e.g., images). To extend DCT to more types of data, a natural idea is to introduce maximum mean discrepancy (MMD), a powerful measurement of the distributional discrepancy between two complex distributions, into DCT scenarios. However, we find that MMD's value can be the same for many pairs of distributions that have different norms in the same reproducing kernel Hilbert space (RKHS), making MMD less informative when assessing the closeness levels for multiple distribution pairs. To mitigate the issue, we design a new measurement of distributional discrepancy, norm-adaptive MMD (NAMMD), which scales MMD's value using the RKHS norms of distributions. Based on the asymptotic distribution of NAMMD, we finally propose the NAMMD-based DCT to assess the closeness level of a distribution pair. Theoretically, we prove that NAMMD-based DCT has higher test power compared to MMD-based DCT, with bounded type-I error, which is also validated by extensive experiments on many types of data (e.g., synthetic noise, real images).", "tldr": "", "keywords": ["Closeness Testing", "Kernel-based hypothesis testing"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7c418c189e05acfba635df1d4a7147a2cdf54ca7.pdf", "supplementary_material": "/attachment/202f118064d2f8646374e388dd5738773883bf01.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes NAMMD (Norm-Adaptive Maximum Mean Discrepancy), a normalization of the standard MMD that divides the discrepancy measure by the sum of the RKHS norms of the kernel mean embeddings. This normalization is intended to adjust for scale differences between distributions and to improve robustness when comparing distributions with different variances or magnitudes. The authors demonstrate that under certain norm conditions (Theorem 9), NAMMD can outperform MMD, and they apply the resulting statistic to distribution closeness testing (DCT), comparing it with Canonne’s total-variation-based DCT. Experimental results show promising improvements in detection power across several benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper introduces a conceptually simple yet elegant modification of MMD that aims to adapt to distributional scales, a long-standing issue in kernel-based two-sample testing.\n\n- The theoretical analysis (especially Theorem 9) provides partial intuition for when NAMMD may outperform MMD.\n\n- The empirical results indicate improved detection power in some settings, particularly for scale-shifted distributions.\n\n- The work situates itself in the broader line of kernel-based hypothesis testing and could inspire further studies on adaptive or normalized discrepancies."}, "weaknesses": {"value": "- The motivation for the specific normalization by the sum of RKHS norms remains unclear. It is not obvious why this normalization is preferable to other kernel-based measures such as Kernel Canonical Correlation Analysis (KCCA; Akaho, 2001) or Hilbert–Schmidt Independence Criterion (HSIC; Gretton et al., 2005), both of which normalize by feature-space variance or covariance to account for scale differences. Clarifying the conceptual distinction between NAMMD and these established approaches would help position the contribution more precisely.\n\n- The paper does not clearly situate NAMMD relative to prior normalized or relative MMD variants, including Normalized MMD (Muandet et al., 2012) and Relative MMD (Bounliphone et al., 2015). It remains somewhat ambiguous whether NAMMD introduces a fundamentally new normalization principle or whether it can be viewed as a reformulation of these earlier approaches.\n\n- The paper should explain how p-values are computed in the NAMMD-based test (e.g., via asymptotic approximation, permutation, or bootstrap). Since the normalization modifies the scaling of the MMD statistic, its asymptotic variance and null distribution could differ from those of standard MMD. A comparison would clarify how the normalization affects calibration and test power.\n\n- Theorem 9 considers only a specific norm condition favoring NAMMD. A more systematic analysis of how kernel bandwidths or scale ratios between P and Q influence this condition would clarify whether it is merely sufficient or also necessary. \n\n- In Section 5.1, only average test power is reported. The empirical type-I error rates of both Canonne’s total-variation-based DCT (Canonne et al., 2023) and the NAMMD-based DCT are not shown, making it unclear whether both tests operate at the same nominal significance level. Reporting empirical type-I error under the null hypothesis would make the comparison more rigorous and interpretable.\n\n[References]\n- Akaho, S. (2001). A kernel method for canonical correlation analysis.\n- Gretton, A., Bousquet, O., Smola, A., & Schölkopf, B. (2005). Measuring statistical dependence with Hilbert–Schmidt norms.\n- Muandet, K., Fukumizu, K., Sriperumbudur, B. K., & Schölkopf, B. (2012). Learning from distributions via support measure machines.\n- Bounliphone, W., Bellet, A., & Tommasi, M. (2015). A test of relative similarity for model selection in generative models.\n- Canonne, C. L., Kamath, G., & Steinke, T. (2023). Distribution closeness testing via total variation."}, "questions": {"value": "- Conceptual distinction — Could the authors clarify how NAMMD differs conceptually from correlation-based kernel measures such as KCCA (Akaho, 2001) or HSIC (Gretton et al., 2005)? In what sense does the normalization by the sum of RKHS norms capture a different form of scale or variance adjustment?\n\n- Relation to prior normalized MMDs — How does NAMMD relate to previously proposed normalized or relative MMD variants, such as those by Muandet et al. (2012) or Bounliphone et al. (2015)? Is the proposed normalization theoretically novel, or can it be interpreted as a reparameterization of these approaches?\n\n- Statistical inference — How are p-values estimated in the NAMMD-based test? Since the normalization changes the scaling of MMD, does its null distribution differ in variance or asymptotic form? A short explanation or comparison would improve reproducibility and theoretical clarity.\n\n- Norm condition in Theorem 9 — Theorem 9 focuses on a specific norm condition that favors NAMMD. Could the authors discuss whether this condition might fail, and what happens in such regimes? For example, would NAMMD reduce to standard MMD, or behave pathologically?\n\n- Empirical validity — In Section 5.1, the comparison with Canonne’s total-variation-based DCT lacks type-I error reporting. Could the authors include empirical type-I error rates under the null to ensure that both methods are calibrated at the same nominal significance level (e.g., α = 0.05)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "eW8v8Hnwx1", "forum": "ZYJ2kjcAMr", "replyto": "ZYJ2kjcAMr", "signatures": ["ICLR.cc/2026/Conference/Submission17874/Reviewer_m3FE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17874/Reviewer_m3FE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17874/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761486626102, "cdate": 1761486626102, "tmdate": 1762927699926, "mdate": 1762927699926, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the problem of distribution closeness testing (DCT), extending the usual two-sample test. The authors propose to use a normalized version of maximum mean discrepancy for this task. Asymptotic theories are developed for their tests."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1, The experiments are broad and cover both synthetic and real-world datasets.\n2, The paper identifies an important but underexplored problem: distribution closeness testing (DCT)"}, "weaknesses": {"value": "1, the paper proposes a normalizing approach, but the paper does not rigorously prove that this scaling yields an optimal variance normalization or minimizes any formal criterion (e.g., unbiasedness or asymptotic efficiency). Thus, NAMMD’s normalization remains heuristic rather than theoretically grounded.\n\n2, I find it somewhat concerning that the theory does not unify DCT and TST despite superficial similarity. The paper reverts to permutation calibration, admitting that the asymptotic distribution does not apply when $\\varepsilon = 0$. \n\n3, While the paper provides many figures and comparisons, key experimental parameters (e.g., sample sizes for Fig. 1, variance of estimators) are not reported, limiting reproducibility and interpretability of the less informative claim.\n\n4, Although DCT is motivated as a closeness test, the practical interpretation of $\\varepsilon$ (what level of MMD/NAMMD difference implies model transferability or acceptable domain shift) is not concretely defined. In the ImageNet experiments, the choice of $\\varepsilon$ and its connection to performance metrics appear ad-hoc.\n\n5, Although DCT is motivated by high-dimensional tasks, the paper does not analyze NAMMD’s behavior under the curse of dimensionality.\n\n6, Most importantly, this papers does not discuss or compare NAMMD to other variance normalized versions of MMD."}, "questions": {"value": "I find figure 1 very misleading and have the following questions:\n\n1, how is the $p$-value computed? Do you use permutations to get the $p$-value.\n\n2, Assuming the p-values are computed using permutations, it depends on the sample size, which is not reported. The number of repetitions is not reported either.\n\n3, Theoretically, when P is not equal to Q, MMD converges to a positive number. While if you permute the samples, it converges to 0. So, p-value is expected to be small."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ooP8bahRKd", "forum": "ZYJ2kjcAMr", "replyto": "ZYJ2kjcAMr", "signatures": ["ICLR.cc/2026/Conference/Submission17874/Reviewer_6EMd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17874/Reviewer_6EMd"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17874/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926823458, "cdate": 1761926823458, "tmdate": 1762927699298, "mdate": 1762927699298, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, authors propose a testing statistic called nom-adaptive MMD for distribution closeness testing. Comparing to the traditional MMD, NAMMD adds a normalisation term, \nand fixes the issue that MMD is the same for kernel mean embeddings with different RKHS norms.  The authors several a testing procedure to examine the closeness of the distributions and shows that the proposed NAMMD has a higher testing power on toy and real world problems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The closeness test is indeed different from traditional two-sample tests and represents an underexplored area in hypothesis testing, with potential downstream applications such as classifier transfer. \n\nThe issue that kernel mean embeddings in MMD can have different RKHS norms but yield the same MMD value is a legitimate concern, and the solution proposed in Equation (1) is both elegant and easy to implement in practice. \n\nThe proposed NAMMD method appears to consistently achieve higher testing power than MMD and total variation–based test statistics, as demonstrated in the experimental results.\n\nThe paper is generally well-written."}, "weaknesses": {"value": "The main concern with this paper is that its technical innovation and motivation appear to be unrelated. From Figures 1(a) and 1(b), I can indeed see that MMD is not ideal when a and b have the same MMD value but their kernel mean embeddings have different RKHS norms. However, it is unclear why this becomes an issue specifically in the context of DCT. Without establishing this connection, the motivation remains weak. If DCT is susceptible to this particular issue of MMD, the authors should clarify in the introduction.\n\nThe authors also do not clearly explain what distinguishes the DCT test statistic from traditional TST test statistics. From the definition in line 117, it seems that as long as a TST statistic outputs some form of dissimilarity measure, it could be used for DCT as well. This further adds to the confusion about why we should focus on the RKHS norm issue discussed in the previous section, as it is not evident how normalizing the MMD resolves any problem when using a TST statistic (MMD) for DCT.\n\nIn the introduction: \n\n> \"Besides, extending these methods using continuous total variation involves the estimation of the underlying density functions of the distributions [25, 26]\" \n\nHowever, this is not accurate. There have been many efforts to adapt total variation to continuous data. For example, [1] propose a general nonparametric estimator for integral probability metrics (of which TV, MMD, and Wasserstein distances are special cases). Similarly, [2] introduce a general framework for estimating f-divergences (of which TV is one example), which has been widely adopted in generative model training.\n\n[1] https://arxiv.org/abs/0901.2698\n[2] https://arxiv.org/abs/1606.00709\n\nThe empirical comparison also does not include other widely used discrepancy measures beyond MMD and TV in the discrete example. For instance, f-divergence–based measures have been used in TST and could serve as a natrual candidate test statistics for DCT."}, "questions": {"value": "What is the main reason that authors consider MMD over other test statistics? For example, Wasserstein distance and classic divergence, both can be extneded to continous variable settings without estimating densities (see [1] and [2]). \n\nLine 085: Specifically, the MMD value can be the same for many pairs of distributions that have different norms in the RKHS Hκ, which potentially have different closeness levels. \n\nFigure 1 a and b are not helpful demonstrating this as P and Q are equally close in both figures, depending on how close you zoom. Could authors find a better illustration of this problem? \n\nIn Figure 1, c and d, why is it not desirable to have MMD stays constant while the p-value of TST changes? \n\nLine 312, how realistic is the condition ||mu_p1||^2 + ||mu_q1||^2 <= ||mu_p2||^2 + ||mu_q2||^2? It looks like that the main results in the proof depends on this particular assumption and there are some explanations in Section 6.2. However, it seems to only suggest the sum of variance of kernel embedding of p1 and q1 should be greater than that of p2 and q2. How strengient is this condition in reality? Could this condition be translated into some more interpretable?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None."}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pleYFRednA", "forum": "ZYJ2kjcAMr", "replyto": "ZYJ2kjcAMr", "signatures": ["ICLR.cc/2026/Conference/Submission17874/Reviewer_Kwpk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17874/Reviewer_Kwpk"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17874/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993657210, "cdate": 1761993657210, "tmdate": 1762927698074, "mdate": 1762927698074, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}