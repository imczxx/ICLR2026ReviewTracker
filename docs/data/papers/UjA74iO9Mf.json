{"id": "UjA74iO9Mf", "number": 20652, "cdate": 1758308653440, "mdate": 1763696084853, "content": {"title": "GinSign: Grounding Natural Language into System Signatures for Temporal Logic Translation", "abstract": "Natural language (NL) to temporal logic (TL) translation enables engineers to specify, verify, and enforce system behaviors without manually crafting formal specifications—an essential capability for building trustworthy autonomous systems. While existing NL–to-TL translation frameworks have demonstrated encouraging initial results, these systems either explicitly assume access to accurate atom grounding or suffer from low grounded translation accuracy. In this paper, we propose a framework for Grounding Natural Language Into System Signatures for Temporal Logic translation called GinSign. The framework introduces a grounding model that learns the abstract task of mapping NL spans onto a given system signature: given a lifted NL specification and a system signature $\\mathcal{S}$, the classifier must assign each lifted atomic proposition to an element of the set of signature-defined atoms $\\mathcal{P}$. We decompose the grounding task hierarchically—first predicting predicate labels, then selecting the appropriately typed constant arguments. Decomposing this task from a free-form generation problem into a structured classification problem permits the use of smaller masked language models and eliminates the reliance on expensive LLMs. Moreover, since the grounding is captured as an abstract task without hard-coding the state space, our approach can generalize to new (or modified) state spaces without retraining. Experiments across multiple domains show that frameworks which omit grounding tend to produce syntactically correct lifted LTL that is semantically nonequivalent to grounded target expressions, whereas our framework supports downstream model checking and achieves grounded logical-equivalence scores of 95.5%, a $1.4\\times$ improvement over SOTA.", "tldr": "We introduce GinSign, a framework for grounding NL into system signatures for TL translation. By framing grounding as structured classification, GinSign outperforms prior work with 95.5% grounded equivalence and generalizes across domains.", "keywords": ["Grounding", "Natural Language Grounding", "Temporal Logic", "Linear Temporal Logic", "NL-to-TL", "Verification", "Translation", "Formalization"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e084f835b0320b3d7e4dad58f08cedc4e102d27f.pdf", "supplementary_material": "/attachment/40c93cc92ea3f12e5916a6df2719289d0023e732.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes an end-to-end grounded \"natural language to temporal logic\" generative model. The paper points out that existing NLP-to-TL transformation methods and models are not usable in practice due to the lacking connections between the generated atomic propositions are linked to the predicates & constants. \n\nFor the grounding process, the paper proposes a hierarchical approach that first does predicate grounding and then argument grounding. Both processes are approached as natural language classification tasks based on BERT model, with an additional filtering step to simplify the problem. For grounding classification model, the paper proposes a non-standard formulation that aims to map a text fragment (given by the lifing model) to a candidate system signature symbol (predicted / typed constant). The classification model is obtained by fine-tuning pre-trained BERT.\n\nThe paper reports clear gains over GPT3-5/4.1 and Lang2LTL baselines with an ability to generalize over unseen predicates/constants."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper points out an important shortcoming of existing methods and proposes a sensible approach.\n\nThe experimental results are interesting, (partly) demonstrating the advantages of the method."}, "weaknesses": {"value": "The results are VLTL-Bench only. \n\nParts of the paper are difficult-to-read without domain expertise. Overall, I believe , the paper could have been written in a more accessible way considering that it is a submission to a primarily a machine learning conference.\n\nWhile the work itself is valuable, parts of the work is clearly highly domain dependent. Personally, I find it hard to clearly estimate the degree of relevance to ICLR community, although it has interesting aspects in terms of the generalization abilities of the proposed BERT based formulation and the potentially increasing interest to formal languages in machine learning research."}, "questions": {"value": "Section 5.1 claims that other datasets like Navigation / Cleanup World / GLTL are not applicable. There is also the DeepLTL dataset (Hahn et al). Even if it is not possible to evaluate in terms of grounding, is it not possible to evaluate in terms of overal LTL synthesis ability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TxiZS3hpbs", "forum": "UjA74iO9Mf", "replyto": "UjA74iO9Mf", "signatures": ["ICLR.cc/2026/Conference/Submission20652/Reviewer_KhUo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20652/Reviewer_KhUo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20652/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761834367756, "cdate": 1761834367756, "tmdate": 1762934042250, "mdate": 1762934042250, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the problem of translating natural language (NL) specifications into temporal logic (TL) by grounding the resulting atomic propositions into system signatures. The proposed framework, GinSign, introduces a hierarchical translation pipeline that separates (1) the deduction of the logical structure (lifted temporal logic) from (2) the grounding of atomic propositions to a predefined system signature composed of types, predicates, and constants.\n\nThe key insight is that grounding NL specifications to semantically meaningful system entities produces more executable and interpretable formal specifications. The two-level grounding approach first predicts the predicate (predicate grounding) and then connects it to the appropriate arguments (argument grounding). A key claim is that by reframing grounding as a structured classification task, GinSign can employ smaller encoder-only models instead of expensive LLMs, thereby improving efficiency while maintaining accuracy. \n\nExperiments on the VLTL-Bench benchmark, which includes three domains (Search and Rescue, Traffic Light, and Warehouse), show that GinSign achieves near-perfect predicate grounding across all domains, outperforming GPT-3.5 Turbo, GPT-4.1 Mini, and prior systems such as Lang2LTL. For argument grounding and logical equivalence evaluation, GinSign also consistently outperforms GPT-based and NL2LTL baselines, achieving ≥ 90% grounded logical equivalence accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is clearly written, and the authors situate their contribution well within the growing literature on natural language to temporal logic translation.\n- The two-level grounding process (first predicates, then arguments) is sound and mirrors how logical forms are constructed compositionally.\n- The results show that GinSign substantially improves grounding accuracy and logical equivalence over strong LLM baselines, including GPT-4.1.\n- Explicitly grounding TL specifications in system signatures could benefit downstream tasks such as automated verification, planning, or control synthesis."}, "weaknesses": {"value": "- While the hierarchical design is reasonable, the technical novelty feels incremental. The improvement largely comes from providing the model with *more structured context* (the system signature and a lifted template) and recasting the task as classification, rather than introducing new learning or reasoning mechanisms.\n- The approach assumes access to fully specified system signatures (types, predicates, and constants). Although the authors acknowledge this limitation, real-world domains often provide only partial or evolving ontologies, which limits the method’s general applicability.\n- Because the evaluation requires access to both lifted and grounded atomic propositions, widely used datasets could not be used, which limits cross-domain validation.\n- The framework relies heavily on prompt engineering and structured templates rather than principled modeling. The paper does not discuss *why* hierarchical separation or classification-based formulation helps beyond empirical evidence, or what insights generalize to other grounding or reasoning tasks.\n- It remains unclear whether GinSign can operate effectively when only natural language input is available (without lifted sentences or system signatures)."}, "questions": {"value": "1. How would the approach perform if only NL input were available, without lifted sentences or explicit system signatures?\n2. Could the model infer or learn parts of the system signature automatically, rather than relying on manual specification?\n3. How sensitive are the results to prompt design or structured templates? Would smaller or less informative prompts substantially degrade performance?\n4. The paper attributes most grounding errors to linguistic ambiguity. Could the authors elaborate on whether other factors, such as missing predicates in the system signature or type mismatches during argument binding, also contributed to these failures?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aL7x0afAwv", "forum": "UjA74iO9Mf", "replyto": "UjA74iO9Mf", "signatures": ["ICLR.cc/2026/Conference/Submission20652/Reviewer_YeYH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20652/Reviewer_YeYH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20652/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762159106987, "cdate": 1762159106987, "tmdate": 1762934041797, "mdate": 1762934041797, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Response to all reviewers"}, "comment": {"value": "We thank all reviewers for their valuable feedback. We appreciate the strengths acknowledged by multiple reviewers, including:\n- [xzXi, Sd4T, YeYH, KhUo] acknowledge that GinSign addresses a clear bottleneck in current NL-to-LTL translation systems. \n- [xzXi, YeYH, KhUo] recognize the sound and effective design of our hierarchical grounding methodology, as well as our strong empirical performance over LLM baselines. \n- [xzXi, YeYH] appreciate the quality and clarity of our presentation, the significance of semantically grounded LTL in combination with syntactically correct LTL generation, and the relevance of accurate grounding to downstream applications in planning, verification, and control.\n\nIn addition to the qualities mentioned above, some concerns were shared by multiple reviewers, including: \n\n>Q1: [xzXi, Sd4T, YeYH, KhUo] Evaluation limited to VLTL-Bench: \n\nWe evaluate on all 3 VLTL-Bench domains. This is because we propose a grounding module, and therefore must evaluate on a dataset with grounded predicate labels. To our knowledge, there is no other sufficiently complex dataset that includes these labels. The datasets that do include grounded predicates are highly limited; for example, CW and GLTL contain only 8 predicates across the entire dataset. Additionally, we omit isolated evaluation of LTL synthesis components because we do not propose novel LTL synthesis methods. Our contribution is purely a grounding approach, and we therefore consider an LTL synthesis evaluation without grounding to be out of scope. We hope the reviewers find this explanation adequate, and welcome the suggestion of additional grounded NL-LTL translation datasets to include in our evaluation, permitted that sufficient time remains in the rebuttal period to do so.\n\n>Q2: [Sd4T, YeYH, xzXi] Handling dynamic domains/signatures: \n\nSeveral reviewers pointed out that GinSign assumes a fully specified, static system signature at inference time. While it is true that the system signature must be fully known, this is a limitation of the grounding task in general, not a specific limitation of GinSign. Table 5 in the paper shows the intra-domain OOD evaluation in which domain prefixes are changed from those that appear during training, i.e., the handling of dynamic domain signatures. Additionally, at the request of reviewer Sd4T, we provide a new experimental results table showing performance on fully OOD domains. We train variations of the GinSign model on 2 out of 3 of the domains, and report grounding results for both predicates and arguments on all 3 domains. These results are now shown in Table 6 in section 5.4. We observe surprisingly high performance on the holdout domains: in the best case, the GinSign Predicate grounder achieves perfect performance on grounding predicates in the Traffic Light domain, despite never being exposed to this data during training. Additionally, the GinSign Argument grounder achieves accuracy and F1 scores of 96.4% and 72.9% respectively on the Search and Rescue domain. We find these results to be encouraging evidence of GinSign’s ability to generalize the grounding task. Even when trained on only 2 different domains, much of the performance transfers to unseen domains for both predicate and argument grounding.\n\n>Q3: [Sd4T, YeYH, xzXi] Scalability to large signatures is unclear\n\nIn order to address this concern, we have added an explanation of how GinSign’s computational cost scales with signature size, demonstrating that as the signature token count grows, the cost of grounding with GinSign remains strictly below the cost of grounding with generative LLMs. This information can now be found in Appendix 2 of the paper. We show that for a signature containing $N$ tokens, the prompt-based generative LLM incurs $O(N^2)$ inference cost due to quadratic self-attention over a single long prompt. In contrast, GinSign shards the signature into $N/m$ fixed-size prefix windows of length $m$ and performs a tournament over candidates, yielding a total cost of $O(m)$ (linear in the number of signature tokens), with $O(log_mN)$ tournament rounds. Thus, as the signature grows, the overall cost of grounding with GInSign remains strictly below that of LLM-based prompting, and scales much more favorably for large system signatures.\n\n>Q4: [Sd4T, YeYH] Comparisons to LLM baselines may be insufficient or unfair.\n\nWe appreciate this feedback, and have performed an additional evaluation using GPT-4o (a reasoning model) with Chain-of-Thought prompting. The results of this new experiment can be found in the updated Table 3. We find that GinSign still outperforms the generative LLMs, even when using the stronger model with CoT prompting, in all but one case (the LLM performs 4% better on argument grounding Search and Rescue). We would also like to point out that GinSign outperforms GPT-4o on grounding Warehouse argument by 23.9%, and in predicate grounding on all domains."}}, "id": "AJXjuNobDc", "forum": "UjA74iO9Mf", "replyto": "UjA74iO9Mf", "signatures": ["ICLR.cc/2026/Conference/Submission20652/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20652/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20652/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763695733417, "cdate": 1763695733417, "tmdate": 1763695733417, "mdate": 1763695733417, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces GinSgin to address the “grounding problem” in Natural Language (NL) to Temporal Logic (TL) translation, where most existing pipelines produce \"lifted\" TL formulas and are not directly suitable for formal verification. The main contribution is a hierarchical grounding approach that runs after standard lifting and translation. It involves a lightweight BERT model that classifies an NL span into a system-defined predicate and then grounds the NL span into specific constants from a set of filtered “prefix”. Experiments on the VLTL-Bench demonstrate that this approach achieves high accuracy and outperforms zero-shot LLM-based baselines on the GLE metric."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- This paper clearly identifies and tackles a practical bottleneck of grounding in the NL-to-TL problem that most prior work overlooks.\n\n- The proposed hierarchical decomposition is a straightforward and effective way to reduce the search space and leverage the type checking to improve overall performance."}, "weaknesses": {"value": "- The entire framework depends on a known, fixed, finite, and static system signature $<T,P,C>$, which is a strong and often unrealistic assumption for open-world or evolving systems, weakening the contribution’s practical impact. The paper focuses only on grounding ambiguity, offloading logical and semantic ambiguity to upstream modules.\n- The method’s effectiveness and scalability to large-scale real-world signatures are unproven. The OOD claims are not fully supported by a cross-domain generalization test, but rather by the intra-domain test (Table 5).\n- The SOTA-beating claims (Table 3) are based on an unfair comparison. GinSign (fine-tuned) is compared against zero-shot, non-SOTA LLMs (GPT3.5/4.1-Mini) using a flat and plain prompt, rather than the hierarchical one that GinSign benefits from."}, "questions": {"value": "- The comparison to LLMs in Table 3 appears unfair. Could the authors provide results for a stronger baseline that prompts an SOTA LLM (e.g., GPT-4o) using the same hierarchical decomposition that GinSign benefits from or other common prompting techniques (e.g., CoT, Self-reflection)?\n\n- How do the authors expect the prefix-sharding and tournament mechanism to scale to significantly larger signatures, for example, a system with thousands of constants? What are the practical computational limits?\n\n- The OOD experiment is intra-domain. Have the authors attempted a cross-domain generalization test (e.g., training on Traffic Light and testing on Warehouse) to validate the \"transferable reasoning\" claim?\n\n- Could the authors add definitions for formal methods notation (like $\\Sigma^\\omega$) to improve accessibility for a broader audience?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sAetrkdXAb", "forum": "UjA74iO9Mf", "replyto": "UjA74iO9Mf", "signatures": ["ICLR.cc/2026/Conference/Submission20652/Reviewer_Sd4T"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20652/Reviewer_Sd4T"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20652/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762558718646, "cdate": 1762558718646, "tmdate": 1762934041445, "mdate": 1762934041445, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a critical bottleneck in natural language (NL) to temporal logic (TL) translation: the lack of semantic grounding of atomic propositions (APs) to system-specific definitions, which renders existing TL outputs syntactically valid but practically unusable for system verification. \n\nThe proposed solution, GinSign, introduces a framework that treats grounding as a hierarchical classification problem against a formal system signature. The key innovation is a two-step process: first grounding a natural language span to a predicate from the signature, and then grounding its arguments from type-filtered constants. This is operationalized using a novel prefix enumeration technique with a masked language model (like BERT), transforming grounding into a scalable, domain-agnostic classification task. \nThe authors evaluate GinSign on the VLTL-Bench dataset (Search and Rescue, Traffic Light, Warehouse domains), showing that it achieves 95.5% grounded logical equivalence (GLE) (a 1.4x improvement over state-of-the-art (SOTA) methods like Lang2LTL), 100% predicate grounding accuracy across all domains, and robust argument grounding ($\\ge$ 90% $F_1$). Critically, GinSign’s outputs support downstream model checking, a capability missing in prior NL-to-TL frameworks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Originality: The formulation of grounding as a prefix-based hierarchical classification is distinct from all existing approaches (e.g., end-to-end LLM generation, embedding-similarity) and is a highly creative solution.\n\n- Quality: The evaluation is thorough: it includes isolated grounding (to validate individual components), end-to-end translation (to assess full pipeline performance), and OOD ablation (to test generalization). The use of multiple baselines ensures that GinSign’s advantages are not overstated.\n\n- Clarity: Complex components are explained with algorithms and examples, making the framework reproducible for other researchers.\n\n- Significance: Unlike prior work that focuses on syntactic correctness, GinSign prioritizes semantic grounding—this shifts NL-to-TL from a \"theoretical exercise\" to a tool that can be integrated into formal verification workflows for autonomous systems."}, "weaknesses": {"value": "- Limitations of Evaluation Domains: The empirical validation is confined to the VLTL-Bench. While it contains three distinct domains, the scale and complexity of the system signatures may not fully represent large-scale, real-world systems (e.g., full autonomous vehicle specifications). Performance and scalability on signatures with orders-of-magnitude more constants remain an open question.\n\n- Limited TL Coverage: GinSign only supports propositional LTL. The paper mentions extending to metric LTL (with time bounds) or first-order LTL (with quantifiers) as future work, but it does not discuss the technical challenges of grounding for these variants. \nConstant Grounding Bottleneck in Warehouse: While GinSign’s Warehouse argument grounding (94.2% $F_1$) outperforms baselines, it is lower than in other domains (Traffic Light: 97.9%, Search and Rescue: 91.1%). The authors attribute this to lexically diverse constants but do not provide a detailed error analysis (e.g., which constants are most often misgrounded, why). Such analysis could guide targeted improvements.\n\n- Dynamic Signature Handling: The framework assumes static system signatures at inference time. For systems where signatures evolve (e.g., adding new predicates/constants), GinSign would require retraining or reconfiguring the prefix—no strategy for incremental adaptation is proposed."}, "questions": {"value": "1. (About Constant Grounding Error Analysis) For the Warehouse domain, could you provide specific examples of misgrounded constants and explain why the current framework fails in these cases?\n2. (About Scalability to Large Signatures) For systems with thousands of constants (e.g., a warehouse with 1,000 unique items), the current shard-based classification may become inefficient. Have you explored retrieval-augmented methods? \n3. (About Dynamic Signature Adaptation) For systems where new predicates/constants are added post-deployment, how would you update GinSign without full retraining? Could the prefix-enumeration mechanism be combined with few-shot learning to adapt to new signature elements?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "syXDoPMeJ5", "forum": "UjA74iO9Mf", "replyto": "UjA74iO9Mf", "signatures": ["ICLR.cc/2026/Conference/Submission20652/Reviewer_xzXi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20652/Reviewer_xzXi"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20652/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762849737200, "cdate": 1762849737200, "tmdate": 1762934040805, "mdate": 1762934040805, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}