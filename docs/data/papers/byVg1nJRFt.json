{"id": "byVg1nJRFt", "number": 6483, "cdate": 1757986733463, "mdate": 1759897911833, "content": {"title": "Animating the Still: Physics-Based 3D Cinemagraph from Multi-View Images Using 3D Gaussian Splatting", "abstract": "3D Cinemagraphs aim to generate visually compelling media by introducing subtle and continuous motion into otherwise static images. Recent efforts have explored this task through 3D reconstruction techniques, but they often fall short in delivering physically plausible and controllable animations. In this paper, we propose a novel physics-driven framework built upon 3D Gaussian Splatting (3DGS) to address these limitations. Given multi-view images and a user-specified force, our approach first reconstructs a 3D scene using 3DGS, then embeds the reconstruction into a physically consistent simulation environment. By modeling external and internal force fields and performing accurate force analysis within the reconstructed 3D space, we synthesize fine-grained and interpretable motion that aligns with physical intuition. Our method allows users to intuitively control motion effects via high-level physical parameters, achieving a delicate balance between realism and artistic flexibility. Extensive experiments under diverse force conditions demonstrate that our approach produces stable, interpretable, and visually appealing results, surpassing prior methods in both robustness and controllability.", "tldr": "", "keywords": ["Cinemagraph"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3c56b5712ab511541dd90d173a1fb730d9ebd11e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a physics-driven framework for generating 3D cinemagraphs using 3D Gaussian Splatting. It reconstructs a 3D scene from multi-view images and embeds it into a physically consistent simulation environment, where external and internal forces are modeled to produce physically plausible motion. The method allows user control through high-level physical parameters, achieving a balance between realism and artistic flexibility."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- 3D cinemagraphs represent an interesting and visually appealing research topic.\n\n- The proposed method takes into account multiple types of external forces.\n\n- In the presented tree example, the method produces more visually realistic results compared to existing approaches."}, "weaknesses": {"value": "- The performance of the proposed method is difficult to interpret. The visual results in Fig. 2 are not very clear, as the displayed frames appear quite similar, making it hard to perceive the motion type. Additionally, there is no supplementary video or other media provided to better demonstrate the effectiveness of the method. For comparison with other approaches, only a single example is shown, which is insufficient for a fair and comprehensive evaluation.\n\n- Are there any quantitative results reported? The authors mention using a dataset with a large number of objects, yet no table or metric-based evaluation is presented to quantitatively assess the method’s performance.\n\n- When applying physical transformations to Gaussian splats, does this cause visual distortion? Since 3D Gaussian Splatting relies on the cumulative effect of multiple Gaussians along the ray, transforming only a subset of them could potentially lead to visual artifacts.\n\n- What is the computational cost or time required to generate an animation using the proposed method?"}, "questions": {"value": "Please refer to the weakness part above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "FADrcByP4Y", "forum": "byVg1nJRFt", "replyto": "byVg1nJRFt", "signatures": ["ICLR.cc/2026/Conference/Submission6483/Reviewer_b62R"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6483/Reviewer_b62R"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6483/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761511251037, "cdate": 1761511251037, "tmdate": 1762918861473, "mdate": 1762918861473, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a novel pipeline that combines Newtonian-based simulation with 3D Gaussian Splatting to generate physically plausible animations. The proposed pipeline consists of three key components: (1) Gaussian primitives reconstruction, (2) incorporation of physical priors and simulation, and (3) loopable cinemagraph rendering. The method is clearly articulated and fairly solid. However, my primary concern lies in the lack of thorough experimental analysis, which is essential to validate the proposed approach."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-organized, and the proposed method is clearly and comprehensively presented.\n2. The introduction of Newtonian-based simulation to 3D reconstruction is both novel and intriguing, showcasing the potential for generating physically plausible animations."}, "weaknesses": {"value": "**Insufficient Method**:\nThe claimed advantage of incorporating physics into 3D cinemagraph generation is not clearly demonstrated and appears limited. The method assumes rigid-body dynamics, which restricts its applicability to non-rigid scenes such as flowing water or deformable objects.\n\n**Limited Experimental Validation**:\nThe experimental evaluation is relatively weak and does not sufficiently demonstrate the effectiveness or generalizability of the proposed method. Specifically:\n1. The paper only compares its results with a single baseline ([16]). It should also include recent physics-integrated methods such as PhysGaussian [32], DreamPhysics [8], and Physics3D [21], using both quantitative and qualitative comparisons.\n2.Figure 2 presents only five examples. Including more scenes would better illustrate the robustness and generalizability of the approach.\n3. Lack of Video Demonstrations: Since the task involves dynamic cinemagraph generation, the paper should provide representative video results to assess temporal coherence and motion realism.\n4. Unclear User Study Design: Details such as the number of samples shown, scene diversity, and participant evaluation protocol are missing, making it difficult to assess the validity of the user study."}, "questions": {"value": "Please see weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "o0ilUWXFR9", "forum": "byVg1nJRFt", "replyto": "byVg1nJRFt", "signatures": ["ICLR.cc/2026/Conference/Submission6483/Reviewer_TbCs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6483/Reviewer_TbCs"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6483/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761567328552, "cdate": 1761567328552, "tmdate": 1762918861071, "mdate": 1762918861071, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper models objects using 3D Gaussian Splatting (3DGS) and incorporates physical modeling to simulate force interactions, thereby producing physically plausible object animations. The method models object motion under the combined effects of external and internal forces, while assigning each Gaussian a specific mass attribute to endow it with physical properties. Moreover, to ensure realistic deformation behavior, the Gaussians are grouped into multiple superGaussians, where each group shares similar physical attributes and motion patterns. Finally, the paper generates infinitely long videos through a cyclic rendering strategy. Experimental results demonstrate that the proposed method produces results that better conform to physical laws compared to existing approaches."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- This paper assigns mass attributes to Gaussians and models object motion based on Newton’s second law to achieve physically plausible animation modeling. The proposed approach differs from previous MPM-based methods and provides a new perspective for modeling physically consistent object deformations.\n- The proposed method is built upon solid physical principles, which ensure the reliability of the approach.\n- Experimental results show that the proposed method produces results that better comply with physical laws compared to the baseline methods, while also offering superior controllability."}, "weaknesses": {"value": "- The baselines compared in this paper are relatively early methods; it is recommended to include comparisons with more recent approaches such as OmniPhysGS[1].\n- The physical animation effects of objects can be more intuitively demonstrated through videos. In the future, the authors could consider presenting video comparison results or demos on the project webpage to allow readers to better understand the model’s outputs.\n- In the introduction, corresponding citations should be added when describing other methods — for example, in lines 36–38 when discussing recent studies, and in lines 44–45 when mentioning 3DGS and related works.\n\n[1] OmniPhysGS: 3D Constitutive Gaussians for General Physics-Based Dynamics Generation. ICLR 2025."}, "questions": {"value": "Please see the weekness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "iNvMfeEg8X", "forum": "byVg1nJRFt", "replyto": "byVg1nJRFt", "signatures": ["ICLR.cc/2026/Conference/Submission6483/Reviewer_rURL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6483/Reviewer_rURL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6483/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761904782807, "cdate": 1761904782807, "tmdate": 1762918860426, "mdate": 1762918860426, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a novel framework for generating 3D cinemagraphs from a set of multi-view static images. The key contribution is the integration of a physics-based simulation directly onto a 3D Gaussian Splatting (3D-GS) scene representation. Instead of relying on learned motion priors, the method first reconstructs a scene using 3D-GS. It then treats the individual Gaussians as a system of physical mass points. To manage complexity and enforce structural coherence, these Gaussians are clustered into \"SuperGaussians,\" which are approximated as rigid bodies. The animation is driven by a simulation that accounts for user-defined external forces (e.g., wind, spiral fields) and internal structural forces (elasticity and damping) that propagate through a sparse, locality-aware constraint graph. Finally, a trajectory blending technique is used to render a seamlessly looping video. The proposed method aims to produce physically plausible, interpretable, and highly controllable animations that surpass the realism of existing techniques."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The central contribution is non-trivial: merging a classical, interpretable physics simulation with a modern neural scene representation like 3D-GS. This approach moves away from black-box generative models for motion and toward a system grounded in first principles, which is a compelling research direction for controllable and physically-aware generation.\n- A direct benefit of the physics-based approach is that the resulting motion is both controllable and interpretable. Users can manipulate intuitive, high-level physical parameters like force fields, stiffness ($k$), and damping ($\\zeta$) to direct the animation, rather than navigating a complex latent space. The resulting motion can be understood through the lens of classical mechanics, which is a significant advantage over purely data-driven methods.\n- The clustering of primitives into \"SuperGaussians\" is a very intelligent way to manage the immense complexity of simulating millions of individual Gaussians. It provides a hierarchical structure that improves both computational efficiency and the structural coherence of the motion.\n- The use of a sparse, local \"constraint graph\" to model internal forces is a reasonable design choice. It reflects the local nature of real-world physical interactions and avoids the computational expense and potential instability of a fully-connected system."}, "weaknesses": {"value": "- The underlying physics is essentially a damped mass-spring system applied to rigid clusters. While effective for the subtle motions required for cinemagraphs, this is a very simplified model. The paper's own conclusion acknowledges that it cannot handle complex phenomena like exaggerated swinging or fluid-like dynamics. Furthermore, the framework does not appear to support crucial physical interactions such as collisions, fracture, or non-rigid deformations beyond simple elasticity, which limits its application to a narrow range of effects.\n- The method is demonstrated on scenes containing single, relatively isolated objects against clean backgrounds (e.g., NeRF synthetic data). It is unclear how the framework would scale to slightly larger, more complex, and cluttered real-world scenes. The SuperGaussian clustering and constraint graph construction could become significantly more challenging and potentially produce less meaningful results in scenes with many interacting or overlapping objects.\n- The paper claims strong user control, but the mechanism for applying forces seems to be at a high level (e.g., defining a global wind field). It is not clear how a user could apply a localized force to a specific semantic part of an object (e.g., pushing a single branch on the Ficus tree). This would presumably require an additional layer for semantic segmentation and selection of SuperGaussians, which is not discussed. There is no supplement demo shown at all, only text appendix."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3Gs1JtUtDs", "forum": "byVg1nJRFt", "replyto": "byVg1nJRFt", "signatures": ["ICLR.cc/2026/Conference/Submission6483/Reviewer_Tp4o"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6483/Reviewer_Tp4o"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6483/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761983940108, "cdate": 1761983940108, "tmdate": 1762918859892, "mdate": 1762918859892, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}