{"id": "E5L43l5EIu", "number": 16591, "cdate": 1758266459073, "mdate": 1759897230967, "content": {"title": "Embodied Agents Meet Personalization: Investigating Challenges and Solutions Through the Lens of Memory Utilization", "abstract": "LLM-powered embodied agents have shown success on conventional object-rearrangement tasks, but providing personalized assistance that leverages user-specific knowledge from past interactions presents new challenges. We investigate these challenges through the lens of agents' memory utilization along two critical dimensions: object semantics (identifying objects based on personal meaning) and user patterns (recalling sequences from behavioral routines). To assess these capabilities, we construct Memento, an end-to-end two-stage evaluation framework comprising single-memory and joint-memory tasks. Our experiments reveal that current agents can recall simple object semantics but struggle to apply sequential user patterns to planning. Through in-depth analysis, we identify two critical bottlenecks: information overload and coordination failures when handling multiple memories. Based on these findings, we explore memory architectural approaches to address these challenges. Given our observation that episodic memory provides both personalized knowledge and in-context learning benefits, we design a hierarchical knowledge graph-based user-profile memory module that separately manages personalized knowledge, achieving substantial improvements on both single and joint-memory tasks.", "tldr": "", "keywords": ["Embodied agent", "Memory", "Agent", "LLM", "Personalization"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8857c24cd59dad2e084bc343ee229472f225909a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper provides an empirical analysis of memory utilization in embodied agents by evaluating them on the task of room rearrangement. It involves a memory acquisition stage and then a memory utilization stage. The model is evaluated along two dimensions of memory utilization: the ability to recall object semantics, and the ability to recall a user’s behavioral patterns. The work presents various controlled analyses to isolate the effect of memory on downstream performance, and highlights that current LLM-powered embodied agents can be good at retrieving information about object semantics, but struggle with aggregating multi-episodic memory to understand behavior patterns. Finally, they propose a graph-like structure to summarize user pattern behavior, and show that it improves performance across single-memory and multi-memory tasks, highlighting the need for better memory structure to enable personalized embodied agents."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The work addresses an interesting problem of personalization of embodied agents. Eventually, household agents would more likely than not exist around a user, and would require specializing to their needs. Memory is an interesting and useful component; the analysis done in this work can be useful guidance for future work. \n- The paper is very well written and makes it easy to follow and understand the results and the analysis presented. \n- I liked the idea of the graph-based hierarchical memory design to embed personal user behaviors; it seems to show clear improvement, at least in the current setup."}, "weaknesses": {"value": "- In Section 5.1, an analysis is conducted, which ablates the value of k, which is the number of retrieved memories. It seems to show that as the value increases how the performance of various agents decreases, credit to information overload. \n  - However, consider this: the overload is also indicative of the LLM’s lack of a longer context, which, once it goes beyond a certain number of memories, is unable to grasp and summarize this information, and hence resorts to general semantic knowledge, instead of personalized one.\n  - If the above were possible, perhaps a better way of measuring information overload could be to provide a more concise version of relevant information, and only increase the amount of direct clues about the user’s personal behavior, without increasing the information in-context too much."}, "questions": {"value": "- What happens if gold memory is not included? Can it work from noisy memory, could be useful analysis to know."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qjcw8e1qbE", "forum": "E5L43l5EIu", "replyto": "E5L43l5EIu", "signatures": ["ICLR.cc/2026/Conference/Submission16591/Reviewer_t5nh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16591/Reviewer_t5nh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16591/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761649393418, "cdate": 1761649393418, "tmdate": 1762926666265, "mdate": 1762926666265, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates how LLM-powered embodied agents handle personalization via memory, focusing on two dimensions: recognizing objects with user-specific semantics and recalling sequences of user behavioral patterns. The authors propose an evaluation framework named MEMENTO, including both single-memory and joint-memory tasks, and find that while agents can use simple object semantic memories, they struggle to incorporate sequential memory of user routines into planning. A deeper analysis identifies two main bottlenecks: information overload when too many memories are retrieved, and coordination failures when multiple memories must be integrated. To address these, the paper explores memory architectures and proposes a hierarchical knowledge-graph-based user-profile memory module that manages personalized knowledge separately."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper provides a systematic analysis of the memory utilization of LLM-powered agents for personalized scenarios, including multiple personal preferences.\n- Underperformance even with the top-k most relevant information for a specific personalization seems interesting.\n- The quantitative comparisons are conducted through diverse open- and closed-sourced LLMs."}, "weaknesses": {"value": "- It is unclear why the problem addressed in this paper is specifically related to embodied agents. Given that the issues (Sec. 3) and underperformances (Sec. 4 and 5) come from the incapabilities of LLMs, it looks more related to LLMs than embodied agents.\n- As it is explicitly given how some objects and routines are to be described, the problem addressed in this paper is rather related to using the context, which should not necessarily have to be personalization, provided well. In this sense, the term \"personalization\" seems misleading.\n- For the result in Figure 4, the authors argue that the current embodied agents struggle to comprehend user patterns, but I'm not fully convinced because the performance drops may come from the longer horizon of the user patterns than the one of the object semantics. This needs to be distinguished. In addition, as there is no clear performance gaps in object semantics, it is unclear if LLMs indeed suffers from using personalized information.\n  - The result in Figure 3 is somewhat related to this point for original/acquisition to single/joint memory utilization.\n- The evaluation metrics used in this paper seem to be inappropriate. The problem that the authors tackle in this paper is about how well LLMs can use personalized information given in the context, but the metrics used are about how well they complete the entire tasks, potentially including aspects beyond personalized memory utilization."}, "questions": {"value": "- For the joint memory, how many personalizations can be jointly used for some decent performance? Is there any quantitative analysis of the number of required personalizations with the corresponding performance of the downstream tasks?\n- Can the analysis be extended to scenarios where personalization indicators (e.g., \"That's my favoriate ...\" or \"It's my ...\") are not given? Addressing personalized information obtained from a set of videos might be a more practical scenario.\n- In Figure 6, some models improve when taking more retrieved samples. Why is this the case? As the current personalization addresses the mapping from an expression to a target object or a set of user patterns, where a single sample might be sufficient for their description."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "LBs5tlYxaz", "forum": "E5L43l5EIu", "replyto": "E5L43l5EIu", "signatures": ["ICLR.cc/2026/Conference/Submission16591/Reviewer_f2sq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16591/Reviewer_f2sq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16591/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994517598, "cdate": 1761994517598, "tmdate": 1762926665708, "mdate": 1762926665708, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the challenges LLM-powered embodied agents face in performing personalized assistance tasks, which require leveraging user-specific knowledge from past interactions (i.e., episodic memory). The authors introduce MEMENTO, a novel two-stage evaluation framework designed to quantify an agent's memory utilization capabilities. This framework assesses performance along two key dimensions: 'object semantics' (recalling personal meaning of objects) and 'user patterns' (recalling behavioral routines). Through experiments with a suite of modern LLMs (e.g., GPT-4o, Llama-3.1) , the authors find that while agents can recall simple object semantics, they significantly struggle to apply sequential user patterns. They identify two critical bottlenecks: 'information overload' from large retrieved memory sets and 'coordination failures' when handling multiple memories. Based on these findings, the paper proposes a hierarchical knowledge graph-based user-profile memory module that separates structured personalized knowledge from raw episodic memory, demonstrating substantial performance improvements."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The two-stage design (memory acquisition vs. utilization) provides a principled way to isolate memory effects from other capabilities, with identical goals but varying instructions across stages, enabling precise measurement of memory utilization through metrics.\n\n- The dataset construction process is rigorous with multiple quality controls.\n\n- The experimental analysis is comprehensive with insightful qualitative analysis"}, "weaknesses": {"value": "- The paper introduces the personalized object rearrangement task as a Partially Observable Markov Decision Process in Section 3.1. The actual agent implementation, however, is a hierarchical controller that uses an LLM as a high-level policy planner in a ReAct-style prompting format. The POMDP formalism and its associated equations feel disconnected from the practical, prompt-based system that is actually built and evaluated. The formalism is not explicitly used to derive the agent architecture or learning algorithm (as it's a zero-shot planner). This creates a minor mismatch between the stated mathematical grounding and the implementation.\n\n- The simplification of the full embodied agent problem means the episodic memory ($h_{acq}$) stored is \"clean.\" It's unclear how performance would be affected if the memory traces themselves were noisy due to perception errors. The proposed KG solution, which relies on clean, symbolic entity names, would also be challenging to implement without this oracle. \n\n- Missing analysis of how memory grows over time (all experiments use fixed 1-2 reference episodes)"}, "questions": {"value": "- What if object semantics and user patterns were stored as structured text templates rather than knowledge graphs? Would this achieve similar benefits with lower complexity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dGPdu0Hx4M", "forum": "E5L43l5EIu", "replyto": "E5L43l5EIu", "signatures": ["ICLR.cc/2026/Conference/Submission16591/Reviewer_KG3h"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16591/Reviewer_KG3h"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16591/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998042262, "cdate": 1761998042262, "tmdate": 1762926665282, "mdate": 1762926665282, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}