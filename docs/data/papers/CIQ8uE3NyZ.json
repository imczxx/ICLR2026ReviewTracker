{"id": "CIQ8uE3NyZ", "number": 12942, "cdate": 1758211872852, "mdate": 1759897475001, "content": {"title": "SELECT: Search-Enhanced Language Models for Analog Circuit Topology Generation", "abstract": "Automating analog circuit topology design is essential to reduce the extensive manual effort required to meet increasingly diverse and customized application demands. Recent advances have applied sequence-to-sequence fine-tuning on pretrained language models to directly generate circuit topologies from user specifications in a single pass. However, these one-shot generation methods failed to generate complex circuits due to their exponentially growing search spaces and limited training datasets. In this paper, we present SELECT, a search-enhanced language model framework that integrates simulator-guided Monte Carlo Tree Search (MCTS) with transformer-based decoding to use test-time computation for improved performance. SELECT introduces novel structural token pruning and P-UCB-based node selection to leverage next-token probability distributions to guide the search process. By combining pretrained priors with simulator feedback at inference time, SELECT converges faster than prior search methods and achieves significantly higher generation success rates, improving by up to 435\\% over RL-based search and 145\\% over LaMAGIC under a strict tolerance of 0.01.\nThese results establish SELECT as the first scalable framework for high-fidelity analog topology generation and a practical step toward LLM-driven circuit design automation.", "tldr": "", "keywords": ["Analog Topology Generation"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/42af12783e47c284593e0caee94189ca2edd3cbf.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work introduces a search-enhanced framework for automated analog topology generation that integrates simulator-guided Monte Carlo Tree Search (MCTS) with pretrained language-model decoding."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "SELECT is the first to incorporate search-based decoding into analog circuit generation\nSELECT achieves a 435%, 145% higher success rate under a low tolerance of 0.01 compared to an RL-search method Fan et al. (2021) and LaMAGIC Chang et al. (2024) with sampling and filtering at the same search budget."}, "weaknesses": {"value": "1. Clarification needed on circuit complexity claims\nThe characterization of 8–10 component circuits as \"complex designs\" may benefit from additional context. As reference:\n\nA basic single-stage cascode op-amp (Design of Analog CMOS Integrated Circuits, 2nd Ed., p. 350, Fig. 9.8) uses 8 components.\nThe classical two-stage op-amp from Ahuja et al. (1983) uses approximately 20 components (Fig. 3b) (An improved frequency compensation technique for CMOS operational amplifiers).\nMore recent designs, such as the switched op-amp from Young-Ju et al., use 34 components excluding biasing and CMFB (Fig. 5) (A 12 bit 50 MS/s CMOS Nyquist A/D Converter With a Fully Differential Class-AB Switched Op-Amp).\n\nIt would be helpful if the authors could clarify their definition of \"complex\" and provide comparative context relative to typical analog circuit design practice.\n\n2. Design space analysis requires more detailed justification\nFigure 1 presents a design space showing 100 topologies for 3-component circuits and 10,000 for 5-component circuits. To better understand this contribution, the authors should address:\n\nWhat proportion of these topologies are functionally viable?\nHow many represent meaningful design variations worth including in the training set?\nWhat criteria were used to filter the design space?\n\n3. Novelty claim needs supporting evidence\nThe claim that this work is \"the first time\" analog topology generation extends to 7–10 component circuits would benefit from a more comprehensive literature review. Specifically, it would be helpful to see:\n\nA systematic comparison with prior work (AnalogCoder, Lamagic, CktGNN, AnalogGenie, etc.)\nDocumentation of the maximum circuit complexity handled by these earlier methods\nClear delineation of what constitutes a substantive advance beyond prior work\n\n4. Relationship to existing MCTS-LLM methods needs clarification\nMCTS has been widely adopted in LLM-based code generation (e.g., \"Planning with Large Language Models for Code Generation,\" \"Large Language Models as Commonsense Knowledge for Large-Scale Task Planning\"). The paper would be strengthened by:\n\nDiscussing how the proposed approach differs from or builds upon these methods\nClarifying domain-specific adaptations required for analog circuit generation\nMore explicitly articulating the unique contributions beyond applying established MCTS-LLM techniques\n\n5. Reproducibility concerns\nThe absence of supplementary materials (code, datasets, or detailed implementation specifications) limits reproducibility. Providing these resources would significantly strengthen the contribution and enable the community to build upon this work."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "yrZ0qX5KTL", "forum": "CIQ8uE3NyZ", "replyto": "CIQ8uE3NyZ", "signatures": ["ICLR.cc/2026/Conference/Submission12942/Reviewer_v82m"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12942/Reviewer_v82m"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12942/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760641286103, "cdate": 1760641286103, "tmdate": 1762923703177, "mdate": 1762923703177, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work aims at improving the performance of automatic analog circuit topology design.\nThe main challenge of existing approaches is that they fail to generate complex circuits due to the exponentially growing search spaces and limited training datasets.\nThe main idea of this work is to leverage test-time computation to improve performance.\nSpecifically, it introduces token pruning, leverage next-token probability distribution to guide the search process, and uses simulator feedback at inference time."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The formulated problem is practical and valuable, which aims to generate complex analog circuit topology with more than six components.\n- The proposed method is reasonable and makes sense.\n- The writing is clear and easy to follow."}, "weaknesses": {"value": "- In lines 157-158, it is mentioned that there is an extended pipeline for data collection to build datasets for circuits with 7-10 components. What does extended pipeline mean? Are there any differences to the one used in LaMAGIC?\n- There is a runtime illustration for the proposed approach. What is the runtime for baselines? It seems that the proposed method is the most time-consuming one as it introduces model inference and simulator feedback in its workflow.\n- The base pretrained language model used in this work is Flan-T5-base, which is quite an old one. I acknowledge that this choice is adopted from LaMAGIC. However, the whole community of pretrained language models evolved very quickly. To make this work solid and up-to-date, new and stronger language models should be adopted (e.g., Qwen or Llama). Besides, a discussion about when base language model becomes stronger, whether the proposed challenges still exist and proposed method still work is valuable and important.\n- For the experiment in Section 6.4, are the two methods compared with the same time budget? Will random generation perform better if it was given more time budget?"}, "questions": {"value": "see above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "d1osLSyW7B", "forum": "CIQ8uE3NyZ", "replyto": "CIQ8uE3NyZ", "signatures": ["ICLR.cc/2026/Conference/Submission12942/Reviewer_ahJq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12942/Reviewer_ahJq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12942/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761820899655, "cdate": 1761820899655, "tmdate": 1762923702786, "mdate": 1762923702786, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework that combines a pretrained Transformer language model with Monte Carlo Tree Search (MCTS) and circuit simulation feedback to automatically generate analog power converter topologies. Unlike prior one-shot or reinforcement-learning methods, SELECT performs search-based decoding, where the language model guides MCTS to explore only the most promising next tokens while simulator feedback evaluates and backpropagates performance rewards. Key innovations include a probability-guided UCB (P-UCB) node selection strategy and structural-token filtering to improve efficiency. Experiments show up to 435% higher success rates than prior methods and demonstrate scalability to 7–10-component circuits."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "+ Novel integration of the LLM and search. SELECT is the first framework to combine a pretrained Transformer with Monte Carlo Tree Search (MCTS) for analog circuit topology generation.\n+ Extending the topology generation to 7–10-component converters is an important step to make the work more practical."}, "weaknesses": {"value": "- Overly exaggerated claim. For people who are familiar with analog circuit design, the paper made a serious overclaim of the generality of their method. Throughout the paper, experiment results are only provided for power converters, which are merely one type of analog/mixed-signal circuits. There is no evidence that directly supports or suggests that the proposed data representation or the language model formulation can be extended beyond the converter circuits. Another overclaim comes from exaggerating the accomplishment on extending the previous method from 3~5-component designs to 6~10-component designs. Fewer than 10-component analog circuits have been quite exhaustively studied by analog designers. Although a method to automate the generation of circuits with such a low component count may be of some theoretical interest, it is of little practical use.\n- Lack of a clear explanation of the algorithmic method. The paper does not provide sufficient details for the reviewer to fully grasp the relationship between the language model training/pretraining and the Monte Carlo Tree Search (MCTS) method with its various selection/expansion/evaluation steps. It is also very difficult to make sense of the baseline methods being compared with in the evaluation.\n- Unclear dataset construction detail. The paper never fully explains how the 7–10-component datasets were generated. For example, the number of rollouts, filtering thresholds, or simulation settings. This omission significantly limits reproducibility.\n- Poor writing and organization. The writing of the paper can be improved. In many places, simple typos greatly impede readability. For instance, for the number of components in each topology, the authors sometimes use numeric forms like “345,” sometimes hyphenated ranges like “3–5,” and sometimes words like “six.” Please ensure consistent formatting throughout."}, "questions": {"value": "Can you explain how the data representation and the training method in this paper can effectively be used for other types of analog circuits? Please give concrete examples.\n\nCan you give examples of 6~10-component converter designs generated by the proposed method? Do the generated designs follow well-known converter topologies? Are there novel topologies in the generated design that are non-obvious to human designers?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "6En6XGyEMg", "forum": "CIQ8uE3NyZ", "replyto": "CIQ8uE3NyZ", "signatures": ["ICLR.cc/2026/Conference/Submission12942/Reviewer_Tme7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12942/Reviewer_Tme7"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12942/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966349326, "cdate": 1761966349326, "tmdate": 1762923702353, "mdate": 1762923702353, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SELECT, a search-enhanced language model framework that combines transformer-based decoding with simulator-guided Monte Carlo Tree Search to improve analog circuit topology generation, demonstrating substantially higher success rates and scalability compared to prior methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed MCTS-based approach demonstrates superior performance in topology generation experiments, representing a promising direction for future research in this field.\n- The experimental evaluation is comprehensive and well-documented."}, "weaknesses": {"value": "- Figure 2 appears to have been adapted directly from LaMAGIC; it would be more appropriate for the authors to redraw the figure to ensure originality and consistency with their own work.\n- The proposed method seems less scalable than prior approaches, as it is only applied to power converter circuit topology generation. Power converters are not necessarily the most representative or critical circuits in analog research. The authors are encouraged to discuss or extend their method to other types of analog circuits.\n- Compared to one-shot generation methods, MCTS is computationally less efficient and requires numerous simulation runs, which may limit its practicality for real-world applications."}, "questions": {"value": "- In Figure 1, why are there no collected topologies for circuits with seven devices?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nZqHY2l8Sw", "forum": "CIQ8uE3NyZ", "replyto": "CIQ8uE3NyZ", "signatures": ["ICLR.cc/2026/Conference/Submission12942/Reviewer_MukN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12942/Reviewer_MukN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12942/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966725076, "cdate": 1761966725076, "tmdate": 1762923701078, "mdate": 1762923701078, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}