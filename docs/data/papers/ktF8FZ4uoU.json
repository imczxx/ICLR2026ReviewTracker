{"id": "ktF8FZ4uoU", "number": 23287, "cdate": 1758341754603, "mdate": 1762975222090, "content": {"title": "Label-Wise uncertainty decomposition for Multi-label Classification by Maximizing Type II Likelihood", "abstract": "Currently, the way deep learning models recognize uncertainty remains inconsistent with human perception. \nIn multi-label classification, quantifying uncertainty at the label level presents challenges, as each label may exhibit distinct model confidence levels. Understanding and decomposing label-specific uncertainty is essential for interpreting model behavior and ensuring reliable predictions. \nWe build a hierarchical Bayesian methodology for multi-label classification that leverages a Type II likelihood and Empirical Bayes. And then we estimate and decompose label-wise uncertainties by the law of the total variance. Our approaches offer four main contributions: (1) it is data centric, as Type II likelihood maximization ensures higher data likelihood; (2) it decomposes label-wise uncertainty into the model variance, the model bias and noise; (3) our uncertainty is intuitively interpretable when combined with observational data; and (4) when applied to out-of-distribution (OOD) detection task, it achieves a \\(~6.88\\%\\) lower FPR95 score than the second-best method on NUS-WIDE.", "tldr": "", "keywords": ["uncertainty estimation", "multilable classification", "Bayesian inference", "Evidential learning", "OOD"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/de822bb7638122fa74251270925b8c3940c3528a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces a Bayesian framework for multi-label classification, leveraging Type II likelihood to estimate label-wise uncertainty. The key idea is to predict Beta-distributed hyperparameters per label, enabling uncertainty decomposition into model variance, bias, and noise via bias–variance analysis. The authors claim interpretability and improved out-of-distribution (OOD) detection using Pascal VOC, COCO, and NUS-WIDE."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The use of Type II likelihood for multi-label uncertainty quantification is an interesting theoretical contribution that bridges Bayesian evidence approximation and evidential deep learning. The paper provides rigorous derivations linking the marginal likelihood, bias-variance decomposition, and learning criterion.\n\n2. The experimental improvements are empirically meaningful, and the proposed “Evidence2” score is intuitively motivated. Moreover, the qualitative examples are helpful in showing how label-wise uncertainty behaves and supports explanation."}, "weaknesses": {"value": "1. The experiments are relatively narrow in scope — mainly on Pascal VOC and NUS-WIDE — without ablation on different architectures, datasets, or scalability. The performance gains, while interesting, are modest and may not justify the added complexity.\n\n2. Key results depend on strong assumptions (e.g., sharply peaked posterior in Assumption 1, flat prior in Assumption 2). The practical effect of these approximations is not tested or discussed."}, "questions": {"value": "1. How sensitive are results to the Beta hyperparameter initialization or to the network’s scale?\n\n2. How does this method scale to larger label sets (e.g., 100+ labels or open-vocabulary tasks)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "VhCtf6uLUl", "forum": "ktF8FZ4uoU", "replyto": "ktF8FZ4uoU", "signatures": ["ICLR.cc/2026/Conference/Submission23287/Reviewer_uayy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23287/Reviewer_uayy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23287/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761277634920, "cdate": 1761277634920, "tmdate": 1762942590190, "mdate": 1762942590190, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "pkZKm1Vds0", "forum": "ktF8FZ4uoU", "replyto": "ktF8FZ4uoU", "signatures": ["ICLR.cc/2026/Conference/Submission23287/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23287/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762975221448, "cdate": 1762975221448, "tmdate": 1762975221448, "mdate": 1762975221448, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a method to model label-wise uncertainty in a multi-label classification setting. This is done by having a neural network learn the parameters of a Beta distribution for each class through optimization of a Type II Likelihood-based cross-entropy loss function. This approach is discussed in terms of propositions that describe the ‘’behaviour’’ of the method during learning, and a bias-variance decomposition. The bias-variance decomposition also gives rise to an uncertainty measure that is used in experiments. Empirically, the proposed method is evaluated by considering the predicted uncertainty for selected examples and by performing out-of-distribution (OOD) detection. In the latter experiment, the models achieves superior performance on two out of the three evaluated datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper tackles the important problem of multi-label classification. \n- The proposed approach achieves good results on selected examples and in the OOD experiments."}, "weaknesses": {"value": "- There is no mention / results of how the method actually performs in the multi-label classification task. Relevant metrics should be reported.\n- The method is only properly evaluated on OOD detection. It would benefit of a more extensive evaluation on different tasks such as, for example, selective prediction.\n- The paper does not adequately address how the drawbacks of evidential learning are addressed in the current work.\n- While the paper mentions multiple times that the label-wise uncertainty provides valuable insights, it is unclear how these insights can actually improve decision-making. As illustrated in Figure 1, the approach seems to produce meaningful label-wise uncertainty, but it is not discussed how this information can actually be used in a beneficial way. \n- No code is provided.\n- The figures are not good. For example, Figure 1 is very messy and hard to read. For Figures 3, 4, and 5 it is unclear what the maximum and minimum of the metric are; is e.g., a bias of 0.075 high or low?"}, "questions": {"value": "- Could you clarify how your paper addresses the problems with evidential learning, as mentioned in the introduction. \n- Why do the OOD measures proposed in Section 3.2 depend only on $a$ and not $b$? If, for example, both $a$ and $b$ are high, the model is actually not confident. Why is this a meaningful measure of uncertainty? \n- What concrete benefits does the label-wise uncertainty have in terms of tasks that use uncertainty?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OobWRgOUyh", "forum": "ktF8FZ4uoU", "replyto": "ktF8FZ4uoU", "signatures": ["ICLR.cc/2026/Conference/Submission23287/Reviewer_6MTF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23287/Reviewer_6MTF"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23287/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761934397840, "cdate": 1761934397840, "tmdate": 1762942589624, "mdate": 1762942589624, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors propose a hierarchical Bayesian framework for multi-label classification to address the limitations of conventional deep learning models in label-wise uncertainty quantification. Specifically, the authors propose to maximize Type II likelihood with Empirical Bayes and predicts hyperparameters of a Beta prior over Bernoulli label probabilities with a neural network. \n\nThe experiments are conducted on several benchmark datasets when the expeirmental results demonstrate improvments based on ResNet backbones. Some visual examples also illustrate how the decomposed uncertainty aligns with human reasoning."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The method is rigorously grounded in Bayesian inference, with proofs showing its superiority as a data-centric learning criterion and convergence properties for uncertainty components.\n* The decomposition, especially model bias, provides human-aligned insights into label-specific ambiguities, as evidenced by intuitive visualizations that reveal model \"nervousness\" in real-world scenarios.\n* The method extends evidential deep learning to label-wise heteroscedastic uncertainty without assuming label independence explicitly, outperforming baselines in accuracy and calibration on benchmark datasets."}, "weaknesses": {"value": "* The label dependencies are ignored when the binary relevance approach treats labels independently.\n* The method depends on approximations like highly peaked posteriors and flat priors, which may not hold for small or noisy datasets, risking inaccurate uncertainty estimates.\n* Maximizing Type II likelihood and decomposing uncertainty may increase training/inference costs compared to standard BCE, though not quantified, limiting scalability for large-scale applications."}, "questions": {"value": "* How does the proposed method perform when applied to datasets with extremely imbalanced label distributions?\n* What are the specific computational costs (e.g., training time, memory usage) associated with maximizing Type II likelihood compared to Type I likelihood?\n* How does the method handle missing or incomplete label information in the training data?\n* How does the model scale with an increasing number of labels or even with the extreme multi-label classification (XMC) tasks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "XrAyn9DgF9", "forum": "ktF8FZ4uoU", "replyto": "ktF8FZ4uoU", "signatures": ["ICLR.cc/2026/Conference/Submission23287/Reviewer_QoP1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23287/Reviewer_QoP1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23287/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989173695, "cdate": 1761989173695, "tmdate": 1762942589239, "mdate": 1762942589239, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a loss similar to the Dirichlet-based loss commonly used in EDL (evidence-based deep learning).\nThe proposed method is predicts the parameters of a Beta distribution per-label in multi-label classification setting, which are denoted by 'a', and 'b'. The variance of the Beta distribution is used for uncertainty quantification. Moreover, 'a' value is used for OOD detection.\nThe final objective for training becomes simply the cross entropy loss on the expected output of the predicted distribution $Beta(a,b)$, i.e. $\\frac{a}{a+b}$.\n\nIn summary, I'm rating this paper as  '2: reject, not good enough', but I'm open to change my score if the authors properly address my comments and concerns."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The introduction and the review of related work is insightful.\n- The quantitative and qualitative evaluations are to some degree convincing."}, "weaknesses": {"value": "- In Sec. 2.4. two losses are compared. First of all, the term 'Gibss classifier' refers to sampling one of predictors and reporting its predictions, instead of marginalising out the belief over predictors. So Gibbs classifier doesn't have any specific training objective, and is used to broadly refer to the afformentioned prediction strategy.\n- Proposition 1 is simply the Jenson inequality. Putting that aside, I don't see how general claims like 'develop a more compact connection with the underlying patterns present in the trainning set' can be made from $\\mathcal{L}_{Type II} < \\mathcal{L})_{Gibbs}$.\n- Assumptions 1-3 are somewhat reasonable, but the connection of each assumption to the derivations should be explicitly  mentioned. In other words, I don't see how they get connected to each proposition and derivation in the paper.\n- In Sec. 3.2. OOD samples are defined as images to which none of training set labels are assignable. But even in this case, since the setting is multi-label, the model can simply predict all zeros (i.e. no label assigned) with a high confidence if the input image is in-distribution (i.e. in-distribution in its commonly-used meaning) . Indeed, I don't see why the multi-label model has to express high uncertainty (or high 'a' value) for these instance.\n- Not included in score:\n  - Gramatical issue in line 49: 'While ... . Their method primarily'. The two sentences should be connected.\n  - Line 142, vague phrase \"deeper levels of uncertainty\"\n  - Line 189 \"The Assmuption 2\" ===> \"The\" is not needed.\n  - Line 335, vague phrase \"consistently patterned data points\"\n  - Line 382, \"The Figure 2\" ===> \"The\" is not needed"}, "questions": {"value": "Please refer to the comments in the 'Weaknesses' section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nM1mY0vHDV", "forum": "ktF8FZ4uoU", "replyto": "ktF8FZ4uoU", "signatures": ["ICLR.cc/2026/Conference/Submission23287/Reviewer_JgQc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23287/Reviewer_JgQc"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23287/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762119161236, "cdate": 1762119161236, "tmdate": 1762942588975, "mdate": 1762942588975, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}