{"id": "b7Ftp6U78i", "number": 11536, "cdate": 1758201121683, "mdate": 1763429797066, "content": {"title": "Inference-time scaling of diffusion models through classical search", "abstract": "Classical search algorithms have long underpinned modern artificial intelligence. In this work, we tackle the challenge of inference-time control in diffusion models—adapting generated outputs to meet diverse test-time objectives—using principles from classical search. We propose a general framework that orchestrates local and global search to efficiently navigate the generative space. It performs compute-efficient global exploration using breadth-first and depth-first tree search and employs a theoretically grounded, scalable local search via annealed Langevin MCMC. We evaluate our approach on a range of challenging domains, including planning, offline reinforcement learning, and image generation, and observe significant gains in both performance and efficiency over baseline methods. These results demonstrate that classical search offers a principled and practical foundation for inference-time scaling in diffusion models. By jointly scaling local and global search for the first time, our framework establishes a new Pareto frontier across challenging decision-making domains.", "tldr": "We propose a principled framework for inference-time scaling of diffusion models through classical search principles, with experiments in planning, RL and image generation.", "keywords": ["diffusion models", "inference-time scaling", "compositional generation", "search algorithms"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/26028c943ce855f4da7efed517cc24480bf44d56.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a unified framework for inference-time scaling of diffusion models by leveraging principles from classical search. The authors formulate the inference process as a combination of global and local search. For global search, they employ tree-search algorithms such as Breadth-First Search (BFS) and Depth-First Search (DFS) to efficiently identify high-quality modes in the generative space. To further refine sample quality beyond the base model's distribution, they introduce a theoretically-grounded local search based on annealed Langevin MCMC. The proposed method demonstrates superior or comparable performance across a range of challenging domains, including long-horizon planning, offline reinforcement learning, and image generation. The paper is supported by comprehensive empirical analyses of its design choices and a theoretical convergence analysis in the appendix."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- **Clarity and Thoroughness of the Proposed Method:** The paper provides a detailed and well-structured discussion of the proposed methods, both in the main text and the appendix. This thoroughness contributes to a clear and concrete presentation of their framework.\n    \n- **Comprehensive Empirical Analysis:** The authors systematically present and analyze the empirical results for each component of their method. For example, they methodically ablate the design choices for BFS (resampling, scoring, and tempering) and subsequently demonstrate the efficiency gains achieved through the introduction of DFS and local search.\n    \n- **Unified Framework for Inference-Time Scaling:** The paper successfully presents a unified framework that integrates global and local search strategies. This framework cohesively combines key functionalities essential for controlled generation, such as branching, exploration, backtracking, and optimization beyond the pretrained distribution."}, "weaknesses": {"value": "- **Large Number of Hyperparameters:** While powerful, the proposed integrated framework introduces a significant number of hyperparameters. These include the BFS tempering parameter () and number of particles, the DFS backtracking step size (​) and score threshold (), and the local search steps (​), among others. As indicated by the experimental results, performance is sensitive to the tuning of these parameters. The authors acknowledge this as a limitation in the \"Limitations and Conclusion\" section and suggest automatic tuning algorithms as future work. I agree with their assessment that this is a key area for improvement.\n    \n- **Fixed Backtracking Step Size $\\Delta_T$:** In the proposed DFS algorithm, when a sample's estimated score falls below a predefined threshold $\\delta$, the algorithm backtracks by adding a fixed amount of noise determined by the hyperparameter $\\Delta_T$​. However, the optimal amount of noise to inject may vary depending on the specific instance. In some cases, a small perturbation might be sufficient to escape a low-quality region, while in others, a near-complete restart from a higher noise level might be necessary. The current method lacks the flexibility to handle this adaptively. In contrast, other contemporary works have explored more dynamic approaches. For instance, Adaptive Bi-directional Cyclic Diffusion (ABCD) [1] addresses this by propagating particles across different noise levels to balance exploration and exploitation. Similarly, Monte Carlo Tree Diffusion (MCTD) [2] uses a selection policy inspired by MCTS to navigate the search space more dynamically.\n\n- **The Statement about the Use of Large Language Model:** The authors doesn’t state explicitly how they used LLM in their submission, which is guided in https://iclr.cc/Conferences/2026/AuthorGuide.\n    \n- **(Minor) Presentation Issues:**\n    - In line 200 on page 4, there appears to be a typo in the transition kernel notation: $xt-1$ should likely be written in LaTeX as $x_{t-1}$.\n\n[1] Lee, Gyubin, et al. \"Adaptive Cyclic Diffusion for Inference Scaling.\" _arXiv preprint arXiv:2505.14036_ (2025).\n\n[2] Yoon, Jaesik, et al. \"Monte carlo tree diffusion for system 2 planning.\" _arXiv preprint arXiv:2502.07202_ (2025)."}, "questions": {"value": "- Could you please provide an empirical ablation study on the backtracking hyperparameter $\\Delta_T$​? Understanding its sensitivity would be valuable for practitioners seeking to apply your method.\n    \n- Regarding the scoring functions in BFS, I understand that 'Difference' and 'Max' scoring account for the trajectory's history. Could you elaborate on the necessity of this? What are the specific advantages of scoring based on the trajectory history compared to only using the score from the current timestep?\n    \n- As mentioned in the \"Limitations and Conclusion\" section, using evolutionary algorithms for hyperparameter tuning is an interesting direction. However, an alternative direction for future work could be to further unify the three search strategies (DFS, BFS, and local search) to be controllable by a smaller, more concise set of core hyperparameters. I would be interested to hear the authors' thoughts on the feasibility and potential of such a direction."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "l3qBNWCYlU", "forum": "b7Ftp6U78i", "replyto": "b7Ftp6U78i", "signatures": ["ICLR.cc/2026/Conference/Submission11536/Reviewer_Vc1j"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11536/Reviewer_Vc1j"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11536/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761644670594, "cdate": 1761644670594, "tmdate": 1762922629308, "mdate": 1762922629308, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on inference-time control of diffusion models to generate samples that maximize given objectives. It combines global search via breadth-first and depth-first search and local search via annealed Langevin MCMC. The method is applied across planning, offline reinforcement learning, and image generation to demonstrate improved performance and efficiency over baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. It explores various design choices in inference-time scaling of diffusion models across global and local search and proposes a unified framework that jointly scales both global and local search.\n2. It proposes a method using depth-first search (DFS), which can adaptively allocate compute.\n3. Decomposed ablation on global search (Section 5.2) and local search (Section 5.3.1) shows the effectiveness and necessity of both methods.\n4. Experiment demonstrates that distilling TTS samples can be a powerful off-policy RL method. (I believe [1] has already done this, though they didn't use the term 'inference-time scaling', but referred to it as global and local optimization, so being the 'first' work seems inaccurate.)\n\n[1] MARK, Max Sobol, et al. Policy agnostic rl: Offline rl and online rl fine-tuning of any class and backbone. arXiv preprint arXiv:2412.06685, 2024."}, "weaknesses": {"value": "1. Usage of Langevin MCMC prevents applying local search for non-differentiable rewards or naturally expanding the method to discrete diffusions. There are other MCMC alternatives, such as Metropolis-Hastings variants (e.g., predictor-corrector), but the choice of Langevin MCMC isn't justified sufficiently.\n2. By reporting only a single reward value in image experiments, it's hard to tell whether there is severe reward hacking and the method is generating broken images. For instance, excessive guidance can achieve high reward but generate a broken image that is off the data manifold. Please provide additional metrics (e.g., additional preference score or FID) or qualitative results to show the proposed method is searching for high-reward samples on the data manifold."}, "questions": {"value": "1. The claim that local search via Langevin MCMC can 'go beyond base model', which repeatedly appears in the paper (Section 1 line 51-52, line 80-81, Section 4.2), may be misleading. Langevin MCMC still generates samples from the compositional distribution $p_0(x)f(x)^\\lambda$ where the support is a subset of the support of $p_0$. Thus, similar to global search, it's searching for high-reward samples in the support of the base model. Even if it can explore very low-probability (relative to the base model) regions, there seems to be no direct evidence in the paper.\n2. SVDD, DAS, and FK-Steering all fall under the umbrella of SMC. Categorizing them as BFS seems like simple reframing. Also, when resampling, does it consider log likelihood with respect to the base model, which is the case for DAS and FK-Steering?\n3. What is TTS in Section 5.3.2? Is it BFS + local search or DFS + local search?\n4. What's the purpose of double-verifier experiments? Solving reward hacking is an important problem, but the experiments don't demonstrate the additional benefit of the proposed BFS. It's rather just introducing an additional technique for a separate problem."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wrk5cUBGpE", "forum": "b7Ftp6U78i", "replyto": "b7Ftp6U78i", "signatures": ["ICLR.cc/2026/Conference/Submission11536/Reviewer_JCZg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11536/Reviewer_JCZg"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11536/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997604609, "cdate": 1761997604609, "tmdate": 1762922628922, "mdate": 1762922628922, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies inference-time scaling for diffusion models via: (i) a global search layer with a BF-style design space (tempering, scoring, resampling) meant to unify existing particle/tree methods; (ii) a DFS variant that backtracks to higher noise when a per-step verifier threshold is violated; and (iii) a local search layer using annealed Langevin MCMC. The authors also relate recurrent training-free guidance to Langevin MCMC in the small-step limit. Experiments span text-to-image (SD 1.5/SDXL/SSD-1B; CompBench), planning (PointMaze), and offline RL, plus a double-verifier trick for reward-hacking mitigation."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The various design choices for the BFS method are clearly presented and the studies help understand which components are helpful.\n- The threshold-based method is a useful modification for DFS that is practical, and experiments show it indeed scales up compute for harder problems as intended.\n- The theoretical result bridge that guided recurrence approximates annealed Langevin MCMC in the small-step limit.\n- The experiments span multiple domains including text-to-image generation, path generation in maze, and continuous control tasks for offline RL."}, "weaknesses": {"value": "My main reservations concern the strength of the paper’s contribution and significance, the clarity of exposition, and a few statements that seem potentially misleading or inaccurate.\n\n### Contribution\n\nThe global search methods BFS/DFS proposed in the paper largely seem to be an alternate perspective or modifications to existing methods, rather than fundamentally new algorithms\n\n- The authors acknowledge that FK-steering/DAS are instantiations of BFS, but I do not see what new insights are provided by this new framing. The design choices for BFS in Section 4.1.1 are essentially ablation studies on existing techniques: FK-Steering [1] explored current/difference/max potential functions (and showed that max performs best), and DAS [2] showed that SSP sampling and tempering help improve performance. This is somewhat corroborated by Table 2, where BFS scores on all tasks are within one standard deviation of DAS scores.\n- DFS modifies the fixed sequential noising/denoising procedure of SoP [3] with a threshold-based adaptive procedure, which is a useful modification, but it is again not a fundamentally new algorithmic contribution.\n\n### Experiments\n\n- **Comparison with SoP.** The paper tries to set apart DFS by stating that SoP uses “small noise injection for local exploration” as opposed to $\\Delta_t \\geq T/4$ for DFS. This is incorrect as SoP in fact uses $\\Delta_t = 0.78\\,T$. Please change this statement to accurately reflect prior work. In addition, despite the conceptual proximity, I find it a bit odd that there is no empirical comparison of DFS with SoP to understand the relative improvement of the proposed thresholding-based modifications.\n- **DFS results.** The claim in Section 5.2 that DFS outperforms BFS/Best-of-N with “up to 2x less computational cost” is slight overclaiming based on the results in Figure 3 (left). The difficulty vs compute discussion in Figure 3 (right) does not show the resulting improvement from the additional compute. Please include baseline scores across the difficulty levels so we can compare the base model vs DFS results.\n- **Hyperparameter burden.** The local search introduces step size and number of steps, DFS introduces threshold $\\delta_t$ and backtracking depth. The paper has reasonable sweeps in its experiments, but introducing this many hyperparameters introduces a burden for practical adoption, as discussed briefly in the limitations. Specifically, regarding the threshold parameter of the DFS method which is introduced in this paper: (1) it is defined as a time-dependent threshold $\\delta_t$, but it seems experiments use a constant value for all $t$? How should one vary this threshold with time? (2) This parameter generally seems hard to tune - given a new reward function with an arbitrary range, how shall a practitioner decide the suitable threshold value?\n- **Insufficient experiment details in the main paper.** Many crucial experimental details that should be in the main paper are provided in the appendix, making the experiments section very hard to read.\n    - Section 5.1 does not specify the prompt dataset used for evaluation. Appendix E.1 says the experiments used ImageReward prompts following the setting in [1], which actually used GenEval and DrawBench prompts for text-to-image. Please provide the correct citation to avoid confusion, and the prompt dataset should be specified in the main paper.\n    - Section 5.3.2 does not specify the number of recurrent steps for local search that are used in the offline RL experiments. This information is not provided in the appendix as well.\n    - Section 5.4 does not explain what the two different verifiers are used for ImageNet conditional generation; this information is only provided in Appendix E.5.\n\n### Clarifications/corrections on statements\n\n- Section 2 states that tree-search methods like [3,4] are special cases of the BFS framework. [3] seems closer to DFS as discussed later in the paper, and [4] does not map trivially to the BFS framework. An explanation to support this statement would be helpful.\n- Section 3.2 discusses sampling from product distributions. However, the wording here is a bit misleading - it seems to suggest simply adding the score functions is enough to sample from product distributions. Also, authors define $\\hat{q_t}(x_0)$ as a distribution on $x_0$ but the equation involves $\\hat{q}_t(x_t)$ as a distribution over $x_t$. The appendix has a detailed explanation, but the wording here should be changed to avoid misunderstanding.\n- The scoring functions for BFS use posterior mean predictions $x_{0|t}$ to get intermediate rewards at noisy states; asserting this “accounts for reward variation during sampling by considering not only the current reward but also its trajectory” is misleading since this prediction is specifically designed to *not* consider the sampling trajectories. Please qualify/modify this statement.\n- The paper could benefit from discussing some relevant works: [5] uses an MCTS-style tree search, and [6] is a particle-based method that uses Gibbs sampling. Both methods outperform FK-steering and/or DAS by a significant margin.\n\n*[1] Singhal, Raghav, et al. \"A General Framework for Inference-time Scaling and Steering of Diffusion Models.\" Forty-second International Conference on Machine Learning, 2025.*\n\n*[2] Kim, Sunwoo, Minkyu Kim, and Dongmin Park. \"Test-time Alignment of Diffusion Models without Reward Over-optimization.\" The Thirteenth International Conference on Learning Representations, 2025.*\n\n*[3] Ma, Nanye, et al. \"Inference-time scaling for diffusion models beyond scaling denoising steps.\" arXiv preprint arXiv:2501.09732 (2025).*\n\n*[4] Li, Xiner, et al. \"Dynamic Search for Inference-Time Alignment in Diffusion Models.\" arXiv preprint arXiv:2503.02039 (2025).*\n\n*[7] Jain, Vineet, et al. \"Diffusion Tree Sampling: Scalable inference-time alignment of diffusion models.\" The Thirty-ninth Annual Conference on Neural Information Processing Systems, 2025.*\n\n*[6] Dang, Meihua, et al. \"Inference-time scaling of diffusion language models with particle gibbs sampling.\" arXiv preprint arXiv:2507.08390 (2025).*"}, "questions": {"value": "- In Figure 3, why is DFS-0.9 slightly lower than DFS-0.7 for the same amount of compute? Intuitively, it seems that thresholds should generally provide more high quality samples.\n- In Figure 4 why why is best-of-N with 8 local steps worse across compute than BoN with 6 local steps?\n- How do the BFS/DFS + local search compare with existing methods in terms of wall-clock times?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dUNuPq8pWx", "forum": "b7Ftp6U78i", "replyto": "b7Ftp6U78i", "signatures": ["ICLR.cc/2026/Conference/Submission11536/Reviewer_TXqE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11536/Reviewer_TXqE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11536/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762196411162, "cdate": 1762196411162, "tmdate": 1762922628556, "mdate": 1762922628556, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a unified inference-time scaling framework for diffusion models that performs global exploration with BFS/DFS over the denoising tree and local refinement via annealed Langevin MCMC guided by a verifier. It clarifies and improves BFS-style methods (tempering, scoring, SSP resampling) and introduces the first adaptive DFS with verifier-threshold backtracking to allocate compute on demand. It demonstrates superior Pareto efficiency across image synthesis, planning, and offline RL, including policy distillation and a double-verifier to curb reward hacking."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- Principled, general framework unifying global tree search and local gradient-based MCMC; theory linking recurrence to Langevin MCMC with convergence insights\n- Algorithmic contributions: improved BFS design and novel adaptive DFS that scales compute by instance difficulty, substantially boosting quality per NFE\n- Strong empirical results and ablations across tasks; new Pareto frontier, competitive offline RL without retraining, effective policy distillation, and robustness via double-verifier"}, "weaknesses": {"value": "- The proposed BFS and DFS methods were shown to be effective across various scenarios. However, establishing a unified methodology with default hyperparameter settings (beyond TTS in RL tasks) would make the approach more practical for broader use.\n- No comparisons with more recent T2I diffusion models beyond SD1.5 and SDXL and recent baselines (e.g., [1]).\n- How stable is the proposed method against reward hacking without the double verifier? Since reward hacking is a critical issue, it should be clarified whether the double verifier is essential for robustness.\n\n---\n[1] Inference-time scaling for diffusion models beyond scaling denoising steps, CVPR, 2025"}, "questions": {"value": "- If the gradient-based guidance component were removed, could the proposed method generalize to discrete diffusion (e.g., MaskGIT, LLaDA)? Any results or insights on this would be valuable.\n- Could this approach be extended to Flow models as well?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "otyixsB0Aj", "forum": "b7Ftp6U78i", "replyto": "b7Ftp6U78i", "signatures": ["ICLR.cc/2026/Conference/Submission11536/Reviewer_KEXB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11536/Reviewer_KEXB"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11536/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762236839109, "cdate": 1762236839109, "tmdate": 1762922628156, "mdate": 1762922628156, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}