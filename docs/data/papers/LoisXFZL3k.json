{"id": "LoisXFZL3k", "number": 2927, "cdate": 1757301920147, "mdate": 1763632054518, "content": {"title": "Faithful Bi-Directional Model Steering via Distribution Matching and Distributed Interchange Interventions", "abstract": "Intervention-based model steering offers a lightweight and interpretable alternative to prompting and fine-tuning. However, by adapting strong optimization objectives from fine-tuning, current methods are susceptible to overfitting and often underperform, sometimes generating unnatural outputs.\nWe hypothesize that this is because effective steering requires the faithful identification of internal model mechanisms, not the enforcement of external preferences.\nTo this end, we build on the principles of *distributed alignment search (DAS)*, the standard for causal variable localization, to propose a new steering method: **Concept DAS (CDAS)**.\nWhile we adopt the core mechanism of DAS, *distributed interchange intervention (DII)*, we introduce a novel distribution matching objective tailored for the steering task by aligning intervened output distributions with counterfactual distributions.\nCDAS differs from prior work in two main ways:\nfirst, it learns interventions via weak-supervised distribution matching rather than probability maximization;\nsecond, it uses DIIs that naturally enable bi-directional steering and allow steering factors to be derived from data, reducing the effort required for hyperparameter tuning and resulting in more faithful and stable control.\nOn AxBench, a large-scale model steering benchmark, we show that CDAS does not always outperform preference-optimization methods but may benefit more from increased model scale.\nIn two safety-related case studies, overriding refusal behaviors of safety-aligned models and neutralizing a chain-of-thought backdoor, CDAS achieves systematic steering while maintaining general model utility.\nThese results indicate that CDAS is complementary to preference-optimization approaches and conditionally constitutes a robust approach to intervention-based model steering.", "tldr": "We propose Concept Distributed Alignment Search (CDAS), a DAS-inspired steering method featuring distribution matching objective and distributed interchange interventions. Through CDAS, we argue that model steering might be different from SFT.", "keywords": ["model steering", "mechanistic interpretability"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ebd33498c8e7bbeb2c6ed089edfe80865bf87556.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This works presents a new activation steering methods building up on the idea of distributed alignment search (DAS). Therefore, the authors introduce a novel distribution matching objective tailored for the steering task by aligning intervened output distributions with counterfactual distributions. Authors verify the proposed method on AxBench, two cases studies and also ablate the performance tradeoff of steering."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is **clearly written** and is easy-to-follow despite a lot of technical details\n- **Appealing formulation** with distribution matching to the counterfactual distribution. Only caveat is that it introduces another axis of data augmentations requirements to satisfy the training data need.\n- **Exhaustive experiments** over multiple benchmarks and various ablation studies, analyzing the benefits and limitations of CDAS. Overall, CDAS shows promising performance, especially under the fact that it seems to lead to less off-target effects than RePS (as confirmed in table 3) which seems to dominate performance-wise.\n- **Steering / Performance tradeoff experiment in table 3** — this aspect is heavily ignored in many papers and I appreciate this analysis. However I am not sure if overriding refusals is the most convincing steering axis to test in this setting, as refusals may happen rarely on these benchmarks. For instance, repeating this experiment on a safety relevant task would further strengthen the evidence."}, "weaknesses": {"value": "- **Noise in Experiments:** Some results seem quite noisy (e.g. Figure 1) — I would strongly recommend adding std. or confidence intervals to the remaining experiments.\n- **Tuned Factor Dependence:** Can you provide more intuition on why there is such a big difference between the unit factor and the tuned factor?\n- **Benefits with Scale:** The authors raise multiple time the argument that CDAS benefits with scale. Do you have an explanation for this? Especially as you present better performance scores for the 7B instead of the 80B model (in Table 2)"}, "questions": {"value": "- Why is DAS missing in the AxBench experiments?\n- Why do you choose the tuning factor differently for DAS/CDAS (based on Alpaca) compared to RePs? Is this the source of the performance discrepancy? \n- Figure 1C: Variance is huge and it seems to work only on one tested layer. Do you have an explanation for this? \n- Table 4: Is the fact that CDAS improves performance on tinyMMLU not an indicating that results might be very noisy? \n- Do trends between methods change in other data regimes (less or more data)\n- Do you match the amount of training data? All pairwise approaches basically use the double amount of data (when treating every prompt + response as one data point)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "eTJ4svNWeT", "forum": "LoisXFZL3k", "replyto": "LoisXFZL3k", "signatures": ["ICLR.cc/2026/Conference/Submission2927/Reviewer_xeJA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2927/Reviewer_xeJA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2927/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761663173049, "cdate": 1761663173049, "tmdate": 1762916445542, "mdate": 1762916445542, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces **Concept Distributed Alignment Search (CDAS)**, an intervention-based model-steering method extending *Distributed Alignment Search (DAS)* from causal variable localization. The method aims to identify concept-specific internal features rather than impose external preferences. Experiments on _AXBENCH_ and two safety case studies (refusal override and CoT-backdoor neutralization) show CDAS can maintain model utility and scales better with model size, though it does not consistently outperform preference-optimization baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Interesting conceptual shift linking steering with causal localization and interpretability.  \n- Comprehensive experiments across benchmarks and safety settings."}, "weaknesses": {"value": "I am very much an outsider to the “model steering” field, however, unfortunately, this paper does a weak job at presenting much needed context for new readers to appreciate the why and how of their manuscript\n\nMuch of the structure and writing assumes readers are familiar with extant work and understand their shortcomings\n\ne.g.,\n* [l42/46] how does “intervention-based” result in “optimization-based”?\n\n* [l52] what does “degenerate, repetitive generations” even mean?\n\n* [l55] why should the readers appreciate DAS, and the proposed extension CDAS, as “standard approach[es] for causal variable localization.” what does this even mean?"}, "questions": {"value": "- What explains the non-monotonic behavior in Fig. 1c?  \n- Please see questions above in weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "0DYi0hG9VT", "forum": "LoisXFZL3k", "replyto": "LoisXFZL3k", "signatures": ["ICLR.cc/2026/Conference/Submission2927/Reviewer_GoDb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2927/Reviewer_GoDb"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2927/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762103868217, "cdate": 1762103868217, "tmdate": 1762916445353, "mdate": 1762916445353, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Building upon the framework of distributed alignment search (DAS), the authors introduce Concept DAS (CDAS), a method that learns interventions via weakly supervised distribution matching between intervened and counterfactual outputs. CDAS facilitates bi-directional, data-driven model steering with fewer hyperparameters and enhanced stability. Through experiments on AxBench and various safety case studies—such as overriding refusal behaviors and neutralizing a chain-of-thought backdoor—the authors demonstrate that CDAS achieves faithful and scalable control while preserving the overall utility of the model. The approach serves as a robust complement to preference-optimization methods, offering an alternative pathway for effective model steering."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper tackles a compelling and timely problem, presenting a solution that is both concise and elegant. The manuscript is well-written and structured, making the methodology and results accessible. The authors conduct extensive experiments to validate CDAS, providing thorough comparisons with existing approaches. Detailed experimental protocols and results are available in the supplemental material, enhancing transparency and reproducibility."}, "weaknesses": {"value": "Despite its merits, there are a few aspects that require clarification or further analysis:\n\n(1) In certain experiments, CDAS underperforms relative to baselines (e.g., Tables 1 and 3). The authors should provide insights or hypotheses explaining these performance gaps.\n\n(2) It remains unclear under which conditions CDAS excels and under which scenarios it may fall short. A discussion of the limitations and situational strengths of the method would strengthen the paper."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "A4QdtwP3gO", "forum": "LoisXFZL3k", "replyto": "LoisXFZL3k", "signatures": ["ICLR.cc/2026/Conference/Submission2927/Reviewer_JHaq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2927/Reviewer_JHaq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2927/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762123384179, "cdate": 1762123384179, "tmdate": 1762916445113, "mdate": 1762916445113, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a new steering method called Concept Distributed Alignment Search (CDAS). It builds upon the Distributed Change Intervention (DCI) technique from the DAS method, combining it with a distribution-matching objective based on the Jensen–Shannon divergence. The method is evaluated on the AXxBENCH benchmark and two safety-related case studies focused on concept suppression."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The CDAS objective encourages the model to learn concepts that are aligned with the model’s overall output distribution under the concept-induced input. Consequently, supervision does not come directly from ground-truth responses, but rather from the model’s own internal distribution. This is an interesting idea, as it may lead to outputs that are more naturally aligned with the inherent responses of LLMs.\n\nIn the refusal override experiments, CDAS achieves the best KL divergence loss, while maintaining reasonable performance on the TruthfulQA and MMLU benchmarks. This suggests that the intervened model’s outputs remain close to the model’s natural response distribution."}, "weaknesses": {"value": "While the premise behind CDAS and its training objective is compelling, the results are mixed. For example, in the experiments presented in Table 1, CDAS achieves the best performance on Gemma-2-9 L20 under a tuned factor, outperforming all other methods. However, on other intervention layers and with smaller models (e.g., 2B), CDAS fails to surpass RePS—although it still outperforms DiM, BiPO, and, in two cases, Lang. \n\nIn the refusal override experiments, CDAS also underperforms on the smaller model. In the CoT experiments for neutralizing backdoors, CDAS successfully overrides malicious behavior, but only when applied to earlier layers; for later layers, the ASR increases sharply and exhibits large variance.\n\nParticularly in the experiments from Table 1, CDAS appears highly sensitive to the setup of the steering factor, which could make its application in practical scenarios cumbersome.\n\nWhile the authors provide quantitative comparisons of CDAS and alternative methods, it would be valuable to include an analysis of training stability and computational overhead (see specific questions below)."}, "questions": {"value": "As mentioned in the weaknesses, CDAS demonstrates somewhat mediocre performance across the evaluated tasks—sometimes surpassing other models or layer interventions, and sometimes falling behind—though potentially producing outputs more faithful to the underlying distribution of the LLM (as indicated by KL divergence). I appreciate that the authors acknowledge these nuances and discuss their method fairly, suggesting that CDAS may be preferable for larger LLMs or when preserving model utility is a key objective. I still believe CDAS is an interesting addition to the family of steering methods.However, I would appreciate deeper insights into the causes of its underperformance. For instance:\n\n- Why does CDAS perform worse on smaller models? \n- Is this due to model scale, or does it depend on the model family?\n- In Figure 1, why does the variance on the ASR task increase so sharply?\n\nA more detailed discussion of these points could significantly strengthen the paper.\n\nIn the same vein, I am curious how CDAS compares to other approaches in terms of training stability. Could the variance in Figure 1 be a result of collapsed or unstable training? How does the training objective behave across experiments? The authors acknowledge that CDAS is sensitive to the steering factor—could this sensitivity be related to the stabilization (or destabilization) of training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cE571Ws6sM", "forum": "LoisXFZL3k", "replyto": "LoisXFZL3k", "signatures": ["ICLR.cc/2026/Conference/Submission2927/Reviewer_haqH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2927/Reviewer_haqH"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2927/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762269047406, "cdate": 1762269047406, "tmdate": 1762916444808, "mdate": 1762916444808, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Global Response (1/2)"}, "comment": {"value": "We sincerely thank all reviewers for their work and constructive comments.\nHere we summarize the common concerns raised by reviewers; all other questions are addressed in responses to individual reviewers.\n\n> **Common concern 1**. Why does CDAS underperform on smaller models? (haqH, JHaq)\n\n**Short answer.**\nCDAS underperformance on smaller models stems from two causes: (1) the intrinsic representational characteristics of small models; (2) the JSD distribution matching objective.\n\nWe first initiate a conceptual discussion regarding why all SVs tend to have worse performance on smaller models than larger models.\nWe then present a new ablation to investigate which design choice causes CDAS to perform worse on smaller models: distribution-matching training objective or the DII intervention protocol.\n\n**Explanation.**\nWe observe a general positive correlation between the best SV performance and model scale in AxBench results.\nThis correlation is observed for CDAS, RePS, DiM and SAE alike, therefore this correlation probably reflects a property of the model rather than the SV.\nWe take the best steering score results of said methods from our manuscript and [R1], and show them as follows.\n\n| Method | Best score on 2B | Best score on 9B |\n| :----- | :--------------- | :--------------- |\n| CDAS   | 0.631            | 0.992 (+0.361)   |\n| RePS   | 0.756            | 0.892 (+0.136)   |\n| DiM    | 0.297            | 0.322 (+0.025)   |\n| SAE    | 0.177            | 0.191 (+0.014)   |\n\n**Ablation study.**\nCDAS consists of two key design choices: the DII *intervention protocol* and the JSD *training objective*.\nIn order to investigate which one causes CDAS to underperform RePS, the SOTA baseline, we conduct a **new ablation experiment**.\n\nTo make ablation possible, we introduce a new method, \"RePS with DII\", by replacing the training objective of CDAS with the RePS objective.\nIts formula is provided in Appendix D.\nComparing \"RePS with DII\" to CDAS/DAS allows us to study the effect of the training objective, while comparing \"RePS with DII\" to original RePS allows us to study the effect of the intervention protocol.\n\nLimited by time and computational resources, we narrow down the experiment scope to 10 random AxBench concepts, as well as two models of the Qwen-2.5 family: Qwen-2.5-3B and Qwen-2.5-7B.\nSteering score results are shown below.\n\n| Method      | Qwen-2.5-3B (fair) | Qwen-2.5-7B (fair) | Qwen-2.5-3B (oracle) | Qwen-2.5-7B (oracle) |\n| :---------- | :----------------: | :----------------: | :------------------: | :------------------: |\n| CDAS        |       0.397        |     **0.771**      |        0.566         |      **0.936**       |\n| RePS w/ DII |       0.066        |       0.085        |        0.108         |        0.148         |\n| RePS        |     **0.682**      |       0.700        |      **0.880**       |        0.892         |\n\n**Results interpretation.**\nIn order to investigate the *effect of the training objective across model scales*, please keep the intervention protocol constant and compare CDAS and \"RePS w/ DII\".\nBoth use DII interventions, but CDAS has a larger inter-model difference in steering score.\nThis indicates that the JSD training objective of CDAS is more influenced by model scale than RePS objective.\n\nIn order to investigate the *effect of the intervention protocol across model scales*, please keep the training objective constant and compare RePS to \"RePS w/ DII\".\nAlthough \"RePS w/ DII\" performance is consistently lower than RePS, there are no significant ($\\leq 0.04$) inter-model differences for both SVs.\nThis indicates that DII is a less influential factor for performance difference between model scales.\n\n**Takeaway.**\nCDAS underperformance on small models is primarily due to model scale and objective, not the DII intervention protocol."}}, "id": "npqKSTeUmT", "forum": "LoisXFZL3k", "replyto": "LoisXFZL3k", "signatures": ["ICLR.cc/2026/Conference/Submission2927/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2927/Authors"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission2927/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763629999897, "cdate": 1763629999897, "tmdate": 1763629999897, "mdate": 1763629999897, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Manuscript Revision Changes"}, "comment": {"value": "We thank all reviewers for their valuable feedback and comments. In response to the suggestions received, we have uploaded a revised version of the paper. Changes are highlighted in red.\nFor clarity and convenience, we summarize the changes below:\n\n* Added DAS results on AxBench (page 24, Table 10).\n* Added standard deviation or standard error to results of both case studies (Table 25, 26, 27, 34, 35).\n* Added benchmark experiment with the trigger for case study 2 (page 45)\n* Added CDAS/RePS results on AxBench task regarding one more model family: Qwen-2.5 (page 28).\n* Added new baseline method (\"RePS with DII\") to Appendix D to facilitate ablation studies (page 19).\n* Added \"RePS with DII\" results in case study 1 to study the effect of intervention protocol and training objective on steering performance and model utility preservation (page 40).\n* Added computational overhead analysis for steering vectors (page 20).\n* Revised Introduction section to make paper more accessible for new readers (page 1, 2).\n* Fixed typos."}}, "id": "uKDaqua2TB", "forum": "LoisXFZL3k", "replyto": "LoisXFZL3k", "signatures": ["ICLR.cc/2026/Conference/Submission2927/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2927/Authors"], "number": 19, "invitations": ["ICLR.cc/2026/Conference/Submission2927/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763632198733, "cdate": 1763632198733, "tmdate": 1763632198733, "mdate": 1763632198733, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}