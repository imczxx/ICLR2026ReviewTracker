{"id": "ysad1axY2i", "number": 12701, "cdate": 1758209584960, "mdate": 1759897493141, "content": {"title": "GAF-Pano: Zero-Shot Layout-Controlled Panorama Generation via Global Attention Fusion", "abstract": "Achieving both global semantic coherence and precise local layout control in wide-aspect-ratio panorama generation is an unresolved challenge with potential applications. Existing methods that synchronize independent views to generate panoramas often lack semantic coherence and struggle with fine-grained object placement, resulting in contextual artifacts and fragmented objects.\nWe introduce GAF-Pano, a training-free framework for zero-shot layout-controlled panorama generation. \nGAF-Pano integrates a Global Attention Fusion mechanism into a pre-trained layout-to-image model. Through a Global Context Synchronization, Fusion, and Dispatch workflow, it periodically aggregates latent features from all local views to construct a unified global context, performs multi-level attention computation over this context to achieve true fusion, and then dispatches the enriched global features back to each view, enabling coherent rendering of complex, holistic layouts. \nFurthermore, we introduce a conditional positional mask to resolve object repetition artifacts that often arise in large specified regions.\nOn a newly constructed yet challenging benchmark for panoramic layout control, GAF-Pano achieves superior performance in both layout fidelity and semantic coherence, faithfully generating complex panoramic scenes.", "tldr": "We propose a new image generation method to generate panoramas with layout control.", "keywords": ["panorama image generation", "layout controlled generation"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9bfd602e7363b6103fdff171fe3790f5f5fcc9c4.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a method for layout-conditioned panorama (wide aspect ratio images). It presents GAF-Pano, a training-free framework, that augments layout-to-image (L2I) diffusion models using a \"Global Attention Fusion (GAF)\" mechanism then enables semantic coherence of disjoint views during inference as well as improved spatial control. The methods builds on previous work that introduced similar fusion mechanisms for this task of layout-controlled generation, and shows improved quantitative and qualitative results."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Strengths\n- Well designed pipeline and training-free framework. The qualitative results are interesting and show improvement over baselines.\n- Qualitative results show good coherence\n- Benchmark (Pano Layout Bench) has value to the community"}, "weaknesses": {"value": "- The initial background/introduction of attention fusion is limited, and I found myself forced to re-read numerous times before properly grasping the concept. This is not a standard algorithm that readers should be expected to know, and greater care to improving the writing here should be made.\n- The “theoretical foundation” claimed in Section 3 is entirely qualitative. No mathematical analysis or justification is given, is it missing?\n- The contribution is somewhat limited, and primarily hinges on applying the fusion mechanism from [1]. The CPM is a key practical contribution, and therefore should be presented with importance in the main paper. I see the ablation in the supp, however I do not agree with the analysis: \"As illustrated in Figure 5 and confirmed by the quantitative results in Table 6, introducing CPM reduces object duplication and visual artifacts compared to the baseline (w/o CPM), while maintaining competitive layout fidelity and text-image consistency.\" While Figure 5 does show less artifacts/duplication, it is unclear how cherry picked these two results are in the larger benchmark, and Table 6 shows w/o CPM has better performance across the board, bringing into question the value of this contribution. \n- The description of baseline implementation is lacking. Authors reference Appendix A.1 for more details, however it is unclear how MAD is implemented, and how layout control is implemented for it.\n- The contribution of the benchmark is downplayed, moving details to the appendix, when it remains a main contribution of the work overall\n\n[1] Quattrini, Fabio, et al. \"Merging and splitting diffusion paths for semantically coherent panoramas.\" European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2024."}, "questions": {"value": "- My main question is to the value of CPM and the differentiation of this work to MAD. The contribution does not seem sufficiently novel and the value of CPM seems weak."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LtjBNeRsql", "forum": "ysad1axY2i", "replyto": "ysad1axY2i", "signatures": ["ICLR.cc/2026/Conference/Submission12701/Reviewer_ogCv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12701/Reviewer_ogCv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12701/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761706805680, "cdate": 1761706805680, "tmdate": 1762923531912, "mdate": 1762923531912, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed GAF-Pano, a training-free framework for zero-shot layout-controlled panorama generation. The framework integrates a Global Attention Fusion mechanism into a pre-trained layout-to-image model, using a Global Context Synchronization, Fusion, and Dispatch workflow (SFD) operating within the attention layers of the diffusion model. GAF-Pano aims to overcome the limitations of prior panorama generation methods in terms of global semantic coherence and fine-grained layout control. Ablation experiments and performance comparisons verify its effectiveness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper proposes a novel method that integrates the global attention fusion mechanism into a pre-trained layout-to-image model in a training-free manner, achieving high-precision control of panorama generation and further completing a wider range of tasks.\n\n2. Figures like Figures 2 and 3 are very cleverly chosen to illustrate the benefits of attention fusion and the motivation for this paper.\n\n3. Detailed ablation results are provided in the main text and supplementary materials, deeply analyzing the contributions of self-attention fusion, cross-attention and conditional position mask, and confirming the rationality of the method."}, "weaknesses": {"value": "1. Lack of recent key papers on panoramic image generation, such as PanFusion (Zhang et al., 2024) and DiT360 (Feng et al., 2025) — they are not cited or explicitly discussed. These works pursue very similar goals (maintaining semantic coherence and layout control in panoramic synthesis)\n\n2. The paper shows failure cases (Figure 11), but lacks quantitative error analysis, e.g., how often certain types of failures occur, or how they correlate with prompt/box complexity. This would put the robustness of the approach into context.\n\n3. The method is tailored and benchmarked for wide-aspect-ratio panorama generation. It is uncertain whether the core global fusion principle can be generalized to more arbitrary spatial arrangements, such as 360-degree panoramas."}, "questions": {"value": "1. Can the authors provide experimental comparisons with PanFusion or DiT360?\n\n2. For scenes with many objects (dense layouts), does this method scale well in terms of computational cost and consistency, or does performance degrade dramatically?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qZZ2uQC2vZ", "forum": "ysad1axY2i", "replyto": "ysad1axY2i", "signatures": ["ICLR.cc/2026/Conference/Submission12701/Reviewer_aV6y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12701/Reviewer_aV6y"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12701/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761757480472, "cdate": 1761757480472, "tmdate": 1762923531605, "mdate": 1762923531605, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the dual challenges of achieving global semantic coherence and precise local layout control in the generation of wide-aspect-ratio panoramic images. The authors identify that existing methods, which typically synchronize independent views, often suffer from object fragmentation and contextual artifacts, failing to provide fine-grained control over object placement.  \nTo solve this, the authors propose **GAF-Pano, a training-free, zero-shot framework**. The core innovation is the integration of a Global Attention Fusion mechanism into a pre-trained Layout-to-Image (L2I) model. The authors claim this mechanism activates a latent \"Global Semantic Modeling Capability\" within the model, enabling holistic planning across the entire panoramic canvas.  \nThis is implemented through a systematic **Sync-Fuse-Dispatch (SFD) workflow** operating within the attention layers at each diffusion sampling step. The workflow consists of three stages: (1) Sync: Aggregates latent features from all local views into a unified global context. (2) Fuse: Performs multi-level attention (self-attention for structure, cross-attention for semantics and layout) on this global context to merge information across views. (3) Dispatch: Propagates the globally-enriched features back to the individual local view pipelines.  \nAdditionally, the paper introduces a **Conditional Position Mask (CPM)** to mitigate object repetition within large bounding boxes. To rigorously evaluate their method, the authors constructed a new benchmark, **Pano-Layout-Bench**. Experimental results show that GAF-Pano significantly outperforms strong baselines like MultiDiffusion, SyncDiffusion, and MAD across various metrics, including layout fidelity (mIoU, AP), text-image consistency (CLIP Score), and style coherence (Intra-LPIPS)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **Fundamental breakthrough on the scaling problem**: The paper tackles a core bottleneck in panorama generation: the memory limitation that arises from scaling. As noted in the pre-experiment in Section 3, directly applying modern L2I models to wide-aspect-ratio canvases is practically infeasible due to prohibitive memory requirements. Existing joint diffusion methods like MultiDiffusion adopted a 'divide-and-conquer' approach by splitting the panorama into overlapping views. However, this workaround introduced a critical side effect of \"information fragmentation,\" leading to object segmentation and semantic inconsistencies.  \nThe primary strength of this paper is its precise diagnosis of this problem and its proposal of a fundamental solution that 'repairs' the existing paradigm. Instead of merely stitching views, GAF-Pano introduces **Global Attention Fusion**, which aggregates latent features from all views into a single global context before the attention operation. This overcomes the limitations of previous methods that reasoned independently on fragmented information, enabling the model to perform true \"holistic planning\" within a memory-efficient framework. This paradigm shift is the key contribution that unlocks both global coherence and precise local control at scale. From this perspective, the problem addressed is not just about layout control but the more fundamental challenge of scalability in generative models. The abstract would be more impactful if it mentioned this memory constraint before discussing global coherence.\n\n- **Step-by-step method**: The Sync-Fuse-Dispatch (SFD) workflow that implements this idea is logically structured into information aggregation (Sync), global reasoning (Fuse), and information propagation (Dispatch). Each component has a clear role and is explained in a step-by-step manner, making the methodology easy for readers to understand.  \n\n- **Experimental Validation**: Authors have conducted an impressive suite of experiments to validate their method's performance. Recognizing the lack of a standardized evaluation protocol, they constructed a new benchmark, Pano-Layout-Bench. According to Appendix A.7, this benchmark consists of 1,341 unique prompts across three aspect ratios (1:2, ... 1:4) and includes a diverse range of scene types and object distributions. The evaluation is comprehensive, using metrics across four distinct categories: Layout Fidelity (mIoU, AP), Text-Image Consistency (CLIP), Stylistic Coherence (Intra-LPIPS), and Visual Quality (Aesthetic Score). The User Study detailed in Appendix A.6 is particularly persuasive. In human evaluations, GAF-Pano overwhelmingly outperformed competing models across all dimensions, including layout fidelity, prompt consistency, style coherence, and overall visual quality."}, "weaknesses": {"value": "- The 'Related Work' is deficient in both structure and content. First, its placement in Section 5, rather than immediately after the introduction, disrupts the logical flow. Second, its content is misaligned with the paper's core topic. While the introduction correctly identifies MultiDiffusion, SyncDiffusion, GVCFDiffusion, PanoFree, and MAD as key prior works for comparison, the 'Related Work' section fails to provide any in-depth discussion of SyncDiffusion, PanoFree, or MAD. Instead, it offers a superficial list of general L2I models like ControlNet and GLIGEN. This omission makes it impossible for the reader to understand the novelty of GAF-Pano in the context of existing panorama generation research.\n- It's hard to grasp the framework flow when looking at core mechanism pipeline, in Fig. 2 and Fig. 4.\n- There are concerns about the implementation of the SyncDiffusion baseline. The main text refers to Appendix A.1 for details on how baselines were adapted for layout control, but the explanation in Appendix A.1.2 is superficial. The authors state in the introduction that SyncDiffusion uses a perceptual loss for smooth transitions, yet there is no mention of how this core mechanism was applied for layout control in the appendix. Furthermore, since SyncDiffusion is not inherently an L2I method, the lack of a specific explanation for how bounding boxes and object descriptions were integrated severely harms reproducibility.\n- Table 1 shows that GAF-Pano's performance improves substantially when using holistic prompts compared to background-only prompts. While Appendix A.2 and Fig.8 demonstrate that MultiDiffusion suffers from object duplication and fragmentation issues due to prompt leakage when using holistic prompts, there is insufficient explanation of why GAF-Pano is more robust to these problems. \n- The authors present GAF-Pano as a general framework applicable to pre-trained L2I models, but experiments are largely limited to a single model—SDXL-based IFAdapter. Even the limitations section in Appendix A.9 acknowledges that \"GAF-Pano is fundamentally constrained by the layout control capabilities of the underlying pre-trained layout-to-image model.\" While Figure 7 in Appendix A.1.1 qualitatively shows that GAF-Pano resolves direct generation failures across three different L2I models (InstanceDiffusion, IFAdapter, CreatiLayout), without quantitative comparison.\n- Appendix A.3 provides overall inference times and lacks analysis of memory overhead or layer-wise computational costs. In the 'Sync' step, which aggregates a global context, could potentially reintroduce a memory bottleneck."}, "questions": {"value": "- The SyncDiffusion baseline in Table 1 shows particularly low performance. Could you please provide the specific implementation details missing from Appendix A.1.2, particularly how the core 'perceptual loss' mechanism of SyncDiffusion was adapted for the layout control task?\n- Why does 'Related Work', not to discuss the key prior works (e.g., SyncDiffusion, MAD) that were mentioned in the introduction?\n- Is it possible to analyze the computational cost of each step in the S-F-D workflow?\n- The Conditional Position Mask (CPM) proposed in Section 4.3.2 depends on an **agent** for prompt classification. Could you please specify the mechanism of this agent (LLM-based?) and its classification accuracy on dataset?\n- Would you provide quantitative comparisons for GAF-Pano when integrated with different backbone models?\n- In Eqn 13, $SPM_i$ is a typo for $CPM_i$ ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Uu2inT1qOO", "forum": "ysad1axY2i", "replyto": "ysad1axY2i", "signatures": ["ICLR.cc/2026/Conference/Submission12701/Reviewer_4Stg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12701/Reviewer_4Stg"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12701/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761912265440, "cdate": 1761912265440, "tmdate": 1762923531216, "mdate": 1762923531216, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}