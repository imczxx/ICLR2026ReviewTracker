{"id": "4uPyOCeN6U", "number": 12644, "cdate": 1758209218145, "mdate": 1759897496515, "content": {"title": "TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them", "abstract": "The adoption of Large Language Models (LLMs) as automated evaluators (LLM-as-a-judge) has revealed critical inconsistencies in current evaluation frameworks. We identify two fundamental types of inconsistencies: (1) \\textit{Score-Comparison Inconsistency}, where lower-rated responses outperform higher-scored ones in pairwise comparisons, and (2) \\textit{Pairwise Transitivity Inconsistency}, manifested through circular preference chains ($A\\!>\\!B\\!>\\!C\\!>\\!A$) and equivalence contradictions ($A\\!=\\!B\\!=\\!C\\!\\neq\\!A$). We argue that these issues come from information loss in discrete rating systems and ambiguous tie judgments during pairwise evaluation. We propose \\textbf{TrustJudge}, a probabilistic framework that addresses these limitations through two key innovations: 1) \\textit{distribution-sensitive scoring} that computes continuous expectations from discrete rating probabilities, preserving information entropy for more precise scoring, and 2) \\textit{likelihood-aware aggregation} that resolves transitivity violations using bidirectional preference probabilities or perplexity. We also formalize the theoretical limitations of current LLM-as-a-judge frameworks and demonstrate how TrustJudge’s components overcome them. When evaluated with Llama-3.1-70B-Instruct as judge using our dataset, TrustJudge reduces Score-Comparison inconsistency by 8.43\\% (from 23.32\\% to 14.89\\%) and Pairwise Transitivity inconsistency by 10.82\\% (from 15.22\\% to 4.40\\%), while maintaining higher evaluation accuracy. Our work provides the first systematic analysis of evaluation framework inconsistencies in LLM-as-a-judge paradigms, offering both theoretical insights and practical solutions for reliable automated assessment. The framework demonstrates consistent improvements across various model architectures and scales, enabling more trustworthy LLM evaluation without requiring additional training or human annotations.", "tldr": "", "keywords": ["LLM-as-a-Judge", "LLM Evaluation", "Large Language Models"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/eebfb70d815babb8b394c1d63adce978e6ec0d65.pdf", "supplementary_material": "/attachment/c8eb4bd0acdeb0c44b3cf99c052428d9b1312c26.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a framework, TrustJudge, designed to alleviate inconsistencies within the LLM-as-a-Judge paradigm. The authors identify and define two primary issues: Score-Comparison Inconsistency and Pairwise Transitivity Inconsistency, and introduce probabilistic methods, namely distribution-sensitive scoring and likelihood-aware aggregation, to address them."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper tackles a significant and highly relevant problem. As LLM-as-a-Judge systems become more prevalent, understanding and mitigating their inherent inconsistencies is crucial for building trustworthy evaluation pipelines. The authors' focus on this issue is a valuable contribution to the field."}, "weaknesses": {"value": "1. The primary weakness of this work lies in the limited novelty of its core strategies. Several of the proposed techniques are extensions or reformulations of existing methods:\n    - The use of log probabilities for scoring is a known technique. The main contribution appears to be ensuring a properly normalized distribution by excluding non-score tokens, which is more of a **technical implementation detail** and is supported by modern LLM inference frameworks (e.g., vLLM). The likelihood-aware aggregation for pairwise comparison can be seen as a **straightforward extension** of this probability-based approach.\n    - Mitigating position bias by swapping response orders is a **standard practice** discussed in prior work [1]. The issue of **transitivity inconsistency** in pairwise comparisons has also been explored previously [2]. While there may be differences in the precise problem formulation and solution, the incremental contribution appears marginal. The manuscript would benefit from a more thorough discussion of these related works.\n\n2. The proposed **X-point scale** lacks demonstrated generalization and is likely to be heavily influenced by the specific tokenizer used by the judge model. For example, \"50\" can be tokenized to \"5\" and \"0\" in Qwen series LLM, making the proposed method inapplicable. Furthermore, the authors do not provide an empirical comparison to show whether this fine-grained scale performs better than a simpler probabilistic binary judgment (e.g., Like a yes-or-no [3]), which could be a more robust and less tokenizer-dependent alternative.\n\n3.  The analysis in Section 3, which concludes that discrete scoring systems suffer from information loss, addresses a well-understood phenomenon. It is intuitive that representing a full probability distribution with a single discrete score sampled from that distribution will result in a loss of information. This portion of the theoretical analysis does not **seem to offer a novel insight**.\n\n4. The application of perplexity (PPL) for resolving ties lacks a strong theoretical foundation. The proof in Proposition 3.2 seems to apply to any scenario where LLM outputs have unequal likelihoods, not just those measured by PPL. The core assumption that **a sequence with lower PPL corresponds to a higher-quality response aligned with human preference** is heuristic. It lacks a causal link and is not experimentally proven. Factors such as *response length, verbosity, or stylistic simplicity* could affect the PPL of a concatenated sequence without directly correlating with higher quality [4]. This weakness is further highlighted by the experimental results, where the PPL-based method is almost universally outperformed by the likelihood-based approach, which itself is a direct extension of using log probabilities.\n\n5. Readability of Figures: Figure 2 is difficult to interpret. A bar plot might be a more effective choice for visualizing this data.\n\n------\n### References\n[1] Zheng et al. \"Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena.\" NeurIPS 2023.\n\n[2] \"Language Model Preference Evaluation with Multiple Weak Evaluators.\" arXiv 2410.12869.\n\n[3] Li et al. \"Generative Verifiers: Reward Modeling as Next-Token Prediction.\" ICLR 2025.\n\n[4] \"What is Wrong with Perplexity for Long-context Language Modeling?\" ICLR 2025."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "1XJtgcNGOH", "forum": "4uPyOCeN6U", "replyto": "4uPyOCeN6U", "signatures": ["ICLR.cc/2026/Conference/Submission12644/Reviewer_gSy2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12644/Reviewer_gSy2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12644/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760778084481, "cdate": 1760778084481, "tmdate": 1762923486329, "mdate": 1762923486329, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper makes methodological advances towards addressing inconsistencies in LLM-as-a-judge systems, identifying two representative failure modes: Score-Comparison Inconsistency (when single-score ratings contradict pairwise preferences) and Pairwise Transitivity Inconsistency (when preference judgments form cycles or contradictions). The authors propose TrustJudge, a framework based on probabilities that:\n1. uses distribution-sensitive scoring to preserve information entropy and produce continuous expectations from discrete ratings, and\n2. applies likelihood-aware aggregation (perplexity-based or bidirectional probability methods) to resolve transitivity violations.\n\nThe authors conduct comprehensive experiments that show that their method can reduce the inconsistency metrics (both score-comparison conflicts and transitivity violations)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The paper presents extensive experiments across a diverse range of models (Llama-3, GPT-4o, Qwen, Gemma) and datasets (MT-Bench, ArenaHard), demonstrating generality.\n\n- The proposed method can be applied post-hoc, without retraining judges or requiring additional human supervision, a strong practical advantage for real-world usage.\n\n- The paper provides some theoretical intuition for why the TrustJudge framework yields more consistent rankings, grounding the empirical studies in a formal explanation about information preservation and entropy reduction.\n\n- The distribution-sensitive scoring mechanism introduces a simple but effective normalization trick: converting model-produced probabilities into logits before softmax normalization, ensuring a valid probability distribution."}, "weaknesses": {"value": "-\tThe explanation of the bidirectional probability-based aggregation method (Eq. 6) is difficult to follow. It would help to include a small, concrete example illustrating what p_order1 and 2 represent, and how m[k] is computed and interpreted.\n\n-\tThe notion of the “ambiguous regime” in Proposition 3.2 requires clarification. Does this term refer exclusively to tie cases, or does it also include cases where the LLM judge selects a winner with low confidence?\n\n-\tThe phrase “lower-rated responses outperform higher-scored ones” (see abstract) may confuse readers; make sure to include the reference to single-score and pairwise evaluations.\n\n-\tThe authors should clarify (Eq. 5) why comparing perplexities of two full orderings is preferable to simply comparing each response’s perplexity under the judge model individually."}, "questions": {"value": "Increasing score granularity clearly helps resolve inequality-type transitivity inconsistencies (ties), but does it also reduce circular inconsistencies? It would be informative to separate these two types of inconsistency in the results to show the impact of TrustJudge on each.\n\nIn experiments comparing TrustJudge with baseline LLM-as-judge setups, are the PPL-based and likelihood-aware aggregation strategies applied to all questions, or only to those where the baseline judge outputs a tie? I assume the former, but clarification in the paper would be helpful."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pUa8YupLDn", "forum": "4uPyOCeN6U", "replyto": "4uPyOCeN6U", "signatures": ["ICLR.cc/2026/Conference/Submission12644/Reviewer_nkL4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12644/Reviewer_nkL4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12644/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761853751463, "cdate": 1761853751463, "tmdate": 1762923485782, "mdate": 1762923485782, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on addressing two core inconsistencies in the LLM-as-a-judge paradigm: Score-Comparison Inconsistency and Pairwise Transitivity Inconsistency, which stem from information loss in discrete scoring systems and ambiguous tie judgments in pairwise evaluations. The authors propose TrustJudge, a probabilistic framework with two key components: 1) distribution-sensitive scoring and 2) likelihood-aware aggregation. Experimental results showing TrustJudge reduces Score-Comparison inconsistency and Pairwise Transitivity inconsistency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The paper makes a notable original contribution by systematically identifying and formalizing two fundamental inconsistencies (Score-Comparison Inconsistency and Pairwise Transitivity Inconsistency) in the LLM-as-a-judge paradigm—an issue not previously analyzed in a unified framework.\n\n* The work has practical and academic significance: practically, TrustJudge improves LLM-as-a-judge reliability (reducing inconsistencies while preserving accuracy) without extra training/annotations, making it scalable for real-world LLM evaluation and DPO training."}, "weaknesses": {"value": "* Novelty Gaps in Core Components: While the paper frames TrustJudge as innovative, key elements overlap with prior work without sufficient differentiation. \n\n* Insufficient Analysis of Limitation Impact:  it does not test how small models (e.g., 3B Llama-3.2) with weaker instruction comprehension fail to generate valid scores/comparisons—critical for a \"model-agnostic\" framework. \n\n* Theorem 3.1 proves information preservation for two-distribution cases but does not extend to multi-distribution scenarios (e.g., 3+ responses in transitivity checks)—a key use case for Pairwise Transitivity Inconsistency."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "O4uxpUQo7A", "forum": "4uPyOCeN6U", "replyto": "4uPyOCeN6U", "signatures": ["ICLR.cc/2026/Conference/Submission12644/Reviewer_C5zH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12644/Reviewer_C5zH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12644/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761882752232, "cdate": 1761882752232, "tmdate": 1762923484566, "mdate": 1762923484566, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work identifies two types of inconsistencies in LLM evaluation systems: score-inconsistency and pairwise-inconsistency. To address the inconsistency issues, the authors invents novel fine-grained/probabilistic scoring and perplexity/likelihood-based ranking methods and incorporate them into the proposed framework called TrustJudge. The  paper also provide a comprehensive theoretical proof and a series of experimental analyses on the effectiveness of the proposed the method. The results show TrustJudge and its components significantly reduce the evaluation inconsistencies in LLM-as-a-judge systems."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1 The problem formulation of evaluation inconsistencies is sound and convincing. This paper goes from a practical issue which is common but often overlooked to a carefully designed solution with a solid theoretical foundation. \n2  The scoring and ranking methods proposed to resolve the inconsistencies of scoring and comparison in LLM evaluation systems are well-formulated.\n3 The proposed system demonstrates good results on different LLMs and problem settings. This indicates the method is robust and may contribute to a large community.\n4 The paper is organized in a clear and logical structure."}, "weaknesses": {"value": "Some symbols are confusing and should be revised： e.g. (1) k is the size of subsets in def 2.2 while k also represents possible comparisons outcomes in eq(6); (2) \\Theta^{\\prime} is score set at line 157 and then become range at line 154 of Algorithm 1; (3) \"p_{R_1} and p_{R_2} constructed in eq (1)\" is depicted at line 235, but I do not see such definition in eq(1) at line 130."}, "questions": {"value": "To show the effectiveness of continuous probabilistic scoring alone, it possible to directly apply softmax on the 5-point scale granularity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CE7APharY2", "forum": "4uPyOCeN6U", "replyto": "4uPyOCeN6U", "signatures": ["ICLR.cc/2026/Conference/Submission12644/Reviewer_VUVV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12644/Reviewer_VUVV"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12644/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761883166684, "cdate": 1761883166684, "tmdate": 1762923484196, "mdate": 1762923484196, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}