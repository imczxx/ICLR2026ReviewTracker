{"id": "oeoCgcYIyf", "number": 8712, "cdate": 1758095658797, "mdate": 1759897768322, "content": {"title": "Coupled Transformer Autoencoder for Disentangling Multi-Region Neural Latent Dynamics", "abstract": "Simultaneous recordings from thousands of neurons across multiple brain areas reveal rich mixtures of activity that are shared between regions and dynamics that are unique to each region. Existing alignment or multi-view methods neglect temporal structure, whereas dynamical latent-variable models capture temporal dependencies but are usually restricted to a single area, assume linear read-outs, or conflate shared and private signals. We introduce Coupled Transformer Autoencoder (CTAE)—a sequence model that addresses both (i) non-stationary, non-linear dynamics and (ii) separation of shared versus region-specific structure,\nin a single framework. CTAE employs Transformer encoders and decoders to capture long-range neural dynamics, and explicitly partitions each region’s latent space into orthogonal shared and private subspaces. \nWe demonstrate the effectiveness of CTAE on two high-density electrophysiology datasets of simultaneous recordings from multiple regions, one from motor cortical areas and the other from sensory areas. CTAE extracts meaningful representations that better decode behavior variables compared to existing approaches.", "tldr": "We introduce a coupled transformer autoencoder that separates shared from private neural dynamics in simultaneous multi-area neuronal recordings.", "keywords": ["multi-region neural recordings", "shared/private disentanglement", "transformer sequence models", "coupled autoencoders", "latent variable dynamics", "Neuropixels", "neural dynamics", "representation learning"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5ad4b5bfc6a3ab40a81a2619fc9518e23f694afd.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors present an transformer-based autoencoder framework for modeling multi-region neural population data. The framework provides mechanisms for separately modeling shared and private variability across brain regions. The authors fit their model on two datasets - motor regions in monkey and multisensory regions in mouse - and analyze the information contained in the resulting subspaces."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "CTAE represents a step forward in the literature of multi-region neural modeling. This framework is powerful and flexible, easily extending to more than 2 regions without an explosion of parameters that other models face. There is additional flexibility in defining subsets of regions that should have shared latent spaces, elegantly encoded in a single matrix. The transformer architecture also naturally takes into account temporal delays between regions, which previous models struggled to do in a scalable manner. The fitting procedure uses standard approaches (Adam) without too many bespoke elements (just a warm-up schedule for the orthogonality loss).\n\nI appreciate that the authors explored the use of this model in two very different datasets: monkey vs mouse, motor vs sensory/cognitive areas, 2 vs 3 regions, etc.\n\nThe writing and figures are very clear."}, "weaknesses": {"value": "Results on real data are hard to interpret. For example, the authors state \"...the shared PMd–M1 subspace captured the dominant task-relevant signals. In contrast, DLAG tended to assign behaviorally relevant variance to both PMd and M1 private subspaces, potentially due to less effective separation between shared and private dynamics.\" While this feels intuitively true, it's impossible to know which model is \"more correct\". The example with the second dataset is even more complex, and hard to if these results are \"good\" or not. I'm wondering if there are other manipulations that can further highlight the benefits of this model. For example, what if you fit the model on data concatenated across the regions, such that there is just a single set of latents, and then use these latents to decode continuous hand position and target condition. How do these values compare to the private/shared subspaces? This sort of analysis would represent a \"baseline\" that is perhaps easier to compare to than DLAG or other existing models.\n\nFollowing the previous comment, this work could be strengthened considerably with simulated data. Can CTAE recover the ground truth when the model hyperparameters match those of the data generation process (e.g. number of latents)? How does performance change when the model hyperparameters are not matched (e.g. more/fewer latents)? How much data is actually needed to train the CTAE (under matched hyperparameters, say)? These questions should be explored more thoroughly with simulated data given the difficulty of interpreting the results on real data."}, "questions": {"value": "L85: is \"absent\" supposed to be here?\n\nThe authors claim one advantage of their framework is \"Generic downstream utility\", i.e. that the latent space is behavior agnostic. However, a robust line of work is developing that attempts to partition neural latents into \"behaviorally-relevant\" and \"behaviorally-irrelevant\". While directly addressing this is outside the scope of this work, I'm curious if the authors think there is room (and/or utility) in expanding their approach to encompass this desire for partitioned subspaces.\n\nAre the trials the same length in both datasets? If not, how do authors manage batches composed of different-length sequences during training?\n\nOne of the major benefits (in my opinion) of the transformer-based approach is that it automatically takes care of time delays between different regions, in a much more robust, adaptive, and elegant way than previous approaches. If this is indeed the case, the authors should highlight this advantage in the main text. How could one actually dive into this more deeply? If there is a way to infer trial-to-trial lags between regions that would be incredibly useful (and interesting to compare to the lags inferred by DLAG)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YXavLTQO2j", "forum": "oeoCgcYIyf", "replyto": "oeoCgcYIyf", "signatures": ["ICLR.cc/2026/Conference/Submission8712/Reviewer_TAyW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8712/Reviewer_TAyW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8712/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761659977637, "cdate": 1761659977637, "tmdate": 1762920516727, "mdate": 1762920516727, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose Coupled Transformer Autoencoder (CTAE) for modeling simultaneous recordings from multiple brain areas using transformer based encoder and decoder priors. CTAE can extract the shared and private representations between regions thus making it a more interpretable model for neuroscience to understand the interactions between different brain regions. The authors demonstrate the utility of CTAE on two electrophysiology datasets."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- CTAE uses a novel objective that explicitly encourages orthogonality between latent dimensions and also prevents region specific variance from leaking into the shared space. Compared to most of the other multi-region and multi-modal models in neuroscience, I like how principled the objective function has been constructed for a more clean way of ensuring the separation of shared and private latents.\n\n- The introduction of a transformer-based autoencoder for multi-region neural recordings is a unique contribution as far as I know. And this can act as a more flexible prior that can capture the necessary long range temporal dependencies that previous GP or RNN based models might not be able to.\n\n- CTAE is scalable to more than two regions, making it suitable for a variety of neuroscience datasets.\n\n- Clear organization and presentation."}, "weaknesses": {"value": "Although these are [1, 2,3,4] multi-modal models, I find them to be closely related in terms of capturing the interpretable shared and private latent representations in neuroscientific data. Did the authors consider comparisons to multi-modal models in neuroscience (e.g. modifying them to handle multi-region data for comparisons)?\n\n1. Vahidi, P., Sani, O. G., & Shanechi, M. M. (2025). BRAID: input-driven nonlinear dynamical modeling of neural-behavioral data. arXiv preprint arXiv:2509.18627.\n2. Schneider, S., Lee, J. H., & Mathis, M. W. (2023). Learnable latent embeddings for joint behavioural and neural analysis. Nature, 617(7960), 360-368.\n3. Gondur, R., Sikandar, U. B., Schaffer, E., Aoi, M. C., & Keeley, S. L. Multi-modal Gaussian Process Variational Autoencoders for Neural and Behavioral Data. In The Twelfth International Conference on Learning Representations.\n4. Yi, D., Dong, H., Higley, M. J., Churchland, A., & Saxena, S. Shared-AE: Automatic Identification of Shared Subspaces in High-dimensional Neural and Behavioral Activity. In The Thirteenth International Conference on Learning Representations."}, "questions": {"value": "Please refer to the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7lHYVtrH2e", "forum": "oeoCgcYIyf", "replyto": "oeoCgcYIyf", "signatures": ["ICLR.cc/2026/Conference/Submission8712/Reviewer_MYUp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8712/Reviewer_MYUp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8712/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761702630346, "cdate": 1761702630346, "tmdate": 1762920516334, "mdate": 1762920516334, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the need to have a model that can effectively disentangle the shared components that mediate inter-area interactions from private signals unique to each region for mechanistic insight and designing causal experiments. The authors present previous work and claim that single-area tools fail when they are applied to concatenations of recordings (essentially making the data multi-area). Furthermore, they also mention that recent efforts show a subset of latent dimensions actively participate in inter-area communication. This subspace is believed to be orthogonal to region-specific dynamics. Other CCA-based approaches treat timepoints as iid samples and discard dynamics. This shows the need for CTAE. \nRecorded neural activity across 2 brain regions is modeled as a nonlinear function of underlying latent dynamics specific to each region. \nS = shared dynamics, \nP^1 = dynamics local to region 1, \nP^2 = dynamics local to region 2\n\nThe model is a coupled autoencoder built on transformer blocks that disentangles shared and private representations. The loss function recovers latents that maximally represent the neural activity. Each encoder is a Transformer stack with self-attention layers that capture long-range, nonlinear temporal dependencies within a region. Each decoder employs standard Transformer cross-attention to reconstruct the original firing rates from its region’s latents. \n\nOverall model (Figure 2):\n2 regions of the brain have separate data. These 2 regions are assumed to be sending signals to each other. The data is smoothed and passed into its individual encoder. The encoder brings the dimensionality down to some inferred latent representation. Each of these latent rep vectors is multiplied by a weight mask, and the result is added to produce a single fused latent. This fused latent contains signals that are local to region1/2 and also shared across regions. To disentangle these signals, 2 separate decoders are used. \n\nLoss: they use 4 loss functions. \nReconstruction loss: so that the autoencoder reproduces its own region’s activity.\nShared-only reconstruction loss such that each decoder reconstructs neural activity from its region using only the shared representation. The authors do this to prevent the decoder from shifting information into private subspaces, leading to inaccurate representations. \nAlignment loss:  The shared latents are meant to capture only dynamics common to both regions. To enforce this, they align each encoder’s shared output to their average, ensuring consistency across regions and preventing region-specific variance from leaking into the shared space. \nOrthogonality loss. To encourage each latent coordinate to capture distinct, non-redundant structure.\n\nThey apply CTAE on the dorsal premotor cortex (PMd) and the primary motor cortex (M1) in macaque monkeys performing a standard delayed center-out reaching task with eight outward targets. \n\nThey evaluate their inferred latents on 2 simple linear decoding tasks: predict hand position, and predict target (out of the 8 targets). \nThey hypothesize that the shared latent space would encode a majority of behaviorally relevant information, particularly target identity. M1 would be for finer temporal structure related to movement, and PMd is for higher-order planning signals. \nThey find: the shared latent subspace captured with CTAE showed dominant task-relevant signals. DLAG, in contrast, tended to assign this behavioral info to both PMd and M1 private subspaces. \n\nFor the 2nd test dataset, they use data from S,C which integrates visual and tactile information and contributes to orienting behavior and whereas ALM encodes preparatory and choice-\nrelated activity during decision-making tasks. The shared subspace captures task-relevant features such as stimulus type and target side. They confirm these findings with CTAE, but they do not contrast it with any other method."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "the method is simple and scalable to more than 2 regions. It is also potentially useful for other kinds of time series data outside of neuroscience. 1 experiment’s comparison with DLAG shows that CTAE is better. 2nd experiment compares CTAE to known region functions and proves that the output from the model matches expectations of region behavior."}, "weaknesses": {"value": "1. comparison to other methods on only one dataset: For experiment 2 - the authors should have tested DLAG here as well. \n2. The interpretation of the results could be improved."}, "questions": {"value": "1. what is the meaning of different degrees of shared or private activity in each brain area, and should we be surprised when decoding a task-relevant variable succeeds in one case and fails in another?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5nqVtdhpn1", "forum": "oeoCgcYIyf", "replyto": "oeoCgcYIyf", "signatures": ["ICLR.cc/2026/Conference/Submission8712/Reviewer_W2Xz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8712/Reviewer_W2Xz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8712/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761875402001, "cdate": 1761875402001, "tmdate": 1762920515962, "mdate": 1762920515962, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new transformer-based autoencoder for modeling neural data collected from multiple brain regions, called CTAE. It deals with the disentanglement of each region's private latent and the shared latent well, resulting in a more biologically interpretable latent subspace and dynamic results."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The proposed method is intuitive and powerful.\n* The experiments and theoretical analysis are comprehensive, especially for the method extension to multiple regions and the real-world experiments."}, "weaknesses": {"value": "* There seems to be no synthetic experiment in the main paper.\n* The reconstruction loss is MSE, which means a Gaussian distribution. This is a technically inappropriate distribution for Poisson spike data, as assumed by the authors in line 54. The real-world dataset is also Poisson spike count."}, "questions": {"value": "* Why not directly require the shared latent subspace to be just one thing? What's the consideration of splitting them and then aligning them during training? Implementing such a model and other variants is easy and can be viewed as intermediate baselines.\n* Is there any theoretical conclusion about the uniqueness of the discovered latent?\n* For the reaching task dataset, what's the reason for assuming hand position is largely represented in the shared subspace?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LHllUUDm3X", "forum": "oeoCgcYIyf", "replyto": "oeoCgcYIyf", "signatures": ["ICLR.cc/2026/Conference/Submission8712/Reviewer_ULYq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8712/Reviewer_ULYq"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8712/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978575187, "cdate": 1761978575187, "tmdate": 1762920515616, "mdate": 1762920515616, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}