{"id": "MnToYQx9My", "number": 1904, "cdate": 1756963154800, "mdate": 1759898179611, "content": {"title": "IGU-LoRA: Adaptive Rank Allocation via Integrated Gradients and Uncertainty-Aware Scoring", "abstract": "As large language models (LLMs) scale to billions of parameters, full-parameter fine-tuning becomes compute- and memory-prohibitive. Parameter-efficient fine-tuning (PEFT) mitigates this issue by updating only a small set of task-specific parameters while keeping the base model frozen. Among PEFT approaches, low-rank adaptation (LoRA) is widely adopted; however, it enforces a uniform rank across layers despite substantial variation in layer importance, motivating layerwise rank allocation. Recent adaptive-rank variants (e.g., AdaLoRA) allocate ranks based on importance scores, yet typically rely on instantaneous gradients that capture only local sensitivity, overlooking non-local, pathwise effects within the same layer, which yields unstable and biased scores. To address this limitation, we introduce \\textbf{IGU-LoRA}, an adaptive-rank LoRA that (i) computes within-layer Integrated Gradients (IG) sensitivities and aggregates them into a layer-level score for rank allocation, and (ii) applies an uncertainty-aware scheme using exponential moving averages with deviation tracking to suppress noisy updates and calibrate rank selection. Theoretically, we prove an upper bound on the composite trapezoidal rule approximation error for parameter-space IG under a pathwise Hessian-Lipschitz condition, which informs the quadrature budget. Across diverse tasks and architectures, IGU-LoRA consistently outperforms strong PEFT baselines at matched parameter budgets, improving downstream accuracy and robustness. Ablations confirm the contributions of pathwise within-layer sensitivity estimates and uncertainty-aware selection to effective rank allocation.", "tldr": "This paper proposes IGU-LoRA, an adaptive-rank LoRA method that leverages integrated gradients and uncertainty-aware scoring to improve parameter-efficient fine-tuning of large language models.", "keywords": ["Low-Rank Adaptation", "Integrated Gradients", "Parameter-Efficient Fine-Tuning", "Uncertainty-Aware Scoring"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e9a414bf1003b8dc4b0cce65c7c747fd76bdbeb0.pdf", "supplementary_material": "/attachment/171d856a7e084882234ccdedd65ba5b14a0a8212.pdf"}, "replies": [{"content": {"summary": {"value": "This paper proposes IGU-LoRA, a parameter-efficient fine-tuning method that employs an adaptive rank mechanism. This paper has two main contributions but looks complex and hard to be followed by other researchers. It computes integrated gradients sensitivities within each layer and aggregates them into a layer-level score to enable adaptive rank allocation. Moreover, it introduces an uncertainty-aware mechanism based on exponential moving averages and deviation tracking to suppress noisy updates and ensure more stable rank selection. In addition, the method is supported by solid theoretical guarantees that justify the soundness of the proposed approach."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "[1]. The paper introduces IGU-LoRA, a new PEFT framework based on adaptive ranks.\n\n[2]. This paper integrates Integrated Gradients into LoRA. Unlike prior adaptive-rank methods, which rely on instantaneous gradients. This paper has sufficient novelty.\n\n[3]. The authors provide solid theoretical guarantees for their approach. They derive an upper bound on the approximation error for the integrated-gradient estimator, quantifying discretization and sampling errors. They also present a stability guarantee for their uncertainty-aware signal-to-noise ratio based scoring. These analyses add strong mathematical rigor and credibility to the method’s design"}, "weaknesses": {"value": "[1] The paper contains formatting issues. It uses the preprint template instead of the anonymous submission template.\n\n[2] The abstract on OpenReview still includes unprocessed LaTeX commands.\n\n[3] There are several typos in the paper. For example, Martix -> Matrix, and revealstructural -> reveal structural.\n\n[4] Some data statistics are insufficiently explained. For instance, the meaning of EU-LoRA is unclear and causes confusion.\n\n[5] The proposed method is overly complex, making it difficult for other researchers to reproduce or follow the approach.\n\n[6] The generalization is not clear. This paper does not report the performance on MMMU."}, "questions": {"value": "[1]. How about the performance on MultiModal Benchmark?\n\n[2]. How about the performance on diffusion model?\n\n[3]. What is the EU-LoRA in Table 5?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xHqvXAO9ow", "forum": "MnToYQx9My", "replyto": "MnToYQx9My", "signatures": ["ICLR.cc/2026/Conference/Submission1904/Reviewer_8KC4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1904/Reviewer_8KC4"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1904/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761299259236, "cdate": 1761299259236, "tmdate": 1762915939893, "mdate": 1762915939893, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces IGU-LoRA, an adaptive low-rank fine-tuning method for large language models (LLMs). IGU-LoRA computes the parameter importance using Integrated Gradients (IG) and combines it with exponential moving average smoothing and deviation tracking to develop an uncertainty-aware scoring mechanism. It then allocates rank budgets per layer by keeping the top singular values of the update $AB$ according to these IG-based scores. Consequently, IGU-LoRA improves upon LoRA, which uses a fixed rank across all layers, and AdaLoRA, which uses instantaneous gradient magnitudes to estimate importance. Theorem 1 provides a theoretical bound that supports the proposed approximation of the IG-based integral, while Theorem 2 establishes the statistical stability of the uncertainty-aware scoring. Empirical results show that IGU-LoRA achieves comparable or better performance over LoRA, AdaLoRA, DoRA, and other PEFT baselines across different benchmarks such as GLUE, BoolQ, and GSM8K."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well motivated and addresses the weakness of prior adaptive low-rank fine-tuning methods such as AdaLoRA. The authors provide a rich motivation for their new scoring mechanism based on IG and exponential moving average smoothing, and they conduct extensive experiments across a wide range of benchmarks and model scales."}, "weaknesses": {"value": "The paper’s contribution appears somewhat incremental given that it mainly replaces the gradient-based importance scores in AdaLoRA with IG-based scores. The theoretical results require strong assumptions that are unlikely to hold in practice, though the theoretical results do not constitute a substantial part of the paper’s overall contribution."}, "questions": {"value": "- My main concern is the sensitivity of the method to the hyperparameters $N$ and $M$, both are used in approximating the IG-based importance scores. The authors present a preliminary study for small values of $N$ in Table 4, but it is somewhat surprising that there is little performance decrease when $N$ decreases from $20$ to $4$. Could the authors provide more insight into why the fine-tuning performance appears not sensitive to $N$? Additionally, how is $M$ selected here and throughout the experiments?\n\t\n- The justification for using Eq (6) to approximate Eq (5) is unclear. If the approximation needs to be unbiased, shouldn't it include a factor of $N-1$ so that  $(N-1)\\cdot \\mathbb{E}{\\frac{\\partial \\mathcal{L}(\\alpha_k W)}{\\partial w_{ij}}}=\\sum_{k=1}^{N-1}\\frac{\\partial \\mathcal{L}(\\alpha_k W)}{\\partial w_{ij}}$? \n\t\n- Regarding the assumptions in the theoretical results, Theorem 1 assumes that $g_{ij}(\\alpha)$ is sub-Gaussian, but additional justification or discussion is needed. Since the loss function for LLMs training is highly nonlinear and complex, this assumption may be difficult to hold in practice. Theorem 2 assumes that $y_t$ are i.i.d. with same mean and variance parameters across $t$, which seems unrealistic given that $W$ is updated after every epoch. Some empirical evidence or discussion would be helpful.\n\t\n- For computational efficiency with large $N$, $M$ must be much smaller than $N$. In that case, Theorem 1 shows that the second term dominates the first, and the total error should be understood as $O(1/\\sqrt{M})$. This suggests $M$ is the more critical factor than $N$. It would be nice to see additional experiments that vary $M$ to confirm this.\n\t\n- Please use different notation for Eq (7) and Eq (11).\n\t\n- In Algorithm 1, clarify what $k$ means and what $P_{:,\\pi_{1:k}}$ in line 13 refers to. \n\nMinor comments:\n- Eq (3): $P_{kj}, Q_{jk} \\Rightarrow P_{ki}, Q_{ik}$.\n- Eq (4): $\\alpha(W-W^{(0)})\\Rightarrow \\alpha(W-W^{(0)}) + W^{(0)}$?\n- In Eq (9), (10), clarify how $\\bar{s}^{(t)}_e(w_{ij})$ and $\\bar{U}^{(t)}(w_{ij})$ are defined for $t=0$."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vl6DJEkmER", "forum": "MnToYQx9My", "replyto": "MnToYQx9My", "signatures": ["ICLR.cc/2026/Conference/Submission1904/Reviewer_FGvV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1904/Reviewer_FGvV"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1904/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761485280731, "cdate": 1761485280731, "tmdate": 1762915939551, "mdate": 1762915939551, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes IGU-LoRA, a novel adaptive low-rank PEFT framework for LLMs. The method addresses the limitations of existing PEFT approaches like LoRA and AdaLoRA, which either use fixed ranks across layers or rely on instantaneous gradients for rank allocation. IGU-LoRA introduces two key innovations:\n\n1. Integrated Gradients Sensitivity Scoring: A pathwise sensitivity measure that captures the global and long-term contributions of parameters within a layer, overcoming issues like gradient saturation and local bias.\n2. Uncertainty-Aware Mechanism: A scoring framework that uses exponential moving averages and deviation tracking to suppress noise and stabilize rank selection.\n\nThe paper provides theoretical guarantees for the IG approximation error under a Hessian-Lipschitz condition and demonstrates IGU-LoRA's superior performance across diverse tasks and architectures. Empirical results show consistent improvements in accuracy and robustness over strong PEFT baselines, with comparable memory and computational efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The use of integrated gradients in the parameter space for rank allocation is a novel and impactful idea, addressing key limitations of gradient-based approaches.\n\nThe paper provides a solid theoretical foundation for the proposed method, including error bounds for IG approximation and stability guarantees for the uncertainty-aware scoring.\n\nThe method is evaluated on diverse benchmarks (e.g., GLUE, mathematical reasoning, and common-sense reasoning tasks) with multiple backbone models, demonstrating its robustness and generalization."}, "weaknesses": {"value": "While IGU-LoRA achieves strong performance, the use of integrated gradients introduces additional computational costs compared to simpler methods like LoRA. This could limit its scalability to extremely large models or real-time applications.\n\nWhile training efficiency is discussed, the impact of IGU-LoRA on inference latency is less emphasized, which could be relevant for deployment scenarios."}, "questions": {"value": "What is EU-LoRA in table 5?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "P5K5UT0ZOY", "forum": "MnToYQx9My", "replyto": "MnToYQx9My", "signatures": ["ICLR.cc/2026/Conference/Submission1904/Reviewer_oiw5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1904/Reviewer_oiw5"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1904/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761687645196, "cdate": 1761687645196, "tmdate": 1762915939222, "mdate": 1762915939222, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces IGU-LoRA, an adaptive variant of LoRA that allocates ranks across layers using Integrated Gradients (IG) computed in parameter space, combined with an uncertainty-aware scoring mechanism. The method aims to overcome the limitations of existing adaptive LoRA approaches that rely on instantaneous gradients. The authors provide theoretical bounds on the approximation error of the IG estimator and the stability of their uncertainty-weighted score. Empirically, IGU-LoRA is evaluated on GLUE and several reasoning benchmarks, showing consistent improvements over strong PEFT baselines like AdaLoRA and DoRA."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. good theoretical contribution. The error bound for the stochastic IG approximation and the stability guarantee for the SNR-based score are welcome additions.\n2. IGU-LoRA maintains comparable training/inference latency and memory usage to baselines while delivering better performance\n3. novelty in importance score, addresses critical limitations like gradient saturation and unstable rank allocation, with clear theoretical justification for IG approximation error."}, "weaknesses": {"value": "1. While experiments include Llama-3-8B, results for models larger than 10B parameters (e.g., Llama-3-70B) are absent. Given that PEFT is most critical for very large LLMs, this limits confidence in IGU-LoRA’s scalability.\n2. The method requires O(N) gradient evaluations per parameter group during training, which is downplayed but still significant, especially for larger models. \n3. What worries me the most is that due to the use of gradient accumulation, the training process of the model can be heavily influenced by factors such as the order of sample shuffling and the size of the batch. This raises significant concerns for me, as slight changes or randomness in the training setup could drastically affect the training outcomes. For the training of large language models (LLMs), this is unacceptable—training the same model with the same data could result in completely different importance scores for the same samples simply because of differences in sample order."}, "questions": {"value": "1. How would IGU-LoRA perform on models with 30B+ parameters? What is the expected training time and memory overhead compared to standard LoRA or AdaLoRA?\n2. How sensitive are the results to the number of IG samples (N and M)\n3. The author needs to thoroughly explain the impact of sample order and batch size on the results, supplemented with corresponding experiments and theoretical analysis. If these factors do not affect the results, why would different samples accumulate gradients with the same score? If they do have an impact, what is the training variance, how significant is the influence of batch size and shuffle order, and are there any visual comparisons of the score differences obtained for the same sample?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZhK2i20Gc1", "forum": "MnToYQx9My", "replyto": "MnToYQx9My", "signatures": ["ICLR.cc/2026/Conference/Submission1904/Reviewer_4NAn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1904/Reviewer_4NAn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1904/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761894524141, "cdate": 1761894524141, "tmdate": 1762915938613, "mdate": 1762915938613, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes IGU-LoRA, an adaptive rank allocation method for PEFT of LLMs. It integrates Integrated Gradients (IG) to compute within-layer parameter sensitivities and introduces an uncertainty-aware scoring mechanism based on exponential moving averages. The approach aims to overcome the instability and bias of gradient-based rank allocation methods such as AdaLoRA. Theoretical results include an error bound on the trapezoidal approximation of IG under a Hessian-Lipschitz condition. Empirically, IGU-LoRA shows consistent improvements over LoRA, AdaLoRA, and DoRA across GLUE, BoolQ, ARC, and GSM8K benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper introduces a new importance-scoring mechanism that replaces instantaneous gradient magnitudes with parameter-space IG.\n2. The experimental evaluation is comprehensive, covering multiple model scales (RoBERTa-large, Qwen-2.5-0.5B, Llama-2/3, DeepSeek) and diverse benchmark types."}, "weaknesses": {"value": "1. In the example of Figure 2(b), any two parameter curves with the same integrated area would yield identical importance scores under Eq. (4). Consequently, the IG formulation cannot distinguish between parameters that are early-important and those that are late-important along the training.\n\n2. Missing Recent Baselines. The paper omits several recent and closely related adaptive-rank methods, such as GoRA [1] (gradient-driven adaptive rank adjustment) and SalientLoRA [2] (saliency-based rank allocation). \n\n[1] Gora: Gradient-driven adaptive low rank adaptation. NeurIPS 2025.\n\n[2] Unveiling LoRA Intrinsic Ranks via Salience Analysis. NeurIPS 2024.\n\n3. Some hyperparameters, such as $\\beta_1$ and $\\beta_2$ in Eq. (10), are not explicitly reported. Moreover, although Theorem 2 provides a stability guarantee under the condition $t \\ge t_{\\mathrm{burn}}$, the paper does not explain how this condition is verified or ensured in practice during training.\n\n4. Eq. (4) assumes a zero baseline $\\mathbf{W}^{(0)} = 0$, but the physical meaning of a zero-weight baseline is unclear for pre-trained models whose parameters are already non-zero. Should the pre-trained weights instead serve as the baseline? Furthermore, a key assumption of IG is path independence; yet, in a non-convex loss landscape, the straight-line path from 0 to $\\mathbf{W}$ may not be meaningful or optimal. The paper does not analyze how different integration paths (e.g., stochastic or learned trajectories) might affect the resulting importance estimates.\n\n5. Insufficient justification for division-based SNR vs. AdaLoRA's multiplication: The paper uses $\\mathrm{SNR} = \\frac{\\bar{s}_e}{\\bar{U}} \\quad (\\text{Eq. 11})$, interpreting uncertainty as \"noise\" to be penalized. However, AdaLoRA uses multiplication $s = \\bar{I} \\times \\bar{U}$, interpreting uncertainty as \"task diversity\" to be rewarded. Table 4 shows only 0.32% improvement over multiplication (57.99→58.31), suggesting the choice may not matter much for these tasks."}, "questions": {"value": "1. The reproduced results for some baseline methods differ substantially from those reported in the original papers, despite using the same model architectures and datasets. It would be helpful if the appendix could include detailed evaluation settings, such as whether multiple-choice questions are treated as open-ended generation or evaluated by choice-probability ranking. In addition, the statement “Each task is run with 5 different random seeds, and we report the median test performance.” is unconventional. Since five independent runs are already conducted, it would be more informative to report the mean ± standard deviation, which is the common practice for measuring performance stability and variance across seeds.\n\n2. How sensitive is the final performance to the number of mini-batches M used for importance estimation in Algorithm 1? Has a sensitivity analysis been conducted to quantify how varying M (e.g., smaller or larger batch groups) affects both the stability of the importance scores and downstream accuracy?\n\n3. The contribution of this paper is mainly a new importance-score method, and I hope it really is very important. Could the authors perform an ablation experiment to verify the interpretability of the proposed importance scores? Specifically, if a parameter (or singular direction) with a very high IG-based importance score is forcibly assigned a rank of zero (i.e., removed), does the model performance drop sharply? Such an experiment would provide more direct evidence that the IG-derived importance values truly capture critical structural contributions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Zo6kv5MZ65", "forum": "MnToYQx9My", "replyto": "MnToYQx9My", "signatures": ["ICLR.cc/2026/Conference/Submission1904/Reviewer_bPkZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1904/Reviewer_bPkZ"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission1904/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761895979707, "cdate": 1761895979707, "tmdate": 1762915938237, "mdate": 1762915938237, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}