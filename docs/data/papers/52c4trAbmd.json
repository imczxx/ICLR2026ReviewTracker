{"id": "52c4trAbmd", "number": 8302, "cdate": 1758077984709, "mdate": 1759897793363, "content": {"title": "AutoTool: Dynamic Tool Selection and Integration for Agentic Reasoning", "abstract": "Agentic reinforcement learning has advanced large language models (LLMs) to reason through long chain-of-thought trajectories while interleaving external tool use. Existing approaches assume a fixed inventory of tools, limiting LLM agents' adaptability to new or evolving toolsets. \nWe present AutoTool, a framework that equips LLM agents with dynamic tool-selection capabilities throughout their reasoning trajectories.\nWe first construct a 200k dataset with explicit tool-selection rationales across 1,000+ tools and 100+ tasks spanning mathematics, science, code generation, and multimodal reasoning. Building on this data foundation, AutoTool employs a dual-phase optimization pipeline: (i) supervised and RL-based trajectory stabilization for coherent reasoning, and (ii) KL-regularized Plackett–Luce ranking to refine consistent multi-step tool selection.\nAcross ten diverse benchmarks, we train two base models, Qwen3-8B and Qwen2.5-VL-7B, with AutoTool. With significantly fewer parameters, AutoTool consistently outperforms advanced LLM agents and tool-integration methods, yielding average gains of 6.4\\% in math \\& science reasoning, 4.5\\% in search-based QA, 7.7\\% in code generation, and 6.9\\% in multimodal understanding. In addition, AutoTool exhibits stronger generalization by dynamically leveraging unseen tools from evolving toolsets during inference.", "tldr": "", "keywords": ["Tool Selection", "Agentic Reasoning"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5adac19fe5dbfbe519c72c7c908a1f1d3f0533a9.pdf", "supplementary_material": "/attachment/6037925133ef396d9d76271c81b05a395cd9f5ba.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces AutoTool, a method designed to evoke dynamic tool selection and integration in LLM reasoning, aiming for development of robust LLM agents under evolving toolsets. AutoTool constructs a 200k agentic reasoning dataset that contains a wide collection of tools and tasks, with tool-selection rationales. Based on that, it develops a dual-phase training scheme for LLM agents, including a SFT + RL phase to stabilize the learning of tool-integrated reasoning trajectories, followed by a KL-regularized Plackett–Luce (PL) ranking phase to refine the tool-selection part of the reasoning. AutoTool achieves performance gains on two LLMs (Qwen3-8B and Qwen2.5-VL-7B) in a diverse set of reasoning tasks, outperforming other advanced\nLLM agents and baseline tool-integration methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- AutoTool innovatively integrates embedding-anchored tool selection and KL-regularized PL ranking into the learning of LLM agents, which contributes to decent originality.\n- The presentation of AutoTool dual-phase learning scheme is theoretically well-motivated and mathematically well-grounded.\n- AutoTool’s proposed challenge of dynamic tool selection under evolving tool environments is crucial for robust and scalable LLM agentic framework development."}, "weaknesses": {"value": "- The experimental analysis of this paper falls short of justifying AutoTool’s effectiveness on improving dynamic tool selection under evolving tool environments, i.e., whether AutoTool performs better tool selection when generalizing to unseen toolsets, which is however the most significant challenge raised by the paper. Evaluation on a new or heldout set of tools and tasks that are unseen at training phase would help further justify this important point.\n- It is unclear how the evolving toolset T with dynamic size is constructed for AutoTool learning, i.e., for each training sample or question, which candidate tools are chosen to form the evolving toolset and how to control a decent tool-selection difficulty regarding to the number or proportion of useful and irrelevant tools in the toolset. The design of evolving toolset T at training phase is crucial for learning the dynamic tool selection.\n- There is no quantitative analysis to verify the positive correlation between the tool selection accuracy and the final answer accuracy. It would be better to more directly justify that, compared to baseline methods, AutoTool has a better hit rate of selecting the correct oracle tool, and this contributes to its better final performances."}, "questions": {"value": "- Any additional experimental results to resolve the above weaknesses?\n- Is there an ablation study to measure how many performance gains are due to the incorporation of additional tool-selection rationales introduced in AutoTool?\n- Are there any qualitative or quantitative comparisons with regard to the scope of toolsets studied in AutoTool and in other related work of tool integration, such as ToolLLM, RestGPT and HuggingGPT?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cATaLlkb71", "forum": "52c4trAbmd", "replyto": "52c4trAbmd", "signatures": ["ICLR.cc/2026/Conference/Submission8302/Reviewer_Rg4C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8302/Reviewer_Rg4C"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8302/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761824267249, "cdate": 1761824267249, "tmdate": 1762920231412, "mdate": 1762920231412, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a dynamic selection method for tools in agentic large language models. Typical agentic models assume a fixed set of tools to use in their reasoning process. This paper introduces a dynamic selection process where the model can utilize a large set of tools through retrieval. The proposed approach can also handle new tools which can be added to the tool repository for the models to use. Empirical results show the dynamic tool selection method outperforms existing tool-integration methods and can generalize well to unseen tools during inference."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Comprehensive empirical results, spanning a diverse set of evaluation datasets\n- Results compared against relevant baselines such as stronger reasoning models, existing tool integration methods and traditional fine-tuning\n- Strong results, the proposed AutoTool framework achieves consistent gains on the diverse datasets compared to multiple approaches."}, "weaknesses": {"value": "- I couldn't find the results on the generalization performance on unseen tools during inference. The key proposal for the embedding-anchored selection method is that it should be able to dynamically adapt to new tools provided during inference, but none of the experimental results seem to highlight it.\n- Not sure I follow why the analysis of autotool is needed with an oracle tool assignment agent. Ideally, the oracle numbers should be present in Table 1 to directly compare other methods on how close they too are with the oracle assignment, if its necessary.\n\nWhile overall the paper and contribution is good, its missing this key ingredient (generalization) - I'm ready to raise my scores if it is presented and analyzed comprehensively."}, "questions": {"value": "Same as my weakness - where is the generalization result? I think that should be the key result to highlight, along with analysis where the generalization works and fails."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NYt3eGuA88", "forum": "52c4trAbmd", "replyto": "52c4trAbmd", "signatures": ["ICLR.cc/2026/Conference/Submission8302/Reviewer_HQaG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8302/Reviewer_HQaG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8302/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920120921, "cdate": 1761920120921, "tmdate": 1762920231098, "mdate": 1762920231098, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents AutoTool, a framework that equips LLM agents with dynamic tool-selection capabilities throughout their reasoning trajectories. The authors construct a 200k dataset with explicit tool-selection rationales across 1,000+ tools and 100+ tasks, then employ a dual-phase optimization pipeline: (i) trajectory stabilization via SFT and RL, and (ii) KL-regularized Plackett-Luce ranking for tool selection refinement. Experiments show consistent improvements across math, science, code generation, and multimodal benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper addresses a genuine limitation in existing work—most approaches assume fixed toolsets, whereas real-world scenarios require dynamic tool selection from evolving inventories.\n\nThe dual-phase optimization pipeline is well-designed, with Phase I establishing stable reasoning patterns and Phase II specifically targeting tool-selection refinement through PL ranking."}, "weaknesses": {"value": "While the combination is effective, the individual components (SFT, GRPO, Plackett-Luce ranking) are well-established techniques. The main contribution appears to be applying PL ranking to tool selection, which is somewhat incremental. The paper would benefit from discussing recent work on tool retrieval and generation. \nAlso there are notation inconsistencies: The paper switches between τ and T for trajectories/trajectory sets."}, "questions": {"value": "I do have some scalability concerns. How does the approach scale beyond 1,000 tools? The embedding-based selection (Eq. 4) requires computing distances to all tools at each selection step."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XtqAZPJkoq", "forum": "52c4trAbmd", "replyto": "52c4trAbmd", "signatures": ["ICLR.cc/2026/Conference/Submission8302/Reviewer_NAkE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8302/Reviewer_NAkE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8302/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762008479851, "cdate": 1762008479851, "tmdate": 1762920230107, "mdate": 1762920230107, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}