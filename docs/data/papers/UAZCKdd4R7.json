{"id": "UAZCKdd4R7", "number": 19398, "cdate": 1758295912730, "mdate": 1759897041346, "content": {"title": "Koopman-Assisted Trajectory Synthesis: A Data Augmentation Framework for Offline Imitation Learning", "abstract": "Data augmentation plays a pivotal role in offline imitation learning (IL) by alleviating covariate shift, yet existing methods remain constrained. Single-step techniques frequently violate underlying system dynamics, whereas trajectory-level approaches are plagued by compounding errors or scalability limitations. Even recent Koopman-based methods typically function at the single-step level, encountering computational bottlenecks due to action-equivariance requirements and vulnerability to approximation errors. To overcome these challenges, we introduce Koopman-Assisted Trajectory Synthesis (KATS), a novel framework for generating complete, multi-step trajectories. By operating at the trajectory level, KATS effectively mitigates compounding errors. It leverages a state-equivariant assumption to ensure computational efficiency and scalability, while incorporating a refined generator matrix to bolster robustness against Koopman approximation errors. This approach enables a more direct and efficacious mechanism for distribution matching in offline IL. Extensive experiments demonstrate that KATS substantially enhances policy performance and achieves state-of-the-art (SOTA) results, especially in demanding scenarios with narrow expert data distributions.", "tldr": "", "keywords": ["Offline Imitation Learning; Offline Reinforcement Learning; Data Augmentation"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/77784c6546e666f9ff42745781c02b4c3c7e43d1.pdf", "supplementary_material": "/attachment/1e65e7ec1a34400edd6cd6f30fdf5b5ad5a9ce45.zip"}, "replies": [{"content": {"summary": {"value": "In this paper, a data augmentation framework, namely KATS that leverages Koopman theory to address the critical distribution shift problem in offline imitation learning is introduced. The presented framework can synthesize trajectories for the training data augmentation while avoiding the compounding errors of recursive rollouts and ensuring computational efficiency and scalability. Experimental results show the effectiveness of the proposed approach."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-motivated and aims to address an important issue in the literature, which generates high-quality, dynamically consistent trajectory-level data while avoiding the compounding errors and ensuring computational efficiency. \n2. Experimental results along with theoretical guarantees demonstrate the advantages of KATS, which yields substantial improvements in policy performance on some tasks."}, "weaknesses": {"value": "1. The presented Koopman-Assisted Trajectory Synthesis (KATS) framework is based on the assumption that the symmetries of a closed-loop dynamical system, driven by a fixed expert policy, are directly reflected as commutation properties of its associated Koopman operator. While the assumption may hold in some cases, it is unclear whether such an argument can be satisfied in a general sense. Can the proposed framework be applied in any type of environment, or is its application limited to some special domains? \n2. In the literature, many works have been proposed for the trajectory-level data augmentation, more recent baselines, especially for diffusion-based approaches, can be added and discussed for the comparison. \n3. In the experiments, the most recent baseline is a rejected paper (TELS) while other baselines were mainly presented two or three years ago. Considering the rapid development of the related research area, it is necessary to adopt more recent baselines to verify the effectiveness of the proposed method."}, "questions": {"value": "Please refer to the weakness points."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1dJHFHBVuO", "forum": "UAZCKdd4R7", "replyto": "UAZCKdd4R7", "signatures": ["ICLR.cc/2026/Conference/Submission19398/Reviewer_qXWS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19398/Reviewer_qXWS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19398/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761724470631, "cdate": 1761724470631, "tmdate": 1762931318725, "mdate": 1762931318725, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a theoretically principled method to generate augmented, synthetic expert demonstrations for offline imitation learning. With said augmented data, one can perform standard behavioral cloning on the union of the given expert dataset and the augmented dataset. The paper grounds their technique for augmenting trajectories in Koopman theory, done in the latent space of a learned autoencoder over the expert data. In particular, they note that if the learned state latents satisfy certain linear properties (e.g. the transition function under the expert data is linear -- said linear transformation is the Koopman operator), then compounding errors are bounded, leading to useful trajectory generation.\n\nExperiments on MuJoCo tasks, both in IL and RL, validate the hypothesis shown, including strong results compared to prior offline IL baselines that either had to rely on suboptimal offline data (e.g. MILO) and other methods employing data augmentation (e.g. KFC+BC). Furthermore, they also try their method in the offline RL setting, comparing to standard baselines and recent Koopman-focused baselines such as KFC++ and showing strong performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "I really like this area of work, as Koopman theory is well grounded and has been used for quite a while in model-based dynamical system control (although I am not super familiar with the literature). There are many advantages in learning a latent space under which the transition dynamics are linear, which include not even having to do RL directly and employing more stable control theory-focused algorithms.\n\nThe theory seems fine to me, and seems to borrow a lot from the KFC paper (Weissenbacher et al. 2022), leading me to believe that it is sound. The experimental results are also strong, showing strong performance improvement even over other Koopman-based RL and IL algorithms."}, "weaknesses": {"value": "There are instances where the paper could be written a bit better (e.g. put your citations in parentheses!). I think there are also potential weaknesses to the method empirically, which include (and correct me if I'm wrong) the following:\n\n- In the RL setting, if the reward function is a function of both state and action, then Q learning may be biased. I think that the reward is only the function of the state in MuJoCo and DMC control domains, which means the method is fine there, but in cases where it is not, then I figure due to said bias, learning is difficult even when the latent system is well-learned.\n\n- Generally, these methods seem to work in small-scale tasks such as OpenAI Gym locomotion, while not having been tested on larger-scale domains such as DMC from pixels or larger control tasks. A potentially great use for this method could be to learn such a linear latent system on real robotic datasets, making learning controllers much faster.\n\nThese are not \"make or break\" weaknesses, more so that this seems not to have been tested. In general, for the focus of IL, there are less problems, as for instance removing action conditioning is fine as the Markovian expert policy is embedded into the latent encoding, which is enough for data augmentation."}, "questions": {"value": "No fundamental questions from me, but I am curious to know if any large-scale experiments were done for this paper, including with either high-dimensional states or with image observations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "boqIfUbY2q", "forum": "UAZCKdd4R7", "replyto": "UAZCKdd4R7", "signatures": ["ICLR.cc/2026/Conference/Submission19398/Reviewer_AWKq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19398/Reviewer_AWKq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19398/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761880855729, "cdate": 1761880855729, "tmdate": 1762931318080, "mdate": 1762931318080, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles covariate shift in offline imitation learning, where agents are limited to fixed datasets with potentially low diversity. Prior Koopman-based methods operate at the single-step level, causing dynamic inconsistency and high cost. Koopman-Assisted Trajectory Synthesis (KATS) is introduced as a trajectory-level data augmentation method that generates novel yet dynamically consistent expert-like trajectories in a learned state-equivariant linear Koopman latent space. In addition, KATS is adaptive in that it prioritizes data synthesis where the model is uncertain. Theoretical results guarantee that symmetries commuting with the learned Koopman operator yield trajectories consistent with expert policy dynamics. In practice, KATS augments data and then applies simple BC, outperforming more complex offline IL and RL baselines. KATS serves as a plug-and-play augmentation module that enhances existing algorithms through high-fidelity, behaviorally consistent data generation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "* Th. 2 is very elegant and clear. Slight suggestion: preamble the section with the gist/a teaser of what the theorem will show.\n* Sec. 5.2: ingenious yet simple.\n* KATS demonstrates that augmenting data and applying behavioral cloning can be a more effective and reliable strategy for imitation, even in data-scarce regimes where traditional apprenticeship learning methods, despite allowing interaction, tend to be fragile and overcomplicated."}, "weaknesses": {"value": "* Th. 3 should be followed by an \"in-words\" interpretation and description of its consequences, along with a hyperlinked reference to the “Implication of the Bound” section presented in the Appendix.\n* KATS is introduced from the machinery of KFC, but the link is somewhat lost until it comes back in 5.1 line 287, where it is clear.\n* The way the authors present sigma in Fig 2 (“Sigma 0.2, Sigma 0.3” etc.) or as “a symmetry basis” suggests a structured family of symmetry operators or scalars, but in the actual text and appendix, they never describe how that basis or scaling is obtained. The figure’s depiction of multiple sigma’s or scaled sigma’s is not grounded in the described theory or implementation. The authors must explicitly indicate how they operationalize the learned sigma network to obtain their basis.\n* The authors write: \"This dramatic leap provides strong validation for our core contribution: the action-independent formulation.\". It is definitely noteworthy and interesting to observe that the action-independent closed-loop formulation combined with an IDM can yield such results. Stating that the generated trajectories are \"by construction, more behaviorally consistent than those from action-conditioned models like KFC\" might be a bit of a stretch however, but an experimental design could be devised to showcase that further.\n* In the appendix L795-796, the authors write \"This process effectively densifies the training data, filling the gaps in the state-space coverage that a sparse dataset would otherwise leave open.\". That is “potentially” what KATS enables, but the coverage is not proven or showcased as such.\n* The paper could use an additional round of polish to remove the inconsistencies in notations."}, "questions": {"value": "* Can the authors make it clear what they mean by scalability/scalable? From the phrasing in the paper, it seems that the scalability claimed by the authors is on the complexity of the task (dimension, degrees of freedom). However, since this is an approach for the low-data regime (limited offline dataset), it might be on the how the developed data augmentations impact performance, etc.\n* Koopman theory imposes a strong inductive bias, going against the bitter lesson. Would the authors defend that modeling the temporal relationship between one latent and its successor simply with a linear operator is enough to model system that are more complex than the ones tackled empirically in the paper? In other words, would adding depth to the encoder always be enough to go in a sufficiently “higher-dimensional space” where the dynamics can reasonably be assumed linear?\n* It is unclear in the text why KFC working at the single-step level is costly in compute (L193). Is it clearer costly because the action-equivariant assumption in KFC requires one linear operator per action dimension (Eq. 2), making it costly to scale with action dimensionality?\n* Section 5.1: modeling the closed-loop system dynamics is a design choice rather than an innovation, is it not? Do the other claim it is an innovation because it is unusual?\n* Is there a particular reason why the authors write \"find symmetry basis\" at line 2 of the algorithm, and not \"learn the symmetries\" (\"sigma model training\" only appears in the appendix, L812-813)? By basis or symmetries, do the author mean that the set verifies the properties of basis, then they then use to craft other symmetries as linear combinations of the elementary symmetries of the basis?\n* What would be informative, for the data augmentation methods, is to get the final size of the dataset used to train the policy with BC (compared to the initial size), along with statistics that could give an idea as to how it expands the initial one in terms of diversity.\n* Could the authors include a few words about the baselines, to get the gist of their approach, which would put KATS in perspective; e.g., how does TELS' data augmentation approach differ from KATS?\n* The authors write in the appendix that the \"[policy] training alternates between original and augmented data with equal weighting\". What is the only sampling strategy that the authors tried? Could the authors give the respective dataset sizes for the reader to be able to gauge how likely to overfit the policy is?\n* Have the authors experimented with learning the IDM from the mapping of the expert states into the learned latent space, i.e. from the latents z instead of the states s?\n* What does the weight distribution (in the sigma loss) look like? In other words, how far from uniform is the \"adaptive\" scheme the authors designed?\n* Providing an ablation study comparing KATS with and without any symmetry training and usage would be insightful.\n\nStyle, typos, suggestions:\n* It would be useful to add, in the algorithm, links to the equation according to which the various networks are optimized.\n* [minor] It might be good to mention that that Koopman machinery is used in latent space earlier in the introduction than at the very end. The paper might also benefit from putting KATS in the context of model learning in latent spaces, which the typical RL literature reader might be more familiar with.\n* [minor] L123-124: the comma after \"shift\" should be removed.\n* [minor] L155-156: z_t and z_{t+1} correspond to a transition (s_t, s_{t+1}) or to a pair of states but not a pair of transitions.\n* [minor] L187-188: why use \"aug\" when the figure 1 (a) uses primes to designates the augmentations?\n* [minor] The last sentence of Def. 2 should be emphasized.\n* [minor] L263: properly format the emdash, or use a colon.\n* [minor] End of page 9: \"Limitaitions\" -> Limitations\n* [minor] L810-811: \"Synthesisi\" (extra \"i\"), \"(KATS)\" (missing space prefix).\n* [minor] L289-290: \"Any symmetry transformation that commutes with K is therefore guaranteed to produce trajectories that adhere to this policy.\" I find this to not be clear."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YbYtKKkWmC", "forum": "UAZCKdd4R7", "replyto": "UAZCKdd4R7", "signatures": ["ICLR.cc/2026/Conference/Submission19398/Reviewer_f7Wk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19398/Reviewer_f7Wk"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19398/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761944204457, "cdate": 1761944204457, "tmdate": 1762931317575, "mdate": 1762931317575, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method based on Koopman Theory for generating trajectories from offline data."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The approach appears reasonably sound."}, "weaknesses": {"value": "1. (I have not read KFC) The authors claim that this work differs from KFC, as KFC only generates single-step data, while KATS generates trajectories. However, judging from Equations 7, 8, 9, and 10, KATS still appears to generate states.\n\n2. Although the experimental results presented by the authors show that KATS performs well, the experiments seem insufficient. For example, there is no ablation study.\n\n3. The baselines compared in Table 1 and Table 2 are inconsistent:\n(1) Table 1 compares KATS+BC and KFC+BC, while Table 2 compares KATS+BC and KFC+CQL. Since the base algorithms of KATS+BC and KFC+CQL are different, the comparison lacks fairness.\n(2) In Table 1, the data augmentation methods compared are SRA, MOLI, and KFC+BC, while in Table 2, the compared methods are TELS, DOGE, POR, and KFC+CQL."}, "questions": {"value": "1. What are the differences and connections between Equations 7–8 and 9–10? In implementation, are they used together or only 9–10?\n\n2. Why does Table 1 compare KATS+BC with KFC+BC, while Table 2 compares KATS+BC with KFC+CQL?\n\n3. Why are the data augmentation methods in Table 1 compared with SRA, MOLI, and KFC+BC, while in Table 2, they are compared with TELS, DOGE, POR, and KFC+CQL?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xe11B2ewvK", "forum": "UAZCKdd4R7", "replyto": "UAZCKdd4R7", "signatures": ["ICLR.cc/2026/Conference/Submission19398/Reviewer_cuKL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19398/Reviewer_cuKL"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19398/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971664315, "cdate": 1761971664315, "tmdate": 1762931317243, "mdate": 1762931317243, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}