{"id": "NBIdT91VZh", "number": 20383, "cdate": 1758305359199, "mdate": 1759896980750, "content": {"title": "Dynamic Parameter Memory: Temporary LoRA-Enhanced LLM for Long-Sequence Emotion Recognition in Conversation", "abstract": "Recent research has focused on applying speech large language model (SLLM) to improve speech emotion recognition (SER). However, the inherently high frame rate in speech modality severely limits the signal processing and understanding capabilities of SLLM. For example, a SLLM with a 4K context window can only process 80 seconds of audio at 50Hz feature sampling rate before reaching its capacity limit. Input token compression methods used in SLLM overlook the continuity and inertia of emotions across multiple conversation turns. This paper proposes a Dynamic Parameter Memory (DPM) mechanism with contextual semantics and sentence-level emotion encoding, enabling processing of unlimited-length audio with limited context windows in SLLM. Specifically, DPM progressively encodes sentence-level information and emotions into a temporary LoRA module during inference to effectively \"memorize\" the contextual information. We trained an emotion SLLM as a backbone and incorporated our DPM into inference for emotion recognition in conversation (ERC). Experimental results on the IEMOCAP and MELD datasets show that DPM significantly improves the emotion recognition capabilities of SLLM when processing long audio sequences, achieving state-of-the-art performance.", "tldr": "PM enables SLLMs to overcome context window limits for emotion recognition. By progressively encoding sentence-level information into a temporary LoRA module, DPM processes unlimited-length audio and achieves state-of-the-art results.", "keywords": ["Speech Emotion Recognition", "Large Language Models", "Long-Sequence Audio Processing"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/466878244023873d707887b8c5d0306065d2f161.pdf", "supplementary_material": "/attachment/d56122281a41fdaec9731fd286672d858823afa5.zip"}, "replies": [{"content": {"summary": {"value": "A speech large language model (SLLM) is proposed for the task of emotion recognition. A DPM mechanism is proposed so that during inference, SLLM can take much longer audio from the conversation for more effective SER."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The problem statement and motivation behind the work are well introduced.\n\nThe overall presentation of the paper and the visuals are clear."}, "weaknesses": {"value": "For a more comprehensive evaluation, I would suggest more evaluations on more conversational style datasets in addition to IEMOCAP and MELD. This could be something to consider for other language speakers and more varied conversational styles. In addition, a synthetic dataset could also be used to show generalizability.\n\nI would also like to know the model's performance on different discrete emotions, instead of total accuracy or macro F1.\n\nI know the main scope of the work is for ERC, but for SER in general, there are many situations where the datasets are monologues, either natural or scripted. These can have long recordings too. For an ICLR paper, it might not be comprehensive enough to just focus on emotion recognition in conversation."}, "questions": {"value": "None."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "XnbvVStjje", "forum": "NBIdT91VZh", "replyto": "NBIdT91VZh", "signatures": ["ICLR.cc/2026/Conference/Submission20383/Reviewer_vAs6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20383/Reviewer_vAs6"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20383/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931696294, "cdate": 1761931696294, "tmdate": 1762933833352, "mdate": 1762933833352, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors in this paper propose a mechanism designated Dynamic Parameter Memory (DPM) to address the critical limitation of a finite context window in Speech Large Language Models (SLLMs) for emotion recognition in long conversations. The core of their approach is to process the audio sequentially, sentence by sentence, and progressively encode the accrued contextual and emotional information into a temporary Low-Rank Adaptation (LoRA) module. This module effectively functions as a dynamic memory that is continuously updated, a design which allows the model to handle audio sequences of theoretically unlimited length with linear computational complexity, as it obviates the need to re-process the entire conversational history. The authors validate their approach on the IEMOCAP dataset, where they report a significant improvement in weighted accuracy and establish a new state-of-the-art performance."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The primary novelty of this work lies in its innovative application of LoRA not as a static fine-tuning method, but as a dynamic, temporal memory for extending the effective context of an SLLM. Instead of conventional approaches like input compression or sliding windows, which risk losing historical information, the authors propose to progressively encode the evolving conversational context directly into the LoRA parameters during inference. This reconceptualization of LoRA is really interesting for researchers and practitioners in the field that would increasingly try to solve issues with more and more past context. The continuously updated memory buffer is a distinct and compelling approach to circumventing the fixed context window limitations in most of the existing transformer-based models.\n2. A significant strength of the proposed Dynamic Parameter Memory (DPM) mechanism is its computational efficiency and inherent scalability for processing long sequences. By adopting a sentence-by-sentence processing scheme that only updates the compact LoRA memory, the method avoids the computationally expensive need to re-process the entire conversational history at each step. This design results in a linear computational cost with respect to the sequence length, making the framework able to get deployed for real-world applications."}, "weaknesses": {"value": "The paper has some weaknesses and I will try to write them down in a somewhat decreasing order of significance that would hopefully help the authors to fix these issues and improve the quality of their paper.\n\n1. A primary concern is the marginal performance improvement when contextualized against the immense increase in model complexity. The reported 10-15% gain in weighted and unweighted accuracy over a four-emotion task on IEMOCAP is unimpressive when compared to results from over seven years ago using simple signal processing features coupled with a two-layer BLSTM architecture proposed more than 7 years ago [A]. It is questionable whether the computational cost is justified (e.g. the 160 million parameters in the LoRA module alone are likely orders of magnitude larger than these older, simpler networks in [A], probably by 2 to 3 orders of magnitude). For the paper's claims to be convincing, the authors must include direct comparisons to these earlier models, or scaled-up versions thereof, to demonstrate that the proposed SLLM-based approach offers a benefit that could not be achieved by more resource-efficient means.\n2. Following the previous point, the paper makes claims of efficiency without providing the necessary quantitative evidence. A holistic computational complexity analysis is conspicuously absent. To properly assess whether the performance gains are worth the effort, the authors must explicitly report the key metrics for their model: the end-to-end inference time on their specified CPU hardware, the actual memory footprint required during inference, and the total number of FLOPs. Without this data, it is impossible for the reader to verify the practical viability of the DPM mechanism for on-device or real-time applications and to make a fair comparison of the trade-offs between this complex architecture and simpler, established models.\n3. While the proposed method for instilling long-term memory in a LoRA module is intriguing, its application to speech emotion recognition may not be the most compelling use case to demonstrate its capabilities. Given that the performance gains over much simpler recurrent architectures are not dramatic, the problem might not sufficiently require the level of long-context understanding that the DPM is designed to provide. The true potential of this method might be better showcased on tasks where extremely long-term dependencies are unequivocally critical, such as long-form document summarization, narrative video understanding, or context retrieval from extensive texts. In its current form, there is a mismatch between the sophistication of the proposed solution and the demands of the chosen evaluation task.\n\n[A] Tzinis, E., Paraskevopoulos, G., Baziotis, C. and Potamianos, A., 2018. Integrating Recurrence Dynamics for Speech Emotion Recognition. In Proc. Interspeech 2018 (pp. 927-931).\n\nI would gladly increase my score if the authors work properly to address the above issues to a proper degree."}, "questions": {"value": "How can you extend the training for unsupervised learning? Meaning that you can have some random audio recordings that you can only get some initial emotion estimations and you can use those to extend the LoRA adaptation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PsdltgHGVe", "forum": "NBIdT91VZh", "replyto": "NBIdT91VZh", "signatures": ["ICLR.cc/2026/Conference/Submission20383/Reviewer_nJz7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20383/Reviewer_nJz7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20383/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761945640434, "cdate": 1761945640434, "tmdate": 1762933832354, "mdate": 1762933832354, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Proposes Dynamic Parameter Memory (DPM) â€” a temporary LoRA-based mechanism for long-sequence emotion recognition in conversations.\n\nIntegrates with an emotion-aware Speech Large Language Model (SLLM) to encode sentence-level emotional context.\n\nEnables unlimited-length audio processing under limited context windows with linear complexity.\n\nAchieves state-of-the-art results on IEMOCAP and MELD datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The manuscript presents a novel inference method (DPM) addressing long-sequence limits in LLMs. This is usually a very complex method that can be very helpful in long sequential emotional recognition conversations.\n\n2. The manuscript also maintains contextual emotion continuity across dialogue turns. This is also very in depth and contextual\n\n3. Demonstrated SOTA performance (e.g., 79.34% WF1). The SOTA performance is a good parameter to consider overall \n\n4. Elegant use of temporary LoRA for dynamic adaptation."}, "weaknesses": {"value": "1. Although the evaluation looks pretty comprehensive but limited to two datasets; lacks real-world or multilingual validation.\n2. The metrics are good but there is no explicit latency or computational cost benchmarks.\n3. Overall there is a high dependency on sentence segmentation quality.\n4. Limited analysis on failure or misclassification cases were also seen overall."}, "questions": {"value": "1. How does DPM handle overlapping speech or noise in real-time audio, this is something that can answered by some metrics ?\n2. What is the exact memory footprint and time overhead of per-sentence LoRA updates?\n3. Can you test the same framework using a multi agentic MCP approach as well, with applications connected. Idea is to explore real world scenarios?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gUSLWsUFLR", "forum": "NBIdT91VZh", "replyto": "NBIdT91VZh", "signatures": ["ICLR.cc/2026/Conference/Submission20383/Reviewer_vBe4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20383/Reviewer_vBe4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20383/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762039386265, "cdate": 1762039386265, "tmdate": 1762933832058, "mdate": 1762933832058, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}