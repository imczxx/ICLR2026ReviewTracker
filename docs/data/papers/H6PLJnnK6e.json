{"id": "H6PLJnnK6e", "number": 389, "cdate": 1756737720135, "mdate": 1763631969853, "content": {"title": "Beyond the Heatmap: A Rigorous Evaluation of Component Impact in MCTS-Based TSP Solvers", "abstract": "The ``Heatmap + Monte Carlo Tree Search (MCTS)'' paradigm has recently emerged as a prominent framework for solving the Travelling Salesman Problem (TSP). While considerable effort has been devoted to enhancing heatmap sophistication through advanced learning models, this paper rigorously examines whether this emphasis is justified, critically assessing the relative impact of heatmap complexity versus MCTS configuration. Our extensive empirical analysis across diverse TSP scales, distributions, and benchmarks reveals two pivotal insights: \\textbf{1}) The configuration of MCTS strategies significantly influences solution quality, underscoring the importance of meticulous tuning to achieve optimal results and enabling valid comparisons among different heatmap methodologies. \\textbf{2}) A rudimentary, parameter-free heatmap based on the intrinsic $k$-nearest neighbor structure of TSP instances, when coupled with an optimally tuned MCTS, can match or surpass the performance of more sophisticated, learned heatmaps, demonstrating robust generalizability on problem scale and distribution shift. To facilitate rigorous and fair evaluations in future research, we introduce a streamlined pipeline for standardized MCTS hyperparameter tuning. Collectively, these findings challenge the prevalent assumption that heatmap complexity is the primary determinant of performance, advocating instead for a balanced integration and comprehensive evaluation of both learning and search components within this paradigm.", "tldr": "This study shows simple heatmaps and well-tuned MCTS can outperform complex heatmap-based approaches for the Travelling Salesman Problem, advocating for a balanced focus on both learning and search components.", "keywords": ["Travelling Salesman Problem", "Heatmap", "Monte Carlo Tree Search", "Combinatorial optimization"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/15d79f2aa45ca1ec281962664938383abeb18f56.pdf", "supplementary_material": "/attachment/c71f8d778663816e44f83cd2c54fc125a7ad6c78.zip"}, "replies": [{"content": {"summary": {"value": "This paper critically evaluates the \"Heatmap + Monte Carlo Tree Search\" paradigm for solving TSP, challenging the prevailing focus on increasingly complex learned heatmaps. Also, the authors propose a learning-free heatmap baseline (GT-Prior) with shown efficiency and synergy accompanying MCTS."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The tuning in search of optimal MCTS configurations and impact study on the respective parameters is valuable.\n2. The proposed parameter-free GT-prior is sensible and computationally efficient.\n3. The experiments are relatively well-structured."}, "weaknesses": {"value": "Please correct me if I made mistakes or ignored important statements already addressed in the initial submission.\n1. Foremost, there might be a fundamental misposition that the authors put forward in this work regarding the research line of developing more complex heatmap models: heatmaps do not merely serve for the specific MCTS serching, instead, most recent heatmap-related methods inherently embody advancements in backbone design, training schemes, or data representation, etc., aligning major focuses in the broader ML community. So the criteria for assessing a heatmap should probably not be whether it helps MCTS perform better. Rather, increasing consensus has been inclined to testing neural TSP solvers in a \"heatmap + greedy\" paradigm to evaluate the raw efficacy of neural parts without the results being disguised by post-inference tricks like MCTS, which I personally also deem more reasonable. \n2. The contribution is a bit limited. Though I appreciate the systematic \"tuning\" of MCTS settings, the grid-search-based evaluations seem more of an engineering practice than some technical innovation. Second, the proposed GT-Prior, though interesting and computationally efficient, is also learning-free and straightforward. So, from a holistic view, the performance reported basically stems from the established MCTS algorithm, leaving the incremental efforts by the authors (conducting parameter search) somewhat simple and limited under the threshold of a top-tier conference.\n3. The performance is not sufficiently impressive. The proposed method fails to outperform DIFUSCO on 2 out of 3 benchmarks, while recent literature has proposed much stronger heatmap models than DIFUSCO.\n4. Minor issues. The language needs further consideration. \"Figure 2 compellingly illustrates...\", \"directly answering Q1 by unequivocally demonstrating...\", and many similar expressions, seem to indicate a slight abuse of adverbs throughout the paper."}, "questions": {"value": "1. How do you define the \"complexity\" or \"sophistication\" of a heatmap? Is it defined by the parameter quantity of neural models that produce the heatmap, or by any mathematical or statistical metrics computed upon individual heatmaps? The authors criticize complex or sophisticated heatmaps but the definition seems obscure. E.g., in Sec 5 the authors say \"the prevailing view that increasingly sophisticated heatmap models are the primary drivers of performance in the \"Heatmap + MCTS\" TSP paradigm.\" Similar statements do not seem grounded enough.\n2. Could you provide comparative results free of intricate search algorithms like MCTS and using a greedy decoder instead, to compare different heatmap baselines including the proposed GT-Prior?\n3. What are the results on smaller-sized instances (e.g., 50/100/200)? Do the main conclusions still hold? What about the MCTS parameters and the GT-Prior's performance?\n4. Could you report comparisons using more recent heatmap methods, like the successors of DIFUSCO, e.g. Fast-t2t?\n5. What is the principle for choosing the specific search space for MCTS configuration instead of a wider or finer-grained range of parameters? The authors stated the settings are \"optimally tuned\", then how is such optimality guaranteed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Z527VF9dNB", "forum": "H6PLJnnK6e", "replyto": "H6PLJnnK6e", "signatures": ["ICLR.cc/2026/Conference/Submission389/Reviewer_eu88"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission389/Reviewer_eu88"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission389/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760697246926, "cdate": 1760697246926, "tmdate": 1762915508942, "mdate": 1762915508942, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper revisits the widely adopted \"Heatmap + Monte Carlo Tree Search (MCTS)\" paradigm for large-scale Traveling Salesman Problem (TSP) solvers. It critically analyzes the respective roles of the heatmap and the MCTS search procedure. Contrary to prior trends that emphasize increasingly complex heatmap design, the paper offers a systematic, empirical evaluation. This evaluation demonstrates that the configuration of MCTS—often taken as a fixed backbone—can have as much, if not greater, impact on solution quality as the heatmap itself. The authors propose a parameter-free GT-Prior heatmap based on the empirically observed k-nearest neighbor edge structure of optimal TSP tours. By tuning MCTS hyperparameters via a robust pipeline for each heatmap, they show that this simple baseline matches or outperforms state-of-the-art learning-based and distance-based heatmaps. This holds across scale, distributional shift, and standard benchmarks, challenging current assumptions in the field. The work argues for more balanced and transparent component evaluation in future research. It provides tools and ablation studies to support reproducibility."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper systematically assesses the \"Heatmap + MCTS\" paradigm for large-scale TSP, isolating and quantifying each component's impact.\n- The work challenges a key assumption: that more complex heatmap models always improve TSP solver performance. With a well-tuned baseline, it shows that optimizing MCTS often matters more than increasing heatmap sophistication.\n- A parameter-free k-nearest neighbor heatmap (GT-Prior) matches or outperforms complex learned heatmaps when paired with optimized MCTS. It generalizes well to new distributions and larger instances."}, "weaknesses": {"value": "- Scope: The analysis, experiments, and proposed GT-Prior heatmap are specialized to the Euclidean TSP. It remains unclear whether the insights transfer to other TSP variants (non-Euclidean, with constraints) or different combinatorial optimization problems (e.g., VRP, graph matching).\n- Dependency on optimal solutions: GT-Prior construction relies on empirical distributions extracted from near-optimal solutions. In scenarios where such solutions are expensive or unavailable—a typical motivation for using learning-based solvers—how practical is GT-Prior?\n- MCTS parameter tuning: While a one-time cost, tuning can be significant for large search spaces or new problem distributions. The paper suggests SMAC3 and other efficient approaches, but more discussion of practical deployment costs would be helpful.\n- Incomplete time metrics: Table 1 includes heatmap and MCTS time but omits training time for learning-based models, data preparation, and other one-off costs. This makes it difficult to fully compare runtime and resource requirements across methods."}, "questions": {"value": "1. Practicality of GT-Prior: For deployment on genuinely new, real-world TSPs where high-quality solutions are not available, how would one construct GT-Prior (since you need optimal/near-optimal tours to compute the empirical k-nearest distribution)? Did you try synthesizing priors from random/greedy solutions as a further baseline?\n2. Tuning cost: Can you provide the absolute time and computational resources required for your grid/SMAC3 MCTS hyperparameter search (including how many instances, search depth, etc.), especially for the largest TSP-10k and TSPLIB cases?\n3. Have you considered (or could you comment on the prospects for) transfer of either your analysis framework or GT-Prior construction to other vehicle routing or graph-based optimization problems?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "piBIv0Yzjo", "forum": "H6PLJnnK6e", "replyto": "H6PLJnnK6e", "signatures": ["ICLR.cc/2026/Conference/Submission389/Reviewer_pNGG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission389/Reviewer_pNGG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission389/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761822183181, "cdate": 1761822183181, "tmdate": 1762915508677, "mdate": 1762915508677, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the classic \"heatmap + MCTS\" pipeline for solving the Traveling Salesman Problem (TSP). The authors examine the extent to which different MCTS parameter settings affect the solution quality and further perform tuning accordingly. Additionally, they propose an approach named ``GT-PRIOR`` to generate the initial heatmap based on K-nearest neighbors."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. This paper is written in an accessible manner, offering a clear explanation of the ``MCTS`` method implemented in ``Att-GCN``, and provides a thorough analysis of how each MCTS parameter influences the solution.\n\n2. This paper conducts sufficient generalization tests across different distributions and scales, including experiments on ``TSPLIB``."}, "weaknesses": {"value": "1. The authors state that ``The underlying assumption is often that heatmap sophistication directly translates to superior solution quality``, yet they provide no experiments to substantiate this claim. They lack analytical experiments to compare the heatmaps produced by different methods, such using greedy strategy.\n\n2. It can be inferred from ``Table 1`` and the sentence ``The Time_Limit for MCTS was set to 0.1 for TSP-500 and TSP-1000, and 0.01 for TSP-10000`` that the authors run MCTS in parallel. However, they never state this explicitly in the table (64 threads for TSP-500/1000 and 2(maybe?) threads for TSP-10000). Moreover, the baseline solvers ``LKH`` and ``Concorde`` are executed in single-thread mode, so the comparison is unfair and likely to mislead readers about the actual efficiency of MCTS. Additionally, previous study [1] suggests that the ``LKH`` and ``Concorde`` figures reported in the table may be outdated or stem from sub-optimal configurations; it is therefore advisable to adopt the updated baseline results.\n\n3. This paper concentrates **solely on the TSP** with ``heatmap+MCTS`` pipeline tailored to it. This approach is hard to extend to richer problems such as the CVRP.\n\n4. In general, as problem size increases, the quality of heatmaps learned by ML methods deteriorates. Previous studiy [2] has shown that heatmaps achieve strong performance on small-scale TSP instances, while this paper does not include experiments on TSP50 or TSP100. \n\n5. Both ``MCTS`` and ``LKH`` are K-opt algorithms; the former adds a heatmap guidance. In my view, once the instance size exceeds 500, LKH dominates MCTS in both speed and solution quality by a large margin. Hence the authors’ hope that ``heatmap + MCTS`` will ``develop TSP solvers that are not only high-performing but also more robust, efficient, and genuinely impactful`` is questionable.\n\n\n[1] *COExpander: Adaptive Solution Expansion for Combinatorial Optimization, ICML 2025*\n\n[2] *Unify ML4TSP: Drawing Methodological Principles for TSP and Beyond from Streamlined Design Space of Learning and Search, ICLR 2025*"}, "questions": {"value": "1. See ``Weakness``\n\n2. As the problem size grows, the time spent on the ``Two-Opt`` step inside ``MCTS`` increases sharply. I would like to know what is the performance difference between running the full MCTS and running plain 2-opt alone on TSP-1000 and TSP-10000. This result might reveal whether MCTS actually makes any meaningful difference at these scales."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "uebRpdLcgl", "forum": "H6PLJnnK6e", "replyto": "H6PLJnnK6e", "signatures": ["ICLR.cc/2026/Conference/Submission389/Reviewer_yJZG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission389/Reviewer_yJZG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission389/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761933430142, "cdate": 1761933430142, "tmdate": 1762915508528, "mdate": 1762915508528, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents an investigation of the effect of tuning MCTS hyperparameters\nand \"simple\" heatmaps on the results of TSP solving with heatmaps and MCTS. The\nauthors describe the shortcomings of the current literature, their experimental\nsetup including a new method to develop heatmaps, and the results they obtained."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "This is a very nice paper that investigates an angle mostly ignored by the\nliterature. The results nicely support the conclusions the authors come to, and\nsuggest that research efforts should be focused in a different direction for\nmore impact. The paper complements the existing literature very nicely.\n\nThe proposed GT-Prior is, to the best of my knowledge, novel and seems to work\nvery well in practice. It would be interesting to investigate to what extent it\ndiffers from heatmaps learned in other ways; in particular whether learned\nheatmaps \"converge\" towards the GT-Prior heatmap. It would be great if the\nauthors could comment on this.\n\nThe time_limit hyperparameter for MCTS should be explained in the main paper,\nnot just in the appendix. It is mentioned as being set to specific values on\npage 6 without having been introduced before, which is confusing (especially as\nthe values are counter-intuitive)."}, "weaknesses": {"value": "None major."}, "questions": {"value": "How does the GT-Prior heatmap compare to learned heatmaps?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 10}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VQGtXlghfK", "forum": "H6PLJnnK6e", "replyto": "H6PLJnnK6e", "signatures": ["ICLR.cc/2026/Conference/Submission389/Reviewer_5EC7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission389/Reviewer_5EC7"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission389/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762008092728, "cdate": 1762008092728, "tmdate": 1762915508411, "mdate": 1762915508411, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Global Response (1/2)"}, "comment": {"value": "## **Commitment to Revision**\nWe sincerely appreciate the reviewers’ constructive feedback, which has helped strengthen our evaluation. In the revised manuscript, we commit to the following updates: \n1. Expanded Baselines: We have incorporated new experiments comparing MCTS against greedy decoding and plain 2-opt, as well as Fast-T2T benchmarks under both default and tuned settings; \n2. Clarified Protocols: We will revise Table 1 to explicitly detail parallelism (exact thread counts) and per-instance time budgets, while refreshing LKH and Concorde baselines to align with updated standards;\n3. Holistic Efficiency Metrics: We will add an appendix table reporting the training times of learned methods to ensure a complete comparison of computational costs; \n4. Presentation: We will tone down subjective language (e.g., removing adverbs such as \"unequivocally\") and resolve the minor writing issues identified by Reviewer eu88.\n\n---\n\n## **On the Nature and Significance of Our Contribution**\n\nWe understand the reviewers' concerns regarding the \"novelty\" and \"engineering\" nature of our work. However, we wish to clarify that our contribution is explicitly **evaluation-centered**. We are not proposing a new solver to top the leaderboard; rather, we are providing the rigorous scientific control that the field currently lacks.\n\n**1. Evaluation is Not Just Engineering**\nThe critique that our grid-search approach is \"engineering practice\" overlooks our scientific intent. We deliberately chose grid search for its transparency and reproducibility, which enabled the detailed SHAP analysis (Fig. 1) that black-box optimization cannot provide. While Appendix H proves that advanced methods like SMAC3 can achieve similar results 17× faster, our goal was to map the *entire* performance landscape to derive foundational conclusions.\n\n**2. GT-Prior is a Scientific Control, Not a Product**\nWe are not proposing GT-Prior as a new state-of-the-art method. Instead, it serves as a **critical baseline**. When a zero-parameter, zero-training-cost prior based on simple structure rivals or beats complex diffusion models (e.g., beating DIFUSCO by 0.23% on TSP-10k with better generalization), it suggests the community may be over-optimizing model architecture while under-optimizing the search mechanism.\n\n**3. Actionable Insights for the Community**\nOur work offers immediate, high-value corrections to current research trends:\n* **The Search Component is Undervalued:** We show that the \"Zero\" heatmap with tuned MCTS (0.66% gap) outperforms learned heatmaps with default MCTS (>1% gap).\n* **Cost-Benefit Reality Check:** GT-Prior matches learning-based performance without the massive overhead of training or heatmap generation (e.g., saving ~28 minutes of generation time on TSP-10k).\n* **Generalization:** We demonstrate that simple priors are far more robust to distribution shifts than complex learned patterns.\n\nIn summary, this paper challenges a fundamental assumption in the ML4CO community—that heatmap sophistication is the primary driver of performance. We provide the evidence and the pipeline to correct this course.\n\n---\n\n### **On Generalizability Beyond TSP**\n\n**1. Why TSP is the Necessary Choice for this Evaluation**\nWe chose to focus on TSP not as a limitation, but as a deliberate strategy to ensure rigorous evaluation. TSP currently offers the richest ecosystem of learning-based methods—including Att-GCN, DIMES, DIFUSCO, and SoftDist—making it the **only domain** where we can fairly isolate and systematically compare the impact of heatmap complexity versus MCTS configuration. Our goal was to rigorously audit the \"Heatmap + MCTS\" paradigm where it is most developed, rather than to propose a universal solver.\n\n**2. Core Insights are Generalizable; Implementation is Problem-Specific**\nWhile our experiments are specialized to Euclidean TSP, the central insight—that simple priors coupled with tuned search can rival complex models—is a principle that extends broadly. We acknowledge that applying this framework to other problems (e.g., CVRP, Graph Matching) requires two specific, albeit non-trivial, adaptations:\n\n* **Designing Problem-Specific Priors:** Just as we utilized the k-nearest neighbor structure for TSP, one would extract a structural prior from established constructive heuristics relevant to the new problem.\n* **Adapting Search Operators:** The MCTS engine would need to swap TSP-specific k-opt moves for operators native to the target domain, such as swap or relocate moves for Vehicle Routing Problems.\n\nThese modifications are conceptually straightforward but require domain-specific engineering. We view our findings not as a closed loop on TSP, but as a methodological blueprint for how to approach these extensions in future research."}}, "id": "2GpyKoYhNv", "forum": "H6PLJnnK6e", "replyto": "H6PLJnnK6e", "signatures": ["ICLR.cc/2026/Conference/Submission389/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission389/Authors"], "number": 7, "invitations": ["ICLR.cc/2026/Conference/Submission389/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763524699329, "cdate": 1763524699329, "tmdate": 1763524699329, "mdate": 1763524699329, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}