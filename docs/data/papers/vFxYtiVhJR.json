{"id": "vFxYtiVhJR", "number": 8096, "cdate": 1758062188163, "mdate": 1759897807769, "content": {"title": "DRO-Augment Framework: Robustness by Synergizing Wasserstein Distributionally Robust Optimization and Data Augmentation", "abstract": "In many real-world applications, ensuring the robustness and stability of deep neural networks (DNNs) is crucial, particularly for image classification tasks that encounter various input perturbations. While data augmentation techniques have been widely adopted to enhance the resilience of a trained model against such perturbations, there remains significant room for improvement in robustness against corrupted data and adversarial attacks simultaneously. \nTo address this challenge, we introduce DRO-Augment, a novel framework that integrates Wasserstein Distributionally Robust Optimization (W-DRO) with various data augmentation strategies to improve the robustness of the models significantly across a broad spectrum of corruptions. \nOur method outperforms existing augmentation methods under severe data perturbations and adversarial attack scenarios while maintaining the accuracy on the clean datasets on a range of benchmark datasets, including but not limited to CIFAR-10-C, CIFAR-100-C, Tiny-ImageNet-C, and Fashion-MNIST.  \nOn the theoretical side, we establish novel generalization error bounds for neural networks trained using a computationally efficient, variation-regularized loss function with augmented data, closely related to the W-DRO problem. Furthermore, we introduce a refined CIFAR-C benchmark that corrects inconsistencies in corruption intensities, providing a more reliable evaluation for future robustness research.", "tldr": "We propose DRO-Augment, a framework combining W-DRO and data augmentation, with both strong empirical robustness and theoretical generalization guarantees. We also proposed refined CIFAR-C datasets", "keywords": ["Distributionally Robust Optimization；Data Augmentation；Deep Learning；Multi-class Classification"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/99537d5f644e45bad68cd61a17d1d89b15dac3e0.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work proposes a novel training framework that integrates Wasserstein Distributionally Robust Optimization (W-DRO) with data augmentation to improve robustness against both adversarial attacks and corrupted data."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The proposed unified framework aims to enhance robustness against both common corruptions and adversarial attacks."}, "weaknesses": {"value": "* The overall contribution of this work appears to be marginal. The objective function defined in Eq. (2.1) is adopted from prior work, and the data augmentation strategies employed are common and well-established.\n* According to the results reported in RobustBench [1], accuracies against adversarial examples and corrupted data are evaluated on two distinct leaderboards. Methods such as NoisyMix and AugMix have already achieved strong performance on corruption benchmarks. Simply combining these data augmentation techniques with adversarial training does not seem to present a novel contribution, which diminishes the originality of this work.\n* The authors claim that “The proposed method can enhance robustness against both common corruptions and adversarial attacks” (lines 95–97). To substantiate this claim, the authors should evaluate the accuracy of existing adversarially trained models reported in RobustBench on corrupted datasets for comparison. In its current form, the empirical results are not convincing. A stronger baseline should be established using standard datasets such as MNIST, CIFAR-10/100, or ImageNet, rather than Fashion-MNIST or Tiny-ImageNet, to ensure fair and comparable results with existing works. I recommend that the authors include a direct comparison with these established models.\n\n[1] Croce, Francesco, et al. \"Robustbench: a standardized adversarial robustness benchmark.\" arXiv preprint arXiv:2010.09670 (2020)."}, "questions": {"value": "What is the relationship between the proposed Wasserstein Distributionally Robust Optimization approach and existing methods that introduce gradient flow regularization (i.e., regularization based on the alignment or flow of gradients) [2]?\n\n[2] Xia, Pengfei, and Bin Li. \"Improving resistance to adversarial deformations by regularizing gradients.\" Neurocomputing 455 (2021): 38-46."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LWkaCVFyib", "forum": "vFxYtiVhJR", "replyto": "vFxYtiVhJR", "signatures": ["ICLR.cc/2026/Conference/Submission8096/Reviewer_t8Zd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8096/Reviewer_t8Zd"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8096/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761805384862, "cdate": 1761805384862, "tmdate": 1762920080026, "mdate": 1762920080026, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DRO-Augment, a framework that combines Wasserstein Distributionally Robust Optimization with data augmentation techniques to improve neural network robustness against both natural corruptions and adversarial attacks. The authors provide theoretical generalization bounds for neural networks trained with variation-regularized loss on augmented data and introduce a refined CIFAR-C benchmark with corrected severity levels."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The combination of W-DRO and data augmentation is well-motivated and technically sound, effectively merging two complementary robustness strategies.\n- The paper establishes generalization error bounds for neural networks trained with W-DRO on augmented data, achieving a faster convergence rate compared to prior work.\n- Extensive experiments across multiple benchmark datasets (CIFAR-10-C, CIFAR-100-C, Tiny-ImageNet-C, Fashion-MNIST) with various attack types (PGD, AutoAttack, C&W, FAB-T, Square) provide convincing evidence of the method's effectiveness."}, "weaknesses": {"value": "- While the paper mentions small additional time costs, there is no systematic analysis of computational overhead compared to baselines, memory requirements, or scalability to larger datasets/models. Actually, this is very critical in practice.\n- The ablation studies, mainly in Table 3, only examine CIFAR-100-C and Fashion-MNIST. It should cover more datasets and analyze the sensitivity to key hyperparameters (for example, the mixing ratios \\frac{\\alpha}{\\beta}) more thoroughly. \n- The experiments use only PreActResNet-18, which limits understanding of how the method generalizes to other modern architectures (Vision Transformers, EfficientNets, etc.). The refined CIFAR-C evaluation only includes ResNet variants, not validating performance on the architectures mentioned as motivation."}, "questions": {"value": "- Can you provide results on modern architectures (ViT, ConvNeXt, EfficientNet) to demonstrate the method's broader applicability? \n- How does performance scale with model capacity?\n- What is the sensitivity of the method to the W-DRO radius?\n- Can you provide a detailed computational analysis, including training time, memory usage, and wall-clock time comparisons across all baselines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Nmeii807St", "forum": "vFxYtiVhJR", "replyto": "vFxYtiVhJR", "signatures": ["ICLR.cc/2026/Conference/Submission8096/Reviewer_tPWS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8096/Reviewer_tPWS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8096/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761947820509, "cdate": 1761947820509, "tmdate": 1762920079485, "mdate": 1762920079485, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces DRO-Augment, a training framework that combines Wasserstein Distributionally Robust Optimization (W-DRO) with data augmentation techniques to improve neural network robustness against both natural corruptions and adversarial attacks. The authors provide theoretical analysis establishing generalization error bounds for their approach and demonstrate empirical improvements on standard corruption benchmarks (CIFAR-10-C, CIFAR-100-C, Tiny-ImageNet-C) and adversarial robustness tests. Additionally, they propose a refined CIFAR-C benchmark to address inconsistencies in the original corruption severity settings"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper tackles both natural corruptions and adversarial attacks simultaneously, which is a practical consideration often overlooked in papers that focus on only one type of robustness. \n\n2. The paper provides generalization error bounds for neural networks trained with W-DRO and augmented data (Theorem 4.1), achieving an improved convergence rate compared to previous work. \n\n3. The authors identify and address a real issue with CIFAR-C severity calibration, proposing a more consistent evaluation framework based on ResNet performance."}, "weaknesses": {"value": "1. The main contribution is essentially combining two existing techniques (W-DRO and data augmentation) without fundamental algorithmic innovation.\n\n2. The paper admits DRO-Augment adds overhead due to gradient-norm evaluation but dismisses it as small. However, no measurements (FLOPs, time comparison) are given. Given that W-DRO involves per-sample gradients, cost may scale poorly with model size.\n\n3. Only PreActResNet-18 is tested. Without scaling to transformers, larger CNNs, or ImageNet-level datasets, the method’s generality and computational feasibility remain uncertain."}, "questions": {"value": "Please refer to the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6O7a8lzN3X", "forum": "vFxYtiVhJR", "replyto": "vFxYtiVhJR", "signatures": ["ICLR.cc/2026/Conference/Submission8096/Reviewer_WWKN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8096/Reviewer_WWKN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8096/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761983002655, "cdate": 1761983002655, "tmdate": 1762920078919, "mdate": 1762920078919, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a combined data augmentation and distributionally robust optimization framework DRO-Augment, aimed at improving both adversarial and natural corruption robustness of neural networks. The authors approximate the Wasserstein DRO objective using a variation-regularization surrogate (a gradient-norm penalty) and integrate it with popular augmentations (Mixup, AugMix, and NoisyMix). The work claims that this combination captures both worst-case perturbations (via DRO penalty) and diverse real-world corruptions (via augmentations). Theoretical contributions include an asymptotic robust generalization bound for mixup-trained models under a sparse ReQU network class, with explicit dependence on the Wasserstein radius ρ. Empirical results on CIFAR-10/100-C, Tiny-ImageNet-C, and adversarial settings (Fashion-MNIST-ε and Tiny-ImageNet-ε) show consistent robustness improvements with minimal accuracy loss. The paper also introduces a refined “severity scale” benchmark for CIFAR-C datasets."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Combines two complementary robustness paradigms, Wasserstein DRO in training and data augmentation before optimization, within a single unified and implementable framework. And effectiveness is validated by consistent empirical gains across multiply common datasets.\n\n2. The generalization bound includes explicit ρ-dependence and recovers the expected nonparametric rate under sparse ReQU networks, improving interpretability of robustness–sample trade-offs.\n\n3. The proposed refinement of CIFAR-C severity scales improves evaluation consistency and could serve as a useful benchmark extension.\n\n4. Writing quality and experimental reproducibility are strong overall. Tables and figures are clear and well-structured."}, "weaknesses": {"value": "1. The claimed L∞-Wasserstein DRO formulation conflicts with the L2-based implementation for the gradient penalty (P. 8, L.400-402). This inconsistency weakens the claim that the model optimizes L∞ W-DRO.\n\n2. The theoretical contribution on adversarial risk bounds is largely incremental. it mainly differs in applying mixup data and sparse ReQU architectures rather than introducing a new bounding method. Also, the network class smoothness bounds for norm of gradient  and (operator) norm of the Hessian (P. 8, L.425-426) are described informally as “almost bounded,” lacking explicit uniform inequalities or norm definitions needed for formal correctness.\n\n3. The authors note that NoisyMix has strong baseline robustness. But there is no per-augmentation analysis clarifying how noise-heavy augmentation interacts with DRO regularization and why improvements are limited."}, "questions": {"value": "1. Could you clarify the claim of focusing on the L∞-Wasserstein DRO while the proxy loss (P. 8, L.400-402) applies an L2 gradient penalty? Is the use of the L2 norm intended as an approximation for the L∞-Wasserstein ball, or should the formulation instead use an L1 penalty (dual of L∞)?\n\n2. Could you clarify the symbol consistency between Eq. 2.1 (P. 3) and Algorithm 1 (P. 4, L172). Equation 2.1 defines the gradient norm using the dual exponent q* with an outer 1/q power, while Algorithm 1 applies norm q without that outer power. Is this a typo inconsistency or an intentional change in implementation?\n\n3. Could you provide  additional  ablations to verify the relation between NoisyMix’s robustness by noise injections and the limited incremental benefit of the DRO regularization?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "X9Sy8yMXhk", "forum": "vFxYtiVhJR", "replyto": "vFxYtiVhJR", "signatures": ["ICLR.cc/2026/Conference/Submission8096/Reviewer_Yrw8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8096/Reviewer_Yrw8"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8096/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762182010382, "cdate": 1762182010382, "tmdate": 1762920078478, "mdate": 1762920078478, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}