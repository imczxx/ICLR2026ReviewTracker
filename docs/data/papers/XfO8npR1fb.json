{"id": "XfO8npR1fb", "number": 23672, "cdate": 1758346993433, "mdate": 1759896802274, "content": {"title": "Cracking the Hessian: Closed-Form Hessian Spectra for Fundamental Neural Networks", "abstract": "The Hessian and its spectrum hold significant theoretical and practical relevance for building optimizers, measuring generalization, compressing models, and more. Prior works have characterized the Hessian through its spectral density, rank, and the outlier–bulk structure of its spectrum, often relying on approximations. However, the precise behavior of Hessian eigenvalues and eigenvectors remains unclear, owing both to the absence of closed-form results for non-trivial neural networks and the computational expense of empirical estimation. In this work, we derive closed-form expressions for all Hessian eigenvalues and eigenvectors in two-layer linear and ReLU networks with scalar input, arbitrary hidden width, and where the loss is aggregated over any number of samples. We further provide closed-form eigenvalues for the core component of Transformer architectures --- a single self-attention layer with arbitrary sequence length. Our results reveal a previously undiscovered `paired' structure of outlier eigenvalues, a cell-wise decomposition of the Hessian spectrum with ReLU, and the sensitivity of the Hessian condition number to the query and key matrix norms, as well as the presence of attention sinks. We complement these findings with experiments beyond the assumed model setting, showing strong correlation between the largest eigenvalue and the spectral norm of weight matrices, and empirical evidence that the paired eigenvalue structure persists more generally. Overall, by establishing these closed forms for the first time, and introducing the corresponding proof technique, we advance our understanding of the Hessian and open new avenues for its use.", "tldr": "We derive the first closed-form Hessian spectra for simple but fundamental neural networks, revealing new structural insights and proof techniques with implications for theory and practice.", "keywords": ["Hessian", "Optimization", "Closed-form", "Deep Learning", "Theory"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3ecac0a4788f65c80418b7bd422e6385af45fd74.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper derives closed-form expressions for Hessian eigenvalues and eigenvectors for two-layer linear and ReLU networks with scalar input, and provides closed-form eigenvalues for a single self-attention layer. The work reveals a previously undiscovered paired structure of outlier eigenvalues and explores correlations between weight matrix norms and Hessian eigenvalues in more complex architectures."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The theoretical contributions represent the first successful derivation of complete, exact Hessian spectra for non-trivial neural networks without approximations. The closed-form results for linear networks (Theorem 3.1), ReLU networks (Theorem 3.4), and self-attention layers (Theorem 3.5) provide valuable analytical tools for understanding loss landscapes, with the paired eigenvalue structure offering new insights into Hessian behavior throughout training.\n  - The empirical validation extends beyond theoretical assumptions to practical architectures, including GPT2 models. The correlation studies between weight matrix spectral norms and Hessian eigenvalues (Section 4.2) provide actionable insights that appear to hold across different parametrizations and network depths, while experiments on attention sinks offer concrete guidance for Transformer architecture design."}, "weaknesses": {"value": "- The theoretical results are restricted to highly simplified settings (scalar input/output for linear and ReLU networks, single self-attention layers), which limits their direct applicability. While the paper attempts to extend results to multi-dimensional cases in the appendix (Section B.4), these extensions require strong structural assumptions on weight matrices (e.g., block diagonal or specific factorizations) that may rarely hold in practice. The gap between the theoretical models (e.g., f(x) = ⟨w,v⟩x) and practical deep networks is substantial, and the paper would benefit from more explicit discussion of when these assumptions are reasonable approximations versus when they fundamentally break down.\n  - The connection between the closed-form results and the empirical observations in Section 4 lacks rigor. For instance, the correlation studies in Section 4.2 show that spectral norms of weight matrices correlate with Hessian eigenvalues, but there is no formal analysis explaining why this correlation exists or under what conditions it should hold. Similarly, the claim that GGN provides worse approximations for Transformers than MLPs (Section 4.3) is based only on GPT2 experiments with limited analysis of the underlying mechanisms. Adding theoretical justification or at least formal conjectures would strengthen these empirical findings.\n  - The paired eigenvalue structure (Section 4.1), while interesting, receives insufficient analysis regarding its practical implications. The paper demonstrates that eigenvalue pairs sum to approximately (1/D)tr(H) but does not explain what this means for optimization dynamics, model training, or practical algorithm design. For example: Does this pairing affect convergence rates? Does it inform choices of learning rates or optimization algorithms? Could it be exploited for better Hessian approximation methods? The paper would benefit from exploring these questions or at least providing concrete examples where the paired structure matters for practical applications.\n  - The experiments validating the paired eigenvalue structure beyond theoretical assumptions (Figure 3) show that the pairing becomes approximate rather than exact. The paper reports differences on the order of 10^(-3) to 10^(-5) but does not analyze when or why these approximations degrade. More importantly, there is no investigation of how network depth, nonlinearities, or other architectural choices affect the quality of this approximation. Understanding these failure modes would be valuable for practitioners and could guide future theoretical work. I will reconsider my score in the rebuttal."}, "questions": {"value": "see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "08twO0JLcd", "forum": "XfO8npR1fb", "replyto": "XfO8npR1fb", "signatures": ["ICLR.cc/2026/Conference/Submission23672/Reviewer_iw5q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23672/Reviewer_iw5q"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23672/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760495167680, "cdate": 1760495167680, "tmdate": 1762942756617, "mdate": 1762942756617, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper first derivied a closed-form formulae for the complete Hessian spectrum of Linear, RELU and self-attention neural networks using a proof technique. The study extended the formulae towards a `paired' structure of outlier eigenvalues, and the correlation between the largest eigenvalue and the spectral norm of weight matrices."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper extended previous studies on the Hessian spectrum structure to several novel theoretical assumptions and insights verified by empirical studies, demonstrating a comprehensive in-depth understanding.\n2. The theorem proof is clear and intriguing, with a new perspevtive on the two paired outlying eigenvalues persisting across different neural architectures."}, "weaknesses": {"value": "The major theorem on closed-form Hessian is derived upon input/output or embedding dimension equal to 1; while extended in the Appendix and verified with empirical observations beyond these assumptions, the strength of the theoretical explanation remains vague."}, "questions": {"value": "1. Upon the paired eigenvalue, would their value or sum correlates stronger to the spectral norm, as a measure of sharpness than only the largest eigenvalue, as theorem 3.1 suggested?\n2. In recent empirical works , roughly ~10 eigenvalue outliers is observed in teh complete Hessian spectrum across a variety of models, neigher the top-2 paired eigenvalues does not add up to the Hessian trace, could you elaborate your theorem on their observations?\n3. Is it possible to derive a two-layer neural network Hessian Lemma under the assumption that the input and/or output dimension equal to 2, or the theorem holds for dimension k+1 if proved for dimension k?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "eTSxEeV5l1", "forum": "XfO8npR1fb", "replyto": "XfO8npR1fb", "signatures": ["ICLR.cc/2026/Conference/Submission23672/Reviewer_Lt5D"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23672/Reviewer_Lt5D"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23672/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761663830345, "cdate": 1761663830345, "tmdate": 1762942756050, "mdate": 1762942756050, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors provide explicit closed form expression for eigenvalues and eigenvectors of simple neural networks: \n- 2 layer linear network from R to R, with 2m parameters (and later they extend this to larger input and output dimensions)\n- 2 layer ReLU network from R to R, with 2m parameters\n- 1 layer of softmax attention (embedding dimension 1, length n, d_k+1 parameters)\n\nThe authors find that in linear models there exists a pair of eigenvalues that sum to the trace of the matrix, and verify that this is approximately true also for larger input and output dimensions (Section 4.1).\n\nThey then discuss (numerically) which matrix norm of the weights correlates most with the largest hessian eigenvalue in linear networks, and find that it is the spectral norm. The authors discuss this issue also in transformers."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The authors obtain very explicit solutions for the spectrum of the Hessian, which allows for direct interpretability."}, "weaknesses": {"value": "The setting the authors consider is very simple, looking at D=1 inputs and outputs (and relaxing this requirement only in a somewhat technical way in line 358-360) and linear architectures. They also consider the smallest (dimension-wise) possible attention layer, which is nice but one should also remember that softmax is morally an invertible function (modulo an overall shift), so it is not clear to me how much more non-linear this setting is.\nThe experiments in subsequent sections do not highlight key properties that are both known to be important in more complicated networks, and are already captured by the simple models, putting into question how much general insight we can gain from the presented results.\n\nSection 4.2: it is unclear to me what is the purpose of this section. It seems to me to test quantities/correlations that are not inspired by the theoretical results. Also, the authors limit themselves to numerical analysis of still very simple networks, while they could perform similar analysis on nets that are at least non-linear.\nSimilar comments hold for Section 4.3, first paragraph."}, "questions": {"value": "line 107: there is a full line of works studying Hessians in spin glass models and simple models of learning, see for e.g. https://arxiv.org/pdf/2006.06997, https://arxiv.org/pdf/2202.04509 and references therein. How does your work relate to those, and in particular, is the statement that no work has obtained closed form expression still valid?\n\nCan you motivate better what is the realtionship between the numerical experiments in Section 4.2 and the previous theoretical analysis?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "YIaxkqI4Co", "forum": "XfO8npR1fb", "replyto": "XfO8npR1fb", "signatures": ["ICLR.cc/2026/Conference/Submission23672/Reviewer_UcKL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23672/Reviewer_UcKL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23672/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761753512397, "cdate": 1761753512397, "tmdate": 1762942755660, "mdate": 1762942755660, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper derives closed-form expressions for the complete Hessian spectra (eigenvalues and eigenvectors) of fundamental neural networks, specifically two-layer linear and ReLU MLPs with scalar input/output, arbitrary hidden width, and MSE loss over any samples, plus a single-head self-attention layer with arbitrary sequence length and embedding dim=1. It uncovers a paired outlier eigenvalue structure summing to a trace fraction, cell-wise spectral decomposition for ReLU, Hessian condition number sensitivity to query/key matrix norms, and attention sinks amplifying outliers. Tested empirically on deeper linear networks with varying depths/widths/dims/parametrizations, and GPT2-124M pre-training on OpenWebText. Results show strong sharpness-spectral norm correlations, worse GGN approximation in Transformers vs. MLPs, and paired structure persistence. Overall, it bridges the gap between approximations and exact Hessian analysis, enhancing insights into optimization, generalization, and loss landscapes.\n\nStrength:\n- Introduces a novel proof technique yielding exact, interpretable closed-forms for non-trivial NNs, enabling precise theoretical insights where prior work relied on bounds or numerics.\n\nWeaknesses:\n- The theoretical results for self-attention are derived under highly restrictive assumptions, such as embedding dimension d=1 and single-head attention, which do not capture the multi-head, high-dimensional nature of real Transformers. This limits generalization, as dimensional interactions could fundamentally alter the spectrum, yet no analysis of higher dimensions is provided.\n- The proof technique, while novel, depends on specific structural assumptions (e.g., block-diagonal weights for multi-dimensional extensions, orthogonal v and b in bias cases) that are unjustified in general deep learning settings; failure to discuss scalability or applicability to non-linear, multi-layer architectures risks overstating the method's utility.-"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Introduces a novel proof technique yielding exact, interpretable closed-forms for non-trivial NNs, enabling precise theoretical insights where prior work relied on bounds or numerics."}, "weaknesses": {"value": "- The theoretical results for self-attention are derived under highly restrictive assumptions, such as embedding dimension d=1 and single-head attention, which do not capture the multi-head, high-dimensional nature of real Transformers. This limits generalization, as dimensional interactions could fundamentally alter the spectrum, yet no analysis of higher dimensions is provided.\n- The proof technique, while novel, depends on specific structural assumptions (e.g., block-diagonal weights for multi-dimensional extensions, orthogonal v and b in bias cases) that are unjustified in general deep learning settings; failure to discuss scalability or applicability to non-linear, multi-layer architectures risks overstating the method's utility.-"}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "dfUwcVEn9q", "forum": "XfO8npR1fb", "replyto": "XfO8npR1fb", "signatures": ["ICLR.cc/2026/Conference/Submission23672/Reviewer_wW7M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23672/Reviewer_wW7M"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23672/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762146414991, "cdate": 1762146414991, "tmdate": 1762942755475, "mdate": 1762942755475, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}