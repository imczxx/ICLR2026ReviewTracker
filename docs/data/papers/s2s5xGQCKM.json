{"id": "s2s5xGQCKM", "number": 16958, "cdate": 1758270585447, "mdate": 1763725738444, "content": {"title": "Generating Directed Graphs with Dual Attention and Asymmetric Encoding", "abstract": "Directed graphs naturally model systems with asymmetric, ordered relationships, essential to applications in biology, transportation, social networks, or visual understanding. Generating such graphs enables simulation, data augmentation and novel instance discovery; however, this task remains underexplored. We identify two key reasons: first, modeling edge directionality introduces a substantially larger dependency space, making the underlying distribution harder to learn; second, the absence of standardized benchmarks hinders rigorous evaluation. Addressing the former limitation requires more expressive models that are sensitive to directional topologies. Thus, we propose Directo, the first generative model for directed graphs built upon the discrete flow matching framework. Our approach combines: (i) a dual-attention mechanism distinctly capturing incoming and outgoing dependencies, (ii) a robust, discrete generative framework, and (iii) principled positional encodings tailored to asymmetric pairwise relations. To address the second limitation and support evaluation, we introduce a novel and extensive benchmark suite covering synthetic and real-world datasets. Experiments show that our method outperforms existing directed graph generation approaches across diverse settings and competes with specialized models for particular classes, such as directed acyclic graphs. These results highlight the effectiveness and generality of our approach, establishing a solid foundation for future research in directed graph generation.", "tldr": "", "keywords": ["graph generation", "directed graphs", "flow matching", "discrete diffusion"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e1358f0c473ecea04d6b7176624649e81e030074.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "DIRECTO is a discrete-state, iterative-refinement generator specifically designed for directed graphs. It introduces two key enhancements: (1) direction-aware positional encodings, and (2) a dual-attention transformer that explicitly combines source-to-target and target-to-source channels. The training process employs discrete flow matching, and the authors also present a discrete-diffusion variant. The generated graphs are evaluated on various benchmarks, including synthetic directed/DAG distributions, TPU compute DAGs, and Visual Genome scene graphs. The evaluation metrics focus on validity, uniqueness, and novelty, as well as a normalized MMD Ratio and label-aware distances on real-world data."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Treating directionality as a first-class citizen (both in PEs and attention) is long overdue. Dual attention is a clean, architecture-level bias that addresses asymmetry.\n\nThe comparison between “dual vs double depth” demonstrates a genuine architectural advantage, not merely an increase in capacity.\n\nEvaluating typed constraints on Visual Genome and acyclicity on DAGs is the appropriate approach. The V.U.N. effectively penalizes memorization.\n\nThe same directional concepts also apply to discrete diffusion (DIRECTO-DD), indicating that they are not exclusive to DFM-specific techniques."}, "weaknesses": {"value": "1. Directed attention doubles attention maps, while MagLap/Multi-q PEs are expensive. Additionally, CTMC sampling requires numerous steps to achieve quality. The paper claims decent scaling, but we need to compare it to strong autoregressive digraph models on larger graphs, considering wall-clock time and VRAM usage versus.\n\n2. The benchmarks are relatively small and close to the training support. We need out-of-distribution (OOD) tests, such as altered degree exponents, flipped community asymmetry, or different label marginals. This will help us understand how brittle dual attention is when arrow statistics shift."}, "questions": {"value": "How much of the performance improvement is attributed to (a) splitting the roles (S/T) versus (b) employing the aggregation trick (concat two maps and then apply one softmax)? Please provide an ablation study that distinguishes between (i) role-splitting alone, (ii) role-splitting with FiLM edge modulation, and (iii) role-splitting with a unified softmax.\n\nWere the sampling steps, time, and VRAM used in each model (including DIRECTO-DD) consistent? Please include a fairness table.\n\nThe authors consider every ordered pair as a categorical “edge (including absent).” How is the graph size N determined at the generation time, and do the metrics account for N?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wmv35YInjC", "forum": "s2s5xGQCKM", "replyto": "s2s5xGQCKM", "signatures": ["ICLR.cc/2026/Conference/Submission16958/Reviewer_gox2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16958/Reviewer_gox2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16958/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761636855075, "cdate": 1761636855075, "tmdate": 1762926979149, "mdate": 1762926979149, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Directo, a method for generating directed graphs based on discrete flow matching. Great care is given to the denoising model arch. To enhance the capability of the method to handle edge directionality, 1) a tailored attention mechanism called \"dual attention\" is proposed; and 2) asymmetric position encodings, such as those based on directional Laplacians, are used. Other GNN components from prior work, FiLM and PNA, are also incorporated into the arch. Besides the method, the paper also creates a benchmark for directed graph generation, with several synthetic and real-world datasets. Directo is shown to have strong performance on this benchmark relative to other methods, based on evaluation metrics adapted to the setting. Finally, further experiments are discussed that explore the impact of ablating the major model arch components, as well as the scalability of the method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The area of directed graph generation seems important but relatively unexplored given the many works for undirected graph generation.\n- The writing is clear, grammatical, and well-organized.\n- The paper introduces not only a new method, but also a benchmark for the area of directed graph generation. A code repository is included for reproducibility.\n- Ablations are included to justify major new components of the model arch."}, "weaknesses": {"value": "- The proposed arch is complex, and while there are ablation studies for some important components, this is not true of all components, e.g., use of FiLM.\n- As the authors note, the proposed method can fail to maintain validity when scaling up (e.g., failing to maintain strict acyclicity beyond 200 nodes).\n- Ideally the broad setting of the paper in terms of the scale of generated graphs would be clarified earlier in the paper. Graph generation papers and algorithms roughly cluster on two categories, those for 10s-100s of nodes (this paper), and others for 1000s-10000s and up.\n- (nit) Some notation could be easier to read, e.g., the use of Kronecker delta in Eq 1 could be replaced with piecewise notation."}, "questions": {"value": "- Much of the main paper describes a complex GNN arch tailored for directed graphs, which could be applied outside of the graph generation setting, e.g., to link prediction or node classification. Has this been attempted? It seems worthwhile to evaluate the arch on the more standardized benchmarks for those tasks. If the results are weak on other tasks but strong for generation, that is also an interesting finding.\n- Relatedly, there is little discussion of the flow matching part in the main paper. Were there any interesting findings related to the flow matching as opposed to the arch that have not been discussed in prior work?\n- Regarding the time distortion function, it is stated that \"these functions are selected based on dataset-specific properties to improve fidelity and structural constraints without need for retraining.\" Could you please clarify the selection procedure, given that there is not a unique objective unlike in typical hyperparameter selection via cross-validation, e.g., for node classification?\n- For graph generation papers in general, a core theme is the trade-off between generating diverse graphs (U.N. from V.U.N.) and graphs that match the training distribution (\"ratio\" in this paper). Is there some way to tune the proposed method to favor one or the other? How does the ease of such tuning compare to other methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DA8kGojHwP", "forum": "s2s5xGQCKM", "replyto": "s2s5xGQCKM", "signatures": ["ICLR.cc/2026/Conference/Submission16958/Reviewer_RPrZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16958/Reviewer_RPrZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16958/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761906893191, "cdate": 1761906893191, "tmdate": 1762926978699, "mdate": 1762926978699, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes a model for generating directed graphs. Its main contributions are in (i) the use of direction-aware positional encodings, (ii) a dual attention mechanism that again takes edge directions into account and (iii) the introduction of new benchmarks for evaluating directed graph generative models. The performance is measured across different synthetic and true graphs and seemingly outperforms other undirected GGM or specialized in generating DAG models. An ablation study shows that the dual attention mechanism is critical in the increased performance."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "* The model proposed in this work succeeds in generating graphs with specific constraints (acyclic, or edges only across certain types) even if those constrains are not explicitly stated (e.g., through some regularization parameter) during the training process. \n* The architecture is quite generic in that it can be used to generate directed graphs of virtually any type as edges are encoding through categorical variables, while it can also accomodate node and graph features."}, "weaknesses": {"value": "*  The model itself, at least as presented, is not self-contained. Section 2 which provides a background on diffusion models and past work seems disconnected to Section 3 that describes the attention mechanism employed. For example, it is not specified how edges are modeled through categorical variables (e.g, is it representing one of the 4 possible classes -- edges in both directions, in one of the two (x2), or absent?), how the rate matrix is parameterized though the proposed architecture, while fig. 2 employs global features that are not part of the loss function in eq. 4.\n* The complexity of the proposed model seems to make it a bit susceptible to choice of hyperparameters (see fluctuation in performance in fig 4).\n* The novelty of the work is on the dual attention mechanism, but it does not extend to other parts of it (e.g., new positional encoding, diffusion process is of DFM, evaluation metrics is MMD)."}, "questions": {"value": "Q1: are global features utilized/ part of the training loss? what is the categorical modeling for edges for the datasets the model is evaluated against?\nQ2: What is the benefit of MagLap encoding vs the directed laplacian of chung?\nQ3: Ratio comes from averaging the MMD for different descriptors. Is it though a good practice to average MMD for different descriptors when it is unbounded and lacks scale comparison?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "tQvPeK7DyJ", "forum": "s2s5xGQCKM", "replyto": "s2s5xGQCKM", "signatures": ["ICLR.cc/2026/Conference/Submission16958/Reviewer_pVm7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16958/Reviewer_pVm7"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16958/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762420416095, "cdate": 1762420416095, "tmdate": 1762926978372, "mdate": 1762926978372, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present DIRECTO, a new method for generating directed graphs, an area that has been underexplored in graph generative modeling. The approach builds upon the discrete flow matching framework and introduces two key architectural components: (1) a dual attention mechanism that captures both source-to-target and target-to-source representations, and (2) direction-aware positional encodings. The authors indicate that the dual attention component is more critical to performance than the positional encodings. Additionally, they contribute a new benchmark suite containing synthetic and real-world datasets, along with metrics tailored for evaluating directed graph generation quality. The paper demonstrates strong empirical results across diverse settings. While the work provides a solid foundation for directed graph generation, conditional generation remains relatively underexplored and is identified as an important direction for future work."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- Novel and Important Problem: The paper addresses a significantly underexplored area in graph generation. The focus on directed graphs is well-motivated, with clear applications in biology, transportation networks, and scene understanding.\n- Comprehensive Technical Approach: The dual attention mechanism is presented as a solution to capture bidirectional dependencies inherent in directed graphs. The integration with discrete flow matching provides a principled generative framework with theoretical grounding.\n- Extensive Empirical Evaluation: The paper presents thorough experiments across multiple datasets, baselines, and ablation studies. The results consistently demonstrate the effectiveness of the proposed approach.\n- Benchmark Contribution: The introduction of standardized benchmarks for directed graph generation is a valuable contribution that will facilitate future research in this area. This work can provide a solid evaluation suite to later directions in the field.\n- Clear Presentation: The paper is well-written with clear motivation, technical exposition, and comprehensive experimental analysis. All visualizations seem relevant and convey information clearly.\n- Thorough Ablations: The systematic ablation studies effectively isolate the contributions of different components."}, "weaknesses": {"value": "- Unclear Claims on Expressiveness: While the authors claim their method is \"expressive\" and \"robust,\" these claims lack formal theoretical justification or empirical evidence. The notion of expressiveness in the context of directed graph generation needs clearer definition and supporting arguments.\n\n- Scalability Concerns vs. Efficiency Claims: The paper mentions \"efficient generation\" but simultaneously acknowledges scalability limitations. This contradiction needs clarification. Table 20 shows significant performance degradation for larger graphs (200-250 nodes), which undermines efficiency claims.\n\n- Conditional Generation Underexplored: While acknowledged as future work, the conditional generation experiments (Section H.7) are limited. Given the practical importance of conditional generation for real-world applications, this might deserve more attention.\n\nLimited Architectural Justification: Several design choices appear ad-hoc:\n- Why is independent interpolation used in the noising process (Eq. 1). It is this unclear if this is a simplifying assumption or theoretically motivated.\n- The gated residual connection for node features (Eq. 23-24) lacks justification compared to standard residual connections used elsewhere."}, "questions": {"value": "- Positional Encoding Design Choice: The authors concatenate positional encodings to node and edge features rather than using more integrated approaches common in modern transformers (e.g., addition, rotational embeddings like RoPE, or ALiBi). What is the rationale for choosing concatenation? Has the impact on parameter efficiency been considered, given that concatenation increases the input dimensionality? Were alternative integration methods explored?\n\n- Figure 1b Clarification: What do the node colors represent in Figure 1b? This visual element should be explained or removed if purely aesthetic.\n\n- Independent Interpolation Assumption: Why is independent interpolation used in the noising process (Eq. 1)? Is this a simplifying assumption for computational tractability, or is there theoretical justification for treating nodes and edges independently during the noising process?\n\n- Architectural Choices: What is the motivation for the gated residual connection in the node feature update (Eq. 23-24) when standard residual connections are used elsewhere? Has ablation been performed on this component?\n\n- Section 3.2 Reference: The last paragraph mentions ablation studies but doesn't specify where results are presented. Could you add a forward reference?\n\n- TPU Tiles Dataset: For the TPU Tiles dataset, was the preprocessing identical to Li et al. (2025), or were there modifications? This should be clarified."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lWX0PnbmxU", "forum": "s2s5xGQCKM", "replyto": "s2s5xGQCKM", "signatures": ["ICLR.cc/2026/Conference/Submission16958/Reviewer_A2gN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16958/Reviewer_A2gN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16958/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762645441395, "cdate": 1762645441395, "tmdate": 1762926977827, "mdate": 1762926977827, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}