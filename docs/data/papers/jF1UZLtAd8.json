{"id": "jF1UZLtAd8", "number": 4882, "cdate": 1757783254330, "mdate": 1759898007400, "content": {"title": "Where do Reasoning Models Make a Difference? Follow the Reasoning Leader for Efficient Decoding", "abstract": "Large reasoning models (LRMs) achieve strong reasoning performance by emitting long chains of thought (CoT), yet these verbose traces slow down inference and often drift into unnecessary detail, known as the overthinking phenomenon. To better understand LRMs' decoding behavior, we systematically analyze the token distribution misalignment for the recent capable LRMs. We observe a similar superficial alignment phenomenon in which misaligned tokens are mostly the stylistic tokens related to thinking patterns that probably occur at the beginning of sentences, further leading to a novel \\textit{sentence-level misalignment diminishing} phenomenon. Exploiting this insight, we propose a collaborative fast-slow thinking decoding method for cost-quality trade-off, FoReaL-Decoding, in which a Leading model leads the first few tokens for each sentence, and then a weaker Drafting model completes the following tokens to the end of each sentence, controlled by a stochastic gate. FoReaL-Decoding smoothly interpolates between the small and the large model. On four popular math-reasoning benchmarks (AIME24, GPQA-Diamond, MATH500, AMC23), FoReaL-Decoding cuts theoretical FLOPs by 30 – 50 and trims CoT length by up to 40, while preserving 86 - 100 of model performance. These results establish FoReaL-Decoding as a simple, plug-and-play route to controllable cost-quality trade-offs in reasoning-centric tasks.", "tldr": "We systematically analyze the token distribution misalignment for large reasoning models and propose a novel collaborative decoding method.", "keywords": ["Large language Model", "Reasoning", "Generation", "Speculative Decoding"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7466687ccfdfa73d7673de6fa683119c5b8bc435.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper studies where reasoning-oriented LLMs actually differ from standard instruction models. The key idea is to identify token-level misalignment patterns and exploit them for efficient decoding. Specifically, it finds that reasoning cues concentrate at sentence beginnings and proposes FoReaL-Decoding, where a strong model generates initial tokens before handing off to a smaller one. Experiments on several math reasoning benchmarks show comparable accuracy with up to 50% lower computation cost."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**[S1]** The paper provides a much-needed analysis of how reasoning and non-reasoning models differ at the token level. The observations are insightful, and the proposed method is conceptually sound and novel. The reverse interpretation of Speculative Decoding is particularly interesting.\n\n**[S2]** The paper is overall well organized, clearly written, and easy to follow despite covering both analytical and methodological aspects.\n\n**[S3]** The work addresses an important and timely problem (i.e., reducing overthinking and improving efficiency in reasoning LLMs)."}, "weaknesses": {"value": "**[W1`] Lack of causal analysis.** The paper identifies token-level patterns but does not clearly establish why reasoning models exhibit these behaviors; the explanations remain descriptive rather than causal.\n\n**[W2] Evaluation bias from leader-forced alignment.** Misalignment is measured relative to the leader’s greedy outputs, which may exaggerate divergence and fail to reflect natural decoding dynamics.\n\n**[W3] Simplistic sentence segmentation.** Sentences are detected only by punctuation or newlines, so the core sentence-initial reasoning cue assumption may break in tasks with non-standard formatting or code-like outputs.\n\n**[W4] Only math domain.** Experiments focus almost exclusively on math reasoning datasets, leaving the generality to other reasoning types (e.g., code, commonsense) unclear.\n\n**[W5] More important efficiency metrics.** The analysis reports theoretical TFLOPs rather than real latency (i.e., throughput), making the claimed efficiency improvements less convincing for real-world deployment.\n\n**[W6] Hyperparameter sensitivity analysis is required.**\nThe gating settings (n, p, and k) are somewhat arbitrary, and robustness or automatic tuning is not explored.\n\n\nI quite like the paper and believe that it has the strength to be accepted. I have recommended rejection since there are several weaknesses highlighted in the review (but I think they can be easily resolved through the rebuttal). I kindly ask the author to resolve my questions during their rebuttal."}, "questions": {"value": "See the weakness above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "F7vIF4Gtue", "forum": "jF1UZLtAd8", "replyto": "jF1UZLtAd8", "signatures": ["ICLR.cc/2026/Conference/Submission4882/Reviewer_56oq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4882/Reviewer_56oq"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4882/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761208437055, "cdate": 1761208437055, "tmdate": 1762917737569, "mdate": 1762917737569, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel reasoning decoding method, FoReaL-Decoding, aimed at accelerating the inference of reasoning models.\nThe method is motivated by two key observations: Global Misalignment Rebound and Local Misalignment Diminish.\nExperimental results show that the proposed approach outperforms existing methods, including lossless frameworks such as Speculative Thinking."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is clear and easy to follow, with well-presented motivation and methodology.\n- The proposed observations are interesting, and the resulting decoding method seems quite effective, outperforming Speculative Thinking on reasoning benchmarks."}, "weaknesses": {"value": "**[W1] Restricted experimental scope.** Despite the interesting observations, both the analyses and experiments are conducted only on the Qwen family. This narrow scope limits the generality and broader applicability of the findings. \n\n**[W2] Limited logical continuity.** While the paper highlights two main observations—Global Misalignment Rebound and Local Misalignment Diminish—the proposed method is mainly motivated by the latter. The connection between the observations and the final design could be more coherently justified. \n\n**[W3] Unclear advantage over speculative decoding.** Although the method is distinct from existing speculative decoding paradigms, its advantage remains questionable. In Table 3, the comparison with Speculative Decoding appears somewhat unfair, as the draft lengths used (10 and 20) are unusually large. A fairer comparison would involve shorter draft lengths."}, "questions": {"value": "**[Q1]** Are the proposed observations generalizable to other reasoning models (e.g., LLaMA family) or to heterogeneous setups where the leading and draft models differ (e.g., LLaMA → Qwen)?\n\n**[Q2]** In Table 1, only TFLOPs are reported. Could the authors also provide real latency measurements on GPUs to better quantify the practical speedup?\n\n**[Q3]** Please re-evaluate the comparison with Speculative Decoding. Under settings where FoReaL-Decoding maintains target performance, compare with shorter draft lengths (e.g., 3 or 5) to ensure fairness and clarity of the claimed advantage."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "BpXOPZbCLq", "forum": "jF1UZLtAd8", "replyto": "jF1UZLtAd8", "signatures": ["ICLR.cc/2026/Conference/Submission4882/Reviewer_y5zv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4882/Reviewer_y5zv"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4882/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761653421109, "cdate": 1761653421109, "tmdate": 1762917737195, "mdate": 1762917737195, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel decoding framework designed to improve the efficiency of reasoning-oriented large language models. After a token-level alignment analysis between reasoning and non-reasoning models, paper highlights two phenomena:\n- Global Misalignment Rebound: Reasoning models remain stylistically and distributionally divergent even as generation length increases\n- Local Misalignment Diminish: Divergence spikes at the beginning of each sentence and then quickly decays.\nLeveraging these findings, the authors propose a collaborative decoding strategy where a strong reasoning model leads the initial tokens of each sentence, while a smaller model completes the decoding.\nExperiments are demonstrated on math-reasoning benchmarks (AIME24, GPQA-D, MATH500, AMC23)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Conducted token-level alignment analysis is highly informative on reasoning-specific patterns.\n- Proposed framework is easy to control and allows adjustment with interpretable parameters.\n- Empirical results shown that the proposed decoding strategy provides significant FLOP reduction and shorter CoTs."}, "weaknesses": {"value": "- Reasoning domain is subjected to math reasoning. Lacks demonstration on domains with  complex problems that require unique problem solving strategies such as constraint satisfaction, MDP.\n- Framework is too-dependent on the existence of a significantly stronger large reasoning model.\n- Interpretation of global and local misalignments are not clearly discussed."}, "questions": {"value": "- Including different domains into evaluation\n- Mechanistic-Interpretability approaches to clearly explain the identified misalignment phenomena\n- Such token level-analysis and focus on divergence spikes could have been discussed alongside with the token-level entropy metrics."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "oK16w6FmGC", "forum": "jF1UZLtAd8", "replyto": "jF1UZLtAd8", "signatures": ["ICLR.cc/2026/Conference/Submission4882/Reviewer_dd3E"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4882/Reviewer_dd3E"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4882/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761855156859, "cdate": 1761855156859, "tmdate": 1762917736701, "mdate": 1762917736701, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper analyzes the differences in token distributions between reasoning models and base/instruction tuned models and finds that token distributions globally diverge from that of base/instruction tuned models with more context, but that on the sentence level, most of the difference occurs at the beginning of sentences. This motivates FoReaL-Decoding where a reasoning model is only used for the first few tokens and a non-reasoning model generates the rest of the sentence. They show that this retains most of the performance of the reasoning model while substantially reducing cost."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The paper is clear and easy to follow.\n* The two phenomena of “global misalignment rebound” and “local misalignment diminish” are potentially valuable empirical insights into how LRMs behave.\n* The proposed FoReaL-Decoding method is a useful decoding method which can be used instead of traditional speculative decoding for LRMs. The method is novel in how it treats beginning and end of sentences as different.\n* This method can have significant impact by reducing reasoning cost."}, "weaknesses": {"value": "* The observed phenomena are not statistically quantified which seems important to accurately judging if this is a real phenomenon.\n* The approach reminds me of s1 where the phrase “wait, “ is repeatedly added the model’s context which leads to a large performance improvement. A comparison to this type of approach where a fixed phrase is added with a certain probability as the beginning of each sentence would be useful to determine how much the “Lead” model actually contributes.\n* Related to the above, it is not shown if the “Lead” model when used with FoReaL-Decoding is actually mostly outputting thinking patterns such as “wait” and “perhaps” or doing something else. Even a qualitative example of what the output from FoReal-Decoding looks like would help clarify this.\n* It is not clear why reasoning length (overthinking) decreases at all with this method. The stochastic binary gate between when to use the draft model vs. lead model seems to be important for this, but the paper does not seem to provide evidence for why such a gate is useful.\n* Main results in Table 1 are missing error bounds."}, "questions": {"value": "1. For Figure 2, the difference between misalignment rebounding and what happens with the instruct and base model is subtle. Can the difference be quantified as statistically significant?\n2. If the Lead model is mostly generating patterns such as “wait” and “perhaps”, then how would FoReaL-Decoding compare to an approach where the lead model is replaced with the static phrase “wait, “ which would start each sentence whenever the lead model is selected?\n3. Why does reasoning length decrease using FoReaL-Decoding? Perhaps an ablation of the stochastic binary gate could answer if the gate is really the reason for the reduction in length.\n\n\nMinor notes:\n* The term \"Local Misalignment Diminish\" sounds a bit weird in the paper since it is often used as a noun phrase, since you refer to is a phenomenon. Renaming this to something like \"Local Misalignment Decay\" will make the sentences flow better."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "tMdK6VvPUT", "forum": "jF1UZLtAd8", "replyto": "jF1UZLtAd8", "signatures": ["ICLR.cc/2026/Conference/Submission4882/Reviewer_HLkD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4882/Reviewer_HLkD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4882/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761940702135, "cdate": 1761940702135, "tmdate": 1762917701265, "mdate": 1762917701265, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}