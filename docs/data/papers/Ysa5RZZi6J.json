{"id": "Ysa5RZZi6J", "number": 22506, "cdate": 1758332022169, "mdate": 1759896862307, "content": {"title": "Nonparametric Unsupervised Data Condensation for Gigapixel Histological Images", "abstract": "Histological whole-slide images (WSIs) are central to computational pathology but are extremely large, often several gigabytes, making them infeasible for direct use in standard vision pipelines. Prior approaches reduce training cost by condensing WSIs into a fixed number of representative features (prototypes), but this approach overlooks the varying complexity and diversity of WSIs, leading to loss of critical information. To this end, we propose **NICER**, a probabilistic data condensation framework that decomposes each WSI into feature patterns to capture heterogeneity and concept prototypes to ensure compactness. By reformulating prototype construction as a nonparametric condensation problem, NICER adapts the number of prototypes to slide complexity while preserving relevant information. Experiments on four histological datasets show that NICER outperforms prior methods, yielding up to 90% performance gains and superior efficiency trade-offs, setting a new paradigm for histological representation learning.", "tldr": "", "keywords": ["unsupervised condensation", "probabilistic model", "histological imaging"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0b195cdb5443cbf7d6070c5d734f93cd32bdcb99.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper describes NICER, a framework for unsupervised learning in histopathology images, based on non-probabilistic data condensation for reducing the number of prototypes through the definition of meta prototypes (or concepts).\nIn this way, authors formalize e new paradigm for histological representation learning, with the main claim of having a framework able to create adaptive sets of prototypes according to the slide. They provide extensive assessment and benchmark against recent baselines on a variety of pathology tasks, showcasing significant improvements."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. Presentation is excellent: the way the framework is framed, the narrative flow, and the highly polished visuals makes the manuscript really enjoyable. \n2. Relevance: the depth of theoretical framework, and the proposed ideas makes the manuscript particularly adequate for ICLR.\n3. Novelty: as far as I could find in the literature, the idea of condensing and reducing prototypes has not yet applied in histopathology and it is particularly valuable. The theoretical framework is well conceived and gives additional strength to the story.\n4. Technical soundness: the concepts are clearly explained, and most of details for replicability are provided, even if availability of source code would be preferrable.\n5. Assessment and comparison: authors report on extensive comparisons against SOTA methods on a variety of tasks, and the results appear generally convincing."}, "weaknesses": {"value": "The paper appears to be solid, but I have some concerns about the fairness in comparison, and the reporting of results:\n1. It seems to me that $K$ is the most important parameter, since it represents the initial target of number of concepts, that is reduced during condensation. It would be important to also report on the final number of concepts after the pipeline is complete.\n2. Qualitative results and visual explainability: Fig.6 and Fig.8. Why tSNE was chosen for performing projection? I think it would provide a bias and also artifacts, as I see some small weird triangular clusters after few iterations. How do you explain them? \nAlso, as far as I could understand, the final set of concepts are associated to visual features and they can be represented visually (for example for generating exemplar patches from histopathology slide). I would have expected that authors provided qualitative results about prototypical assignment, and examples on how these prototypes look, like it is done in PANTHER.\n3. Fairness of comparison: as far as I could understand, the main competitor is PANTHER, but I don't think that the benchmarking is completely fair. For example, it is not clear what parameters and conditions are considered for creating Table 3; and also Figure 8 is not fair, since it seems that the prototypes obtained from Panther has limited expressivity, while instead from the original manuscript the prototypical assignment map shows the opposite; I think that this abrupt clustering of prototypes is a bias effect due to tSNE projection, but I do not feel it can be interpreted as limitation in expressivity power of the prototypes found with PANTHER framework."}, "questions": {"value": "1. Minor: in the introduction, I would mention about tile-based processing that is inherently parallel.\nLine 209: is. $\\zeta$ parameteres appear out of nowhere in line 225. A table representing and explaining all parameters would help in readability of the manuscript.\n2. The way the paradigm is theoretically framed reminds about sparse coding with overcomplete dictionaries: \nAharon, M., Elad, M., & Bruckstein, A. (2006). K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation. IEEE Transactions on signal processing, 54(11), 4311-4322. I would like that authors try to analize analogies and differences.\n3. Scalability performance: what do you expect as trade-off for condensation? How much does it cost to perform condensation instead of keeping the full WholeOfBag?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No concerns"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bQE86zThDs", "forum": "Ysa5RZZi6J", "replyto": "Ysa5RZZi6J", "signatures": ["ICLR.cc/2026/Conference/Submission22506/Reviewer_SG2S"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22506/Reviewer_SG2S"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22506/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761559448807, "cdate": 1761559448807, "tmdate": 1762942247577, "mdate": 1762942247577, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces‚ÄØNICER, a nonparametric unsupervised data condensation framework for whole-slide histology images (WSIs). NICER adaptively determines the number of prototypes per slide by formulating condensation as a hierarchical probabilistic model (features -> patterns -> concepts). The goal is to balance‚ÄØinformation preservation‚ÄØand‚ÄØcomputational efficiency. The method is evaluated across four datasets and on two main tasks: cancer subtyping and survival prediction. The authors report consistent improvements over prior works in the field of prototype learning, such as‚ÄØPANTHER‚ÄØand‚ÄØProtoCount."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. Relevant problem:‚ÄØWSI condensation is a well-known bottleneck in computational pathology, as slides are composed of a very large number of tiles, many of which are redundant. Tackling this problem in an unsupervised way is of practical and methodological interest. \n2. Comprehensive empirical evaluation:‚ÄØThe experiments cover multiple datasets and tasks with consistent baselines and metrics. The reported gains over comparable prototype-based approaches are systematic."}, "weaknesses": {"value": "1. Methodological Ambiguities \nDespite the heavy probabilistic framing, the method is‚ÄØmathematically under-specified: \n- The hierarchical model ùëÉ(ùêª,ùëç‚à£Œ©) ‚ÄØis introduced but not clearly derived or grounded in an actual probabilistic generative process. \n- Many equations (e.g., Eq. 2‚Äì9) appear to be reformulations of clustering or assignment heuristics, rather than principled probabilistic inference steps. \n- The ‚Äúnonparametric‚Äù property arises mainly from‚ÄØpruning unused prototypes, not from a Bayesian nonparametric process. \n- Numerous notation and formulation issues undermine clarity: \n  * ùí© ‚ÄØ(Gaussian) is confused with ‚Ñï ‚ÄØ(natural numbers). \n  * Confusion between probability laws and densities in expressions such as log(ùí©(‚ãÖ)). \n  * Inconsistencies between Eq. 6 and Eq. 8 \n  * Typos (max vs. min, line 173). \n  * Equation 4 is ill-defined. \n  * Some variables are not defined (e.g. d l173, Œ± l229). \n  * ‚ÄúSince both hi and z‚àó (i) are ‚Ñì2-normalized embeddings, we approximate ‚à•hi‚à•2 ‚âà ‚à•z‚àó (i)‚à•2 ‚âà 1‚Äù.  It is equal to 1, no approximation here. \n- Overall, the pattern exploration method relies mostly on‚ÄØdeterministic clustering mechanisms, with the Bayesian formalism serving mainly as an interpretive framework rather than a fully realized inference model. \n \n2. Performance Claims \n- The reported ‚Äúup to 90% performance gains‚Äù (abstract) are misleading. \n- Table 1‚ÄØshows that NICER features still underperform the vanilla method (whole bag). Ideally, condensation should reduce redundancy‚ÄØwhile maintaining or improving performance, as demonstrated in‚ÄØPANTHER paper; here, the gain comes at the cost of lower performance. \n- The paper should include comparisons to other‚ÄØwhole-slide representation models‚ÄØ(e.g., GigaPath, GigaSSL, PRISM, HIPT). \n \n3. Biological Interpretability \n- The biological or histological meaning of prototypes is under-explored: \n  * What morphological patterns do prototypes capture? \n  * Visualization of tile-prototype associations or spatial prototype maps would significantly strengthen the claim of the paper."}, "questions": {"value": "- Some mathematical expressions are difficult to follow because several variables are not defined when first used. I recommend clearly defining all variables and revising the math sections to make them more precise, accurate, and rigorous. \n- Simplify the mathematical formulations to highlight the core mechanism. \n- What morphological or histological patterns do the learned prototypes capture? \n- Could the authors provide visualizations of tile‚Äìprototype associations or spatial prototype maps to support biological interpretability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1JVcIGaY21", "forum": "Ysa5RZZi6J", "replyto": "Ysa5RZZi6J", "signatures": ["ICLR.cc/2026/Conference/Submission22506/Reviewer_sdeQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22506/Reviewer_sdeQ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22506/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761866452454, "cdate": 1761866452454, "tmdate": 1762942247394, "mdate": 1762942247394, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces NICER, a probabilistic nonparametric method for unsupervised data condensation of gigapixel histology slides. Unlike prior approaches that use a fixed number of prototypes per slide, NICER adapts the number of prototypes to each slide‚Äôs morphological complexity. It models prototype construction hierarchically, preserving diverse local patterns while enforcing compact global representation. Across multiple datasets, NICER achieves strong gains in F1 and efficiency over existing condensation and MIL baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**Clear motivation and problem relevance.**  \n  The paper identifies an important challenge in computational pathology about how to compress extremely large WSIs while retaining morphological diversity.  \n\n**Readable structure and visuals.**  \n  Figures are generally clear and intuitive. The narrative follows a standard and familiar structure, making the paper easy to navigate.  \n\n**Potential applicability.**  \n  Adaptive prototype condensation could, in principle, generalize to other domains that require scalable representation learning, even though this is not empirically verified."}, "weaknesses": {"value": "**Inflated novelty.**  \nThe core mechanism of NICER is largely a reformulation of existing prototype learning and clustering frameworks such as PANTHER, OT-based embeddings, and Gaussian mixture condensation. The ‚Äúpattern‚Äìconcept‚Äù hierarchy is functionally equivalent to a coarse-to-fine clustering scheme, and the probabilistic factorization adds notation without introducing new learning objectives or inference principles. Overall, the contribution is incremental rather than conceptually novel.\n\n**Inaccurate ‚Äúnonparametric‚Äù claim.**  \nAlthough repeatedly described as nonparametric, NICER is a fully parametric neural framework with learnable embeddings and trainable parameters. Its capacity is bounded by predefined hyperparameters and adjusted via heuristic pruning. The approach does not perform genuine nonparametric inference or kernel-based adaptation. Hence, its ‚Äúnonparametric‚Äù behavior is empirical and heuristic rather than statistical or data-driven.\n\n**Unverifiable and internally inconsistent experimental comparisons.**  \nThe paper does not clarify which configuration underlies the reported ‚ÄúSOTA‚Äù results, making them empirically unverifiable and potentially biased in favor of NICER. In addition, both PANTHER (and possibly other prototype-based methods) and the survival prediction tasks are sensitive to hyperparameters and data splits, which makes the reported improvements difficult to reproduce.\n\n**Unsupported efficiency and generalization claims.**  \nThe paper emphasizes a superior efficiency‚Äìperformance trade-off and even a new paradigm for histological representation learning, yet provides no runtime, GPU memory, or throughput measurements. The reported metric reflects only compression ratio, not computational cost. Moreover, all experiments are confined to a bag-of-features assumption. This narrow scope and lack of computational evidence undermine both the efficiency and generalization claims."}, "questions": {"value": "- Including additional baseline comparisons beyond PANTHER and OT-based methods If possible. \n\n- If possible, provide a runtime and preprocessing time analysis. The preprocessing stages (patch extraction, embedding, and condensation) appear to dominate total computation time.  It would be helpful to quantify how much time each stage requires compared with end-to-end MIL training or inference.  This could clarify whether NICER improves overall pipeline efficiency."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8BFAsS6HVc", "forum": "Ysa5RZZi6J", "replyto": "Ysa5RZZi6J", "signatures": ["ICLR.cc/2026/Conference/Submission22506/Reviewer_9Nuz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22506/Reviewer_9Nuz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22506/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762172253129, "cdate": 1762172253129, "tmdate": 1762942247195, "mdate": 1762942247195, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces NICER, a framework for unsupervised data condensation of gigapixel whole-slide images (WSIs). The method aims to address the limitation of prior works that use a fixed number of prototypes, proposing instead a two-stage probabilistic model that adapts the prototype capacity to the complexity of each slide. It first extracts a large set of feature patterns to preserve information, then condenses them into a smaller set of concept prototypes. The authors claim this nonparametric approach achieves state-of-the-art performance on four histological datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper identifies an important and relevant problem in computational pathology: the inadequacy of fixed-capacity representations for WSIs of varying complexity. The proposed two-stage approach of preservation followed by condensation is, at a conceptual level, an intuitive and promising direction."}, "weaknesses": {"value": "1. The paper's central conceptual pillar is its \"nonparametric\" nature. However, the method is simply an iterative algorithm with a heuristic pruning step. This is a severe misrepresentation of the methodology. \n2. The paper's entire premise is built on improving the trade-off between accuracy and efficiency. Yet, there is a complete and inexplicable absence of any empirical data regarding efficiency‚Äîno training times, no inference speeds, no memory usage comparisons.\ntion.\n3. The methodology is described at such a high level that it is impossible to reproduce. Key design choices (initialization, network architectures, reconciliation of top-k vs. top-1) are omitted."}, "questions": {"value": "1. Can you provide a rigorous justification for using the term \"nonparametric\"? If not, are you willing to retract this claim and re-frame your contribution more accurately as an \"adaptive-capacity\" model?\n\n2. Please provide a new table comparing NICER against key baselines (e.g., PANTHER, H2T) on wall-clock training and inference time per WSI, as well as peak GPU memory consumption.\n\n3. Please provide the exact implementation details necessary for reproducibility: (a) How was the initial pattern set Z generated? (b) What are the specific architectures and hyperparameter settings? (c) Please clarify the discrepancy between the \"top-k\" description and the \"top-1\" formulation in Eq. 2 and state precisely what objective was implemented."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Fo02djkPSm", "forum": "Ysa5RZZi6J", "replyto": "Ysa5RZZi6J", "signatures": ["ICLR.cc/2026/Conference/Submission22506/Reviewer_FYhf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22506/Reviewer_FYhf"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22506/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762433379551, "cdate": 1762433379551, "tmdate": 1762942246820, "mdate": 1762942246820, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces NICER, a nonparametric, unsupervised condensation framework for gigapixel WSIs. Instead of fixing a per-slide prototype budget, NICER first over-preserves morphology by learning slide-specific patterns (redundant by design), then condenses them into concept prototypes, pruning unused concepts so the final count adapts to slide complexity. The formulation is probabilistic with latent pattern‚Äìconcept assignments optimized via alternating updates. Across four datasets (PANDA, NSCLC, BRCA, LUAD) and two tasks (subtyping, survival), NICER outperforms prior unsupervised prototype learners (DeepSets, ProtoCount, H2T, OT, InfiniteGPFA, PANTHER) and maintains a favorable accuracy‚Äìefficiency trade-off relative to Whole-Bag features (Tables 1‚Äì2, pp. 6‚Äì7; Table 3, p. 8). Ablations show how initial pattern count M and top-Œ∫ affect capacity and saturation (Fig. 4, p. 7; Table 3, p. 8)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Addresses a real bottleneck: avoids one-size-fits-all prototype budgets by adapting capacity per slide via a principled pruning mechanism (Sec. 2.3‚Äì2.4, pp. 4‚Äì5).\n\nBalanced preservation‚Üíefficiency: the two-stage ‚Äúintentional redundancy then condensation‚Äù reduces early information loss and retains rare morphology (Intro & Fig. 3, pp. 2‚Äì3).\n\nStrong, broad empirical results: consistent wins over multiple unsupervised baselines (including the latest PANTHER approach) and across three MIL heads (ABMIL/DSMIL/ILRA) for subtyping and survival (Tables 1‚Äì2, pp. 6‚Äì7).\n\nTrade-off evidence: clear performance‚Äìcompression curves and sensitivity analyses (Table 3 & Fig. 4, pp. 8‚Äì7; Figs. 5‚Äì6, p. 7).\n\nPractical framing: operates on foundation-encoder features, with implementation details and ablations that are actionable."}, "weaknesses": {"value": "High Complexity and Computational Cost: NICER‚Äôs sophistication comes at the cost of increased complexity. The method involves an iterative two-stage learning process with many latent variables, which is more complicated to implement and tune than simpler one-step clustering or standard MIL models. The paper mentions using a 46GB GPU for experiments, indicating substantial memory and computation requirements. This could hinder adoption in practice ‚Äì laboratories with limited computational resources might struggle to run NICER, whereas simpler methods (e.g. k-means or fixed GMM prototypes) are more lightweight. The authors do not report runtime comparisons, so the efficiency trade-off of NICER‚Äôs richer modeling is not fully clear.\n\nHyperparameter Sensitivity: While NICER is nonparametric in that it determines prototype counts automatically, it still requires setting certain hyperparameters that can affect results. In particular, the initial number of patterns (M) and the patch-to-pattern association limit (top-Œ∫) must be chosen. The authors‚Äô ablations show that too small an M can hurt performance and too large a Œ∫ can diffuse patch information. Thus, practitioners need to choose these carefully (the paper finds e.g. M‚âà200 and Œ∫‚âà3 work well). NICER‚Äôs performance might degrade if these are mis-specified for a new dataset. In contrast, some simpler baselines have fewer tunable parameters. This points to a potential limitation in ease-of-use: despite its adaptive nature, NICER isn‚Äôt completely ‚Äúhands-off‚Äù to configure.\n\nModel Assumptions and Theoretical Guarantees: NICER relies on a probabilistic model (e.g. assuming patch features are approximately Gaussian around pattern means). These assumptions, while reasonable, are not deeply validated. Additionally, the optimization is heuristic (alternating updates for patterns, concepts, and assignments). The paper provides no formal proof of convergence or bounds on information loss during condensation. A skeptical reader might question whether the gains come from the sophisticated model or simply from clever engineering choices. Some discussion or theoretical insight into why the two-stage approach outperforms single-stage clustering (beyond empirical observation) would strengthen the work.\n\n\nNovelty scope. The main novelty is the nonparametric per-slide capacity and the explicit pattern‚Üíconcept condensation; however, the broader ideas (unsupervised prototyping, mixture-like modeling, hierarchical abstraction) overlap with existing lines. The paper could sharpen what is mathematically distinct from fixed-K GMM or from PANTHER‚Äôs soft assignment.\n\nClinical relevance and interpretability. While the paper demonstrates strong quantitative performance on subtyping and survival prediction, histological subtyping is a task pathologists routinely perform using visual cues. To establish clinical utility, it would be important to show that the concept prototypes learned by NICER correspond to morphologic patterns recognized by human experts (e.g., tumor regions, stroma, necrosis). The absence of such interpretability analysis limits the translational impact of the work.\n\nExternal validity and batch effects. The evaluation relies exclusively on public TCGA and PANDA datasets, which are known to exhibit site-specific staining and preprocessing artifacts. These batch effects can inflate in-domain performance while limiting generalization. Validation on independent institutional or multi-center cohorts would provide stronger evidence that NICER‚Äôs adaptive condensation generalizes across data sources."}, "questions": {"value": "Prototype Budget Determination: Could you clarify how NICER decides the final number of prototypes per slide? Is there an implicit threshold or stopping criterion in the generative model that prunes ‚Äúredundant concepts‚Äù? For example, do you fix an initial maximum (M patterns or concepts) and then drop those with negligible assigned patches? Understanding what controls the adaptive prototype count (and how variable it is across slides) would help gauge the method‚Äôs robustness.\n\nRationale for Two-Stage Condensation: What is the key advantage of the hierarchical patterns‚Üíconcepts approach versus a single-stage nonparametric clustering of patches? In principle one might try a Dirichlet Process or adaptive K-means on the patch embeddings directly. Does the two-step process (intentional redundancy then merging) simply preserve rare features better, or does it also aid optimization stability? Any insight or experiments comparing NICER‚Äôs two-stage pipeline to a one-stage variant would clarify why the hierarchy is crucial.\n\nComputational Efficiency: How do the training time and memory usage of NICER compare to simpler prototype methods like PANTHER or to standard MIL models? The method appears resource-intensive; for instance, did you need to process one WSI at a time, or were multiple slides optimized in parallel? Any data on runtime per slide or per epoch would be appreciated. This information would help readers assess the practicality of NICER for large-scale or real-time applications.\n\nFeature Extraction and End-to-End Learning: Are the patch features used in NICER fixed from a pretrained model, or were they trained/finetuned as part of this work? If fixed, did you observe any failure cases attributable to feature quality? And do you anticipate gains if one jointly learned the feature encoder with the NICER framework? It would be interesting to know if integrating representation learning (perhaps via a multi-task or self-supervised loss) was attempted, or if not, why the decoupled approach was chosen.\n\nPosition & Context: NICER currently treats the WSI as an unordered bag of patch features, focusing on morphological content. Might incorporating spatial context improve the prototypes (for example, ensuring that ‚Äúconcepts‚Äù correspond to contiguous regions or specific structures in tissue)? Some recent works add coordinate information or model the WSI as a graph to capture architecture. Did you consider extensions of NICER to encode spatial relationships between patches or to enforce that selected prototypes are spatially diverse? This could be relevant for tasks like tumor localization, so we wonder if it‚Äôs a plausible future direction.\n\nComparison with Other Unsupervised Methods: You included an ‚ÄúInfinite GPFA‚Äù baseline (Yu et al., 2025) which, like NICER, aims to learn latent factors without fixing their number. That method underperformed significantly. Can you shed light on why NICER achieves better results than InfiniteGPFA or other nonparametric clustering approaches? For example, is it due to NICER‚Äôs alternating optimization capturing more variance, or the specific way NICER handles patch-to-prototype assignments (top-Œ∫ redundancy, etc.)? A deeper explanation would highlight what design choices are most critical for NICER‚Äôs success relative to earlier approaches.\n\nClinical alignment of prototypes. Given that histologic subtyping is a task pathologists perform visually, have you examined whether the discovered prototypes correspond to interpretable histopathologic structures or features that pathologists recognize? For instance, do the top-activating patches for individual prototypes map to tumor, stroma, or inflammatory regions in a way that aligns with diagnostic reasoning? Such validation would help contextualize the model‚Äôs relevance to practical pathology workflows.\n\nCross-institutional validation. TCGA datasets contain known batch effects and pre-analytic heterogeneity. Have you tested NICER‚Äôs generalization when trained on one institution and tested on another (e.g., PANDA KRLS ‚Üí RUMC split or external private cohorts)? If not, could the authors discuss how NICER‚Äôs adaptive, nonparametric mechanism might mitigate or exacerbate domain shifts across institutions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ZEyxRRaiNj", "forum": "Ysa5RZZi6J", "replyto": "Ysa5RZZi6J", "signatures": ["ICLR.cc/2026/Conference/Submission22506/Reviewer_St93"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22506/Reviewer_St93"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission22506/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762532791248, "cdate": 1762532791248, "tmdate": 1762942246621, "mdate": 1762942246621, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work introduces NICER, a data condensation method that compresses bag-of-feature inputs (modeling whole-slide images in pathology) into a compact set of slide-adaptive prototypes for downstream use. NICER works by first learning a high-capacity set of patterns that each patch selects via top-k similarity, then condensing those patterns into a smaller set of concepts while pruning unused concepts which adapts to slide complexity. Benchmark tasks include classification(TCGA-NSCLC, PANDA) and survival prediction (TCGA-LUAD, TCGA-BRCA) with comparisons against unsupervised prototyping baselines (e.g., DeepSets, ProtoCounts, H2T, PANTHER) and MIL predictors (e.g., ABMIL, DSMIL, ILRA). Additional experiments include sensitivity to the initial number of patterns and ablating $k$ in top-$k$ selection."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Good presentation and figures.\n- Good number of ablation studies performed (performance trade-off, prototype diversity, $k$ in top-$k$).\n- All comparisons use same feature encoder, with ablations of MIL architecture.\n- Related work in pathology is well-cited."}, "weaknesses": {"value": "- Study design follows that of PANTHER in evaluating on challenging pathology tasks (PANDAS, survival tasks) with PANTHER being one of the primary comparisons. However, only a few survival tasks are evaluated, with missing evaluation on external datasets such as CPTAC which was one of the core strengths of PANTHER as a prototypical method. Can NICER also generalize to CPTAC for LUAD survival?\n- Method is presented nicely but missing many references to data condensation methods. How much of the method comes from existing ideas  in fundamental ML/AI? Very hard to understand the technical contribution.\n- From my understanding of this work, NICER does not produce a slide-level representation similar to PANTHER. Rather, it learns a more compact set of patch feature prototypes followed by applying a MIL architecture on top.\n- - More fundamental baselines that this work should compare against is k-means, adaptive clustering methods, gaussian / dirchlet process mixture models and other EM clustering ideas in reducing the WSI to a fixed set of prototypes. there exist many non-parameter approaches for solving this same task of pruning redundant clusters in clustering problems.\n- - Which formulation of PANTHER Is being compared?\n\nOverall, I don't see the novelty of NICER at this time. Core idea of reducing redundant concepts in unsupervised clustering has a very straightforward extension to pathology, with many fundamental baselines missing that can also be used to find efficient prototype sets. In terms of experimental design, NICER does not evaluate on external datasets for survival prediction, so it is unclear how NICER would generalize."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "DcyD7hrxwY", "forum": "Ysa5RZZi6J", "replyto": "Ysa5RZZi6J", "signatures": ["ICLR.cc/2026/Conference/Submission22506/Reviewer_t1kv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22506/Reviewer_t1kv"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission22506/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762577732638, "cdate": 1762577732638, "tmdate": 1762942246404, "mdate": 1762942246404, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}