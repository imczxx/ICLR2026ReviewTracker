{"id": "ae6gnbWlga", "number": 9434, "cdate": 1758122307689, "mdate": 1759897725062, "content": {"title": "SymForce: Large Language Models as Symbolic Physics Engines for Molecular Conformation", "abstract": "Prevailing methods for molecular conformation generation treat 3D structures as static prediction targets, a significant limitation in chemistry. We improve upon this paradigm by reconceptualizing the task as a dynamic process of physical reasoning. Our framework, SymForce, employs a large language model (LLM) as a symbolic physics engine that generates corrective force instructions based on geometric deviations. These symbolic forces then guide an iterative, differentiable optimization to refine the 3D structure. SymForce achieves state-of-the-art performance with a 0.81 Å mean RMSD on GEOM-Drugs. Critically, it exhibits vastly superior generalization to large, out-of-distribution molecules, with performance degrading by only 34.6\\% compared to 70.6\\% for a leading diffusion-based method. Ablation studies confirm this symbolic reasoning is essential, as its removal causes a 42.0\\% performance drop. By integrating an LLM as a symbolic reasoner within a physical simulation loop, SymForce establishes a new paradigm for physics-informed AI and opens new directions in molecular modeling and beyond. The code is available at https://anonymous.4open.science/r/SymForce_code.", "tldr": "A framework employing a large language model as a symbolic force generator and then translated into numerical force vectors through a differentiable coordinate update mechanism.", "keywords": ["Molecular Conformation Generation", "Symbolic Force Generator", "Forphysics-Informed AI", "Large Language Model"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e0cd4842226afce6454853df4498635077650251.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes SymForce, a framework that employs LLM as the symbolic physics engine to generate corrective force instructions based on geometric deviations, thereby guiding an iterative, differentiable optimization to refine the 3D structure.\n\nExperiments demonstrate that SymForce achieves state-of-the-art performance, opening promising avenues for physics-informed AI in computational chemistry and materials science."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. This paper proposes to reconceptualize molecular conformational generation as a dynamic process reasoning problem, which overcomes the limitations of prevailing methods.\n\n2. The experimental results are promising, and ablation studies further confirm the essential role of symbolic reasoning."}, "weaknesses": {"value": "**For the proposed experiments**\n1. As shown in Figure 2, the proposed SymForce relies on initial 3D coordinates as input, which renders its comparison with conformation generation baselines unfair.\n2. Molecular conformation generation is a well-defined task with established evaluation metrics and widely recognized baselines. However, this paper fails to align its evaluation metrics with those of previous works and overlooks many important baselines such as MCF [1] and AvgFlow [2]. \n3. In addition to comparing with RDKit ETKDG, this paper should also compare the computational efficiency against more recent and stronger baselines.\n\n**For the proposed method**\n\nWhile reading this paper, many descriptions of the proposed method are confusing and difficult to follow. For example, the training process is not clearly explained:\n1. While Appendix A.1 states that the LLM component is fine-tuned on a dataset derived from MD simulations, this paper provides neither essential details about the dataset nor illustrative examples of the input prompts.\n2. As illustrated in Equation 5-8, the total loss is composed of the coordinate loss, the force loss, and the physics loss.  However, it is unclear how the reference forces used in the force loss are obtained. \n\nDue to these unclear descriptions, I have to examine the provided code. However, the code itself has severe problems, which raise additional **concerns about the correctness and reproducibility of the proposed method**.\n1. Those key scripts mentioned in the README, including training, inference, and evaluation scripts,  are all absent from the provided code.\n2. The actual model implementation differs substantially from the description provided in the paper:\n    * This paper claims that the LLM component is fine-tuned on a dataset derived from MD simulations (Appendix A.1 in this paper). However, the provided code indicates that no model fine-tuning is actually performed, and that the system instead relies solely on prompt engineering to guide the LLM’s behavior (lines 291-395 in https://anonymous.4open.science/r/SymForce_code/SymForce/models/symforce_encoder.py). \n    * This paper claims that the LLM component receives both the invariant chemical prior and the time-varying geometric state as inputs (lines 186-196, 251-254 in this paper) to generate symbolic force. However, the provided code indicates that they are actually not used in the implementation, and that the system only relies solely the distance and history to generate symbolic force, which is very unreasonable (lines 337-367 in https://anonymous.4open.science/r/SymForce_code/SymForce/models/symforce_encoder.py).\n    * This paper claims that  the total loss is composed of the coordinate loss, the force loss, and the physics loss (Equation 5-8 in this paper). However, the provided code indicates that the force loss is always zero, meaning that this term does not actually contribute to the training process (lines 359-366 in https://anonymous.4open.science/r/SymForce_code/SymForce/models/symforce.py).\n    * In addition, many parts of the provided code appear to contain incorrect, which raises serious doubts about how the reported results in the paper are actually obtained:\n      * During the iterative process, the ``chemical_context`` and ``geometric_context`` are assigned exactly the same values (lines 492-488 in https://anonymous.4open.science/r/SymForce_code/SymForce/models/symforce_encoder.py).\n      * For the molecular understanding, only the molecular tokens of the first sample in each batch are replaced with the corresponding  molecular embedding (lines 379-382 in https://anonymous.4open.science/r/SymForce_code/SymForce/models/symforce.py).\n\n**In this case, the authors must provide a clear and reasonable explanation for the issues mentioned above and release fully reproducible code to verify their results; otherwise, the validity and credibility of the reported results cannot be ensured**.\n\n[1] Wang, Y., Elhag, A. A., Jaitly, N., Susskind, J. M., and Bautista, M. Á. Swallowing the bitter pill: Simplified scalable conformer generation. In Forty-first International Conference on Machine Learning, 2024.\n\n[2] Cao, Zhonglin, et al. \"Efficient molecular conformer generation with SO (3) averaged flow-matching and reflow.\" In Forty-second International Conference on Machine Learning, 2025."}, "questions": {"value": "Please refer to the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "J7TaeVRV7K", "forum": "ae6gnbWlga", "replyto": "ae6gnbWlga", "signatures": ["ICLR.cc/2026/Conference/Submission9434/Reviewer_N7Y5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9434/Reviewer_N7Y5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9434/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761248290798, "cdate": 1761248290798, "tmdate": 1762921034104, "mdate": 1762921034104, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SymForce, a framework that reconceptualizes molecular conformation generation as a process of iterative symbolic physical reasoning. The method employs a Large Language Model (LLM) (Llama-3.1-8B-Instruct) as a “symbolic physics engine” that generates textual force-field instructions based on geometric deviations, which are then converted into numerical vectors to iteratively refine molecular coordinates. The approach is evaluated on GEOM-Drugs and QM9, claiming state-of-the-art accuracy (0.81 Å RMSD) and better out-of-distribution generalization than diffusion models."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper has the following strengths:\n\n- **Conceptual Creativity** – The idea of using an LLM as a symbolic force generator for 3D molecular modeling is novel and potentially interesting if properly validated.\n\n- **Effort on Interpretability** – Using symbolic (textual) forces provides some interpretability advantage over latent-vector-based methods.\n\n- **Empirical Effort** – The authors include both quantitative benchmarks and qualitative case studies, showing an attempt to connect symbolic reasoning with physical correction."}, "weaknesses": {"value": "There are several critical weakness of this work:\n\n- **Missing Critical Related Work** - The paper omits several essential prior works using LLMs directly targeting 3D conformation generation from 2D molecular graphs, for instance [1,2,3,4]. It can be seen that none of these works (or relevant ones) are mentioned in Sections 2.2 or 2.3. These papers already explore LLM-based reasoning or text-driven 3D structure generation. Without citing or benchmarking against them, the claimed novelty and positioning of SymForce are not credible. The related-work section instead emphasizes general molecular LLMs (e.g., Mol-Instructions, LlasMol) that are irrelevant to 3D conformation synthesis.\n\n- **Unclear Model Fine-Tuning and Hallucination Control** - The LLM is described as a “physics engine,” but it is not clear whether it is fine-tuned for downstream conformer generation. If the model is not specifically trained to output valid force fields, hallucinations or inconsistent symbolic forces are inevitable. The paper does not mention any data-driven adaptation, reinforcement mechanism, or validation of generated textual forces. Hence, it is unclear how the LLM maintains physical correctness or stability during optimization.\n\n- **Unfair Baseline Comparisons with LLM methods** - The experimental section compares SymForce against molecule LLM models such as Mol-Instructions, 3D-MoLM, and LlasMol, etc; however, all of these ones are designed for caption generation or multimodal understanding, **not 3D conformer generation**. This renders the comparisons methodologically invalid. The reported “state-of-the-art” results are therefore unsubstantiated because none of the baselines are optimized for the same task.\n\n- **Missing Direct Benchmark Against True 3D Conformation LLMs**\n\nAs noted above, several recent LLM-based models specifically target 3D structure prediction or generation. The absence of comparisons with these works, even at a qualitative level, makes it difficult to judge the progress claimed. The current benchmarks only include diffusion models (Torsional Diffusion, GeoDiff), Classical and Graph Generative Models,  and unrelated molecular LLMs, leaving a large gap in empirical validation.\n\n- **Ambiguity in Experimental Setup** - Details such as training data, supervision signals, and whether the LLM and geometric encoder are jointly trained or frozen remain vague. The description of “iterative symbolic-to-numerical updates” is an interesting concept, but underspecified experimentally. Without clarity on hyperparameters, dataset splits, or convergence criteria, reproducibility is hard to follow.\n\nOverall, while the paper introduces a conceptually intriguing idea - using an LLM as a symbolic force generator, the work fails on several scientific and methodological grounds: (1) the related-work section misses crucial LLM-based conformation generation studies, (2) it lacks clarity on model training and hallucination control, (3) comparisons with non-comparable baselines make the evaluation invalid, and (4) it omits direct benchmarking with recent 3D-aware LLMs. As a result, the contribution is not convincing, and the empirical evidence is insufficient to support publication. A major revision would be required to make the work competitive.\n\n\n[1] Language models can generate molecules, materials, and protein binding sites directly in three dimensions as XYZ, CIF, and PDB files\n\n[2] BindGPT: A Scalable Framework for 3D Molecular Design via Language Modeling and Reinforcement Learning\n\n[3] Geometry-Informed Tokenization of Molecules for Language Model Generation\n\n[4] Chem3DLLM: 3D Multimodal Large Language Models for Chemistry"}, "questions": {"value": "- Can the author clarify how to set up and benchmark with the LLM models mentioned in the experiments?\n\n- How is the model's performance when evaluated against a dedicated LLM for 3D conformer tasks? \n\n- How can the method be robust, given the potentially hallucinatory force outputs generated by the LLM model? What happens if we replace this LLM model with some other pre-trained LLM on molecular data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qmQN4F6vEy", "forum": "ae6gnbWlga", "replyto": "ae6gnbWlga", "signatures": ["ICLR.cc/2026/Conference/Submission9434/Reviewer_ASFd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9434/Reviewer_ASFd"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9434/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761869137426, "cdate": 1761869137426, "tmdate": 1762921033814, "mdate": 1762921033814, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a qualitatively novel idea for 3D structure generation using a specially trained Large Language Model (LLM) that serves as a symbolic force generator.  The LLM provides textual information about deformations in internal coordinates such as bonds, which are then physically constrained and used to update the internal coordinates of the molecule, and the algorithm is optimized using a loss that balances coordinate prediction and force consistency.  Similar to the recent Mol-LLaMa paper, this work encodes geometric information about small molecules using an external tool, in this case PaiNN, and translates these encodings to a context for the LLM.  The authors test the model on molecular conformation generation tasks (GEOM-Drugs), property prediction (QM9), and qualitative molecular understanding studies."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper presents a highly original concept that addresses an exciting area of modern machine learning interfacing to drug discovery. The idea of using an LLM as a symbolic force generator is conceptually novel,  algorithm 1 is presented in a clear fashion, and the case studies and comparisons to other models are interesting to read."}, "weaknesses": {"value": "The current main results, including the ablations and comparisons are confusing and unclear.  The authors state that they used official codes and hyperparameters under identical computational budgets, but there is no reference or link to the code or the parameters they used.  There exists no simple \"Mean RMSD\" metric in the official GEOM-Drugs repo, for example, and the old torsional diffusion paper reported an ensemble-base AMR value of 0.58 A, so it is not clear exactly what the authors mean by \"Mean RMSD\" or how they obtained the numbers for theirs or for other methods.  I inspected the provided zipfile of the source code kindly provided by the authors in the anonymous repo, but none of the python files mentioned in the instructions in their README existed in the archive and many of the other files appeared to come from Mol-LLaMa or other repos.  Because the details in the appendix do not explain how the molecular dynamics simulation were performed in order to generate training data (what code/duration/force field/samples) it is not clear if there was substantial leakage between training and evaluation conformations. Importantly, the section and supplement about molecular understanding do not align with the rest of the work and are not explained---was that a result of pretraining on the force tokens, or was there an additional (Mol-LLaMa-like) training stage and if so where are the additional details of this process?   Finally, and as a totally minor point with regards to the current writeup: it is very unclear what the need of this mixed symbolic (via LLM) and analytical process is and why a specialized neural net could not replace the current role of the LLM."}, "questions": {"value": "Please see the questions regarding unclear parts in the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pdgyWH2sQ3", "forum": "ae6gnbWlga", "replyto": "ae6gnbWlga", "signatures": ["ICLR.cc/2026/Conference/Submission9434/Reviewer_uFsP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9434/Reviewer_uFsP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9434/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761886615822, "cdate": 1761886615822, "tmdate": 1762921033229, "mdate": 1762921033229, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SymForce, a framework for molecular conformation generation. The core idea is to employ a large language model (LLM) as a \"symbolic physics engine.\" The framework iteratively observes the geometric deviations of a 3D molecular structure and uses an LLM (Llama-3.1-8B-Instruct) to generate symbolic force instructions (e.g., [BOND_STRETCH]). These symbolic instructions are then translated into numerical force vectors by a \"symbolic-to-numerical translation\" module, which in turn guide a differentiable optimization process to refine the geometry. The authors claim state-of-the-art (SOTA) performance on the GEOM-Drugs dataset, superior generalization to large, out-of-distribution molecules, and enhanced interpretability."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- Novel Concept: The high-level idea of integrating symbolic reasoning into a differentiable optimization loop for a scientific problem is novel and intellectually interesting.\n\n- Addresses Generalization: The work attempts to tackle the important problem of generalization to larger molecules, which is a known weakness of many data-driven approaches in this domain.\n\n- Goal of Interpretability: The framework's goal of providing symbolic, human-readable outputs (the force instructions) is a worthwhile endeavor to move beyond \"black box\" force prediction."}, "weaknesses": {"value": "## Misleading Core Claim of \"Symbolic Reasoning\"\nThe central claim of \"symbolic physical reasoning\" appears to be an overstatement. A close reading of Appendix A.1 reveals that the LLM was fine-tuned on a synthetic dataset. This dataset was created by running classical molecular dynamics (MD) and then programmatically mapping the numerical physical states (e.g., bond deviations) to pre-defined symbolic text labels (e.g., [BOND_STRETCH]).\n\nThe LLM is not \"reasoning\" about physics; it is learning a translation task: to imitate a hard-coded script that maps numbers to predefined text. The \"interpretability\" (Argument 5 from the critique) is therefore not an emergent property but an artifact of this human-engineered label set. Traditional force fields (e.g., AMBER) are already \"interpretable\" via decomposed energy terms (bonds, angles, etc.) without the immense overhead of an 8B LLM.\n\n## Unsubstantiated \"State-of-the-Art\" Claim\nThe paper's claim to SOTA performance is weak and based on an outdated set of comparisons.\n\n- Limited Benchmarks: The performance comparison in Table 1 is primarily against models from 2022 (GeoDiff, Torsional Diffusion). It fails to include comparisons against any modern, truly state-of-the-art conformer prediction models (e.g., more recent flow-matching [1], diffusion-language models [2], or other advanced architectures).\n\n- Marginal Improvement: Without these modern baselines, the SOTA claim is invalid. The reported 0.03 Å improvement over GeoDiff (a 2022 model) is marginal and unconvincing.\n\n[1] Hassan, Majdi, et al. \"Et-flow: Equivariant flow-matching for molecular conformer generation.\" Advances in Neural Information Processing Systems 37 (2024): 128798-128824.\n\n[2] Liu, Zhiyuan, et al. \"NEXT-MOL: 3d diffusion meets 1d language modeling for 3d molecule generation.\" arXiv preprint arXiv:2502.12638 (2025).\n\n## Prohibitive Computational Cost & Impracticality\nThe method is computationally prohibitive. As shown in Table 3, it requires 2.5 seconds per molecule, which is 25 times slower than the classical RDKit (ETKDG) baseline (0.1s). This cost stems from iteratively calling an 8B LLM for optimization. For a method that does not convincingly beat the actual SOTA, this level of computational cost makes it unusable for any practical application, such as high-throughput virtual screening.\n\n##  Critical Methodological Ambiguity (Confused Gradients)\nThe paper describes its framework as a \"differentiable coordinate update,\" but it is critically unclear how gradients are calculated.\n\n- The gradient must flow from the coordinate update (Eq. 4) back through the \"Symbolic-to-Numerical Translation\" module (Eq. 3) and into the LLM weights (Eq. 2).\n\n- The translator (Eq. 3) takes discrete symbolic text (e.g., [BOND_STRETCH]) from the LLM as input. How does the gradient flow back through this discrete sampling process? The paper provides no explanation (e.g., REINFORCE, Gumbel-Softmax, or if the LLM is frozen).\n\n- This omission of a core methodological detail makes the \"differentiable optimization\" claim highly suspect and the work irreproducible.\n\n## Misaligned Objectives and Sloppy Presentation\n\n- Misaligned Task: The paper dedicates significant space (Fig. 1, Table 4, Appendix A.7) to a \"molecule understanding\" task. This text-generation task is entirely misaligned with the core objective of conformer generation. The authors fail to show how this capability aids the geometry task (or vice-versa). Furthermore, this task is trivially solved with far greater richness and accuracy by general-purpose SOTA LLMs. The paper's own comparisons are superficial and misleading. The results attributed to GPT-4o are poor and unrepresentative of the actual model's (GPT-4o) capabilities. In practice, SOTA foundation models like the real GPT-4o or Claude 3.5 can reproduce far superior and more detailed molecular analyses, which renders this entire \"understanding\" component of SymForce redundant and the authors' comparison flawed.\n\n- Poor Quality: The manuscript is filled with numerous typographical errors and inconsistent statements, which reflects a lack of rigor and reduces confidence in the technical contents."}, "questions": {"value": "1. Can you please clarify precisely how gradients are back-propagated from the numerical coordinate update (Eq. 4) through the discrete symbolic text output of the LLM (Eq. 2)? What specific technique (e.g., REINFORCE, Gumbel-Softmax) is used to make this path differentiable, and why was this critical detail omitted?\n\n2. Why were modern SOTA conformer generation models (e.g., from 2023, 2024, or 2025) omitted from the benchmark in Table 1?\n\n3. How do you justify the 25x computational cost increase over a standard baseline (RDKit) for what appears to be a marginal (and potentially outdated) 0.03 Å improvement over a 2022 model?\n\n4. Can you provide evidence that the LLM is doing more than simply learning a pattern-matching translation from numerical deviations to the pre-defined symbolic labels you created in the synthetic dataset (Appendix A.1)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No Ethics Concerns."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0kFgG5RZJM", "forum": "ae6gnbWlga", "replyto": "ae6gnbWlga", "signatures": ["ICLR.cc/2026/Conference/Submission9434/Reviewer_Umjv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9434/Reviewer_Umjv"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9434/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761902106903, "cdate": 1761902106903, "tmdate": 1762921032866, "mdate": 1762921032866, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}