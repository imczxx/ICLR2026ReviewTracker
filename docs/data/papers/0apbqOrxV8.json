{"id": "0apbqOrxV8", "number": 18335, "cdate": 1758286531440, "mdate": 1759897109968, "content": {"title": "Energy Efficient Language Models through Dynamic Sparsity", "abstract": "Transformer models, despite their impressive performance, often face practical limitations due to their high computational requirements driven largely by the memory-bound KV-cache. State-space Models (SSMs) attempt to address this issue with linear attention, easing memory pressure and improving compute and memory efficiency. However, their efficiency is instead limited by dense linear layers with inherently low arithmetic intensity, again leading to a memory-bound landscape, posing challenges for deployment on hardware-constrained edge devices where these models might otherwise excel. In this work, we present a technique to induce high activation sparsity in quantized SSMs with minimal performance degradation, both for smaller-scale models suitable for edge-deployment and larger billion scale models. We nullify activations within a trainable threshold ($\\pm \\Delta$), which preserves outliers that are crucial for high performance. With only 1/4 of the effective MAC (Multiply-Accumulate) operations of a dense model, our sparse MatMul-free models maintain competitive performance compared to the dense base model. As GPUs offer limited support for unstructured sparsity during inference, we target a neuromorphic hardware platform that efficiently supports this dynamic and unstructured activation sparsity on a silicon level. Based on previous deployment results of a dense model, our sparsified models can increase throughput by 37$\\times$ while decreasing power consumption by 16$\\times$ compared to an edge GPU-based deployment of a comparable transformer-based LLM. Compared to a baseline dense model on the same hardware, we show improvements of 5.4$\\times$ in both metrics, paving the way for future explorations of highly efficient language models leveraging dynamic activation sparsity.", "tldr": "This work introduces a method for inducing high activation sparsity in quantized State-space Models, enabling near-baseline performance with significantly reduced latency and power when deployed on neuromorphic hardware.", "keywords": ["State-space models", "large language models", "activation sparsity", "unstructured sparsity", "neuromorphic hardware", "event-driven computation", "low-power inference"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/48a39a3e1eb323f6f81cf5a5852ac18f3ce20a51.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel method to induce high activation sparsity in quantized SSMs (MMFreeLM)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper's experiments show that this method can achieve 76% reduction in effective MAC  operations with negligible impact on task performance.\n2. The method is easy but useful. Using a learnable, per-projection threshold $\\Delta$ allows the model to assign different sparsity levels based on layer sensitivity."}, "weaknesses": {"value": "1. The paper's most impactful claims (e.g., 75mJ/token and 224.1 throughput in Table 3) do not appear to be actual measured results from running the sparse model on Loihi 2. As described in Section 4.5, these figures are calculateed from a performance model based on measurements of the dense model. The paper's claims would be strengthened if the authors could provide real acceleration data from Loihi 2, even on a single, small-scale sparse layer.\n\n2. The proposed method requires keep training on top of the pre-trained model. This process introduces additional learnable parameters and a new loss term. The paper does not discuss the additional computational overhead or convergence time this adds to the training phase. Could author discuss and add those cost?"}, "questions": {"value": "See weakness above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "phtTMJxUel", "forum": "0apbqOrxV8", "replyto": "0apbqOrxV8", "signatures": ["ICLR.cc/2026/Conference/Submission18335/Reviewer_JPiG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18335/Reviewer_JPiG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18335/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761461214677, "cdate": 1761461214677, "tmdate": 1762928047757, "mdate": 1762928047757, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method to induce high activation sparsity in quantized State Space Models. The approach uses learnable threshold-based pre-activation gates that zero out activations within a delta while preserving outliers. The authors demonstrate that their sparse models maintain competitive performance with up to 72% activation sparsity and project significant efficiency gains when deployed on neuromorphic hardware."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The sensitivity analysis provides valuable insights into which projections and layers can tolerate sparsity, and provides proper motivation for the paper. The authors offer an orthogonal complement to pruning and quantisation, while building upon existing techniques.\n2. The paper evaluates both 370M and 2.7B parameter models across multiple benchmarks, showing consistent results.\n3. The learnable two-sided ReLU with smooth surrogate gradient is computationally lightweight and unlike prior ReLU-based sparsification it generalises across all projections and learns per-projection thresholds.\n3. Targeting neuromorphic hardware that can actually exploit unstructured sparsity is a good choice that was thoroughly explained."}, "weaknesses": {"value": "1.  Results are extrapolated from dense deployments rather than measured on actual sparse models. Real deployment results on Loihi 2 would strengthen credibility.\n2. Competing SSM-based efficiency techniques (Mamba pruning, LoRA-style compression, structured token pruning) are not directly compared experimentally.\n3. The paper claims “minimal additional training cost” but does not report training time or compute the overhead introduced by sparsity regularisation.\n3.  The paper can include more important prior work on activation sparsity for neuromorphic computing. demonstrates similar sparsity-inducing techniques for neuromorphic hardware on simpler models. [ Activity Sparsity Complements Weight Sparsity for Efficient RNN Inference (https://arxiv.org/abs/2311.07625), Sparsity-Aware Hardware-Software Co-Design of Spiking Neural Networks: An Overview (https://arxiv.org/abs/2408.14437)\n]"}, "questions": {"value": "1. Were the sparsity thresholds initialised globally or per-layer? How sensitive are results to this initialisation?\n2. Have you explored structured sparsity variants such as block or channel for compatibility with GPU inference? Were the more stringent sparsity setups too detrimental to results achieved?\n3. How stable is training with high lambda, beyond what values are there cases where too much sparsity leads to collapse?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YDizCWXUkA", "forum": "0apbqOrxV8", "replyto": "0apbqOrxV8", "signatures": ["ICLR.cc/2026/Conference/Submission18335/Reviewer_R6HG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18335/Reviewer_R6HG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18335/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761588571815, "cdate": 1761588571815, "tmdate": 1762928047363, "mdate": 1762928047363, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a sparsification algorithm for SSMs targeting neuromorphic hardware, namely Loihi 2."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The sparsification algorithm of the paper seems to perform well, and introduces significant activation sparsity."}, "weaknesses": {"value": "Sparsification is an old topic and I find the paper's contribution to be very limited to a single proposal that was laid out in one figure. They then introduced a modification to the loss function to \"encourage\" the pushing of the values to +/- \\Delta. There was no explanation why the function is a good one, and also no details about how \\Delta is learned - how is \\Delta updated in the training process?\n\nThe other major weakness of the paper is that it just evaluated its proposal with other activation functions. Since sparsification is not new, there ought to be an evaluation against other sparsification methods. Without this, it is hard to place the contribution of the work."}, "questions": {"value": "1. How would your method compare to other state-of-the-art sparsification algorithms, even for traditional ANNs?\n\n2. Any reason for k = 10 (page 5) being a \"good\" value? Also, what's the intuition behind Eq. 3?\n\n3. Would the approach also work for transformers?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None."}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pQJT0cpyrg", "forum": "0apbqOrxV8", "replyto": "0apbqOrxV8", "signatures": ["ICLR.cc/2026/Conference/Submission18335/Reviewer_TZy8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18335/Reviewer_TZy8"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18335/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761635621364, "cdate": 1761635621364, "tmdate": 1762928046874, "mdate": 1762928046874, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "To address the high computational requirements introduced by the memory-bound KV-cache, State-space Models (SSMs) are proposed to ease memory pressure. But the new bottleneck of SSMs (linear layers) is still memory-bound, making it hard to be deployed on resource-constrained edge devices.\nThis paper proposed a trainable dynamic-sparsity mechanism for quantized State-Space Models (SSMs). The sparse model can achieve 37x better throughput on Intel Loihi 2 when compared with the dense model on edge GPU & 5.4x better throughput when compared with the dense model on the same hardware."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Over 60% MAC sparsity can be achieved with ~1% accuracy loss."}, "weaknesses": {"value": "Loihi 2 sparse results are modeled, not measured.\nNovelty compared with other work? It seems both TurboSparse & Q-Sparse have already introduced activation sparsity."}, "questions": {"value": "How is the paper compared with other sparse LLM work?\nWhat is the extra parameter size for the sparsification (delta, etc)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "RTrYiTVCvX", "forum": "0apbqOrxV8", "replyto": "0apbqOrxV8", "signatures": ["ICLR.cc/2026/Conference/Submission18335/Reviewer_GaZW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18335/Reviewer_GaZW"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18335/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762285253654, "cdate": 1762285253654, "tmdate": 1762928046421, "mdate": 1762928046421, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}