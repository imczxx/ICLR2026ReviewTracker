{"id": "vR2vLgnUvx", "number": 10082, "cdate": 1758160082976, "mdate": 1759897675300, "content": {"title": "EXPLOR: Extrapolatory Pseudo-Label Matching for OOD Uncertainty Based Rejection", "abstract": "EXPLOR is a novel framework that utilizes support-expanding, extrapolatory pseudo-labeling to improve prediction and uncertainty-based rejection on out-of-distribution (OOD) points. EXPLOR utilizes a diverse set of pseudo-labelers on an expansive augmented dataset to improve OOD performance through multiple MLP heads (one per pseudo-labeler) with shared embedding trained with a novel per-head matching loss. Unlike prior methods that rely on modality-specific augmentations or assume access to OOD data, EXPLOR introduces extrapolatory pseudo-labeling on latent-space augmentations, enabling robust OOD generalization with any real-valued vector data. In contrast to prior modality-agnostic methods with neural backbones, EXPLOR is model-agnostic, working effectively with methods from simple tree-based models to complex OOD generalization models. We demonstrate that EXPLOR achieves superior performance compared to state-of-the-art methods on diverse datasets in single-source domain generalization settings.", "tldr": "", "keywords": ["OOD Generalization", "Pseudo-labeling", "reject option"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0b2588a58ab5f39adedadf5350b956880b5f225b.pdf", "supplementary_material": "/attachment/68b3934597386eb127842a4d84c92aafa8532c9c.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces EXPLOR, a framework for single-source out-of-distribution (OOD) generalization and uncertainty-based rejection. The method integrates three elements: (1) latent-space extrapolation to synthetically expand training support, (2) supervision from a diverse set of pseudo-labelers, and (3) a multi-head student trained with per-head and mean-matching losses. A bias–variance decomposition is provided as an intuitive justification. Experiments on seven chemical and several tabular datasets demonstrate consistent improvements in AUPRC and AUPRC@R<τ over relevant baselines."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- **Relevance and clarity**\nThe paper addresses an important problem in OOD generalization under a single-source assumption. The motivation is clear, the method is concise, and the presentation is easy to follow.\n\n- **Methodological consistency**\nThe combination of per-head matching and latent extrapolation provides a coherent multi-task formulation that plausibly enhances robustness.\n\n- **Reproducibility and efficiency**\nThe implementation is simple, cost-efficient, and reproducible with standard hardware."}, "weaknesses": {"value": "- **Redundancy at inference**\nEXPLOR retains all pseudo-labelers at test time (Eq. 8), forming a hybrid ensemble of teachers and student heads. This design questions whether the student truly distills ensemble knowledge or merely supplements it. The claimed variance-reduction interpretation (Eq. 9–10) remains heuristic without quantitative analysis.\n\n- **Limited conceptual novelty**\nEach component of EXPLOR—ensemble pseudo-labeling, latent-space augmentation, and mean-matching regularization—has clear precedents in prior work (e.g., Hydra 2021, PixMix 2022, ACET 2019). The paper’s main contribution lies in system-level integration within a single-source OOD setup rather than in a new theoretical insight.\n\n- **Dataset and representation scope**\nThe use of ChEMBL, TDC, and DrugOOD benchmarks is reasonable, but all experiments employ fixed ECFP4 fingerprints. This limits the generality of the “modality-agnostic” claim. Results on learned embeddings, such as graph neural networks or visual features, would better demonstrate transferability.\n\n- **Ablation and statistical support**\nPer-head matching and bottleneck ablations show small absolute gains (around 1 percent) and lack significance testing. The uncertainty claims would be stronger with calibration or variance metrics (for example expected calibration error).\n\n- **Heuristic theoretical argument**\nThe bias–variance decomposition provides intuition but lacks empirical verification. No analysis is presented to confirm that predictive variance actually decreases as claimed."}, "questions": {"value": "**Inference overhead**\nWhat is the actual computational overhead in terms of time and memory when retaining up to 1024 pseudo-labelers during inference compared with using the student alone? A quantitative comparison would clarify the method’s practicality.\n\n**Dependence on pseudo-labelers**\nHow would EXPLOR perform if pseudo-labelers were unavailable at test time? Would the student alone preserve similar accuracy and uncertainty behavior?\n\n**Generality across learned embeddings**\nDoes the proposed framework extend beyond fixed handcrafted features to learned embeddings such as those obtained from graph neural networks or visual backbones? Showing this would strengthen the claim of modality-agnostic generalization.\n\n**Notation clarification for Equation 8**\nEquation 8 appears to omit parentheses in the summation term."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QEX3qyLSWP", "forum": "vR2vLgnUvx", "replyto": "vR2vLgnUvx", "signatures": ["ICLR.cc/2026/Conference/Submission10082/Reviewer_mPjQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10082/Reviewer_mPjQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10082/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761838793384, "cdate": 1761838793384, "tmdate": 1762921470843, "mdate": 1762921470843, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new method for single-source domain generalization. The method trains multiple pseudo-labelers on different data subsets. It expands training data through latent-space augmentations. Then it trains a multi-headed network where each head matches a different pseudo-labeler. The approach works with any vector data and different base models. Experiments show strong performance on high-confidence predictions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Single-source domain generalization is realistic for drug discovery applications. Many real scenarios only have one labeled dataset. The paper targets this practical setting.\n\n2. Works with tree models and neural networks. Works with any vector data. Unlike image-specific methods, this is general purpose. Can be applied to many domains.\n\n3. Tests on diverse datasets including chemical and tabular data. Compares with multiple baselines. Shows consistent improvements over pseudo-labelers across datasets."}, "weaknesses": {"value": "1.  The expansion pushes points away from origin by z' = (1 + |ε|)z. But no validation that expanded points are realistic. They might just be random noise. No check if they represent plausible OOD samples.\n\n2. The method relies heavily on pseudo-labels from diverse labelers. But no check if pseudo-labels are reliable on OOD data. If all pseudo-labelers are wrong, student learns bad supervision. No quality control mechanism.\n\n3. Diverse ensembles are standard ensemble practice. Pseudo-labeling is well-known in semi-supervised learning. Main contribution is combining them with latent expansion. The individual components are not new."}, "questions": {"value": "1. How do you verify expanded points are realistic? Can you show they resemble real OOD samples?\n\n2. How do you ensure pseudo-labels are reliable? What if all pseudo-labelers are wrong?\n\n3. Why 1024 models? How did you choose this number? What happens with 64 or 256?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8UlfZjAJnf", "forum": "vR2vLgnUvx", "replyto": "vR2vLgnUvx", "signatures": ["ICLR.cc/2026/Conference/Submission10082/Reviewer_8PYw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10082/Reviewer_8PYw"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10082/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971202536, "cdate": 1761971202536, "tmdate": 1762921470393, "mdate": 1762921470393, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces EXPLOR, a method for single-source out-of-distribution (OOD) generalization using pseudo-label matching across multiple heads.\nThe core idea is to expand latent representations beyond the in-distribution manifold via simple scaling, generate pseudo-labels from diverse models (e.g., XGBoost, D-BAT), and train a multi-head network to match each pseudo-labeler’s predictions.\nThe approach aims to improve high-confidence OOD predictions and rejection accuracy.\nExperiments on chemical (ChEMBL, DrugOOD) and tabular (Tableshift) datasets show consistent improvements over baseline and semi-supervised methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Clear problem formulation. The paper targets the single-source OOD setting, which is realistic but rarely addressed. The motivation from drug screening and risk prediction is well justified.\n\n2. Simple yet effective design. EXPLOR combines latent-space expansion and per-head pseudo-label matching into a lightweight framework that requires no unlabeled OOD data or domain annotations.\n\n3. Strong empirical performance. Across more than ten datasets, EXPLOR achieves stable gains, particularly in the high-confidence regime (AUPRC@R < 0.2).\n\n4. New evaluation metric. The introduction of AUPRC@R < τ provides a practical way to assess selective prediction quality, relevant to safety-critical tasks."}, "weaknesses": {"value": "1. Limited novelty. The method essentially combines self-training, ensemble averaging, and multi-task learning in a new context.\nNo fundamentally new theoretical idea or architecture is introduced.\n\n2. Empirical generality overstated. Although the paper claims to be modality-agnostic, all experiments are confined to tabular data.\nThere is no evidence that the approach extends to images, text, or graphs.\n\n3. Dependence on pseudo-label quality. The performance gain scales with the accuracy of pseudo-labelers. Poor labelers could degrade the overall results, and this dependency is only briefly mentioned in the appendix.\n\n4. Weak theoretical justification. The variance-reduction derivation (Eq. 9–10) is heuristic; there is no formal analysis showing that latent scaling approximates the true OOD distribution.\n\n5. Overstated terminology. Terms like “extrapolatory” or “modality-agnostic” may mislead readers, given the limited scope of experiments."}, "questions": {"value": "Please carefully read Weakness and answer all the five concerns."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qXNE8XiWDo", "forum": "vR2vLgnUvx", "replyto": "vR2vLgnUvx", "signatures": ["ICLR.cc/2026/Conference/Submission10082/Reviewer_EE2A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10082/Reviewer_EE2A"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10082/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761981193979, "cdate": 1761981193979, "tmdate": 1762921469839, "mdate": 1762921469839, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}