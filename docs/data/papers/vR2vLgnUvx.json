{"id": "vR2vLgnUvx", "number": 10082, "cdate": 1758160082976, "mdate": 1763731855488, "content": {"title": "EXPLOR: Extrapolatory Pseudo-Label Matching for OOD Uncertainty Based Rejection", "abstract": "EXPLOR is a novel framework that utilizes support-expanding, extrapolatory pseudo-labeling to improve prediction and uncertainty-based rejection on out-of-distribution (OOD) points. EXPLOR utilizes a diverse set of pseudo-labelers on an expansive augmented dataset to improve OOD performance through multiple MLP heads (one per pseudo-labeler) with shared embedding trained with a novel per-head matching loss. Unlike prior methods that rely on modality-specific augmentations or assume access to OOD data, EXPLOR introduces extrapolatory pseudo-labeling on latent-space augmentations, enabling robust OOD generalization with any real-valued vector data. In contrast to prior modality-agnostic methods with neural backbones, EXPLOR is model-agnostic, working effectively with methods from simple tree-based models to complex OOD generalization models. We demonstrate that EXPLOR achieves superior performance compared to state-of-the-art methods on diverse datasets in single-source domain generalization settings.", "tldr": "", "keywords": ["OOD Generalization", "Pseudo-labeling", "reject option"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fe29c2dcbe8e6a20bade13f55afd926a1f67dc1b.pdf", "supplementary_material": "/attachment/68b3934597386eb127842a4d84c92aafa8532c9c.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces EXPLOR, a framework for single-source out-of-distribution (OOD) generalization and uncertainty-based rejection. The method integrates three elements: (1) latent-space extrapolation to synthetically expand training support, (2) supervision from a diverse set of pseudo-labelers, and (3) a multi-head student trained with per-head and mean-matching losses. A bias–variance decomposition is provided as an intuitive justification. Experiments on seven chemical and several tabular datasets demonstrate consistent improvements in AUPRC and AUPRC@R<τ over relevant baselines."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- **Relevance and clarity**\nThe paper addresses an important problem in OOD generalization under a single-source assumption. The motivation is clear, the method is concise, and the presentation is easy to follow.\n\n- **Methodological consistency**\nThe combination of per-head matching and latent extrapolation provides a coherent multi-task formulation that plausibly enhances robustness.\n\n- **Reproducibility and efficiency**\nThe implementation is simple, cost-efficient, and reproducible with standard hardware."}, "weaknesses": {"value": "- **Redundancy at inference**\nEXPLOR retains all pseudo-labelers at test time (Eq. 8), forming a hybrid ensemble of teachers and student heads. This design questions whether the student truly distills ensemble knowledge or merely supplements it. The claimed variance-reduction interpretation (Eq. 9–10) remains heuristic without quantitative analysis.\n\n- **Limited conceptual novelty**\nEach component of EXPLOR—ensemble pseudo-labeling, latent-space augmentation, and mean-matching regularization—has clear precedents in prior work (e.g., Hydra 2021, PixMix 2022, ACET 2019). The paper’s main contribution lies in system-level integration within a single-source OOD setup rather than in a new theoretical insight.\n\n- **Dataset and representation scope**\nThe use of ChEMBL, TDC, and DrugOOD benchmarks is reasonable, but all experiments employ fixed ECFP4 fingerprints. This limits the generality of the “modality-agnostic” claim. Results on learned embeddings, such as graph neural networks or visual features, would better demonstrate transferability.\n\n- **Ablation and statistical support**\nPer-head matching and bottleneck ablations show small absolute gains (around 1 percent) and lack significance testing. The uncertainty claims would be stronger with calibration or variance metrics (for example expected calibration error).\n\n- **Heuristic theoretical argument**\nThe bias–variance decomposition provides intuition but lacks empirical verification. No analysis is presented to confirm that predictive variance actually decreases as claimed."}, "questions": {"value": "**Inference overhead**\nWhat is the actual computational overhead in terms of time and memory when retaining up to 1024 pseudo-labelers during inference compared with using the student alone? A quantitative comparison would clarify the method’s practicality.\n\n**Dependence on pseudo-labelers**\nHow would EXPLOR perform if pseudo-labelers were unavailable at test time? Would the student alone preserve similar accuracy and uncertainty behavior?\n\n**Generality across learned embeddings**\nDoes the proposed framework extend beyond fixed handcrafted features to learned embeddings such as those obtained from graph neural networks or visual backbones? Showing this would strengthen the claim of modality-agnostic generalization.\n\n**Notation clarification for Equation 8**\nEquation 8 appears to omit parentheses in the summation term."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QEX3qyLSWP", "forum": "vR2vLgnUvx", "replyto": "vR2vLgnUvx", "signatures": ["ICLR.cc/2026/Conference/Submission10082/Reviewer_mPjQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10082/Reviewer_mPjQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10082/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761838793384, "cdate": 1761838793384, "tmdate": 1762921470843, "mdate": 1762921470843, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "We sincerely thank all the reviewers for their insightful comments and suggestions on our manuscript. We are pleased that the reviewers found EXPLOR’s novel approach well motivated, and appreciated its strong empirical performance as a single source domain generalization method on a diverse, thorough evaluation.\n\n**Contributions and Novelty**\n\nEXPLOR leverages concepts such as pseudo-labeling, ensemble learning, and latent-space augmentation, however, its core mechanism fundamentally differs from prior work. In EXPLOR, the multi-head architecture shares a common feature extractor, but branches into multiple specialized prediction heads that are each trained on different views of the data. These heads therefore learn complementary hypotheses over a shared representation, creating latent structure that cannot be reproduced by simply stacking existing techniques and that enables OOD generalization without multiple environments, which is crucial for single source domain generalization setting where only one environment is available. While EXPLOR is inspired by prior components—as is common in ML research—its contribution lies in the capability enabled by their integration, not in any individual part. Foundational advances such as Variational Autoencoders (variational inference + autoencoders), U-Net (CNNs + skip connections), and Transformers (attention + feed-forward networks + residual connections) were considered novel because their combinations produced behaviors that none of the components could achieve alone. In the same spirit, EXPLOR’s *novel combination* of ensemble learning, (*a novel expansive*) latent-space augmentation, and mean-matching regularization together with *the novel multihead matching* training yields a meaningfully new training framework tailored to the single-source domain generalization setting—a scenario where existing techniques do not directly apply. \n\n\n**Empirical Studies**\n\nOur intention in using the term “modality-agnostic” is not to claim universal validation across all modalities, but rather to clarify that EXPLOR operates independently of modality-specific inductive biases (e.g., convolutions for images, token positions for text). In our paper, we used  *ECFP4 fingerprints* for TDC, ChEMBL, and DrugOOD experiments, and *tabular data* from tableshift to evaluate the model as 2 different modality to validate our claim. **Note that the tabular data experiments operate over a wide range of general features in various domains**. The components of  EXPLOR – multi-head model supervised by model-agnostic pseudo-labelers and latent-space augmentation do not rely on spatial or sequential structure, in contrast with image- or text-specific augmentation pipelines. This is precisely why the augmentation mechanism is modality-agnostic in design: it perturbs latent features in a way that applies equally to tabular vectors, or any fixed-length learned representation. Moreover, EXPLOR can be paired with any pseudo-labelers, including tree-based predictors, MLPs, and neural encoders such as GNNs or vision transformers, so it is modality-agnostic by design. See Table 7 in Appx. for an ablation study that shows that EXPLOR improves the performance over myriad pseudo-lablers.\n\n\n**Theoretical Motivation Justification**\n\nOne motivation of our methodological design is through the lens of variance reduction (eq. 9). We conducted additional experiments to confirm the variance reduction properties of EXPLOR as detailed in Fig. 6 and Table 3. By performing bootstrap-type trials we compared the variance of predictions on OOD points across trials for EXPLOR models versus the empirical risk minimization (ERM) loss. We see a significant reduction of variance, further validating our design and motivation.\n\n**Summary**\n\nIn summary, we believe that EXPLOR’s approach for handling single source domain generalization problems will be valuable to the machine learning community, and thus hope it is recommended for publication."}}, "id": "99yYvnE7o2", "forum": "vR2vLgnUvx", "replyto": "vR2vLgnUvx", "signatures": ["ICLR.cc/2026/Conference/Submission10082/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10082/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10082/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763730752215, "cdate": 1763730752215, "tmdate": 1763730752215, "mdate": 1763730752215, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new method for single-source domain generalization. The method trains multiple pseudo-labelers on different data subsets. It expands training data through latent-space augmentations. Then it trains a multi-headed network where each head matches a different pseudo-labeler. The approach works with any vector data and different base models. Experiments show strong performance on high-confidence predictions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Single-source domain generalization is realistic for drug discovery applications. Many real scenarios only have one labeled dataset. The paper targets this practical setting.\n\n2. Works with tree models and neural networks. Works with any vector data. Unlike image-specific methods, this is general purpose. Can be applied to many domains.\n\n3. Tests on diverse datasets including chemical and tabular data. Compares with multiple baselines. Shows consistent improvements over pseudo-labelers across datasets."}, "weaknesses": {"value": "1.  The expansion pushes points away from origin by z' = (1 + |ε|)z. But no validation that expanded points are realistic. They might just be random noise. No check if they represent plausible OOD samples.\n\n2. The method relies heavily on pseudo-labels from diverse labelers. But no check if pseudo-labels are reliable on OOD data. If all pseudo-labelers are wrong, student learns bad supervision. No quality control mechanism.\n\n3. Diverse ensembles are standard ensemble practice. Pseudo-labeling is well-known in semi-supervised learning. Main contribution is combining them with latent expansion. The individual components are not new."}, "questions": {"value": "1. How do you verify expanded points are realistic? Can you show they resemble real OOD samples?\n\n2. How do you ensure pseudo-labels are reliable? What if all pseudo-labelers are wrong?\n\n3. Why 1024 models? How did you choose this number? What happens with 64 or 256?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8UlfZjAJnf", "forum": "vR2vLgnUvx", "replyto": "vR2vLgnUvx", "signatures": ["ICLR.cc/2026/Conference/Submission10082/Reviewer_8PYw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10082/Reviewer_8PYw"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10082/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971202536, "cdate": 1761971202536, "tmdate": 1762921470393, "mdate": 1762921470393, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces EXPLOR, a method for single-source out-of-distribution (OOD) generalization using pseudo-label matching across multiple heads.\nThe core idea is to expand latent representations beyond the in-distribution manifold via simple scaling, generate pseudo-labels from diverse models (e.g., XGBoost, D-BAT), and train a multi-head network to match each pseudo-labeler’s predictions.\nThe approach aims to improve high-confidence OOD predictions and rejection accuracy.\nExperiments on chemical (ChEMBL, DrugOOD) and tabular (Tableshift) datasets show consistent improvements over baseline and semi-supervised methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Clear problem formulation. The paper targets the single-source OOD setting, which is realistic but rarely addressed. The motivation from drug screening and risk prediction is well justified.\n\n2. Simple yet effective design. EXPLOR combines latent-space expansion and per-head pseudo-label matching into a lightweight framework that requires no unlabeled OOD data or domain annotations.\n\n3. Strong empirical performance. Across more than ten datasets, EXPLOR achieves stable gains, particularly in the high-confidence regime (AUPRC@R < 0.2).\n\n4. New evaluation metric. The introduction of AUPRC@R < τ provides a practical way to assess selective prediction quality, relevant to safety-critical tasks."}, "weaknesses": {"value": "1. Limited novelty. The method essentially combines self-training, ensemble averaging, and multi-task learning in a new context.\nNo fundamentally new theoretical idea or architecture is introduced.\n\n2. Empirical generality overstated. Although the paper claims to be modality-agnostic, all experiments are confined to tabular data.\nThere is no evidence that the approach extends to images, text, or graphs.\n\n3. Dependence on pseudo-label quality. The performance gain scales with the accuracy of pseudo-labelers. Poor labelers could degrade the overall results, and this dependency is only briefly mentioned in the appendix.\n\n4. Weak theoretical justification. The variance-reduction derivation (Eq. 9–10) is heuristic; there is no formal analysis showing that latent scaling approximates the true OOD distribution.\n\n5. Overstated terminology. Terms like “extrapolatory” or “modality-agnostic” may mislead readers, given the limited scope of experiments."}, "questions": {"value": "Please carefully read Weakness and answer all the five concerns."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qXNE8XiWDo", "forum": "vR2vLgnUvx", "replyto": "vR2vLgnUvx", "signatures": ["ICLR.cc/2026/Conference/Submission10082/Reviewer_EE2A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10082/Reviewer_EE2A"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10082/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761981193979, "cdate": 1761981193979, "tmdate": 1762921469839, "mdate": 1762921469839, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}