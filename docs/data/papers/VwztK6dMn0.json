{"id": "VwztK6dMn0", "number": 4620, "cdate": 1757729235813, "mdate": 1759898023142, "content": {"title": "UDIS: A User-query Driven Framework for Image Forgery Localization", "abstract": "The rapid advancement of image editing technologies has amplified the urgency of developing reliable Image Forgery Localization (IFL) methods. Recent approaches based on Multimodal Large Language Models (MLLMs) have shown promise but suffer from $\\textbf{weak visual-text alignment}$: they fail to regulate visual attention to the specific regions mentioned in user queries, leading to irrelevant responses. We argue that this limitation originates from a $\\textbf{global outcome driven}$ paradigm that directs interpretability toward forgery localization results and focuses visual attention on the entire image. To address this issue, we propose a paradigm shift: interpretability in IFL ought to be $\\textbf{regional user-query driven}$. Building on this principle and supported by a dataset containing queries related to the authenticity of specific regions, we present the $\\textbf{U}$ser-query $\\textbf{D}$riven $\\textbf{I}$mage $\\textbf{S}$hield (UDIS), a novel framework incorporating two key modules. The $\\textbf{Query-Guided Module (QGM)}$ introduces a $\\texttt{[QUERY]}$ token and a visual features filtering process based on the queries to strengthen the $\\textbf{input-level}$ alignment (focusing on connecting query and MLLM’s visual attention). The $\\textbf{Evidence-Aware Module (EAM)}$ introduces an $\\texttt{[EVI]}$ token and an auxiliary authenticity evidence classification task to enhance alignment at the $\\textbf{output-level}$ (focusing on associating explanatory text knowledge with forgery localization capability). By learning the two special tokens, MLLM’s alignment ability is enhanced, and the modal-consistency knowledge embedded in the tokens further supports the forgery localization process. Extensive experiments demonstrate that the proposed approach provides query-focused authenticity explanations, underscoring its superior practical value, and achieves state-of-the-art IFL performance.", "tldr": "", "keywords": ["Image Forgery Localization", "User-query Driven"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/24f034d039fe585b2dbac4c9e2c887340f1fed56.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes UDIS, a framework designed to enhance multimodal alignment in MLLM-based Image-For-Language  systems by introducing the principle that interpretability should be regional user query driven. UDIS integrates two key modules: the Query-Guided Module (QGM), which refines visual feature selection based on user queries, and the Evidence-Aware Module, which aligns outputs with visual evidence. The experiments on multiple datasets verify the effectiveness of the proposed UDIS."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "User-query based IFL is interesting and study-worthy\nThe experiment results are promosing."}, "weaknesses": {"value": "1, In  query-guided module, is it necessary to introduce two sets of learnable queries, i.e. the query token [QUERY] and the learnable query vectors Q^L? I understand that the authors attempt to capture both global and local feature, what if introduce only one set of learnable tokens, their CA outputs and their average vector as the local and global information? This would be streamline the framework.\n\n2, there is a lack visualization of selected Patch embeddings to verify that the selected patches are indeed related to the query text.\n\n3, How to determine that a query does not refer to any specific region (at the end of subsection 3.3)?\n\n4,  How to acquire T to supervise the  LLM output \\hat{T}  in L_{txt}?\n\n5, There is a lack of quantitative study of the methods under object-specified query\n\n6,  During the main experiments, a general query text is adopted for fair comparison, how much performance gain would acuqire if user the forgery region focused query text?\n\n\nminor questions:\n1, what's the final evidence classification accuracy?\n\n2, which layer is the ending of encoding the [QUERY] [LOC] [EVI]?  The last LLM layer? \n\n3, Inference time should be compared."}, "questions": {"value": "see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SN78mc3Q4m", "forum": "VwztK6dMn0", "replyto": "VwztK6dMn0", "signatures": ["ICLR.cc/2026/Conference/Submission4620/Reviewer_pXs9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4620/Reviewer_pXs9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4620/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761056019637, "cdate": 1761056019637, "tmdate": 1762917472144, "mdate": 1762917472144, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The article proposes the interesting concept of user-query driven and designs an image forgery localization framework UDIS based on a multimodal large language model. It consists of two modules: Query-Guided Module and Evidence-Aware Module, which respectively enhance the visual-text alignment capabilities of the forensic large model at the input and output ends, solving the defect that the forensic large model cannot answer specific user questions related to forensics and further improving the localization capability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The article proposes a user-query driven design principle for forensic models, which offers valuable insights and practical value.\n2. The proposed QGM guides the model's focus on specific image regions by selecting image features most relevant to the user's question, improving the model's visual-text alignment capabilities at the input-level. The EAM, through the auxiliary task of authenticity evidence classification, transforms knowledge from text annotations into localization capability, thereby enhancing the model's visual-text alignment capabilities at the output-level. The design motivations for both modules are clearly stated and the structure is simple, offering practical value.\n3. Compared to state-of-the-art image forgery localization methods, the proposed method achieves superior performance.\n4. The article is clearly written and well-organized."}, "weaknesses": {"value": "1. It is recommended to provide the probability distribution of different authenticity evidence on the training dataset to verify that the definitions of these authenticity evidence have sufficient ability to distinguish different images.\n2. More experiments are needed to verify the effectiveness of the method, such as the localization ability on AI-edited image datasets such as GRE[1].\n\n[1] Rethinking Image Editing Detection in the Era of Generative AI Revolution"}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8FSX8lJZpZ", "forum": "VwztK6dMn0", "replyto": "VwztK6dMn0", "signatures": ["ICLR.cc/2026/Conference/Submission4620/Reviewer_c3nf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4620/Reviewer_c3nf"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4620/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761703421967, "cdate": 1761703421967, "tmdate": 1762917471914, "mdate": 1762917471914, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a key limitation in existing MLLM-based Image Forgery Localization (IFL) methods: their weak visual-text alignment, which results in a failure to focus on specific regions mentioned in user queries. The authors propose a paradigm shift from a \"global outcome driven\" approach to a \"regional user-query driven\" one. \n\nTo enable this, they introduce UDIS (User-query Driven Image Shield), a new framework with two core components: 1) a Query-Guided Module (QGM) to enhance input-level alignment by filtering visual features based on the query, forcing the MLLM to attend to relevant regions ; and 2) an Evidence-Aware Module (EAM) to improve output-level alignment by using an auxiliary classification task to bridge the gap between coarse-grained textual explanations and fine-grained localization masks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The design of the EAM identifies a real-world problem: the \"discrepancy between the supervisory signals\" (coarse, structured text vs. fine-grained, unstructured masks). Using \"authenticity evidence\" (e.g., \"Color Difference,\" \"Blend Boundary\") as a shared, intermediate representation to bridge this modality gap via an auxiliary task  is an intelligent and effective design choice.\n\n- The model achieves state-of-the-art IFL performance (F1, IoU) against numerous baselines, including other MLLM-based methods, across a wide range of test datasets."}, "weaknesses": {"value": "- The process for annotating the forgery evidence (Color Difference, Blur, etc. ) is less clear than the process for the pristine evidence. Appendix A.2  provides concrete, heuristic-based rules for the 5 pristine types (e.g., \"compute mean and variance differences in Lab color space\"). However, it's not specified if the 5 forgery types are also annotated heuristically or if this was a massive manual annotation effort. If heuristic, this is a crucial detail for reproducibility and understanding potential biases (i.e., is the EAM learning forensics or just learning to replicate the heuristics?).\n\n- he EAM relies on a fixed, discrete taxonomy of 5 forgery and 5 pristine evidence types . This feels somewhat restrictive and similar to older, handcrafted-feature-based methods. It's unclear how this framework would handle novel generative forgeries (e.g., diffusion-based inpainting, as in the CocoGlide dataset ) where the \"evidence\" might be semantic or stylistic inconsistency, rather than fitting neatly into \"Blur\" or \"Texture Abnormal.\" A discussion on the EAM's extensibility or its performance on forgeries that defy this taxonomy would be welcome."}, "questions": {"value": "Regarding \"Weakness #4,\" how does the EAM's fixed evidence taxonomy handle modern generative forgeries, such as those in the CocoGlide dataset? Does the model learn to map semantic artifacts (which are not in the list) to one of the existing 5 forgery types, or does the EAM's contribution diminish for these more advanced forgeries?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jDDH2ferfe", "forum": "VwztK6dMn0", "replyto": "VwztK6dMn0", "signatures": ["ICLR.cc/2026/Conference/Submission4620/Reviewer_DR1U"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4620/Reviewer_DR1U"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4620/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761728234092, "cdate": 1761728234092, "tmdate": 1762917471701, "mdate": 1762917471701, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "UDIS (User-query Driven Image Shield) proposes a new paradigm for Image Forgery Localization (IFL) using Multimodal Large Language Models (MLLMs). Existing methods often fail to align visual attention with user queries, leading to irrelevant or global explanations. UDIS redefines interpretability as regional, user-query driven, introducing two modules. Query-Guided Module (QGM) aligns user queries with visual regions via a [QUERY] token and feature filtering. Evidence-Aware Module (EAM): aligns textual authenticity evidence with visual localization via an [EVI] token and auxiliary classification task. A curated dataset with region-specific queries and authenticity evidence supports training. Experiments across six benchmarks show state-of-the-art localization performance and superior interpretability, with robustness against post-processing distortions."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Conceptual novelty: This paper redefines interpretability in IFL as user-query driven, providing a fresh paradigm beyond outcome-based localization.\n\n2. Strong multimodal design: The QGM and EAM effectively improve input/output alignment, yielding better focus and explainability.\n\n3. Comprehensive dataset curation: This paper Introduces region-level Q&A-style annotations and evidence categories, enhancing real-world relevance.\n\n4. Extensive experiments, ablations, and robustness tests consistently show superior F1/IoU and interpretability metrics."}, "weaknesses": {"value": "1. The result in Figure 9 is quite puzzling: it appears that the model predicts a mask regardless of whether the answer is “real” or “fake”. \n\n2. Moreover, the paper forces the large‑language model (LLM) to produce detection results in a very rigid format: “the xxx is real/fake, because its xxx (Evidence type)”. The first part is a binary classification (real vs. fake) and the second part is a fixed multi‑class evidence type. Such a rigid output format significantly undermines the LLM’s inherent advantage of generating varied and rich textual responses. In effect, the LLM becomes replaceable—another backbone could output the same fixed pattern with similar performance.\n\n3. In Table 2, the model's forgery detection capability is presented, but it is compared mainly against other LLM‑based methods rather than the non‑LLM based approaches (e.g., those listed in Table 1 such as MVSS‑Net, IML‑ViT, APSC‑Net). Furthermore, the reported detection accuracy for the proposed method (UDIS) is only 0.732, which seems relatively low and perhaps insufficient for acceptance in practical forensic settings. Additionally, Table 2 lacks evaluations on multiple benchmarks in the way Table 1 provides coverage across several datasets."}, "questions": {"value": "Please refer to the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yv2oIlzbuU", "forum": "VwztK6dMn0", "replyto": "VwztK6dMn0", "signatures": ["ICLR.cc/2026/Conference/Submission4620/Reviewer_CXft"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4620/Reviewer_CXft"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4620/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761981124860, "cdate": 1761981124860, "tmdate": 1762917471197, "mdate": 1762917471197, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}