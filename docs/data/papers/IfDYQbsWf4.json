{"id": "IfDYQbsWf4", "number": 18806, "cdate": 1758291002812, "mdate": 1759897080444, "content": {"title": "Flow Expansion via Verifier-Constrained Noised State Space Exploration", "abstract": "Flow and diffusion models are typically pre-trained on limited available data (e.g., molecular samples), covering only a fraction of the valid design space (e.g., the full molecular space). As a consequence, they tend to generate samples from only a narrow portion of the feasible domain. This is a fundamental limitation for scientific discovery applications, where one typically aims to sample valid designs beyond the available data distribution. To this end, we address the challenge of leveraging access to a verifier (e.g., an atomic bonds checker), to adapt a pre-trained flow model so that its induced density expands beyond regions of high data availability, while preserving samples validity. We introduce formal notions of strong and weak verifiers and propose algorithmic frameworks for global and local flow expansion via probability-space optimization. Then, we present Flow Expander (FE), a scalable mirror descent scheme that provably tackles both problems by verifier-constrained entropy maximization over the flow process noised state space. Next, we provide a thorough theoretical analysis of the proposed method, and state convergence guarantees under both idealized and general assumptions. Ultimately, we empirically evaluate our method on both illustrative, yet visually interpretable settings, and on a molecular design task showcasing the ability of FE to expand a pre-trained flow model increasing conformer diversity while preserving validity.", "tldr": "", "keywords": ["flow models", "diffusion models", "exploration", "verifiers", "scientific discovery"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/09fd2c82d4f089db00c0e28506a0258373f94bda.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Flow Expander (FE), a general framework for expanding the support of pre-trained flow models to cover the valid design space more uniformly. The method uses verifiers—functions that check the validity of samples (e.g., physical or chemical constraints)—to guide exploration and improve the generative model’s coverage beyond its initially narrow region."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Introduces a method to expand flow models using strong or weak verifiers to expand diversity.\n- The scheme allows practical, gradient-based fine-tuning compatible with existing flow and diffusion models."}, "weaknesses": {"value": "- What is $\\lambda_t$ and $\\gamma_t$ in Eq. 8 and 9? Are these weightings and discount factors? And how are they chosen?\n- How do you parametrize the verifier function $v(x)$, is it modeled like a Gumbel-Softmax? Also, I wonder if it's strict to have $v(x)$ to be bounded, is the method extendable if one has an unbounded $v(x)$?\n- I am not sure about the downstream applications of this method in drug discovery, as currently it's only restricted to the bounded verifier objective to check validity or bonds. Usually, this can also be done via BO in latent space by embedding priors with GP or just generally with rejection sampling in latent space to get valid molecules only, similar to an explore and exploit-based method. If the $v(x)$ can be extended to the unbounded domain such that one can use molecular properties to guide it, then it would be a good contribution.\n- Does the model incorporate whether the verifier is noisy?\n- Could FE be viewed as iteratively reshaping an implicit energy landscape defined by verifier penalties?"}, "questions": {"value": "See the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "NsxOeU1jtU", "forum": "IfDYQbsWf4", "replyto": "IfDYQbsWf4", "signatures": ["ICLR.cc/2026/Conference/Submission18806/Reviewer_e76w"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18806/Reviewer_e76w"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761916658256, "cdate": 1761916658256, "tmdate": 1763000000132, "mdate": 1763000000132, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem that pre-trained generative models (flows, diffusion) tend to sample from a narrow part of the valid design space, which is a key limitation for scientific discovery. The authors propose to \"expand\" the model's density by leveraging an external verifier. The paper formalizes this into two problems: Global Flow Expansion (using a perfect strong verifier) and Local Flow Expansion (using an imperfect weak verifier). \n\nTo solve these, the paper introduces Flow Expander (FE), a mirror descent algorithm. A key idea is to formulate the optimization objective over the entire noised state space of the flow process ($Q^\\pi = \\{p_t^\\pi\\}_{t \\in [0,1]}$) rather than just the final time-step $p_1^\\pi$. This is claimed to provide a principled way to avoid score divergence issues near $t=1$. The paper provides theoretical convergence guarantees and presents experiments on 2D illustrative tasks and a molecular conformer generation task (QM9)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "* Addresses how to leverage pre-trained generative models to explore novel and valid regions of a design space, moving beyond the original data distribution.\n* Formalizes the problem into Global Flow Expansion (using a strong verifier) and Local Flow Expansion (using a weak verifier).\n* Lifts the optimization objective from the final time-step ($p_1$) to the entire noised state space ($Q^\\pi$) to theoretically mitigate the score divergence problem that occurs as $t \\to 1$."}, "weaknesses": {"value": "* One weakness is the use of potentially uninformative baselines. The paper compares FE (a \"search + constraint\" method) against \"search-only\" (S-MEME/FDC) and \"constraint-only\" (CONSTR). This comparison is not fully informative, as FE is designed to outperform them. A fair and important baseline would be unconstrained exploration (FDC/S-MEME) followed by post-hoc rejection sampling using the verifier. Without this, the practical value of FE's complex optimization is unknown.\n* The method's reliance on a differentiable verifier is a considerable practical limitation. The chosen solver (Adjoint Matching, Alg. 3) requires gradients from $\\log v(x)$. Most real-world verifiers for scientific discovery (e.g., RDKit SanitizeMol, physics simulators) are black-box and non-differentiable. The paper's workaround (smoothing a simple function in App G.1, G.5.2) does not solve this general problem, limiting the method's applicability.\n* The experimental validation is not fully convincing. The 2D experiments can be sensitive to tuning, and the QM9 dataset is too small-scale to demonstrate robustness.\n* There is a notable absence of hyperparameter ablation studies for the key parameters ($\\alpha, \\gamma_k, \\eta_k$).\n* This is particularly concerning for the L-FE molecular experiment. The chosen parameters ($\\alpha=9$, $\\gamma_k=0.00001/(1+k)$) are so conservative that the effective step size is $\\tilde{\\gamma}_k \\approx 0.0001$ and the KL weight $\\beta=0.9$. This suggests the model is moving very little from the pre-trained state. The claimed high validity (81%) is likely just the original model's high validity, not a product of the algorithm.\n* As discussed in Appendix H, $\\alpha$ and $\\gamma_k$ are entangled, jointly determining the effective step size $\\tilde{\\gamma}_k$. This implies the method is likely quite sensitive to hyperparameter tuning, but this important aspect is not analyzed.\n* The computational cost appears very high. The algorithm requires $\\approx 2 \\times K \\times N$ full model fine-tuning runs (e.g., $2 \\times 8 \\times 4 = 64$ in the L-FE experiment). This may be impractical for large-scale problems, and the paper makes no analysis of this cost or scalability against other baselines.\n* A potential theory-practice gap exists. The convergence guarantees (Thm 5.2) rely on assumptions (E.1, E.2) about the solver, but there is no proof or justification that the actual solver used (Adjoint Matching, Alg. 3) satisfies these assumptions."}, "questions": {"value": "* Can you provide a direct comparison against the FDC + post-hoc rejection sampling baseline? This would be very helpful to demonstrate that your complex constrained optimization is superior to a simple filter.\n* How do you propose to use FE with a truly black-box, non-differentiable verifier (e.g., a hard RDKit sanitization check)? This seems to be the most common and important use case.\n* Please address the question that your L-FE experiment parameters ($\\alpha=9$, $\\gamma_k \\approx 0.00001$) are so conservative the model is \"not moving\" from the pre-trained state. Can you provide a hyperparameter ablation study for $\\alpha$ and $\\gamma_k$ to show how the diversity/validity trade-off changes?\n* To help us understand the method, can you provide an ablation showing the results of running only the EXPAND step and only the PROJECT step for $K$ iterations?\n* Can you provide an experiment for Global Flow Expansion on a real-world dataset, not just a 2D toy problem?\n\nI would be willing to raise my score if the authors can thoroughly address the concerns raised in the weaknesses and questions section. In particular, the concerns regarding the experiments (ablation, large-scale dataset)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "K89oNNPXVx", "forum": "IfDYQbsWf4", "replyto": "IfDYQbsWf4", "signatures": ["ICLR.cc/2026/Conference/Submission18806/Reviewer_MbXc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18806/Reviewer_MbXc"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761919901373, "cdate": 1761919901373, "tmdate": 1762929923553, "mdate": 1762929923553, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Flow and diffusion models are typically pre-trained on limited available data. As a result, they tend to generate samples from only a narrow portion of the feasible domain.\nTo address this limitation, the authors assume access to a verifier and propose adapting a pre-trained flow model so that its induced density expands beyond regions of high data availability. They pose the key question:\n“How can we leverage a given verifier to adapt a flow or diffusion model to generate designs beyond high data-availability regions while preserving validity?”\nThe authors consider two types of verifiers:\n•\tStrong verifier: a function nu: X -> {0,1} that characterizes validity exactly, i.e., nu(x)=1 if and only if x is valid.\n•\tWeak verifier: a function that acts as a filter—it rejects some invalid designs but may fail to detect others (formally, nu(x)=0 => x is invalid)."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Major contributions: \n•\tFlow Expander (FE), a principled probability-space optimization scheme\n•\tA theoretical analysis of the proposed algorithm\n•\tAn experimental evaluation of FE\n\nIt is a well-written paper, with new ideas and interesting results. \n\nI think many researchers in our community will appreciate this paper."}, "weaknesses": {"value": "•\tThe paper is somewhat dense and not always easy to follow.\n\n•\tThe numerical experiments are somewhat limited. I appreciate both the illustrative examples and the results on the molecular design task, but I wish the paper included more high-impact, real-world examples where verifiers exist."}, "questions": {"value": "•\tIn the description of Continuous-time Reinforcement Learning, states and actions have been defined, but I think the definition of reward is missing.\n\n•\tLine 175: If Omega_v is not a bounded set, then without further constraints, there is no maximum entropy distribution. Is there a simple way to generalize Problem 5 to this unbounded setting?\n\n•\tInstead of maximizing entropy, can we get reasonably good results by simply maximizing the variance of the distribution instead?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YKSvNnIF5t", "forum": "IfDYQbsWf4", "replyto": "IfDYQbsWf4", "signatures": ["ICLR.cc/2026/Conference/Submission18806/Reviewer_oQPY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18806/Reviewer_oQPY"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761954932894, "cdate": 1761954932894, "tmdate": 1762929903703, "mdate": 1762929903703, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Flow Expander (FE), a framework that expands the support of pretrained flow or diffusion models under verifier constraints. The method formulates verifier-constrained entropy maximization as a mirror-descent optimization problem over probability measures, consisting of two alternating steps: an Expansion step that increases entropy and explores new modes, and a Projection step that enforces validity through a soft-verifier function. The authors provide theoretical convergence guarantees and demonstrate the approach on toy 2D examples and QM9 molecular conformers. The work is theoretically well-motivated, connecting flow-based generative modeling with constrained optimization, but its empirical validation and baseline clarity remain limited."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**Strong motivation and relevance.**\nThe paper tackles an important limitation of pretrained flow and diffusion models—namely, their inability to explore beyond the data manifold while maintaining sample validity. The idea of integrating verifier-based constraints into generative model fine-tuning is timely and relevant for scientific design applications (e.g., molecular or material generation).\n\n**Principled formulation.**\nThe proposed *Flow Expander* framework is grounded in a clear optimization principle: verifier-constrained entropy maximization. Casting this as a mirror-descent problem in the space of probability measures provides a mathematically elegant and unified view of exploration under validity constraints.\n\n**Theoretical completeness.**\nThe paper presents a solid convergence analysis. The proofs, though dense, follow established mirror-descent theory and offer formal justification for the proposed update rule.\n\n**Potentially general concept.**\nThe introduction of a *soft-verifier* mechanism is conceptually interesting and, if properly extended, could provide a practical interface between learned generative models and rule-based or simulation-based validity filters used in real-world design workflows (e.g., high-throughput screening, physical constraints, or chemical property checks)."}, "weaknesses": {"value": "**Limited and unconvincing experiments.**\nThe empirical evaluation is restricted to 2D toy examples and a small-scale QM9 conformational generation task. These setups are insufficient to demonstrate practical effectiveness or scalability of the proposed method. The results primarily serve as proof-of-concept demonstrations rather than evidence of real-world impact or generalization capability.\n\n**Unclear and unverifiable baselines.**\nThe paper cites Uehara et al. (2024, Section 8.2) as the source of the “CONSTR” baseline. However, that section contains only a theoretical corollary without any algorithmic description, implementation details, or experimental setup, making it impossible to reproduce or verify the reported baseline results. Moreover, many components of the proposed method appear to be directly borrowed from S-MEME (e.g., the mirror-descent formulation, entropy maximization objective, and theoretical convergence argument), yet the paper does not clearly delineate which parts are newly introduced and which are adapted from prior work. This lack of transparency in baseline selection and methodological novelty significantly undermines the credibility and reproducibility of the experimental claims.\n\n**Severe clarity and notation issues.**\nThe paper suffers from significant readability and presentation problems:\n1. Misuse of notation and inconsistent subscripts/superscripts.\n2. line (234) incorrectly states $\\delta\\mathcal{G}(\\mu)\\in F(\\mathcal{X})$, though the functional derivative should be a function over $\\mathcal{X}$.\n3. Algorithm 4 is referenced but missing.\n4. Symbols such as $F(\\mathcal{X}), \\mathcal{G}_t$, and $\\mathcal{L}(Q)$ are repeatedly overloaded, making the derivations unnecessarily hard to follow. These issues significantly reduce the accessibility of an otherwise theoretically interesting paper.\n\n**Applicability and experimental realism.**\nThe introduction of *soft-verifiers* is an interesting and potentially powerful concept, as it could, in principle, allow high-throughput filtering strategies—commonly used in drug and material discovery—to be incorporated into generative models. However, the paper does not provide convincing examples where this mechanism becomes practically important. Beyond toy examples, the molecular conformational experiments hold limited chemical relevance: in conformational space, the goal is typically to reproduce the Boltzmann distribution rather than to impose external validity filters, so the verifier concept is of marginal utility."}, "questions": {"value": "**Separation from S-MEME.**\nMany components of the proposed Flow Expander (e.g., entropy maximization, mirror-descent formulation, convergence proof) appear closely aligned with S-MEME. Could the authors clearly specify which elements are newly introduced in this paper (e.g., verifier projection) and which are inherited from S-MEME or related prior works?\n\n**Applicability to discrete domains.**\nThe proposed formulation assumes a continuous variable space, where functional gradients and mirror-descent updates are well defined.\nHow could this framework extend to **discrete or combinatorial domains** such as molecular graphs or protein sequences, where the notion of a variational gradient is not clearly defined?\nIn particular, can the *soft-verifier* idea be adapted to these settings, which are arguably more relevant to real-world drug or material discovery?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "The reviewer utilized a large language model (LLM) to assist in reviewing and interpreting the heavy mathematical parts of the paper."}, "rating": {"value": 4}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "cvF7mVTzbG", "forum": "IfDYQbsWf4", "replyto": "IfDYQbsWf4", "signatures": ["ICLR.cc/2026/Conference/Submission18806/Reviewer_Kx6q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18806/Reviewer_Kx6q"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761965615092, "cdate": 1761965615092, "tmdate": 1762929838975, "mdate": 1762929838975, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}