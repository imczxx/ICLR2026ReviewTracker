{"id": "RZT1ixYGk1", "number": 3341, "cdate": 1757405109970, "mdate": 1763628689753, "content": {"title": "Beyond Aggregation: Guiding Clients in Heterogeneous Federated Learning", "abstract": "Federated learning (FL) is increasingly adopted in domains like healthcare, where data privacy is paramount. \nA fundamental challenge in these systems is statistical heterogeneity—the fact that data distributions vary significantly across clients (e.g., different hospitals may treat distinct patient demographics). \nWhile current FL algorithms focus on aggregating model updates from these heterogeneous clients, the potential of the central server remains under-explored.\nThis paper is motivated by a healthcare scenario: could a central server not only coordinate model training but also guide a new patient to the hospital best equipped for their specific condition? We generalize this idea to propose a novel paradigm for FL systems where the server actively guides the allocation of new tasks or queries to the most appropriate client.\nTo enable this, we introduce a density ratio model and empirical likelihood-based framework that simultaneously addresses two goals: (1) learning effective local models on each client, and (2) finding the best matching client for a new query. \nEmpirical results demonstrate the framework's effectiveness on benchmark datasets, showing improvements in both model accuracy and the precision of client guidance compared to standard FL approaches. This work opens a new direction for building more intelligent and resource-efficient FL systems that leverage heterogeneity as a feature, not just a bug.", "tldr": "", "keywords": ["Federated learning; Healthcare"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c00332b6f91b1f494566ab335d25122b1bc8f29d.pdf", "supplementary_material": "/attachment/fd4a1867c75f59d3c67f534c1fa15f26911ffbeb.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposed a FL paradigm named FedDRM, that treats client heterogeneity as an asset rather than a limitation. \nBy leveraging an empirical likelihood-based framework, FedDRM simultaneously trains personalized local models and enables the central server to intelligently route new queries to the most suitable client. \nHowever, the experiments are limited to CIFAR benchmarks, which are small scale and fewer than existing methods. They may be insufficent to demonstrate the superity of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The idea of leveraging heterogeneity for query routing instead of merely mitigating it, seems interesting and offer a novel perspective in FL.\n\n2. The empirical likelihood framework provides a principled foundation for joint model training and client matching, with a tractable dual loss formulation."}, "weaknesses": {"value": "1. The only dataset is CIFAR (including cifar 10 and cifar 100), which is significient different from the data in domains such as healthcare and finance. This limits the support for claims about the method’s potential in such areas.\n\n2. The client-classification head may face challenges when scaling to very large client pools (let's say, >100 clients), as gradient drift could become worsen."}, "questions": {"value": "1. Could the client-classification mechanism be distilled into a lighter-weight model to reduce inference overhead?\n\n2. How could FedDRM adapt to dynamic client populations? For example, the data distributions evolve over time."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VX2nKiT19y", "forum": "RZT1ixYGk1", "replyto": "RZT1ixYGk1", "signatures": ["ICLR.cc/2026/Conference/Submission3341/Reviewer_C2JH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3341/Reviewer_C2JH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3341/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761653737760, "cdate": 1761653737760, "tmdate": 1762916679500, "mdate": 1762916679500, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the problem of heterogeneity among clients in federated learning. The paper classifies the heterogeneity into two categories: i) Covariate shift ii) label shift. Then the paper investigates the problems of data heterogeneity in federated learning which are combination of these types heterogeneity.To address this problem, the paper defines new local loss functions for clients. Then using some adding heads to a base shared or global model, the federated learning is performed. Experiments on image classification is conducted to show the effectiveness of the proposed algorithms."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper proposes more responsibilities for the server in federated learning such that the server guides the clients during training. This idea is interesting and can leads to improvements.\n- The convergence rate of the proposed algorithm is obtained for strongly convex loss functions.\n- The proposed algorithm is compared against variety of federated learning baselines."}, "weaknesses": {"value": "- The most important weakness of the paper is presentation. The importance and novelty of the paper’s contributions are not clearly conveyed. I recommend that the authors explicitly and concisely list the main contributions of the work, such as the specific problems that the proposed algorithm aims to solve. At present, there is no clear evidence or justification demonstrating that the proposed algorithm effectively addresses the key issues claimed in the paper.\n- The paper focuses solely on the multi-class classification problem, which is a relatively minor limitation.\n- The discussion following Theorem 2.5 does not discuss if the proposed algorithm improves the convergence rate compared to existing methods.\n- The data heterogeneity modeled in the experiments is synthetic. While this is common in federated learning research, the introduction suggests that the paper targets particular types of heterogeneity. Because of this, the practical applicability of the studied problem is not clear."}, "questions": {"value": "- While reading the paper, I found it unclear why Theorem 2.1 is important. I suggest adding more explanations to clarify its significance, or alternatively, moving it to the appendix. Could you elaborate on this point?\n- Could you also elaborate on the relevance of data modeling in the experiments to the problems discussed in the introduction?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "P33jhMZLr4", "forum": "RZT1ixYGk1", "replyto": "RZT1ixYGk1", "signatures": ["ICLR.cc/2026/Conference/Submission3341/Reviewer_Yf1W"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3341/Reviewer_Yf1W"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3341/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761877661459, "cdate": 1761877661459, "tmdate": 1762916679317, "mdate": 1762916679317, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes FedDRM, a federated learning (FL) framework that extends beyond traditional aggregation to enable the central server to actively route new queries (e.g., patient data) to the most suitable client in heterogeneous environments. Drawing from a healthcare motivation—directing patients to specialized hospitals—the authors model client data distributions using a semiparametric density ratio model (DRM) anchored to a nonparametric empirical likelihood (EL) baseline at the server. Under assumptions like covariate shift, they derive exponential tilts linking client distributions (Eqs. 2-3) and extend this to marginals (Theorem 2.1). The profiled EL loss decomposes into cross-entropy terms for label prediction and client identification, jointly optimizing local accuracy and routing precision. Experiments on CIFAR-10/100 with Dirichlet heterogeneity (α=0.3) compare against baselines like FedAvg, reporting gains in \"system acc\" (routed performance) and guidance metrics, though results appear inconsistent across tables."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The core idea of reframing heterogeneity as an asset—via server-guided routing— is a genuine advance over passive FL methods. By turning the server into an \"intelligent router\" (Fig. 1), it addresses a practical gap: e.g., in finance, routing fraud queries to distribution-matched banks, or in healthcare, assigning patients to expert clients. This not only boosts efficiency but also highlights FL's untapped potential for adaptive, privacy-preserving systems.\n\n2. The DRM-EL framework elegantly unifies heterogeneous training with query matching. The use of multiplicative tilts (Eq. 3) to capture shifts without raw data sharing is nonparametric yet efficient, and the loss decomposition (label + client CE) provides a clean, interpretable objective. Theorem 2.1's extension to marginals under covariate shift adds rigor, making the method theoretically grounded while extensible to label/full shifts.\n\n3. Despite limitations, the reported \"system acc\" improvements (e.g., leveraging routing for end-to-end gains) demonstrate the framework's promise over aggregation-only baselines. This dual focus—accuracy + precision—positions FedDRM as a step toward resource-efficient FL, with broad applicability in multi-client domains."}, "weaknesses": {"value": "1. The introduction builds excitement around the routing idea but omits any preview of the DRM or EL machinery, leaving readers disoriented when section 2 dives straight into FedDRM. What is DRM? A brief 1-2 sentence teaser in the intro would bridge this.\n\n2. While results show promise, the scope is too narrow to substantiate claims under severe heterogeneity. You only report Dirichlet (dir) α=0.3 (low heterogeneity; near-IID), but FL's real pain is high heterogeneity. How does FedDRM scale here? Add analysis across α values or extend to more datasets to show robustness.\n\n3. What is the number of clients in the two main tables? I found that the results seem best fit with m=8; however, the results are not well-aligned. The system acc for FedDRM is 59.59% under dir=0.3, which is significantly lower than the result in the first main table.\n\n4. FedDRM requires uploading additional density ratio parameters (e.g., tilts γ_i, ξ_i in Eq. (3), lines 144-147) alongside model updates, potentially undermining FL's privacy guarantees (e.g., vs. FedAvg's aggregated-only sharing, lines 32-35). These tilts encode distributional shifts (e.g., π_i margins), risking inference attacks on sensitive traits like demographics (Fig. 1, lines 45-60)."}, "questions": {"value": "1. The authors only report the results when Dirichlet (dir) α=0.3 (low heterogeneity; near-IID), but FL's real pain is high heterogeneity. How does FedDRM scale here? Could the authors add analysis across more α values or extend to more datasets to show robustness?\n2. Could you please explain the experimental details? For example, what is the number of clients in the two main tables? I found that the results seem best fit with m=8; however, the results are not well-aligned. \n3. Could the author please provide privacy guarantees for the additional uploaded parameters?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "z5wJSmKq0A", "forum": "RZT1ixYGk1", "replyto": "RZT1ixYGk1", "signatures": ["ICLR.cc/2026/Conference/Submission3341/Reviewer_avg5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3341/Reviewer_avg5"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3341/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927559048, "cdate": 1761927559048, "tmdate": 1762916679130, "mdate": 1762916679130, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}