{"id": "evepIXBxL8", "number": 17374, "cdate": 1758275189863, "mdate": 1759897179381, "content": {"title": "Physically-Guided Optical Inversion Enable Non-Contact Side-Channel Attack on Isolated Screens", "abstract": "Noncontact exfiltration of electronic screen content poses a security challenge, with side-channel incursions as the principal vector. We introduce an optical projection side-channel paradigm that confronts two core instabilities: (i) the near-singular Jacobian spectrum of projection mapping breaches Hadamard stability, rendering inversion hypersensitive to perturbations; (ii) irreversible compression in light transport obliterates global semantic cues, magnifying reconstruction ambiguity. Exploiting passive speckle patterns formed by diffuse reflection, our Irradiance Robust Radiometric Inversion Network (IR$^4$Net) fuses a Physically Regularized Irradiance Approximation (PRIrr‑Approximation), which embeds the radiative transfer equation in a learnable optimizer, with a contour-to-detail cross-scale reconstruction mechanism that arrests noise propagation. Moreover, an Irreversibility Constrained Semantic Reprojection (ICSR) module reinstates lost global structure through context-driven semantic mapping. Evaluated across four scene categories, IR$^4$Net achieves fidelity beyond competing neural approaches while retaining resilience to illumination perturbations.", "tldr": "", "keywords": ["Computer Vision", "Deep Learning", "Side Channel Attack", "Information Security", "Information Theft"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3d25f57f3388425adc9910609f07d9fd876f9148.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a novel optical projection side-channel attack that enables non-contact, passive reconstruction of screen content from diffuse wall reflections—posing a new threat to physically isolated systems. The core technical challenges are the ill-conditioned nature of the optical inversion (due to near-singular Jacobians and Hadamard instability) and irreversible semantic loss from light transport compression. To address these, the authors propose **IR4Net**, a physically guided deep inversion framework comprising two key modules: (1) **PRIrr-Approximation**, which embeds the radiative transfer equation into a learnable, momentum-guided iterative optimizer to stabilize inversion and suppress perturbation amplification; and (2) **ICSR (Irreversibility-Constrained Semantic Reprojection)**, which recovers global semantics via context-aware feature mapping in deep semantic space. Evaluated on four custom datasets (ReSh-WebSight, ReSh-Password, ReSh-Chart, ReSh-Screen), IR4Net outperforms both reconstruction-based (e.g., Uformer, ConvIR) and generative (e.g., CycleGAN) baselines in PSNR, SSIM, and RMSE, while demonstrating superior robustness under low illumination and noise."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "(1) The paper identifies and demonstrates a previously overlooked attack vector—reconstructing screen content from *diffuse wall reflections alone*—which fundamentally challenges assumptions about the security of air-gapped systems.  \n(2) The proposed IR4Net integrates physics-based modeling (radiative transfer, Lambertian reflection) with deep learning in a principled way, using momentum-guided inversion and frequency-selective upsampling to address ill-posedness and perturbation sensitivity.  \n(3) Comprehensive experiments across four diverse datasets, ablation studies on optimization schemes, and robustness tests under low luminance and noise convincingly validate the method’s superiority over strong baselines.  \n(4) The ICSR module offers a creative solution to semantic loss by enforcing perceptual consistency between structural and semantic feature spaces, enabling coherent global reconstruction even when high-frequency details are irreversibly degraded."}, "weaknesses": {"value": "- The datasets (e.g., ReSh-Screen with only 1,272 images) are not publicly released, and critical experimental details—such as exact camera-screen-wall geometry, wall BRDFs, or lighting calibration—are insufficiently described, severely limiting reproducibility.  \n- The method assumes ideal Lambertian wall reflectance, yet real-world surfaces often exhibit non-Lambertian or spatially varying reflectance; the paper lacks quantitative analysis of performance degradation under such conditions.  \n- The claim of “no line-of-sight” is potentially misleading: the setup still requires indirect optical paths (e.g., shared wall), and the attack’s feasibility under more extreme occlusion (e.g., around corners or through multiple bounces) remains unverified."}, "questions": {"value": "(1) Could the authors provide the exact physical configuration used in data collection (e.g., screen-to-wall distance, camera-to-wall distance, wall material properties, ambient lighting conditions)? Without these, independent replication is nearly impossible.  \n(2) How does IR4Net perform on non-Lambertian surfaces (e.g., glossy paint, metal, or textured wallpaper)? Are there quantitative metrics (e.g., PSNR drop) showing sensitivity to BRDF deviation from the ideal diffuse assumption?  \n(3) The paper states the attack works “without line-of-sight,” but Figure 5(c) shows a shared wall between rooms. Can the method reconstruct content when the screen is not optically connected to the observed wall via any single-bounce path (e.g., around a corner with two or more diffuse bounces)?  \n(4) The ICSR module aligns structural and semantic features via cosine similarity—could this lead to plausible but factually incorrect hallucinations (e.g., generating “admin” instead of the actual typed password)? Are there examples of such failures?  \n- What are the computational requirements (inference time, memory footprint) of IR4Net? Is real-time reconstruction feasible on consumer hardware, or is the method limited to offline analysis?  \n- Why were recent physics-informed neural networks (e.g., PINNs, NeRF-based inverse rendering) not included in the baselines? How does IR4Net conceptually and empirically differ from these approaches?  \n(5) The ablation in Table 2 only compares iterative solvers but does not isolate the contributions of the spatial diffusion path, semantic attenuation path, and frequency-selective upsampling in PRIrr-Approximation. Could the authors provide a module-wise ablation?  \n(6) Given the serious security implications, have the authors engaged in responsible disclosure with relevant hardware or OS vendors? Do they plan to delay public release of code or datasets until practical countermeasures (e.g., screen filters, ambient light control) are developed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dhtY9KojAZ", "forum": "evepIXBxL8", "replyto": "evepIXBxL8", "signatures": ["ICLR.cc/2026/Conference/Submission17374/Reviewer_4VYg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17374/Reviewer_4VYg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17374/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761624394431, "cdate": 1761624394431, "tmdate": 1762927284447, "mdate": 1762927284447, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This manuscript introduces a non-contact side-channel attack capable of reconstructing the content of an isolated electronic screen. The attack leverages the diffuse reflection of the screen's light from a nearby surface, such as a wall. The authors identify two primary technical challenges: the ill-posed nature of the optical inversion problem, which amplifies noise, and the severe loss of semantic information due to light transport.o address this, they propose IR4Net with two key components: 1) Physically-Regularized Irradiance Approximation, and 2) Irreversibility-Constrained Semantic Re-Projection. The authors created four new datasets (ReSh-WebSight, ReSh-Password, ReSh-Chart, and ReSh-Screen) to evaluate their method. The experiments demonstrate that IR4Net can approximately reconsturct the content of an isolated electronic screen."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "+ The manuscript is well-organized. \n+ The proposed attack is novel. The concept of reconstructing screen content from faint, diffuse reflections on a wall opens a new and significant avenue for information leakage in environments previously considered secure.\n+ The proposed model is reasonable and indeed a solid baseline for this new, challenging task."}, "weaknesses": {"value": "+ The most alarming weakness is the methodology used to partition the datasets. The authors state that the four datasets were \"randomized into training, validation, and test subsets in an 8:1:1 ratio.\" This description, if it refers to a simple random split of individual image samples. This suggests a critical misunderstanding of how to evaluate generalization in content-aware tasks. These datasets are built on a finite set of templates. A simple random split means that variations of the exact same template or UI element will exist across the training, validation, and test sets. For example, the model might be trained on 80% of screenshots from a website with a specific header and sidebar, and then tested on the remaining 20% of screenshots from the same website. In this case, the model is not learning the general physics of optical inversion; it is memorizing the layout of the template. The task degrades from a difficult inverse problem to a simple inpainting or pattern completion task on a known structure.\n\n+ Baseline Fairness. Given that the task is novel and highly challenging, it is unclear if the baseline models were suitable for this specific domain. Many of these models were designed for tasks like denoising or dehazing where the underlying image structure is far more preserved. A brief discussion on how the baselines were applied or potentially fine-tuned would strengthen the experimental claims. The authors are also encourage to bring more baselines for a comprehensive view.\n\n+ Practicality of the attack. A real-world attacker cannot guarantee that their target will be displaying content that matches their pre-trained dataset. An effective side-channel attack tool must be robust and general-purpose. If the IR4Net model requires an attacker to first build a massive, tailored dataset of the specific application or website they intend to spy on, its feasibility as a covert threat is dramatically reduced.\n\n+ Lack of Hardware Specification. The paper provides no details on the acquisition hardware. Was a consumer-grade DSLR used, a smartphone, or a high-end scientific camera with high dynamic range and low sensor noise? Was a long exposure time necessary? These details are fundamental to understanding the cost and feasibility of mounting such an attack."}, "questions": {"value": "Please resolve the concerns in the weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "c6oVn9SJ3b", "forum": "evepIXBxL8", "replyto": "evepIXBxL8", "signatures": ["ICLR.cc/2026/Conference/Submission17374/Reviewer_9oV2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17374/Reviewer_9oV2"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17374/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761929877048, "cdate": 1761929877048, "tmdate": 1762927283972, "mdate": 1762927283972, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes IR4Net, a physics-informed neural network for non-contact optical side-channel attacks on isolated screens. By leveraging wall-reflected speckle patterns, the method reconstructs screen content using a physically-regularized inversion module and a semantic completion module. Experiments on four\nscene categories, show strong performance under various perturbations such as low light, noise, and material changes."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper has thoroughly discussed the related work. \n- Physics-guided design: Embeds radiative transfer modeling into learning, improving stability and inversion accuracy.\n- Strong performance: Outperforms existing methods across PSNR, SSIM, RMSE, and LPIPS, under various conditions (e.g., low brightness, noise).\n- Thorough evaluation: Includes ablation, noise tests, luminance robustness, material variation, and temporal consistency."}, "weaknesses": {"value": "1. The evaluation is primarily conducted on synthetic datasets. It remains unclear how well the method generalizes to real-world environments with complex conditions such as multipath reflections or dynamic lighting. Could the authors provide results or discussion in such scenarios?\n\n2. Analysis on inference time, computational cost, or resource requirements should be added, which limits understanding of its practicality in real-world attacks. Please include runtime metrics or efficiency evaluations.\n\n3. The proposed method may be sensitive to wall reflectance properties, but there is no quantitative analysis of this dependency. How robust is the method under varying surface materials or reflectance levels?\n\n4. The operational feasibility of the attack is not fully discussed. What are the requirements in terms of camera resolution, alignment precision, or environmental constraints?\n\n5. No clear defense strategies are proposed. It would be valuable to include potential countermeasures or mitigation suggestions to guide practical security considerations.\n\n6. Visual quality needs improvement: Teaser, pipeline, and visual examples appear blurry and should be presented with higher clarity."}, "questions": {"value": "Refer to the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No Ethics Concerns."}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "a2HlxR87qL", "forum": "evepIXBxL8", "replyto": "evepIXBxL8", "signatures": ["ICLR.cc/2026/Conference/Submission17374/Reviewer_J4Kx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17374/Reviewer_J4Kx"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17374/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993212517, "cdate": 1761993212517, "tmdate": 1762927283587, "mdate": 1762927283587, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes IR⁴Net (Irradiance Robust Radiometric Inversion Network), a novel framework for non-contact side-channel attacks on isolated screens via optical projection inversion. The core challenge addressed is reconstructing screen content from diffuse wall reflections, which suffers from two critical issues: (i) near-singular Jacobian of projection mapping leading to instability against perturbations; (ii) irreversible information compression in light transport causing semantic loss. To tackle these, IR⁴Net integrates two key modules: (1) Physically Regularized Irradiance Approximation (PRIrr-Approximation), which embeds the radiative transfer equation into a learnable optimizer to constrain inversion trajectories; (2) Irreversibility-Constrained Semantic Re-Projection (ICSR), which restores global semantic structure via context-driven feature alignment. The model is evaluated on four datasets (ReSh-WebSight, ReSh-Password, ReSh-Chart, ReSh-Screen) and demonstrates superior performance over reconstruction-centric (Uformer, ConvIR) and generation-centric (pix2pix, CycleGAN) baselines in terms of PSNR, SSIM, and robustness to luminance attenuation and noise. Additionally, the paper introduces a new attack paradigm that leverages passive wall reflections, avoiding line-of-sight or RF monitoring."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Existing non-contact side-channel attacks rely on electromagnetic emanations (Chen et al., 2024), acoustic signals (Duan et al., 2024), or thermal traces (Zhang et al., 2024b), which are vulnerable to shielding or distance attenuation. This work is the first to propose using diffuse wall reflections as a covert channel for screen content exfiltration, enabling attacks on physically isolated, laser-shielded, or electromagnetically shielded systems—an underexplored direction in side-channel security.\n- Unlike purely data-driven reconstruction models (e.g., Uformer, Wang et al., 2022b; ConvIR, Cui et al., 2024) that ignore optical propagation physics, PRIrr-Approximation embeds the radiative transfer equation into the denoising process, mitigating perturbation amplification caused by near-singular mapping. The ICSR module further addresses semantic loss, outperforming baselines in preserving edge continuity and textural consistency (e.g., SSIM=0.817 on ReSh-Screen vs. 0.731 for ConvIR).\n- The paper conducts extensive experiments on luminance attenuation (0–300 nits), Gaussian/salt-and-pepper noise (15–45 dB), and diverse wall materials (matte, textured, contaminated), demonstrating stable performance (e.g., PSNR only drops by 25.9% at 300 nits vs. 68% for UNet). This is a significant advantage over existing reconstruction methods that degrade sharply under environmental perturbations (DarkIR, Feijoo et al., 2025)."}, "weaknesses": {"value": "- The core idea of \"physics-guided optical inversion for projection reconstruction\" overlaps with recent works on inverse rendering (e.g., Ostrek & Thies, 2024; Stable Video Portraits) and optical side-channel attacks (e.g., Fang et al., 2022). The paper fails to clearly articulate how its approach differs from these: for example, whether PRIrr-Approximation’s physics embedding is more accurate than prior physics-informed diffusion models, or how the attack paradigm is more stealthy than existing optical monitoring methods.\n- The paper omits critical recent works in optical inverse problems (e.g., 2025 CVPR papers on physics-aware diffusion inversion) and side-channel attacks (e.g., 2024 ACM CCS works on non-contact screen content extraction). This lack of contextualization undermines the novelty claim and academic rigor. Additionally, it does not compare with SOTA side-channel attack frameworks (e.g., DeepCache, Liu et al., 2024) in terms of attack success rate or stealthiness.\n- Environmental Constraints: Experiments are conducted in controlled settings (fixed screen-wall distance: 0.9m; camera distance: 2m) without testing extreme conditions (e.g., distance >5m, strong ambient light, uneven wall surfaces).\n- Computational Efficiency: The paper does not report inference latency in detail—critical for a side-channel attack that requires real-time or near-real-time reconstruction. Compared to lightweight baselines (e.g., Leffa, 1.8B params, 3.32s inference), IR⁴Net’s 904M params may still be too slow for practical attacks.\n- Attack Stealthiness: No evaluation of whether the attack can be detected (e.g., via screen brightness fluctuations, camera detection), limiting its real-world applicability.\n- The ablation study only validates PRIrr-Approximation’s replacement with neural constructs (AST, ConvIR) but not the necessity of its physics-based components (e.g., radiative transfer equation embedding).\n- The Semi-Attention mechanism’s design rationale is underdeveloped—why is \"denoising-to-all, reference-to-self\" attention optimal compared to other attention masks (e.g., cross-attention between references)?\n- ICSR’s cosine similarity loss is not compared to alternative semantic alignment losses (e.g., CLIP loss), leaving uncertainty about its superiority."}, "questions": {"value": "see Weaknesses part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dqh0b6btUA", "forum": "evepIXBxL8", "replyto": "evepIXBxL8", "signatures": ["ICLR.cc/2026/Conference/Submission17374/Reviewer_HCwF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17374/Reviewer_HCwF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17374/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762741454082, "cdate": 1762741454082, "tmdate": 1762927283125, "mdate": 1762927283125, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}