{"id": "eNjIsrbSez", "number": 12940, "cdate": 1758211863310, "mdate": 1759897475105, "content": {"title": "FeatHawkes: Scalable Feature-Based Attribution for Temporal Event Data", "abstract": "Attribution, the problem of assigning proportional responsibility for an outcome to each event in a temporal sequence of causes, is central to diverse applications ranging from marketing and seismology to sports analytics. While incorporating exogenous features substantially enhances the expressiveness of attribution models, existing approaches lack the scalability required to integrate modern machine learning methodology. We introduce FeatHawkes, a feature-augmented Hawkes process framework for event-level attribution in continuous time. Our core contribution is a novel first-order optimization routine for Hawkes processes that leverages stochastic gradient methods, scaling favorably with both dataset size and feature dimensionality. This gradient-based formulation enables compatibility with automatic differentiation and end-to-end ML pipelines. We release FeatHawkes as an open-source Python library, and demonstrate its effectiveness through synthetic experiments and a case study on professional football data, where the framework supports what-if analyses such as quantifying the impact of replacing players in a lineup.", "tldr": "", "keywords": ["Attribution", "Hawkes Process", "Methodology", "Sport Analytics"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a670c6417135cbce340cfb70ec0302c79a7feada.pdf", "supplementary_material": "/attachment/c55feffe07db3f3501a4c1cf29646bf882aa6ad0.zip"}, "replies": [{"content": {"summary": {"value": "In their submission, the authors consider Hawkes Processes to model temporal count data. Their contributions are two-fold: 1) For the special (but widely used) case of an exponential kernel they propose a way to fit model parameters through stochastic gradient descent, which seems to show similar accuracy as state-of-the-art methods at a significantly improved runtime cost. 2) The consider the case where process parameters depend on external features and demonstrate (for the special case of a logistic regression) that these can be fit to data. In their experiments, they consider two synthetic datasets and one real-world dataset related to football analytics."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The paper is clearly written and accessible.\n* The authors clearly frame research gaps and own contributions.\n* The authors clearly formalize the problem and provide a nice pedagogical introduction to the Hawkes process.\n* Addressing the fitting procedure through SGD seems like an approach worthwhile trying. The authors nicely contextualize their proposed into the existing approaches for Hawkes processes."}, "weaknesses": {"value": "* I am not convinced that the title of the paper actually captures the main contribution of the paper, which is the fitting procedure, rather than the attribution aspect. The attribution aspect receives little to no attention in the main text. Also, when introducing the Hawkes process, the authors put very little emphasis on the attribution aspect. There is a long and detailed discussion in the supplementary material, which goes into the direction of attribution, which is really interesting. But actually the main text should justify the title.\n* The authors only mention Shapley values, but they could embed their attribution approach better into the rich literature on attribution methods in the XAI community e.g. [1],[2],[3], but only if they really want to emphasize the focus on attribution methods (see previous point).\n* The authors mention causal attributions, but don't really pick up on this topic later. There is relevant literature in the XAI communinty e.g. [4],[5].\n* The experimental part could be more comprehensive: As far as I understand, the authors used two single synthetic datasets (unclear if they really generalize to other parameter values) and a real-world football dataset, which does not seem to be publicly available. To illustrate the applicability of the approach, it would be helpful to include another real dataset ideally publicly available and from another application domain (the authors list many such application domains in the introduction).\n* I find the experimental evaluation of the real-world example problematic. Unlike for the synthetic dataset, where there is a well-defined ground truth there is no such ground truth in this case. I don't think comparing parameter predictions for a simple and a more complex (feature-based) model is appropriate- in fact the simple model could be correct and the complex model could overfit to the data. It would be more appropriate to use other measures such as the approximation error etc to provide arguments why the more complex model is superior to the simple one.\n\nThe main weakness lies in the limited experimental validation and a lack of attribution insights.\n\n\n[1] Scott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. In Advances in Neural Information Processing Systems, pages 4765–4774, 2017.\n[2] Ian C Covert, Scott Lundberg, and Su-In Lee. Explaining by removing: A unified framework for model explanation. Journal of Machine Learning Research, 22(1):9477–9566, 2021.\n[3] Wojciech Samek, Grégoire Montavon, Sebastian Lapuschkin, Christopher J Anders, and Klaus-Robert Müller. Explaining deep neural networks and beyond: A review of methods and applications. Proceedings of the IEEE, 109(3):247–278, 2021.\n[4] Goyal, Y., Feder, A., Shalit, U., & Kim, B. (2019). Explaining classifiers with causal concept effect (cace). arXiv preprint arXiv:1907.07165.\n[5] Alcaraz, J. M. L., & Strodthoff, N. (2024). CausalConceptTS: Causal attributions for time series classification using high fidelity diffusion models. arXiv preprint arXiv:2405.15871."}, "questions": {"value": "* How severe is the restriction to Gaussian kernels? Are there commonly known examples where different parameterizations are used?\n* At the end of 4.1, the authors discuss a direct comparison to Shapley values for the case where the true model follows a Hawkes process, which seems to provide an advantage for the Hawkes attribution as compared to the model-agnostic Shapley. It would actually be very interesting to see such a comparison for a real-world dataset that is not strictly a Hawkes process."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vPxgwfwgIA", "forum": "eNjIsrbSez", "replyto": "eNjIsrbSez", "signatures": ["ICLR.cc/2026/Conference/Submission12940/Reviewer_hN9U"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12940/Reviewer_hN9U"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12940/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761059289626, "cdate": 1761059289626, "tmdate": 1762923702489, "mdate": 1762923702489, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an attribution method on top of Hawkes processes. The authors provide experiments with synthetic and soccer data to validate their proposed method."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. Understanding how models work is an underexplored yet critical problems, especially for high-stake decision-making applications such as sports analytics.\n2. This paper is easy to follow.\n3. This paper provides additional analyses with soccer to interpret and discuss the attribution results."}, "weaknesses": {"value": "1. While this paper presents interesting attribution applications to sports, it is an application-oriented paper that focuses on designing a method for the soccer setting and that develops an open-source library. I would recommend the authors consider submitting to data mining related conferences (e.g., KDD) given the limited nature and experiments mentioned below.\n2. It is great that the authors present other similar domains that may involve similar scenarios in the first paragraph of the introduction; however, the proposed method is only evaluated with the soccer scenario, limiting the empirical generalizability to the corresponding claims.\n3. It is insufficient with only discussing statistical-based attribution methods. This paper does not discuss and evaluate why existing attribution methods cannot tackle this task (note that the challenges in Sec. 2.4 are more related to Hawkes processes), e.g., [1, 2]. [1] is another attribution-based approach for badminton, which also tackles feature-level *predictive* attributions.\n4. It remains unclear why the authors opt for the Hawkes process, where the second challenge in Sec. 2.4 is tailored to it. Based on the aforementioned concerns, this paper lacks technical novelty even though it will be open-sourced.\n5. The synthetic experiments are too simplified and unclear about the motivation.\n6. In L437-441, the authors explain the interpretation of having stable and unstable results. However, there is no further validation that can support the corresponding claims, e.g., how could the authors verify if the high errors are really because of underperformance during for those teams. Also, how would other temporal attribution methods perform? Similarly, in L1628, the authors mention *it does not believe that Mbappé can take over Gakpo’s dynamic in Liverpool, likely due to Mbappé’s natural position being more of a central striker than an initiator like Gakpo*. If the authors could not verify and clearly explain the reason, I have reservations that this tool could really convince coaches to trust it.\n\n[1] ShuttleSHAP: A Turn-Based Feature Attribution Approach for Analyzing Forecasting Models in Badminton\n\n[2] You Mostly Walk Alone: Analyzing Feature Attribution in Trajectory Prediction\n\n[3] TimeSHAP: Explaining Recurrent Models through Sequence Perturbations"}, "questions": {"value": "Please see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Zq9r34KJN3", "forum": "eNjIsrbSez", "replyto": "eNjIsrbSez", "signatures": ["ICLR.cc/2026/Conference/Submission12940/Reviewer_hn9A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12940/Reviewer_hn9A"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12940/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761130735834, "cdate": 1761130735834, "tmdate": 1762923702035, "mdate": 1762923702035, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose FeatHawkes, an algorithm for attributing outcomes to events in a point process. The authors propose a GPU-compatible implementation of this algorithm and benchmark it on synthetic data as well as a proprietary football dataset."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Level of technical description is very high; it is easy to follow the techique and evaluation protocol from the paper and appendix.\n2. Paper is overall clearly written.\n3. The software will be available under an open source license and the code is attached to the submission. The API looks clean and simple to use."}, "weaknesses": {"value": "1. Discussion of prior work is very limited. Main comparison is vs. Ogata (1978) and Veen & Schoenberg (2008), vs. more recent work. The authors should justify this choice, but ideally expand to more recent literature.\n2. The numerical studies are very superficial. 4.1. uses a single data generating process, same for 4.2 (which on top is a proprietary dataset). The authors should use public benchmark, and rigorously compare against prior work. Right now, the work is very anecdotal.\n3. Terminology and interpretation is unclear, e.g. in Table 1. What do the different terms mean in the context of the attribution problem? This needs to be more clear from table/caption, or the referencing text.\n4. Many figures and tables and their results (Figure 3, Table 1) are hard to place into context as only FeatHawkes was run. There are not methods from the literature, or some naive baseline to compare to judge the right magnitude of the numbers."}, "questions": {"value": "1. In Figure 1, it seems like the estimation performance is very much on par with existing algorithms. Am I reading correctly that the speed gain in panel (b) is the main contribution of the work?\n2. What would be a suitable baseline in Table 1? What is the correct way to interpret the results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "4rzqg4bEHi", "forum": "eNjIsrbSez", "replyto": "eNjIsrbSez", "signatures": ["ICLR.cc/2026/Conference/Submission12940/Reviewer_XMDa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12940/Reviewer_XMDa"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12940/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761935289175, "cdate": 1761935289175, "tmdate": 1762923701640, "mdate": 1762923701640, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a method for credit attribution in time series that goes beyond last touch attribution by modeling the problem as a Hawkes process. The authors propose a specific formulation of the Hawkes process that can be computed via stochastic gradient descent, making it GPU-compatible and enabling better scalability compared to previous approaches. To validate their method, the authors benchmark it against synthetic use cases, demonstrating that it operates faster than existing approaches and scales more effectively. Finally, the authors apply their method to a real-world football dataset that they compiled.​​​​​​​​​​​​​​​​"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The authors propose a new formulation of the Hawkes process and provide an efficient algorithm to estimate it.\n* On synthetic experiments with known ground truth, they demonstrate that their method can scale to more features and achieve smaller estimation errors.\n* The authors apply their method to a real-world dataset and quantitatively show what analyses can be performed with it.\n* On real-world data, they also compare their approach with a featureless model. \n* In the appendix, they include a case study demonstrating the predictive power of credits assigned with their method.​​​​​​​​​​​​​​​​"}, "weaknesses": {"value": "* The real-world evaluation is conducted only for one sport—football—and while the authors describe that Hawkes process applications can be wide-ranging, it is not clear if the proposed formulation is suitable for other domains.\n* The authors show through a case study what information and conclusions can be drawn from knowing the parameters of the Hawkes process. However, they do not provide any quantitative assessment.\n* It is unclear how more accurate results translate to any downstream tasks, as knowing the parameters of the process might not be an end task in itself.\n* Similarly, regarding the quantitative assessment of predictive power, an aggregation of some metric over multiple datasets would be useful.​​​​​​​​​​​​​​​​"}, "questions": {"value": "* Do you know of any real-world datasets where the ground truth is known or where there are clearly defined downstream tasks?\n* Up to how many features does your method scale\n* Shapley values are well understood in terms of their axioms. Does attribution from this process follow some of these axioms, such as null player or symmetry, or perhaps others?​​​​​​​​​​​​​​​​"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "kZJOslW2WS", "forum": "eNjIsrbSez", "replyto": "eNjIsrbSez", "signatures": ["ICLR.cc/2026/Conference/Submission12940/Reviewer_ypRi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12940/Reviewer_ypRi"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12940/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761987151835, "cdate": 1761987151835, "tmdate": 1762923700523, "mdate": 1762923700523, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}