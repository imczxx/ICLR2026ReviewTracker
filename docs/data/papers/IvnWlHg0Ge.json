{"id": "IvnWlHg0Ge", "number": 15246, "cdate": 1758249282381, "mdate": 1759897318596, "content": {"title": "Disentangle, Gate, and Optimize: Cross Domain Transfer power by Multi Objective Bayesian Optimization", "abstract": "Prompt Tuning (PT) has recently shown remarkable success in diverse Natural Language Processing (NLP) tasks, providing an efficient knowledge transfer paradigm to textually instruct models with domain-level guidance.\nHowever, existing PT approaches often struggle to accurately distinguish between domain-invariant and domain-specific knowledge of input texts, thereby inducing negative transfer that harms model performances across various domains. \nTo mitigate this, recent studies have introduced the concept of adversarial training to highlight domain-specific nuances for improving the model's adaptation ability, but often rely on overly complex parameter optimization, which hinders smooth generalization.\nMotivated by this, we propose a novel prefix tuning framework, named Adaptive Robust Prefix Optimization (ARPO), in which adaptive representation disentanglement precisely decouples domain-specific information from invariant knowledge, while Multi-Objective Bayesian Optimization (MOBO) dynamically adjusts adversarial strategies for improved model robustness. \nSpecifically, we first develop disentangled representation learning based on Information Bottleneck theory with dynamic orthogonality and conditional independence constraints, combined with adaptive adversarial training driven by dynamic thresholds. \nWe then employ MOBO for efficient search within the high-dimensional strategy space. \nWe theoretically prove that the proposed MOBO approach is feasible and guaranteed to converge under reasonable assumptions.\nExtensive evaluations on GLUE, Super GLUE, MRQA 2019, GSM8K, and HumanEval show that ARPO achieves around 6% improvement in two experimental settings, highlighting its robust cross-domain generalization.", "tldr": "", "keywords": ["Prompt Tuning", "Cross Domian Transfer", "Multiple Objective Bayesian Optimization"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c17ff1f04a038d48e1839ec1bef57b126fde7497.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a method for parameter-efficient fine-tuning of pre-trained language models that enhances cross-domain robustness and training stability. The disentangled prefix tuning framework separates domain-invariant (DI) and domain-specific (DS) knowledge. The Information Bottleneck objective, dynamic adversarial training schedule, and Multi-Objective Bayesian Optimization altogether improve model robustness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Propose a principled approach to decompose prefix parameters into DI and DS components, which enables better generalization across domains by isolating shared semantics from domain-specific noise.\n- Introducing a condition-based trigger (gradient variance stability) for adversarial updates improves training dynamics. This avoids early-stage instability common in adversarial training, contributing to faster and steadier convergence.\n- The paper shows strong empirical gains and validates the effectiveness of the proposed methods."}, "weaknesses": {"value": "- MOBO and dynamic scheduling likely add computational overhead. No discussion of inference latency, parameter count, or training time efficiency limits claims about practicality. Could this become a bottleneck in large-scale applications?"}, "questions": {"value": "- While the DI:DS 5:5 performs best, is this ratio transferable across tasks/domains, or must it be re-tuned each time? Does auto-tuning via MOBO include this hyperparameter?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "k7jTHsIu8N", "forum": "IvnWlHg0Ge", "replyto": "IvnWlHg0Ge", "signatures": ["ICLR.cc/2026/Conference/Submission15246/Reviewer_y1fc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15246/Reviewer_y1fc"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15246/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761703250168, "cdate": 1761703250168, "tmdate": 1762925542817, "mdate": 1762925542817, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a training framework for prefix-tuned LLMs (ARPO) that disentangles domain-invariant and domain-specific information. It uses a gated adversarial curriculum and multi-objective Bayesian optimization to balance performance and robustness. Experiments on various NLP tasks demonstrate the effectiveness of the proposed method against baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The problem that the paper aims to tackle involves several important yet difficult pieces. For example, distinguishing between domain-specific and domain-invariant is still arguably an open problem. This paper proposes a training framework incorporating loss functions of domain-specific and domain-invariant mutual information terms. The empirical evaluation is done on numerous tasks."}, "weaknesses": {"value": "This paper has some flaws that raises concerns about the significance of the proposed method and its results. \n* First, this paper states that Prompt Tuning includes Adapters and LoRA (line 49). However, Adapters and LoRA both involve model parameter tuning and are not prompt tuning methods.\n* This paper is not well written. For example, in the first paragraph of section 3.1, $x, D, Y$ are used without being defined. \n* Although the paper includes some ablation studies such as prefix length and disentanglement constraints, the proposed method is significantly more complex. E.g.,  it has three complicated steps: the first step has 5 loss terms, the second has 3 loss terms, and the third involves multi-objective Bayesian optimization over discrete-continuous domains. I appreciate that the authors summarize the hyper parameters in table 8, and that limited sensitivity investigation is provided in table 7, but questions remain given the huge hyper parameter space: does the optimal range it hold for every tasks; is the optimal range independent from each other; how would one find the optimal range efficiently in practice?"}, "questions": {"value": "* Is it possible to show transfer for any two of the datasets? The dataset used in the experiments seems selective."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ID3BXQbvmm", "forum": "IvnWlHg0Ge", "replyto": "IvnWlHg0Ge", "signatures": ["ICLR.cc/2026/Conference/Submission15246/Reviewer_Vd6T"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15246/Reviewer_Vd6T"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15246/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762066166791, "cdate": 1762066166791, "tmdate": 1762925542232, "mdate": 1762925542232, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ARPO, a three-stage framework for cross-domain transfer: 1) Disentangle learnable prefixes into domain-invariant and domain-specific parts via information-theoretic and geometric regularizers); 2) Gate adversarial/perturbation training with a dynamic controller; 3) Optimize strategy and hyperparameters via multi-objective Bayesian optimization (MOBO). Experiments on multiple backbones and transfer pairs report consistent improvements and better robustness under distribution shift."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. Training stability: The dynamic gate reduces early-stage adversarial damage and improves convergence behavior in practice.\n2. Promising empirical signal: Gains are shown across several model families and transfer settings, with robustness benefits under perturbations."}, "weaknesses": {"value": "1. **Unclear methodological exposition.**\nThe presentation of the method is difficult to follow and lacks essential preliminaries that would help readers understand the design choices and assumptions. While the appendix supplies some details, the main text should summarize the core ideas (key variables, objectives, constraints, and training flow) without requiring readers to consult the appendix to grasp the basic mechanism.\n\n2. **Insufficient rigor in writing and notation.**\nThere are many notational and mathematical issues that hinder precise understanding. For example:\n    - Around line 150, the symbol $I$ is used without definition. \n    - In Eq.2, $\\| P_{DI}^TP_{DS} \\|$ should be $\\| P_{DI}P_{DS}^T \\|$.\n    - In Eq.7, the numerator involves $\\text{var}(\\nabla L_{\\text{task}}(t-w))$. As written, this applies a variance to a vector, yet a scalar is required in the fraction. \n    - In Algorithm 1, $d$ is overloaded to mean both domain and dimension, and $\\theta$ is used both for model parameters and for a threshold. \n    - The subscript setting for Eq.17 is incorrect.\n    There are also some other issues. I suggest the authors should check the paper carefully to correct the above and other issues.\n    \n3. **Overly complex design and heavy hyperparameterization.**\nFor the adaptation task, the method introduces a large set of hyperparameters—including $\\lambda_{1:5}, \\gamma, \\omega$, a suite of pre-designed operators—each of which typically has its own settings (e.g., token-PGD requires the number of attack steps and an adversarial budget) and so many other hyperparameters. This level of complexity raises serious concerns about practicality and deployability unless robust defaults, sensitivity analyses, and clear tuning guidance are provided.\n\n4. **Substantial computational overhead.**\nRelative to standard fine-tuning, the approach requires multiple full or partial trainings ($|X_0|+T_{BO}$ times training)for Bayesian optimization. The empirical gains reported do not yet convincingly justify this added compute. The paper should quantify wall-clock time, GPU hours, and energy usage, and compare them against the achieved improvements; otherwise, the cost-benefit trade-off remains unfavorable.\n\n5. **Missing ablations.**\nThe paper lacks systematic ablation studies isolating the contribution of each component (e.g., disentangling regularizers, gating, individual operators, and the BO layer). Such ablations are necessary to establish which parts are essential and which provide marginal benefit.\n\n6. **Limited transparency and reproducibility.**\nAlthough the appendix includes a few hyperparameter ablations, many important settings are not documented. In addition, code is not provided, preventing independent verification of the results. This raises concerns about reproducibility."}, "questions": {"value": "1. In fact, I am still confused about the transfer setting after reading Algorithm 1. For example, are all samples in $D_train$ from the same dataset? If so, why samples from the same dataset could be deviced into positive and negative sample pairs? And why is this an adversarial loss? It seems to help the model to cluster some samples. \n\n2. In Algorithm 1, is the final output part used for inference solely comprised of the trained prefix $P^*$?\n\n3. How are phrase-level and task-level operators performed?\n\n4. How are Cost and Robust in $\\textrm{f}(x)$ calculated?\n\n5. In Algorithm 1, $\\lambda_{1:5}$ are Input. How are they are optimzied with Adam according to Table 8?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7V5ZW1DEoS", "forum": "IvnWlHg0Ge", "replyto": "IvnWlHg0Ge", "signatures": ["ICLR.cc/2026/Conference/Submission15246/Reviewer_MWAq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15246/Reviewer_MWAq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15246/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762179652393, "cdate": 1762179652393, "tmdate": 1762925541761, "mdate": 1762925541761, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}