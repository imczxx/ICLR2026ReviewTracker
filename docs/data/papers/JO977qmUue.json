{"id": "JO977qmUue", "number": 22098, "cdate": 1758326007096, "mdate": 1763646773736, "content": {"title": "Regularization via Invariant Patterns: Temporal Domain Randomization for Human Activity Recognition", "abstract": "Synthetic data has become a common strategy to address data scarcity in Human Activity Recognition (HAR). However, models trained on synthetic samples often overfit to spurious features, leading to a substantial domain gap when transferred to real-world data. To address this challenge, we propose Regularization via Invariant Patterns (RIP), a novel data-centric method that extends the idea of domain randomization to the temporal domain. RIP augments time-series windows by \"framing\" them with invariant (constant-valued) patterns, compelling models to focus on informative signals rather than irrelevant temporal context.\nEvaluated across five HAR datasets, four classifiers, and more than 2,000 experiments, RIP consistently improves F1 scores, achieving gains of up to +53 percentage points (over +160\\% relative improvement) compared to synthetic baselines — often matching or surpassing real-data baselines. Beyond synthetic scenarios, RIP also boosts performance in real-only training settings, highlighting its broad applicability. Both theoretical analysis and empirical results show that RIP stabilizes weight updates and enhances calibration, all without modifying model architectures.", "tldr": "", "keywords": ["HAR", "Sythetic data", "Regularization"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/52a98424fef40c0d22892c622507f8e253949d6e.pdf", "supplementary_material": "/attachment/758f564c2572bb1cc39372bb827925356ed2580c.pdf"}, "replies": [{"content": {"summary": {"value": "This paper proposes a regularization method (RIP) that augments each time-series sample by framing it with constant-valued segments. The goal is to reduce reliance on spurious temporal context, particularly in synthetic data settings. RIP is architecture-agnostic and improves generalization in both synthetic-to-real (TSTR) and real-only (TRTR) setups. Evaluation across five HAR datasets and multiple models shows consistent gains in F1 and calibration."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Addresses an underexplored and practical problem: generalization from GAN-generated HAR data.  \n- The method is simple, lightweight, and broadly applicable.  \n- Experiments are extensive, covering multiple datasets and models with consistent improvement.  \n- Calibration and stability analyses complement accuracy results.  \n- The approach requires minimal tuning and introduces no architectural complexity."}, "weaknesses": {"value": "1. **Terminology clarity**  \n   `S`, `R`, `TRTR`, Duplication factor `i` and constant value `γ` appear early (e.g., line 62) without explanation. These should be briefly defined when first introduced.\n\n2. **Related Work is incomplete**  \n   The paper omits relevant work in all three subsections. For example:  \n   - Domain randomization in time-series: *PhASER* (Mohapatra et al., ICLR 2025), Cutout (Yang et al., ESWA 2022)  \n   - Regularization for HAR: *TS-TCC* (Eldele et al., IJCAI 2021), *AdvMask* (Yang et al.), *DynamicMixup* (Guo et al., EEE Transactions on Multimedia 2023)  \n   - Domain generalization: *AFFAR* (Qin et al., ACM TIST 2022), *DDLearn* (Qin et al., KDD 2023), *MixStyle* for wearable HAR (Napoli et al., ESANN 2025), *SynthAct* (Schneider et al., ICRA 2024)\n   These should be cited to contextualize the contribution.\n\n3. **Algorithm design and justification**  \n   Algorithm 1 may be redundant given the detailed text. The `γ` and `i` choices are limited and appear heuristic; it is unclear whether the theoretical claims generalize beyond these settings.\n\n4. **RIP–GAN separation**  \n   RIP does not rely on synthetic data, yet the paper is structured as if its utility is specific to TSTR. The weaknesses of TLCGAN data (e.g., unstable transitions or spurious context) should be explicitly discussed.\n\n5. **Framing effect and data scaling**  \n   Adding `2i` constant windows increases input length substantially. It is unclear whether this effectively increases the training set size or acts as implicit duplication. This may partially explain the observed gains and should be clarified.\n\n6. **Model selection**  \n   The models used (DClassifier, TS-Classifier, TSBF, TSRF) are not SOTA. While they cover a spectrum of architectures, modern high-performing models such as InceptionTime or Transformer-based HAR models are not included. This limits claims about general performance. Future comparisons with stronger baselines are encouraged.\n\n7. **Baselines and fairness**  \n   Mixup, Cutmix, and DRO underperform in Table 4. These methods are not designed for low-fidelity synthetic data. Their inclusion requires justification.  \n   For ℓ₁ and ℓ₂ (Table 3), regularization strength selection is not explained. In some cases (e.g., WISDM), these degrade performance severely, which weakens the comparison.  \n   TS-Classifier is relatively weak; it is unclear whether RIP’s gains generalize to stronger models.\n\n8. **Figures and formatting**  \n   Table 1 and Table 2 captions are inconsistent; only the first specifies TSTR. Both appear to exceed text width.  \n   Figure 2 caption mislabels line colors as models, though they represent `γ` values. Section headings should use consistent phrasing (“Robustness and fairness”).\n\n9. **Reproducibility and compute**  \n    CPU/GPU details are missing from the runtime section, limiting interpretability. “Due to space limitation” (line 336) is mentioned, but the main text does not use the full page limit.\n\n10. **Novelty**  \nThe framing concept is intuitive and related to prior masking or context dropout techniques, but its application to synthetic HAR is novel. The contribution is incremental methodologically but solid in empirical utility."}, "questions": {"value": "- Could you clarify how the duplication factor i and constant value γ were selected? Were they tuned per dataset, and do the theoretical claims (e.g., variance reduction) hold under other values?\n\n- RIP appears applicable to real data as well. Could you explain more concretely what properties of the TLCGAN-generated samples make RIP particularly helpful in the synthetic setting?\n\n- Does the framing effect introduced by RIP increase the number of training tokens seen by the model? If so, how do you control for the effect of sequence length versus regularization?\n\n- For Table 3, were the ε values for ℓ₁ and ℓ₂ regularization selected via tuning, or fixed across datasets? WISDM results drop significantly—how should we interpret this?\n\n- Have you considered applying RIP to more recent time-series architectures such as InceptionTime or TST?\n\nFor all questions, please refer to the Weakness part"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZdqGYHMUAQ", "forum": "JO977qmUue", "replyto": "JO977qmUue", "signatures": ["ICLR.cc/2026/Conference/Submission22098/Reviewer_7CbN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22098/Reviewer_7CbN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22098/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761540275801, "cdate": 1761540275801, "tmdate": 1762942065051, "mdate": 1762942065051, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response to Reviewers’ Comments"}, "comment": {"value": "Dear Reviewers,\n\nWe want to express our sincere gratitude for the time and care you dedicated to evaluating our submission. We were encouraged by the strengths you highlighted in our study, namely:\n\n* Addresses a critical gap. The paper addresses the well-known synthetic-to-real mismatch in HAR, a core, unresolved limitation in current time-series models.\n\n*  Simple and novel idea. RIP introduces a new architecture-agnostic form of temporal-domain randomization that is easy to implement and broadly applicable.\n\n* Strong and consistent results. Evaluated on five HAR datasets and four classifiers (2,000+ runs), RIP delivers robust and repeatable improvements in both TSTR and TRTR settings.\n\n*  Clear evidence for why it works. Theoretical and empirical analyses show that RIP reduces hidden-state variance and stabilizes optimization, providing solid justification for the observed gains.\n\n*  A broader set of ablation studies on key model components, as well as experiments exploring applications beyond time-series HAR scenarios.\n\nWe appreciate the constructive feedback you provided. Therefore, we prepared a comprehensive response document that addresses each comment from each reviewer individually and in detail. We also prioritized the most critical issues across reviews to ensure that the revised manuscript directly resolves the core concerns raised. The complete point-by-point responses are available at the link  https://anonymous.4open.science/r/RIP-5180/_2025__Rebutal_ICLR%20(1).pdf .\n\nBeyond addressing individual comments, we have also substantially revised the manuscript itself. Specifically, we:\n\n   * Improved overall clarity, coherence, and textual organization;\n   * Updated and aligned figures, tables, captions, and legends, correcting inconsistencies;\n   * Added an additional evaluation protocol (LOSO);\n   * Included new mathematical analyses, covering:\n\n        * The structure of Transformer-based models for time series,\n        * The effect of the duplication factor in RIP,\n        * The behavior of RNNs with nonlinear activation functions under RIP;\n\n  * Added Transformer-based classification baselines to strengthen empirical comparisons;\n  * Introduced a new illustrative figure to make the RIP mechanism clearer;\n  * Moved the pseudocode to  the appendices and expanded implementation details;\n  * Included further discussion regarding computational cost, dataset domain randomization challenges, and the role of the hyperparameters ;\n  * Updated the related works list to reflect recent works in time-series activity recognition;\n  * Conducted additional dataset-focused analyses, including:\n\n       * Axis-wise effects of RIP,\n       * Dataset size and temporal-window statistics,\n       * The impact of RIP on data distribution;\n    \n  * Included details about datasets (window length size);\n  * Included a discussion about \"why RIP is more noticeable under synthetic data\";    \n  * Integrated results from Optuna-based optimization, clarifying how the search improved the stability and viability of the method;\n  * added parameter-sensitivity studies suggested by the reviewers.\n\n\nWe remain attentive to further improving the paper. If additional clarifications or adjustments are needed, we are ready to incorporate them.\n\nWe appreciate the opportunity to revise our work and hope the changes clearly demonstrate the improvements and the study's strengthened contribution.\n\nSincerely,\n\n\nThe Authors"}}, "id": "tEgoDyEQgO", "forum": "JO977qmUue", "replyto": "JO977qmUue", "signatures": ["ICLR.cc/2026/Conference/Submission22098/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22098/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22098/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763640294139, "cdate": 1763640294139, "tmdate": 1763640294139, "mdate": 1763640294139, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors aim to improve the model performance when trained on synthetic data in the domain of human activity recognition. Specifically, the authors design a Regularization via Inviriatn Patterns, a data-centric method to force the model to focus on informative signals rather than irrelevant context. For evaluation, the authors utilize multiple real world dataset for human activity recognition. Results highlight the advantages of this method with a significant performance gain. Overall, the topic of this paper is interesting, some concerns, however, limit the contribution of this paper."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "[1] The topic is interesting. Werable device based human activity recognition is a promising direction, and synthetic data for model training is also interesting. \n\n[2] The future work is briefly discussed and could benefit future research. \n\n[3] The experiments are conducted on 5 real-world datasets."}, "weaknesses": {"value": "[1] It is not sure what is the technical challenge to adapt the domain randomniation to the temporal domain. \n\n[2] Since this paper addresses the problems in activity recognition, but there are no most recent activity recognition papers discussed or compared in the experiment. This could be an issue. \n\n\n[3] In Figure 2, “each color denotes a model” might be each bar denotes a model? If the x-axis is correctly labeled. \n\n[4] The writing and presentation could be further improved. For example, I could not find the experimental results for boosting performance in real-only training settings, which is indicated in the abstract. \n\n[5] Detailed information about the dataset used is missing. For example, since this is a classification problem, how many classes exist in each dataset should be introduced. Also, the sampling rate, window size are also missing. \n\n[6] In line 101, it is not clear what does it mean “constant windows frame the original window”. \n\n[7] How to construct the augmented dataset is not clear. After reading section 2, it is still not quite clear. Is it via concatenating the constant and the original sensor data? \n\n[8] COuld you also discuss the limitations or challenges of the propose method?"}, "questions": {"value": "Questions are provided on weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jczlv11pVr", "forum": "JO977qmUue", "replyto": "JO977qmUue", "signatures": ["ICLR.cc/2026/Conference/Submission22098/Reviewer_5Kg5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22098/Reviewer_5Kg5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22098/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761779362524, "cdate": 1761779362524, "tmdate": 1762942064560, "mdate": 1762942064560, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Regularization via Invariant Patterns (RIP), a data-centric method that extends the idea of domain randomization to the temporal domain. RIP augments time-series windows by ”framing” them with invariant (constant-valued) patterns, compelling models\nto focus on informative signals."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. This paper is well organized.\n2. The overall logic is clear."}, "weaknesses": {"value": "1.\tThe paper claims that RIP can alleviate the synthetic-to-real domain gap, but all experiments are limited to the \"train synthetic → test real\" or \"train real → test real\" mode, and do not include cross-subject, cross-device, or cross-dataset tests. To demonstrate that RIP truly promotes domain generalization, these more challenging cross-domain experiments should be included.\n2.\tThe authors compare RIP with methods such as ℓ₁/ℓ₂, Mixup, Cutmix, and DRO, but these methods typically operate at the sample or feature level, rather than the temporal dimension. The authors should also compare RIP with temporal masking methods that are more structurally similar to it. Furthermore, the paper does not specify whether all baselines were retuned or used default settings, which may affect fairness.\n3.\tThe experimental tables were not formatted consistently, especially Tables 1 and 2, which were misaligned.\n4.\tThe authors derive the effect of RIP on the hidden state variance using a simplified linear RNN model (φ(x)=x). This analysis neglects the effects of nonlinear activation functions and common structures such as batch normalization and attention. Since RIP is mainly applied to deep models (ConvLSTM, Transformer-based), the variance constraint conclusions derived only for linear RNNs are difficult to generalize. It is recommended to supplement the influence of nonlinear terms."}, "questions": {"value": "1. In the theoretical section, the authors state that RIP “drives weights toward greater uniformity”, citing the Kolmogorov–Smirnov statistic as evidence. However, uniformly distributed weights do not necessarily represent better generalization or stability, and the paper lacks discussion on the causal relationship between this metric and generalization performance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "none"}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "STNUwdAwlI", "forum": "JO977qmUue", "replyto": "JO977qmUue", "signatures": ["ICLR.cc/2026/Conference/Submission22098/Reviewer_h5KR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22098/Reviewer_h5KR"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22098/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761780063641, "cdate": 1761780063641, "tmdate": 1762942063864, "mdate": 1762942063864, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a new data augmentation technique for regularising time-series models for human activity recognition. The inspiration of this method is taken from image-based data background randomization methods. In summary, the method simply adds an invariant pattern (e.g., a matrix of 1s or 2s ...) earlier and later to the original data. The performance has been shown to be better compared to using their method and with other data augmentation techniques. Extensive experiments and analysis have been done. Some limitations of the paper appear to be incremental novelty and clarity of presentation, and under description of the method."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The results in the paper show that their method of regularization via invariant patterns as a data augmentation improves the performance of time-series models by a large margin. \n\nThe paper presents extensive experiments and validation of their approach and comprehensively analyzes various scenarios, including checking the validity of invariant patterns and simple duplications in input patterns."}, "weaknesses": {"value": "The method is less clearly explained. Figure 1 is a simple illustration of the paper, prepended and appended to a time-series data matrix. The explanation of how this pattern is prepended and appended to the original timeseries should be shown in Fig. 1 or in a separate figure.  Algorithm 1 reads redundant. Better to explain the method properly on Page 2. Hard to locate where the Tables are referred to in the paper. Paper writing/presentation needs improvement. The hyperparameter setting information in the main paper is below very minimal. The hyperparameter settings for the algorithms should be mentioned in the main paper rather than pushed into an excessively large appendix."}, "questions": {"value": "What is SRIP(L) in Figures 3 and 4?\nDifferent parameter values for RIP have been used across datasets. How can one know how to set these values? These appear to be experimentally found values? Confirm.\n\nOn some datasets, such as MHEALTH RIP, they do not perform significantly better than L or L2 regularisation, but for some, they perform excessively well. Please explain.\n\nThe results presented in the paper all appear to have been executed by the authors themselves. Are there any comparisons with state-of-the-art results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "S0uuICSDBE", "forum": "JO977qmUue", "replyto": "JO977qmUue", "signatures": ["ICLR.cc/2026/Conference/Submission22098/Reviewer_H4k2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22098/Reviewer_H4k2"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22098/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761912988738, "cdate": 1761912988738, "tmdate": 1762942063595, "mdate": 1762942063595, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}