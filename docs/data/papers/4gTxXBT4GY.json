{"id": "4gTxXBT4GY", "number": 8856, "cdate": 1758100014027, "mdate": 1763668476488, "content": {"title": "Neurosymbolic Language Reasoning as Satisfiability Modulo Theory", "abstract": "Natural language (NL) contains extensive logical structure, finely meshed with ''gestalt'' content best interpreted statistically. LLMs are indispensable for interpreting the gestalt content but known to perform unreliably on logic. We characterize this logical reasoning gap for traditional ``compositional'' tasks, but also for less appreciated \"combinatorial'' tasks, that arise in natural text understanding. To close the gap, we introduce a neurosymbolic language called Logitext that allows the logical structure of text to be elaborated explicitly in formal notation. Logitext is represented internally by a novel form of natural language constraints. We show how to solve these constraints using an algorithm that combines ideas from textual gradient descent and Boolean Satisfiability (SAT) solving. The algorithm serves as a theory that extends a traditional Satisfiability Modulo Theory (SMT) solver, enabling fine-grained joint logical and NL-based reasoning. Our measurements show significant benefit from this joint reasoning toward addressing the reasoning gaps above.", "tldr": "A way to unify statistical and logical language understanding via a SMT theory of natural language text constraints.", "keywords": ["neurosymbolic", "SMT", "logic", "reasoning"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7a9371a0cc61f4218698e62027b93e4da87894c3.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper describes an approach to the logical annotation of unstructured text documents that allows the definition of logical constraints in natural language in the context of a semi-structured prompt to a hybrid LLM/SMT solver. This allows the document to be translated into an SMT theory, formed by combining LLM valuations for atomic propositions within the constraints with auto-formalization of complex statements in the document, for which a solver then finds a satisfying assignment or determines the theory is unsatisfiable."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "An effective and innovative approach to logical reasoning with LLMs that uses an SMT solver as cognitive scaffolding. This is an improvement over previous approaches which depend on autoformalization into logical statements followed by independent execution of a solver over the generated theory. The deeper integration of the LLM into the core of a hybrid reasoning engine is an important direction to pursue, because it begins to address how best to exploit the complementary strengths of formal reasoners and the approximate retrieval of LLM parametric knowledge for reasoning. The presentation is clear and for this reviewer informative and thought-provoking, the description of the formalization for natural language text constraints and the NLSolver were thorough easy to follow. The author(s) effectively make the case that using an LLM to ground atomic statements in the context of a solver is a viable, practical approach to reasoning in neurosymbolic systems that addresses some of the shortcomings of current approaches."}, "weaknesses": {"value": "The paper extends SMT with a theory for textual constraints, but does not discuss formal soundness or completeness guarantees. What are the conditions under which the NLSolver is guaranteed to find a solution if one exists? The paper would benefit from a more rigorous theoretical treatment of these questions.\n\nThe paper doesn't adequately address how it ensures factuality of LLM evaluations when these serve as atomic propositions in the logical theory. What happens when the LLM misclassifies a natural language constraint? The LLMVerify function is treated as an oracle, but in practice, LLMs can be inconsistent or incorrect. The paper would benefit from error analysis on how LLM evaluation errors propagate through the logical reasoning process and what safeguards exist to detect or mitigate such errors."}, "questions": {"value": "Have the authors investigated the usability of the Logitext language from a human factors perspective? What is the learning curve for non-experts to write effective annotations? How error-prone is the annotation process? Understanding the practical challenges of getting users to correctly annotate documents is crucial for real-world deployment.\n\nHow does the system handle ambiguous natural language that could have multiple valid autoformalizations? Does it maintain multiple hypotheses or commit to a single interpretation? This is particularly important for legal and policy documents where ambiguity may be intentional or unavoidable.\n\nCan the authors provide any formal guarantees about their system? For example, under what conditions is the NLSolver guaranteed to be sound, never returning an incorrect solution? Even partial guarantees would strengthen the theoretical contribution."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "bU5IcSiqNz", "forum": "4gTxXBT4GY", "replyto": "4gTxXBT4GY", "signatures": ["ICLR.cc/2026/Conference/Submission8856/Reviewer_WyQz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8856/Reviewer_WyQz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8856/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761060757781, "cdate": 1761060757781, "tmdate": 1762920621212, "mdate": 1762920621212, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Responses to issues of concern to multiple reviewers"}, "comment": {"value": "We thank the reviewers for their comments. We summarize our responses to the main issues here and provide further details to individual reviewers.\n\n## Issue S1: Overhead of hand annotation\nThe reviewers point out that the additional labor of hand-annotation of documents may make Logitext burdensome, impractical or not scalable.\n\nIt is true that for consumer usage (e.g., in ChatGPT), annotating prompts is impractical. In many production scenarios however, prompts are part of deployed programs and undergo extensive \"prompt engineering\" to maximize accuracy before deployment. We believe that Logitext-style annotations may be a natural tool in this phase. In our experience, adding annotations to even multi-page prompts (e.g., those in the CMOD dataset) may take an hour or so, and can address opportunities that simple textual rephrasing cannot.\n\nWe will clarify this focus in our paper.\n\nMore broadly, we have ongoing work in auto-annotation. Here we view Logitext as a \"target language\" where the use of logical solvers as tools for a production prompt can be made explicit and communicated to humans before deployment. So defining a concrete syntax and semantics for the Logitext language, as in this paper, is still valuable even if annotation is automated.\n\n\n## Issue S2: Fragility to clause-level errors\nThe reviewers point out that although Logitext may remove errors due to mis-evaluation of logical operations **between** clauses, it introduces new sources of errors via errors in LLM evaluation of **the clauses themselves**.\n\nThis is a critical point: we agree it is not clear, **a priori**, that replacing a single call to an LLM with N separate calls that are combined deterministically will yield higher accuracy. E.g., consider a clause C0 which is true 100% of the time by ground truth. Say a single \"holistic\" LLM call returns true 90% of the time. Say the clause is a conjunct of two subclauses C1 and C2, each of which the LLM separately and independently evaluates to true 90% of the time. Then we would expect Logitext's accurately to be (0.9)^2 = 81%. Given that real documents may contains tens of relevant clauses, accuracy may plunge. \n\nIt is our **empirical** observation that for many natural documents, commonly annotated structures have characteristics favorable for compositional reasoning. To get an idea why, we now include an analysis in Appendix A.4 of the \"disruptive behavior\" policy of Figure 2. To summarize, for \"successful\" document/input combinations (the majority in our dataset), we observe:\n1. Most subclauses (perhaps because they are simpler) have much higher accuracy rates on most inputs than the parent clause.\n2. Subclause misclassifications are not independent: many (successfully classified) inputs tend to have most sub-clauses correctly classified. Many inputs are \"obvious\".\n3. Misclassified clauses may be \"shadowed\" by others so their errors don't count. In the above example, if clause C0 were **false** 100% of the time, then even if C1 or C2 were mistakenly true, it would suffice if the other were false. The more subclauses, the greater the shadowing effect.\n4. Finally, Logitext is complementary to prompt rewriting. Subclauses that are exposed as consistently wrong can be re-written before deployment, a targeted version of traditional prompt engineering. In this submission, we have not done so.\n\nFor all these reasons, noise in evaluating subclauses (which we agree is prevalent) is not necessarily catastrophic for Logitext.\n\n## Issue S3: Section 3 is hard to understand\nThe reviewers especially called out the density of symbols/notation, the fact that Algorithms Check() and NLSolver() were presented in the main text but not explained in full detail, definitions for various prompts used in the algorithms were missing.\n\nWe have completely rewritten Section 3 to:\n1. Reduce the number and complexity of symbols in the text,\n2. Move the full definitions of Algorithms XX and YY to the appendix and focus in far more detail on their key components in the main text, and\n3. Share the full prompts used in the appendix, along with a brief description of them in the main paper."}}, "id": "H1fnCnbncZ", "forum": "4gTxXBT4GY", "replyto": "4gTxXBT4GY", "signatures": ["ICLR.cc/2026/Conference/Submission8856/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8856/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8856/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763667693504, "cdate": 1763667693504, "tmdate": 1763667693504, "mdate": 1763667693504, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Logitext, a neuro-symbolic language that bridges the gap between natural language and formal language. Logitext is represented as natural language text constraints, which streamlines a logical structure of the natural language text. Furthermore, authors extend an SMT solver and propose a NLSolver using an LLM to solve natural language text constraints. The proposed method is evaluated on 15 tasks and yield impressive performance on three types of settings, supporting the effectiveness of the method."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper newly introduces a language called Logitext to fully represent the logical structure behind the natural language text. This is a very important problem in legal, political, and societal domain.\n2. The performance is impressive. Logitext performs much better than few-shot prompting and the previous neurosymbolic approach on various benchmarks."}, "weaknesses": {"value": "The presentation should be further improved for clarifications.\n\n### Major points\n- There are lots of words \"solver\", but I'm confused which solver do you exactly mean. I think you'd better come up with a clearer notation. There are lots of related words (e.g., solver, logical solver, SMT solver, LLM-based solver, symbolic solver), but for people who read this paper for the first time, it's really hard to get which \"solver\" do you mean in the paper throughout.\n- For Logitext, what if an implicit premise is hidden in the text, so that you can't capture the entire underlying logical structure of the text by simply annotating it?\n- The description of algorithm (Section 3.3) could be further improved. Now, there are too many variables only defined in Figure 4, not in the main paper, which hinders to fully understand the details.\n- For the new benchmark CMOD, what is the source of these moderation policies? I cannot find it in anywhere.\n- Line 367: 10+ instances per task seems so small. Elaborate the dataset size for each task.\n- Line 425-426: Authors should elaborate how this neurosymbolic prompt looks like. If it is something from a previous work, then authors should cite that work.\n\n### Minor points\n- In Figure 2 (b), authors should mention that the definition of combinatorial gap is in Appendix A.1. Readers would be confused.\n- Which solver did you use in Section 2.2? Did you use NLSolver or an SMT solver?\n- In Figure 3, why is there C8? for defining disruptive behavior and immediate threat, you even do not use C8, and as the definition of C6 shows, i guess C8 is equivalent to C6.\n- Line 213, if I understand correctly, the first `<var>` and the second `<var>` point two different ones. for clarification, you should indicate those as `<var1>` and `<var2>` instead. Also, what do `<var>`, `<clause>`, and `<phrase>` exactly mean? Authors should elaborate this right after they describe the whole new notations.\n- Line 217, authors should cite related papers for `pyz3`.\n- Line 253-254, authors should describe how u_i is related to c_jh and what do p_i's mean here. I could understand from the context, but to formally define Logitext, authors should consider this. Also, why does this formalization re-occur here? I think it's already briefly describe in 3.1 Clause naming.\n- Line 263, the notation l_jh suddenly appears. what does it mean?\n- Line 268: in the previous paragraph, NLTC was notated as v_jh but here it is notated as v_i where 1<=i<=n. Could authors clarify this point?\n- Line 412: Text is overlapped by Figure 8."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VWlDoJluRv", "forum": "4gTxXBT4GY", "replyto": "4gTxXBT4GY", "signatures": ["ICLR.cc/2026/Conference/Submission8856/Reviewer_AF7g"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8856/Reviewer_AF7g"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8856/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761096124915, "cdate": 1761096124915, "tmdate": 1762920620702, "mdate": 1762920620702, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce Logitext - which is a neurosymbolic language to extend NLTCs to SMT solvers. They identify \"compositional\" and \"combinatorial\" reasoning gaps in LLMs when dealing with certain types of documents. In these cases, Logitext lets you formalize part of the document (the \"logic\") - and then uses an iterative solver with Z3 for logical and an NLSolver for textual constraints.\n\nHowever, this method feels quite contrived, and I don't see any applicability of this beyond some carefully curated examples that require a lot of manual annotation anyways. The complexity of the Logitext systems appears to not be proportionate to the demonstrated gains."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper does address a real problem wrt LLMs struggling with logical consistency in policy documents.\n2. The paper is clearly motivated through empirics on reasoning gaps.\n3. To my knowledge, this mixture of SMT solvers with NL constraints is novel."}, "weaknesses": {"value": "1. The Logitext system seems quite contrived and requires significant manual effort to convert natural docs.\n2. Manual annotation of the logical structure defeats the purpose of scalable automated reasoning. Therefore real usage of this is highly questionable.\n3. The convergence of the NLSolver is not guaranteed and the caching employed seems quite ad-hoc.\n4. Some of the proposed baselines appear weak and raise concerns about high quality evals."}, "questions": {"value": "1. How does the cost of annotation simply compare to using better prompting strategies?\n2. How sensitive is the performance to annotation quality and completeness.\n3. What happens (as is likely) when logical structures in the document are incomplete or vague?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "A2clEBydLH", "forum": "4gTxXBT4GY", "replyto": "4gTxXBT4GY", "signatures": ["ICLR.cc/2026/Conference/Submission8856/Reviewer_EsVD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8856/Reviewer_EsVD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8856/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761802313238, "cdate": 1761802313238, "tmdate": 1762920619035, "mdate": 1762920619035, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces LogiText, a neurosymbolic language which supports partial formalization, and a novel SMT (Satisfiability Modulo Theory) solving framework. This approach aims to bridge the \"compositional\" and, most notably, the \"combinatorial\" reasoning gaps that persist in LLMs by coupling an SMT's Boolean search with an iterative LLM-driven \"generate-validate-refine\" loop."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper proposes a neurosymbolic language, LogiText. LogiText does not require converting the entire document into strict logical formulas; instead, it allows for explicitly annotating only the key logical structures (e.g., Boolean relations) while retaining ambiguous textual clauses as natural language. This design bridges the gap between traditional symbolic solvers (which require fully formalizable domains) and real-world complex documents (which are essentially a mix of text and logic), greatly enhancing the practical value of neurosymbolic methods in domains like legal analysis and content moderation (CMOD).\n\n2. The authors propose a neurosymbolic framework for reasoning with semi-structured language that positions the LLM as an SMT theory solver. Specifically, the SMT symbolic algorithm is responsible for efficient Boolean structure search, and the LLM-driven NLSolver then generates assignments that satisfy logical and semantic constraints by iteratively calling LLM sampling, validation, and refinement operations.\n\n3.  Experimental results demonstrate that on the text instance generation (TIG) and text Coverage Generation (TCG) tasks, the performance of the LogiText-based formalization and the LLM-driven SMT neurosymbolic solving algorithm significantly outperforms that of end-to-end LLMs."}, "weaknesses": {"value": "1. The framework's reliance on precise clause-level annotation and evaluation is a critical vulnerability. LogiText relies on human experts to manually annotate natural language documents. This not only incurs high labor costs but also limits the method's scalability and application scope. Furthermore, the framework is fragile to \"clause-level\" errors. It still relies on the precise evaluation of each clause, and a failure in evaluating one clause can cause the entire logical chain to collapse. As results on LegalBench (Figure 8) show, a textual judgment error by the LLM on any single clause can lead to reasoning failure. In contrast, the \"holistic reasoning\" of end-to-end LLMs sometimes exhibits stronger reasoning capabilities. Especially in real, complex scenarios, the partitioning of clauses and the formalization of their logical relationships remain a significant challenge.\n\n2. In the NLSolver algorithm, although the authors introduce a caching mechanism to reduce the number of LLM calls, the cost of LLM calls in the \"generate-validate-refine\" framework (an iterative refinement process) is still a non-negligible issue. Admittedly, we believe that proposing a low-cost and efficient solving method remains a challenge in this type of search-based neurosymbolic framework. To better assess the practical viability of this framework, we ask the authors to report the average (and maximum) number of LLM calls required by NLSolver to solve each task in the experimental evaluation.\n\n3. Section 3 is hard to follow, partly because the complex notation. Please improve the presentation quality of this part.  \n\n(Formatting Issue) Line 412 is incomplete."}, "questions": {"value": "1. The paper states that the benchmarks consist of 15 tasks with \"10+ instances each\". This seems like a very small scale for evaluation. Could the authors elaborate on the size of the test sets? How can you be confident in the generalizability of the results?\n\n2. The paper mentions using the set of unsatisfied constraints to guide the refinement (Algorithm 1b, line 24). This is a key mechanism. Could the authors provide a concrete example of this refinement prompt? How is the LLM instructed to 'fix' the previously generated text based on which specific natural language constraints failed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "kkCN0tIQEd", "forum": "4gTxXBT4GY", "replyto": "4gTxXBT4GY", "signatures": ["ICLR.cc/2026/Conference/Submission8856/Reviewer_qLbD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8856/Reviewer_qLbD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8856/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761903318115, "cdate": 1761903318115, "tmdate": 1762920618653, "mdate": 1762920618653, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}