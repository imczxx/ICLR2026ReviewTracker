{"id": "m276fke38H", "number": 20641, "cdate": 1758308525856, "mdate": 1759896966301, "content": {"title": "In Good GRACES: Principled Teacher Selection for Knowledge Distillation", "abstract": "Knowledge distillation is an efficient strategy to use data generated by large teacher language models to train smaller “capable” student models, but selecting the optimal teacher for a specific student-task combination requires expensive trial-and-error. We propose a lightweight score called GRACE to quantify how effective a teacher will be when post-training a student model to solve math problems. GRACE efficiently measures distributional properties of student gradients, and it can be computed without access to a verifier, teacher logits, teacher internals, or test data. From an information-theoretic perspective, GRACE measures leave-one-out stability in gradient-based algorithms, directly connecting it to the generalization performance of distilled student models. On GSM8K and MATH, GRACE correlates strongly (up to 86%) with the performance of the distilled Llama and OLMo students. In particular, training on GRACE-selected teacher provides at least a 6% improvement over naively using the best-performing teacher. We further demonstrate the utility of GRACE in providing guidance on crucial design choices in distillation, including (1) the best temperature to use when generating from the teacher, (2) the best teacher to use given a size constraint, and (3) the best teacher to use within a specific model family. Altogether, our findings demonstrate that GRACE can efficiently and effectively identify the most compatible teacher for a given student and provide fine-grained guidance on how to perform distillation.", "tldr": "GRACE is a gradient-based score that efficiently predicts the best teacher for knowledge distillation, without requiring teacher internals or test data", "keywords": ["Knowledge distillation", "Directional coverage", "Gradient variance", "Cross Validation", "Best Teacher prediction"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/55e5c5fdc3ac8723d42091190baaf7928670ac37.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a metric for evaluating teacher LLMs for synthetic data generation, for training student models. They propose a per-sample student-model gradient based metric GRACE for evaluating the teacher models. The proposed metric is well correlated with student model performance, and often currently identifies the best/ideal teacher for training the student. The metric is evaluated across a range of teacher model families, and multiple student models and datasets."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 4}, "strengths": {"value": "1. The proposed metric is well motivated, and reasonably extends G-Vendi, and is easy to compute cheaply.\n1. The proposed method achieves good predictive correlation and succesffully predicts the best teacher model across multiple datasets and student models.\n1. The proposed method correctly identifies/predicts generation temperature across different teacher model sizes, unlike some prior baselines which monotonically increase with temperature.\n\nWith synthetic LLM-generated data and seqKD being used ever more often, this paper explores a useful direction."}, "weaknesses": {"value": "1. Most of the experiments in the paper (except figure 11) use temperature 1. Most llms however are typically used a much lower temperatures. The performance correlation of GRACE drops sharply for greedy sampling, which implies the method is indeed affected by temperature. This significantly weakens the impact of most of the analysis/experiments in this paper.\n1. The proposed method uses an ad-hoc gradient scaling of $1/log(L)$, motivated by a decrease in gradient norm with increasing sequence length, and the authors show the proposed scaling fitting their dataset. But Xia et al 2024 (which the authors refer to) shows in Figure 3 that this gradient shape varies somewhat across datasets, and is difficult to model. In my own experiments, modelling token gradients correlated random variables along the sequence gives good fits ($1/sqrt(L)$) at predicting grad norm, and in some other domains, losses from longer sequences are sometimes normalized with $1/L$. It is not immidiately obvious why this particular proposed gradient scaling would be ideal. This same scaling seems to have also been used for the baselines.\n1. While the paper presents a very detailed analysis and results, the paper layout is somewhat confusing. The appendix in particular seems not well laid-out."}, "questions": {"value": "1. Regarding Figure 21, does this show the gradient norms for gsm or for math? How does the gradient norm distribution vary across the two datasets?\n1. Did the authors try other fits for the gradient norm, for example power law $G = A + B*L^C$ ?\n1. How sensitive is the performance of the GRACE metric to the choice of this gradient norm scaling? Do other scalings significantly affect the correlation/best teacher selection?\n1. G-vendi seems to perform very well and similar to the author's method (Figure 13), except for the Qwen family. Do the authors have any conjecture as to why that may be?\n1. Line 878 says \"we use d=1024\". Are these the results in Figure 8?\n1. Does \"GradCV\" in Figure22/23 refer to GRACE?\n1. The proposed method will penalize gradient variance - eg if a teacher were to generate \"diverse\" generations in some sense. In multi-task settings, or mixture of datasets (as is common in llm finetuning), will this penalty be counterproductive in selecting the right teacher, selecting teachers with less \"coverage\"?\n1. (minor) Legend colors are missing in Figure 13."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yYpbmF3W1a", "forum": "m276fke38H", "replyto": "m276fke38H", "signatures": ["ICLR.cc/2026/Conference/Submission20641/Reviewer_vXv9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20641/Reviewer_vXv9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20641/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761954310794, "cdate": 1761954310794, "tmdate": 1762934038616, "mdate": 1762934038616, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of selecting the optimal teacher model for knowledge distillation, particularly in the context of large language models. The authors propose a score called GRACE that predicts a teacher's effectiveness for a given student and task. The score is computed using student gradients on a small set of teacher-generated data, without requiring access to teacher internals or test data. The authors provide a theoretical motivation for GRACE by connecting it to leave-one-out conditional mutual information and demonstrate empirically that it correlates strongly with final student performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-motivated. The trial-and-error approach for teacher selection is computationally costly, and a principled, efficient method is a valuable contribution.\n\n2. The connection of the proposed score to CMI for generalization bound is clever.\n\n3. A key strength is that GRACE is lightweight and does not require access to teacher logits or internal states. This makes the method broadly applicable, even in black-box or API-based distillation scenarios."}, "weaknesses": {"value": "1. The theoretical motivation (Lemma 2.1 and Appendix A) connects GRACE to the generalization gap in terms of loss. However, the empirical experiments measure correlation with final test accuracy (Average-at-k). The authors also note in the appendix (lines 752-755) that \"GRACE serves as a reliable predictor of student performance, even though it fails to correlate with loss-based quantities\". This is a disconnect that undermines the theoretical argument and should be discussed more prominently.\n\n2. The paper's writing could improve. Particularly, Lemma 2.1 does not explain what are the variables in the conditional MI and which variable is the condition. This lemma needs to become well-defined.\n\n3. There are a few claims in the paper that either I misunderstood or they are wrong. For example, lines 190-193 connect the small eigenvalues to high-signal direction. This is quite contrary to what eigenvalues express. Another example, In Fig 6, final sentence of the caption is not correct, it does not match the figure."}, "questions": {"value": "1. In Fig 6, could you please clarify what the right figure is showing and how it should be compared to the other two figures? It seems that the results of the proposed metric does not match the right figure.\n\n2. The authors nicely study the effect of their score on the correctness of the answer. How do you expect GRACE to perform on tasks where generation diversity is more important than correctness, such as dialogue or story generation?\n\n3. Is there a principled way of choosing $C$ in your method? It seems that it is costly to run the trail and error.\n\n4. The paper finds that filtering teacher generations for correctness is not beneficial for student performance (Fig 15). This is an interesting result. Do you have a hypothesis for why this happens? Could this perhaps suggest that the style or reasoning process is more important to distill than the final correct answer?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "kB36wfGSLj", "forum": "m276fke38H", "replyto": "m276fke38H", "signatures": ["ICLR.cc/2026/Conference/Submission20641/Reviewer_miyx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20641/Reviewer_miyx"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20641/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761975486254, "cdate": 1761975486254, "tmdate": 1762934037841, "mdate": 1762934037841, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces GRACE, a lightweight score designed to optimize teacher selection for knowledge distillation in math problem-solving tasks. \nGRACE quantifies the effectiveness of a teacher model by measuring the distributional properties of student gradients, without needing access to teacher logits, internals, or test data. \nIt is linked to generalization performance and correlates strongly with the performance of distilled student models (up to 86% on GSM8K and MATH datasets). \nGRACE improves student performance by at least 6% over traditional methods that use the best-performing teacher. \nAdditionally, GRACE provides valuable insights on key distillation decisions, such as selecting the optimal teacher, generation temperature, and model size. \nOverall, GRACE offers a more efficient and effective approach for teacher selection in distillation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- GRACE offers an efficient method to identify the most suitable teacher for distillation, improving the distillation process without requiring extensive trial and error.\n\n- The proposed GRACE strongly correlates with student performance, as demonstrated by its high correlation (up to 92%) with post-distillation results, out-performing traditional metrics like G-Vendi and G-Var.\n\n- It provides actionable insights to practitioners, including optimal generation temperature and teacher selection under size or model family constraints."}, "weaknesses": {"value": "- While effective, GRACE's correlations with student performance are not perfect, indicating that further refinement and additional explanatory factors might improve its accuracy. \n\n- The score’s performance can be sensitive to hyperparameters, such as the number of prompts and generation dimension, which can complicate its application.\n\n- The current task is limited to Math problem-solving, however, this is a small task within the NLP and AI domain. Is there any possibility of generalizing to other tasks or any insights benefiting other tasks?\n\n- GRACE primarily relies on gradient information, which may not fully capture other important aspects of the distillation process, such as task-specific features. While not needing teacher logits is an advantage, in some cases, having access to them could potentially further improve the performance of GRACE. Would it be better to incorporate comprehensive information?"}, "questions": {"value": "- Is there any possibility of generalizing to other tasks or any insights benefiting other tasks?\n\n- Would it be better to incorporate comprehensive information?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VNFatMnAVw", "forum": "m276fke38H", "replyto": "m276fke38H", "signatures": ["ICLR.cc/2026/Conference/Submission20641/Reviewer_EhFJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20641/Reviewer_EhFJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20641/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761981705763, "cdate": 1761981705763, "tmdate": 1762934037374, "mdate": 1762934037374, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}