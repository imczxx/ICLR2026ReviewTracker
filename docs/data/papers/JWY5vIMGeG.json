{"id": "JWY5vIMGeG", "number": 2244, "cdate": 1757040263568, "mdate": 1763296400381, "content": {"title": "SFA-KAN: Spatial-Frequency Aggregation Kolmogorov-Arnold Network for OCT Segmentation", "abstract": "Current medical image segmentation methods exhibit significant limited robustness in optical coherence tomography (OCT) images, primarily attributable to incomplete representation of organ structures and the illumination heterogeneity during image acquisition. To this end, we propose an efficient approach for extracting complete structure and fine-grained details of OCT images, the Spatial-Frequency Aggregation Kolmogorov-Arnold Network (SFA-KAN). Specifically, our method introduces the Spatial-Frequency Aggregation (SFA) module, which operates in the latent space of a convolutional encoder-decoder architecture. This module hierarchically aggregates features from both the spatial and frequency domains. For spatial-domain feature extraction, we propose the Spatial-Shift KAN (S2KA) block, which employs width and height directions channel-mixing KAN linear layers combined with spatial-shift operations. This design facilitates patch-wise communication and captures long-distance multi-directional dependencies across the entire image within a single computational pass. For frequency-domain feature extraction, we introduce the Spatial-Shift Frequency Transform (S2FT) block, which employs the same spatial operations as the S2KA block followed by multi-scale fast Fourier transform to isolate clinically-relevant frequency components, enhancing segmentation of anatomically diverse structures. Subsequently, the features from these two different domains are channel-wise concatenated and aggregated via cross attention, enabling the model to reconstruct high-frequency details while preserving global structural integrity. Experiments conducted on two privately collected OCT image datasets employing pixel-based metrics and clinical metrics demonstrated that SFA-KAN achieves state-of-the-art performance for OCT image segmentation.", "tldr": "Our work proposes SFA-KAN to address poor robustness in OCT segmentation via its SFA module (S2KA for spatial, S2FT for frequency features, cross-attention aggregation), achieving SOTA on two private OCT datasets.", "keywords": ["OCT Image", "Kolmogorov-Arnold Network", "Dual-Domain"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/666969b34b19dfe8cf41bab019fd268a011a77c0.pdf", "supplementary_material": "/attachment/272548f06055b9b0d08ed317a564ad85146bbed2.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose a novel architecture for OCT segmentation with the contribution to add a block to the latent space of an encoder architecture, combining spatial features from a Kolmogorov–Arnold Network with learned frequency-domain representations. The method is evaluated on custom data of OCT anterior eye segment images."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Novel idea of the introduction of SFA-KAN module for OCT segmentation, which is embedded in an encoder-decoder architecture to also take features in the spatial frequency domain into account, is an interesting concept. The mathematics behind is explained well and the intention is easily understandable. \n- The authors show improved performance of their method over existing approaches."}, "weaknesses": {"value": "- The motivation of the work is too short and needs to be extended for the reader to understand the necessity and impact of the method. More details on the imaging issues should be provided that motivate the proposed method and its potential. The problem statement (missing anatomy, heterogeneity, etc.) is not described enough.\n- The claim to have a solution for OCT segmentation in ophthalmology is too broad, as the method was tested on very limited amount of data. More importantly, the method was not evaluated on retinal OCT, which is the primarily studied for OCT segmentation in most works. Posterior segment imaging as well as the retinal structures and pathologies are more complex than anterior segment structures. To support this strong claim, the performance should also be shown in segmentation of the retina on more diverse datasets.\n- The dataset is claimed to be custom recorded. There are details missing about how the annotation has been conducted and by whom. Especially, how was the ground truth of incomplete anatomical structures generated? There are also details missing about the OCT system used. Finally, there are details missing regarding the demographics of the patient group, especially if there were pathologies in the data.\n- While the proposed approach might work and improve the state-of-the-art, it is not clear how the method impacts the claims made in abstract and introduction. Which structures and details do the authors mean, when they write: “complete structure and fine-grained details of OCT images”? How do they show that the method is able to “isolate clinically-relevant frequency components, enhancing segmentation of anatomically diverse structures”?"}, "questions": {"value": "- Where do the authors address the impact of illumination heterogeneity in image acquisition, which is addressed in the very first sentence of the abstract?\n- With which motivation do the authors specifically segment anterior OCT B-scans, as most works on OCT segmentation address retinal images? Are there any limitations of the method for retinal OCT/advantages for anterior segment OCT?\n- Page 2, line 098: Where do the authors take the claim from Yu et al. 2021, as I could not find it in the referenced paper?\n- With which OCT machine were the images taken? Which settings were used? What was the demographic of the patient group? How many patients participated in the data collection? How was the ground truth of missing structures generated?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "uclG3Nglpt", "forum": "JWY5vIMGeG", "replyto": "JWY5vIMGeG", "signatures": ["ICLR.cc/2026/Conference/Submission2244/Reviewer_kk9F"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2244/Reviewer_kk9F"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2244/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761289548056, "cdate": 1761289548056, "tmdate": 1762916159349, "mdate": 1762916159349, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a Spttial-Frequency Aggregation KA Network (SFA-KAN) for segmentation of OCT images. This framework involoves S2KA for partial dependency modeling and S2FT for frequency-domain analysis."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The proposed framework has novelty, especially since the frequency components are essentially aligned with the OCT imaging principles."}, "weaknesses": {"value": "However, (1) The paper lacks an evaluation on a public dataset. The Dataset1 and Dataset2 are basically the same dataset w/ and w/o augmentation. There are multiple public OCT datasets available online. \n(2) when generating Dataset2, the authors used horizontal flipping. This is not suitable for OCT images since the light propagates from the top to the bottom. The backscattering intensity will always be lower at the bottom and stronger in the top, given the same conditions. With horizontal flipping, the dataset will contain patterns that will never show in real OCT images, creating a gap between the training set and real-world data distribution."}, "questions": {"value": "The authors need to fix the data augmentation and do experiments on public datasets."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ON6vKlBmHD", "forum": "JWY5vIMGeG", "replyto": "JWY5vIMGeG", "signatures": ["ICLR.cc/2026/Conference/Submission2244/Reviewer_DXve"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2244/Reviewer_DXve"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2244/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761880482978, "cdate": 1761880482978, "tmdate": 1762916159155, "mdate": 1762916159155, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the task of semantic segmentation in OCT images to improve model robustness for incomplete organ structures. The problem aims to enhance existing architectures to effectively model the underlying patterns while maintaining computational efficiency. The proposed solution is the Spatial-Frequency Aggregation Kolmogorov-Arnold Network (SFA-KAN), a U-Net architecture featuring a SFA module at its bottleneck. This module consists of two components: a Spatial-Shift KAN (S2KA) block for capturing long-range spatial dependencies using diagonal shifts and KAN linear layers, and a Spatial-Shift Frequency Transform (S2FT) block for isolating relevant frequency components using a multi-scale Fast Fourier Transform with a dynamic band selector. Features from these spatial and frequency domains are subsequently fused via cross-attention. The method was evaluated on two privately collected OCT datasets using both pixel-based metrics (mIoU, DSC, Accuracy, ASSD) and clinical metrics (Mean Absolute Error for Central Corneal Thickness, Iris Thickness, and Lens Thickness)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The authors claim three primary contributions: the S2KA block for spatial modeling, the S2FT block for frequency analysis, and achieving superior segmentation performance on their custom OCT datasets. \n\nThe motivation to address illumination heterogeneity is impactful for clinical translation, and the exploration of a dual-domain approach combined with Kolmogorov-Arnold Networks (KANs) is a relevant research direction."}, "weaknesses": {"value": "The paper presents several limitations. \n\nThe \"efficient approach\" claim is not supported by the evidence, as no quantitative analysis of computational complexity (e.g., parameter counts, floating-point operations per second, or inference time) is provided for the proposed model or any of the baselines presented. \n\nThe central claim of achieving SOTA performance cannot be supported by evaluating on two private datasets.\n\nThe claim of \"heterogeneity-robustness\" is weakly supported, as the model's performance under heterogeneity was tested using synthetic augmentations (rotations, flips) rather than on data from genuinely diverse clinical settings, devices, or patient populations. \n\nFinally, the related work section omits several concurrent and directly relevant methods that also integrate KANs into U-Net architectures for medical segmentation, such as Y-Net [1], which is also for OCT segmentation.\n\n[1] Farshad, A., Yeganeh, Y., Gehlbach, P. and Navab, N., 2022, September. Y-net: A spatiospectral dual-encoder network for medical image segmentation. In International conference on medical image computing and computer-assisted intervention (pp. 582-592). Cham: Springer Nature Switzerland."}, "questions": {"value": "Could the authors clarify why they did not evaluate on public benchmarks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "g9Cgech29k", "forum": "JWY5vIMGeG", "replyto": "JWY5vIMGeG", "signatures": ["ICLR.cc/2026/Conference/Submission2244/Reviewer_ZYKw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2244/Reviewer_ZYKw"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2244/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761914752511, "cdate": 1761914752511, "tmdate": 1762916158912, "mdate": 1762916158912, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SFA-KAN, a model designed to capture complete structures and fine details in OCT images. Its key contribution is the Spatial–Frequency Aggregation (SFA) module, which combines spatial-domain and frequency-domain information. The module includes two components: S2KA, which extracts spatial features using shift operations and KAN layers, and S2FT, which extracts multi-scale frequency features using FFT. These complementary features are fused in the bottleneck through cross-attention to improve segmentation accuracy. SFA-KAN is evaluated on two collected OCT datasets and consistently outperforms baseline approaches across both segmentation metrics and clinically relevant thickness measurements."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well motivated, and the method is presented as a clear  dual-domain framework that combines spatial and frequency features using the S2KA and S2FT blocks, supported by KAN-based nonlinear modeling. The ablation study strengthens the overall approach by showing that each module adds measurable value and that the full spatial-frequency design delivers the strongest results. Including clinically relevant thickness measurements further demonstrates the practical usefulness of the method in real OCT analysis."}, "weaknesses": {"value": "While the method is promising, the work has several limitations. \n\n1) The datasets are relatively small, and the second dataset is created through simple augmentations of the first, which limits generalization. Including additional datasets or testing on external benchmarks would strengthen the evidence for robustness.\n2) Components such as the stability of the frequency-domain adjustments, and the specific role of the KAN layers are not fully clarified. Providing more detailed explanations, visualizations, or targeted experiments would help clarify these mechanisms.\n3) The introduction highlights the computational cost of transformer-based methods, yet the paper does not report efficiency metrics such as parameter counts or complexity comparisons."}, "questions": {"value": "Does the cross-attention fusion in the bottleneck significantly increase computation, and could a simpler fusion mechanism achieve similar results?\n\nCould the S2KA and S2FT blocks be compared against, or replaced with, existing spatial- and frequency-capturing modules to determine whether the proposed designs offer a clear advantage over established alternatives?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TAT9pr5DiM", "forum": "JWY5vIMGeG", "replyto": "JWY5vIMGeG", "signatures": ["ICLR.cc/2026/Conference/Submission2244/Reviewer_L2Xb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2244/Reviewer_L2Xb"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2244/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762574658365, "cdate": 1762574658365, "tmdate": 1762916158791, "mdate": 1762916158791, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}