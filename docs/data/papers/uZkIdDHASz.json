{"id": "uZkIdDHASz", "number": 20384, "cdate": 1758305363253, "mdate": 1759896980673, "content": {"title": "Fast Two-photon Microscopy by Neuroimaging with Oblong Random Acquisition (NORA)", "abstract": "Advances in neural imaging have enabled neuroscientists to study how the activity of large neural populations produce perception, behavior and cognition. Despite many developments in optical methods, there exists a fundamental tradeoff between imaging speed, field of view, and resolution that limits the scope of neural imaging, especially for the raster-scanning multi-photon imaging needed for imaging deeper into the brain. One approach to overcoming this trade-off is computational imaging, in which an imaging system efficiently encodes the target image through its optical design and then recovers the acquired information through inverting the encoded measurements algorithmically. Computational imaging thus fundamentally depends on the reliability of recovery. While such approaches are emerging for recovery of optical neural imaging from encoded measurements, they lack a core theoretical sampling theory that will guarantee reliable and accurate recovery. We present here such a theory, based on the widely used model of functional optical imaging videos being low-rank. We show that under simple blurring and randomized line-subsampling conditions, full videos can be recovered from a small fraction of the lines, providing the opportunity for an order-of-magnitude speedup. We use this theory to develop a practical design for fast imaging: Neuroimaging with Oblong Random Acquisition (NORA). NORA, guided by our theory, can be implemented through simple-to-implement changes to widely available systems. Moreover, following our theory, NORA reconstructs the entire video together via nuclear-norm minimization on the pixels-by-time matrix, rather than more common frame-by-frame recovery. We simulated NORA imaging using the Neural Anatomy and Optical Microscopy (NAOMi) biophysical simulator, showing that NORA can accurately recover 400~$\\mu$m~X~400~$\\mu$m fields of view at subsampling rates up to 20X despite realistic noise and motion conditions, thereby demonstrating that our theory holds. These speeds open up the capability of future systems to extend into imaging faster processes in neural systems, such as voltage and glutamate.", "tldr": "Theory-grounded method for fast multi-photon microscopy using simple optical design and matrix completion", "keywords": ["Low-Rank", "Computational Imaging", "multi-photon imaging", "matrix completion", "two-photon imaging", "nuclear-minimization", "neuroimaging"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/303c553c4b4108f6a7a1a6948614d13a0070b7c5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents a reconstruction framework for acquisition using a two-photon microscope. After an analysis of the image formation, an optimization problem is build for the reconstruction. The problem is solved using a fast conical optimization scheme. The experiments show some interesting results and the system seems promising for imaging."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The reconstruction problem is cast as a matrix completion problem. The following optimization problem is motivated by well know reconstruction analysis and results. In the proposed setting, the main contribution of the paper is the central theorem that gives some insight on the reconstruction error. It gives ideas on how many measurements are needed for an acceptable reconstruction."}, "weaknesses": {"value": "I see several weaknesses in the paper.\n\n- The implementation is an optical framework. Such part will only interest people with instrumentation knowledge. Thus, the ICLR community may be not the best for such contribution.\n- There is no analysis of the noise from a physics point of view. What is the nature of the error matrix? Is it random? Is it compound of several error terms?\n- Please check how the references are inserted into the LaTeX file and use \\citep for paper citation and \\citet for title..."}, "questions": {"value": "- Does the noise mostly Gaussian or Poissonian? If Poissonian would it be more interesting to take it into account using Anscombe transform (see [1])?\n- What is $A_n$ in equation (13)?\n- What is the adjoint operator of $\\mathcal{A}_k$?\n\n\n [1] Azzari, L., & Foi, A. (2016). Variance stabilization for noisy+ estimate combination in iterative Poisson denoising. IEEE signal processing letters, 23(8), 1086-1090."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CI3O6HSX9t", "forum": "uZkIdDHASz", "replyto": "uZkIdDHASz", "signatures": ["ICLR.cc/2026/Conference/Submission20384/Reviewer_SyYH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20384/Reviewer_SyYH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20384/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761735605201, "cdate": 1761735605201, "tmdate": 1762933835053, "mdate": 1762933835053, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a computational two-photon imaging scheme that addresses the speed limit of traditional point-by-point scanning 2P imaging. It skips most raster lines per frame while slightly blurring along the slow-scan axis with an oblong PSF, and reconstructs the full pixels-by-time matrix with nuclear-norm minimization. The theory proves that under a low-rank assumption on the sample, accurate video reconstruction can be achieved under a very low sampling rate. Simulations with NAOMi indicate accurate recovery at 10–20× line-subsampling under realistic noise and motion, preserving ROI time traces."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is clearly written with theoretical analysis."}, "weaknesses": {"value": "No experimental demonstration conducted, no adequate comparison with existing techniques."}, "questions": {"value": "1. The simulation of blurring and subsampling (line 313-315) does not follow the real experiment scenario. To simulate the real 2P imaging in your schematic, you should apply subsampling on the ground truth (sample under observation) first, and then apply the blurring PSF. Otherwise, the crosstalk from neighboring (unsampled) lines will mix up with your sampled ones. The forward model, reconstruction algorithm, as well as the theory proofs should be modified accordingly as well. \n2. What are the spatial extents of line-by-line and rigid motions being introduced compared to the neuron sizes? It would be great to see the trend in reconstruction quality as motion increases, and under what kinds of motion the reconstruction finally breaks.\n3. How does this compare to line-scanning-based 2P imaging, which only needs one galvo scanner and will be, in principle, much faster than this technique?\n\n[1] Tal, Eran, Dan Oron, and Yaron Silberberg. \"Improved depth resolution in video-rate line-scanning multiphoton microscopy using temporal focusing.\" Optics letters 30.13 (2005): 1686-1688.\n\n[2] Xue, Yi, et al. \"Scattering reduction by structured light illumination in line-scanning temporal focusing microscopy.\" Biomedical optics express 9.11 (2018): 5654-5666.\n\n4. What is the exact sensor noise level being introduced in the simulation? How does the reconstruction react to the scattering introduced noise in neurons?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "qG6ftDbFC3", "forum": "uZkIdDHASz", "replyto": "uZkIdDHASz", "signatures": ["ICLR.cc/2026/Conference/Submission20384/Reviewer_haBw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20384/Reviewer_haBw"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20384/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761934393980, "cdate": 1761934393980, "tmdate": 1762933834509, "mdate": 1762933834509, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes NORA to enhance the resolution of standard two-photon microscopy by combining optical blurring, subsampling, and computational reconstruction. Two cylindrical lenses generate an elongated PSF, enabling a blur-and-subsample strategy in which each high-resolution pixel contributes to multiple overlapping wide-line scans. The forward imaging model represents the optical path as a linear blur operator applied to a low-rank fluorescence video matrix, followed by subsampling. Reconstruction is performed via nuclear norm-regularized least-squares optimization, which leverages correlations across frames and the low-rank prior to recover high-resolution pixel values from undersampled measurements."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. NORA achieves accelerated two-photon microscopy acquisition by combining random line scanning with an elongated PSF, which can be implemented with minimal hardware changes.\n2. The paper is well-structured, clear, and easy to follow."}, "weaknesses": {"value": "1. The reconstruction in NORA relies on nuclear norm optimization, modeling the fluorescence video as a low-rank matrix. This low-rank prior may not hold when the imaged activity is highly complex or nonlinear, such as in large-scale rapid neural dynamics or highly dynamic cellular structures, potentially leading to degraded reconstruction performance. In other words, if the intrinsic dimensionality of the video significantly exceeds the assumed rank, increasing the number of samples may still be insufficient to accurately recover fine details.\n2. Elongating the PSF allows integration of information along the slow-scan direction, reducing the number of required scans; however, it introduces local blurring. While the spatial resolution along the fast-scan axis is preserved, resolution along the slow-scan axis is inevitably compromised, which may limit the method’s suitability for experiments requiring fine structural analysis. Moreover, the extent of PSF elongation is inherently limited and cannot fully cover missing scan lines, making reconstruction still dependent on multi-frame information and the low-rank prior.\n3. While NORA leverages low-rank priors and linear forward modeling to achieve high-speed imaging, its performance is inherently limited by assumptions such as low-rank structure and the partial blurring along the slow-scan axis. These limitations raise the question of whether deep learning-based approaches could further enhance imaging performance.\n4. The experimental evaluation of NORA is limited by the lack of testing under realistic imaging conditions. Additionally, the study provides limited quantitative analysis of image quality, such as metrics for spatial resolution, reconstruction accuracy, or signal-to-noise ratio, making it difficult to rigorously compare the method against existing approaches or to fully characterize its practical performance."}, "questions": {"value": "Please see the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ETHRaaxAZ5", "forum": "uZkIdDHASz", "replyto": "uZkIdDHASz", "signatures": ["ICLR.cc/2026/Conference/Submission20384/Reviewer_GYmL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20384/Reviewer_GYmL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20384/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994242136, "cdate": 1761994242136, "tmdate": 1762933834160, "mdate": 1762933834160, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors develop a method for recovering high-resolution neuroimaging videos  from low-resolution measurements (specifically, blurred randomized line sampling).  The method solves  sparse inverse problem, exploiting the spatio-temporal redundancy of the globally moving signal, and is tested on a two-photon microscopy simulator."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "An important practical problem, and the presentation is generally clear."}, "weaknesses": {"value": "Novelty?  I assume these videos are undergoing globally rigid motion, which induces substantial spatio-temporal redundancy.  I don't know the multi-photon imaging literature well, but this is a well-studied problem in photographic video processing, and many algorithms exist to perform motion-compensated estimation or restoration (including those that underlie video coding systems like MPEG).  This also shows up in the visual neuroscience literature, where some authors have explored how human vision can maintain high acuity when the eys are constantly moving (both large saccadic eye movements, and small fluctuations).  There are currently no citations to any of this literature.\n\nA secondary concern, perhaps more for the area chairs to decide, is whether ICLR is the right venue for this paper.  Although estimation is a theme in the meeting, this paper does not discuss representations, or learning."}, "questions": {"value": "Would be interesting to see a comparison of the compressed-sensing style solution used in the paper against a more traditional translational motion solution,  which assumes the spatio-temporal signal is two dimensional (or, equivalently, that it's Fourier spectrum lies on a plane).  For non-translational (but still smooth) motions, this can be done locally, as is found in many optic flow estimation algorithms."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YRIyzdqIeH", "forum": "uZkIdDHASz", "replyto": "uZkIdDHASz", "signatures": ["ICLR.cc/2026/Conference/Submission20384/Reviewer_7SsV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20384/Reviewer_7SsV"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20384/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762209537383, "cdate": 1762209537383, "tmdate": 1762933833641, "mdate": 1762933833641, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}