{"id": "5UrPAW3uI1", "number": 4952, "cdate": 1757818959154, "mdate": 1763649518281, "content": {"title": "FedOpenMatch: Towards Semi-Supervised Federated Learning in Open-Set Environments", "abstract": "Semi-supervised federated learning (SSFL) has emerged as an effective approach to leverage unlabeled data distributed across multiple data owners for improving model generalization. Existing SSFL methods typically assume that labeled and unlabeled data share the same label space. However, in realistic federated scenarios, unlabeled data often contain categories absent from the labeled set, i.e., outliers, which can severely degrade the performance of SSFL algorithms.\nIn this paper, we address this under-explored issue, formally propose the open-set semi-supervised federated learning (OSSFL) problem,  and develop the first OSSFL framework, FedOpenMatch. Our method adopts a one-vs-all (OVA) classifier as the outlier detector, equipped with logit adjustment to mitigate inlier-outlier imbalance and a gradient stop mechanism to reduce feature interference between the OVA and inlier classifiers. In addition, we introduce the logit consistency regularization loss, yielding more robust performance.\nExtensive experiments on standard benchmarks across diverse data settings demonstrate the effectiveness of FedOpenMatch, which significantly outperforms the baselines.", "tldr": "We propose the first approach, FedOpenMatch, for semi-supervised federated learning with open-set unlabeled client data, which achieves sota performance under both close-set and open-set tests.", "keywords": ["semi-supervised federated learning", "open-set", "federated learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5c2b208aa158701fd5a1af8cfe7a15cca59f5d4b.pdf", "supplementary_material": "/attachment/112b15b6a00f9a39a71938d95cb4f5db323f29a5.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a method called FedOpenMatch for open-set federated semi-supervised learning. By \"open-set\", the authors refer to the setting where outlier classes exist in unlabeled datasets, and the model should be able to classify inlier classes right, while detecting outlier classes. To address the problem, FedOpenMatch leverages a two-head structure, with a feature extractor, an inlier classifier and an OVA outlier classifier. The authors introduce several techniques to enhance the performance of FedOpenMatch, such as stop-gradients for the OVA branch, logit consistency instead of probability consistency, and logit adjustment to handle the imbalance issue of OVA classifiers. Experiments are done on three datasets and against multiple baselines, where FedOpenMatch outperforms a variety of baselines, including open-set and closed-set ones."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper tackles the problem of open-set federated semi-supervised learning, which is of practical value. Being able to detect outlier classes is an important property especially in FL, where the collected data may contain a large amount of noise. \n2. This paper is overall well-written and easy to follow. The organization of this paper is reasonable, and the technical solutions and intuitions are clearly stated together, making it easy to understand. \n3. Experiments of FedOpenMatch is extensive. The authors compare against lots of baselines, including SSFL algorithms and adapted Open-set SSL methods (to the FL setting) with multiple baselines, number of seen classes, etc. Moreover, ablation studies are sufficient and demonstrate the impact of each individual design technique. Some ablation studies even analyze why the proposed techniques help (e.g. analyzing gradient similarity to understand the impact of gradient stop). This makes the paper well-justified."}, "weaknesses": {"value": "1. One major weakness of this paper is that it is built upon multiple existing ideas. For example, the logit adjustment method is directly taken from Menon et al. 2021, and the weak-strong consistency is modified from existing methods. Overall, this slightly weakens the amount of novel insights of this paper, despite still being a solid paper with new problems tackled. \n2. I am interested in how FedOpenMatch is sensitive to the number of local iterations/epochs. As local clients only have unlabeled data, training on solely unlabeled data for too long may lead to diverging model updates. Therefore, from my understanding, the number of local iterations/epochs is an important parameter to determine in federated SSL. The authors did not provide such analyses though. \n3. Gradient similarity fail to completely explain the accuracy curve. While in Figure 3, the relations between gradient similarity and open-set accuracy is significant, such relations are not so apparent in Figures 4 and 5. For example, in Figure 4, for the early ~250 steps, gradient similarity is below 0.2, yet the accuracies are close. This makes me wonder whether there are other factors that may impact the accuracy, e.g. gradient magnitude.  \n4. Minor points. \n    - It seems that in Eqn. 6, the sign of $\\omega\\log \\pi$ is reversed. I checked the original paper and found that the sign before the term should be - instead of +."}, "questions": {"value": "One minor question about FedOpenMatch is when a sample will be categorized as outlier, e.g. when all OVA classifiers report it as an outlier? I am not highly familiar with open-set semi-supervised learning so some additional backgrounds may help."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "0DFIaYKsPC", "forum": "5UrPAW3uI1", "replyto": "5UrPAW3uI1", "signatures": ["ICLR.cc/2026/Conference/Submission4952/Reviewer_abnT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4952/Reviewer_abnT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4952/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760863389131, "cdate": 1760863389131, "tmdate": 1762917788981, "mdate": 1762917788981, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces the open-set semi-supervised federated learning (OSSFL) problem, where clients possess unlabeled data potentially containing unseen classes, and the server maintains a small labeled set. To address this, the authors propose FedOpenMatch, a framework that jointly trains an inlier classifier and a one-vs-all (OVA) outlier detector. The method incorporates gradient stop, logit adjustment, and logit consistency regularization to improve stability and open-set discrimination under federated conditions."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper presents a clear problem setting that distinguishes SSFL, OSSL, FOSR, and the OSSFL. By adding the GS, logit adjustment and LCR to a standard architecture, experimental results show FedOpenMatch improves both closed-set and open-set balanced accuracy over federated adaptations of OSSL baselines and standard SSFL methods."}, "weaknesses": {"value": "While the paper positions as a new OSSFL formulation, its novelty relative to prior open-world SSFL work is limited and largely rooted in scenario framing rather than a new learning principle. The authors should better justify why the label-at-server configuration represents the dominant or more practical case, and clarify how insights generalize across settings. As it stands, the novelty appears to hinge more on scenario framing than on a fundamentally new learning principle.\n\nAdditionally, centralized OSSL algorithms appear to be adapted to FL. Their relatively weak and unstable performance raises concern that implementations or hyperparameters under FL are suboptimal. More evidence could be helpful to show these are strong federated instantiations rather than strawmen.\n\nFurther, the evaluation setup is narrow, using only ResNet-18, limited Dirichlet heterogeneity, and no covariate or mixed-shift scenarios. Key design details, such as pseudo-label staleness under non-IID drift, are under-analyzed. Finally, grouping all unseen classes into a single \"unknown\" category obscures variability."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "inmp0lYMov", "forum": "5UrPAW3uI1", "replyto": "5UrPAW3uI1", "signatures": ["ICLR.cc/2026/Conference/Submission4952/Reviewer_5NdG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4952/Reviewer_5NdG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4952/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761761369173, "cdate": 1761761369173, "tmdate": 1762917788633, "mdate": 1762917788633, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper defines Open-set Semi-Supervised Federated Learning (OSSFL) (unlabeled client data contain unseen classes) and presents FedOpenMatch, the first framework for this setting. It combines an OVA outlier detector with logit adjustment for imbalance, a gradient-stop to decouple OVA/inlier heads, and logit consistency regularization. Experiments on standard benchmarks show sizable improvements in open-set accuracy (e.g., +14.33% on CIFAR-100)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- First formalization of OSSFL and a tailored framework\n- Strong, consistent gains; well-motivated components (OVA + adjustment + gradient-stop + consistency)\n- Good figures/tables and taxonomy (SSFL vs. OSSL vs. FOSR vs. OSSFL).\n- Addresses a real-world failure mode for SSFL; likely baseline for future work."}, "weaknesses": {"value": "- Limited analysis of non-IID client shifts (class/feature distribution) on OVA calibration.\n- Communication/compute overhead of OVA and consistency losses isn’t profiled; end-to-end systems analysis would help.\n- Robustness to extreme open-set ratios and ablations isolating each component could be expanded."}, "questions": {"value": "- How sensitive is OVA performance to class imbalance and thresholds under client heterogeneity?\n- Can gradient-stop harm representation sharing between inlier/OVA? Any alternatives (e.g., orthogonal heads)?\n- What happens when unknown prevalence is very high or client pools have disjoint seen sets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MJie6uOiWF", "forum": "5UrPAW3uI1", "replyto": "5UrPAW3uI1", "signatures": ["ICLR.cc/2026/Conference/Submission4952/Reviewer_ikNd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4952/Reviewer_ikNd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4952/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761846038604, "cdate": 1761846038604, "tmdate": 1762917788256, "mdate": 1762917788256, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces **FedOpenMatch**, the first framework for **Open-Set Semi-Supervised Federated Learning (OSSFL)**—a realistic yet previously unexplored setting where unlabeled client data contain **outliers**. Unlike standard SSFL methods that assume closed-set label spaces, FedOpenMatch jointly trains an **inlier classifier** and a **one-vs-all (OVA) outlier detector** to safely leverage open-set unlabeled data.  Extensive experiments on CIFAR-10, CIFAR-100, and SVHN show FedOpenMatch significantly boosts."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper demonstrates good **originality** by formally defining a new and realistic problem setting—Open-Set Semi-Supervised Federated Learning (OSSFL)—which bridges the gap between open-set semi-supervised learning and federated learning. The experimental design is also **rigorous**, covering multiple datasets, label scarcity regimes, and heterogeneity levels, with thorough ablation studies validating each component. The writing is clear and well-structured."}, "weaknesses": {"value": "1. The method assumes the server’s labeled set is perfectly balanced and clean, which may not hold in real-world label-at-server settings; robustness to label noise or skewed class priors is unexamined. \n\n2. Second, all experiments use ResNet-18 and synthetic Dirichlet splits—evaluations on larger models (e.g., ViTs) may change the conclusion on feature conflicts between the OVA classifier and the inlier classifier."}, "questions": {"value": "Does your method work with bigger models or more realistic data splits?\n\nAll experiments use ResNet-18 and synthetic data splits (Dirichlet). But real-world data may have domain shifts (e.g., different hospitals or cameras), and people now often use Vision Transformers (ViTs).  \n- Have you tried FedOpenMatch with a ViT or a more realistic non-IID split (e.g., by domain or semantic group)?  \n- Would the “gradient stop” still be needed in those cases, or is it only helpful for ResNet-18?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "jUhs7HNJPG", "forum": "5UrPAW3uI1", "replyto": "5UrPAW3uI1", "signatures": ["ICLR.cc/2026/Conference/Submission4952/Reviewer_jhAD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4952/Reviewer_jhAD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4952/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761983751682, "cdate": 1761983751682, "tmdate": 1762917787973, "mdate": 1762917787973, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}