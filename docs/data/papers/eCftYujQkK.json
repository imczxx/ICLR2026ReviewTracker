{"id": "eCftYujQkK", "number": 18431, "cdate": 1758287767011, "mdate": 1759897104078, "content": {"title": "SimGFM: Simplifying Discrete Flow Matching for Graph Generation", "abstract": "Discrete Flow Matching (DFM) presents a promising approach for graph generation; however, existing adaptations often introduce substantial complexity by incorporating task-specific heuristics, compromising the continuity equation and significantly expanding the hyperparameter space. Moreover, their sampling efficiency remains limited, as the required number of steps is often comparable to diffusion models, diminishing DFM’s practical advantages.\nTo address these limitations, we propose SimGFM, a simplified graph DFM for graph generation. SimGFM introduces a graph-structured rate formulation based on minimalist design principles—characterized by a clear mathematical expression, free of ad-hoc heuristics, and consistent with the continuity equation. SimGFM achieves strong empirical results: on QM9, it matches prior models requiring 500–1000 steps with only 10 steps, and on most datasets, its performance at 50 steps matches or surpasses these baselines, demonstrating both efficiency and competitiveness.", "tldr": "SimGFM achieves competitive graph generation in 10–50 steps through a principled, heuristic-free probabilistic design.", "keywords": ["Graph Generation", "Discrete Flow Models", "Flow Matching"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d0a2f597d9124ab09f5f7fa534fbae893ce25dda.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces SimGFM (Simplified Graph Flow Matching), a novel approach for graph generation based on discrete flow matching (DFM). SimGFM's core innovation is a graph-structured rate formulation grounded in minimalist design principles, specifically aiming for a clear mathematical expression that is free of ad-hoc heuristics and fully consistent with the continuity equation. The model demonstrates a significant empirical advantage, achieving competitive performance on the QM9 dataset using only 50 sampling steps (a process that previously required 500−1000 steps) and matching or surpassing baseline models on most datasets at just 50 steps. This demonstrates a compelling blend of efficiency and competitive generative capability."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1. **Substantial Advancement in Discrete Graph Flow Matching Efficiency:** The proposed SimGFM model addresses a critical and long-standing challenge in discrete graph flow matching: the computational burden imposed by a large number of sampling steps. By introducing an elegant, simplified rate formulation, the model achieves a significant reduction in the required sampling steps while demonstrably maintaining competitive performance across diverse graph generation benchmarks.\n\n2. **Exemplary Clarity and Presentation:** The manuscript is exceptionally well-structured and written. The authors effectively communicate complex theoretical concepts, the proposed methodology, and the empirical results."}, "weaknesses": {"value": "1. **Perceived Simplicity of Core Methodology**: While the reviewer appreciates the elegance of the proposed method, some readers might find the technical contribution to be relatively straightforward, as the core innovations primarily revolve around a refinement of the rate-matrix estimator and the time scheduler."}, "questions": {"value": "1. There is a potential issue with the citation of the CatFlow model in the manuscript. Could the authors please verify the accuracy and completeness of the reference corresponding to the CatFlow work?\n\nI have no further questions for authors."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dr6D5YBZFS", "forum": "eCftYujQkK", "replyto": "eCftYujQkK", "signatures": ["ICLR.cc/2026/Conference/Submission18431/Reviewer_nKK3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18431/Reviewer_nKK3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18431/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761141347563, "cdate": 1761141347563, "tmdate": 1762928127152, "mdate": 1762928127152, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SimGFM, a discrete flow matching generative model for graph generation. The work distinguishes between two concurrent formulations of Discrete Flow Matching (DFM): the formulation of Campbell et al. and that of Gat et al. (also referred to as the VF-denoiser). Unlike previous DFM paper based on Campbell’s formulation, this paper builds upon the Gat et al. variant, which is presented as conceptually simpler and more flexible.\n\nThe authors identify a potential limitation in the deterministic updates of the VF-denoiser, which they claim can lead to mode collapse and reduced sample diversity. To address this, the paper introduces a random VF-denoiser (rvf-denoiser), which replaces the claimed deterministic update by sampling from the denoiser’s probability distribution and before updating the graph using a Dirac delta with mass at the sampled graph. This modification is intended to promote exploration and improve diversity during generation.\n\nExtensive experiments on multiple datasets are presented, with the proposed method reported to improve state-of-the-art results on most metrics."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper is clearly written and easy to follow. \n\nThe mathematical propositions and proofs are well-structured, intuitive, and appear to be correct.\n\nThe experimental section is extensive, covering a range of datasets and showing strong empirical performance across several benchmarks."}, "weaknesses": {"value": "### Main Claims\nThe paper’s primary contribution is the introduction of the random VF-denoiser (rvf-denoiser) in place of the standard vf-denoiser. However, it is not clear that the two procedures are different. Based on the formulation, the rvf-denoiser appears to be mathematically equivalent to the VF-denoiser:\n\n   $p_{s | t}^{\\text{rvf}}(x^i | x_t) = E_{x^i_{1|t} \\sim p_\\theta(x_1 | x_t)}[p(x_s | x^i_{1|t}, x_t)] \n    = E_{x^i_{1|t}}[\\delta_{x_t}(x_s) + h u^{rvf}(x^i, x_t)]\n    = \\delta_{x_t}(x_s) + hE_{x^i_{1|t}}[u^{rvf}(x^i, x_t)] \n    = \\delta_{x_t}(x_t) + hu(x^i, x_t)\n    = p^{vf}_{s | t}(x^i | x_t)$\n\nIf this reasoning holds, the rvf-denoising step is equivalent to the vf-denoising step, raising doubts about the novelty and motivation of the approach.\n\nThe paper presents the VF-denoiser as deterministic (lines 56 and 207), yet in practice, $G_{t+\\Delta_t}$ is randomly sampled at each denoising step. This apparent inconsistency should be clarified.\n\nThe authors argue that the rvf-denoiser “allows the trajectory to commit early to one alternative and break symmetry,” thereby enhancing exploration and diversity (lines 233–238). Such claims should be supported by either a theoretical argument or dedicated empirical evidence demonstrating that rvf-denoising indeed leads to improved diversity without sacrificing sample quality.\n\nFinally, the paper states that rvf and vf have similar computational costs. However, since the rvf-denoiser requires two samplings per denoising step, the additional cost may not be negligible. Providing quantitative runtime comparisons would substantiate this claim.\n\n### Related Work\nThe recent paper [1] appears closely related, as it also employs an iterative denoising framework involving sampling $x_{1|x}$ before reconstruction. A more detailed discussion of how SimGFM differs from this approach would help clarify the novelty and positioning of the proposed method, as well as potentially clarify the distinction between VF and rVF.\n\n### Empirical Evaluation\nIf vf and rvf are indeed distinct methods (and not equivalent formulations), the experimental section should include a systematic comparison between them to validate the claimed benefits of the rvf-denoiser.\n\nFor reproducibility, the paper should indicates the source distribution $p_0$ used for each experiment (for nodes and edges). \n\nIn addition, the results reported for the Ego-Small dataset appear to outperform the training set itself, which should not be possible. This discrepancy likely indicates a presentation or evaluation issue and should be clarified.\n\nFor the QM9 datasets (both with and without hydrogen), the paper does not specify which version is used (kekulized vs. aromatic bonds). This distinction is crucial, as results across these versions are not directly comparable. \n\n------\n[1] Y. Boget. Simple and critical iterative denoising: A recasting of discrete diffusion in graph gen-\neration. In Proceedings of the 42th International Conference on Machine Learning, Proceedings\nof Machine Learning Research. PMLR, July 2025."}, "questions": {"value": "Are rvf and vf really different or two equivalent formulartions of the same model?\n\nWhy the authors state that the vf-denoiser is deterministic?\n\nHow the authors explain that the results for ego-small outperform the training set?\n\nOut of curiosity, what does vf stands for?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ne9PK7Go0M", "forum": "eCftYujQkK", "replyto": "eCftYujQkK", "signatures": ["ICLR.cc/2026/Conference/Submission18431/Reviewer_UM94"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18431/Reviewer_UM94"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18431/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761235631580, "cdate": 1761235631580, "tmdate": 1762928126737, "mdate": 1762928126737, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper propose to use another DFM formulation for simplicity and improved performance with less step numbers"}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well written: the formulation and notations are very clear.\nThe motivation is well supported, and the experiments are thorough."}, "weaknesses": {"value": "1. Given the clarity of Figure 2, QM9 is not a proper dataset for method comparison, since almost all current methods can achieve saturating performance above 99%. It does not sufficiently support a meaningful comparison between DFM and the current state-of-the-art models.\n2. Although the approach is well supported and motivated, it appears to be a relatively quick adaptation of a new DFM formulation to the current SOTA model, with only a slight modification in the reverse process: sampling  $G_1$​ instead of using the full posterior distribution. This operation is also used in other DFM formulations where $G_1$​ has to be sampled. This limits the contribution of the paper. I would encourage the authors to further clarify whether there are additional insights or meaningful changes beyond this modification to enhance the contribution of the paper.\n3. The performance on a more complex molecular dataset such as MOSES is worse, and this is not explained."}, "questions": {"value": "1. Why do the authors think that this method does not perform well on more complex molecular datasets? Have you tested it on other datasets?\n2. Given the simplicity of the method, I assume there are few parameters to tune beyond the scheduler mentioned in the appendix. Could the authors confirm this?\n3. Could the authors further clarify the motivation in details at the beginning of Section 3.1 for comparing with the other DFM formulation (Campbell)? Why is this formulation expected to perform better with fewer denoising steps? Potentially, are there any visualizations available to compare the actual denoising trajectories between the two formulations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "bY2nywKXtQ", "forum": "eCftYujQkK", "replyto": "eCftYujQkK", "signatures": ["ICLR.cc/2026/Conference/Submission18431/Reviewer_onhW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18431/Reviewer_onhW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18431/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761583306309, "cdate": 1761583306309, "tmdate": 1762928126194, "mdate": 1762928126194, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}