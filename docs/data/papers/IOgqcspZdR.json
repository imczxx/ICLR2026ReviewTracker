{"id": "IOgqcspZdR", "number": 20665, "cdate": 1758308759404, "mdate": 1759896965163, "content": {"title": "CultureVLM: Characterizing and Improving Cultural Understanding of Vision-Language Models", "abstract": "Vision-language models (VLMs) have advanced human-AI interaction but struggle with cultural understanding, often misinterpreting symbols, gestures, and artifacts due to biases in predominantly Western-centric training data. In this paper, we construct CultureVerse, a large-scale multimodal benchmark covering 19,682 cultural concepts, 188 countries/regions, 15 cultural topics, and 3 question types, with the aim of characterizing and improving VLMs' multicultural understanding capabilities. Then, we propose CultureVLM, a series of VLMs fine-tuned on our dataset to achieve significant performance improvement in cultural understanding. Our evaluation of 16 models reveals significant disparities, with a stronger performance in Western concepts and weaker results in African and Asian contexts. Fine-tuning on our CultureVerse training set enhances cultural perception, demonstrating cross-cultural, cross-continent, and cross-dataset generalization without sacrificing performance on models' general VLM benchmarks. We further present insights on cultural generalization and forgetting. We hope that this work could lay the foundation for more equitable and culturally aware multimodal AI systems.", "tldr": "", "keywords": ["Culture bias", "Vision-Language Models", "Fine-tuning"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/54e1d30bd7d2289adb7c993be055f11bfac7062e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents CultureVerse a scalable pipeline and multimodal multiple choice corpus covering 188 countries/regions, 15 cultural topics and 3 question types. The proposed corpus is obtained using GPT-4o to process Wikipedia Documents and extract cultural concepts, afterwards images are retrieved from Google Images, and finally QA pairs are generated, containing 3 QA types: Image, Recognition, Cultural Knowledge and Scene Understanding. The authors also propose CultureVLM, which are VLMs that are finetuned on the proposed resource (CultureVerse) with the overall goal of improving the global cultural perception and understanding. The paper shows evaluations with multiple VLMs, showing that finetuning on CultureVerse improves the cultural understanding of the models, the authors perform multiple evaluations showing regional disparities, the relation of cultural understanding and model/data scale, generalization of cultural concepts and more."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "Paper Strenghs:\n1. The authors tackle the gap of the limited understanding of culture in VLMs, with a scalable method to gather data from different cultures and regions, which has been an issue in past works. Another strength is the creation of different types of questions to evaluate and improve the multicultural knowledge of VLMs from different aspects.\n2. Finetuning Models in CultureVerse helps the models to improve their cultural perception and cross-cultural generalization. The authors show improvements in different datasets such as CVQA and CulturalVQA showing improvements on both.\n3. The paper was well written and easy to read with broad evaluations and ablations."}, "weaknesses": {"value": "Paper Weaknesses:\n1. In section 3.1 - Image Retrieval, it is not really clear how the images were obtained, this was done manually or using directly some tool with Google Images? . On the other hand, the authors state that for each cultural concept 5 images are obtained, in my personal experience finding images specially for low-resource cultures is hard, so maybe the authors can clarify a bit more on this process. Also, how did you managed the situation with licenses, many images on the web are not free. (Which increase the difficulty of finding images related to a certain aspect of a culture), did you use specific webpages ?\n2. I think that a weakness is the human evaluation, the paper states that \"Annotators refined the questions and answers by removing redundant information and resolving any ambiguities to maintain clarity and accuracy\". I really think that you need specialized annotators for this, judging aspects of other cultures is hard for fixing QA pairs (even if you use google search), that is why works like CVQA works with people from all around the world for this type of validations, however I understand this limits scalability. On the other hand, the paper states that only 10 annotators were hired to do all this process, and due to the scale of the proposed corpus it's not really clear how this task was managed by only 10 annotators, which brings concerns of the quality of the validation. I would like to see the authors' point of view on this matters.\n3. Due to CultureVerse is a multimodal corpus, how does the model works when you do not give the image ?. A well know fact, is that VLMs over-rely on text. In page 20, the authors show examples of the corpus, the questions on Image Recognition and Cultural Knowledge   seems to always refer to the image, which is good, but in the case of Scene Understanding (first example: \"In a theatrical performance...\"), the question is not directly referring to the image, so the VLM can rely entirely on the text, perform the reasoning and answer the question. If there is enough time, it would be good to see performances when the images are not given to the models, even if is for one model.\n4. Only as a suggestion if the authors agree, when I saw figure 2a the first time, it gives the impression that Asia contains only Landmarks, or that cultural knowledge is coming only from Europe. So a better design for this graph could be considered to give a better understanding."}, "questions": {"value": "Please refer to Weaknesses for my question and doubts. Overall I think the paper brings good contributions, so I'm currently giving it borderline accept, but I would like to see the responses of the authors on my concerns, and sorry if I misunderstood something. After Rebuttal I will revise my decision."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Snz1QN8BMZ", "forum": "IOgqcspZdR", "replyto": "IOgqcspZdR", "signatures": ["ICLR.cc/2026/Conference/Submission20665/Reviewer_2WM5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20665/Reviewer_2WM5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20665/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761897870451, "cdate": 1761897870451, "tmdate": 1762934053370, "mdate": 1762934053370, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces CultureVLM, a series of vision–language models fine-tuned on CultureVerse, a new large-scale multimodal dataset covering 188 countries, 15 cultural topics, and over 19,000 cultural concepts. The dataset includes three types of tasks—image recognition, cultural knowledge, and scene understanding—and aims to measure and improve VLMs’ cross-cultural generalization. Experiments on 16 models show that CultureVLM enhances cultural awareness while maintaining general capabilities on other VQA benchmarks. Analyses reveal regional disparities (Western bias) and demonstrate that fine-tuning on CultureVerse mitigates them, particularly for Asia and Africa."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- CultureVerse substantially expands geographic and conceptual coverage beyond existing datasets such as MaRVL, CVQA, CulturalVQA, and ALM-Bench, reaching near-global representation.\n- The authors evaluate 16 models across tasks, regions, and cultural categories, offering an unusually systematic view of cross-cultural disparities.\n- The paper provides ablations on fine-tuning size, generalization across continents and categories, and catastrophic forgetting, which strengthens the empirical contribution.\n- The paper addresses fairness and inclusion in multimodal AI, highlighting performance gaps for low-resource regions."}, "weaknesses": {"value": "- Reliance on Wikipedia and GPT-generated questions. These sources risk reinforcing the same Western-centric biases the paper seeks to mitigate; the authors should better quantify how much content originates from non-Western data and how QA quality varies by region. Moreover, since native annotators from nearly 200 regions were not available, annotators relied on Google and Wikipedia to infer correctness. This may reproduce Western-centric biases and limit true cultural authenticity. The authors could at least acknowledge this limitation or complement it with small-scale native validation for underrepresented regions.\n\n- Evaluation metrics. Accuracy alone may not capture the subtlety of cultural understanding and reasoning. Alternative or human-evaluated metrics could strengthen validity. It would also be great if you could elaborate further on how you evaluate the cultural stepwise reasoning process in the recognition tasks. It seems you only evaluate the model's multiple-choice selection and not the reasoning process. How do you ensure the reasoning process is indicative of the output? Also, in the cultural knowledge questions, you mention that reasoning is required, but I do not see how reasoning is involved in this task. Could you further elaborate and provide an example? There is also an inconsistency, as in lines 374-375, you mention stepwise reasoning as a prompt method for the image recognition task, and in the appendix (lines 859-860), you mention it for cultural knowledge and scene understanding questions. \n\n- Reproducibility and filtering pipeline. The dataset construction process involves multiple stages (entity extraction, LLM question generation, filtering), but the filtering criteria are not well quantified. What proportion of automatically generated samples were discarded or corrected? How were duplicates or culturally ambiguous examples handled? The absence of these statistics limits reproducibility and makes it difficult to assess dataset quality or coverage.\n\n- Dataset transparency and annotation quality. While Appendix D.1 offers a general overview of the annotation process, it omits key quantitative and reproducibility details. The paper should report the cultural background of the annotators, inter-annotator agreement, annotation guidelines, and procedures for logging evidence, and discuss potential Western bias introduced by relying solely on non-native annotators verifying cultural content through search engines and Wikipedia. Recent work has shown that in known computer vision benchmarks where crowdsourced annotators were employed, there were cultural implicatures that were difficult for them to identify and were later extracted by annotators with culture-specific backgrounds [Karamolegkou et al., 2024](https://aclanthology.org/2024.hucllm-1.5/)."}, "questions": {"value": "- How do you ensure that the QA pairs generated by GPT-4o reflect authentic cultural knowledge rather than textual stereotypes? Was any cross-validation with native annotators performed? \n\n- Can you provide statistics on the proportion of non-English Wikipedia documents or local-language sources included per region?\n\n- Since “scene understanding” involves context-sensitive reasoning, how is ambiguity resolved when multiple answers might be culturally plausible?\n\n**Comments**\n\n- In Figure 4, you should specify in the caption what performance (%) indicates. You should also specify what the readers see in a, b, c, d. \n\n- In lines 859-861, you mention that you use stepwise reasoning for cultural knowledge and scene understanding questions, while in lines 373-374, you mention that you perform stepwise reasoning in the recognition tasks. Please clarify the prompting setups for each task.\n\n- The authors state that the dataset “will be governed through protocols and licenses” but do not specify which protocols or licenses (e.g., CC-BY, CC-BY-NC-SA, or data-use agreements). Providing this information would clarify how the community can legally and ethically use CultureVerse and ensure compliance with open-science standards."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lTsjLPUQze", "forum": "IOgqcspZdR", "replyto": "IOgqcspZdR", "signatures": ["ICLR.cc/2026/Conference/Submission20665/Reviewer_pyUY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20665/Reviewer_pyUY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20665/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959777101, "cdate": 1761959777101, "tmdate": 1762934052600, "mdate": 1762934052600, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors develop a scalable data collection pipeline to collect CultureVerse, a multimodal dataset of culturally diverse images from 188 countries with English language questions (image recognition, cultural knowledge and scene understanding) covering 15 cultural topics.  The scale of the resulting corpus supports both model fine-tuning (producing CultureVLMs) and benchmarking (through a test set where the automatically generated questions were verified by humans).  They find that in general, VLMs exhibit regional disparities in cultural understanding, performing better on the Americas and less well for Asia and Africa.  This gap is narrowed through fine-tuning on CultureVerse."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The authors explore an urgent need in VLM development: multicultural awareness.\n\nTheir automated cultural knowledge extraction pipeline is able to handle more countries than existing datasets.\n\nThe authors are fairly robust in their evaluation – in particular, I liked their inter-culture / inter-region correlation experiments and their experiments that validate adaptation of their dataset to existing cultural understanding benchmarks like CVQA."}, "weaknesses": {"value": "### Reliance on Wikipedia to source cultural concept examples\n\nCultureVerse is extremely dependent on Wikipedia (in particular, English-language Wikipedia) for identification of country specific examples of its chosen cultural concepts.  While understandable, this means that it inherits the same limitations that Wikipedia exhibits by construction.  Of these limitations, the most critical are Wikipedia’s cultural biases which have been documented in work like https://arxiv.org/pdf/2305.14456.  Can the authors speak to this at all?  \n\n### Reliance on GPT4o instead of native representatives of each country / culture\n\nWhile I am sympathetic to the need for scalable methods for automatically constructing a training dataset, I am nervous about the tremendous reliance on GPT4o in the construction of CultureVerse’s test set.  GPT4o is used to 1) filter out cultural concepts examples that lack distinct regional specificity, 2) generate comprehensive descriptions of country-specific cultural concept examples with information like location, characteristics, history and cultural significance and 3) formulate questions based on this GPT4o-generated cultural concept information.  \n\nThe authors cite Li et al 2024c as arguing that GPT4o shows strong performance for text-based cultural understanding but 1) I am not sure that paper actually shows that -- could the authors cite relevant lines? and 2) by construction it would seem this benchmark has an implied ceiling of GPT4o’s cultural awareness which has been shown to be lacking in other work (e.g. ALM-Bench, CVPR 2025).  Can the authors speak to this at all?\n\t\t\nMoreover, though the authors perform a manual review of their test set, this review is not conducted by native representatives of each country / culture.  Would these reviewers actually be able to catch errors in cultural knowledge introduced by GPT4o?  In several places (line 77, 163, 240, 244, 299-300) the authors refer to these reviewers as “expert” but it would seem they are not country / culture experts so much as they are trained on their annotation pipeline.  I would strongly encourage the authors to use a different term to describe them as currently the paper gives the impression that they are culture experts\n\nAs such, it would seem that CultureVerse is best suited as a fine-tuning corpus for evaluating VLMs on other cultural understanding benchmarks (as they do in their results on CVQA / CulturalVQA) rather than as a benchmark on its own.  Otherwise the community runs the risk of perpetuating the biases of GPT4o if it becomes a widely targeted leaderboard.\n\n### Novelty\n\nRelatedly, the past few years have seen the introduction of several new benchmarks for evaluating the cultural understanding of vision-language models.  Many of these benchmarks, like ALM-bench (CVPR 2025), are multilingual and involve native representatives of their selected cultures in their construction.  While CultureVerse is larger in scale, quality seems more important than quantity when discussing benchmarks.  Can the authors motivate the marginal value of CultureVerse compared to these other benchmarks in a more quantitative fashion?  Assuming the GPT4o-related concerns with CultureVerse described above have been addressed, it would be interesting to see model performance correlation on CultureVerse versus existing benchmarks like ALM-bench – are the benchmarks testing for different kinds of cultural understanding? \n\n### Nitpicks / Typos\n\n- line 131: “face more severe situation”\n- line 157: “particularly FOR underrepresented groups”\n- line 303: “regions with more countries yield larger datasets” – there are more countries in Africa than any other continent yet this region is among the smallest; as this is likely due to the limitations of Wikipedia (see above), it would be good to say so here as the rationale rather than merely country counts\n- line 307: “multimodel”\n- line 338: “pose challenges for comparable VLMs”\n- line 341: “relies heavily on diverse and relevant image data” – can you add a citation for this?  perhaps https://proceedings.neurips.cc/paper_files/paper/2024/hash/c07d71ff0bc042e4b9acd626a79597fa-Abstract-Conference.html or some other\n- line 370: “cultural knowledge often resides in a model’s memory, an aspect overlooked in VLM development” – can you add a citation for this?  perhaps https://arxiv.org/abs/2406.11665 or some other"}, "questions": {"value": "I found it curious that the authors chose to reserve the first image of each country-specific cultural concept for the test set (in particular, for the more common cultural concepts).  Does that mean that examples of every country’s specific cultural concepts (like sari) in its test set are also seen during training?  Why not hold out some concepts to test generalization?  If there’s examples of every class type in the training dataset, the benchmark becomes more of an image label learning benchmark than a cultural understanding benchmark.  \n\nTo what degree is GPT-4o favored in this evaluation due to its core role in the construction of this corpus?  Would it be possible to re-run the pipeline for a subset of the test set and use Gemini instead of GPT-4o to measure this effect?\n\nIn Figure 5a, it would be nice to see the scores pre fine-tuning right now as it’s hard to make sense of the transferability without that baseline to compare against. \n\nSome missing references:\n- From Local Concepts to Universals: Evaluating the Multicultural Understanding of Vision-Language Models (EMNLP 2024)\n- Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset (EMNLP 2022)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hJBxi9pxrK", "forum": "IOgqcspZdR", "replyto": "IOgqcspZdR", "signatures": ["ICLR.cc/2026/Conference/Submission20665/Reviewer_AuDx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20665/Reviewer_AuDx"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20665/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988012950, "cdate": 1761988012950, "tmdate": 1762934051964, "mdate": 1762934051964, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces CultureVLM, a framework for characterizing and improving cultural understanding in Vision-Language Models (VLMs). The authors develop CultureVerse, a large-scale multimodal cultural dataset covering 188 countries/regions, 15 cultural topics, and 228K samples across three question types: image recognition, cultural knowledge, and scene understanding. The paper evaluates 16 VLMs and demonstrates significant regional disparities in cultural understanding, with models performing best on Western cultures (Americas, Europe) and worst on Asian and African cultures. The authors fine-tune several models on CultureVerse, showing improvements in cultural understanding while maintaining general capabilities."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **Timely and Socially Significant Problem Formulation**  \nThe work addresses a pressing gap in multimodal AI - the lack of cultural inclusivity in models. As prior studies highlight, most LLMs and VLMs align strongly with Western cultural norms.\n\n- **Comprehensive Dataset Construction Framework**  \nThe CultureVerse pipeline is clearly described and methodologically coherent. The combination of automated Wikipedia scraping followed by concept refinement and multi-tiered QA ensures scalability while maintaining reasonable data quality.\n\n-  **Thorough Experimental Analysis**  \nThe paper provides extensive analysis across multiple dimensions - regional disparities, task characteristics, model scaling effects, and generalization capabilities. The finding that cultural understanding doesn't scale linearly with model size (e.g., Llama 3.2-11B matching Qwen 2-72B performance) is particularly noteworthy."}, "weaknesses": {"value": "- **Methodological Concerns with Dataset Construction**\nThe heavy reliance on GPT-4o for concept extraction and question generation raises concerns about systematic biases being embedded in the dataset. While the authors claim GPT-4o has \"strong performance for text-based cultural understanding,\" this assertion lacks adequate validation. Recent work has shown that even advanced LLMs exhibit cultural biases , potentially propagating these biases into the benchmark.​​  \n\n- **Evaluation Methodology Limitations**      \nThe exclusive use of multiple-choice questions limits the assessment of nuanced cultural understanding. The authors acknowledge this limitation but don't adequately address how this format may not capture the complexity of cultural competence. Some more fine-grained evaluations would strengthen the work.\n\n- **Insufficient Analysis of Data Quality**   \n While the authors report high accuracy rates for automated annotations (93-99%), the validation is based on only 10 human annotators with limited cultural expertise. The paper lacks detailed analysis of inter-annotator agreement or validation across diverse cultural perspectives. This is particularly concerning given the global scope of the dataset.  \n\n- **Lack of fine-grained analysis**    \nThe finding about regional disparities, while important, is not surprising given known biases in training data. The paper would benefit from deeper analysis of why these disparities exist and how they can be systematically addressed.​"}, "questions": {"value": "Please refer to the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "i8NMNgMFOs", "forum": "IOgqcspZdR", "replyto": "IOgqcspZdR", "signatures": ["ICLR.cc/2026/Conference/Submission20665/Reviewer_sbZ9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20665/Reviewer_sbZ9"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20665/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761999011421, "cdate": 1761999011421, "tmdate": 1762934051504, "mdate": 1762934051504, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}