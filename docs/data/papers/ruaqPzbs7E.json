{"id": "ruaqPzbs7E", "number": 5311, "cdate": 1757898894268, "mdate": 1759897981858, "content": {"title": "Rethinking Shapley Value for Data Contribution", "abstract": "Shapley value is a principled and widely used framework for data valuation in machine learning. However, its application has led to a critical, yet often overlooked, conceptual confusion between the value of a data point (its average utility across all subsets) and its specific, structural contribution (its role in shaping the final model). This conflation is problematic since valuation scores that are strongly influenced by small subsets may not reliably indicate the true contribution of a data point. To resolve this, we propose a framework designed to directly measure structural contribution. Our method modifies the Shapley formulation by 1) using a similarity-based utility function to capture impact on the global model structure, and 2) applying a Beta-weighting scheme to prioritize larger, more stable subsets. Experiments on SVMs show our method more accurately identifies support vectors, which serve as the ground truth for contribution, outperforming standard Shapley-based approaches in both precision and recall. This approach also shows strong performance in data pruning tasks and is applicable to broader probabilistic models. Our work provides not just a new method, but a clearer conceptual framework to distinguish the valuation of a data point from its true contribution.", "tldr": "", "keywords": ["data valuation", "data contribution", "shapley values"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b14c33ec1d3355ea26cf7304bc68bc40a984c536.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "An observation is made:  the accuracy combined with the Shapley value  might not well represents how a point from a set drives the model structure. The solution proposed is to change the utility and the semi-value. Compare the model trained on the full dataset against what we  get with a subset of it, then use a semi-value that put more weights on the large coalitions."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The paper is timely, and the idea of proposing a specific metrics for the impact on the final model structure is of interest."}, "weaknesses": {"value": "I however regret the lack of analysis as well as too poor arguments. \nThe presentation is not precise enough with the notion introduced. \nMany paragraphs are too vague. Valuations and contributions are claimed to be different, but not defined. \nThe usage of true and truly reflects this vagueness: \"the true X\" is not a well formed, unambiguous mathematical statement. \nIn a well defined context, one should be able to just say \"X\". This pattern is repeated many times in the paper. \nThe theoretical properties are mostly direct consequences of the definitions."}, "questions": {"value": "1. Can you provide a definition of contribution?\n2. It seems that you suppose that the value is always increasing in a cooperative game, are you? Is it? \n3. What is the \"true role\" of a data point?\n4. In example 2 of table 1, C plays the same role as A and B if we exclude the singletons, so can you elaborate on why this is a paradox? \n5. Why not using directional derivatives instead of Beta_weighted semi-value, if you are only interested in the final model? \n6. Is your redefinition of the KL (with the epsilon) standard?\n7. Can you provide more argument on why the final model should be the target? Suppose for instance that half the points have a bad impact on the accuracy, and half the points a good impact, then maybe what we want is to know that the bad points are bad? \nProbably what could help me would be a use case for your methodology. What are the downstream tasks you envision for your valuation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fnRUCVi3vD", "forum": "ruaqPzbs7E", "replyto": "ruaqPzbs7E", "signatures": ["ICLR.cc/2026/Conference/Submission5311/Reviewer_9sCH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5311/Reviewer_9sCH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5311/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761570359006, "cdate": 1761570359006, "tmdate": 1762918000915, "mdate": 1762918000915, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a novel framework for measuring data point contribution, developed to address the conflation of data valuation and structural contribution in traditional Shapley value methods. The authors propose a new methodology using a similarity-based utility function and a Beta-weighting scheme, and evaluate its effectiveness on data pruning tasks to identify critical data points."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1、The paper's distinction between data valuation and structural contribution addresses a key limitation in traditional Shapley-based methods.\n2、The method is grounded in a solid theoretical foundation by combining cooperative game theory with model similarity metrics.\n3、The framework's efficacy is demonstrated through well-designed experiments showing superior performance in data pruning tasks."}, "weaknesses": {"value": "1、The validation's exclusive reliance on SVMs creates a risk of circular reasoning, as it benchmarks against support vectors—the very structural elements the method is designed to identify. This narrow empirical scope fails to substantiate the framework's claimed generalizability.\n2、The complete omission of a computational cost analysis is a critical oversight for a Shapley-based method. This absence makes it difficult to evaluate the framework's practical scalability and viability for larger-scale problems."}, "questions": {"value": "1、The validation is currently limited to SVMs, which have a clear ground truth in support vectors. Could the authors extend their experiments to include more diverse model architectures, particularly deep neural networks? This would require providing quantitative results and explaining the evaluation protocol used to measure \"structural contribution\" in the absence of a direct analogue to support vectors.\n2、The paper lacks sifficient analysis of computational cost, which is critical for Shapley-based methods. Could the authors provide a complexity analysis or empirical runtime comparisons against baseline methods on identical hardware to assess the framework's practical scalability?\n3、The framework is designed to separate \"valuation\" from \"contribution.\" Could the authors discuss the potential trade-offs of this separation? Specifically, are there scenarios where a data point with high general utility (valuation) might be assigned a low score if it is not structurally critical to the final model, and would this be a desirable outcome?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "EZnBVEbqcL", "forum": "ruaqPzbs7E", "replyto": "ruaqPzbs7E", "signatures": ["ICLR.cc/2026/Conference/Submission5311/Reviewer_BtCs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5311/Reviewer_BtCs"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5311/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761726070098, "cdate": 1761726070098, "tmdate": 1762917999930, "mdate": 1762917999930, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "**Paper**: *Rethinking Shapley Value for Data Contribution* (ICLR under review).  \n**Core idea**: The paper argues that *data valuation* (average utility across all subsets) is not the same as *data contribution* (a point’s role in shaping the final model). It proposes a semivalue-style framework that (i) replaces accuracy-based utilities with **similarity-based utilities** that align subset models to the full model—specifically, **symmetric KL** over predictive distributions and an RKHS-based functional similarity—and (ii) reweights marginal contributions to **emphasize large coalitions** (e.g., Beta(1,8)) so that scores better reflect stable, full-model behavior. Empirically, the method concentrates value on true support vectors and correlates more strongly with SVM dual coefficients \\(|\\alpha_i|\\), improving SV identification metrics over accuracy-based Shapley/Banzhaf baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- **Clear problem framing.** The paper crisply separates *valuation* from *contribution* and explains why small subsets can distort contribution estimates.\n- **Well-motivated utilities.** The **symmetric KL** utility captures fine-grained distributional differences between full vs. subset models; the paper gives a local second-order expansion that clarifies its sensitivity. The RKHS option provides a functional alignment view.\n- **Principled weighting.** Using **Beta weights** to emphasize large coalitions (e.g., Beta(1,8)) is positioned as complementary to prior “small-subset-focused” semivalues (e.g., Beta Shapley), aligning better with stable full-model behavior.\n- **Evidence consistent with goals.** The method concentrates value on *support vectors* and shows stronger correlation with SVM dual coefficients \\(|\\alpha_i|\\), indicating better structural alignment than accuracy-based baselines."}, "weaknesses": {"value": "1) **Critical related work is omitted, overstating novelty.**  \nThe manuscript does not discuss *On the Inflation of KNN Shapley*, a closely related work that **explicitly diagnoses small-subset–induced inflation** and proposes a **subset-size remedy**, which is highly aligned with this paper’s central motivation (mitigating small-subset artifacts). This omission leaves readers without a clear picture of how the present approach differs in assumptions, guarantees, or empirical behavior, and risks **overclaiming novelty**.  \n\n\n2) **Lack of large-scale, deep-learning evaluations.**  \nDespite solid small/medium-scale evidence, the paper lacks **end-to-end deep-model** or **large-dataset** experiments that stress test scalability and practical value (e.g., modern vision/text benchmarks, pretrained encoders, or full-network training). Without these, it is hard to judge external validity and deployment readiness."}, "questions": {"value": "Same with weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IPCsuNkxgx", "forum": "ruaqPzbs7E", "replyto": "ruaqPzbs7E", "signatures": ["ICLR.cc/2026/Conference/Submission5311/Reviewer_dLM4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5311/Reviewer_dLM4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5311/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968098014, "cdate": 1761968098014, "tmdate": 1762917999500, "mdate": 1762917999500, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the data valuation/contribution problem, where the authors highlight out a conceptual confusion caused by the classical Shapley value concept, that is, the average marginal utility of a data point across all subsets, versus its specific structural contribution in shaping the final model (though this might be a bit of “over-claiming” since recent works on data valuation already accounts for this issue – see detailed comment below). \n\nThe authors proposed to replace the accuracy utility function with a similarity-based utility function (RKHS-based function similarity for SVM models, and also model agnostic KL-based similarity for general model probability outputs). In addition, the authors proposed to prioritize larger, more stable subsets’ marginal utilities, which represents a different weighting scheme from standard Data Shaprly and its variants like Beta-Shapley and Banzhaf value. Finally, the authors show experimental results for SVM on different benchmark datasets comparing the proposed method with the classical Shapley value method, and original Beta Shapley value method, and the Banzhaf value method. Experimental results show that the proposed method can effectively assign higher values to support vectors, and keeping valuable points in a removal by ascending values experiment."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper is generally well written and proposes an interesting research idea, which distinguishes the average marginal utility from the specific structural contribution of a data point. They propose a new variant of Shapley value via similarity-based utility function, together with the Beta-weighting scheme, and show its effectiveness in SVM. The experimental results show that the model can maintain accuracy after removing 80% of the data, which shows some interesting practical implications, such as in the area of data pruning can be explored with the results from this paper."}, "weaknesses": {"value": "In my opinion, there are a few major limitations. \n\nFirst, the idea of distinguishing data’s value and its “structure contribution” is already there in the literature. This seems to significantly reduce the novelty of this paper’s core motivation “…application has led to a critical, yet often overlooked, conceptual confusion between the value of a data point (its average utility across all subsets) and its specific, structural contribution (its role in shaping the final model)”, and made this statement a little bit over-stated. For example, an example among a few other recent works is “An Instrumental Value for Data Production and its Application to Data Pricing” by [Ai et al., ICML’25], though they call   “structural contribution” the “instrumental value” instead -- however, conceptually these are similar. Moreover, through economic analysis about valuation and contribution, the above ICML  paper arrived at a valuation function that, essentially, put all weight on the largest subset. This paper’s re-weighting approach can be viewed as a “Beta-smoothed” version of that.  \n\nSecond, the proposed approach is based on some interesting observation, but it lacks solidness and novelty, especially given that the idea of carefully weighting different data subsets with different weights in order to account for some limitations is already extensively explored, and led to a few variants already. It seems to me this is just an additional variant to that literature. In fact, it feels like even the novelty of the re-weighting idea appears somewhat overstated to me. It seems to me, compared to Beta Shapley (Kwon & Zou, 2022),  the only real difference is the parameter choice (beta > alpha instead of alpha > beta), which flips the bias from small to large subsets (though I know this paper also proposed a different valuation function).\n\nThird, the experiments are limited to support the claim that the method is model-agnostic. Specifically, results are only shown for SVMs and one logistic regression test on the Wine dataset. Besides the neural network models omitted by authors due to “prohibitive retraining (Line 466)”, there are no results on other common simple models like random forests or even decision trees, which are easy to retrain and help demonstrate contribution in more diverse settings. Even with logistic regression, experimental results on more than just the Wine dataset would make the model-agnostic claim stronger. This leads to significant concern about the broad applicability of the proposed approach, especially that I do not see any intuition that it would work for other ML models, particularly today’s large auto-regressive model or diffusion models, where it seems every piece of data matters. \n\nForth, some of the theoretical results are relatively straightforward. For instance, Theorem 4.3 seems straightforward – if we have larger value for all subsets with size at most m, then putting “sufficiently large” weights on these size surely will make the averaged value larger.  It seems to me a more interesting statement might be, for what parameter sets of your chosen Beta distribution, it will lead to larger value for i.    \n\nFifth, another weakness is, in the experiments, one major missing data valuation method is the leave-one-out (LOO) baseline, which directly estimates a data point’s marginal contribution when removed from the full training set. This is an extreme case of large subset emphasis that aligns with the authors’ goals. Also this baseline was explicitly included in the original Beta Shapley work (Kwon & Zou, 2022) as a comparison, but it is entirely absent here, with no discussion or justification for its exclusion."}, "questions": {"value": "How does varying these two parameters (i.e., other values other than Beta(1, 8) but keeping beta > alpha) affect the algorithm’s performance? It would be helpful to provide some results when varying these two parameters.\n\nHow do all other algorithms perform on the sorted Shapley value experiment (i.e., Figure 1) of each data point? It seems only Standard Shapley and Beta(1,8)-kl are presented. Also, is there an explanation for the tail elements always being support vectors?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GVxlqz9S5R", "forum": "ruaqPzbs7E", "replyto": "ruaqPzbs7E", "signatures": ["ICLR.cc/2026/Conference/Submission5311/Reviewer_ogdD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5311/Reviewer_ogdD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5311/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762008320938, "cdate": 1762008320938, "tmdate": 1762917999176, "mdate": 1762917999176, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}