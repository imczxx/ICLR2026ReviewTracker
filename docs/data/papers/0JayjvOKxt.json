{"id": "0JayjvOKxt", "number": 16981, "cdate": 1758270901913, "mdate": 1759897206393, "content": {"title": "When and Where to Reset Matters for Long-Term Test-Time Adaptation", "abstract": "When continual test-time adaptation (TTA) persists over the long term, errors accumulate in a model and further lead it to predict only a few classes regardless of the input, known as model collapse. Recent studies have explored reset strategies that erase these accumulated errors completely. However, their periodic resets lead to suboptimal adaptation, as they occur independently of collapse. Also, their full resets cause the catastrophic loss of knowledge acquired over time, even though it could be beneficial in future. To this end, we propose 1) an Adaptive and Selective Reset (ASR) scheme that dynamically determines when and where to reset, 2) an importance-aware regularizer to recover essential knowledge lost from reset, and 3) an on-the-fly adaptation adjustment scheme to enhance adaptability under challenging domain shifts. Extensive experiments across long-term TTA benchmarks demonstrate the effectiveness of our approach, particularly under challenging conditions. Our code will be released.", "tldr": "", "keywords": ["Test-Time Adaptation", "Continual Test-Time Adaptation"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/504c73f24c6ccca26313babd1bdf7dfd05964f6b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes the Adaptive and Selective Reset (ASR) scheme to address the problem of model collapse in long-term Test-Time Adaptation (TTA). The main contributions are: 1) The ASR mechanism dynamically determines when and which parts of the model to reset; 2) An importance-aware knowledge recovery regularizer based on Fisher information; 3) Dynamic adjustment of hyperparameters according to domain differences to enhance adaptability. Experiments show that ASR performs well in multiple benchmark tests and significantly improves the stability and adaptability of the model."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear Structure: The article is well-organized with distinct logical sections, progressing from introduction to methodology and then experiments, which allows readers to easily grasp the research content and contributions.\n\n2. Professional Expression: Accurate terminology, rigorous mathematical formulas, and clear presentation of charts and experimental results enhance the article's scientific validity and readability.\n\n3. Dynamic and Selective Reset Mechanism: The ASR scheme dynamically determines the timing and scope of resets, effectively preventing model collapse while minimizing knowledge loss.\n\n4. Enhanced Comprehensive Adaptability: By integrating knowledge recovery and dynamic adjustment mechanisms, ASR improves the model's adaptability in complex environments and achieves outstanding performance."}, "weaknesses": {"value": "1.The author aims to address the challenge of model collapse in long-term TTA. The proposed ASR module triggers resets based on the concentration of predicted classes. However, there is an issue here. In long-term TTA, model collapse can lead to increased concentration of predicted classes. Yet, in real-world scenarios, such increased concentration could stem from various factors. For instance, the distribution of test data is often non-stationary and imbalanced. Test data may temporarily concentrate on a few classes over time, which is not due to any issue with the model itself. The author needs to analyze this aspect.\n\n2.In Section 3.2, the calculation of prediction concentration seems to indicate that a higher value corresponds to lower class prediction concentration. However, the reset criterion set by the author is that prediction concentration is higher than cumulative concentration. Is there an error here? The author is advised to double-check."}, "questions": {"value": "It is suggested that the author, when addressing the issue of when to reset, should first rule out other non-model factors that may cause the predicted classes to concentrate on a few categories."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BK9O8JKWTr", "forum": "0JayjvOKxt", "replyto": "0JayjvOKxt", "signatures": ["ICLR.cc/2026/Conference/Submission16981/Reviewer_8GCC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16981/Reviewer_8GCC"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16981/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761107471350, "cdate": 1761107471350, "tmdate": 1762926997803, "mdate": 1762926997803, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of model collapse in long-term continual test-time adaptation (TTA) due to error accumulation. The authors propose an Adaptive and Selective Reset (ASR) scheme that dynamically determines when to reset by monitoring prediction concentration and where to reset by selectively resetting layers based on the estimated collapse risk. The method is supplemented by an importance-aware regularizer to recover lost knowledge and an on-the-fly mechanism to adjust adaptation based on domain discrepancy."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The primary strength is the novel ASR mechanism, which offers a more motivated and flexible alternative to naive periodic resets by dynamically linking the reset trigger and scope to a quantifiable measure of model collapse (prediction concentration). This adaptive approach is intuitive and addresses a clear limitation of prior work. The method is validated by extensive experiments on long-term TTA benchmarks, demonstrating significant performance gains, particularly on the challenging CCC-Hard dataset."}, "weaknesses": {"value": "1. The definition of \"prediction concentration\" (Eq. 1), which is central to the reset trigger, is based on the entropy of average logits. This metric seems sensitive to factors not fully explored: it's unclear if it's robust to logits of different magnitudes, and its dependency on batch composition (batch size, class distribution) is a concern. Furthermore, the supporting correlation in Figure 3 lacks context, as the dataset and settings used to generate it are not specified. \nMoreover, the paper's justification for the method's effectiveness (e.g., Line 474) relies on the assumption that TTA models \"strengthen predictive confidence\" for the imbalance label setting. This holds for entropy minimization methods but not necessarily for all TTA strategies. This raises a significant question about whether ASR can reliably detect collapse in models using other objectives, such as consistency regularization, potentially limiting its applicability.\n\n2. While the \"importance-aware knowledge recovery\" component is intended to address catastrophic forgetting, the experiments lack direct evidence of its efficacy. In recurring domain scenarios (e.g., IN-C 20 visits), it is not shown whether the model effectively re-utilizes previously learned knowledge from a specific domain or simply re-adapts more successfully from a cleaner reset state.\n\n3. The comparisons in Table 1 are difficult to interpret. As ASR is presented as an add-on component, it's unclear if it should be compared only against RDumb or also against other SOTA add-ons like COME (which is listed but not directly compared, e.g., COME+ETA vs. ASR+ETA). To validate its general utility, ASR should be evaluated on a broader range of base TTA methods, particularly those utilizing different objective functions beyond ETA and ROID.\n\n4. The evaluation benchmarks (like CCC and CIN-C) primarily feature slow and predictable domain changes. I'm wondering if we reset the model every time the domains change (i.e., exactly at the domain boundary), is this performance an upper bound for ASR or RDumb? (e.g., in Figure B.1, which is CIN-C)  Furthermore, this raises questions about the method's robustness in more dynamic environments, where it's unclear if it would still reset appropriately when the domain changes faster, or if frequent resets would degrade adaptation performance. Evaluating on a more dynamic benchmark, such as the CDC setting from DPCore, would be a valuable test."}, "questions": {"value": "1. In Figure 2, what do the numbers, icons, and the different colors in the top bar represent? A legend would be helpful.\n\n2. The paper states hyperparameters were tuned on a small holdout from CCC-Hard (Line 310). Were these exact same hyperparameters then used for all other datasets and settings (CIN-C, IN-C, IN-D109, non-i.i.d.)?\n\n3. A general question about resetting. How would a parameter-reset method like ASR be applied to TTA methods that do not primarily adapt the model parameters, such as prompt-based methods (e.g., FOA, DPCore)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WxBWCfdJ4p", "forum": "0JayjvOKxt", "replyto": "0JayjvOKxt", "signatures": ["ICLR.cc/2026/Conference/Submission16981/Reviewer_wwgg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16981/Reviewer_wwgg"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16981/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761454580233, "cdate": 1761454580233, "tmdate": 1762926997339, "mdate": 1762926997339, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles long-term continual TTA, where models suffer from error accumulation and eventual collapse (predicting only a few classes). The authors propose:  1. Adaptive and Selective Reset (ASR) — dynamically determines when and which layers to reset based on prediction concentration, mitigating both over- and under-resetting. 2. Importance-aware knowledge recovery — recovers lost information post-reset using Fisher-based regularization with a hybrid (CMA + EMA) accumulation scheme. 3. On-the-fly adaptation adjustment — adaptively adjusts according to prediction inconsistency between the source and the current model. Extensive experiments on CCC, CIN-C, IN-C, and IN-D109 show large gains over prior TTA methods (e.g., +44.12% on CCC-Hard)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The studied problem of when and where to reset is a very practical problem, and it is a key step to enhance the stability of TTA under long-term and large-scale real-world application settings.\n\nThe proposed methods (from fixed or heuristic resets to a data-driven and risk-aware reset strategy) are simple yet effective.\n\nThe combination of adaptive reset timing, layer-wise selective reset, and Fisher-based knowledge recovery makes the overall method cohesive and effective."}, "weaknesses": {"value": "The proposed method involves many hyperparameters, making it potentially difficult to tune in real-world online testing scenarios. Could the authors clarify how these hyperparameters are determined and whether ASR is sensitive to them?"}, "questions": {"value": "How about the performance of more recent and advanced TTA methods, such as CMF, PeTTA, or ReCAP (Region Confidence Proxy for Wild Test-Time Adaptation, ICML 2025), when combined with ASR? Is ASR still effective in these cases?\n\nHow about the computational efficiency of the accumulated Fisher Matrix? More detailed analyses are preferred.\n\nI am also curious about the performance of ASR on lightweight backbones, such as ViT-Tiny or Swin-Tiny.\n\nIt would be more informative to replace Tables 3 and 4 with a unified figure showing results for a wider range of reset intervals (e.g., 2000, 4000, 6000) and reset ratios (e.g., 10%, 20%, 30%), enabling a more thorough sensitivity ablation analysis."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "e2pQ0EyV9j", "forum": "0JayjvOKxt", "replyto": "0JayjvOKxt", "signatures": ["ICLR.cc/2026/Conference/Submission16981/Reviewer_UtEd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16981/Reviewer_UtEd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16981/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761891130558, "cdate": 1761891130558, "tmdate": 1762926996605, "mdate": 1762926996605, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors investigate the problem of long-term continual test time adaptation. Previous algorithms were shown to collapse at some point during longer term adaptation, and simple resetting methods have been proposed as baselines in this problem setting. Full model reset like in RDumb naturally yields a substantial drop in downstream performance in the first steps after the reset, hence the authors propose an adaptive resetting scheme where the timing of these resets is adaptively computed, and instead of resetting the full model, only parts of the model parameters are reset to baseline. The authors show in multiple experiments vs. main baselines ROID and RDumb that their adaptive strategy yields performance improvements in the CCC and other continual adaptation benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- empirical performance of the proposed algorithm outperforms the considered methods\n- results are clearly presented, and the paper is easy to follow\n- considered experiments are well presented, relevant ablations performed"}, "weaknesses": {"value": "The method is overall incremental, and the components of the method are heuristic fixes to the collapse problem. The scientific depth of the study is limited; I see limited value between what is already known in the field. The method fundamentally does not overcome the issue that reset is required to prevent collapse in longer-term test-time adaptation.\n\nWhile there are certaintly gains over the state of the art, they seem marginal and the amount of engineering to get these 1%-point improvements makes it questionable if the simpler variants are also sufficient in practice."}, "questions": {"value": "1. Which empirically observed behaviors motivated the development of the different adaptation of the reset procedure? Can you make statements about sources of the collapse (as you allude to with Figure 3)\n2. Section 3.3:  \"recover essential knowledge lost\" and \"While parameters and their Fisher matrices increasingly align with the current domain, their proximity to reset makes them more vulnerable (...)\" -- is there empirical and theoretical evidence for these statements?\n3. Could you make the code for the algorithm available, will it be released under an open source license?\n4. Could you comment on additional hyperparameters that were introduced, and the robustness of the method under variations of these?\n5. Were the algorithms in e.g. Table 1 and other tables re-run for this paper, or are any number in the paper copied from previous papers?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zNnuh2kKTv", "forum": "0JayjvOKxt", "replyto": "0JayjvOKxt", "signatures": ["ICLR.cc/2026/Conference/Submission16981/Reviewer_CQqn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16981/Reviewer_CQqn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16981/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995531374, "cdate": 1761995531374, "tmdate": 1762926996131, "mdate": 1762926996131, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response"}, "comment": {"value": "We deeply appreciate your time and effort in reviewing our paper. We are currently revising the manuscript and will submit the updated version as soon as possible.\n\nThank you for your patience."}}, "id": "Llafd8rbfR", "forum": "0JayjvOKxt", "replyto": "0JayjvOKxt", "signatures": ["ICLR.cc/2026/Conference/Submission16981/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16981/Authors"], "number": 11, "invitations": ["ICLR.cc/2026/Conference/Submission16981/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763725981566, "cdate": 1763725981566, "tmdate": 1763726028628, "mdate": 1763726028628, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}