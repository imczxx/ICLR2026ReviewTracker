{"id": "QkHKaPfRAB", "number": 8194, "cdate": 1758073203015, "mdate": 1763620568650, "content": {"title": "ProSafePrune: Projected Safety Pruning for Mitigating Over-Refusal in LLMs", "abstract": "Large Language Models (LLMs) excel in various domains, but their safe deployment faces the challenge of balancing safety and utility. Existing alignment strategies often strengthen refusal mechanisms to reduce harmful outputs, but harmless instructions with superficial risky words are mistakenly rejected, which is known as over-refusal. \nThis work first reveals that over-refusal stems from a cognitive bias in the model's internal representation space: LLMs naturally encode safety attributes in hidden states, and pseudo-harmful instructions overlap with harmful features, causing over-harmful encoding. \nTo address this, we propose ProSafePrune, a subspace-projected low-rank parameter pruning framework for mitigating LLM over-refusal. By projecting pseudo-harmful features into subspaces and removing low-rank directions corresponding to harmful components in the most discriminative layers, we significantly reduce over-refusal while preserving the model’s ability to reject genuinely harmful requests, improving performance on general tasks. In experiments, across different models, our method significantly lowers the average false rejection rate while slightly improving general task performance.", "tldr": "", "keywords": ["LLM", "Safety", "Over-Refusal", "Alignment"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/78232aaf85f9333674e7a36d49b7e9b33ea44ac1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes ProSafePrune, a low-rank parameter pruning method to mitigate over-refusal in large language models. By identifying and pruning harmful components within pseudo-harmful subspaces, the approach reduces false refusals while preserving genuine safety. Experiments on multiple LLMs show improved compliance and balanced safety performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed method addresses an important and timely issue in LLM alignment with clear motivation and practical relevance.\n\n2. This paper proposes a lightweight, training-free pruning framework that is theoretically grounded and computationally efficient."}, "weaknesses": {"value": "1. The claimed “cognitive bias in internal representations” remains largely conceptual — the paper lacks deeper interpretability analysis or causal evidence supporting this mechanism.\n\n2. The proposed pruning relies on white-box parameter access, limiting applicability to real-world LLMs.\n\n3. The novelty is incremental, as the idea of subspace-based low-rank pruning has been explored ; this paper mainly repurposes it for the over-refusal context.\n\n4. While benchmarks show strong quantitative results, the evaluation misses human evaluation."}, "questions": {"value": "1. The paper attributes over-refusal to “over-harmful encoding” in internal representations. Could the authors elaborate on how this relates to recent work on safe unlearning? Conceptually, is ProSafePrune pruning a similar subspace that unlearning methods aim to erase, or does it operate on a different mechanism?\n\n2. How were the pruning hyperparameters (e.g., λ and rank r) selected, and how sensitive are the results to these choices?\n\n3. Would combining ProSafePrune with post-training alignment or inference-time steering further improve the safety–utility trade-off?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "n7Ud8uDwIx", "forum": "QkHKaPfRAB", "replyto": "QkHKaPfRAB", "signatures": ["ICLR.cc/2026/Conference/Submission8194/Reviewer_jCyL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8194/Reviewer_jCyL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8194/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760708593213, "cdate": 1760708593213, "tmdate": 1762920149905, "mdate": 1762920149905, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on mitigating over-refusal in LLMs. The authors argue that this behavior comes from harmful encodings overlapping with pseudo-harmful ones in the model’s latent space. To address this, they propose a training-free and subspace-based low-rank pruning method. The key idea is to use (truncated) SVD to identify and remove directions in parameter space that push pseudo-harmful instructions toward harmful representations while not compromising the model’s refusal and general abilities. Experiments across model scales in Llama and Qwen families show lower false rejection rates and stable safety performance, while maintaining or improving general-task performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. **Simple and elegant method.**\n- Low-rank pruning based on subspace overlap is lightweight and does not require retraining or inference-time overhead.  \n\n2. **Strong empirical results.**\n- Overall, the proposed method improves compliance on multiple pseudo-harmful benchmarks while maintaining safety on harmful ones (Table 1, Figure 4).  \n\n3. **Good theoretical evidence support.**\n- The energy-removal guarantee in Theorem 3.2 supports the claim that pruning minimally disrupts the model’s general capacity.  \n\n4. **Interesting insights connected to alignment tax.**\n- The additional experiments in Section 5.2 add conceptual depth to understanding how overly strong safety alignment can constrain model capabilities."}, "weaknesses": {"value": "1. **Suspiciously large gap on OR-Bench despite training on it.**\n- In Table 1, the proposed method shows promising performance on average, but for LLaMA‑3‑8B on OR-Bench the score (71.0) is far lower than Self-CD (86.0). Since the pseudo-harmful subspace is built using OR-Bench data, this is a bit suspicious and raises the question of whether the subspace construction is stable.\n\n2. **The results would be more robust with additional evidence.**\n- For example, confidence intervals or std errors for model performances for Table 1 and Figure 4, how pruning rank and λ are selected for Table 3, and potential evaluation on do_sample=True to give a better sense of the method’s stability under more realistic decoding settings.\n\n3. **Small evaluation samples.**\n- The model performances are reported on a few hundred examples per dataset (according to Section B.2), which has the concern that small fluctuations could produce the reported gains."}, "questions": {"value": "- Qualitative analysis on cases where the proposed method helps or hurts.\n- Submodule-level insight. The pruning is done on Q/K/V/O/MLP modules with no analysis on which parts of the network contribute most to improvements."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XHoUgGz1qD", "forum": "QkHKaPfRAB", "replyto": "QkHKaPfRAB", "signatures": ["ICLR.cc/2026/Conference/Submission8194/Reviewer_bZK9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8194/Reviewer_bZK9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8194/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761778846892, "cdate": 1761778846892, "tmdate": 1762920149162, "mdate": 1762920149162, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the over-refusal issue in LLMs, where harmless instructions are incorrectly rejected due to overlapping safety and harmful feature representations. The authors introduce ProSafePrune, a subspace-projected low-rank pruning framework that removes harmful components from key layers, effectively mitigating over-refusal while preserving genuine safety behavior and slightly improving overall task performance across various models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Addressing the over-refusal issue in LLMs through parameter subspace-projected low-rank pruning is a novel approach, and the extensive experiments convincingly demonstrate its effectiveness.\n\n2. The paper is well organized and clearly written, making it easy to follow."}, "weaknesses": {"value": "1. The advantage of the proposed parameter subspace low-rank pruning approach over representation editing in mitigating over-refusal in LLMs is not convincingly demonstrated. Incorporating additional theoretical analysis or interpretability-oriented empirical studies could strengthen the comparative argument and better substantiate the contribution of this work.\n\n2. The finding that the proposed framework does not degrade, and even slightly improves, the general capabilities of LLMs is intriguing. However, the underlying causes of this improvement remain unclear. A more in-depth discussion would help elucidate the underlying mechanisms of this phenomenon.\n\n3. The evaluation is currently limited to LLMs within the 7B–14B parameter range. Assessing the scalability and effectiveness of the proposed framework on larger models (e.g., Qwen3-32B, Llama-3.1-70B) would further validate its robustness and practical applicability."}, "questions": {"value": "1. The finding that the proposed framework does not degrade, and even slightly improves, the general capabilities of LLMs is intriguing. What do the authors consider to be the underlying causes of this improvement?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5qA51N9baI", "forum": "QkHKaPfRAB", "replyto": "QkHKaPfRAB", "signatures": ["ICLR.cc/2026/Conference/Submission8194/Reviewer_htFg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8194/Reviewer_htFg"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8194/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761946716946, "cdate": 1761946716946, "tmdate": 1762920148724, "mdate": 1762920148724, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ProSafePrune, a training-free framework designed to mitigate the \"over-refusal\" phenomenon in LLMs. The authors identify the root cause as a cognitive bias within the model's internal representation space, where pseudo-harmful instructions are \"over-harmfully encoded\". ProSafePrune uses subspace projection via truncated SVD to identify and prune low-rank components corresponding to harmful amplification directions in the most discriminative layers."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper shifts the focus from activation-level interventions to directly modifying the model parameters to mitigate the over-refusal phenomenon, which is a new direction.\n2. ProSafePrune consistently demonstrates superior performance across diverse LLMs (LLaMA-2/3) and a range of over-refusal benchmarks (OR-Bench, PHTest, XSTest, OKTest)."}, "weaknesses": {"value": "1. Sensitive to prune layers and hyperparameter lambda: From table 3 and figure 8, there is a close relationship between model performance and careful tuning of those hyperparameters. It is better to explain how ProSafePrune selects the prune layers since authors only claim high-scoring middle layers as candidates for pruning but without presenting the score threshold for selection.\n2. Unclear scalability: The experiments focus on models up to 14B parameters. It’s not clear how well the approach would scale to larger models that may have different internal representations.\n3. Lack of pruning time report: Although ProSafePrune employs once static pruning, it is better to report the time cost compared to those training-free baselines."}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3zl4oHasMQ", "forum": "QkHKaPfRAB", "replyto": "QkHKaPfRAB", "signatures": ["ICLR.cc/2026/Conference/Submission8194/Reviewer_QSHo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8194/Reviewer_QSHo"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8194/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762087410924, "cdate": 1762087410924, "tmdate": 1762920148340, "mdate": 1762920148340, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "We thank all the reviewers for their recognition of our work!\n\nIn summary, through this rebuttal we have clarified key design decisions and provided additional evidence requested by the reviewers. Specifically, we (1) clarified the design choices of our method, including how we select pruning layers, the number of layers, the rank r, and the scaling factor λ, and showed that performance is generally robust within the high-scoring middle-layer region; (2) added experiments on larger models (Llama2-70B and Qwen3-32B), demonstrating that ProSafePrune scales to higher parameter regimes; (3) reported pruning time and inference-time comparisons, showing that our method is essentially cost-free at inference compared to representation-editing and self-CD baselines; (4) provided stability results under stochastic decoding (do_sample=True), and additional evaluations with larger sample sizes to address robustness concerns.\n\nOn the analysis side, we (5) introduced a new comparison against single-vector representation editing, including category-wise cosine analysis and projection-energy measurements, showing that false refusal is inherently multi-dimensional and better captured by our low-rank subspace approach; (6) added a Logits Lens–based interpretability study of cognitive bias and alignment tax, and discussed why ProSafePrune can slightly improve general capabilities; (7) included submodule-level pruning analysis and qualitative case studies; and (8) clarified the conceptual distinction between our “over-harmful encoding” mechanism and safety unlearning, as well as the relationship between our white-box setting and other alignment frameworks. \n\nIn response to several valuable suggestions raised by the reviewers that were not fully addressed in the original submission, we have added the corresponding analyses and experiments. A revised PDF has been uploaded, with all newly added content highlighted in blue."}}, "id": "FS4e3uSQys", "forum": "QkHKaPfRAB", "replyto": "QkHKaPfRAB", "signatures": ["ICLR.cc/2026/Conference/Submission8194/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8194/Authors"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission8194/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763620647149, "cdate": 1763620647149, "tmdate": 1763637498647, "mdate": 1763637498647, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}