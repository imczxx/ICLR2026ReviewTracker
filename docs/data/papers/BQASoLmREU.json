{"id": "BQASoLmREU", "number": 14462, "cdate": 1758236229407, "mdate": 1759897368558, "content": {"title": "Efficient Multimodal Spatial Reasoning via Dynamic and Asymmetric Routing", "abstract": "Recently, visualization-of-thought (VoT) has unlocked new opportunities for complex spatial reasoning in multimodal large language models (MLLMs) by complementing verbal reasoning with visual thinking.\nHowever, the autoregressive accumulation of lengthy and redundant tokens substantially increases computation and memory costs.\nIn this paper, we present a new efficient framework for multimodal spatial reasoning, named \\emph{DARE}, designed to adaptively prune multimodal tokens across different network depths, reasoning hops, and modalities. \nFirst, \\emph{DARE} devises an intra- and inter-hop-aware differentiable retention mechanism to dynamically estimate token importance both within each reasoning step and across successive hops. \nRecognizing that deeper network layers encode visual cues into verbal streams, \\emph{DARE} introduces an asymmetric compression strategy that prunes tokens according to modality-specific redundancy and semantic importance.\nFurthermore, \\emph{DARE} incorporates a progressive KV-cache retention policy aligned with cross-modal fusion dynamics, further reducing memory overhead during autoregressive reasoning.\nOur method delivers substantial reductions in computation and memory footprint, averaging a 40.37\\% reduction in FLOPs and 46.07\\% reduction in KV caches usage, \nwhile consistently preserving or even improving reasoning performance across seven multimodal spatial reasoning benchmarks, and further generalizing to broader multimodal reasoning tasks, \nestablishing a scalable and robust recipe for efficient multimodal reasoning.", "tldr": "We introduce DARE, a novel framework for efficient multimodal reasoning that leverages visual-to-text information flow and asymmetric routing, cutting FLOPs and KV-cache by over 40% without loss of accuracy.", "keywords": ["Autoregressive multimodal reasoning", "Layer- and hop-aware retention", "Green AI"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/436dac246d2464a719bcab953aeb1c535d02e489.pdf", "supplementary_material": "/attachment/d0677dc8a817d7820adbddc689306199ce1f4918.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces DARE (Dynamic and Asymmetric Routing), a new framework designed to address the significant computational and memory costs associated with multi-hop reasoning in Multimodal Large Language Models (MLLMs). It proposes a dynamic token pruning mechanism. Through experiments on seven spatial reasoning benchmarks, the authors demonstrate that DARE achieves substantial reductions in FLOPs and KV-cache usage."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper provides a clear motivation by outlining the computational efficiency challenges in multi-hop multimodal reasoning. Furthermore, the work is presented with a coherent structure, making the methodology and experimental sections straightforward to follow."}, "weaknesses": {"value": "Regarding the experiments on dynamic spatial reasoning, I am genuinely interested in understanding how the results in Table 2 were obtained. As someone familiar with unified MLLMs and interleaved multimodal reasoning, I noticed that the datasets mentioned—MAZE, MINIBEHAVIOR, and FROZENLAKE—do not appear to be publicly available, at least to the best of my knowledge. This raises some concerns about the reproducibility and authenticity of the reported results, as independent verification is currently not feasible. I believe that providing access to the source code and implementation details of this part would help clarify how the experiments were conducted. To adhere to the double-blind review policy, an anonymous link to a code repository would be very helpful."}, "questions": {"value": "Please see the weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pqWFlKYAq5", "forum": "BQASoLmREU", "replyto": "BQASoLmREU", "signatures": ["ICLR.cc/2026/Conference/Submission14462/Reviewer_ddYw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14462/Reviewer_ddYw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14462/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761479097391, "cdate": 1761479097391, "tmdate": 1762924865227, "mdate": 1762924865227, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new framework that enhances the efficiency of MLLMs during spatial-reasoning tasks by adaptively pruning multimodal tokens across network depths, reasoning hops, and modalities. DARE integrates a layer- and hop-aware differentiable retention mechanism with an asymmetric compression strategy to selectively preserve essential tokens. Experiments on multiple multimodal spatial reasoning benchmarks show that DARE significantly reduces FLOPs and memory overhead while maintaining performance.\n\nI have reviewed this paper for NeurIPS 2025. After careful check, I noticed that the authors have incorporated the reviewers' suggestions and addressed their concerns in this version. For example, the comparison between DARE and MoD (Appendix D.4: Comparison with Heuristic Token Retention and Routing Methods) and the experiments across models of different sizes (Scalability to Larger and Smaller Models, Section G.1). I think this version is clear and well-written, meeting the standard for acceptance."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1. The motivation is solid, and the method is well-motivated. The authors tackle a key efficiency bottleneck in multi-hop multimodal spatial reasoning. The approach is clearly formulated and effectively presented.\n\n2. The main experiments are comprehensive, covering seven spatial-reasoning benchmarks, general VQA, hallucination detection, and detailed ablation studies.\n\n3. The authors provide thorough discussion and analysis, including comparisons between DARE and MoD, interpretation of retention rates, the necessity of learning-based routing, and how DARE scales as model size increases. Overall, the paper offers a complete and clear discussion of the DARE method and its position within the broader research landscape."}, "weaknesses": {"value": "No obvious weaknesses."}, "questions": {"value": "After careful review, the authors have addressed all the questions I raised in my previous review, and I have no further questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "kipq0gdHAK", "forum": "BQASoLmREU", "replyto": "BQASoLmREU", "signatures": ["ICLR.cc/2026/Conference/Submission14462/Reviewer_wQMw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14462/Reviewer_wQMw"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14462/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761636854628, "cdate": 1761636854628, "tmdate": 1762924864539, "mdate": 1762924864539, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces DARE, a novel framework designed to improve the efficiency of multi-hop multimodal spatial reasoning by addressing the high computational costs of existing methods. It achieves this through several key contributions: a modality-aware token routing mechanism with dedicated routers at each transformer layer to score token importance; an intra- and inter-hop aware retention strategy that uses Gumbel-Softmax to learn dynamic pruning ratios across both network layers and reasoning steps; and a KV-cache policy that reduces memory overhead by aligning with token pruning decisions. The authors report significant efficiency gains while maintaining or improving performance."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. DARE shows compelling performance, consistently achieving comparable or superior accuracy to its baselines while being significantly more efficient.\n2. The framework demonstrates impressive generalization by showing effectiveness on two different interleaved reasoning architectures: one based on visual token referencing (VolCano) and another on mental image generation (Anole).\n3. The paper is supported by a comprehensive set of experiments and ablation studies that strongly validate the proposed design choices. The authors' effort in providing this level of detail, including a well-organized appendix, is very impressive."}, "weaknesses": {"value": "1. **Impact of New Hyperparameters on Applicability:** The proposed method introduces several new hyperparameters (e.g., target retention ratios $p_{target}$, hard pruning threshold $\\epsilon$, prefix size $\\kappa$). While the paper includes helpful ablation studies, finding the optimal set of these hyperparameters for a new model or task could be a non-trivial and expensive process, potentially limiting the method's plug-and-play applicability.\n\n2. **Fixed Number of Reasoning Hops**: The framework appears to operate with a pre-defined maximum number of reasoning hops ($H$). Real-world problems may require a variable number of reasoning steps. It is unclear how DARE would adapt to tasks that require more or fewer hops than what it was trained for, which may limit its flexibility in more open-ended scenarios."}, "questions": {"value": "1. How do the router's importance scores change when the model is given a different task? For instance, does a visual search task yield a different tendency compared to a dynamic navigation task (like MAZE)?\n\n2. The term \"hop\" is central to the paper but is not explicitly defined. Is a \"hop\" defined as a single autoregressive generation step for an intermediate thought (which could be a mix of visual and textual tokens), as suggested by Figure 2? A precise definition would be helpful.\n\n3. In Table 1, DARE-LH shows a particularly large accuracy improvement over the VolCano baseline on EmbSpatial compared to other compositional tasks like VSR. Is there an intuition for why the proposed method is especially effective for this specific benchmark?\n\n4. Table 3 reports results for DARE-L but not DARE-LH on the General VQA and Hallucination benchmarks. Is this because these tasks are typically solved in a single reasoning step (i.e., one hop), making the inter-hop (-LH) mechanism not applicable?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HkEs2NjAu4", "forum": "BQASoLmREU", "replyto": "BQASoLmREU", "signatures": ["ICLR.cc/2026/Conference/Submission14462/Reviewer_8DKA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14462/Reviewer_8DKA"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14462/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761805966029, "cdate": 1761805966029, "tmdate": 1762924863831, "mdate": 1762924863831, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces DARE, a novel and well-motivated framework for efficient multimodal spatial reasoning. By dynamically and asymmetrically pruning tokens across layers and reasoning hops, the method achieves reductions in computation and memory while often improving task performance. The paper is supported with comprehensive analysis and evaluation with comparisons over different system variants."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-motivated. The paper excels at identifying and motivating two nuanced challenges in multi-hop multimodal reasoning: the dynamic, shifting importance of tokens across both network depth and reasoning steps, and the asymmetric redundancy patterns between visual and textual data. \n2. Interesting technical design. I really like the use of a differentiable, end-to-end learnable routing mechanism compared to fixed heuristics. Furthermore, the asymmetric compression strategy and the explicit focus on reducing KV-cache usage are critical for autoregressive models.\n3. Comprehensive empirical evaluation. The authors validate DARE across an extensive and diverse set of benchmarks, comparing it against diverse baselines. The results are good, showing that DARE not only meets its efficiency goals in terms of FLOPs and KV cache reduction but also even improves accuracy, demonstrating the method's effectiveness."}, "weaknesses": {"value": "1. Reproducibility and reliability of the results: I'm concerned with the experimental results in Table 2, especially with MVoT and VoT. To be more specific, I would appreciate it if the authors can clarify:\n* Computational resources: can Anole 7B be trained with 40 GB GPUs for how long? Could the authors provide training logs for clarification purposes?\n* Experiment results: given that there is no public available datasets and model checkpoints MVoT uses in the original paper, and the reported numbers in Table 2 strictly aligns with the results in MVoT paper, plus the experimental settings (number of epochs, types of GPUs, numbers of GPUs) are not same as in the original paper, I would appreciate the authors provide more details regarding this. (I tried to look into the supplementary materials in the zip file, but didn't find the training script)\n2. Methodological complexity and hyperparameters. While effective, DARE is a complex system with numerous interacting components and hyperparameters (target retention ratios, pruning thresholds, Gumbel temperature, etc.). The paper could benefit from a clearer discussion of the tuning effort required and the generalizability of the chosen hyperparameter values to different model architectures or domains."}, "questions": {"value": "See as above in weaknesses. I'm happy to adjust the scores if the author can address the concerns in the weaknesses.\n\nTypo: L037 MoT should be MVoT"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "WqedtGbXEX", "forum": "BQASoLmREU", "replyto": "BQASoLmREU", "signatures": ["ICLR.cc/2026/Conference/Submission14462/Reviewer_UNBZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14462/Reviewer_UNBZ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14462/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927503880, "cdate": 1761927503880, "tmdate": 1762924863417, "mdate": 1762924863417, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}