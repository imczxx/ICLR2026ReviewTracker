{"id": "29Mote2SrR", "number": 25378, "cdate": 1758367319407, "mdate": 1759896722890, "content": {"title": "Hierarchical Feedback Interface for Human-in-the-Loop Reinforcement Learning in Debugging", "abstract": "We propose Hierarchical Feedback Interface (HFI) for human-in-the-loop\nreinforcement learning in debugging which structures human feedback\ngrouped into high level objectives and low level refinements to cover the\nsubjectivity and inefficaciousness of ad-hoc corrections. The HFI employs a\ntwo-tiered policy architecture, in which a high-level policy abstracts\ndebugging goals into ac a interpretable meta-objectives, and a low-level\npolicy translates these into actionable feedback thus grounding\nhuman input to the ALigned-and-goal reasoning. The framework integrates a\nhierarchical actor-critic mechanism - with the high-level policy\ngenerating goal vectors over reduced state representations, while the\nlow level policy conditions of both code specific features and these\ngoals to generate context-aware feedback.", "tldr": "", "keywords": ["Reinforcement Learning in Debugging"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8a3e9c4f1d1111df09bb5b27b93e15cd35858148.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents a “hierarchical feedback interface” that is supposed to integrate human feedback at two levels for optimizing hierarchical RL policies. It targets a code debugging use case.\n\nWhile the topic is potentially relevant, the submission is not in a reviewable state. The writing quality and structural issues prevent proper evaluation of the technical contribution. A major rewrite and clarification of the methodology (especially the technical contribution described in chapters 4 and 5) would be required before this work could be meaningfully reviewed."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "+ The topic is interesting in general; making hierarchical RL work is a long-standing challenge. The use case seems practical and relevant.\n+ There seems to be a novel contribution somewhere in there, but I was unable to assess it.\n+ The proposed evaluation seems good in theory"}, "weaknesses": {"value": "- The paper reads like a draft (especially for sections 4 and 5). The convoluted writing, errors, sentence fragments, and usage of unexplained concepts (like Temporal Convolution Network) make it difficult to grasp the approach and contribution fully. Some key elements, like formula 12, are not explained (how is the weighting done?).\n- Figures are not referenced in the text (Figures 1,2,3) or have meaningful captions\n- The related work section is sparse, missing some crucial papers, e.g., on preference-based RL \n- For the experiments, many crucial details are missing"}, "questions": {"value": "-"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NZx7IzF126", "forum": "29Mote2SrR", "replyto": "29Mote2SrR", "signatures": ["ICLR.cc/2026/Conference/Submission25378/Reviewer_WuVi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25378/Reviewer_WuVi"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25378/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761842333068, "cdate": 1761842333068, "tmdate": 1762943417639, "mdate": 1762943417639, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper does hierarchical RLHF for debugging. The feedbacks are abstracted into high level and low level goals. This is a good idea however the paper is not in an acceptable state."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "Good idea."}, "weaknesses": {"value": "The paper is clearly rushed with lots of typos. \nPages 6-8 are almost empty.\nExperiments are run on one seed (right?) so the results are null."}, "questions": {"value": "Can you run your experiments on mutliple seed please and do a qualitative analysis of a single bug fix wth HFI please?\nCan you detail the training details of the PPO ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ohceYjQzap", "forum": "29Mote2SrR", "replyto": "29Mote2SrR", "signatures": ["ICLR.cc/2026/Conference/Submission25378/Reviewer_sXc4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25378/Reviewer_sXc4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25378/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761912080339, "cdate": 1761912080339, "tmdate": 1762943417470, "mdate": 1762943417470, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a hierarchical feedback interface for human-in-the-loop rl for code debugging. A high-level policy outputs goal vectors, while a low-level policy does concrete fixes. A PRM is used to translate human judgement into differentiable signals. Authors conduct experiments to show that their method has a higher bug-fix rates and fewer interventions than baselines."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "* Tackles an important problem of incorporating human feedback for debugging. The solution of using hierarchical RL is relatively interesting combined with PRM."}, "weaknesses": {"value": "* Section 4 is poorly written and very hard to understand. Key mechanisms like gating mechanism in eq (12) are not specified. There are also random phrases in Section 4, like \"goal relevance\", which suggests an unfinished state for the paper.\n\n* Figure 1 is confusing as well: the architecture doesn't show a clear \"human\" component even though that's the core of the proposed method. The human expert only shows up in Figure 2.\n\n* Evaluation details are omitted: PRM specification, episode length, etc. Only a few hyperparameters are given.\n\n* Novelty is limited due to prior work on HRL + preference RL, especially since human is not actively in the loop for this method.\n\n* Writing quality is overall very poor"}, "questions": {"value": "1. What's the PRM used for the experiments? Is it finetuned for the debugging task on new data that you collected?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "lHCFWedoHo", "forum": "29Mote2SrR", "replyto": "29Mote2SrR", "signatures": ["ICLR.cc/2026/Conference/Submission25378/Reviewer_Xgs6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25378/Reviewer_Xgs6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25378/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761981819356, "cdate": 1761981819356, "tmdate": 1762943417277, "mdate": 1762943417277, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}