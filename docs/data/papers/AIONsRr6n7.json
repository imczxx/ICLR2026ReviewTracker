{"id": "AIONsRr6n7", "number": 5915, "cdate": 1757946059178, "mdate": 1762972940860, "content": {"title": "Closed-Loop Activation Density Control for Sparse Distributed Memory", "abstract": "Associative memory models often suffer from sensitive parameters that hinder stable operation in high-dimensional settings. In particular, Pentti Kanerva's Sparse Distributed Memory (SDM) requires setting a Hamming distance threshold $T$ to determine which memory locations are activated on a query, a choice that critically affects performance.\n\nWe address this parameter sensitivity: directly tuning $T$ is ill-conditioned around the nominal operating point (half the dimension), where a minute change in $T$ produces a large swing in the number of activated locations $k$. Instead, we control the activation density $p = k/L$, which is well-posed, and adjust $T$ indirectly.\n\nOur controller combines inverse-CDF actuation with slope-normalized integral feedback to cancel the large plant gain near $n/2$. The result is a closed-loop SDM that adapts $T$ on the fly to track a desired sparsity level $p^*$ across queries.\n\nEmpirically, the loop achieves near-perfect target tracking ($R^2 \\approx 1.00$) and improves query efficiency, reducing activation error by $\\approx 5.2\\times$ compared to naive threshold control at equal query budgets, while standard bisection attains similar raw error but requires $\\approx 1.9\\times$ more queries.\n\nThe method generalizes across dimensions $n\\in{512,1024,2048}$ and target activation counts $k^*\\in{3,6,12}$, and remains stable under mild departures from binomial assumptions when using empirical slope estimates.", "tldr": "We solve the parameter sensitivity problem in Sparse Distributed Memory by controlling activation density rather than threshold, achieving 4.9× better error reduction through slope-normalized integral feedback control.", "keywords": ["associative memory", "sparse distributed memory", "control theory", "high-dimensional memory", "feedback control", "binomial distribution"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3a81d0e2c5d86b9a93f706823f8bebd20f6eb571.pdf", "supplementary_material": "/attachment/9a346ed3d0daf219abb38ae8de69fcbec0e158ab.zip"}, "replies": [{"content": {"summary": {"value": "This paper solves a critical parameter sensitivity problem in Sparse Distributed Memory (SDM). Instead of tuning the ill-conditioned Hamming threshold $T$, the authors propose controlling the activation density $p = k/L$ directly using a closed-loop feedback controller. This method combines an inverse-CDF mapping with slope-normalized integral feedback to dynamically adjust T, achieving precise target tracking with high efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper's main strength is its novel and rigorous application of control theory to a known problem in associative memories. It correctly identifies the high plant gain as the source of instability and designs a principled controller to neutralize it.\n\n2. The paper is extremely well-written, using clear explanations and insightful figures (e.g., Figure 1) to make a complex technical problem immediately understandable.\n\n3. The experiments convincingly support the claims. The method is shown to be not only highly accurate ( $R^2 \\approx 1.0$ ) but also more cost-efficient than relevant baselines like bisection search, which requires $\\sim 1.9 \\mathrm{x}$ more queries for similar performance."}, "weaknesses": {"value": "1. Limited Scope Beyond Classical SDM: The experiments are confined to the classical SDM model. While the authors suggest broader relevance to modern architectures like MoE, the paper lacks even a small-scale experiment to demonstrate this transferability.\n2. Idealized Data Assumptions: The controller design assumes the data is uniformly random, leading to a binomial distribution of Hamming distances. The paper doesn't address how performance would be affected by structured or correlated data that violates this assumption."}, "questions": {"value": "1. Could you elaborate on the practical challenges of integrating this closed-loop controller into a modern MoE layer to replace a standard top-k gating function?\n\n2. How robust is the controller if the true distribution of Hamming distances deviates significantly from the assumed binomial model due to structured data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "ihqntWLKNd", "forum": "AIONsRr6n7", "replyto": "AIONsRr6n7", "signatures": ["ICLR.cc/2026/Conference/Submission5915/Reviewer_9WzH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5915/Reviewer_9WzH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761508611632, "cdate": 1761508611632, "tmdate": 1762918346638, "mdate": 1762918346638, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the critical parameter sensitivity of the activation threshold `T` in Sparse Distributed Memory (SDM), a long-standing ill-conditioned problem. The authors propose a principled closed-loop control system that directly regulates the activation density `p=k/L`. The core contribution is a slope-normalized feedback controller which effectively cancels the system's extreme sensitivity. Experiments show this method dramatically improves stability and accuracy, significantly outperforming naive control and bisection search in terms of both final error and query efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "*   The paper's key strength is its novel formulation of the SDM threshold tuning issue as a formal control problem. The proposed solution, a slope-normalized feedback controller, is principled, theoretically sound, and a creative application of control theory.\n*  The work is exceptionally clear, with rigorous experiments against strong baselines (e.g., bisection search) that convincingly demonstrate its superiority. Its significance extends beyond SDM, offering a promising paradigm for dynamic sparsity control in modern architectures like Mixture-of-Experts (MoE)."}, "weaknesses": {"value": "*    The method's performance depends on a pre-specified target activation count `k*`. The framework does not currently address how this target could be adapted dynamically, which might be necessary in scenarios where the optimal sparsity level changes with memory load or task demands.\n*    While the proposed application to modern architectures like MoE is exciting, this claim is not yet substantiated. The paper lacks a discussion of the technical challenges in adapting the method from the discrete, binomial world of SDM to the continuous, data-dependent distributions found in attention mechanism."}, "questions": {"value": "1.  How does the controller perform during transient periods if the target `k*` is changed dynamically during operation?\n2.  Could you elaborate on the main technical challenges in adapting this control method to an MoE layer, particularly regarding the estimation of the activation function and its slope for normalization, given the complex, non-binomial distributions involved?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2q48zwJCo9", "forum": "AIONsRr6n7", "replyto": "AIONsRr6n7", "signatures": ["ICLR.cc/2026/Conference/Submission5915/Reviewer_btQ2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5915/Reviewer_btQ2"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761882716926, "cdate": 1761882716926, "tmdate": 1762918346316, "mdate": 1762918346316, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper looks at a long-standing problem in Kanerva’s Sparse Distributed Memory: picking the distance threshold that decides how many memory locations light up during recall. Around the usual operating point, tiny tweaks to this threshold can flip thousands of activations, which makes the system brittle. The authors’ fix is to control the fraction of locations that activate directly, rather than tuning the threshold by hand. They first choose a threshold that should yield a target activation fraction based on a simple probabilistic model, then wrap this with a feedback controller that keeps the actual activations locked to that target despite randomness. They also argue the idea should transfer to modern architectures—like attention and Mixture-of-Experts—where keeping sparsity stable matters for speed, stability, and accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Importance. I like that you go after a core stability knob in SDM and connect it to attention/MoE sparsity control, it seems broadly relevant beyond classical associative memory. \n\nNovelty. It seems the combination of inverse-CDF actuation with slope-normalized integral feedback to regulate p is new. \n\nClarity/organization. The paper has a reasonably clear presentation."}, "weaknesses": {"value": "Your claim that you’re more cost-efficient than bisection hinges on the assumed “query cost” model; can you report results under alternative costings (e.g., wall-clock, oracle calls, or amortized per-step overhead) and include confidence intervals/seed-wise tests to show the ~1.9× advantage holds statistically? \n\nBudget-capped bisection shows 30% failures—can you analyze why (e.g., initial bracket miss, stochasticity) and add a variant with smarter bracketing to ensure the comparison isn’t penalizing a fixable implementation choice?\n\nMissing citations. The controller is framed via slope normalization and feedback linearization; could you broaden the control-theory context (e.g., stochastic integral control / adaptive gain scheduling) and also cite more recent sparsity-control mechanisms in attention/MoE beyond the classics you already reference?\n\nOne related work but not cited: Fuzzy Tiling Activations: A Simple Approach to Learning Sparse Representations Online by Pan et al. It introduces a differentiable alternative to hard bin/threshold schemes that stabilizes sparse representations and is robust under shift; your work tackles a closely related brittleness (many locations flipping around a threshold) but solves it via closed-loop activation-density control.\n\nThe linearized analysis yields a practical envelope but leaves measurement noise and discretization effects to experiments; can you bound steady-state error and give a robustness margin (e.g., input noise variance → tracking error) so readers know when guarantees degrade? \n\nYour theoretical results rely on i.i.d. random addresses/queries (binomial geometry); how does stability and tracking behave with structured addresses or correlated query streams (e.g., clustered memories), and can you extend the theory (or add stress tests) for non-binomial regimes?\n\nSince you motivate applicability to attention/MoE, can you add a small demo (e.g., regulating top-k keys or experts on a toy transformer/MoE) to show that the controller slots in cleanly and preserves accuracy under a fixed activation budget? \n\nYou report tail error (post warm-up) and cost-weighted error; can you justify the warm-up choice, show sensitivity to the window, and test robustness to changing the query stream (not just fixing it per trial) so conclusions don’t hinge on one trajectory?"}, "questions": {"value": "see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cmxtEYvxJA", "forum": "AIONsRr6n7", "replyto": "AIONsRr6n7", "signatures": ["ICLR.cc/2026/Conference/Submission5915/Reviewer_KYzd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5915/Reviewer_KYzd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761903246478, "cdate": 1761903246478, "tmdate": 1762918345914, "mdate": 1762918345914, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents AHSE, a dual-branch architecture that combines serial feature evolution (SEED) with parallel error-correcting output codes (PATH). It develops a SPOT fusion circuit to integrate these branches and provides theoretical results on ECOC robustness for Broad Learning Systems under weight noise. The model achieves strong results across multiple datasets and includes detailed ablations validating each design choice."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "• The paper provides a principled control-theoretic formulation of a long-standing heuristic problem in associative memory, replacing brittle threshold tuning with activation-density feedback.\n• The inverse-CDF actuation with slope normalization is a mathematically elegant and computationally efficient solution to the binomial sensitivity issue.\n• Empirical results across multiple settings (see Figures 2–5, pages 6–8) demonstrate remarkably consistent tracking and stability, with clear quantitative improvements in cost-efficiency over baselines.\n• The work establishes theoretical stability bounds (Eq. 6) and validates them experimentally, offering both analytical and practical insights rarely found in SDM literature.\n• The discussion (page 9) thoughtfully extends the concept of activation-density control to attention mechanisms and sparse expert models, positioning the work as a conceptual bridge between symbolic memory and modern deep learning."}, "weaknesses": {"value": "• The experiments are primarily synthetic, focusing only on canonical SDM configurations. No demonstrations on downstream learning or associative recall tasks are provided to illustrate the real-world impact of improved control.\n• The controller is currently fixed-target—it maintains a single desired density P; adaptive or context-dependent sparsity targets could make the approach more versatile.\n• The linearized analysis (Eq. 5–6) is elegant but approximate; stability predictions deviate from measured limits (see Figure 5), and the paper could discuss these discrepancies more deeply.\n• The study would benefit from additional comparisons with modern sparse-gating or attention mechanisms to substantiate claims of broader applicability.\n• Finally, while the system generalizes across dimensions, it is unclear how it scales when embedded in neural or hybrid architectures, where feedback latency and stochasticity differ from SDM assumptions."}, "questions": {"value": "Could the authors extend their analysis to demonstrate recall accuracy or capacity improvements in SDM tasks when activation-density control is used, beyond query efficiency?\n\nHave you experimented with adaptive or learned target densities P* that adjust dynamically based on load or retrieval error? If so, how does the control behave?\n\nThe slope-normalized controller relies on binomial statistics; how robust is it if the address distribution deviates from uniformity (e.g., correlated memory locations)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YLnbqd95Gn", "forum": "AIONsRr6n7", "replyto": "AIONsRr6n7", "signatures": ["ICLR.cc/2026/Conference/Submission5915/Reviewer_djNt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5915/Reviewer_djNt"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762052223582, "cdate": 1762052223582, "tmdate": 1762918345328, "mdate": 1762918345328, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "We sincerely thank all reviewers for their detailed, constructive, and insightful feedback. We are encouraged that all reviewers appreciated the paper's novel control-theoretic formulation (R-djNt, R-btQ2, R-9WzH) and its clarity (R-KYzd, R-btQ2, R-9WzH).\n\nThe feedback centered on four key themes:\n\n- Downstream Impact: Is the method beneficial beyond query efficiency (R-djNt)?\n- Robustness: How does it perform when the i.i.d. binomial assumption is violated (R-djNt, R-KYzd, R-9WzH)?\n- Adaptivity: Is it limited to a fixed k* (R-djNt, R-btQ2)?\n- Broader Scope: Can it practically apply to modern architectures like MoE/attention (all reviewers)?\n\nWe are pleased to report that we have addressed all four themes with new experiments (now in Appendix C), a revised abstract, and updated discussion in the main paper.\n\n1. Downstream Recall (R-djNt): We added an equal-budget BER test at SNR ≈ 1. As hypothesized, BER saturates near 0.5 for all methods, confirming this regime is non-discriminative. This result justifies our focus on upstream regulation as the key, actionable metric for controller design in high-noise environments.\n\n2. Robustness (R-djNt, R-KYzd, R-9WzH): We added a non-binomial stress test (clustered addresses) and show that the controller remains stable with bounded error (tail error ≈ 3.08) by switching to an empirical slope.\n\n3. Adaptivity (R-djNt, R-btQ2): We added two dynamic tests:\nA step-response test (k*: 6 → 12) shows a well-damped response with no overshoot.\nAn adaptive k demo* shows the controller can track a dynamic target driven by BER feedback.\n\n4. Broader Scope (All Reviewers): We added an attention-style density control demo. Using an empirical slope, our controller hits the target key budget exactly (k_mean=16.0, k_std=0.0) and matches fixed top-k accuracy, proving initial viability as a drop-in replacement.\n\n5. Cost Models (R-KYzd): We added two alternative cost models (Oracle Calls, Wall-Clock Proxy) and a \"seeded-bisection\" baseline. Our method remains the most cost-efficient, and the ≈1.9x overhead for bisection is robust.\n\nUpdates to Main Paper\n\nAbstract: The abstract is updated to reflect the new robustness and generalization findings.\n\nIntroduction (Sec 1): We now include the 220x improvement from the micro-sweep, clarifying how its setup differs from the 5.2x equal-budget benchmark.\n\nMethod (Sec 3.3): We've anchored the method in control theory, citing Slotine & Li for feedback linearization (per R-KYzd).\n\nResults (Sec 4.3): We reframed the SNR ≈ 1 BER result as a justification for our focus on upstream metrics.\n\nDiscussion (Sec 5): We replaced the tentative MoE/attention claims with the concrete results from the new attention-style demo.\n\nAppendix D: We added the FTA (Pan et al., 2019) citation and discuss its orthogonality to our work (representation learning vs. budget control).\n\nWe believe these additions substantially strengthen the paper, confirming its robustness and demonstrating its practical applicability beyond classical SDM. We have also provided direct answers to each specific question below.\nPointers to Where Results Appear in the Paper\n\nFig. 2: Query efficiency (5.2× lower error) and cost models (≈1.9× bisection overhead).\n\nFig. 3: Control-law validation (R² = 1.00).\n\nFig. 4: Convergence prediction (R² = 0.703) and noise-tube model.\n\nFig. 5: Stability envelope (practical boundary c ≲ 0.6).\n\nTable 1: Micro-sweep results (up to 220× improvement). We clarify in Sec. 4.6 why this differs from the 5.2× in Fig. 2 (different budgets).\n\nTable 2: Normal-vs-exact threshold accuracy (max |ΔT*| = 1).\n\nAppendix C: All 6 new rebuttal experiments (BER, adaptive k*, step response, non-binomial test, attention-style demo, cost models).\n\nAppendix D: FTA (Pan et al., 2019) discussion.\n\nSec. 3.3: Control-theory anchor (Slotine & Li)."}}, "id": "eeEMVOc2EI", "forum": "AIONsRr6n7", "replyto": "AIONsRr6n7", "signatures": ["ICLR.cc/2026/Conference/Submission5915/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5915/Authors"], "number": 7, "invitations": ["ICLR.cc/2026/Conference/Submission5915/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762976049165, "cdate": 1762976049165, "tmdate": 1762976049165, "mdate": 1762976049165, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Please read and reply to authors' responses"}, "comment": {"value": "Hi,\n\nI know that some of you are probably busy with rebuttals for your own ICLR submissions, but please be sure to read the authors' responses to your initial reviews and take part in the discussion.\n\nBest,\\\nAC"}}, "id": "MNAJzO27Hg", "forum": "AIONsRr6n7", "replyto": "AIONsRr6n7", "signatures": ["ICLR.cc/2026/Conference/Submission5915/Area_Chair_JsXA"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5915/Area_Chair_JsXA"], "number": 8, "invitations": ["ICLR.cc/2026/Conference/Submission5915/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763392252605, "cdate": 1763392252605, "tmdate": 1763392252605, "mdate": 1763392252605, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}