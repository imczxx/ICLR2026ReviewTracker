{"id": "ooiR5tMN3J", "number": 6446, "cdate": 1757984417597, "mdate": 1763371430055, "content": {"title": "DDI-Gaussian: Distributed Dynamic Instance Gaussian for Autonomous Driving", "abstract": "Current dynamic 3D Gaussian approaches attempt to decompose scene motion by using purely implicit features or additional 3D annotations. However, these strategies hinder fine-grained and interpretable control over Gaussians and overlook the inherent instance consistency, spatial continuity, and local rigidity in scene motion. To this end, we propose a novel framework that achieves MLP-free Gaussian instance distinction and effectively disentangles dynamic urban street scenes. Specifically, we assign each Gaussian a compact multi-hot instance feature, enabling direct differentiation without relying on an additional network. To model transient motions, we initialize sparse control points at the instance level and construct the motion field from coarse to fine by leveraging spatiotemporal relationships. Additionally, we introduce two instance-level losses: an instance-level region loss and an instance-semantic loss. The former, combined with the opacity rendering pipeline, enables precise instance-level rendering and suppresses ghosting artifacts. The latter enforces cross-view feature consistency and optimizes the spatial positions of instances. Notably, our framework avoids costly 3D instance annotations by instead utilizing 2D pseudo-labels generated by Segment Anything Model (SAM) for supervision. Our demo video and code are available in the anonymous repository at  https://anonymous.4open.science/r/DDI-GS-750E/.", "tldr": "The proposed approach enables efficient discrimination of 3D Gaussians for instance-level scene understanding without requiring extra 3D annotations or additional networks, and achieves state-of-the-art performance in dynamic scene reconstruction.", "keywords": ["3D Gaussian、Autonomous Driving、Instance-Level、Dynamic Scene Reconstruction"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/409de2a1dcc71cf1f357f7ed651cee66ca202a75.pdf", "supplementary_material": "/attachment/23b04cbef78909e9e91ab9779b8487fb698dc2d9.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents DDI-Gaussian, a new framework for dynamic 3D Gaussian scene reconstruction, especially for street scene reconstruction. Main contribution lies in the instance control compared to previous methods. In addition, the method is implemented in a distributed multi-GPU system and leverages 2D pseudo-labels from SAM to avoid costly 3D annotations. Experiments on Waymo-NOTR and Waymo-Street datasets demonstrate improved scene reconstruction and rendering quality."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Instance-level control is essential for the self-supervised method like S3Gaussian.\n2. Distributed training implementation is also practical for street scene reconstruction."}, "weaknesses": {"value": "1. Limited novelty: the core idea seems a mixed of existing semantic 3DGS works. The instance control can be implemented by panoptic supervision and the vanilla rasterization can be changed into gsplat for better distributed training pratice. \n2. Lack of baselines: OmniRe (ICLR2025), SplatAD(CVPR2025), DeSiRe-GS (CVPR2025), EMD (ICCV2025)."}, "questions": {"value": "1. Does the method scale efficiently beyond two GPUs?\n2. Could instance-level encoding be extended to support part-level or semantic decomposition?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "U6609mK68E", "forum": "ooiR5tMN3J", "replyto": "ooiR5tMN3J", "signatures": ["ICLR.cc/2026/Conference/Submission6446/Reviewer_KAej"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6446/Reviewer_KAej"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6446/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761495387116, "cdate": 1761495387116, "tmdate": 1762918838457, "mdate": 1762918838457, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents DDI-Gaussian, a new framework for dynamic 3D Gaussian scene reconstruction, especially for street scene reconstruction. Main contribution lies in the instance control compared to previous methods. In addition, the method is implemented in a distributed multi-GPU system and leverages 2D pseudo-labels from SAM to avoid costly 3D annotations. Experiments on Waymo-NOTR and Waymo-Street datasets demonstrate improved scene reconstruction and rendering quality."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Instance-level control is essential for the self-supervised method like S3Gaussian.\n2. Distributed training implementation is also practical for street scene reconstruction."}, "weaknesses": {"value": "1. Limited novelty: the core idea seems a mixed of existing semantic 3DGS works. The instance control can be implemented by panoptic supervision and the vanilla rasterization can be changed into gsplat for better distributed training pratice. \n2. Lack of baselines: OmniRe (ICLR2025), SplatAD(CVPR2025), DeSiRe-GS (CVPR2025), EMD (ICCV2025)."}, "questions": {"value": "1. Does the method scale efficiently beyond two GPUs?\n2. Could instance-level encoding be extended to support part-level or semantic decomposition?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "U6609mK68E", "forum": "ooiR5tMN3J", "replyto": "ooiR5tMN3J", "signatures": ["ICLR.cc/2026/Conference/Submission6446/Reviewer_KAej"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6446/Reviewer_KAej"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6446/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761495387116, "cdate": 1761495387116, "tmdate": 1763365420951, "mdate": 1763365420951, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "DDIG assigns a compact multi-hot instance feature to each Gaussian, enabling self-supervised modeling of different instances within a scene without requiring 3D instance annotations. Additionally, distributed training is employed to accelerate the overall training process."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The method does not rely on 3D instance annotations, which reduces annotation costs for large-scale applications.\n\n - Distributed training significantly accelerates training speed."}, "weaknesses": {"value": "- The paper lacks comparisons with state-of-the-art methods (e.g., OmniRe, BezierGS).\n\n - The approach does not clearly demonstrate how deformable traffic participants are modeled.\n\n - For modern end-to-end autonomous driving systems, the explicit semantic modeling in DDIG may be less critical. Moreover, noticeable floaters appear around object boundaries in the semantic renderings."}, "questions": {"value": "- Although the method is annotation-free, comparisons with state-of-the-art approaches that use 3D annotations (e.g., OmniRe, BezierGS) are still necessary, since 3D annotations are not prohibitively expensive relative to the potential reconstruction quality loss.\n\n - How does the proposed method handle deformable traffic participants?\n\n - The advantages of DDIG over existing methods should be presented more clearly (e.g., through RGB renderings or instance-level rendering videos). Currently, the improvement over StreetGaussian is not very evident—for instance, in Figure 3, the ground surface appears blurrier than in StreetGaussian."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tetwojjoEu", "forum": "ooiR5tMN3J", "replyto": "ooiR5tMN3J", "signatures": ["ICLR.cc/2026/Conference/Submission6446/Reviewer_k2AD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6446/Reviewer_k2AD"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6446/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761752315095, "cdate": 1761752315095, "tmdate": 1762918838014, "mdate": 1762918838014, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "1. This paper studies dynamic 3D scene reconstruction for autonomous driving. It focuses on the problem that current 3D Gaussian Splatting (3DGS) methods lack instance-level understanding in large-scale street scenes.\n2.  The authors propose Distributed Dynamic Instance Gaussian (DDI-Gaussian), introducing (1) Multi-hot instance encoding, where each Gaussian is assigned a learnable multi-hot vector to directly distinguish different instances, supervised by masks generated from the Segment Anything Model. (2) Sparse Instance Control Points, where each instance selects a small set of control points using FPS. These control points model sparse motion fields through a lightweight MLP, and dense motion fields are obtained via KNN and linear blend skinning interpolation.\n3.  Experiments are conducted on Waymo-NOTR and Waymo-Street. The proposed approach outperforms prior state-of-the-art methods such as StreetGaussians. Ablation studies further verify the importance of the instance-semantic loss and control points."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The method is technically sound and well-motivated.\n2. The experiments and ablations are sufficient to support the main claims."}, "weaknesses": {"value": "1. The distributed training setup for 3DGS is difficult to view as a novel contribution.\n2. The paper does not compare against more recent SOTA methods such as NeuralRAD or SplatAD.\n3. The generalization to unseen large-scale views (e.g., new lanes or unseen driving perspectives) is unclear."}, "questions": {"value": "Please consider discussing the problems raised during weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ezbr1H689W", "forum": "ooiR5tMN3J", "replyto": "ooiR5tMN3J", "signatures": ["ICLR.cc/2026/Conference/Submission6446/Reviewer_qcpz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6446/Reviewer_qcpz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6446/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920218230, "cdate": 1761920218230, "tmdate": 1762918837641, "mdate": 1762918837641, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes DDI‑Gaussian (DDIG), a dynamic 3D Gaussian splatting framework that targets instance‑level understanding and motion modeling in urban driving scenes. The core ideas are:\n\n- assign each Gaussian a compact multi‑hot instance code to enable direct, per‑Gaussian instance discrimination;\n\n- model motion using instance‑level sparse control points whose time‑conditioned offsets are predicted by a lightweight MLP and interpolated to dense Gaussians via KNN/LBS;\n\n- introduce an instance‑level region loss (paired with an opacity map rendering pipeline) to suppress ghosting, and an instance‑semantic consistency loss;\n\n- implement training/rendering in a distributed manner and supervise instance masks with SAM‑generated 2D pseudo‑labels fused across views."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper argues convincingly that instance‑level modeling matters for urban dynamic scenes and that ghosting along motion trajectories is a persistent issue\n\n- The multi‑hot per‑Gaussian instance code aims to avoid an auxiliary ID‑prediction MLP, and the instance‑level control‑point motion model reduces per‑Gaussian MLP inference, aligning with efficiency goals\n\n- The paper details hybrid parallelism and dynamic load balancing leveraging Grendel‑style ideas. This is an interesting engineering incorporation."}, "weaknesses": {"value": "- The paper says the per‑Gaussian instance embedding is “activated by a Sigmoid and then discretized via element‑wise rounding” to form a multi‑hot code. Rounding is non‑differentiable; the paper does not state whether a straight‑through estimator (STE) or an alternative surrogate is used so that BCE supervision on the rendered mask can back‑propagate into the instance codes. As written, gradients to the rounded codes would be zero almost everywhere, calling into question how the instance embeddings are actually learned. This is a critical technical omission.\n\n- the text states “For all metrics, our method achieves the best performance.” But Table 1 (D32) shows StreetGaussian outperforming DDIG on PSNR (27.78 vs. 27.12)* and *SSIM (0.818 vs. 0.811)**—the very metrics focused on dynamic objects.\n\n- While the paper displays instance maps and “semantic images” (e.g., Figure 4–5, p.8; Figure 9, p.14), there are no segmentation metrics (e.g., PQ, AP/AR, IoU) against any ground truth or even pseudo‑label references. Given that instance awareness is a primary contribution, the absence of standard instance/semantic quality metrics undermines the central claim.\n\n- the paper defines view‑independent semantic features f_i and instance features e_i. But the instance‑semantic loss (Eq. 4, p.6) suddenly uses e to denote semantic features, reusing the same symbol previously assigned to instance features\n\n- The paper positions itself against Gaussian Grouping and control‑point‑based deformation (SC‑GS, Superpoint‑GS) but does not provide direct quantitative comparisons to these methods\n\n- The pipeline depends on SAM masks and a cross‑view association strategy “following Gaussian Grouping” (briefly mentioned in Sec 3.2, p.4), but there is no study of failure modes (mask fragmentation, ID switching) or sensitivity to SAM prompts/parameters. Since labels drive the instance code learning, robustness needs to be quantified.\n\n- complete wall‑clock times, memory usage, Gaussian counts per method, and distributed scaling curves are missing or only anecdotally described"}, "questions": {"value": "- How are gradients propagated through the rounded instance codes?\n\n- You mention following Gaussian Grouping to associate masks. What concrete association algorithm do you use (cost matrix, IoU thresholds, tracking heuristic), and how do you prevent ID collisions given the fixed 8‑bit multi‑hot code?\n\n- Please clarify the symbols and dimensions\n\n- Ablations vs. prior art.\n\n- What value of \\lambda is used in Eq. (5, p.6), and how sensitive is performance to it? Also, does the region loss ever delete small, fast‑moving objects (false negatives) due to mask misalignment from SAM?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pUgggXDz8M", "forum": "ooiR5tMN3J", "replyto": "ooiR5tMN3J", "signatures": ["ICLR.cc/2026/Conference/Submission6446/Reviewer_RntX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6446/Reviewer_RntX"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6446/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762324875238, "cdate": 1762324875238, "tmdate": 1762918837289, "mdate": 1762918837289, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}