{"id": "N35pVnh31b", "number": 15279, "cdate": 1758249739150, "mdate": 1759897316251, "content": {"title": "Small Models, Smarter Learning: The Power of Joint Task Training", "abstract": "The ability of a model to learn a task depends critically on both task difficulty and\nmodel size. We study this relationship for compositional operations, focusing on\nnested ListOps and extending beyond arithmetic to permutation groups, with the\ngoal of determining how task difficulty sets the minimum parameter requirements\nfor small transformer models. We vary task difficulty by introducing new operations\nor combinations of operations into the training data. We find that while operations\nsuch as modular addition or permutation group products are difficult in isolation,\njoint training with other operations, including product, maximum, or auxiliary\nsub-block operations, reduces the parameter requirements by factors of 2 to 7.\nAnalysis of learned embeddings using PCA reveals that when joint training helps it\nis usually accompanied by an increase in highly regular structures in the embedding\nof inputs. These results suggest that joint training leads to qualitatively different\nlearning trajectories than learning operations in isolation, with shared number\nrepresentations supporting difficult tasks such as addition. Our findings further\ndemonstrate the importance of training curriculum on the emergence of abilities in\nlanguage models.", "tldr": "Joint training on compositional tasks lowers model size and makes learning difficult operations easier.", "keywords": ["LLM", "Small Models", "Emergent Abilities", "ListOps", "Joint Training"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cee4da7ad47c143d1079a3e22c1ca78209f8d122.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work investigates how task difficulty and model size jointly determine a transformer’s ability to learn compositional operations such as modular arithmetic and permutation groups. The authors find that joint training with additional or auxiliary operations can dramatically reduce the parameter requirements, compared to training on isolated tasks. The authors further attribute this improvement to better learned embedding via PCA analysis. They also observed that the training trajectories are quantitatively different."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper presents a very clear setup and is well written.\n2. The use of datasets with controllable difficulty provides a strong foundation for conducting rigorous and systematic research."}, "weaknesses": {"value": "My main concern is the limited analysis of model size. The authors constrain the model to a single head and model depth one with recursive reuse, but prior work shows that recursion under a tight parameter budget can severely restrict model capacity even with a similar FLOPs [1], and that the number of heads matters for modular arithmetic datasets [2]. This does not invalidate the authors’ contributions, but a more thorough study of model size, especially head count and depth, would be important.\n\n\n1. https://arxiv.org/pdf/2507.10524\n\n2. https://arxiv.org/pdf/2502.10390"}, "questions": {"value": "I was wondering whether the authors have examined in detail how the mixture of datasets contributes mechanistically to learning. While the paper shows that the embeddings exhibit clear structure, most of the interpretability analysis focuses solely on the embedding level. It would be helpful if the authors could further analyze how the learned features evolve with recurrent depth, whether certain layers or depths specialize in specific tasks. More importantly, I am curious whether any shared computational circuits emerge as the dataset's complexity increases.\n\nWhy do the authors present results primarily for non-prime moduli in most plots? Wouldn’t prime moduli represent a more challenging setting, where qualitatively different behaviors might emerge?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gSpvhwhpiv", "forum": "N35pVnh31b", "replyto": "N35pVnh31b", "signatures": ["ICLR.cc/2026/Conference/Submission15279/Reviewer_5chU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15279/Reviewer_5chU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15279/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761666981356, "cdate": 1761666981356, "tmdate": 1762925580575, "mdate": 1762925580575, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates if small models can learn difficult tasks through a synthetic (extension of) ListOps dataset. They discover that joint training with multiple tasks can often lead to efficient learning. They also study embedding patterns to give a 'white-box' explanation for their models."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1) The paper studies the effect of joint task learning with multiple experiments, which cover a lot of different aspects of the learning problem (eg. prime v/s non-prime moduli, shuffling of order for ADD, etc.)\n2) Interpretability done with embedding vectors was useful. In particular, the restricted embedding hypothesis was a strong evidence for the claims made about the utility of joint training.\n3) Experiments on permutation groups present an interesting addition, with a lot of scope for future works."}, "weaknesses": {"value": "1) There is some literature which talks about compositional and/or multi-step mathematical reasoning, the paper was missing references to these [1, 2, 3]. Although the current paper has several important experiments which were missing or not considered in the papers that are mentioned below, it will be useful for the authors to devote some space to discussing these differences in the main text. \n2) The last section on 'Discussion and Limitations' doesn't really discuss limitations. For example, these results on synthetic datasets may not transfer immediately to realistic data. The restricted embedding hypothesis, while useful for interp, may not be suitable for practical purposes. \n3) Finally, these results on mathematical operations may not necessarily translate to large scale given the widely known problem of arithmetical reasoning in LLMs. This could be alleviated by performing experiments with increasing context length to the maximum limit as allowed by the authors' compute budget.\n\n\n[1] A. Abedsoltan, H. Zhang, K. Wen, H. Lin, J. Zhang and M. Belkin, “Task Generalization With AutoRegressive Compositional Structure: Can Learning From $D$ Tasks Generalize to $D^T$ Tasks?,” arXiv preprint arXiv:2502.08991, Feb. 2025.\n\n[2] T. Wang and W. Lu, “Learning Multi-Step Reasoning by Solving Arithmetic Tasks,” arXiv preprint arXiv:2306.01707, Jun. 2023. \n\n[3] W. You, S. Yin, X. Zhao, Z. Ji, G. Zhong and J. Bai, “MuMath: Multi-perspective Data Augmentation for Mathematical Reasoning in Large Language Models,” arXiv preprint arXiv:2405.07551, May 2024."}, "questions": {"value": "1) Could you also state that in appendices A.2 contain results for prime moduli (in the first para of Section 3)?\n2) Have you tried any experiments where you leverage the ability of the model to learn multiple tasks by then focussing on each of the tasks individually? An example could be to see if further finetuning is necessary for a model to learn just ADD once it has learnt MAX+MED+ADD?\n3) Another experiment in the same vein might be to try to finetune models to learn slightly OOD tasks (eg. PROD which is ADD in log space).\n4) Finally, if time permits, another interesting experiment to try would be to see what happens if the tasks are presented in a continual learning fashion? Is that as useful as joint learning?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "J39azGVTXg", "forum": "N35pVnh31b", "replyto": "N35pVnh31b", "signatures": ["ICLR.cc/2026/Conference/Submission15279/Reviewer_e3ET"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15279/Reviewer_e3ET"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15279/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761755357977, "cdate": 1761755357977, "tmdate": 1762925580201, "mdate": 1762925580201, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies how small transformer models learn algorithmic tasks, particularly compositional mathematical operations such as those in the ListOps. The authors explore how task difficulty, model size, and training curriculum interact to influence learning efficiency and the emergence of abilities in small models."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "Quality and Originality: The paper presents a systematic empirical exploration of how joint task training impacts the learning thresholds of small transformer models and attempts to reframe the understanding of scaling laws."}, "weaknesses": {"value": "1. Lack of Novelty. Results are not surprising and authors need to discuss the multi-task learning (i.e., joint training can improve the performance is a common wisdom) and curriculum learning literature. Authors in the introduction discuss scaling laws but they do not provide the exact formulation of laws that contain curriculum learning factors. No precise alternative of KC complexity as well.\n\n2. Small-scale experiments do not support motivations and hurt significance: Authors only conduct experiments on a small scale, not widely used Transformers architecture, and I cannot verify if this can be generalized to larger architectures. Also, based on the text part of Model Architecture, it's hard to reproduce the used model, and the authors should provide more details there (for example, providing a figure or model signature with specific layers will be very helpful to understand your experiments). Larger scale (with more parameters) experiments seem important to verify anything related to \"scaling laws\".\n\n3. Potentially Trivial Experiments: Not sure if basic arithmetic + permutation group computations (although controllable) are important targets for LLM analysis. When the authors say EASY/HARD tasks, I find it surprising that some of these synthetic tasks are hard for these transformer models and before the Methodology section, I strongly recommend the authors provide preliminary background knowledge to explain the context.\n\n4. Presentation and clarity could be significantly improved. There are too many references to the Appendix without a careful explanation of details about what these experiments are in the main text (For example, line 80 Appendix K) and till line 80 it's hard to understand what is this randomized sum table and its difference with pure SUM.  For permutation groups operations, like OP, it will be much better to provide a concrete example in the main body. Also please fix the presentation of Figure 2 since some texts now overlap."}, "questions": {"value": "1. How well do these findings transfer to natural language or real-world multi-task learning scenarios? Demonstrating such transfer would strengthen the broader relevance of the conclusions.\n2. Can the authors formalize or quantify how task combinations interact to better predict which combinations yield synergy versus interference?\n3. Can the authors situate their findings within the broader context of several key work of scaling law theory and at least think about how to incorporate the missing parts like curriculums?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "VAmRINKVr8", "forum": "N35pVnh31b", "replyto": "N35pVnh31b", "signatures": ["ICLR.cc/2026/Conference/Submission15279/Reviewer_72MW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15279/Reviewer_72MW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15279/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761876852164, "cdate": 1761876852164, "tmdate": 1762925579597, "mdate": 1762925579597, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates how joint task training can reduce the parameter requirements for learning arithmetic tasks. The authors also provide a preliminary mechanistic explanation suggesting that joint training leads to more structured embeddings."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper presents several interesting phenomena\n\n- The embeddings of jointly trained models separate even and odd numbers on ADD and PROD tasks. \n- The experiment on shuffled SUM suggests that the benefit of joint training emerges only when the easy and hard tasks share underlying numerical properties (Figure 3).\n- The transfer learning experiment demonstrates that pretraining on simpler tasks and then transferring to harder ones is an effective curriculum. (Figure 5)"}, "weaknesses": {"value": "- The novelty and significance of the work may be limited.\n  - The general observation that joint training or curriculum learning benefits language models, including for arithmetic tasks, has been reported previously. The most related prior work I know is [1]; it would be helpful for the authors to clarify how their approach and findings differ from that work.\n  - While the finding that joint training leads to more structured embeddings is interesting, the paper does not analyze how these embeddings form or how they influence the parameter requirements of learning the task.\n- It would be helpful if the authors could more explicitly summarize the main takeaways, epspecially how the findings on synthetic tasks might transfer to more realistic scenarios.\n- The transfer learning experiment in Section 3.1 does not convincingly support the “embedding-restriction” hypothesis to me, as the results do not directly demonstrate that the effective search space is reduced.\n\n- The paper would benefit from including at least a minimal related-work section in the main text for better contextualization.\n- Minor comments (do not affect the score):\n  - l161 \"sizewe\" -> \"size we\".\n  - The interchangeable use of *SUM* and *ADD* could be confusing; I recommend using one consistently.\n  - Figure 2a: the two subplots overlap.\n  - Figure 2 caption (line 266): “(c)” should likely be “(b)”.\n  - l348 \"The also show\"."}, "questions": {"value": "- Why did the authors choose to use a recurrent version of the Transformer instead of a standard multi-block architecture? Would the results remain consistent under a conventional architecture? It would be useful to clarify this choice more explicitly.\n\n- How did the authors determine the performance for a fixed number of parameters? As discussed in Section 4, even after convergence, grokking may occur for arithmetic tasks.\n- The jointly trained embeddings reportedly separate even and odd numbers. Do the authors have an explanation for why such parity patterns emerge in the ADD and PROD tasks, given that parity does not appear to play a direct role in either task?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qKmAgSAErH", "forum": "N35pVnh31b", "replyto": "N35pVnh31b", "signatures": ["ICLR.cc/2026/Conference/Submission15279/Reviewer_S5KR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15279/Reviewer_S5KR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15279/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762004026776, "cdate": 1762004026776, "tmdate": 1762925579171, "mdate": 1762925579171, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}