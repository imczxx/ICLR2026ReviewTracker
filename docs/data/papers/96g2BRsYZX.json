{"id": "96g2BRsYZX", "number": 7314, "cdate": 1758015373743, "mdate": 1759897860491, "content": {"title": "GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent System", "abstract": "In the realm of multi-agent systems, the challenge of partial observability is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide.\nTo solve this issue, we propose Global State Diffusion Algorithm to infer the global state based on the local observations.\nBy formulating the state inference process as a multi-modal diffusion process, GlobeDiff overcomes ambiguities in state estimation while simultaneously inferring the global state with high fidelity.\nWe prove that the estimation error of GlobeDiff under both unimodal and multi-modal distributions can be bounded.\nExtensive experimental results demonstrate that GlobeDiff achieves superior performance and is capable of accurately inferring the global state.", "tldr": "", "keywords": ["Multi-Agent Systems", "Partial Observability", "Diffusion Models"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a98b9079bb557b78d362e93e2e98228315c73799.pdf", "supplementary_material": "/attachment/d222440a495374faf6596bd26dfa57bc20eb8fa8.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces the idea of using diffusion models to infer full state observations from local (single agent) observations in general partially observable multi-agent reinforcement learning problems. They provide some analysis of how to cast the learning problem in terms of the generative models, they derive theoretically some error bounds in the expected prediction errors between the generative model and the true fully observable state, and include a wide range of empirical results demonstrating how incorporating a diffusion model into a baseline MARL algorithm helps improve significantly the average returns obtained by the agents."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The problem is highly relevant. Partial observability in dec-POMDPs is a prevalent bottleneck in terms of general MARL algorithms succeeding at producing optimal distributed policies in complex MARL environments.\n- The solution the authors propose is reasonable and very straightforward: use powerful generative models to aid agents form posterior densities over true fully observable states based on local observations.\n- The empirical results seem thorough, and the authors compare against a reasonable amount of baselines."}, "weaknesses": {"value": "- Using diffusion models to approximate posterior distributions of fully observable states in Dec-POMDPs is not really a novel idea. See [1]; authors even test MAPPO implementations with diffusion generative models in the SMAC benchmarks.\n- Theorem 1 does not really add any insight or seems to be particularly useful; it states that the expected approximation error between true samples and generated ones is bounded by a linear combination of some distance between distributions and the variance of the generative model (this is not a very insightful result). The proof also follows almost immediately from the triangle inequality.\n- I am slightly concerned of the validity of the baseline comparisons. I am not convinced it is fair to compare GlobeDiff+MAPPO against a vanilla MAPPO with the same number of trainable parameters. See below for a question on this.\n- Some sentences in the introduction are not very clear. First, I would appreciate some nuance in the assumption that a MARL problem is necessarily partially observable (this is not the case in general, there are game theoretic problems that are fully observable like eg bimatrix games...). Also, the following sentence (lines 49-51) is not clear: \"Unfortunately, the focus on interpreting past experiences without significantly enhancing the agent's ability to leverage global information\". Isn't interpreting past experiences a way of inferring global information?\n- (*Minor but I had to raise it*) In the paper title, as well as in the first line of the introduction, 'multi-agent system' should be plural, 'multi-agent systems', and the first line should be 'Multi-agent systems have...'.\n \n\n[1] Wang, Tonghan, et al. \"On Diffusion Models for Multi-Agent Partial Observability: Shared Attractors, Error Bounds, and Composite Flow.\" Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems. 2025."}, "questions": {"value": "1. Can the authors reference [1] above and frame their work in this context? I believe the author's experimental results are more thorough than [1], but I believe it affects the claims that diffusion models have not been used in Dec-POMDPs.\n2. Is theorem 1 a contribution of equal weight as Theorem 2? I am not sure it's a relevant result, I believe more space dedicated to Theorem 2 would probably benefit the paper.\n3. In eq (4) authors derive the ELBO of a generative model, which is a well known expression and a common approach to training variational approximations to posterior densities in general Bayesian generative problems. A reference to this and some nuance would make the paper clearer.\n4. I have a fundamental question about the baselines used to compare. In my view, GlobeDiff+MAPPO is in some way adding a large amount of model complexity to vanilla MAPPO. While there is no good way of measuring this and ensuring it's constant among all baselines, I don't believe it is fair to compare baselines against each-other without making any reference to the size of the policy/value networks. Were the architectures of the policies kept constant across all baselines? I would then argue that it is trivial that GlobeDiff+MAPPO provides a performance increase, since at the very least this is adding model complexity to the representation the agents learn. What I would be interested in knowing is, if for example, one can train GlobeDiff+MAPPO where the number of parameters in the networks (of the diffusion model + the RL policy) is **the same** as the number of parameters in a vanilla MAPPO policy. If even under comparable model complexity the authors observe such improvements, I will be more convinced that the approach adds any value to the MARL field. If under a similar (total) number of parameters the performance is similar, I would argue perhaps deep RL recurrent policies with enough complexity generate some form of internal representation of the global state reconstruction based on agent observations (which is, in fact, the implicit argument behind using recurrent policies in Dec-POMDPs)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qjX8hY1X57", "forum": "96g2BRsYZX", "replyto": "96g2BRsYZX", "signatures": ["ICLR.cc/2026/Conference/Submission7314/Reviewer_TZGo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7314/Reviewer_TZGo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7314/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761225333860, "cdate": 1761225333860, "tmdate": 1762919426818, "mdate": 1762919426818, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes GlobeDiff, a method that leverages a conditional diffusion model with a latent variable to infer the global state from local observations in partially observable multi-agent systems. The approach is integrated into the CTDE framework and evaluated on modified SMAC benchmarks. The paper includes theoretical error bounds and extensive experimental results showing superior performance over several baselines.\n\nWhile the core idea of using a generative model for state inference is novel in the MARL/PO context and the results are promising, the paper's presentation significantly undersells its contributions. The writing often obscures the key insights and motivations, making the work appear more incremental than it likely is."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Formulating global state inference as a conditional, multi-modal generation problem is a compelling and timely approach. The use of a diffusion model to capture the \"one-to-many\" mapping inherent in PO is a significant conceptual contribution beyond simple belief estimation.\n\nThe method is well-designed. The introduction of the latent variable z to handle multi-modality, coupled with the specific variational training objective (Eq. 10) that aligns the prior and posterior networks, is a non-trivial and thoughtful adaptation of the diffusion model framework for this problem.\n\nThe experimental results are comprehensive. GlobeDemonstrates consistent and significant performance gains across a wide range of challenging SMAC (PO) scenarios against a diverse set of baselines (belief-based, communication-based, and other generative models).\n\nProviding theoretical error bounds (Theorems 1 & 2) for both unimodal and multi-modal cases is a notable strength that adds rigor and credibility to the proposed approach.\n\nThe ablation studies (prior network, diffusion steps) effectively validate key design choices. The state reconstruction visualization using t-SNE and Voronoi polygons (Fig. 5) is excellent and provides clear, intuitive evidence of the model's capability."}, "weaknesses": {"value": "（1） The introduction successfully outlines the problem but fails to clearly and forcefully state the paper's core intellectual contribution. The description of GlobeDiff is presented as a method, not a solution to a fundamental challenge (the \"one-to-many\" mapping). The key insight—that generative models can sample from the distribution of plausible global states while discriminative methods collapse to a single mode—is buried in the methodology rather than being the central thesis of the paper.\n\n（2） The method section dives too quickly into mathematical derivations without first providing a high-level, intuitive overview of the framework. The reader is left to reverse-engineer the design philosophy from the equations. A paragraph explaining the roles of z as a \"mode selector\" and the loss function as a way to bridge the training-inference gap for z is crucial.\n\n（3） The analysis largely stops at reporting that GlobeDiff performs better. It lacks a deep, diagnostic analysis of why and when it excels.\n\n（4） There is no qualitative analysis of specific episodes or timesteps. For example, showing a situation where a local observation is ambiguous, and illustrating the different global states sampled by GlobeDiff versus the incorrect or averaged state estimated by a baseline (like Dynamic Belief) would be immensely powerful.\n\n（5） The paper's central claim is handling multi-modality, but this is not directly tested or contrasted. Quantifying the diversity of generated states (e.g., using metrics like Average Distance to Nearest Neighbor within a batch of samples for the same x) and comparing it to the diversity of the true underlying states would provide strong, direct evidence.\n\n（6） Attributing VAE/MLP's poorer performance merely to \"limited representation capacity\" is insufficient. A discussion, supported by visualization, showing that the VAE produces blurry \"averaged\" states would directly support the multi-modal argument.\n\n（7） The computational overhead of running a multi-step denoising process during execution is not discussed. This is a critical consideration for real-time applications.\n\n（8） A discussion of the method's limitations (e.g., performance in environments with extremely high-dimensional state spaces, or when the \"one-to-many\" mapping is exceptionally complex) would provide a more balanced view and guide future research."}, "questions": {"value": "The latent variable z is central to the method. Can you provide more intuition or analysis of what z learns to represent? Does it correspond to semantically meaningful aspects of the global state?\n\nThe communication scenario (Eq. 2) is presented but not analyzed. How critical is the quality and scope of the communicated information to the performance of GlobeDiff? Have you tested scenarios with limited or noisy communication?\n\nTheorem 2 requires a \"mode separation condition.\" How often do you expect this condition to hold in practice, and what is the empirical performance of GlobeDiff when the modes of the global state distribution are less well-separated?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "myju0aORFQ", "forum": "96g2BRsYZX", "replyto": "96g2BRsYZX", "signatures": ["ICLR.cc/2026/Conference/Submission7314/Reviewer_mKZR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7314/Reviewer_mKZR"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7314/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926020321, "cdate": 1761926020321, "tmdate": 1762919426430, "mdate": 1762919426430, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a novel method “GlobeDiff” for tackling partial observability in multi-agent systems by framing global state inference as a conditional, multi-modal denoising process. The proposed GlobeDiff algorithm leverages diffusion models to generate a belief over the global state from local observations, enhanced by a latent variable to handle ambiguity. The paper is supported by theoretical error bounds and extensive empirical evaluation on modified StarCraft Multi-Agent Challenge (SMAC) environments."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Novel and Innovative Technical Approach: The core idea of applying diffusion models to the problem of global state inference in Dec-POMDPs is highly innovative. Instead of traditional belief estimation or communication, the authors formulate the problem as a conditional generative task. The introduction of a latent variable z to model the one-to-many mapping from local observations x to potential global states s is a sophisticated and technically sound solution to a fundamental challenge in this domain.\n\n2. Strong Theoretical Foundation: The paper provides rigorous theoretical analysis, which is often lacking in deep learning-based MARL research. Theorems 1 and 2 establish formal bounds on the estimation error for both unimodal and multi-modal distributions. This theoretical grounding significantly strengthens the claims of the method's efficacy and provides insight into the conditions under which it is expected to perform well.\n\n3. Comprehensive and Convincing Experimental Evaluation: 1) The proactive modification of the SMAC benchmark to create a more challenging and appropriate testbed for partial observability (SMAC-v1/2 PO). 2) Extensive comparisons against a diverse set of strong baselines (LBS, Dynamic Belief, CommFormer) and ablations against other generative models (VAE, MLP)."}, "weaknesses": {"value": "1. Dependence on Offline Data and Potential Distribution Shift: The training mechanism relies on an initial offline dataset to pre-train the GlobeDiff model. In many practical MARL scenarios, such a representative offline dataset may not be available. Furthermore, while the model is updated online, the initial dependence on offline data and the potential for distribution shift between offline and online data phases remain non-trivial challenges that are not fully addressed.\n\n2. High Computational Complexity and Practical Overhead: Training and maintaining three separate components—the diffusion denoising network ϵθ, the prior network p_ϕ, and the posterior network q_ψ—is computationally expensive. The multi-step iterative denoising process during inference also adds latency. This complexity could be a major barrier to real-world deployment, especially in applications requiring low-latency decision-making or with limited computational resources."}, "questions": {"value": "1. how to apply the methods to a latency-aware environment?\n2. The authors compare against generative model baselines like VAE and MLP. However, given that you are using a history of observations (Eq. 1) in one scenario, how would a powerful sequence model like a Transformer [1,2], trained to directly predict the global state from the historical trajectory, perform as a baseline? \n\n[1] Sequential Asynchronous Action Coordination in Multi-Agent Systems: A Stackelberg Decision Transformer Approach   \n[2] PTDE: Personalized training with distilled execution for multi-agent reinforcement learning"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ydENmKabMF", "forum": "96g2BRsYZX", "replyto": "96g2BRsYZX", "signatures": ["ICLR.cc/2026/Conference/Submission7314/Reviewer_m4w8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7314/Reviewer_m4w8"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7314/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762081411215, "cdate": 1762081411215, "tmdate": 1762919425992, "mdate": 1762919425992, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}