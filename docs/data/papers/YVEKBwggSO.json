{"id": "YVEKBwggSO", "number": 18443, "cdate": 1758287850095, "mdate": 1759897103106, "content": {"title": "Towards Understanding the Transferability of Adversarial Suffixes in Large Language Models", "abstract": "Discrete optimization-based jailbreaking attacks on large language models aim to generate short, nonsensical suffixes that, when appended onto input prompts, elicit disallowed content. Notably, these suffixes are often transferable—succeeding on prompts and models for which they were never optimized. And yet, despite the fact that transferability is surprising and empirically well-established, the field lacks a\nrigorous analysis of when and why transfer occurs. To fill this gap, we identify three statistical properties that strongly correlate with transfer success across numerous experimental settings: (1) how much a prompt without a suffix activates a model’s internal refusal direction, (2) how strongly a suffix induces a push away from this direction, and (3) how large these shifts are in directions orthogonal to refusal. On the other hand, we find that prompt semantic similarity only weakly correlates with transfer success. These findings lead to a more fine-grained understanding of transferability, which we use in interventional experiments to showcase how our statistical analysis can translate into practical improvements in attack success.", "tldr": "", "keywords": ["adversarial attacks", "jailbreaks", "mechanistic interpretability"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/be06897fb503ec5ab0fe266fc53f3448c8d2f744.pdf", "supplementary_material": "/attachment/4e4cbc9c37d41da9f8253ee0fba66938fe982f83.zip"}, "replies": [{"content": {"summary": {"value": "This work investigates the transferability of adversarial jailbreak suffixes by analyzing their impact on a model's internal \"refusal direction\" vector. The study finds that transfer success is positively associated with suffix push and orthogonal shift. Conversely, transfer is negatively associated with \"refusal connectivity,\" which is how much the original prompt aligns with the refusal direction. The authors also conclude that semantic similarity between prompts is only a weak predictor of transfer success."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "This paper provides many interesting empirical analyses on suffix-based jailbreak attacks. For example, it identifies specific factors that strongly correlate with successful suffix-based transfer like suffix push and refusal connection. For another example, the analysis shows that the semantic similarity of a pair of prompts does not mean that a suffix originally generated for one prompt can more easily transfer to another one; this was found to be only a weak correlation."}, "weaknesses": {"value": "1. The paper's key discovery about the refusal direction and orthogonal shift is essentially identical to what Rep Steering[1] already showed. Rep Steering uses hidden representations in jailbreak attacks to push attacks toward the acceptance direction. They also ran experiments proving that jailbreaks work because they shift harmful prompts to look more like harmless ones in the representation space, using their proposed method. They even tested their conclusion on more advanced methods like AutoDAN.\n\t\n2. The experiments only test GCG-type suffixes. The paper needs to include tests with human-readable attack methods like AutoDAN.\n\t\n3. The experiments only use two small models: Qwen2.5-3B and Llama3.2-1B. Why didn't the authors test on larger models with better safety features? This is a significant limitation.\n\n[1] Towards Understanding Jailbreak Attacks in LLMs: A Representation Space Analysis"}, "questions": {"value": "1. How does your refusal direction finding differ from Rep Steering's existing work on representation shifts?\n\n2. Why test only GCG-related suffixes and not human-readable attacks like AutoDAN?\n\n3. Why test only on small models like Qwen2.5-3B and Llama3.2-1B instead of larger, safer variants?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "r7dWYFRQwm", "forum": "YVEKBwggSO", "replyto": "YVEKBwggSO", "signatures": ["ICLR.cc/2026/Conference/Submission18443/Reviewer_ssRD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18443/Reviewer_ssRD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18443/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761390886957, "cdate": 1761390886957, "tmdate": 1762928139528, "mdate": 1762928139528, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the mechanisms underlying the transferability of adversarial suffixes that can jailbreak LLMs when appended to harmful prompts. The authors conduct a large-scale statistical and interventional analysis and identify three geometric factors that correlate strongly with transfer success, refusal connectivity, suffix push, and orthogonal shift. Through experiments across several instruction-tuned models, the paper demonstrates that suffix push and orthogonal shift are consistently predictive of transfer success, while high refusal connectivity decreases transferability. Interventional experiments such as prompt rephrasing and modified GCG loss functions validate these insights and show how they can improve attack efficacy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "-\tThe paper presents a systematic and mechanistic study of adversarial suffix transferability in LLMs. This paper formalizes and quantifies it through interpretable geometric features linked to internal representations.\n-\tThe work is methodologically sound and well-controlled. Definitions of geometric quantities are clear and well-grounded in prior interpretability research on refusal directions.\n-\tThe findings provide a conceptual and practical framework for understanding why some jailbreaks generalize across prompts and models. \n-\tThe paper is clearly written and logically structured."}, "weaknesses": {"value": "-\tExperiments are limited to small-sized open models and a single dataset. Whether the conclusions generalize to larger frontier models or to more diverse jailbreak scenarios, such as multi-turn or multilingual settings, is unknown.\n-\tInter-model asymmetries (e.g., Llama to Qwen vs. Qwen to Llama) are observed but not fully analyzed. A more detailed discussion of how alignment strength or architectural factors influence these asymmetries would strengthen the argument.\n-\tMissing discussion with existing work on adversarial suffix transferability [1,2]. \n\n[1] Advancing adversarial suffix transfer learning on aligned large language models. EMNLP 2024.\n\n[2] Unnatural Languages Are Not Bugs but Features for LLMs. ICML 2025."}, "questions": {"value": "-\tDo larger or more strongly aligned models exhibit similar geometric relationships, or does stronger alignment reduce transferability via altered refusal representations? Any insight on how the way of model training/alignment contribute to these factors for transferability?\n-\tHave the authors tested whether the same correlations hold for other harmful prompt distributions or multi-turn jailbreaks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "waThhsewyA", "forum": "YVEKBwggSO", "replyto": "YVEKBwggSO", "signatures": ["ICLR.cc/2026/Conference/Submission18443/Reviewer_J1KW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18443/Reviewer_J1KW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18443/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761967874288, "cdate": 1761967874288, "tmdate": 1762928139021, "mdate": 1762928139021, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "```\nThis paper empirically analyzes how different factors could affect the transferability (across prompts or models) of jailbreak suffixes synthesized via ONLY the GCG attack. Main findings include: (1) jailbreak robustness of LLMs (or \"prompts\") might have connection with the LLM refusal direction, (2) semantically similar prompts do not lead to similar jailbreak suffixes. These findings may help the ML safety community to better understand the mechanism behind suffix jailbreak attacks.\n```"}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "```\nThis paper provides many interesting empirical analyses on suffix-based jailbreak attacks that I appreciate. For example, jailbreak suffixes can easily transfer within a single model but are difficult to transfer across different models. For another example, the semantic similarity of a pair of prompts does not mean that a suffix originally generated for one prompt can more easily transfer to another one.\n```"}, "weaknesses": {"value": "```\n1. A major weakness of this paper is that the authors only leverage a single jailbreak attack named GCG to conduct their empirical investigation, which is not enough. I believe that verifying the obtained findings on various jailbreak attacks beyond GCG attack is very important.\n\n2. Furthermore, one should also notice that GCG can only reproduce gibberish suffix texts to conduct attacks. So it remains unknown whether conclusions obtained from GCG would also hold for human-readable jailbreak suffixes. I suggest the authors adopt additional suffix jailbreak attacks that can produce **semantic** jailbreak prompts in their experiments such as BEAST [r1], Zhu's AutoDAN [r2], AmpleGCG [r3], AdvPrompter [r4], etc.\n\n3. In Definition 4 \"Refusal connectivity\", the authors propose to use the cosine similarity between the activation vector $a_i^{base}$ and the refusal direction $v_{refusal}$ to analyze/measure the jailbreak robustness of LLMs (i.e., Figure 4 in Section 5.3). I cannot see the motivation behind this. The refusal direction is defined as the difference between the (averaged) normal activation vector and the (averaged) refusal activation vector, why would one want to analyze the similarity between the activation vector and the \"activation vector difference\"? After all, how can a \"(prompt's) activation feature\" be compared with a \"direction\" in the activation space?\n\n\n**References**\n\n[r1] Sadasivan et al. \"Fast Adversarial Attacks on Language Models In One GPU Minute\". ICML 2024.\n\n[r2] Zhu et al. \"AutoDAN: Interpretable Gradient-Based Adversarial Attacks on Large Language Models\". COLM 2024.\n\n[r3] Liao et al. \"AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs\". COLM 2024.\n\n[r4] Paulus et al. \"AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs\". ICML 2025.\n```"}, "questions": {"value": "```\nSee **Weaknesses**.\n```"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "poMAnRJH0U", "forum": "YVEKBwggSO", "replyto": "YVEKBwggSO", "signatures": ["ICLR.cc/2026/Conference/Submission18443/Reviewer_zopi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18443/Reviewer_zopi"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18443/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762102658837, "cdate": 1762102658837, "tmdate": 1762928138582, "mdate": 1762928138582, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the mechanism underlying the transferability of adversarial suffixes in large language models (LLMs). The authors conduct a statistical and interventional analysis to understand why certain adversarial suffixes—optimized on one prompt or model—can successfully jailbreak others.\nThe study introduces three geometric factors derived from the models’ activation space—refusal connectivity, suffix push, and orthogonal shift—and quantifies their influence on transfer success through large-scale experiments."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper features a comprehensive empirical setup, covering multiple model families and including both intra-model and inter-model transfer analyses, which enhances the generalizability of the conclusions.\nIts findings have direct implications for understanding and improving the robustness (or conversely, the design) of jailbreak attacks against LLMs."}, "weaknesses": {"value": "A key limitation lies in the lack of deeper mechanistic explanation. While the correlations between geometric features and transfer success are clearly demonstrated, the causal reasoning behind why these specific directions influence model behavior remains insufficiently explored. In particular, the paper does not explain why a larger “suffix push” geometrically leads to semantic compliance or behavioral change in the model."}, "questions": {"value": "1. On semantic similarity experiments: Since the GCG-generated suffixes are largely meaningless, it seems plausible that they contribute minimally to the embedding similarity between original and adversarial prompts. Could the authors visualize or report the embedding distribution of base versus adversarial prompts to validate this assumption?\n2. On Figure 5: The observation that adding the least successful suffixes only marginally reduces refusal alignment, while the most successful suffixes cause a significant drop, appears somewhat counterintuitive. Could the authors provide further explanation —e.g., examining dependence on layer depth or suffix length—to clarify the underlying cause?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XvRxyrbmt6", "forum": "YVEKBwggSO", "replyto": "YVEKBwggSO", "signatures": ["ICLR.cc/2026/Conference/Submission18443/Reviewer_GpgR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18443/Reviewer_GpgR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18443/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762161862740, "cdate": 1762161862740, "tmdate": 1762928137885, "mdate": 1762928137885, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}