{"id": "jcFH0AUux2", "number": 15876, "cdate": 1758256389509, "mdate": 1759897275931, "content": {"title": "Beyond Expert-Annotated Labels: An Adaptive Label Learning Method for Knowledge Tracing", "abstract": "Knowledge Tracing (KT) serves as an indispensable technology in intelligent tutoring systems (ITS), aiming to predict learners' future performance based on their past interactions. Current KT models commonly use predefined knowledge concept (KC) labels to improve prediction accuracy. These labels provide grouping information about questions, allowing models to infer learners' performance on low-frequency questions. However, the subjectivity of human labeling may not accurately reflect which questions share similar cognitive processes, potentially limiting the models' performance. To address this, we redefine KT as a problem of learning from question groupings and introduce an adaptive framework that iteratively refines groupings through alternating optimization. We initiate with random groupings and freeze them to optimize the KT model with gradient descent, then select the loss-minimizing configuration by computing the loss for each possible reassignment of questions to different groups under continuous assignment probabilities, repeating this process until convergence. We evaluate our approach on real-world ITS datasets, incorporating the optimized groupings into different KT models instead of KCs, which markedly improves model performance and achieves state-of-the-art results. Further experiments uncover the underlying semantic connections between our automatic groupings and prior KCs, revealing potential similarities in cognitive mechanisms among KCs, providing new insights and research directions for educational and cognitive sciences. Code is available in the supplementary materials.", "tldr": "We propose an adaptive framework for optimizing question groupings in Knowledge Tracing models, which significantly enhances prediction accuracy and uncovers hidden cognitive mechanisms among questions.", "keywords": ["Knowledge Tracing", "AI for Education", "Assessment", "Adaptive Label Learning"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2944c5a2c1b94448ec1bebf0388ffac09bf6d99d.pdf", "supplementary_material": "/attachment/ad83ef4d77ce0ad4b0912851ca70a3016bd51008.zip"}, "replies": [{"content": {"summary": {"value": "The paper reframes the knowledge graph learning in Knowledge Tracing (KT) as learning from question groupings rather than relying on expert-annotated knowledge concepts (KCs). It proposes ALL4KT, an alternating-minimization framework that: \n- initializes random question-to-group assignments, \n- trains a chosen KT model with these groups fixed, \n- evaluates the global loss that would result from reassigning each question to each group, \n- performs a soft (Sinkhorn/OT) relaxation over this loss matrix to obtain assignment probabilities before taking an argmax to update groups.\n\nExperiments on ASSIST2009, ASSIST2012, Algebra2005, and Bridge2006 show consistent gains over question-ID and KC-labeled baselines across multiple KT models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- Comprehensive empirical validation across four real datasets and eight KT architectures, with 5-fold CV and multiple metrics (AUC/ACC/RMSE)\n- The pipeline diagram (Figure 1) and problem formalization are easy to follow\n- Results suggest data curation / labeling quality can outweigh architecture complexity, this is interesting."}, "weaknesses": {"value": "1. A lot of structure-aware and transformer-based works are missing in the related works and are not compared. E.g., GKT (Nakagawa et al., 2019), QIKT (Chen et al., 2023), PSIKT (Zhou et al., 2024), HKT (Wang et al., 2021), GIKT (Yang et al., 2022). You should compare the structure learned across all kinds of models instead of only reporting prediction accuracy. \n\n2. If I understand correctly, the proposed grouping removes the expert-annotated KC graph and instead rediscover KCs and their relationships in a data-driven manner. But it gives you unlabeled groups whose semantics are unknown. In real educational practice, teachers and curriculum designers need interpretable KCs to build or adjust curricula. Without access to ground-truth KC labels, how can these automatically discovered groups be named or interpreted in a way that supports educational use?\n\n3. While KC unreliability is well-motivated, the experimental baselines do not include automatic skill discovery / Q-matrix learning / item clustering approaches that are closer in spirit to ALL4KT (e.g., data-driven KC discovery, item–skill mapping, item-embedding clustering, or the baselines I mentioned in point 1). The paper cites relevant ones but doesn’t compare against such methods,\n\n4. Complexity analysis is thorough, but empirical runtime/compute is not reported. For large |G| and many questions, computing L (size |Q|×|G|) by sweeping reassignment costs is quite heavy. The paper lists hardware/software (Sec. 4.1) but does not provide wall-clock times, number of outer iterations actually used before convergence in each dataset, or sensitivity to dataset size.\n\n5. The method relabels seen questions. For unseen questions (common in production), how are groups assigned without re-running the alternating procedure? There’s no content-feature encoder or item-embedding kNN mapping described.\n\n6. I found the three evaluation settings (“Q”, “KC”, and “Ours”) in Table 2 somewhat unclear:\n    - How exactly is “question information” used in the “Q” setting, are embeddings learned per question ID?\n    - In the “KC” vs. “Ours” comparison, do both settings have comparable parameter counts? If “Ours” learns additional structure (group assignments) while “KC” uses fixed labels, then “Ours” effectively introduces extra learnable parameters, which might explain better predictive performance. It would be informative to test performance in low-data regimes.\n    - Why initialize group assignments randomly rather than starting from the KC graph or using KC-informed priors? How stable is the grouping? \n\n7. The group-KC semantic analysis (Figure 5) is interesting, but the claim that the resulting \"uncommon\" groups reflect cognitive mechanisms seems overstated. Without more validation, such as teacher labeling, student error pattern analysis, or item-content alignment, it is difficult to rule out that the discovered associations are superficial correlations."}, "questions": {"value": "Please find them in the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6UVqnGvgMj", "forum": "jcFH0AUux2", "replyto": "jcFH0AUux2", "signatures": ["ICLR.cc/2026/Conference/Submission15876/Reviewer_UbwN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15876/Reviewer_UbwN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15876/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761659220281, "cdate": 1761659220281, "tmdate": 1762926094985, "mdate": 1762926094985, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ALL4KT, an adaptive label learning method that formulates Knowledge Tracing as a question-grouping problem rather than relying on expert-annotated knowledge concepts. The method iteratively refines question groupings using alternating minimization: optimizing model parameters via gradient descent and reassigning questions to groups based on loss minimization. Extensive experiments across four real-world ITS datasets demonstrate that ALL4KT consistently improves performance across several backbone models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed method makes it possible to not using expert-labeled question groups. Instead, the KCs are learned addaptively.\n2. The proposed method shows consistant improvements over different backbone models.\n3. Provide theoretical analysis of the proposed optimization method."}, "weaknesses": {"value": "1. Some details are missing: How does the KT model utilize the information in matrix Z? Is the gourp information corresponding to a embedding vector that is trainable?\n2. The used datasets seem very old, which are from about 15 years ago. Could be better to use more recent datasets to demonstrate the strengths of the model.\n3. The time complexity of the proposed model is high. As shown in Sec 3.4, it is propotional with user number. So it is very diffcult to scale when the user amount is large. While the used benchmark datasets are very small, making it difficult to judge the actual training cost of the method."}, "questions": {"value": "Please refer to the weaknesses part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "S77uQ1QJWP", "forum": "jcFH0AUux2", "replyto": "jcFH0AUux2", "signatures": ["ICLR.cc/2026/Conference/Submission15876/Reviewer_NhaU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15876/Reviewer_NhaU"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15876/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761824028237, "cdate": 1761824028237, "tmdate": 1762926094139, "mdate": 1762926094139, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an adaptive label learning method for KT, ALL4T, that learns optimal question groupings to overcome the limitations of subjective, expert-annotated KC labels. The method uses an alternating optimization framework, starting with random groupings and iteratively refining them by training the KT model and then updating assignments to minimize loss, using a relaxation strategy to avoid local optima. Experiments show that replacing traditional KCs with these learned groupings significantly boosts the performance of various KT models on real-world datasets, achieving SOTA results."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper introduces ALL4KT, an adaptive framework that learns data-driven question groupings instead of relying on subjective, expert-annotated KCs. By replacing KCs with these optimized groupings, the method markedly improves the performance of various KT models and achieves SOTA results across four real-world datasets.\n- The method uses alternating minimization to iteratively refine groupings. Crucially, it employs an assignment relaxation strategy based on optimal transport to avoid the local optima and oscillations associated with greedy hard assignments. This soft assignment approach effectively balances exploration and exploitation to find more stable and meaningful groups.\n- The optimized groupings enhance model robustness, especially for low-frequency questions where models typically struggle due to data scarcity. Furthermore, a semantic analysis of the learned groups uncovers underlying cognitive connections and unexpected relationships between KCs that are not captured by manual labels, providing new, data-driven insights for cognitive science."}, "weaknesses": {"value": "- The paper questions the subjectivity of expert-annotated multiple KCs but provides no empirical evidence to support this claim. Furthermore, the motivation itself is partially flawed; for instance, KCs in datasets like ASSISTments (arithmetic) are often objective and fixed, a distinction the paper fails to address.\n- The \"question assignment matrix\" (line 133) is widely known in the educational domain as the Q-matrix [1]. The paper overlooks the extensive body of research dedicated to Q-matrix optimization [2-4], which may diminish the novelty of its contribution.\n- The proposed question-centric approach may be inefficient, as the number of questions is typically vast (which is why most KT models are KC-centric). This inefficiency clashes with the real-time processing demands of KT systems. Moreover, the method's heavy reliance on the Q-matrix makes it inapplicable to datasets without predefined KC labels ($e.g.$, Statics2011 [5]), severely restricting its scope.\n- The evaluation should be based on more benchmark against recent research. The method, which processes multiple KCs as a single input, is not compared against relevant prior work [6] addressing the same setup.\n\n[1] Rule Space: An Approach for Dealing with Misconceptions Based on Item Response Theory\n\n[2] An Empirically Based Method of Q-Matrix Validation for the DINA Model: Development and Applications\n\n[3] Using Machine Learning to Improve Q-matrix Validation\n\n[4] Attentive Q-Matrix Learning for Knowledge Tracing\n\n[5] A Data Repository for the EDM Community: The PSLC DataShop\n\n[6] Interpretable Knowledge Tracing with Multiscale State Representation"}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "uPs5YNcRQ1", "forum": "jcFH0AUux2", "replyto": "jcFH0AUux2", "signatures": ["ICLR.cc/2026/Conference/Submission15876/Reviewer_5bjP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15876/Reviewer_5bjP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15876/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972094388, "cdate": 1761972094388, "tmdate": 1762926093693, "mdate": 1762926093693, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles the reliance of Knowledge Tracing (KT) on manually defined Knowledge Concepts (KCs) by proposing ALL4KT, a framework that learns question groupings automatically through alternating minimization and Sinkhorn-based soft assignment. It iteratively alternates between training KT models with fixed groupings and reassigning questions based on loss minimization, using probabilistic relaxation to avoid local optima.\n\nALL4KT is model-agnostic and improves AUC, accuracy, and RMSE across several KT backbones (DKT, DKVMN, AKT, ReKT, FlucKT) and four public datasets. The learned clusters show interpretable cognitive patterns.\n\nWhile empirically strong, the method’s novelty is limited, it applies standard alternating optimization. The work would benefit from deeper theoretical grounding, runtime efficiency analysis, and quantitative validation of the discovered semantic structure."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper identifies an important weakness in existing KT pipelines, the reliance on noisy, subjective expert labels, and proposes a principled data-driven alternative.\n- The alternating optimization setup can be applied to various KT models without modifying their structure, making the method easy to integrate.\n- Experiments across multiple datasets and baselines consistently show improvements, supporting the claim that learned groupings can outperform expert KCs.\n- The semantic analysis of learned groups offers qualitative insight into the relationships among questions and cognitive concepts."}, "weaknesses": {"value": "- The method is essentially a straightforward application of alternating minimization with Sinkhorn relaxation. While the framing within KT is new, the optimization machinery itself is standard and lacks deeper theoretical innovation.\n- The convergence discussion only shows monotonic loss reduction but does not guarantee good local minima or meaningful clustering. There is no analysis of identifiability or generalization of the learned groupings.\n- The approach retrains the KT model multiple times and computes loss matrices for every question–group pair, which may be prohibitive for large-scale or online ITS deployments."}, "questions": {"value": "- How sensitive are the results to random initialization of group assignments?\n- What is the computational overhead compared to a single KT training run?\n- Can the method handle multi-label settings (questions belonging to multiple KCs)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "kvg9l41Lzp", "forum": "jcFH0AUux2", "replyto": "jcFH0AUux2", "signatures": ["ICLR.cc/2026/Conference/Submission15876/Reviewer_XKTo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15876/Reviewer_XKTo"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15876/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982947357, "cdate": 1761982947357, "tmdate": 1762926093345, "mdate": 1762926093345, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}