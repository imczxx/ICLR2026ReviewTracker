{"id": "1vacZJxi56", "number": 4301, "cdate": 1757658703199, "mdate": 1763439122745, "content": {"title": "Secret-Protected Evolution for Differentially Private Synthetic Text Generation", "abstract": "Text data has become extremely valuable on large language models (LLMs) and even lead to general artificial intelligence (AGI).\nA lot of high-quality text in the real world is private and cannot be freely used due to privacy concerns. Therefore, differentially private (DP) synthetic text generation has been proposed, aiming to produce high-utility synthetic data while protecting sensitive information.\nHowever, existing DP synthetic text generation imposes uniform guarantees that often overprotect non-sensitive content, resulting in substantial utility loss and computational overhead. Therefore, we propose Secret-Protected Evolution (SecPE), a novel framework that extends private evolution with secret-aware protection. \nTheoretically, we show that SecPE satisfies $(\\vp, \\vr)$-secret protection, constituting a relaxation of Gaussian DP that enables tighter utility–privacy trade-offs, while also substantially reducing computational complexity relative to baseline methods.\nEmpirically, across the OpenReview, PubMed, and Yelp benchmarks, SecPE consistently achieves lower Fréchet Inception Distance (FID) and higher downstream task accuracy than GDP-based Aug-PE baselines, while requiring less noise to attain the same level of protection. \nOur results highlight that secret-aware guarantees can unlock more practical and effective privacy-preserving synthetic text generation.", "tldr": "", "keywords": ["synthetic data", "differential privacy"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/422d5e307447a8a6fcd7fae530c1bbfab2ad680d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes **Secret-Protected Evolution (SecPE)**, a novel framework for generating high-fidelity synthetic text under formal privacy constraints. Unlike traditional Differential Privacy (DP), which enforces uniform guarantees across all data points, SecPE introduces the concept of **Secret Protection**, focusing on safeguarding specific sensitive content (“secrets”) rather than entire records. The framework extends the Private Evolution (PE) paradigm and integrates a new **Secret Clustering** module, which leverages public data and limited noisy private updates to build secret-aware cluster centers for efficient selection. In the **Protected Evolution** phase, candidate synthetic texts are iteratively generated and selected based on similarity to these noisy representatives. Theoretical analysis shows that SecPE satisfies $(p, r)$-secret protection—a relaxation of Gaussian Differential Privacy (GDP)—and yields tighter utility–privacy trade-offs. Empirical results on **OpenReview**, **PubMed**, and **Yelp** datasets demonstrate that SecPE achieves lower FID, higher downstream accuracy, and significantly reduced computational cost compared to µ-GDP–based Aug-PE baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "### Strengths\n1. The paper introduces a **new privacy notion, (p, r)-secret protection**, that generalizes and relaxes Gaussian DP, offering a theoretically grounded yet more flexible privacy-utility balance.\n2. The proposed **SecPE algorithm** effectively combines secret-aware protection with the efficiency of K-means–based clustering, reducing computational complexity from $O(MN_{syn})$ to $O(KN_{syn})$.\n3. **Empirical results** on multiple datasets show consistent performance improvements, with SecPE achieving higher downstream accuracy and lower FID values compared to Aug-PE.\n4. The framework provides a **clear theoretical linkage** between secret protection and existing DP frameworks (DP, GDP), thereby establishing conceptual coherence.\n5. The experimental section is thorough, including analyses on efficiency, downstream accuracy, FID, and ablations over LLM size and clustering hyperparameters.\n\n### Quality\nThe paper is technically solid and theoretically well-founded. The connection between secret protection and Gaussian DP is clearly derived and mathematically consistent. The experimental evaluation is extensive and replicable. However, the lack of a real-world deployment or qualitative human evaluation of the generated text slightly limits the practical validation.\n\n## Clarity\nThe paper is **clearly written and well structured**, especially in the methodology section. Figures and algorithms (notably Algorithms 1–3) provide a good overview of the pipeline. However, some mathematical symbols (e.g., blow-up function and trade-off function) could be briefly explained when first introduced to enhance readability for non-privacy experts.\n\n### Significance\nSecPE represents a **notable conceptual advance** in privacy-preserving text generation, shifting from record-level to secret-level guarantees. Its relaxation of GDP could inspire a new line of research in secret-aware privacy mechanisms, potentially extending beyond text to multimodal settings. The method’s computational efficiency also makes it practical for real-world applications where DP-finetuning is infeasible."}, "weaknesses": {"value": "### Weaknesses\n1. The paper would be strengthened by **a more comprehensive comparison with DP-finetuned LLMs**, which, while computationally costly, have been shown to perform competitively in private text synthesis.\n2. Although the paper reports improvements in synthetic quality, **SecPE’s performance on personally identifiable information (PII)** tasks shows only marginal gains. The method’s real-world effectiveness in dense secret scenarios therefore remains somewhat inconclusive.\n3. The definition of \"secret\" remains **qualitative and application-dependent**. The paper acknowledges this limitation but does not explore strategies for adaptive or data-driven secret detection beyond keyword-level identification.\n4. The **sensitivity of the algorithm to different clustering sizes (K)** and to varying prior parameters $(p, r)$ could be analyzed more rigorously, as these hyperparameters directly influence both privacy guarantees and utility."}, "questions": {"value": "1. How sensitive is SecPE’s performance to the choice of secret prior probabilities \\(p_j\\)? Would a mis-specified prior significantly degrade the protection or utility?\n2. Could the authors discuss how SecPE scales when the number of secrets grows very large (e.g., thousands of potential sensitive attributes)?\n3. The authors mention that clustering abstracts away fine-grained details. Could this abstraction lead to mode collapse or reduced diversity in the generated synthetic data?\n4. In *user-level DP*, the protection unit is an **entire user’s data** (i.e., all records belonging to a user), whereas SecPE protects **individual secrets** regardless of user identity. Could SecPE be extended to user-level protection, or combined with it to achieve multi-granular privacy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lw6Joz8Cej", "forum": "1vacZJxi56", "replyto": "1vacZJxi56", "signatures": ["ICLR.cc/2026/Conference/Submission4301/Reviewer_2rqM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4301/Reviewer_2rqM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4301/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761834740660, "cdate": 1761834740660, "tmdate": 1762917285058, "mdate": 1762917285058, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Secret-Protected Evolution (SecPE), a novel framework for generating synthetic text that addresses key limitations in existing privacy-preserving methods. The authors identify that standard Differential Privacy (DP), imposes a uniform privacy guarantee that over-protects non-sensitive data, leading to unnecessary utility loss. The paper provides a strong theoretical foundation, proving the pipeline satisfies (p, r)-secret protection. Empirically, evaluations on OpenReview, PubMed, and Yelp benchmarks show SecPE consistently outperforms a GDP-based baseline."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Strengths include the novel and practical privacy formulation, some computational efficiency gains, comprehensive evaluation across multiple models and datasets"}, "weaknesses": {"value": "(1) The framework also relies on a clear definition of \"secrets\" and their prior probabilities (p), which is left somewhat ambiguous and could be a practical hurdle. \n\n(2) The presentation needs some improvement.   For example, the sentence on LIne 75-77 is not understandable.   The definitions needs some background knowledge, which is absent. \n\n(3) Finally, performance improvements are more modest when secrets are dense (as in a PII task), and the method's dependence on representative public data for clustering is not fully explored."}, "questions": {"value": "(1) How can secrets be systematically defined and their priors quantified in real-world scenarios?\n\n(2) Could adaptive clustering mitigate the minor utility loss in non-private settings?\n\n(3) How does the framework compose over multiple data releases"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xENwbkrkz7", "forum": "1vacZJxi56", "replyto": "1vacZJxi56", "signatures": ["ICLR.cc/2026/Conference/Submission4301/Reviewer_Rcqb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4301/Reviewer_Rcqb"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4301/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761873890848, "cdate": 1761873890848, "tmdate": 1762917284828, "mdate": 1762917284828, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a novel Secret Protection Evolutionary framework (SecPE) for differentially private (DP) synthetic text generation. The work aims to address the issue of significant utility loss and high computational overhead associated with traditional DP methods in text generation. By introducing the concept of Secret-Protected Evolution\tas an alternative to uniform DP guarantees,  it achieves a better utility-privacy trade-off. In the theoretical part, the paper defines a (p, r)-secret protection criterion and establishes its connection to Gaussian DP. The experimental section validates the advantages of SecPE across several benchmark datasets (OpenReview, PubMed, Yelp), demonstrating reductions in Fréchet Inception Distance (FID), improved accuracy on downstream tasks, and decreased runtime."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.This work proposes a (p,r)-secret protection framework and establishes its theoretical connection to Gaussian Differential Privacy (GDP), offering a new perspective for privacy-preserving research.\n2.The experimental design is comprehensive, and the validation is thorough."}, "weaknesses": {"value": "1.The paper operates on the assumption that \"secrets\" can be predefined; however, in real-world scenarios, sensitive content is often dynamic and non-enumerable.\n2.The paper fails to analyze the impact of the cluster number K on the effectiveness (it only mentions \"insensitive\" but provides no ablation studies).\n3.The improvement on the PII task is relatively limited (Table 7), potentially due to high secret density diminishing the protection benefits. Further analysis on the impact of secret sparsity is required."}, "questions": {"value": "The manuscript employs the term \"operative point\" on multiple occasions without providing a formal definition."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UTcQSRRciE", "forum": "1vacZJxi56", "replyto": "1vacZJxi56", "signatures": ["ICLR.cc/2026/Conference/Submission4301/Reviewer_ntT2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4301/Reviewer_ntT2"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4301/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761928887694, "cdate": 1761928887694, "tmdate": 1762917284567, "mdate": 1762917284567, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors adapt private evolution to offer guarantees under the “secret-protection” framework, which is a recent DP relaxation proposed by (Ganesh et al., 2025). They introduce a clustering step with public data to improve efficiency of PE. They conduct experiments by instantiating the secret-protection framework by declaring random words as “secrets” and examples containing them to betray the secret, showing utility improvements over regular PE that provides uniform protection."}, "soundness": {"value": 4}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The topic is of high importance to the community. Secret protection is a promising DP relaxation that can potentially address many “type mismatches” between DP and the kind of sensitive data that companies own and want to extract value out of. Synthetic data via private evolution is one of the least resource- and expertise-intensive ways to get something out of your sensitive data. For these two reasons, finding a good design here will unlock a lot of useful practical applications.\n\n- The experiments demonstrating utility improvement of SecPE compared to PE, in the setting where the secret protection definition is instantiated by declaring PII or random words as “secrets” (with examples containing them considered to betray the secret), are well-executed and highly interesting."}, "weaknesses": {"value": "- As secret protection is a relatively nascent privacy framework, I believe the authors could do more in terms of exposition in Section 3.1, as well as (1) give the specific instantiation of (S,E,T) (in the notation of (Ganesh et al., 2025)) that defines the neighboring relationship fundamental to applications of secret protection, and (2) describe how secret clustering relates to secret protection.\n\n  - Specifically, the authors give a relatively terse statement of the secret-protection definition. Lemma 3.2 proves GDP implies a particular instantiation of secret protection. Rather than focusing on this point, the main text would be better served to describe further the algorithmic changes to PE enabled by relaxation of the DP definition.\n\n- The core algorithmic tool for enabling the secret protection guarantee is from (Ganesh et al., 2025). Nothing particular PE under secret protection is introduced.\n\n- While authors report computational efficiency gains from SecPE, these gains feel misattributed. Reported speedup is in terms of improving pairwise similarity calculations. First, it is relatively unintuitive to me that the bottleneck is similarity computation, rather than iterative rewrites with a possibly expensive API model. Perhaps a FLOPs or memory analysis of the operation, compared to inference FLOPs and memory would shed some light here. Second, avoiding pairwise similarity computations seems orthogonal to SecPE, and there exist many simple and practical solutions to the problem for regular PE. For example:\n  - Using approximate nearest neighbours search over the index of synthetic examples (https://github.com/google-research/google-research/tree/master/scann).\n  - Clustering the synthetic data, and voting on clusters. Although not used in PE, this is employed in the highly-related work on private postprocessing (https://arxiv.org/abs/2402.13659), which can be viewed as half of one step of private evolution."}, "questions": {"value": "- Secret protection is instantated by a (S,E,T) tuple (in the notation of Ganesh et al, 2025). In experiments, what is T?\n\n- Any intuitions about how the number of secrets and their choice affect the utility improvement of SecPE compared to PE? Is this entirely predicted by the computed noise and sampling parameters?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ImaG7BWHi0", "forum": "1vacZJxi56", "replyto": "1vacZJxi56", "signatures": ["ICLR.cc/2026/Conference/Submission4301/Reviewer_Gvyt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4301/Reviewer_Gvyt"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4301/-/Official_Review"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763142151536, "cdate": 1763142151536, "tmdate": 1763142151536, "mdate": 1763142151536, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}