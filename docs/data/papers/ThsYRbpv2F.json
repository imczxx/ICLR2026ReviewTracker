{"id": "ThsYRbpv2F", "number": 1573, "cdate": 1756893183476, "mdate": 1763733166602, "content": {"title": "Grounding and Enhancing Informativeness and Utility in Dataset Distillation", "abstract": "Dataset Distillation (DD) seeks to create a compact dataset from a large, real-world dataset. While recent methods often rely on heuristic approaches to balance efficiency and quality, the fundamental relationship between original and synthetic data remains underexplored. This paper revisits knowledge distillation-based dataset distillation within a solid theoretical framework. We introduce the concepts of Informativeness and Utility, capturing crucial information within a sample and essential samples in the training set, respectively. Building on these principles, we define \\textit{optimal dataset distillation} mathematically. We then present InfoUtil, a framework that balances informativeness and utility in synthesizing the distilled dataset. InfoUtil incorporates two key components: (1) game-theoretic informativeness maximization using Shapley Value attribution to extract key information from samples, and (2) principled utility maximization by selecting globally influential samples based on Gradient Norm. These components ensure that the distilled dataset is both informative and utility-optimized. Experiments demonstrate that our method achieves a 6.1\\% performance improvement over the previous state-of-the-art approach on ImageNet-1K dataset using ResNet-18.", "tldr": "We propose a theoretically principled dataset distillation method which achieves SOTA performance.", "keywords": ["Explainable AI", "Generative AI"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/21cfc19a5affef93d17cec3cdbd7bfe56227977c.pdf", "supplementary_material": "/attachment/9185345929689a3083110cbcfad84b3ca4a39e79.pdf"}, "replies": [{"content": {"summary": {"value": "This paper proposes InfoUtil including two key concepts: Informativeness (how much useful information a sample carries) and Utility (how essential a sample is for training). InfoUtil maximizes these objectives via (1) Shapley Value-based informativeness attribution and (2) Gradient Norm-based utility selection. Experiments on ImageNet-1K with ResNet-18 show a 6.1% improvement over prior SOTA."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The presentation is clear and well-structured.\n\nThe theoretical analysis  is reasonably justified."}, "weaknesses": {"value": "I noticed that the authors carefully adopt different levels of teacher models to generate soft labels for different IPC settings. However, since this labeling strategy is directly borrowed from prior works rather than being a core contribution of this submission, it should be consistently applied to all comparison methods to ensure fairness, at least to RDED. Otherwise, part of the reported performance gain may be attributed to better soft labeling rather than the proposed method itself.\n\nThe performance on ConvNet with CIFAR is significantly weaker than that of recent competitors. In addition, several of the compared distillation-based baselines are outdated. Pls consider some newer and stronger baselines such as \n- Elucidating the Design Space of Dataset Condensation\n- Dataset Distillation via the Wasserstein Metric\n- Breaking Class Barriers: Efficient Dataset Distillation via Inter-Class Feature Compensator.\n- Heavy Labels Out! Dataset Distillation with Label Space Lightening\n\nThe current ablation is also insufficient. The contributions of GradNorm Scoring and Attribution Cropping should be clearly isolated from the carefully designed soft labeling strategy in order to demonstrate their real effectiveness. Furthermore, in large IPC settings, it is unclear why SRe²L and RDED are missing, especially given that both are already open-sourced and widely used. \n\nLines 435–436 in Table 6 report identical settings (both GradNorm Scoring and Attribution Cropping), yet the numbers differ. Please verify and correct.\n\nFinally, there are typos, e.g., “scriptsizeImageNet.” in line 364."}, "questions": {"value": "pls see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ut8u8fYTiF", "forum": "ThsYRbpv2F", "replyto": "ThsYRbpv2F", "signatures": ["ICLR.cc/2026/Conference/Submission1573/Reviewer_CGAE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1573/Reviewer_CGAE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1573/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761281501077, "cdate": 1761281501077, "tmdate": 1762915819667, "mdate": 1762915819667, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces InfoUtil, a theoretically grounded framework for dataset distillation that aims to generate compact yet highly representative datasets. The method operates in two key stages. In the first stage, it employs the Shapley value, a game-theoretic attribution method, to identify the most informative image patches, ensuring that each synthetic sample captures the essential visual and semantic information from the original data. In the second stage, InfoUtil selects samples based on their gradient norms, which serves as a principled measure of utility by estimating the influence of each sample on model training dynamics. This dual optimization of informativeness and utility enables the distilled dataset to retain both rich content and strong learning potential. Extensive experiments across multiple benchmark datasets and architectures demonstrate that InfoUtil not only achieves superior performance but also provides interpretability and computational efficiency compared to existing methods, making it a robust and scalable approach to dataset distillation."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "The strength of this work lies in its solid theoretical foundation and practical effectiveness. Unlike prior heuristic or empirical approaches, InfoUtil unifies the concepts of informativeness and utility within a principled mathematical framework, providing interpretability and transparency to dataset distillation. Its combination of game-theoretic Shapley value attribution and gradient norm-based sample selection ensures that the distilled data are both highly informative and influential for model training. Furthermore, InfoUtil achieves state-of-the-art performance across multiple benchmarks while being significantly more computationally efficient, requiring far less memory and training time than previous methods. This balance of theoretical rigor, interpretability, and scalability makes InfoUtil a robust and impactful contribution to the field of dataset distillation."}, "weaknesses": {"value": "Despite its strong theoretical grounding and empirical performance, the paper contains a few minor weaknesses. There are some typo errors. \n\n1. In lines 89–90, where the phrase \"we reconsider the knowledge distillation-based dataset distillation process by introducing Principled Dataset Distillation (Definition 4)\" should read \"Optimal Dataset Distillation\" to maintain consistency with the terminology used throughout the paper. \n2. Similarly, in line 323, the word \"nclude\" in “Baseline nclude trajectory-matching\" should be corrected to \"include.\""}, "questions": {"value": "A writing suggestion. In line 181-184, the authors should clarify which components are functions of \\tilde{D}. Explicitly specifying the elements that depend on the distilled dataset would improve the mathematical clarity of the formulation and help readers better understand how \\tilde{D} influences the optimization process."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0zJwU1m9AN", "forum": "ThsYRbpv2F", "replyto": "ThsYRbpv2F", "signatures": ["ICLR.cc/2026/Conference/Submission1573/Reviewer_987g"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1573/Reviewer_987g"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1573/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761386341592, "cdate": 1761386341592, "tmdate": 1762915819418, "mdate": 1762915819418, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper revisits knowledge-distillation-based dataset distillation and introduces a principled framework named InfoUtil, which jointly optimizes Informativeness and Utility in the synthesis of compact datasets. The authors formally define informativeness at the patch level using a Shapley-value–based game-theoretic attribution, and utility at the sample level using gradient flow. The proposed two-step pipeline first selects the most informative image regions and then retains high-utility samples via gradient-norm scoring. Extensive experiments on CIFAR, Tiny-ImageNet, and ImageNet-1K show consistent improvements over prior methods such as RDED and SRe2L."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Presents a clear theoretical framework that connects informativeness and utility under a unified definition of optimal dataset distillation.\n2. The use of Shapley-value–based attribution provides interpretability and theoretical grounding to the distilled sample selection.\n3. Demonstrates strong empirical performance across multiple datasets and architectures, showing robustness and scalability.\n4. Ablation studies and cross-architecture evaluations validate each component’s contribution and highlight the method’s generalizability."}, "weaknesses": {"value": "1. Although informativeness is formally defined as an optimization over binary masks (Eq. 2), the method substitutes this process with a Shapley-value attribution heuristic. The paper does not show that Shapley-based patch selection approximates or lower-bounds the true informativeness objective, nor does it provide conditions under which this substitution is valid. This leap from optimization to attribution lacks formal grounding, especially given nonlinear interactions among image regions.\n\n2. The theoretical analysis of Utility (Definition 2, Equation (3)) relies on a continuous-time gradient flow formulation to describe training dynamics. In this setup, parameter updates are modeled as smooth differential equations. However, in practice, training is conducted via discrete stochastic gradient descent (SGD) with randomness from data augmentation and normalization layers. The paper does not specify under what assumptions the continuous gradient flow accurately approximates the discrete SGD process (e.g., small learning rate, smooth loss landscape). Consequently, the theoretical derivations based on gradient flow may not faithfully represent real training behavior, which weakens the practical validity of the proposed Utility-based analysis.\n\n3. Theorem 1 establishes only an upper bound  $U(x, y) \\le c \\|\\nabla_{\\theta} \\ell(f_{\\theta}(x), y)\\|.$ However, using the gradient norm as a surrogate for utility in sample selection implicitly assumes a monotonic or bounded relationship between the two. Without a corresponding lower bound or a proof of ranking consistency, this substitution lacks theoretical justification; large gradient norms do not necessarily imply high utility. As a result, the theoretical foundation of the utility maximization step remains incomplete.\n\n4. The baseline methods used for the main comparison, namely RDED (CVPR 2024) and SRe2L (NeurIPS 2023), are relatively outdated. Several more recent dataset distillation techniques, such as EDC (NeurIPS 2024) and DELT (CVPR 2025), have demonstrated significantly improved performance and scalability. Without comparisons to these stronger and more up-to-date baselines, it is difficult to substantiate the claim that the proposed method achieves state-of-the-art or optimal performance.\n\n5. (Minor) In line 414, there should be a space between \"samples\" and \"We\".\n\n6. (Minor) Visualization is important; the authors are encouraged to move the results from Appendix F to the main paper for better clarity."}, "questions": {"value": "1. Could the authors further elaborate on the key differences between the proposed InfoUtil and RDED? From the visualizations, it appears that the improvement mainly comes from the occurrence of complete targets. However, in RDED, similar results can be achievable by simply adjusting the difficulty level of the selected patches. In that case, RDED could potentially produce images visually comparable to those from InfoUtil. I am therefore curious whether InfoUtil still provides additional information gain beyond what RDED can achieve through such adjustments.\n\n2. Is the Shapley-based patch selection the only possible approach to maximize informativeness? Could alternative attribution or saliency methods, such as Grad-CAM, achieve comparable results in practice? It would be helpful if the authors could clarify why Shapley values are particularly suited for this task and whether other approaches were considered or tested.\n\n3. I am curious whether the images distilled by InfoUtil could further improve the performance of training-based (TB) methods if used as initialization. Since InfoUtil is designed to generate informative and utility-optimized synthetic data, it would be interesting to investigate whether integrating it with TB approaches could lead to additional performance gains or faster convergence compared to using RDED for initialization."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DFR14bbNE3", "forum": "ThsYRbpv2F", "replyto": "ThsYRbpv2F", "signatures": ["ICLR.cc/2026/Conference/Submission1573/Reviewer_tEAx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1573/Reviewer_tEAx"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1573/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761416100152, "cdate": 1761416100152, "tmdate": 1762915819119, "mdate": 1762915819119, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper propose a new knowledge distillation-based dataset distillation approach that is better theoretically motivated compared to previous method. Their proposed method InfoUtil, which compresses the original dataset at a feature level and at a sample level. At the feature level, InfoUtils utilizes KernelShap to locate salient features within an image to crop on. At the sample level, InfoUtils calculate the gradient norm of each sample and filter samples with low values. InfoUtil demonstrate superior performance compared to previous methods on most benchmarks except for the popular dataset distillation setting: training simple CNNs on CIFAR-10."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. To the best of my knowledge, the proposed method is novel.\n2. The work is well motivated as many dataset distillation methods lack theoretical foundations.\n3. The proposed method outperforms two existing knowledge distillation-based dataset distillation methods: SRe2L and RDED."}, "weaknesses": {"value": "**1.** The storage budget for the resultant distilled dataset is missing in the paper. One of the key problem with knowledge-based dataset distillation methods is that the resulting distilled dataset can become considerably larger than expected due the soft-labeling [1,2], defeating the whole purpose of dataset distillation. With the lack information on storage size, the usefulness of the proposed method in practice is unclear. \n\n**2.** The performance in the most standard dataset distillation setting, training a simple Convent on CIFAR-10, is very subpar. For 1 image per class, the proposed method only achieves 28.5% compared to MTT 46.3%. BPTT and memory address [3], a previous work that is over 3 years old, achieves 49.1% and 66.4% respectively. While the standard dataset distillation setting maybe too simple and unrealistic, since this work positions itself as being theoretically grounded, the considerable gap in performance in this setting is concerning. To put into perspective, 28% is comparable to gradient matching [4], a dataset distillation work that is 5 years old. \n\n**3.** Missing more recent methods such as TEDDY [5] or EDF [6]. All of the baselines used for comparisons are from 2023 or earlier. \n\n**4.** Missing qualitative examples on what the distilled data looks like\n\n**5.** The presentation of the work should be improved. While the problem formulation is good, the argument in the paper does not provide adequate support as outlined below:\n\n**5.1.** The paper describes gradient flow and how it provides a better approximation of the training dynamics unlike SGD updates. However, the algorithm provided approximates the gradient flow measure with gradient norm, motivated by a bound derived with the assumption of SGD updates. It is unclear from the paper why this can be done as the argument seems very circular. Similarly, as the DATM paper shown, different patterns are learned at different stages of training. The paper lack any discussion on this topic. \n\n**5.2.** The paper outlines challenge 1 with the efficiency performance trade-off between matching-based dataset distillation method, but lack any further discussion as the method proposed is a knowledge-distillation based method\n\n**5.3.** Since the paper position itself as being more theoretically grounded, it needs more details on image reconstruction, soft label generation, and diversity control. For instance, adding random noise during the patch selection process is not grounded in the proposed theory at all. \n\n**5.4.** Minor typos: nclude -> include line 323,  table 6 ablation is confusing (row 2 and 3 are the same?)\n\n[1] Qin, Tian, Zhiwei Deng, and David Alvarez-Melis. \"A label is worth a thousand images in dataset distillation.\" Advances in Neural Information Processing Systems 37 (2024): 131946-131971.\n\n[2] Xiao, Lingao, and Yang He. \"Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?.\" Advances in Neural Information Processing Systems 37 (2024): 16406-16437.\n\n[3] Deng, Zhiwei, and Olga Russakovsky. \"Remember the past: Distilling datasets into addressable memories for neural networks.\" Advances in Neural Information Processing Systems 35 (2022): 34391-34404.\n\n[4] Zhao, Bo, Konda Reddy Mopuri, and Hakan Bilen. \"Dataset Condensation with Gradient Matching.\" Ninth International Conference on Learning Representations 2021. 2021.\n\n[5] Yu, Ruonan, et al. \"Teddy: Efficient large-scale dataset distillation via taylor-approximated matching.\" European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2024.\n\n[6] Wang, Kai, et al. \"Emphasizing discriminative features for dataset distillation in complex scenarios.\" Proceedings of the Computer Vision and Pattern Recognition Conference. 2025."}, "questions": {"value": "1. What is the connection between this work and works on data selection, data pruning, and corset selection? Dataset distillation typically optimize the distilled data itself, but the method provided seems to only crop photos and select a subset from real data.  It is unclear whether this constitutes as synthetic data.\n2. How important is adding noise to the patch selection process?\n3. How connected is the utility function, which utilizes gradient norm, to the empirical fisher information? i.e. does maximizing the utility function finds a subset with the maximal empirical fisher information?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "delwElmYP4", "forum": "ThsYRbpv2F", "replyto": "ThsYRbpv2F", "signatures": ["ICLR.cc/2026/Conference/Submission1573/Reviewer_fiHj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1573/Reviewer_fiHj"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1573/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761788167053, "cdate": 1761788167053, "tmdate": 1762915818978, "mdate": 1762915818978, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "(Part 1) General Response"}, "comment": {"value": "We sincerely thank the reviewers for their time and insightful feedback. We are encouraged by the recognition of InfoUtil’s theoretical grounding and are grateful for the constructive suggestions regarding baselines and rigorous validation. To address these points and demonstrate the superiority of our framework in scalable dataset distillation, we have conducted extensive new experiments and analyses during the rebuttal period.\n\n**1. Comprehensive Comparison with 7 New SOTA Baselines**\nTo validate InfoUtil against the latest state-of-the-art, we significantly expanded our evaluation scope. We compared our method against **7 recent baselines** including **DELT, EDC, WMDD, HeLLo, INFER, TEDDY, and EDF** (covering NeurIPS 2024 and CVPR 2025 works). Across these diverse benchmarks, InfoUtil consistently established a new State-of-the-Art, outperforming competitors like INFER by **10.3%** on CIFAR-10 and WMDD by **9.4%** on Tiny-ImageNet. We have provided results in **Table 8-9 in Appendix H** and **Table 11-13 in Appendix I** in the revised manuscript.\n\n**2. Rigorous Isolation of Core Contributions**\nWe addressed the concern regarding the soft-labeling strategy through a rigorous controlled experiment. By strictly unifying the teacher model (using the exact same Fully Converged Teacher for both the baseline RDED and InfoUtil), we demonstrated that InfoUtil still outperforms RDED (e.g., **+5.1%** on ResNet-18). This confirms that our performance gains stem from the proposed Informativeness and Utility modules rather than teacher tuning. We have provided results in **Table 19 in Appendix N** in the revised manuscript.\n\n**3. Superior Data Quality Validated via Initialization**\nFurthermore, we rigorously tested the intrinsic quality of our distilled data by using it as initialization for the training-based method **EDC**. The results show that initializing with InfoUtil consistently boosts EDC’s performance compared to standard or RDED initialization (e.g., **+0.9%** gain on ImageNet-1K). This confirms that our method captures more robust fundamental patterns. We have provided results in **Table 18 in Appendix L** in the revised manuscript.\n\n**4. Expansion to Large IPC Settings**\nWe extended our evaluations to challenging Large IPC settings (up to IPC=200) on Tiny-ImageNet and ImageNet-1K, adding missing comparisons with SRe²L and RDED. The results confirm that InfoUtil scales effectively, maintaining its advantage even when the budget increases. We have provided results in the revised manuscript.\n\n**5. Ablation Study on Design Choices**\nWe conducted comprehensive ablation studies to validate our specific design choices. Our comparison of **Shapley Value vs. Grad-CAM** confirms the necessity of game-theoretic attribution (**+13.49%** improvement). Additionally, ablations on **Noise Injection** demonstrate its critical role in ensuring diversity. We have provided results in **Table 16 in Appendix K** and **Table 17 in Appendix L** in the revised manuscript.\n\n**6. Efficiency and Storage Analysis**\nA detailed analysis further highlights the method's practicality. We verified that InfoUtil runs over **50× faster** than matching-based methods while maintaining a minimal storage footprint (comparable to RDED). Experiments with **Top-K label sparsification** further demonstrate that storage can be reduced by orders of magnitude without performance loss. We have provided results in **Table 7 in Appendix G** in the revised manuscript.\n\n**7. Comparison with Coreset Selection**\nTo explicitly distinguish our synthesis approach from selection methods, we benchmarked against standard Coreset Selection (Herding, K-Means). InfoUtil achieved massive gains (e.g., **7.6x higher** than Herding on ImageNet-1K), proving the necessity of our synthesis pipeline. We have provided results in **Table 14-15 in Appendix J** in the revised manuscript."}}, "id": "NIfhap6Wh8", "forum": "ThsYRbpv2F", "replyto": "ThsYRbpv2F", "signatures": ["ICLR.cc/2026/Conference/Submission1573/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1573/Authors"], "number": 17, "invitations": ["ICLR.cc/2026/Conference/Submission1573/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763733402442, "cdate": 1763733402442, "tmdate": 1763734418915, "mdate": 1763734418915, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "(Part 2) General Response"}, "comment": {"value": "We explicitly thank the Area Chair and all reviewers (Reviewers fiHj, tEAx, 987g, and CGAE) for their time and constructive feedback. We are encouraged by the reviewers' shared recognition of the necessity for scalable dataset distillation and by the \"**positive assessment**\" (Reviewer 987g) of our work.\n\nWe especially appreciate the acknowledgment that addressing the trade-off between storage budget and performance is a \"**key problem**\" (Reviewer fiHj) and an \"**important**\" challenge for the community (Reviewer CGAE). We share the view that isolating the \"**intrinsic gains**\" from soft-labeling strategies (Reviewer CGAE) is essential for rigorous method validation. As noted by Reviewer tEAx, our work demonstrates the potential of replacing heuristics with a \"**formally defined**\" framework.\n\nRegarding the methodology, we value the consensus on the soundness of our design. Reviewer fiHj explicitly noted that our \"**problem formulation is good**\" and Reviewer 987g appreciated the \"**principled**\" nature of our approach. Specifically, the game-theoretic grounding of our informativeness metric was a design that reviewers explicitly engaged with (Reviewer tEAx).\n\n**To comprehensively address the concerns and substantiate this design, we have conducted extensive additional evaluations, adding 7 recent SOTA baselines (DELT, EDC, WMDD, HeLLo, INFER, TEDDY, and EDF) and rigorous controlled experiments**. These revisions confirm our \"strong empirical performance\" (Reviewer CGAE) by demonstrating that InfoUtil establishes a new state-of-the-art (e.g., **+5.1%** over baselines with identical settings) and provides superior initialization for training-based methods."}}, "id": "DAPuyBb0Dk", "forum": "ThsYRbpv2F", "replyto": "ThsYRbpv2F", "signatures": ["ICLR.cc/2026/Conference/Submission1573/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1573/Authors"], "number": 18, "invitations": ["ICLR.cc/2026/Conference/Submission1573/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763734454887, "cdate": 1763734454887, "tmdate": 1763734454887, "mdate": 1763734454887, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}