{"id": "nP6dVUWZAE", "number": 6812, "cdate": 1757996721588, "mdate": 1759897892179, "content": {"title": "OATS: Online Data Augmentation for Time Series Foundation Models", "abstract": "Time Series Foundation Models (TSFMs) are a powerful paradigm for time series analysis and are often enhanced by synthetic data augmentation to improve the training data quality. Existing augmentation methods, however, typically rely on heuristics and static paradigms. Motivated by dynamic data optimization, which shows that the contribution of samples varies across training stages, we propose OATS (Online Data Augmentation for Time Series Foundation Models), a principled strategy that generates synthetic data tailored to different training steps. OATS leverages valuable training samples as principled guiding signals and dynamically generates high-quality synthetic data conditioned on them. We further design a diffusion-based framework to produce realistic time series and introduce an explore-exploit mechanism to balance efficiency and effectiveness. Experiments on TSFMs demonstrate that OATS consistently outperforms regular training and yields substantial performance gains over static data augmentation baselines across six validation datasets and two TSFM architectures. The code is available at the link https://anonymous.4open.science/r/OATS-536E.", "tldr": "", "keywords": ["time series foundation model", "data augmentation"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/267c0d44dcbef4e5f15e28c5cb834cd15af7ccde.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel online data augmentation framework for Time Series Foundation Models (OATS). OATS dynamically generates new data at each training step by: (1) using a data attribution method (TSIS) to identify \"high-quality\" training samples based on their influence on a small validation set; (2) using these high-quality samples as conditional prompts for a diffusion model to generate new, synthetic data; and (3) employing an explore-exploit mechanism to manage the high computational cost. The experiments demonstrate that this dynamical approach outperforms regular training and static augmentation baselines."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "1. **Novelty**: The core idea using a data attribution score for sampling, exploitation-exploration paradigm is very interesting and novel. The motivation, that data augmentation should be a dynamic process tailored to the model's state rather than a static, one-time operation, is well-motivated conceptual contribution. \n\n2. **Principled Framework**: The paper proposes a complete, end-to-end framework. The use of data attribution (influence functions) to define data \"quality\" is a much more principled approach than the manual heuristics (jitter, mixup) it compares against.\n\n3. **Efficiency Considerations**: The authors correctly identify the high computational cost of their method and proactively address it with a practical explore-exploit mechanism, including a sensible analysis of the cost-performance trade-off (Fig 4)."}, "weaknesses": {"value": "1. **No Standard Deviations**: Results in Tables 1 & 2 are reported from what appears to be a single run, with no random seeds mentioned. Without mean and std. dev. over multiple seeds, it is impossible to know if these gains are statistically significant or just random noise from a lucky run. \n\n2. **Details on the Validation Set**: The entire method relies on calculating influence scores relative to a 32-sample validation set. The authors does not describe the composition of this set. This will affect the analysis a lot. For example, a high TSIS for the \"solar power\" subset might not mean it's \"high quality\" data; it might just mean the 32-sample validation set was heavily biased with solar power data.\n\n3. **Poor Representation**: The paper presentation can be better. For example, line 244, \n$\\mathcal{B}_t \\sim \\pi_r^{\\left|\\mathcal{B}_t\\right|}$​, which I believe this describes uniform batch sampling, but the notation is confusing. Also, Figure 1's numbering, the main figure goes from (1) $\\rightarrow$ (3). I think step (2) and (3) are entangled. For example, Figure 4. No distinction between first row plots and second row, only caption mentions it.\n\n4. **Unjustified Heuristics**: The TSIS score (Eq 1) combines a influence score with a completely unexplained, heuristic-based SNR hard filter $\\left(I_{\\mathrm{SNR}\\left(z_i\\right)<k} \\cdot \\infty\\right)$. This point is unjustified."}, "questions": {"value": "I am actually very positive about the proposed method, and am willing to raise the score to 6 or 8 as long the authors could justify my questions and resolve my concerns.\n\n**Major concerns**\n1. What's the random seeds you've used during the experiments and why did you not report any of the mean and std?\n\n2. What's the exact composition of the validation set? Without this, I think the described analysis is less meaningful. For example, even if dataset portion is very low during training (e.x., PEMS07), if the validation dataset consists of huge amount of PEMS07, then the TSIS score for that data samples will be high.\n\n3. Could you justify the inclusion of the hard-coded SNR filter in the TSIS calculation? What is the sensitivity to the threshold $k$, and why is this heuristic necessary on top of the influence score?\n\n**Minor concerns**\n1. $\\infty$ is not a number, if you want to include $\\infty$ value with SNR, I think you should change the range from $\\mathbb{R}$ to $\\mathbb{R} \\cup \\\\{ \\infty, -\\infty \\\\}$.\n2. Figure 4's y axis represents the different dataset, would it be possible to add dataset name on it? For example, NLL (dataset 1) or something.. \n3. Also, I think it would be nice if you could mention what 'overall' measurement does on Table 1, and 2 at experiments setup or somewhere that we can easily see, like evaluation metrics paragraph. It's average performance of using prediction lengths, but only mentioned in Table 1 caption.\n4. You don't provide the proof of proposition 1 even though I think it's very obvious and just a few lines of proof. But as long as you mentioned it as proposition, I think you should provide the proof in Appendix.\n5. Line 220, equation 3, would it be better for add 'a' and 'b' to 'm', so that change `+m` to `+am + b` to automatically control the bias? Would this improve the performance?\n\nAgain, I think the idea is cool and I am willing to raise the score as long as my concerns are justified or resolved."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Xt1TSbksoe", "forum": "nP6dVUWZAE", "replyto": "nP6dVUWZAE", "signatures": ["ICLR.cc/2026/Conference/Submission6812/Reviewer_hNyo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6812/Reviewer_hNyo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6812/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761443807733, "cdate": 1761443807733, "tmdate": 1762919079402, "mdate": 1762919079402, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Online Data Augmentation for Time Series Foundation Models, a strategy for dynamically generating synthetic data during TSFM training. It uses data attribution scores TSIS, based on influence functions, to identify valuable training samples , which guide a conditional diffusion model for data generation. An explore-exploit mechanism aims to reduce computational cost. While addressing the relevant issue of adaptive augmentation, the method's reliance on approximations and heuristics raises concerns about its robustness and practicality."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1 Addresses the significant problem of improving TSFM training via adaptive augmentation, moving beyond static heuristics. The concept of integrating online data attribution with conditional generative modeling is an interesting synthesis.\n\n2 Motivates the approach by highlighting limitations of existing methods. The overall framework is presented clearly. Using influence functions offers a principled motivation. Experiments show positive results compared to static baselines."}, "weaknesses": {"value": "1 TSIS calculation relying on approximations (first-order Taylor, SGD assumption)  whose accuracy for large models with adaptive optimizers, like AdamW used here, is questionable and unverified. This undermines the reliability of the guiding signal.\n\n2 The efficiency mechanism depends on the \"locality of TSIS\" heuristic, assuming similar influence within subsets. This may not hold generally, and performance could be sensitive to subset definition. Lack of sensitivity analysis for this and key hyperparameters (epsilon, beta) makes its robustness uncertain. And Crucial sensitivity analyses for SNR threshold k, and the validation set's impact are missing, hindering reproducibility and understanding the method's limits.\n\n3 OATS adds significant complexity: conditional diffusion model & online influence calculation. The paper doesn't convincingly show that the performance gains justify this complexity, lacking comparing to potentially simpler adaptive methods.\n\n4 TSIS calculation depends on a small validation set with 32 samples. Performance might be sensitive to this set's choice/quality, risking overfitting the augmentation strategy. This was not investigated."}, "questions": {"value": "1 Could you provide stronger validation for the accuracy of the influence score approximation with large TSFMs and AdamW optimization? How reliable is the resulting guiding signal?\n\n2 How robust is performance to the subset partitioning method? Can you provide evidence supporting the \"locality of TSIS\" assumption? Please provide sensitivity analyses for epsilon and beta & sensitivity analyses for key hyperparameters like the SNR threshold k and diffusion model parameters.\n\n3 Can you provide a clearer cost-benefit analysis? How does OATS compare to simpler adaptive augmentation strategies? Do the gains justify the complexity across different scales/budgets?\n\n4 Regarding the Validation Set D_val: Please provide analysis on how the choice, size (beyond 32 samples), and quality of D_val impact performance. How is overfitting to this set mitigated?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3wb8ExX38V", "forum": "nP6dVUWZAE", "replyto": "nP6dVUWZAE", "signatures": ["ICLR.cc/2026/Conference/Submission6812/Reviewer_KZ1u"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6812/Reviewer_KZ1u"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6812/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761483370467, "cdate": 1761483370467, "tmdate": 1762919078956, "mdate": 1762919078956, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces OATS, a dynamic data augmentation framework designed for large-scale time series foundation models. Unlike existing static augmentation methods, OATS continuously generates synthetic samples during training based on time-series influence scores that measure each sample’s contribution to model performance. High-quality samples, identified via TSIS, guide a diffusion-based conditional generation module to synthesize realistic time series. An explore–exploit mechanism balances computation and exploration of new data subsets. Empirical evaluations on six datasets and two TSFM architectures show consistent improvements in normalized MAPE and NLL, demonstrating that OATS outperforms TSMixup, Jitter, and regular training."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Novel online augmentation formulation. The paper introduces a principled online data augmentation framework tailored to time series foundation models, replacing heuristic static methods with influence-based selection. The originality and coherence of this formulation represent a meaningful advance in dataset optimization for TSFMs.\n\n2. Explore–exploit mechanism for computational balance.\nThe explore–exploit design introduces a probabilistic scheduling approach that reuses cached influence scores while selectively updating them. This mechanism reduces redundant computation while maintaining adaptability to model dynamics."}, "weaknesses": {"value": "1. Unclear definition and maintenance of cached subsets.\nThe paper assumes that the dataset is divided into L disjoint subsets and maintains exponentially moving averages of influence scores for each (Eq. 4), but the rationale for this partitioning is underexplained. There is limited discussion of how subset granularity or the decay factor β affects performance.\n\n2. Limited baseline scope and fairness of comparison.\nThe experiments compare OATS only to Jitter and TSMixup, neglecting other adaptive or generative baselines. Additionally, the ratio of real to synthetic samples and the computational budget per method are not reported, which may affect fairness. The absence of statistical significance tests in Tables 1–2 weakens the claim of consistent superiority.\n\n3. Incomplete details of the diffusion model configuration.\nWhile Sec. 2.2 specifies the use of a conditional diffusion model, critical parameters such as the number of sampling steps, noise schedule, and conditioning dimensions are missing. The influence of class conditioning (Eq. 3) is not empirically isolated, and the qualitative results in Fig. 6 are descriptive but not quantified. As diffusion generation is a major computational component, more information is required to judge its efficiency and contribution."}, "questions": {"value": "1. What evidence supports the claimed efficiency and scalability of OATS?\nCan the authors report detailed GPU/CPU utilization, wall-clock time, and memory footprint for different ϵ values? How does the method perform on larger TSFMs or longer sequence lengths, and are there stability issues when scaling to these settings?\n\n2. Could the diffusion model’s configuration and conditioning mechanism be detailed further?\nWhat diffusion steps, noise variance schedules, and conditioning embedding sizes were adopted in Sec. 2.2? How much does the class-conditioning term in Eq. 3 improve results compared to an unconditional diffusion model? \n\n3. Can the authors provide a quantitative justification for the TSIS approximation?\nWould it be possible to include either an empirical correlation between first-order influence estimates and actual validation loss changes, or a theoretical error bound derived from Proposition 1? How sensitive is TSIS to gradient noise or varying learning rates during training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Wrx1Wq6Ky9", "forum": "nP6dVUWZAE", "replyto": "nP6dVUWZAE", "signatures": ["ICLR.cc/2026/Conference/Submission6812/Reviewer_yySA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6812/Reviewer_yySA"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6812/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761646909302, "cdate": 1761646909302, "tmdate": 1762919078636, "mdate": 1762919078636, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces OATS, an online data augmentation method for pre-training time series foundation models on data across diverse domains. OATS estimates per-sample value from training dynamics, trains a diffusion-based framework conditioned on those high-value signals, and adopts an explore-exploit mechanism to balance quality and diversity. Experiments on multiple datasets show that OATS outperforms standard augmentation baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Dynamically augmenting time series according to evolving training signals is important and well motivated.\n\n2. The proposed method of sample selection, a diffusion generator, and an explicit explore–exploit mechanism is new in this context.\n\n3. Experiments on multiple time series datasets demonstrate the effectiveness of the proposed method over standard augmentation methods."}, "weaknesses": {"value": "1. The compared data augmentation methods, such as mix-up augmentations and jittering, are basic and limited. Another type of time series augmentation methods is based on training generative models [1]. Additionally, there exists work that [2] proposes similar online data augmentation by selecting high-quality data.\n\n2. Evaluation of time series foundation models is limited to 6 datasets. Consider adding more diverse, standardized time series foundation model benchmarks such as GIFT-EVAL to better demonstrate the method's performance. Moreover, how does the proposed method compare with Chronos and Moirai on these benchmarks?\n\n3. Results may depend on the initial data partitions/subsets. How sensitive are the final results to initial partitions?\n\n4. Performance appears sensitive to the explore–exploit ratio and is not consistent across prediction lengths and datasets.\n\n[1] Time Series Data Augmentation for Deep Learning: A Survey\n\n[2] Filter, Augment, Forecast: Online Data Selection for Robust Time Series Forecasting"}, "questions": {"value": "1. Could you explain more on time series prototypes and how many prototypes are generated?\n\n2. For datasets where OATS increases the proportion of selected/augmented samples during training, what patterns did you observe? Do these correspond to “harder” datasets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rkps3dcIp4", "forum": "nP6dVUWZAE", "replyto": "nP6dVUWZAE", "signatures": ["ICLR.cc/2026/Conference/Submission6812/Reviewer_ges9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6812/Reviewer_ges9"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6812/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761953789200, "cdate": 1761953789200, "tmdate": 1762919078111, "mdate": 1762919078111, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}