{"id": "do4hqhMBiu", "number": 24525, "cdate": 1758357643556, "mdate": 1759896761814, "content": {"title": "A Diffusion-Based Data Augmentation Approach for Synthetic Human Portraits Dataset", "abstract": "Deep learning models have achieved remarkable success in computer vision. However, their generalizability remains limited when applied to new tasks. Data augmentation can help mitigate this issue, but traditional augmentation methods, such as rotation and scaling, are easy to conduct, but are also becoming increasingly inadequate when facing modern machine learning tasks. To address this issue, we propose a diffusion-based image-to-image augmentation workflow that transforms the original human images into new samples while keeping biometrical data unchanged, enriching the dataset without altering its key features. The resulted augmented dataset contains 225 synthetic anatomical models, each containing 44 images, resulting in a total of 9,900 images. Evaluation experiments demonstrate that the augmented dataset maintains 99.99% classification accuracy after 200 training epochs. Moreover, the quantitative evaluation shows that the maximum pixel deviation among all selected facial keypoints is only 10.1 pixels, with most remaining within 5–8 pixels, indicating that the new dataset is highly consistent with the original one. These findings demonstrate that diffusion-based augmentation is able to expand data diversity without compromising model performance nor the data accuracy.", "tldr": "", "keywords": ["Diffusion Models; Data Augmentation; Transfer Learning; Image-to-Image Translation;  Human Synthetic Dataset."], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/96c557c5a8bc469e3d14d3d21e12f4b118a2f79f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a diffusion-based image-to-image augmentation method that attempts to preserve facial/acupoint landmarks. The pipeline uses a combination of Stable Diffusion (SD-1.5), an IP-Adapter, an IC-Light module, and a choice of noise level injection to control how much the original image is retained. The motivation is to generate new visual diversity (background, lighting, skin tone, hair) while keeping acupoint labels valid, so that one can reuse existing labels without relabeling. The authors build a new “AcuSim” dataset (225 subjects × 44 views ≈ 9,900 images) and report very high accuracy (~99 %) on a CNN for acupoint classification and small landmark drift (5–8 pixels for most points)."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1) The goal is compelling: reduce labeling burden by generating new but label-consistent data.\n2) The idea of mixing partial guidance (injection of original image at noise level) to maintain structure is promising."}, "weaknesses": {"value": "1)  The paper is not ready for submission for instance in pp 5 it mentioned that \"Figure 2: Enter Caption\". As we can see in pp 2 in \"Figure 1: General Workflow\"\n2) The method is largely an engineering combination of existing modules (Stable Diffusion, IP-Adapter, lighting control). The novelty lies in their orchestration for this task, but that might be considered incremental.\n3) The “99 % accuracy” result is too good to be believable without more context: which baseline, which dataset split, how many classes, variance across runs, and is the model overfitting?\n4) There is no test of generalization: i.e. train on augmented data, test on new subjects or different lighting/pose settings. Does the augmentation help or hurt out-of-distribution generalization?\n\nMissing relevant references in literature review\n\n1) Context-guided Responsible Data Augmentation with Diffusion Models\n\n2) Effective Data Augmentation With Diffusion Models\n\n3) Diffusion models: A comprehensive survey of methods and applications\n\n4) GenMix: Effective Data Augmentation with Generative Diffusion Model Image Editing\n\n5) DiffuseMix: Label-Preserving Data Augmentation with Diffusion Models"}, "questions": {"value": "1) Compare the proposed method vs. classical augmentation (flip, color jitter, random crop) and, ideally, a GAN-based or identity-preserving diffusion baseline on the acupoint task.\n2) Provide ablation experiments: how much each module (IP-Adapter, IC-Light, injection strength) contributes, and report performance vs drift tradeoffs across settings.\n3) Test generalization: train with augmented + original, evaluate on unseen subjects, unseen lighting, or even a held-out real dataset to ensure no overfitting.\n4) If possible, show that downstream tasks beyond acupoint classification (e.g. landmark regression, localization) benefit from the augmentation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "KLiuaUmiqW", "forum": "do4hqhMBiu", "replyto": "do4hqhMBiu", "signatures": ["ICLR.cc/2026/Conference/Submission24525/Reviewer_5i3i"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24525/Reviewer_5i3i"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24525/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760502472950, "cdate": 1760502472950, "tmdate": 1762943112358, "mdate": 1762943112358, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper is an incomplete submission."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "N.A."}, "weaknesses": {"value": "This paper is an incomplete submission."}, "questions": {"value": "N.A."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "3J3gNkaq90", "forum": "do4hqhMBiu", "replyto": "do4hqhMBiu", "signatures": ["ICLR.cc/2026/Conference/Submission24525/Reviewer_xTmF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24525/Reviewer_xTmF"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24525/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761441509386, "cdate": 1761441509386, "tmdate": 1762943112123, "mdate": 1762943112123, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper appears to be incomplete"}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The paper appears to be incomplete"}, "weaknesses": {"value": "The paper appears to be incomplete"}, "questions": {"value": "The paper appears to be incomplete"}, "flag_for_ethics_review": {"value": ["Yes, Other reasons (please specify below)"]}, "details_of_ethics_concerns": {"value": "The paper appears to be incomplete"}, "rating": {"value": 0}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "dAdY1TShWO", "forum": "do4hqhMBiu", "replyto": "do4hqhMBiu", "signatures": ["ICLR.cc/2026/Conference/Submission24525/Reviewer_nwNu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24525/Reviewer_nwNu"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24525/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761803991787, "cdate": 1761803991787, "tmdate": 1762943111784, "mdate": 1762943111784, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}