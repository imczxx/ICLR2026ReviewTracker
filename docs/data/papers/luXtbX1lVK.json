{"id": "luXtbX1lVK", "number": 8824, "cdate": 1758099403173, "mdate": 1759897761728, "content": {"title": "String Seed of Thought: Prompting LLMs for Distribution-Faithful and Diverse Generation", "abstract": "We introduce _String Seed of Thought (SSoT)_, a novel prompting method for LLMs that improves _Probabilistic Instruction Following (PIF)_. We define PIF as a task requiring an LLM to select its answer from a predefined set of options, each associated with a specific probability, such that the empirical distribution of the generated answers aligns with the target distribution when prompted multiple times. While LLMs excel at tasks with single, deterministic answers, they often fail at PIF, exhibiting biases problematic for applications requiring non-deterministic behaviors, such as human-behavior simulation, content diversification, and multiplayer games.\nIt also harms the diversity of generated responses, a crucial factor in test-time scaling, by causing the outputs to collapse into a limited set of answers. To address this, we propose SSoT, a simple prompting method that instructs an LLM to first output a random string to generate sufficient entropy. SSoT also instructs the LLM to extract randomness by manipulating this string to derive a final answer, thereby preserving diversity while adhering to specific constraints. We demonstrate that SSoT significantly improves the PIF performance of LLMs, approaching the ideal performance of a pseudo-random number generator. Notably, our experiments on NoveltyBench show SSoT's benefits extend beyond closed-set tasks to open-ended tasks by enhancing response diversity.", "tldr": "We propose String Seed of Thought (SSoT), a simple prompting method that uses a random string as a seed to enable LLMs to accurately follow probabilistic instructions and enhance the response diversity.", "keywords": ["Large Language Models", "Prompting", "Diversity"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e7ec12280ef424944cb3bc41371b98e4dd76f92e.pdf", "supplementary_material": "/attachment/47e0ee3e4e1e7514d48801f10178b281ae937c38.zip"}, "replies": [{"content": {"summary": {"value": "The authors of this paper introduced Seed of Thought (SSoT), a prompting method for improving LLMs' probabilistic instruction following. For example, LLMs can approximately draw 50/50 for heads or tails if the prompt is to \"flip an unbiased coin\". The probabilistic instruction following method proposed in this paper is done by crafting prompts: LLMs need to first generate a random sequence and then derive an answer based on the generated sequence."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Two theorems provide the lower bound of the total variation distance between the sample and the required distributions. \n2. The experiment section is well presented overall. Figures and tables convinced me that the proposed method indeed improves the LLM's probabilistic instruction-following capabilities. \n3. In addition to 2, the rich details in the appendix and the uploaded supporting material benefit the reproduction of numerical studies."}, "weaknesses": {"value": "1. The assumptions that \"each character is randomly drawn from a distribution\" of the proved theorems are hard to meet for LLMs. They are pre-trained on text corpora. Every individual token generated by them is based on its previous content (Causal Language Modeling), thus never random. I can be proved wrong, at least empirically, by an analysis of the distribution/duplication of LLM-generated random strings.\n\n2. Personally, I am not fully motivated to tune LLM to perform PIF tasks, which could be done precisely with `random` modules if the option set is predefined. This point is the major driver of my evaluation score. The authors can further elaborate on this in the motivation section, or add results for PRNG in Section 5.2, where I cannot link why PRNG is inadequate for diversity-aware generation.\n\n3. The SSoT System prompts in Appendix A are different for each case, which weakened the generalization capability of the proposed method (thinking `please think step-by-step` for CoT). An explanation of why we need different descriptions, or how to design SSoT prompts, alleviates this weakness.\n\n**Presentation-related Suggestions:**:\n1. Several paragraphs need to be rewritten into formal academic writing (e.g. line 146, `the only thing you need to do` uses second-person narration)\n2. The last panel of Figure 2 (line 186) is hard to read, as the Ideal threshold shape overlapped with the tiny bars"}, "questions": {"value": "1. I am not familiar with the TV distance bound with random hash function theories, nor did I check every step of the derivatives. Can the author briefly describe the contribution of these theorems in terms of deterministic hash decoding (or a more specific/related field), regardless of whether the LLM-instruction following can meet the assumptions or not?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VPmPUPoPJi", "forum": "luXtbX1lVK", "replyto": "luXtbX1lVK", "signatures": ["ICLR.cc/2026/Conference/Submission8824/Reviewer_KwFB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8824/Reviewer_KwFB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8824/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760761429165, "cdate": 1760761429165, "tmdate": 1762920592764, "mdate": 1762920592764, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes String Seed of Thought (SSoT), a prompt-only method for probability instruction following and open-ended diversity. The model is first prompted to generate a pseudo-random character string, and then leverages its reasoning ability to map that seed to the required output via simple rules (e.g., sum-mod/rolling hash). The authors provide theoretical guarantees of how self-correlated strings can be mapped to a near-uniform distribution with a deterministic hash mapping, and further show the distribution gap for the sum-mode strategy that LLM typically uses. Empirically, SSoT improves distribution faithfulness on coin-flip/k-of-n/RPS tasks and increases diversity on NoveltyBench. It contributes to the LLM applications that requires controllable stochasticity and diversity."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This method is simple yet effective. It works well across different LLMs and task types without tuning, demonstrating strong engineering practicality.\n2.  This method is theoretically sound. It provides a rigorous bound showing that the TV distance between the empirical and target distribution decreases as the generated string length increases, even when the string exhibits autocorrelation. This result gives the method solid mathematical grounding. Moreover, the authors derived the bound for the sum-mod strategy that the model empirically adopts, offering a clear explanation of why the approach works.\n3. The experiments are comprehensive and convincing, covering multiple application scenarios: closed-set probabilistic sampling and open-ended diverse generation. Multiple strong baselines are compared, and the method is tested on 5 advanced LLMs, all showing substantial improvements. This demonstrates its robustness across architectures and tasks. The paper also provides detailed supplementary materials for reproducibility.\n4. Beyond reporting quantitative results, the authors perform an in-depth analysis of LLM’s reasoning behavior during generation. They discover that the models spontaneously develop strategies, such as sum-mod and rolling hash mappings, adaptively according to the task, to extract random actions from the generated strings. This is not only an interesting empirical observation but also deepens our understanding of LLM reasoning behaviors."}, "weaknesses": {"value": "1. It would be better if the authors could provide some failure case analysis. In Table 1, the performance of QwQ-32B on the 2-choice task is even worse than the baseline. Is this degradation due to autocorrelation in the generated random strings, inappropriate mapping, or possible execution/calculation errors?\n2. The models used in the experiments are all quite large. Considering that SSoT relies on the model itself to decide the mapping strategy and execute it, this raises doubts that the performance may be strongly limited by the capability (especially in reasoning) of the models. It also raises concerns about scalability to more complex PIF tasks, as it remains unclear whether LLMs can reliably come up with and implement more complex operations.\n3. The intrinsic reasoning process of generating random strings and mapping is not transparent. Although the authors provide analysis of the models’ reasoning behavior, it remains unclear whether future versions of these models will change their strategies, or whether different models would adopt different strategies, which makes the algorithm unstable and difficult for users to control. This lack of transparency also weakens the connection between the authors’ theoretical analysis and practical implementation.\n4. Considering the assumptions on the conditional distribution of the string in Theorems 4.1 and 4.2, it would be better to verify them quantitatively."}, "questions": {"value": "1. I hope the authors could provide a more detailed introduction to the datasets for the DAG task and the related metrics. I checked the reference to understand how “distinct” and “utility” are calculated. It seems that distinct evaluates pure diversity, while utility combines both diversity and quality. However, I'm still unclear what the columns in Table 2, such as \"creativity\" and “naming”, represent. If they are subsets of the dataset, improvements in some tasks, including \"creativity\", would be valuable. However, I feel we shouldn't expect diversity increases in subsets like \"facts\", especially when the utility metric can't decompose the changes in quality."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7PuAXOf0b8", "forum": "luXtbX1lVK", "replyto": "luXtbX1lVK", "signatures": ["ICLR.cc/2026/Conference/Submission8824/Reviewer_kxrX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8824/Reviewer_kxrX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8824/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761432742187, "cdate": 1761432742187, "tmdate": 1762920592315, "mdate": 1762920592315, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "String Seed of Thought (SSoT) is a proposed prompting method that injects a random string as a “seed” into an LLM’s chain-of-thought to induce more faithful probabilistic behavior and greater output diversity. The technique works by first asking the model to generate a random string, then having the model algorithmically manipulate that string to select a final answer according to a target probability distribution. The authors provide both theoretical guarantees (showing that with sufficiently long random strings the output distribution can approach the desired distribution) and extensive empirical evidence that SSoT yields significantly improved distribution alignment and more diverse responses across multiple models and tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The SSoT prompting strategy is conceptually simple to implement (just adding a brief instruction to generate and use a random string) and is applicable to a wide range of LLMs without any model modifications.\n\n2. SSoT dramatically improves an LLM’s ability to follow probabilistic instructions, achieving empirical sampling frequencies very close to the target probabilities and also boosts the diversity of open-ended generations, outperforming other diversity-promoting baselines like prompt paraphrasing or higher-temperature sampling while maintaining output quality. Experiments across five state-of-the-art LLMs and various scenarios consistently show that SSoT yields superior distribution-faithful performance and surpasses strong prompting baselines in both accuracy of sampling and response diversity.\n\n3. The paper provides a solid theoretical foundation, proving (informally) that as the length of the internally generated string increases, the total variation distance between the model’s output distribution and the target distribution diminishes even if the string characters are not fully independent."}, "weaknesses": {"value": "1. This method may cause potential errors and hurt answer quality. While the method focuses on matching distributions and diversity, the paper provides little discussion on whether the use of SSoT could inadvertently affect the correctness or factuality of outputs in tasks where a specific correct answer is expected.\n\n2. Most experiments involve tasks with a small, discrete set of outcomes (binary or a few categories), so it remains uncertain how well SSoT would scale to more complex distributions or tasks with a larger set of possible outputs (or continuous output spaces).\n\n3. The theoretical guarantees rest on assumptions like sufficiently long random strings and bounded bias in character generation; in practice, these conditions cannot be strictly met, so the gap between the idealized guarantees and real model behavior is not fully understood."}, "questions": {"value": "1. How sensitive is SSoT’s effectiveness to the length of the random string used, and how can we provide for choosing an appropriate string length to balance randomness and efficiency in practice?\n\n2. Have the authors tested SSoT on tasks with highly skewed or arbitrary target distributions (beyond uniform cases like fair coin flips), and if so, how well does the method maintain the correct proportions in those more challenging scenarios?\n\n3. Does the inclusion of a random string (and its manipulation) ever degrade the perceived quality or coherence of the final answer, and how can one ensure that this random seed is hidden or handled so that it doesn’t confuse end-users in a real application?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CDUatTio3y", "forum": "luXtbX1lVK", "replyto": "luXtbX1lVK", "signatures": ["ICLR.cc/2026/Conference/Submission8824/Reviewer_yb85"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8824/Reviewer_yb85"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8824/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761628352859, "cdate": 1761628352859, "tmdate": 1762920591714, "mdate": 1762920591714, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}