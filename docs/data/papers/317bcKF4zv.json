{"id": "317bcKF4zv", "number": 15560, "cdate": 1758252667400, "mdate": 1759897299127, "content": {"title": "SLM-MUX: Orchestrating Small Language Models for Reasoning", "abstract": "With the rapid development of language models, the number of small language models (SLMs) has grown significantly. Although they do not achieve state-of-the-art accuracy, they are more efficient and often excel at specific tasks. This raises a natural question: can multiple SLMs be orchestrated into a system where each contributes effectively, achieving higher accuracy than any individual model? Existing orchestration methods have primarily targeted frontier models (e.g., GPT-4) and perform suboptimally when applied to SLMs. To address this gap, we propose a three-stage approach for orchestrating SLMs. First, we introduce SLM-MUX, a multi-model architecture that effectively coordinates multiple SLMs. Building on this, we develop two optimization strategies: (i) a model selection search that identifies the most complementary SLMs from a large pool, and (ii) test-time scaling tailored to SLM-MUX. Our approach delivers strong results: Compared to existing orchestration methods, our approach achieves up to 13.4% improvement on MATH, 8.8% on GPQA, and 7.0% on GSM8K. With just two SLMs, SLM-MUX outperforms Qwen 2.5 72B on GPQA and GSM, and matches its performance on MATH. We further provide theoretical analyses to substantiate the advantages of our method. In summary, we demonstrate that SLMs can be effectively orchestrated into more accurate and efficient systems through the proposed approach.", "tldr": "", "keywords": ["large language model", "small language models"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8da0174aff5256760749acc7bebd43f4a66f20ad.pdf", "supplementary_material": "/attachment/5908ec35ff4961263230c1283eaa0b0a89181951.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes an orchestration framework for small language models (SLMs), called SLM-MUX, and further explores test-time scaling strategies specifically for this method. The authors show that SLM-MUX can effectively coordinate multiple SLMs and achieves strong performance across various mathematical reasoning tasks.\n\nTheir main contributions are as follows:\n1. They identify the limitations of applying traditional orchestration methods, originally developed for large language models (LLMs), to SLMs.\n2. They introduce SLM-MUX, an orchestration approach that works particularly well for SLMs compared to discussion-based methods.\n3. They investigate strategies for model selection and search–compute scaling, tailored to the SLM-MUX framework."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The authors identify an interesting problem: existing orchestration methods developed for large language models (LLMs), such as discussion-based approaches, do not directly transfer well to small language models (SLMs). \n\nThe paper provides extensive empirical evaluations and complementary mathematical analyses to study the proposed SLM-MUX framework."}, "weaknesses": {"value": "The proposed method, including its model selection objectives, appears somewhat heuristic. While the consistency of sampled answers may indeed correlate with correctness, relying on it as the primary criterion for selecting the best responses seems somewhat ad hoc. A stronger theoretical justification would help strengthen confidence in this approach. The analysis presented in the discussion section is a good starting point, but it would benefit from being expanded and made more rigorous to support the claims more convincingly.\n\nRegarding the contradiction penalty, it also comes across as rather ad hoc, as it penalizes models that consistently produce incorrect answers. Overall, these components feel more like empirical adjustments designed to boost performance metrics rather than principled elements of the framework."}, "questions": {"value": "I understand that this method requires a validation set for model selection and related adjustments. Do the baseline methods (such as the discussion-based approaches) also rely on a validation set? How do you ensure that the demonstrated advantage is not due to access to additional information, or better overfitting capability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UCzd19GJTa", "forum": "317bcKF4zv", "replyto": "317bcKF4zv", "signatures": ["ICLR.cc/2026/Conference/Submission15560/Reviewer_7wuE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15560/Reviewer_7wuE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15560/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761672790737, "cdate": 1761672790737, "tmdate": 1762925834949, "mdate": 1762925834949, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose an SLM orchestration method called SLM-MUX. The authors show that orchestration methods that work for LLMs interestingly do not work when orchestrating SLMs. The authors propose a simple orchestration framework for SLMs based on picking the answers which are the most self-consistent after multiple generations. The authors provide an SLM model selection protocol for identifying sets of models which are able to orchestrate well. In mathematical reasoning datasets the authors demonstrate their approach outperforms existing orchestration methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The paper is well written and easy to follow.\n\n* The authors provide a detailed empirical analysis to demonstrate the effectiveness of SLM-MUX versus baselines. Also they additionally provide ablations of important components such as the trade-offs in the model selection objectives and the performance against the number of predictions made by the SLMs."}, "weaknesses": {"value": "* The contribution of the paper is limited. SLM-MUX is doing a maximum consistency selection over SLMs which is open to abuse from SLMs that are consistently wrong on a test set (see question below)? Additionally SLM-MUX requires a model search prior to being used to remove SLMs which are highly confident in their wrong answers, so do we require a training set?\n* The mathematical analysis needs development: I think I understand that using $p_{max}$ versus $\\bar{p}$ like in AgentForest results in a higher number of correct answers? I think this deserves a bit more development. Like how is it related to multiple models? You mention $p_{max}$ is the max of three models (in line 466) which is rather ad-hoc, this could be any number of models. However you cannot evaluate $p$ without a training set? If you only have a test set you will consistently pick wrong answers potentially and you cannot assess $p_{max}$?\n* The results in Figure 7 are rather disappointing showing that 2 SLMs maximize the score which balances union accuracy while minimizing the contradiction penalty. I feel that this is a fundamental limitation of this LM orchestration technique that if you do not collaborate to come up with an answer, there will inevitably be some contradictions. So I can see that having 2 SLMs will reduce this contradiction in the responses, however this also feels sub-optimal. We should be in a state that adding more SLMs strictly improves performance.\n* Inconsistencies in the evaluations. Some results are reported over multiple runs with means and standard deviations e.g. Table 1. While others which are important such as Figure 5 which demonstrate how existing orchestration methods work for LLMs but not for SLMs only report a single seed. For instance it looks like the existing orchestration methods don’t work either for LLMs, but with no error bars to assess the noise in the experimental process this is difficult to conclude."}, "questions": {"value": "* I’m confused by the definition of the Contradiction metric. How does it generalize to more than two models. Surely encouraging contradiction enables a more diverse set S for SLM-MUX, in lines 322-323 you specifically mention that diverse outputs enables SLM-MUX’s abilities. Did you try varying the model selection objective? A good comparison for the model selection criterion would be simply a random selection of SLMs.\n\n* What would happen if you have no training set and you want to evaluate SLM-MUX 0-shot on a new test set? In algorithm 1 you do not have any validation accuracies or ground truth labels $y$ to select the most consistent model?\n\n* What does SC signify in the row Single-Best-SC in Table 1?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "T9kAGVt6LP", "forum": "317bcKF4zv", "replyto": "317bcKF4zv", "signatures": ["ICLR.cc/2026/Conference/Submission15560/Reviewer_2yhV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15560/Reviewer_2yhV"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15560/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761906420717, "cdate": 1761906420717, "tmdate": 1762925834187, "mdate": 1762925834187, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses an important problem of small language model (SLM) orchestration. Due to the limited capabilities of SLMs, existing orchestration methods which typically targeted frontier models often performs suboptimally when applied to SLMs. This paper introduces SLM-MUX which is an effective SLM orchestration architecture which optimizes model selection search and test-time scaling. The paper shows strong results of SLM orchestration with significant performance improvement across various reasoning datasets."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper tackles a crucial problem of SLM orchestration which is often overlooked by existing literature of multi-agent orchestration\n- The method is training-free and light-weight\n- The experiments show strong performance across multiple reasoning benchmarks"}, "weaknesses": {"value": "In practise, often SLMs are fine-tuned to be domain experts which forms strong reasoning models. Empirical evidence show strong performance gain through orchestration, however, it is unclear how the framework performs with fine-tuned domain-specific SLMs."}, "questions": {"value": "In practice, small language models are often fine-tuned to become domain-specific, and these expert SLMs typically exhibit strong reasoning capabilities. While the paper demonstrates notable gains from orchestrating general-purpose instruction-tuned SLMs, it remains unclear how SLM-MUX would perform when combining domain-specific fine-tuned SLMs. Could the authors discuss how the method helps with these more domain-specific fine-tuned SLMs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "roQE8EovV2", "forum": "317bcKF4zv", "replyto": "317bcKF4zv", "signatures": ["ICLR.cc/2026/Conference/Submission15560/Reviewer_8HgN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15560/Reviewer_8HgN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15560/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761948372523, "cdate": 1761948372523, "tmdate": 1762925833730, "mdate": 1762925833730, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of orchestrating multiple small language models (SLMs) to achieve higher reasoning accuracy and efficiency than any individual SLM. The authors propose SLM-MUX, a multi-model architecture that coordinates SLMs without explicit inter-model discussion. The approach consists of three stages:\n\n1. SLM-MUX orchestration: Models independently generate answers; the most consistent answer (by self-consistency) is selected.\n2. Model selection search: Identifies complementary SLMs to maximize union accuracy and penalize overconfident contradictions.\n3. Test-time scaling: Adjusts the number of models and samples to optimize accuracy-compute tradeoff.\n\nEmpirical results show SLM-MUX outperforms existing orchestration methods (Mixture-of-Agents, LLM-Debate, Multi-Agent Verification) on MATH, GPQA, and GSM8K benchmarks, sometimes surpassing much larger models (Qwen 2.5 72B). Theoretical analysis and ablation studies support the design choices."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**Originality:** The approach is based on a good intuition (that of multiple smaller processors being more effective at computing than a single large processor) and on a clearly identified problem - the failure of discussion-based methods in orchestrating SLM responses due to their tendency to fall into groupthink.\n\n**Quality:** The paper puts together three simple ideas into a solution that is evaluated using rigorous experimental methodolgy, with comprehensive benchmarking across MATH, GPQA, and GSM8K, and shows clear improvements over baselines.\n\n**Clarity:** The writing is clear and well-structured, making the technical content accessible. The motivation for SLM-MUX is articulated up front, and the different components of the solution (SLM-MUX orchestration, model selection, and test-time scaling) are explained clearly, step-by-step.\n\n**Significance:** Owing to the ever-growing cost of LLMs and the enormous demand for AI agents, it is critical to build agentic frameworks around smaller, lower-cost models, if we want them to scale across users and platforms and be cost-effective. This paper is a step in that direction as it shows that we need to rethink approaches to model orchestration if we wish to effectively use SLMs in agentic scenarios and then proposes a solution that improves over baselines and is also clear and easy to implement."}, "weaknesses": {"value": "1. The consistency-based confidence-estimation will not work for open-ended question-answering which forms a major part of the use-cases of LLM-based agents and chatbots.\n\n2. It seems to me that the contradiction penalty in Section 3.2 will not differentiate between sets with different proportions of correct and wrong answers and so it may not fully overcome the problem of including over-confident but wrong models.\n\n3. The brute-force solution of O(S) in Section 3.2 will not scale to a large number of candidate models and so test-time scaling via adding participating model types is going to be fairly limited.\n\n4. It is not really a fair comparison if you follow the workflow and prompts designed for LLMs in the baselines (lines 313-314) when it is known that prompts are so sensitive to the underlying model."}, "questions": {"value": "1. There are multiple combinations of models possible for each value of K. Are the plots in Fig 7 only considering a single combination for each K? If yes, which combination is it?\n\n2. How/why was $\\lambda = 1$ chosen?\n\n3. Why is the test set same as the validation set for the plots in Fig. 9? Shouldn't they be different?\n\n4. In line 467 where you say, \"By increasing $p_\\max$...$, what part of your approach are you referring to? Does model-selection increase $p_\\max$? Can it be proved?\n\n5. From Fig. 5 (b) it seems that the improvements with discussion-based methods are fairly limited even for frontier LLMs. I would recommend trying two ablation studies - a) Applying SLM-MUX to frontier LLMs and b) Applying model-selection + discussion-based methods to SLMs. This can better illustrate the effectiveness of the individual components of your approach and also show if SLM-MUX is a viable solution even for frontier LLMs."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "m0m35xiksy", "forum": "317bcKF4zv", "replyto": "317bcKF4zv", "signatures": ["ICLR.cc/2026/Conference/Submission15560/Reviewer_XgnD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15560/Reviewer_XgnD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15560/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762092777217, "cdate": 1762092777217, "tmdate": 1762925833315, "mdate": 1762925833315, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}