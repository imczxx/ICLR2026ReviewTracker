{"id": "7X0HFmpTvV", "number": 7631, "cdate": 1758029903021, "mdate": 1759897842449, "content": {"title": "Cross-domain Attention for Transfer Learning between Tabular Data without Shared Features", "abstract": "Unlike image and text, the transfer learning of tabular data is challenging due to the heterogeneity in feature types, structure, and semantics across disparate application domains. Existing methods assume shared features between data tables to transfer knowledge, often by fine-tuning a large pre-trained model. To facilitate learning between domains without shared features, we propose a \\emph{data-agnostic} Cross-domain Attention Transfer Learning (CATTLE). CATTLE performs self-supervised learning of $key$, $value$, $query$ projection weights of a transformer using source data. Pre-trained weights of selective attention layers are used in a separate transformer to learn cross-domain attention for target data, instead of conventionally fine-tuning the same pre-trained model. Our experiments on ten pairs of source-target data sets without shared features show that CATTLE is statistically and in terms of performance rank superior to nine state-of-the-art baselines, including traditional ML, deep tabular representation learning, and transfer learning methods proposed for tabular data sets. A single tabular data set from an arbitrary domain is sufficient to achieve cross-domain attention to generalize to new downstream learning, eliminating the need for large foundation models pre-trained by many disparate tabular data sets. CATTLE source code is available publicly.", "tldr": "This paper presents a new cross-attention method using transformer weights instead of key and value representations to achieve cross-domain transfer learning between disparate tabular data sets.", "keywords": ["tabular data", "cross-attention", "transfer learning", "cross-domain"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f22e44ce43ae34aab1faa16bc0a3a70e8d52137b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes CATTLE, a data-agnostic Cross-domain Attention Transfer Learning framework for tabular data. Specifically, CATTLE reuses the attention-related weights from a pretrained Gated Feature Tokenizer Transformer trained on source data, for fine-tuning the target data. The authors evaluated their method on 10 pairs of source-target datasets, arguing the state-of-the-art performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper is well written.\n\n2. Motivation is great. Transfer learning for tabular data is non-trivial and challenging problem, where its potential is great for improving the prediction performance of tabular tasks."}, "weaknesses": {"value": "1. How did the authors choose the source dataset and target dataset? Can the authors provide the criteria? Because, it might be seen as cherry picked results because the target data set has a very small number of test data, leading to high variance of the score.\n\n2. In addition, how are the source and target datasets paired? Why only the two source data is used for one target data? Is it possible to use all the source data at once for the pretraining? In this sense, it is also possible to use 2000 datasets in OpenTabs too.\n\n3. I think the method is not that new compared to XTab, CM2, or TransTab. Architecture modification is just a marginal contribution, and many previous works follow a pretraining-finetuning framework. Where to freeze (or not freeze) seems to be just a design choice.\n\n4. Lack of baselines. The authors only use the simple tree-based or deep-learning models as a baseline. These days, more powerful models are proposed, like TabPFNv2, ReaMLP, and so on. The authors should provide a comparison result against them.\n\n5. Missing citations. There are other transfer learning frameworks for tabular data, for example, P2T [1]. This work also proposed to use a source data that has no overlapping columns with the target dataset.\n\n6. Lack of ablation study. The authors should provide the impact of number of source data, some design choices like freezing the attention weight.\n\n[1] Nam et al., Tabular Transfer Learning via Prompting LLM, COLM 2024."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "W63dHGjfJA", "forum": "7X0HFmpTvV", "replyto": "7X0HFmpTvV", "signatures": ["ICLR.cc/2026/Conference/Submission7631/Reviewer_vqS8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7631/Reviewer_vqS8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7631/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761109457463, "cdate": 1761109457463, "tmdate": 1762919710387, "mdate": 1762919710387, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes CATTLE(Cross-domain Attention Transfer Learning), a novel transfer learning framework for tabular data. Unlike image or text data, transfer learning for tabular data poses challenges due to the heterogeneity of features (type, structure, semantics) across different domains. While existing works often assume shared features between source and target datasets, this paper targets transfer learning between domains with entirely disjoint feature spaces. CATTLE selectively extracts only the Key (W_k) and Value (W_v) weights from the last attention layer of a source model (gFTT_s). These extracted weights are then injected into the first two layers of a new target model (gFTT_t) and frozen, while the target model only learns the Query (W_q) weights. The paper describes this mechanism as data-agnostic cross-attention, transferring knowledge at the weight level rather than the data representation level. Experiments on 10 disjoint dataset pairs (based on OpenML) show that CATTLE achieves strong performance rankings based on AUROC and ACC compared to existing SOTA models like XGBoost, TransTab, CM2, and XTab, with the self-supervised pretraining version performing better than the supervised one. The authors claim that CATTLE is effective even with a single source dataset, enabling transfer learning between tables without shared features and without requiring large-scale pretraining."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- This paper clearly defines and proposes a solution (CATTLE) for an important challenge in the tabular data domain. It addresses transfer learning between domains that have entirely different feature spaces and no shared features. While existing methods often assume some degree of feature overlap or focus on within-domain transfer, CATTLE overcomes these limitations and provides a more general approach. This improvement enhances the practical utility of tabular data, which is one of the most widely used data types across applications.\n\n- The strategy of freezing the transferred Key (W_k) and Value (W_v) weights in the target model's initial layers while only training the Query (W_q) weights with target data is effective. This allows the model to retain the source domain's way of representing and summarizing information (Key/Value) while learning how to utilize and query this information specifically for the target domain's data (Query). This provides flexibility, preserving generalizable knowledge from the source while adapting to target domain characteristics.\n\n- The finding that self-supervised pretraining using unlabeled source data achieves better performance than the supervised one is noteworthy. Acquiring large labeled datasets for tabular data is often challenging and costly, unlike image or text data. The effectiveness of CATTLE's self-supervised approach (masked feature reconstruction) suggests that model performance can be significantly improved using readily available large unlabeled datasets, making it a highly practical and powerful advantage for real-world applications"}, "weaknesses": {"value": "- The paper lacks enough explanations for why transferring attention weights (W_k, W_v) from the upper layers of the source model to the lower layers of the target model is the most effective approach. While the ablation study in Section 4.4 (Table 5) empirically supports this choice, the paper does not offer solid rationale for why this transfer is effective. There is insufficient analysis on what specific knowledge from the source domain is actually encoded in the transferred W_k, W_v weights and how they map to or interact with the features of the target domain.\n\n- While CATTLE Self-Supervised achieves the top average rank in Table 2, the absolute performance differences compared to the second-best or other top-performing models are often very small. For instance, on the VH dataset, CATTLE Self-Supervised (0.942 AUROC) shows only a 0.007 improvement over TransTab (0.935) and XTab (0.935). Such minimal margins make it difficult to argue for a strong practical advantage derived from CATTLE's novel mechanism, in particular considering potential implementation cost of CATTLE. In addition, the comparisons are primarily made against models like TabNet and TransTab, which are not the most recent model, so it is unclear how CATTLE would perform relative to newer baselines.\n\n- The paper claims in the Ablation Study (Section 4.4, Figure 4) that the choice of source dataset has a negligible impact, citing a AUROC difference of approximately 0.019 across different source datasets for the target cmc dataset. This interpretation appears contradictory to the significance attributed to smaller performance gains in Table 2, where a 0.007 AUROC difference on the VH dataset is implicitly used to argue for CATTLE's superiority over SOTA methods. This suggests an inconsistent standard for evaluating the importance of performance differences.\n\n- The method’s generalizability has not been sufficiently validated. CATTLE is tested only on the gFTT architecture, and its performance on other tabular deep learning architectures such as TabNet is unknown. In addition, the paper does not quantify or analyze how different the source and target domains are. There is no examination of how CATTLE performs under various levels of domain shift, so it remains unclear whether the method is robust when the domains are highly dissimilar."}, "questions": {"value": "- The CATTLE approach involves transferring and freezing specific attention weights (W_k, W_v) and training only part of the model, instead of fine-tuning the entire model. Theoretically, this could offer significant advantages in terms of computational cost and training speed during the fine-tuning phase compared to standard full-model fine-tuning approaches. It would be valuable to know whether this potential efficiency gain was quantitatively measured or compared in the experiments. For instance, are there comparative results on fine-tuning time or resource usage for CATTLE versus other baseline models on the same target dataset? If this potential efficiency gain is considered a key advantage of the methodology, what level of improvement could be expected?\n\n- This study primarily validates CATTLE's performance using standard benchmark datasets like OpenML. While widely used, these datasets might differ significantly in scale and complexity from large-scale tabular data found in real-world web or industrial applications. It would be useful to clarify whether CATTLE's cross-attention mechanism and selective weight transfer are expected to demonstrate similar performance improvements, especially compared to SOTA models, on much larger and more complex tables. From a scalability perspective, potential limitations to CATTLE's performance or training stability as the dataset size increases could also be discussed, along with any plans for further experiments to validate its applicability on large-scale datasets.\n\n- The paper claims to learn generalized representations even across entirely different domains without shared features, presenting AUROC and ACC results as evidence. However, these metrics primarily measure the final model's predictive performance on the target task and have limitations in directly showing how well the learned intermediate representations themselves have generalized or captured domain-invariant properties. It would be important to clarify whether AUROC/ACC alone are considered sufficient to conclude that CATTLE successfully learns generalized representations, and what the justification is for this interpretation. Alternatively, further analyses such as linear probing, domain discrimination tests, or representation visualization might be necessary or planned to more directly assess the quality and generalizability of the learned representations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nM14gN7ygS", "forum": "7X0HFmpTvV", "replyto": "7X0HFmpTvV", "signatures": ["ICLR.cc/2026/Conference/Submission7631/Reviewer_99Sa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7631/Reviewer_99Sa"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7631/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761903482192, "cdate": 1761903482192, "tmdate": 1762919709845, "mdate": 1762919709845, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Cross-domain Attention Transfer Learning (CATTLE), a model that allows transfer learning between tabular datasets without shared features. The work is based on (1) self-supervised pre-training from source data, and (2) fine-tuning on specific dataset of interest. CATTLE extracts attention-related weights from a pretrained Gated Feature Tokenizer Transformer (gFTT) trained on source data are transferred into a newly initialized gFTT, which is then finetuned using target data. The experiments show solid performances compared to several baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "In general, the paper is easy to follow. The biggest strength of CATTLE would be the learning of the relationship between tabular data sets from different domains without requiring a common feature space, which can be useful in various settings of transfer learning and domain adaptation."}, "weaknesses": {"value": "-\tThe paper needs to enrich the works in tabular learning for pre-training and transfer, such as TabPFN or CARTE.\n-\tThe choice of source-target combination requires more justification.\n-\tThe choice of hyperparameters space is limited (for instance for XGB).\n-\tThe baselines should include more recent tabular learning models of TabPFNv2, and RealMLP.\n-\tThe experiment results is limited. If CATTLE can cope with non-shared features, than it means that it can also cope with cases where there are limited matching of the shared features. There could be more datasets that can be explored to truly see the value of CATTLE.\n-\tThe writings of the paper can be improved.\n-\tResults on smaller train-size on the target dataset may show effectiveness of CATTLE."}, "questions": {"value": "-\tWhat are the computational times for running the experiments?\n-\tWhat is the reason behind selecting only one source for the experiments? \n-\tWhat is the reason behind the presented combination of source-target datasets for the experiments?\n-\tWhat is the reason behind selecting BERT to extract the column features?\n-\tThrough the recent advances in tabular learning, it seems possible to use llms to encode rows in a table as a sentence and perform various forms of domain adaption or transfer learning. Have the authors considered these as baselines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "fKdglFsFrY", "forum": "7X0HFmpTvV", "replyto": "7X0HFmpTvV", "signatures": ["ICLR.cc/2026/Conference/Submission7631/Reviewer_ttcS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7631/Reviewer_ttcS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7631/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762007638114, "cdate": 1762007638114, "tmdate": 1762919708715, "mdate": 1762919708715, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes CATTLE (Cross-domain Attention Transfer Learning), a framework for transfer learning between tabular datasets with disjoint feature spaces. The method builds upon a modified FT-T architecture (Gated Feature Tokenizer Transformer, gFTT), and the key idea is to transfer and freeze the key/value projection matrices of the attention layers from a pretrained source model, while retraining the query projections on a new target dataset. The authors argue that this enables data-agnostic structural transfer between heterogeneous tables. Experiments on multiple OpenML datasets demonstrate improvements over classical baselines and prior tabular transfer methods such as TransTab, XTab, and CM2."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper addresses a challenging and underexplored problem: transfer learning across heterogeneous tabular domains without shared features.\n\n- The idea of transferring attention weights rather than feature-level representations is interesting."}, "weaknesses": {"value": "- **Lack of theoretical foundation and over-reliance on empirical results.**\nThe proposed transfer mechanism is motivated almost entirely by empirical observation, without any theoretical or representational justification. Most architectural decisions—including which layers to transfer, which weights to freeze, and how to structure the transfer—are justified solely by ablation performance. Without an analysis of what these weights represent, it is unclear why they should generalize across feature spaces.\n\n- **Unconvincing and counterintuitive “top-to-bottom” layer transfer.**\nThe practice of copying deep (semantic) layers from the source transformer into shallow (low-level) layers of the target transformer contradicts the conventional understanding of hierarchical representation learning. Deep layers typically capture domain-specific semantics, while shallow layers encode general patterns. Reversing this hierarchy lacks any conceptual rationale, raising doubts about the generality of the claimed “structural transfer.”\n\n- **Contradiction between the use of column-level semantic embeddings and the absence of adaptive column matching.**\nThe model depends on explicit column embeddings and fixed feature order, which breaks permutation invariance and introduces implicit dependence on feature semantics. However, it simultaneously claims to be “data-agnostic” and performs no adaptive matching or semantic alignment between source and target columns. This creates an internal inconsistency: the method relies on column-level semantics to function, yet provides no mechanism to align or reconcile them across heterogeneous domains."}, "questions": {"value": "- What is the conceptual basis for transferring deep source layers into shallow target layers?\nHow does this align with known representational hierarchies in transformers?\n\n- Can the authors provide any evidence (e.g., attention visualization) showing that the transferred weights capture reusable relational patterns?\n\n- Would the method’s behavior change if the target dataset’s column order were permuted?\n\n- Is there any evidence that the transferred attention structure captures semantically meaningful relations rather than random initialization bias?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wLn1KUJUI3", "forum": "7X0HFmpTvV", "replyto": "7X0HFmpTvV", "signatures": ["ICLR.cc/2026/Conference/Submission7631/Reviewer_GMLi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7631/Reviewer_GMLi"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7631/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762796122204, "cdate": 1762796122204, "tmdate": 1762919708430, "mdate": 1762919708430, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}