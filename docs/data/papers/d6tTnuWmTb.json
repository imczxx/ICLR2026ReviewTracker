{"id": "d6tTnuWmTb", "number": 9030, "cdate": 1758107948242, "mdate": 1763033671739, "content": {"title": "ICLabAgent: Multi-Agent LMM Framework for Integrated Circuit Footprint Geometry Labeling", "abstract": "Integrated circuit (IC) footprint geometry labeling refers to the process of converting pin diagrams in IC datasheets into machine-readable geometric parameters. This task is critical in printed circuit board (PCB) design and component assembly, as accurate labeling ensures proper IC placement and reliable connectivity. The process is challenged by unstructured annotations, complex footprint arrangements, and abstract geometric diagrams, making fully automated labeling methods inadequate. Traditional EDA tools require heavy manual input and are slow. Existing automation methods, such as OCR or object detection, can extract text or simple shapes but fail to capture the implicit geometric relationships in IC diagrams, leaving the labeling task incomplete. Recent work has shown that end-to-end large multimodal models (LMMs) can perform IC geometry labeling. However, by treating the task as a black box, these methods are prone to shortcut learning and lack interpretability. In this work, we introduce ICLabAgent, the first multi-agent framework for fully automated IC footprint geometry labeling that explicitly models the workflow of expert engineers to produce more interpretable and reliable labeling outcomes. Furthermore, we present ICAgent-Instruct, the first dynamic planning and reasoning dataset tailored for IC footprint geometry labeling. Extensive experiments show that ICLabAgent improves overall accuracy by $10.3$% compared to the previous SOTA method and by $79.5$% compared to manual annotation. Despite using only simple supervised fine-tuning on a 7B model (Qwen2-VL-7B), ICLabAgent surpasses general-purpose LMMs such as GPT-5 (by $94.6$%) and Gemini-2.5 Flash (by $378.8$%).", "tldr": "", "keywords": ["LMM Agent", "Geometry Reasoning", "Integrated Circuit Footprint"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/4d97116ee3cbb5183ee40147dbe0de258ca7fa5b.pdf", "supplementary_material": "/attachment/b7d64bdc5790e95803943b6c9c5b19d6480ec79d.zip"}, "replies": [{"content": {"summary": {"value": "The paper presents a significant and novel contribution to the application of LMMs in the critical engineering domain of Integrated Circuit footprint geometry labeling. The proposed ICLABAGENT framework successfully transitions from the existing end-to-end \"black-box\" approaches to an interpretable, decomposed multi-agent architecture that explicitly models the sequential cognitive workflow of expert PCB engineers. This structural stability results in a substantial improvement in overall geometric accuracy, establishing a new state-of-the-art performance level. The work is supported by robust component evaluation and an instructive ablation study demonstrating the non-redundant contribution of each specialized agent."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe framework introduces an interpretable, decomposed multi-agent LMM architecture that explicitly models the four-stage sequential cognitive workflow of expert PCB engineers. This design fundamentally addresses the stability and black-box limitations of existing end-to-end models.\n2.\tThe novel ICAGENT-INSTRUCT dataset provides rich, expert-level procedural supervision, including dynamic planning strategies, that enables the model to learn how to reason geometrically rather than relying only on final outputs .\n3.\tThe framework achieves state-of-the-art overall layout accuracy, delivering a substantial improvement over the LLM4-IC8K baseline and meeting the strict precision requirements necessary for PCB manufacturing .\n4.\tRigorous ablation studies confirm the non-redundant and essential contribution of each specialized agent in the workflow, validating the robustness and structural soundness of the decomposed design over end-to-end black-box approaches."}, "weaknesses": {"value": "1.\tThe theoretical argument in Section 5.4 (Stage-3-only) for \"constraining output space reduces cumulative errors\" is insufficient and non-intuitive. This would elevate the finding from an specific observation to a general principle for structured reasoning tasks\n2.\tThe paper omits critical \"performance-cost balance\" metrics for industrial utility, despite specifying GPU hardware (Section 5.1). It does not report total training time (e.g., hours on 8×A100) or inference time cost.\n3.\tIt lacks a comparison with the LLM4-IC8K baseline in these metrics. Intuitively, multi-agent sequential reasoning may consume more computing resources , which raises questions about the fairness of direct performance comparison and limits assessment of its industrial deployment potential. \n4.\tThe sole use of absolute error (MAE) fails to distinguish error characteristics across parameter type. It is recommended that the authors supplement the absolute error metrics with normalized errors."}, "questions": {"value": "The technical attributes and working mechanism of the Description Generation Tool (Stage 4) are insufficiently described, leaving ambiguity as to whether it uses fixed algorithmic logic or model-based reasoning. If the tool uses fixed algorithmic logic (e.g., geometric rules), please specify the core logic for different footprint types."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DA2Ag0UL83", "forum": "d6tTnuWmTb", "replyto": "d6tTnuWmTb", "signatures": ["ICLR.cc/2026/Conference/Submission9030/Reviewer_LGRX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9030/Reviewer_LGRX"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9030/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761393803168, "cdate": 1761393803168, "tmdate": 1762920750978, "mdate": 1762920750978, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "t37HlK3wJm", "forum": "d6tTnuWmTb", "replyto": "d6tTnuWmTb", "signatures": ["ICLR.cc/2026/Conference/Submission9030/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9030/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763033671125, "cdate": 1763033671125, "tmdate": 1763033671125, "mdate": 1763033671125, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ICLABAGENT that is a novel multi-agent framework leveraging large multimodal models for automated integrated circuit footprint geometry labeling. The framework emulates the step-by-step reasoning process of expert PCB engineers, addressing limitations of existing end2end black-box methods. It comprises three specialized agents: Diagram Agent, Planning Agent, and Parameter Agent. Then, a new dataset called ICAGENT-INSTRUCT, is constructed to train these agents with expert-level reasoning annotations. This work highlights the potential of multi-agent LMM systems in complex geometric reasoning tasks within EDA workflows."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- This work addresses a real-world bottleneck in PCB design: manual IC footprint labeling from datasheets is slow, error-prone, and lacks automation.\n- Explicitly models human-expert reasoning, avoiding black-box shortcuts and improving trust and debuggability.\n- This work gains significant accuracy gains and it outperforms GPT-5 by 94.6% and Gemini-2.5-Flash by > 50% on the same benchmark. Besides, it has +10.3% IoU over previous best and +79.5% over human industrial baseline."}, "weaknesses": {"value": "- Limited generation validation: since all experiments conducted on a single benchmark (ICGEOQA), there is no evaluation on other public libraries (SnapEDA, Ultra Librarian) to assess domain robustness.\n- Limited failure case discussion: here only high-level limitations mentioned, but no detailed qualitative examples of typical failure patterns."}, "questions": {"value": "- When footprint diagrams and textual specs conflict, which source does the framework trust, and can it explicity model conflict detection and confidence weighting?\n- Could injecting explicit symmetries, DRC rules, or overlap-area constraints import few-shot robustness compared with the current purely data-driven approach?\n- How does the multi-agent inference cost compare with traditional CV-rule hybrid methods, and what model-compression/quantization steps maintain accuracy while reducing carbon footprint?\n- Are this work plugins for Cadence/KiCad and what is the integration overhead?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tPZ8a4bbNd", "forum": "d6tTnuWmTb", "replyto": "d6tTnuWmTb", "signatures": ["ICLR.cc/2026/Conference/Submission9030/Reviewer_j5Ne"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9030/Reviewer_j5Ne"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9030/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923992406, "cdate": 1761923992406, "tmdate": 1762920750151, "mdate": 1762920750151, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the problem of integrated circuit footprint geometry labeling, which is the process of extracting specific information about the integrated circuit footprint—such as the number of pins, coordinates of the pins, pin dimensions, etc.—from an integrated circuit datasheet. This paper introduces a new framework that leverages four different vision-language models as agents for different stages of the extraction process: (1) a diagram agent for locating the footprint diagram in the datasheet, (2) an agent for categorizing the footprint pattern and high-level characteristics of the design, (3) an agent for pulling out more fine-grained parameters of the design, and (4) an agent for specifying exactly the pin count, coordinates, and dimensions."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- Integrating vision-language models into EDA flows is a timely and promising area of research. This work also presents high novelty in addressing a stage of IC development that has not been touched on much in previous work. \n- Splitting the IC footprint labeling task into multiple steps for different agents is a good idea to overcome the limitations of solving the task zero-shot."}, "weaknesses": {"value": "- This could be due to my lack of background in the area, but it is very difficult to grasp the problem that this paper is trying to solve. The problem definition and motivation are not clearly established until late in the paper (see comments below).\n- The experimental comparison to general-purpose LMMs is unfair. Testing these models only in a zero-shot setting provides a significant and potentially misleading advantage to the authors' fine-tuned model. A fair comparison would require at least few-shot prompting for the baselines.\n- The paper needs to describe in greater detail the construction of its proposed dataset. From my understanding, the dataset is based on prior work, but the paper fails to clearly articulate the specific, novel contributions made during its construction. While the authors mention creating a 'dynamic planning and reasoning' dataset, the process for generating these new reasoning-focused annotations is not sufficiently detailed. This makes it difficult to assess the novelty and significance of this contribution."}, "questions": {"value": "- Especially since this is a machine learning conference, it could be helpful to show a figure of what is meant by a footprint diagram and “Suggest Pads”/“Land Patterns.”\n  The reader can look this up on the internet, but it would be helpful to have a small illustration, even in the appendix.\n\n- > These steps are essential for ensuring interpretability and reliability. In contrast, our multi-agent design explicitly mirrors this human workflow through diagram detection, type classification, parameter extraction, and description generation.\n\n  No workflow was mentioned at this point in the paper.\n\n- Line 107: Since Figure 1 is being referenced, it would be good to have a brief overview in text so that readers can follow along with the figure.\n\n- Lines 137–138: What is meant by perceiving–planning–reasoning–execution architecture here?\n\n- Line 177: It would be really nice to have a figure at this point in the paper so we can better understand the problem that is being solved.\n\n- Line 183: This explanation needs to appear much higher in the paper. Until this paragraph, the general problem that this paper aims to solve is extremely unclear.\n\n- Line 208: Say where in Figure 2; otherwise it is difficult to cross-reference."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3Pi7yDqG9R", "forum": "d6tTnuWmTb", "replyto": "d6tTnuWmTb", "signatures": ["ICLR.cc/2026/Conference/Submission9030/Reviewer_toJk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9030/Reviewer_toJk"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9030/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761960015556, "cdate": 1761960015556, "tmdate": 1762920749368, "mdate": 1762920749368, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ICLabAgent, a multi-agent large multimodal model (LMM) framework for automated IC footprint geometry labeling — a key task in PCB design that converts pin diagrams into machine-readable parameters. The framework mimics the human engineer’s reasoning process via three specialized agents: a Diagram Agent for region detection, a Planning Agent for footprint classification and parameter planning, and a Parameter Agent for parameter extraction and reasoning. The authors also introduce ICAgent-Instruct, a new dataset with expert-level planning annotations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper presents a novel agentic decomposition of an engineering workflow that was previously handled as a black-box task. It is the first to apply multi-agent LMM reasoning to IC footprint labeling, bridging the gap between visual-semantic understanding and geometric reasoning. The modular design (region detection → type classification → parameter extraction) improves interpretability and reduces hallucination, validated via comprehensive ablation.  The ICAGENT-INSTRUCT dataset is carefully curated to capture step-by-step reasoning, enhancing reproducibility. The model consistently outperforms both general-purpose and domain-specific baselines on multiple granular metrics (IoU, MAE, RMSE). The work addresses a real industrial pain point, and the presented approach could generalize to other engineering diagram-understanding tasks."}, "weaknesses": {"value": "All experiments are conducted on datasets derived from ICGEO8K. It is unclear whether the method generalizes to unseen schematic types (e.g., analog vs digital ICs, irregular layouts).\n\nThe ablation in Table 3 focuses on stage removal but lacks insight into cross-agent communication efficiency and error propagation.\n\nThe reported superiority over GPT-5 and Gemini-2.5 is informative but somewhat unfair since those models are used zero-shot; fine-tuned LMM baselines or strong visual backbones (e.g., InternVL) would strengthen the claim.\n\nThe paper references diagram-detection “tools” (e.g., Tool 1–3) without sufficient architectural or hyperparameter detail.\n\nLimited discussion of computational cost and latency, which are critical in industrial PCB workflows."}, "questions": {"value": "How is inter-agent communication implemented? Are messages exchanged in natural language or structured schema, and how is context preserved across agents?\n\nWhat is the impact of CoT-style supervision versus simple instruction fine-tuning in each agent’s performance?\n\nHow does the model handle ambiguous or partially occluded footprint diagrams where geometric parameters are missing or inconsistent?\n\nCould the authors clarify the robustness of the approach to noisy or low-resolution datasheets (common in older IC documents)?\n\nAre there plans to release ICAGENT-INSTRUCT with standardized tool APIs to enable reproducible evaluation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nQiJ2SxLcp", "forum": "d6tTnuWmTb", "replyto": "d6tTnuWmTb", "signatures": ["ICLR.cc/2026/Conference/Submission9030/Reviewer_BkGe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9030/Reviewer_BkGe"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9030/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762061486261, "cdate": 1762061486261, "tmdate": 1762920748837, "mdate": 1762920748837, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}