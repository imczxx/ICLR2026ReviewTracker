{"id": "5gjZh86sRa", "number": 4631, "cdate": 1757730206967, "mdate": 1759898022589, "content": {"title": "UOTIP: Unbalanced Optimal Transport Map for Unpaired Inverse Problems", "abstract": "We address the problem of unpaired image inverse problems, where only independent sets of noisy measurements and clean target signals are available. We propose a novel inverse problem solver based on Unbalanced Optimal Transport, called Unbalanced Optimal Transport Map for Inverse Problems (UOTIP). Our method formulates the reconstruction task—predicting clean target signals from noisy measurements—as learning a UOT Map from noisy measurement distribution to clean signal distribution by incorporating a likelihood-based cost function. By relaxing the exact marginal constraint, the UOT framework provides key advantages to our model: robustness to multi-level observation noise, adaptability to class imbalance between noisy and clean datasets, and generalizability to diverse noise-type scenarios. Moreover, with a quadratic cost formulation, our model effectively handles linear inverse problems with unknown corruption operators. Our experiments show that our model achieves state-of-the-art performance on unpaired image inverse problem benchmarks, across linear (super-resolution and Gaussian deblurring) and nonlinear (high dynamic range reconstruction and nonlinear deblurring) inverse problems.", "tldr": "We propose a novel approach for unpaired image inverse problems based on Unbalanced Optimal Transport (UOT).", "keywords": ["Optimal transport", "Unbalanced optimal transport", "Inverse problem"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5edfc6eca7a5a8e11256097a0df0e845b8d98821.pdf", "supplementary_material": "/attachment/7c19e6f6077021e2717cd3fcad3fe2cc6e8197d1.zip"}, "replies": [{"content": {"summary": {"value": "The paper presents a novel inverse problem solver based on unbalanced optimal transport (UOT), which can learn from unpaired datasets of measurements and ground-truth signals. The paper motivates a loss based on UOT that requires training two networks in a minimax way, the inverse solver $T$ and a potential function $v$. The paper compares with other inverse solvers based on optimal transport, showing competitive results on super-resolution, Gaussian deblurring, high-dynamic range reconstruction, and non-linear deblurring."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Introduces an interesting loss for training reconstruction networks based on optimal transport that can handle class imbalances and unpaired data.\n- Presents better reconstruction performances than other optimal-transport baselines in various inverse problems.\n- A series of ablations of the proposed method are presented that illustrate the impact on unbalanced datasets and robustness across noise types and varying noise levels."}, "weaknesses": {"value": "- A discussion of links to the state-of-the-art outside optimal transport is lacking: there exist various approaches that can train reconstruction networks with unpaired datasets, and it would add a significant amount of value to the paper to include a discussion on the links and differences with these methods, and also some numerical comparisons. \n    - learned regularisers: There are various papers learning regularizers from unpaired data, e.g., \"Adversarial regularizers in inverse problems\", NeurIPS 2018, or \"A neural-network-based convex regularizer for inverse problems.\" IEEE TCI 2023. it would be good to understand how the potential function used in this paper relates to them.\n    - GAN-based: CycleGAN also doesn't require paired data that have a close relationship to optimal transport e.g. \"Optimal Transport driven CycleGAN for Unsupervised Learning in Inverse Problems\", SIAM 2019.\n    - diffusion/PnP priors: there is an extensive literature on training denoising-based priors (aka Tweedie's formula), which also doesn't require paired data (one could add noise to the ground-truth to learn the denoiser).\n\n- The method seems to fail in noisy settings $\\sigma_y\\geq 0.1$ (see e.g. fig. 17), while most state-of-the-art learned inverse problem solvers can handle this amount of noise.\n\n- I have a few concerns regarding the blind inverse problem setting:\n    - The size of the measurements often doesn't match the size of the signals/images. This should be clarified from the beginning and offer a generic solution. This is only mentioned for the SR experiments, and it is unclear how one would resize measurements in other blind scenarios. \n   - The experiments for the blind case are only reported in tables. It would be good to show some visual results to understand how well the algorithm performs.\n\n- The presentation of the experiments could be improved:\n   - The Poisson noise definition is unclear, and the reader is pointed to (the appendix!) of another paper to understand it. After reading the cited paper, I understood that the rate is defined w.r.t. to 8-bit pixel values $[0,255]$. This differs from the Gaussian noise definition, which is on normalized values $[0,1]$. This is non-consistent and confusing. I recommend including a clear definition of the Poisson noise in the paper.\n   - the non-linear operator is not described either - it feels that the paper 'copied-pasted' some degradation operators from other papers without making an effort to explain them to the reader.\n\n\n- The figures/tables could be improved: Fig. 1 is a simple description of what is an inverse problem is, and does not convey any specific information about the paper. Fig. 5 would be clearer as a table instead of a bar plot.\n\n- I believe the loss could be better explained to a wider machine learning audience by simplifying the notation in eq. 15: I would replace the values of $\\Psi_i$ by one of the two options considered in the paper, replace integrals by sums over a finite dataset (or write expectations). \n\n- The idea of class imbalances is not very common in inverse problems to the best of my knowledge. I would suggest to explain the motivation early on in the paper.\n\n- I believe the unpaired setting with a known forward operator might not be sufficiently realistic: even if the noise level is unknown, one could generate paired data by applying the degradation operator at multiple noise levels to the ground-truth data, and then train an end-to-end network on this paired dataset. Note that it is a standard practice to train end-to-end networks on multiple noise levels."}, "questions": {"value": "- It is unclear how the datasets of measurements and signals are created: is there overlap between the measurement and signal datasets? More specifically, can we find the noisy/degraded version of a clean signal in the measurement dataset? I would expect that a fair, unpaired dataset has no overlap, since otherwise one could try to pair them by 'manually' (or with a simple ad-hoc distance/metric), looking for the closest measurement to any given ground truth signal.\n\n- The two conditions 3.1 seem to contradict the perception-distortion trade-off (Blau and Michaeli, 2019) that states that one can't recover the signal distribution exactly - condition i - and at the same time have low distortion - condition ii - (i.e., low error wrt ground-truth) reconstructions?\n\n- The multi-level noise experiment doesn't seem very realistic: in such an experiment, why wouldn't one average the multiple noise realisations of the same image in the dataset? This would boost the SNR and remove the unbalanced issue.\n\n- It is not fully clear to me whether the optimization wrt $T_\\theta$ is done inside the integral of $y$ or outside in practice, i.e. do you minimize the objective for each sample $y$ or just on average over the $y$ distribution?\n\n- The resizing operation in the blind SR problem doesn't break the twist condition?\n\n- Would you still expect the algorithm to work in blind settings where the simple quadratic loss $\\|x-y\\|^2$ is not a good proxy for the error, i.e. motion deblurring, where $x$ can be shifted by one pixel to the right, leading to large quadratic errors?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zw5tvCqEQg", "forum": "5gjZh86sRa", "replyto": "5gjZh86sRa", "signatures": ["ICLR.cc/2026/Conference/Submission4631/Reviewer_nmHQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4631/Reviewer_nmHQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4631/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760922619133, "cdate": 1760922619133, "tmdate": 1762917479268, "mdate": 1762917479268, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an unbalanced optimal transport map for solving inverse problems, which targets unpaired imaging inverse problems with noisy measurements and clean images are sampled independently. Traditional OT enforces strict marginal matching between two distributions, however, the proposed method relaxes this via unbalanced OT, where mass is rescaled using divergence penalties. This allows to address challenges like imbalance datasets and noise level variations. \n\nThe proposed method combines a likelihood-based cost, enforcing measurement consistency, with a quadratic regularization term that satisfies the theoretical twist condition for the existence and uniqueness of the transport map. \n\nThe authors validate their approach on four inverse problems—Gaussian deblurring, super-resolution, HDR reconstruction, and nonlinear deblurring—showing that UOTIP consistently outperforms strong baselines such as NOT, OTUR, and RCOT. The paper’s main contributions include: (1) introducing UOT into the unpaired inverse problem setting, (2) formulating a principled likelihood-based transport cost grounded in inverse problem modeling,  and (3) demonstrating improved results with enhanced robustness to diverse noise and imbalance conditions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The paper is generally well-written and well-structured, with clear motivation and comprehensive ablation studies.\n* The paper presents convincing and strong experimental evidence to verify the  claims of superiority of the performance of the proposed method. \n* The provided experimental results are broad and inclusive (2 varied datasets, 4 inverse problems, and comparison with three relevant baselines). \n* The performance of the proposed methods shows clear improvements over the existing baselines. \n* The authors have included additional results demonstrating the ability of the proposed method to handle different noise types, noise levels and source and target data imbalance. \n* The authors have provided ablation studies to assess the effect of cost functions, one problem adaptive which uses the measurement model and the second general quadratic cost function."}, "weaknesses": {"value": "The core elements of the proposed framework—optimal transport maps, unbalanced OT, and likelihood-based cost formulations—already exist in the literature. The novelty of the paper therefore lies primarily in connecting and integrating these existing components within the context of unpaired inverse problems, rather than introducing a fundamentally new framework. \n\n* The concept of using optimal transport maps (OT) for unpaired image tasks is not new. For example, the paper \"An Optimal Transport Perspective on Unpaired Image Super‑Resolution (2022)\" used the OT framework for unpaired SR. Thus, the baseline idea of “map distribution of measurement  to distribution of clean signal via OT” has been investigated. \n* The concept of unbalanced optimal transport (UOT) itself is well‐established in the OT literature (e.g., handles mismatched masses, outliers) and has been applied in other ML contexts. \n* Using likelihood‐based costs  appears in some related works (Inverse Entropic OT Solves Semi-supervised Learning via Data Likelihood Maximization (2024)). \n\n* The paper  does not analyze training cost or scalability, which may become a concern for higher-resolution data."}, "questions": {"value": "The proposed likelihood cost function  inherently depends on the properties of the forward operator A. Could the authors clarify what specific assumptions are required on A for the theoretical results to hold? Could the authors also comment on the cases where assumptions are not met in practice, but the method seems to work?\n In particular, does the framework extend to nonlinear or non-differentiable operators, or is it restricted to Lipschitz-continuous and differentiable forward models? How would the method behave for inverse problems where A is discontinuous, piecewise-defined, or only approximately known?\nI believe a broader discussion of the characteristics of the inverse problems that could be addressed with the proposed method needs to be included in the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SAgsENPYUo", "forum": "5gjZh86sRa", "replyto": "5gjZh86sRa", "signatures": ["ICLR.cc/2026/Conference/Submission4631/Reviewer_8dhT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4631/Reviewer_8dhT"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4631/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761241392232, "cdate": 1761241392232, "tmdate": 1762917478921, "mdate": 1762917478921, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes UOTIP, a novel solver for unpaired inverse problems that learns an Unbalanced Optimal Transport (UOT) map from noisy measurements to clean signals with a standard likelihood-based cost function as guidance. The UOT framework provides robustness to multi-level noise and class imbalance, enabling UOTIP to achieve state-of-the-art performance on several linear and nonlinear inverse problem benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper provides clear, empirical evidence for why UOT is superior to standard OT for inverse problem tasks.\n\n2. Within its comparison class (other OT-based methods like NOT, OTUR, and RCOT), UOTIP achieves state-of-the-art performance across all four linear and nonlinear benchmarks.\n\n3. The writing is clear and easy to follow."}, "weaknesses": {"value": "1. The paper claims \"state-of-the-art performance\" , but the experimental comparison is limited to other Optimal Transport (OT) methods (NOT, OTUR, RCOT) . The actual state-of-the-art for many unpaired inverse problems often involves diffusion models or other advanced generative methods. Please compare with BlindDPS, GibbsDDRM, UNSB.\n\n2. The paper's main likelihood cost $c_l$ is based on the $L_2$ norm, which is optimal only if you assume Gaussian measurement noise. The paper then tests this exact same Gaussian-derived cost function on Laplace noise and Poisson noise (Sec 4.2). It claims this shows \"generalization\", which is overclaimed. It just shows the model doesn't completely fail, not that it's robust. A solid paper would have derived the correct likelihood cost for Laplace (an $L_1$ norm) or Poisson noise to show the framework's flexibility, not just the robustness of a mismatched cost.\n\n3. The paper presents the robustness to multi-level noise and class imbalance as key advantages of their model. However, the paper itself cites prior work for these exact properties of Unbalanced Optimal Transport.Therefore, the paper isn't discovering that UOT is robust; it's simply applying a known benefit of UOT to the inverse problem domain. The core novelty is just the application and the $\\mathcal{A}$-dependent cost function, which is a standard approach used in [1][2].\n\n4, This $c_q$ variant for 'real' unknown corruption setting was only tested on the two linear inverse problems. The paper provides no evidence for how this \"blind\" variant would perform on the much more complex nonlinear tasks (HDR and Nonlinear Deblurring). \n\n\n5. Following my previous comment 4. The paper's claim of handling \"unknown corruption operators\" is misleading. The main contribution and study, the likelihood cost $c_l(y,x) = ||\\mathcal{A}(x)-y||_2^2$, explicitly requires a known operator $\\mathcal{A}$. The \"blind\" capability is relegated to a $c_q$-only variant that is not comprehensively evaluated. This variant was only tested on linear problems, providing no evidence for its performance on the more complex nonlinear tasks.\n\n[1] Chung, H., Kim, J., Kim, S. and Ye, J.C., 2023. Parallel diffusion models of operator and image for blind inverse problems. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 6059-6069).\n\n[2] Murata, N., Saito, K., Lai, C.H., Takida, Y., Uesaka, T., Mitsufuji, Y. and Ermon, S., 2023, July. Gibbsddrm: A partially collapsed gibbs sampler for solving blind inverse problems with denoising diffusion restoration. In International conference on machine learning (pp. 25501-25522). PMLR.\n\n[3] Kim, B., Kwon, G., Kim, K. and Ye, J.C., Unpaired Image-to-Image Translation via Neural Schrödinger Bridge. In The Twelfth International Conference on Learning Representations."}, "questions": {"value": "Same as my Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BWSUuKhpYo", "forum": "5gjZh86sRa", "replyto": "5gjZh86sRa", "signatures": ["ICLR.cc/2026/Conference/Submission4631/Reviewer_84WS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4631/Reviewer_84WS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4631/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761943906820, "cdate": 1761943906820, "tmdate": 1762917478580, "mdate": 1762917478580, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to recover a clean target signal distribution from a noisy observation distribution within an 'unpaired' inverse problem framework.  In particular, the authors propose learning an Unbalanced Optimal Transport (UOT) mapping to transform the observed distribution into the target distribution.  The authors finally propose training a hybrid loss and demonstrate its effectiveness through experimental results on both linear and nonlinear inverse problems (natural image restorations)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The idea of applying UOT to unpaired inverse problems is very interesting. Since UOT can address distributional mismatch issues, it could provide an alternative solution to problems that standard OT struggles to handle directly.\n\n- The authors also studied the theoretical conditions for the existence of OT maps (twist and semi-concavity) and tried to demonstrate the rigour of cost design in satisfying solubility conditions, thereby surpassing some empirical methods.\n\n- The experimental results are good with respect to multiple tasks and noise types/levels. It shows that better results are achieved when the noise model aligns with the cost."}, "weaknesses": {"value": "- Theoretical proof can be improved. For example, the paper uses Fathi and Figalli's theorem to guarantee the existence of the OT map. However, no rigorous proof is provided as to whether the conditions within that theorem (e.g. local semi-concavity, left twist and the zero-mass condition) are met in high-dimensional image spaces and under the cost function, c(y, x). \n\n- The claim that adding a quadratic term guarantees the existence and injectivity of a map depends on key constants (e.g. λ > Lipschitz L). How can L be estimated in practice? Does the proof rely on hidden strong assumptions?\n\n- No presented convergence guarantees or training dynamics plots weaken confidence in practicality.\n\n- The experimental results are not significantly superior.\n\n- The writing could be further improved. Typo: in Eq. (23), the last term should be written as $A(x)$ instead of $A(y)$."}, "questions": {"value": "- What network architectures are used for training? It's necessary to complete hyperparameter descriptions, seeds, training times and memory consumption are needed.\n\n- Are the baselines being trained and tuned equivalently? There are no comparisons to diffusion/posterior-sampling methods.\n\n- What if the inverse problem is that x and y are in different domains? For example, consider MRI image reconstruction. I am curious about the performance on e.g. biomedical imaging applications. \n\n- Eq(17)-Eq(20): What if the noise models/levels are unknown?\n\n- Verifying that c(y, x) satisfies the Fathi and Figalli assumptions (local semi-concavity, left twist and μ not assigning mass to certain sets) is necessary for the task at hand."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lVzIUqzH0x", "forum": "5gjZh86sRa", "replyto": "5gjZh86sRa", "signatures": ["ICLR.cc/2026/Conference/Submission4631/Reviewer_8LLr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4631/Reviewer_8LLr"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4631/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761958200799, "cdate": 1761958200799, "tmdate": 1762917478145, "mdate": 1762917478145, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}