{"id": "3ZDptypV4r", "number": 12007, "cdate": 1758205149615, "mdate": 1763679511502, "content": {"title": "Not All Tokens Matter Equally: Uncertainty-Guided Test Time Prompt Adaptation", "abstract": "Not all prompt tokens contribute equally to generalization under distribution shift. While test-time prompt tuning provides a lightweight approach to adapt vision-language models without retraining, most methods update all prompt tokens uniformly, without considering their individual uncertainty or relevance. We introduce SPLAT (Spike and SLab Prompt Adaptation at Test time), a selective adaptation framework that adjusts the update strength of each token based on its estimated uncertainty. SPLAT uses Monte Carlo Dropout to measure token-wise epistemic uncertainty and applies a gating function to scale gradient updates accordingly. This mechanism is grounded in a probabilistic interpretation of a spike-and-slab prior, allowing each token to be softly preserved or adapted. We further derive a variational learning objective that encourages stable adaptation while preserving pretrained knowledge. Experiments on ten cross-dataset and four domain zero-shot generalization benchmarks show that SPLAT not only improves accuracy over existing test-time prompt tuning methods but also reduces unnecessary updates and provides finer-grained, token-level control during adaptation, a capability absent in prior approaches.", "tldr": "We propose SPLAT (Spike-and-sLab Prompt Adaptation at Test-time), a selective prompt adaptation framework that modulates each token’s update magnitude based on test-time uncertainty.", "keywords": ["Vision-Language models", "Prompt Learning", "Test-Time Adaptation"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cc0c4dc1bf167d0024b39da8260308f803096ab2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes uncertainty-guided weighting of gradient updates for learnable prompts in test-time prompt adaption tasks based on CLIP. It estimates epistemic uncertainty using MC Dropout, followed by a gating function that outputs weights for gradients of each learnable prompt. It also shows a connection between the proposed method with spike-and-slab prior through variational objective. Compared to existing test-time prompt adaptation methods based on entropy minimization, the authors demonstrate the effectiveness of the proposed method on 15 benchmark datasets."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. It provides clear motivation and setting for the proposed method.\n2. The proposed method is simple and applicable to many existing test-time prompt adaptation methods.\n3. The authors provide extensive experiments on many different datasets to demonstrate the effectiveness of the proposed method"}, "weaknesses": {"value": "1. The title can be misleading. The paper focuses on test-time prompt adaptation using CLIP. Although the former is specified, CLIP is not specified. Some readers may think it is applicable for any models with tokens (may be true but not demonstrated in the paper).\n2. Writing is somewhat redundant. For example, some related works in Section 2 and 3 are unnecessarily repeated without giving much additional information.\n3. It relies on MC Dropout which requires to have dropout layers, which are not always used in practice. \n4. It is not convincing that MC Dropout primarily captures epistemic uncertainty although it computes total variance. How is aleatoric uncertainty minimized just because input prompt tokens are deterministic and shared? Would it still be there if there is uncertainty for inputs: for instance, a given image is blurry so the corresponding input text is ambiguous. The claim may be true for some inputs but I am not sure how generalizable it is.\n5. The connection with spike-and-slab provided in Section 4.3 is somewhat hand-wavy. In particular, the second term in Eq.(11) is KL between two Gaussians with $\\mu_j$ and $e_j^0$. With $\\mu_j$, it is unsure how this is interpreted as spike. \n6. The improvements, especially Table 1, are somewhat marginal compared to the second best baselines; improvement is mostly $<1\\\\%$. More importantly, the reported numbers are based on single run. Without standard deviation, it is hard to compare different methods."}, "questions": {"value": "1. Did the authors have comparison of different methods in terms of run-time? It would be great to see what’s the computational overhead of the proposed method given that MC Dropout is known for its computational bottleneck."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "11MBPbNLsv", "forum": "3ZDptypV4r", "replyto": "3ZDptypV4r", "signatures": ["ICLR.cc/2026/Conference/Submission12007/Reviewer_5nLR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12007/Reviewer_5nLR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761494785740, "cdate": 1761494785740, "tmdate": 1762922996807, "mdate": 1762922996807, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SPLAT, which estimates token-wise epistemic uncertainty via MC-Dropout, then map it to a gating weight, and scale each prompt token’s update accordingly, finally, it grounded in a spike-and-slab prior with a test-time ELBO. The Evaluations on 10 cross-dataset and 4 OOD dataset benchmarks show gains over prior TPT."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper introduces a novel perspective on TPT for CLIP-style VLMs, shifting the focus from the visual branch or prompt engineering to token-level importance modeling.\n2. The core idea is intuitive, enabling fine-grained, input-adaptive control over prompt adaptation.\n3. The method is probabilistically well-grounded, leveraging a spike-and-slab prior and variational objective that elegantly balances between adapting uncertain tokens and preserving pretrained knowledge.\n4. The approach is parameter-efficient and deployable compared with original TPT."}, "weaknesses": {"value": "1. The proposed method is only validated on CLIP-style VLMs (e.g., ViT-B/16 with text encoders). It remains unclear whether the approach extends to other backbones(ResNet50, ViT-L)/architectures such as SigLIP, SigLIP-v2, or decoder-style VLMs like Flamingo, which differ significantly in their tokenization and adaptation mechanisms.\n2. The reliance on MC-Dropout introduces multiple stochastic forward passes at inference time. While the authors briefly explore trade-offs with the number of samples, a thorough analysis of latency, throughput, or hardware constraints is missing, particularly important for real-time or resource-constrained settings.\n3. The method exclusively adopts MC-Dropout for epistemic uncertainty without comparing to alternative approaches such as deep ensembles, Laplace approximations. (at least the evidence of such design should be discussed)\n4. Several recent training-free adaptation methods are not included in the comparison, such as TDA [1] (CVPR 2024) and TCA [2] (ICCV 2025). These methods achieve strong performance with zero learnable parameters and often outperform TPT variants. TCA in particular requires no test-time augmentations, suggesting a stronger baseline for parameter- and compute-efficient adaptation.\n\n\n[1]. Efficient test-time adaptation of vision-language models\n\n[2]. Is Less More? Exploring Token Condensation as Training-free Test-time Adaptation"}, "questions": {"value": "1. Have you evaluated SPLAT on other vision-language architectures beyond CLIP? These models differ significantly in tokenization and architecture, and it would strengthen the claim of general applicability.\n2. Are there observed failure modes when uncertainty estimates are noisy?\n3. Given that MC-Dropout introduces additional inference cost, have you explored adaptive strategies for selecting the number of stochastic forward passes? \n4. Why was MC-Dropout chosen over alternatives? Have these been compared experimentally or considered for future extension? A discussion of trade-offs would be helpful.\n5. SPLAT applies uncertainty-guided updates to learnable text tokens, which are known to lack interpretability. Could you clarify the motivation for focusing on these tokens specifically, and how your method improves their reliability or interpretability under distribution shift?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "VjIJOtVz7s", "forum": "3ZDptypV4r", "replyto": "3ZDptypV4r", "signatures": ["ICLR.cc/2026/Conference/Submission12007/Reviewer_ZcKM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12007/Reviewer_ZcKM"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761713543403, "cdate": 1761713543403, "tmdate": 1762922996450, "mdate": 1762922996450, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SPLAT, a test-time prompt tuning method that estimates token-wise epistemic uncertainty (via MC-Dropout) and uses a gating function to scale the **gradient updates** of prompt tokens, so that “uncertain” tokens adapt more while “certain” tokens are updated less. The approach is plug-and-play on top of CLIP-style prompt learners (e.g., CoOp/CoCoOp/MaPLe/MMRL) with frozen encoders, and reports consistent gains on cross-dataset and ImageNet OOD benchmarks. The work is conceptually clean — linking uncertainty estimates to selective token adaptation and offering a spike-and-slab variational view — though some pipeline details (esp. Fig. 2) and robustness questions (uncertainty calibration, aleatoric vs epistemic, token influence) remain."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Simple, general **plugin** that works with existing prompt-learning methods and keeps encoders frozen.  \n- Provides a probabilistic interpretation (spike-and-slab/ELBO) that matches the algorithmic design.  \n- Demonstrates **consistent improvements** across diverse cross-dataset and OOD settings with modest overhead."}, "weaknesses": {"value": "### 1) Is “update uncertain tokens more, certain tokens less” always the right bias?\nThe central heuristic can fail depending on what the uncertainty encodes and how influential a token actually is.\n\n- **Aleatoric-dominant uncertainty.** If token-wise uncertainty is high due to inherent noise (e.g., synonym churn, function words, semantically idle tokens), larger updates can add variance without utility — or even degrade performance.\n- **Miscalibration.** If the model is over/under-confident, the gate can neglect *certain-but-wrong* tokens and overfit *uncertain-but-uninfluential* ones. A small exploration floor is needed so “certain” tokens still get minor adjustments.\n- **Ignoring influence/salience.** Uncertainty alone does not indicate that changing a token will move the loss. Updating high-uncertainty but **low-influence** tokens wastes compute.\n\n### 2) Ambiguities in the test-time prompt-tuning pipeline (Figure 2, right panel)\n\n- **Natural-language bubble vs. learnable prompt.** The bubble “*a photo of a Hornbill*” suggests raw NL is passed to the text encoder at test time. In TPT, the input should be **[learnable context tokens] + [class tokens]** (continuous prompt embeddings + the discrete class name). The figure should reflect this to avoid implying human-written sentences are used verbatim.\n- **Arrow semantics.** Outgoing arrows from the **image encoder** and the **gated prompt** appear to feed into the **text encoder**, which is misleading.\n- **Scope: text-only or also image-side tokens?** The method is presented as acting on **text tokens**. Prior works like MaPLe/MMRL adjust **both** sides (vision & text). Please clarify whether uncertainty-aware gating was considered for **image-side tokens** (e.g., visual prompt tokens) and, if not, why; a comparison (text-only vs. text+image gating) would be informative."}, "questions": {"value": "Please see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "iV8KMw0huS", "forum": "3ZDptypV4r", "replyto": "3ZDptypV4r", "signatures": ["ICLR.cc/2026/Conference/Submission12007/Reviewer_WcHG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12007/Reviewer_WcHG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761952136952, "cdate": 1761952136952, "tmdate": 1762922995986, "mdate": 1762922995986, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}