{"id": "czJqKToDGq", "number": 3762, "cdate": 1757515612560, "mdate": 1759898071166, "content": {"title": "Gauge-invariant representation holonomy", "abstract": "Deep networks learn internal representations whose geometry—how features bend, rotate, and evolve—affects both generalization and robustness. Existing similarity measures such as CKA or SVCCA capture pointwise overlap between activation sets, but miss how representations change along input paths. Two models may appear nearly identical under these metrics yet respond very differently to perturbations or adversarial stress. We introduce representation holonomy, a gauge-invariant statistic that measures this path dependence. Conceptually, holonomy quantifies the “twist” accumulated when features are parallel-transported around a small loop in input space: flat representations yield zero holonomy, while nonzero values reveal hidden curvature. Our estimator fixes gauge through global whitening, aligns neighborhoods using shared subspaces and rotation-only Procrustes, and embeds the result back to the full feature space. We prove invariance to orthogonal (and affine, post-whitening) transformations, establish a linear null for affine layers, and show that holonomy vanishes at small radii. Empirically, holonomy scales with loop radius and depth, separates models that appear similar under CKA, and correlates with adversarial and corruption robustness across training regimes. It also tracks training dynamics as features form and stabilize. Together, these results position representation holonomy as a practical and scalable diagnostic for probing the geometric structure of learned representations beyond pointwise similarity.", "tldr": "We introduce representation holonomy, a gauge-invariant statistic that captures the path dependence of learned features, revealing geometric structure in deep networks linked to robustness beyond pointwise similarity measures.", "keywords": ["Representation learning", "Gauge invariance", "Holonomy", "Geometric deep learning", "Robustness"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bc767c64e955736910e948c7c5f104a26300612b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work presents a geometrically guided diagnostic tool for meaning the path-dependent geometry of learning features in neural networks. The authors present a novel problem formulation and approach that empirically demonstrate that lower holonomy results in greater model robustness. While the contributions are significant the presentation of the paper could be improved in places with improved rationale, and writing clarity. However, the resulting outputs are potentially valuable as a tool for model comparison and diagnostic work for practictioners and researchers."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "- The identified problem of intermediate feature paths during input perturbations is an interesting and rationaled area of study. The authors address a potentially problematic area of neural network diagnostics, and present an interesting solution using geometry as a diagnostic tool, which is a valuable and interesting direction.\n- The mathematical approach is seemingly well constructed and correct, with the representation holonomy being a highly original and novel direction of model analysis, supported by proofs. \n- The results and analysis demonstrates the correlation of holonomy with adversarial robustness, and links model geometry and its model robustness, a new insight that is an interesting tool for early-training model selection and to investigate flatter representation manifolds.\n- Limitations are presented and discussed."}, "weaknesses": {"value": "**Major:**\n- The problem setting while rationaled in the text could be better supported and demonstrated empirically. For example, what evidence is provided that supports the statement “two models can appear highly similar under CKA or CCA, and still behave differently under adversarial or corruption stress because their intermediate features rotate differently along input paths.”\n- Generally the presentation of the manuscript is poor in places (mainly in its clarity and readability), many of the preliminaries and experimental setup information is assumed by the authors. For example 5.2 is presented with little introduction, and \n\n**Minor:**\n- Acronyms such as SVCCA, CKA, etc need to be defined, while most readers will know such terminology, it is good practice to define such acronyms.\n- The term corruption or adversarial stress could be better defined in the early part of the work to introduce the reader to the concepts. However, this is a minor readability complaint and an opinion. \n- However, much of the presentation could be improved where some preliminary explanation and definitions would strengthen the readability. This could include moving some of the preliminaries from the appendix into the main manuscript as there is space to do so.\n- Code should be included for reproduction and validaiton."}, "questions": {"value": "1. You mention: “projected by a fixed orthonormal Johnson–Lindenstrauss map to p⋆=1024 if needed”. What is the the determination if the projection is needed or not?\n\n2. Did you experiment with alternatively chosen loops, if so how much does performance vary? Given this is a noted limitation, is it significantly impactful to the work?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "gWINdHknUj", "forum": "czJqKToDGq", "replyto": "czJqKToDGq", "signatures": ["ICLR.cc/2026/Conference/Submission3762/Reviewer_ERwd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3762/Reviewer_ERwd"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3762/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761686599959, "cdate": 1761686599959, "tmdate": 1762916973216, "mdate": 1762916973216, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new geometric framework called representation holonomy, which quantifies how neural features change along loops in input space using gauge-invariant parallel transport. The authors define a practical estimator combining global whitening, shared-subspace Procrustes alignment, and loop composition, and they prove gauge and affine invariance as well as small-radius asymptotics. Empirical analyses on MNIST and CIFAR suggest that holonomy increases with layer depth and may correlate with robustness indicators such as adversarial and corruption accuracy.\n\nThe concept is theoretically intriguing and potentially valuable for studying the geometry of learned representations. However, both the experimental validation and the presentation of the theory can be much improved for clarity and completeness."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* Conceptual originality: Introducing holonomy—a gauge-invariant geometric notion from differential geometry—into representation analysis is creative and nontrivial.\n* Mathematical rigor: The formal statements (gauge invariance, affine invariance, small-radius behavior) are internally consistent using matrix perturbation tools. Although I have to admit that I didn’t get a chance to go over all the appendices.\n* Potential significance: In principle, this idea could offer new insights for feature-space curvature and robustness that go beyond CKA and related similarity measures."}, "weaknesses": {"value": "* Incomplete and inconclusive experiments: The reported results (e.g., Figs. 2–3) show overlapping confidence intervals, and several key correlations (Table 2) are weak or include zero within the 95% CI. Without stronger or broader evidence, the empirical support for holonomy as a meaningful metric remains limited.\n* Missing comparisons to existing metrics: Although the paper discusses CKA and CCA extensively, it never provides side-by-side empirical comparisons. Such baselines are crucial to demonstrate what new insights holonomy provides.\n* Lack of sensitivity analysis: The estimator relies on multiple hyperparameters (e.g., k). The paper should quantify how results depend on these choices to establish robustness.\n* Unclear connection to task relevance: Theoretical results (e.g., Eq. 4) include several interacting error terms, but it remains unclear how holonomy relates in a concrete or predictive way to model performance or generalization.\n* Poor illustration of geometric intuition: Given the geometric nature of the work, schematic or pictorial figures showing loops, transports, or curvature effects are essential. The heavy formalism and lack of visual explanation make the paper difficult to follow.\n* Presentation density: The writing style is more reminiscent of a mathematical physics paper than a machine-learning paper, which may alienate part of the ICLR audience."}, "questions": {"value": "1. How sensitive are the results to hyperparameter choices such as k?\n2. Can you provide quantitative comparisons with CKA or SVCCA to highlight the unique information captured by holonomy?\n3. Among the four terms in the error bound (Eq. 4), which dominates in practice?\n4. In your experiments, are there any correlations between task performance (e.g., error) and your measures?\n5. Could schematic illustrations or toy examples be added to visually illustrate the concept of holonomy in representation space?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VvaOXpOh5n", "forum": "czJqKToDGq", "replyto": "czJqKToDGq", "signatures": ["ICLR.cc/2026/Conference/Submission3762/Reviewer_n1HR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3762/Reviewer_n1HR"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3762/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761960303117, "cdate": 1761960303117, "tmdate": 1762916972784, "mdate": 1762916972784, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new representation similarity metric that complements existing metrics like CCA or CKA by taking into account how changes the input space map to changes in the representation space. In particular, the proposed representation holonomy metric is invariant to affine transformations and is zero for small loops in the input space. The estimator for this quantity is shown to be numerically stable and tractable to compute for various architectures of DNNs. Experiments show that holonomy is a valid measure of geometric effects (while measuring something different than other RS metrics), relatively robust to parametric choices, and can be used to predict robustness from small probes."}, "soundness": {"value": 4}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* Holonomy captures properties of a network that aren't measured by other representation similarity metrics. In particular, this metric captures the dynamics of representations as inputs change, which may make it more relevant to studies of properties like robustness than traditional RS metrics.\n* Holonomy can be used in conjunction with existing RS metrics to allow for a significantly deeper understanding of learned representations, as shown in section 5.3.\n* Estimates of error are included with most of the experimental results.\n* The evaluation section provides strong evidence that the theoretical claims made in Section 3 are exhibited in realistic settings.\n* Practical improvements can be made using holonomy as a diagnostic, such as improving methods for early stopping.\n* Limitations are thoroughly discussed in section 6.1."}, "weaknesses": {"value": "* The theory is somewhat difficult to follow. A reader coming from the representation similarity literature might not have a background in the mathematics that are relevant to this paper. I think that defining terms more clearly and pointing readers to relevant background would be helpful. For example, gauge-invariance is never defined despite being in the title. Given the breadth of the ICLR audience, this type of knowledge cannot be assumed.\n* Similarly, the inclusion of proof sketches would be helpful for readers. What are the important mathematical techniques that are used to establish the properties of representation holonomy?"}, "questions": {"value": "* Does the number of points in the loop impact the accuracy/variance of your estimator? Why did you choose 12 points for your experiments?\n* Do the suggestions for uses of holonomy in section 6 correspond to any concrete experiments, or are these future avenues of study?\n* The caption for Figure 2 states that Layer 2 exhibits larger holonomy, but the data in the plot for Layer 1 appears to be larger in magnitude, which appears to contradict the caption. Is my understanding of the data being displayed in Figure 2 incorrect?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "W0ZFQfSIjY", "forum": "czJqKToDGq", "replyto": "czJqKToDGq", "signatures": ["ICLR.cc/2026/Conference/Submission3762/Reviewer_rL8F"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3762/Reviewer_rL8F"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3762/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986891718, "cdate": 1761986891718, "tmdate": 1762916972481, "mdate": 1762916972481, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors define, implement, and test a measure of Holonomy, designed to quantify geometric distortions within network representations, in a way that current metrics do not.  The authors provide mathematical definitions, details of computation/implementation, and empirical demonstrations on a variety of datasets and models. These demonstrate that holonomy differs from other metrics in the literature, confirm expected properties (increases with stimulus loop radius) as well as less-expected properties (increases with network depth, decreases with training, and correlates with average network robustness to noise or adversarial attack), suggesting its usefulness in applications of diagnosing and improving networks."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This is an important topic.  ML networks are highly redundant in their parameterization and optimization landscapes, and it is\ncritical for the field to develop measures that can characterize fundamental properties for use in analysis/comparison/design.\n\nThe paper is built on a mathematical foundation that is rich, and perhaps not so familiar to a large portion of the NeurIPS community.  The authors have generally done a good job of defining and explaining their construction, and the community will benefit (but see below).\n\nThe authors have also done a careful job of implementing and testing their measure, providing reasonable detail, evaluation of computational cost, verification of expected properties, and demonstration of potential uses."}, "weaknesses": {"value": "The main weakness, for me, is that after several passes I am still uncertain of exactly why the properties captured by holonomy (distortion of geometry along closed-loop paths) are essential to understanding or comparing network functionality.  Specifically, under what conditions are the properties captured by holonomy, but not captured by current alignment methods (CCA, RSA) or differential analalyses (Lie derivatives, or simply comparison of local Jacobians), essential for evaluating or improving a network?  When is loop composition/path-dependency important (as opposed to simpler tests of invariance or equivariance)?  Perhaps the authors could provide more examples of applications/tasks where this arises?\n\nAnother weakness: Given that derivation and computation are complex and involve many approximate steps, it would be really useful to verify the entire enterprise on a few simple examples for which ground truth is known.  For example, image translation loops represented in a purely convolutional (and thus translation-equivariant) architecture, vs. a representation with known aliasing artifacts (e.g., subsampling in the inner layers).  This could prove interesting also in evaluating boundary-handling artifacts (the other source of non-translation-invariance in CNNs), which are expected to worsen in later layers.  I do see in the Discussion that the authors specify \"beyond-local-loops\" as a future direction, so my example woud need to be computed with very small displacements, perhaps to the point of rendering it unconvincing."}, "questions": {"value": "In Figures 1/2, why does measured holonomy not tend to zero as r goes to zero? Also, can the authors rule out the possibility that the increase of holonomy with loop radius is a result of increased numerical error?  Does the trend persist if the number of loop samples is adjusted in proportion to loop radius r?\n\nHave you measured holonomy of a score network used for diffusion generative modeling?  Some literature suggests that  generalization and equivariance to geometric distortions are more robust than for recognition networks (eg, Kadkhodaie et al 2024).  But they are also typically not curl-free (even though an optimal denoiser should be, since it computes a score), and this failure would presumably be exposed by the holonomy measure."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Lkg3pGUOuI", "forum": "czJqKToDGq", "replyto": "czJqKToDGq", "signatures": ["ICLR.cc/2026/Conference/Submission3762/Reviewer_Jj9N"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3762/Reviewer_Jj9N"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3762/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762023997435, "cdate": 1762023997435, "tmdate": 1762916972290, "mdate": 1762916972290, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}