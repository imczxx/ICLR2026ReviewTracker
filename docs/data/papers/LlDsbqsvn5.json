{"id": "LlDsbqsvn5", "number": 4238, "cdate": 1757644967750, "mdate": 1759898044286, "content": {"title": "RedNote-Vibe: A Dataset for Capturing Temporal Dynamics of AI-Generated Text in Social Media", "abstract": "The proliferation of Large Language Models (LLMs) has led to widespread AI-Generated Text (AIGT) on social media platforms, creating new challenges for content authenticity. The identification of AIGT on social media platforms presents unique challenges due to engagement-driven content and temporal dynamics. To bridge this gap, we introduce a novel RedNote-Vibe dataset, collected from RedNote (Xiaohongshu), one of the most influential Chinese social media platforms. This dataset contains user posts and their parallel AIGT variants generated using diverse LLMs, spanning from before ChatGPT's release to the present. We further propose a detection method based on psycholinguistic principles, namely PsychoLinguistic AIGT Detection Framework (PLAD), which achieves SOTA performance compared to recent model-based methods and provides superior interpretability. Our analysis also reveals temporal trends of AI content adoption and engagement pattern differences between human and AI-generated content.", "tldr": "We provide the first longitudinal (5-years) dataset from RedNote platform for social media AIGT research.", "keywords": ["AI-Generated Text", "Social Media", "User Engagement", "RedNote(Xiaohongshu)", "Psycholinguistics"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/afa83e674f0bc033a7f619d7a50a9941bc0709b7.pdf", "supplementary_material": "/attachment/d3b0762d752213f679dae8f4c91381cefb23826e.zip"}, "replies": [{"content": {"summary": {"value": "This paper looks at how to spot AI-generated text in dynamic social media environments. It introduces the PsychoLinguistic AIGT Detection Framework (PLAD) — an interpretable method that uses psycholinguistic features. Not only does it deliver strong performance using model-based techniques, but it also gives clear insights into the style fingerprints of different LLMs and shows how AI-generated text connects to user engagement. By digging deep into the dataset, the study uncovers trends in AI adoption over time and highlights differences in engagement patterns between human-written and AI-generated content."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This work focuses on the social media domain, capturing a large-scale real-world dataset from RedNote and constructing a parallel version with AI-generated content. The dataset is intentionally designed to support research on AI-generated discourse (AIGD).\n    \n2. From an interpretable perspective, the study develops a framework based on psycholinguistic features, which is used for training and predicting with AI content detectors."}, "weaknesses": {"value": "1. The paper lacks sufficient details about the dataset construction process.\n    \n\n   - Line 078: Please clarify the source and location of RedNote’s official user behavior report.\n    \n   - Line 084: What are the filtering criteria? Is the metadata from raw crawled data, or is it already processed after filtering?\n    \n   - Please provide a clear description of the language distribution of the dataset.\n    \n   - Regarding the parallel AI-generated posts: they appear to be rewrites rather than entirely original creations, as the original content is supplied and then rewritten based on prompts. If so, please explain the rationale and methodology behind this process.\n    \n   - Line 117: What are the “6 providers”? Are they specific companies? Please elaborate.\n    \n\n2. As the core contribution of the paper, the description of the psycholinguistic features is overly superficial.\n\n   - In Section 3, the “four dimensions of human language expression” are only defined in terms of what aspect they measure, without listing the 31 linguistic features in detail or explaining how each feature is extracted.\n    \n   - The appendix only shows six representative features for illustration, with comparative results, making it hard to understand the implementation and reproduction process.\n    \n   - Please describe the feature extraction methodology clearly, especially for different languages — are the extraction methods identical across languages? The paper does not address this point.\n    \n\n3. Concerns About Experimental Reliability\n\n   - Some average sequence lengths exceed 512 tokens, yet several PLM-based models used in the paper have a maximum input length of 512. Was the input simply truncated? If so, please clarify. Considering alternatives like Longformer could be beneficial [1][2].\n    \n   - Previous works [1] found that using a small set of features as model input did not surpass PLM-based methods in accuracy. This paper uses 31 features, which sounds promising, but the importance and justification of this choice are not clearly discussed.\n    \n   - The paper does not provide enough details on dataset splits (training/validation/test).\n    \n   - Prior studies have reported PLM-based methods reaching >98% accuracy [1][2]; however, the paper’s reported accuracy is below 90%, raising questions about the credibility of the results.\n    \n   - For Subsection 4.2 regarding zero-shot experiments, prior works [1][2][3] suggest that PLM-based models are not as weak in cross-source detection as the reported results here. This discrepancy needs explanation.\n    \n\n4. Although the **Ethics Statement** briefly mentions masking personally identifiable information, the dataset construction section does not explain how privacy protection was implemented. A more comprehensive description is necessary.\n\n5. While the paper claims to focus on AI detection in dynamic data, the dataset itself is static. The time-related analysis is only performed through the “Exploration Set.” This is similar in spirit to [3], except the domain of data differs.\n\n6. Some models used (e.g., Claude, Gemini) are not commonly used in the Chinese internet context. This could introduce bias in the training data. Using such models to train and then evaluate predictions on real-world data may weaken the validity of conclusions.\n\n[1] Beyond Binary: Towards Fine-Grained LLM-Generated Text Detection via Role Recognition and Involvement Measurement\n\n[2] MAGE: Machine-generated Text Detection in the Wild\n\n[3] Large language models penetration in scholarly writing and peer review"}, "questions": {"value": "See weakness.\n\n015：Xiaohongshu? maybe rednote?"}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety"]}, "details_of_ethics_concerns": {"value": "Although the **Ethics Statement** briefly mentions masking personally identifiable information, the dataset construction section does not explain how privacy protection was implemented. A more comprehensive description is necessary."}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "UKztVwR283", "forum": "LlDsbqsvn5", "replyto": "LlDsbqsvn5", "signatures": ["ICLR.cc/2026/Conference/Submission4238/Reviewer_t6i2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4238/Reviewer_t6i2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4238/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761904682175, "cdate": 1761904682175, "tmdate": 1762917249002, "mdate": 1762917249002, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a real AIGT dataset from social media spanning 5 years and develops an AIGT detector based on psycholinguistic features."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. A 5-year AIGT dataset with a large amount of real data is released, and some analysis of the dataset is provided.\n2. PLAD demonstrates superior detection performance."}, "weaknesses": {"value": "1. I believe temporal analysis of the data is a very important contribution. Unfortunately, in Section 5.1, the authors only analyze frequency. Several important analyses are missing: How has AIGT data changed over the 5 years? How has the detection difficulty evolved?\n2. The authors lack some basic statistical information about the dataset. For example, what is the yearly frequency distribution of the data?\n3. An important issue concerns data bias. The authors only state that “We adopt a web crawler to collect 120,000 notes from January 2020 to July 2025,” but provide no measures to ensure the data is unbiased.\n4. The authors construct data through customized LLM simulations. However, a more important issue is how to obtain genuinely published AIGT data from social media.\n5. The data construction seems inconsistent with their claimed 5-year span. In line 118, they actually use only data before November 2022 (the pre-LLM period)."}, "questions": {"value": "I suggest the authors to include some specific data examples in the paper."}, "flag_for_ethics_review": {"value": ["Yes, Legal compliance (e.g., GDPR, copyright, terms of use, web crawling policies)"]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JErpnzOeSO", "forum": "LlDsbqsvn5", "replyto": "LlDsbqsvn5", "signatures": ["ICLR.cc/2026/Conference/Submission4238/Reviewer_kgFj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4238/Reviewer_kgFj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4238/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931937628, "cdate": 1761931937628, "tmdate": 1762917248686, "mdate": 1762917248686, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce RedNote-Vibe, a 5-year social-media dataset from Xiaohongshu (RedNote) with post text plus rich engagement metadata (likes, comments, collections) spanning pre-LLM to July 2025, expressly to study temporal dynamics of AI-generated text (AIGT) in the wild. They also propose PLAD -- a psycholinguistics-based, interpretable detector for AIGT."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. Presentation: It was very easy to read and follow. I appreciate the authors' effort for their clear presentation.\n2. Longitudinal, engagement-aware dataset: I like the way the authors combined pre-LLM and post-LLM contents, and framed its usability for AI-content detection and analysis.\n3. Interpretable detector (PLAD): The paper proposes a psycholinguistics-based, feature-driven approach aimed at interpretability rather than a purely black-box classifier."}, "weaknesses": {"value": "1. Some subsections need more explanation/details. For example, the 'Data Collection' subsection should be clearer, the 'Feature Extraction and Classification' subsection should add more details, the 'Experiment Setup' subsection should mention how the other baselines were implemented/tweaked for specific identification, etc.\n\n2. For the zero-shot experiment, I would recommend adding more detectors as baselines; only BERT-base is not enough.\n\n3. For the 'Analysis' section, authors should explicitly mention how they are identifying the AI-text and AI-augmented authors. It's not clear from the paper in its current state.\n\n4. There are prior works that covered AI-text in social media, such as [1], Reddit posts in [2], etc. The author needs to clarify how their dataset differs from these existing datasets and why PLAD adds more value to the community. \n\n4. There are some related works that might be worth mentioning, such as [3,4] for AI-augmented users, etc.\n\nReferences:\n\n[1] Are We in the AI-Generated Text World Already? Quantifying and Monitoring AIGT on Social Media\n\n[2] RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors\n\n[3] Almost AI, Almost Human: The challenge of detecting AI-polished writing\n\n[4] LLM-as-a-coauthor: The challenges of detecting LLM-human mixcase"}, "questions": {"value": "1. I did not understand some of the parts in the 'Data Collection' subsection, e.g., *\"We first extract the example tags provided in the report for each category, then expand them to approximately 50 representative tags per topic through manual curation.\"*, etc. Can you elaborate it? \n2. How were the statistics-based and model-based methods adopted for the model- and provider- identification task?\n3. Is there any specific reason to include only the BERT-base model for zero-shot comparison?\n4. For the 'Analysis' section, how are you deciding/filtering the AI-texts?\n5. For the subsection 'Author-Level AI Usage and Engagement', how did you identify the AI-augmented authors?"}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety"]}, "details_of_ethics_concerns": {"value": "Need to evaluate if the web-crawled dataset contains any personally identifiable information."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Rjl8biykPn", "forum": "LlDsbqsvn5", "replyto": "LlDsbqsvn5", "signatures": ["ICLR.cc/2026/Conference/Submission4238/Reviewer_MZRp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4238/Reviewer_MZRp"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4238/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761937994872, "cdate": 1761937994872, "tmdate": 1762917248349, "mdate": 1762917248349, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "RedNote-Vibe - the first longitudinal AIGT dataset."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The real novelty is Chinese Xiaohongshu with engagement and a 5-year span."}, "weaknesses": {"value": "Please check the questions."}, "questions": {"value": "Can you compare with the closest time-aware datasets? Like SAID and MultiSocial, which can do longitudinal analysis too. Only designed to longitudinal analysis is not a good novelty.\n\nPsycholinguistic feature scores partly produced by a proxy LLM will decrease the interpretability.\n\nPlease add a human audit with inter-rater agreement, and quantify the bot risk.\n\nPlease release the exact prompts and compare with a control where the prompts vary widely.\n\nPlease add strong Chinese baselines trained under identical budgets.\n\nUnlabeled the “exploration set”, then using PLAD to analyze. It is circular."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8M0Hjvl4Ge", "forum": "LlDsbqsvn5", "replyto": "LlDsbqsvn5", "signatures": ["ICLR.cc/2026/Conference/Submission4238/Reviewer_dnne"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4238/Reviewer_dnne"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4238/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761967429840, "cdate": 1761967429840, "tmdate": 1762917248041, "mdate": 1762917248041, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}