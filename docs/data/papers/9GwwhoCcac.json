{"id": "9GwwhoCcac", "number": 5397, "cdate": 1757907145605, "mdate": 1763115417172, "content": {"title": "A Little Selection Goes A Long Way! Parameter Efficient Domain Adaptive Object Detection via Noise-Guided Layer Selection", "abstract": "Domain Adaptive Object Detection (DAOD) aims to adapt a detector trained on a labeled source domain so that it generalizes well to a target domain with a different data distribution. Existing DAOD methods often fine-tune the entire source model on the target domain, which leads to parameter inefficiency and limits practical deployment on edge devices. In this paper, we demonstrate that fine-tuning only a subset of layers within the backbone can achieve comparable or even better performance. We propose \\textbf{N}oise-\\textbf{G}uided \\textbf{L}ayer \\textbf{S}election, \\textbf{NGLS}, a method to identify backbone layers that best support learning domain-invariant representations. NGLS perturbs an auxiliary dataset with Gaussian noise, measures the cosine similarity of features across layers, and selects those layers whose similarity over the threshold. To demonstrate the effectiveness of our method, we integrate NGLS into two distinct DAOD tasks, Source-Free Object Detection (SFOD) and Unsupervised Domain Adaptive Object Detection (UDAOD). To further validate the generality of our method, we evaluate NGLS with two widely used detectors, Faster R-CNN (FRCNN) and Deformable DETR (DeDETR). The experimental results demonstrate that our method significantly reduces the number of required trainable parameters during adaptation while maintaining comparable or even surpassing performance compared to baseline methods. Specifically, in the Cityscapes to Foggy Cityscapes adaptation, we improve the performance of a DeDETR-based SFOD method by 0.8\\% mAP while reducing 98\\% of the model’s trainable parameters, and we improve the performance of an FRCNN-based SFOD method by 2.1\\% mAP while reducing 93\\% of the trainable parameters.", "tldr": "", "keywords": ["domain adaptation", "object detection"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/410dc0cfd3b1940cff7dea00834f8dd4cdb729d8.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses the parameter inefficiency issue of existing Domain Adaptive Object Detection (DAOD) methods, which typically require fine-tuning the entire source model on the target domain, thereby limiting deployment on edge devices. The authors propose Noise-Guided Layer Selection (NGLS), a plug-and-play method that identifies backbone layers critical for learning domain-invariant representations by perturbing auxiliary data with Gaussian noise and measuring cosine similarity between clean and noisy layer outputs. NGLS is integrated into two DAOD tasks (Source-Free Object Detection (SFOD) and Unsupervised Domain Adaptive Object Detection (UDAOD)) and evaluated on two detectors (Faster R-CNN and Deformable DETR) across six domain shift scenarios. Key results include reducing trainable parameters by up to 98% while maintaining or improving performance (e.g., 2.1% mAP gain for FRCNN-based SFOD and 0.8% mAP gain for DeDETR-based SFOD in Cityscapes to Foggy Cityscapes adaptation)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. NGLS introduces a simple yet effective noise-guided layer selection strategy that addresses a critical real-world challenge (parameter inefficiency). Its plug-and-play design allows seamless integration with existing DAOD methods, enhancing usability.\n2. The paper tests NGLS across diverse domain shifts (weather, dataset scale, realism to art, synthetic to real) and multiple state-of-the-art baselines (IRG, PETS, DRU, CAT). This breadth demonstrates the method’s generality and robustness.\n3. The authors conduct thorough ablations on threshold selection, auxiliary data choice, and high vs. low similarity layers, validating the core assumptions of NGLS and providing actionable insights for parameter tuning."}, "weaknesses": {"value": "1. One major concern for this paper is the motivation of parameter-efficient model training for the SFOD problem. It feels like this paper simply borrows the philosophy of parameter-efficient fine-tuning in the large language model into SFOD. However, it is not the same case. I wonder if it is important to research parameter-efficient training for SFOD because the parameters for the detector are usually on a small scale compared with LLMs.\n2. As shown in Table 6, the proposed method reduces the number of updated parameters, but the GPU memory only reduces by around 20%.\n3. There are many ways to add perturbations for the feature; the authors need to compare different implementation ways, such as dropout."}, "questions": {"value": "1.  In Table 9, the Selection Criterion is very weird and arbitrary. For example, IRG high similarity is defined as above 0.9998, while that of PETS is above 0.99. Why is there a difference between different methods to choose the threshold,d, and how to choose the threshold?\n2. This paper lacks an ablation study to explore different strategies of layer selection, such as a random selection baseline."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "fkLqmZXJxd", "forum": "9GwwhoCcac", "replyto": "9GwwhoCcac", "signatures": ["ICLR.cc/2026/Conference/Submission5397/Reviewer_DzeF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5397/Reviewer_DzeF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5397/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761298113228, "cdate": 1761298113228, "tmdate": 1762918038045, "mdate": 1762918038045, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "We thank all reviewers for their time and constructive feedback. After careful consideration, we have decided to withdraw this paper."}}, "id": "OhRvDWfliQ", "forum": "9GwwhoCcac", "replyto": "9GwwhoCcac", "signatures": ["ICLR.cc/2026/Conference/Submission5397/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5397/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763115416440, "cdate": 1763115416440, "tmdate": 1763115416440, "mdate": 1763115416440, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a Noise-Guided Layer Selection (NGLS) method. It injects Gaussian noise into auxiliary data and measures inter-layer similarity to select backbone layers that contribute most to domain invariance. The approach is novel, simple, and effective, enabling parameter-efficient domain adaptive object detection. Experiments are conducted on both SFOD and UDAOD tasks. The results show that the method greatly reduces the number of trainable parameters while maintaining or even surpassing baseline performance, demonstrating strong practical value."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "－ The paper is the first to apply noise-guided layer selection to domain adaptive object detection. By combining layer similarity analysis, it introduces a lightweight and pluggable selection mechanism.\n\n－The method shows remarkable parameter efficiency, achieving a significant reduction in trainable parameters across multiple baselines. \n\n－ The approach is simple and reproducible, relying only on an auxiliary dataset (COCO) and cosine similarity, without depending on source or target domain labels."}, "weaknesses": {"value": "－ As noted in Paper 062, the proposed NGLS is inspired by the works of Meng and Zhang. However, its design appears relatively simple and seems to merge ideas from both. The authors are encouraged to conduct deeper analysis to better emphasize the novelty and include direct comparisons, especially with Zhang’s method, to demonstrate the effectiveness and unique advantages of NGLS.\n\n－The idea of identifying robust feature layers by comparing clean and noise-injected images is reasonable. However, it remains unclear whether these layers maintain or improve their robustness after target-domain optimization. The authors are encouraged to include further theoretical discussion and visualization-based analysis to clarify this mechanism.\n\n－ It is suggested to include additional experiments with randomly selected layers to verify the necessity and robustness of the NGLS strategy. \n\n－ More noise analysis is encouraged, such as examining the impact of different Gaussian parameters and various noise distributions on layer selection results.\n\n－ There are also minor spelling errors, for example, “adaptaiton” on line 108 should be corrected."}, "questions": {"value": "－ Clarify novelty and provide comparative analysis of NGLS.\n\n－  Clarify robustness of feature layers after target-domain optimization.\n\n－  More experimental analysis.\n\nFor details, please refer to the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LxtjCIfd6x", "forum": "9GwwhoCcac", "replyto": "9GwwhoCcac", "signatures": ["ICLR.cc/2026/Conference/Submission5397/Reviewer_AfsH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5397/Reviewer_AfsH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5397/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761367644566, "cdate": 1761367644566, "tmdate": 1762918037804, "mdate": 1762918037804, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the parameter efficiency issue in Domain Adaptive Object Detection (DAOD) and proposes a novel method called NGLS (Noise-Guided Layer Selection). Its core idea is to inject Gaussian noise into auxiliary data and measure the robustness of each layer in the backbone network to the noise, identifying and fine-tuning only the layers that are most critical to domain invariance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper proposes a novel plug-and-play layer selection method, NGLS, that leverages Gaussian\nnoise perturbation to identify backbone layers most robust to domain shifts.\n2. By fine-tuning only the NGLS-selected layers, our approach substantially reduces the number of parameters while achieving comparable or superior performance to full-model finetuning in both SFOD and UDAOD settings.\n3. NGLS only requires a handful of unlabeled auxiliary images for robust layer selection,\neliminating the need for source or target domain labels and supporting practical, dataefficient adaptation."}, "weaknesses": {"value": "1. Lack of in-depth discussion regarding the relationship between \"noise\" and \"domain invariance\", which is a critical issue. Why should layers that are robust to Gaussian noise necessarily be robust to domain shift?\n2. Limitation of the layer selection criterion. NGLS selects layers based solely on the output similarity of individual layers, ignoring the collaborative interactions among layers. It is possible that certain layers appear sensitive to noise when considered in isolation, but become robust to domain shift when combined with other layers. NGLS would erroneously exclude such layers.\n3. The validation of generalizability across different backbone architectures is insufficient. The experiments are primarily conducted on ResNet. It remains unclear whether the method remains effective for more modern backbones (e.g., Swin Transformer), as their layer structures and feature extraction mechanisms fundamentally differ from those of CNNs."}, "questions": {"value": "Please refer to the Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hjan0RZ3QJ", "forum": "9GwwhoCcac", "replyto": "9GwwhoCcac", "signatures": ["ICLR.cc/2026/Conference/Submission5397/Reviewer_xcWJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5397/Reviewer_xcWJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5397/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761913075393, "cdate": 1761913075393, "tmdate": 1762918037605, "mdate": 1762918037605, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a method to identify layers that are invariant to perturbations in their input, which are then adapted to previously unseen domains by domain-adaptive object detection methods. Invariance is assessed on an auxiliary dataset by perturbing inputs to each layer with gaussian noise and measuring cosine similarity to the unperturbed features. By keeping non-invariant layers frozen, the number of trainable layers and GPU memory usage is reduced, while largely keeping performance on the target domain intact, compared to full adaptation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The proposed method is largely complementary to existing DAOD methods. The method for finding invariant layers is simple but effective. The experiments and ablations are thorough."}, "weaknesses": {"value": "I have two primary concerns. First, I think the need for reducing the number of trainable parameters could be more strongly motivated. I can see a hypothetical need for real-world edge device deployments, but how much of a bottleneck  the number of trainable parameters would be in that case is unclear to me. Second, I feel like the paper does not intuitively motivate and discuss its main contribution very well. The process described in the paper “select[s] layers that maintain high similarity for adaptation.”. Intuitively, those are the layers most invariant to domain shift, and as such should see the _least_ need to be fine-tuned, compared with layers that are not invariant under domain shift."}, "questions": {"value": "* Why does it make sense to inject noise before each layer? Why not just inject noise / perform some other type of augmentation on the input images?  \n* Intuitively, why is there need to tune the invariant layers, which should need little to no adaptation? Table 9 shows experimental evidence, but misses an intuitive explanation for this unexpected phenomenon."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WCyNFwIx04", "forum": "9GwwhoCcac", "replyto": "9GwwhoCcac", "signatures": ["ICLR.cc/2026/Conference/Submission5397/Reviewer_X8kH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5397/Reviewer_X8kH"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5397/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984079700, "cdate": 1761984079700, "tmdate": 1762918037409, "mdate": 1762918037409, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Noise-Guided Layer Selection (NGLS), a plug-and-play method for parameter-efficient domain adaptive object detection. Instead of fine-tuning all model parameters, NGLS selectively fine-tunes only backbone layers that are most robust to domain shifts. It identifies these layers by injecting Gaussian noise into an auxiliary dataset and measuring layer-wise cosine similarity between clean and noisy features."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is easy to follow and clearly written, with well-structured explanations that make the methodology understandable.\n2. The proposed approach is conceptually simple and methodologically concise.\n3. The algorithm is designed in a plug-and-play manner, demonstrating strong generalizability and potential for seamless integration into various DA frameworks."}, "weaknesses": {"value": "1. I have some concerns, that is the using auxiliary datasets to identify layers whose outputs remain similar under Gaussian noise perturbation does not necessarily indicate that these layers have learned domain-invariant representations. Rather, it only shows that these layers are robust to the injected Gaussian noise. However, robustness to Gaussian noise cannot be directly equated with robustness to domain shift, as the two represent fundamentally different types of distributional variations.\n2. A minor concern is that DA aims to train model parameters to extract domain-invariant representations. Intuitively, this process should involve optimizing the more domain-specific layers, since they are most sensitive to distributional differences. It is therefore somewhat counter-intuitive that the authors choose to fine-tune layers that are less affected by perturbations. The paper would benefit from a clearer justification explaining why adapting the more stable layers leads to better cross-domain generalization."}, "questions": {"value": "1. While the paper reports a substantial reduction in the number of trainable parameters, the improvement in GPU memory usage is relatively modest (only around 20%). Given that most DAOD and SFOD methods are not highly memory-intensive to begin with, it would be helpful if the authors could provide a detailed analysis of training efficiency in terms of time or computational cost, possibly with a comparison table.\n2. In the ablation study, an experiment where layers are randomly sampled for fine-tuning may be included, to compare against the proposed noise-guided selection. Additionally, when comparing low-similarity and high-similarity layers, the number of trainable parameters should be kept consistent, rather than determined by manually set thresholds."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MYqOE8Hs9g", "forum": "9GwwhoCcac", "replyto": "9GwwhoCcac", "signatures": ["ICLR.cc/2026/Conference/Submission5397/Reviewer_fF8Z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5397/Reviewer_fF8Z"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission5397/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762101464439, "cdate": 1762101464439, "tmdate": 1762918037193, "mdate": 1762918037193, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}