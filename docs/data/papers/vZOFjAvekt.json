{"id": "vZOFjAvekt", "number": 19311, "cdate": 1758295322920, "mdate": 1759897046278, "content": {"title": "Test-time Generalization for Physics through Neural Operator Splitting", "abstract": "Neural operators have shown promise in learning solution maps of partial differential equations (PDEs), but they often struggle to generalize when test inputs lie outside the training distribution, such as novel initial conditions, unseen PDE coefficients or unseen physics. Prior works addresse this limitation with large scale multi physics pretraining followed by fine tuning, but this still requires examples from the new dynamics, falling short of true zero shot generalization. In this work, we propose a method to enhance generalization at test-time, i.e, without modifying pretrained weights. Building on DISCO, which provides a dictionary of neural operators trained across different dynamics, we introduce a neural operator splitting strategy that, at test time, searches over compositions of training operators to approximate unseen dynamics. On challenging out-of-distribution tasks including parameter extrapolation and novel combinations of physics phenomena, our approach achieves state-of-the-art zero shot generalization results, while being able to recover the underlying PDE parameters. These results underscore test-time computation as a key avenue for building flexible, compositional, and generalizable neural operators.", "tldr": "We introduce a test-time generalization framework that enables to approximate unseen dynamics as compositions of pretrained neural operators, improving zero-shot generalization without updating parameters.", "keywords": ["Neural operators", "Zero shot generalization", "Test time adaptation", "Partial differential equations (PDEs)"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/05d6f52e5f19978fc582f4acf0d2bb06e9fb4efd.pdf", "supplementary_material": "/attachment/ad490588ab781e88a7936d6352e05e6260c1bb64.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents a test-time adaptation approach for neural surrogate models to improve the out-of-distribution (OOD) performance. The authors combine pretrained operators and a beam search method, and a test-time scaling law is provided. There are two OOD scenarios considered in this paper, i.e., parameter extrapolation and operator composition. Several numerical experiments have shown the superiority of the proposed test-time computation framework compared to baseline models. \n\nContributions:\n\n- The authors are tackling the critical OOD problem in scientific machine learning. \n\n- The test-time adaptation in scientific machine learning is new."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The test-time generalization in scientific ML is under-explored. This paper investigates a critical topic.\n\n- This paper is well-written. The motivation and formulation of test-time scaling are well presented."}, "weaknesses": {"value": "This is a good topic, but I have a few concerns regarding the experiments part. \n\n- First, I think the OOD scenarios can be broader. Apart from the parameter extrapolation and operator composition, the authors might also consider unseen initial conditionals, boundary conditions, geometries, etc. Please refer to the unisolver paper [1]. \n\n- Second, it would be good to have a more explicit discussion of computational overhead. On Page 2, the authors also claimed that “This test-time strategy comes at a higher computational cost, but enables to better adapt when faced with unseen dynamics.” It is good to see the performance improvement in the paper, but it would also be useful to see how much extra computation this actually requires. I think including some numbers or plots on runtime or resource use would give readers a better sense of the tradeoff between performance and efficiency. \n\n- Third, the tested PDEs can be broader. The Navier-Stokes equations seem to be one of the standard benchmark datasets that people will test. The authors might also consider testing on more diverse PDEs. \n\n---\n\n**Refs:**\n\n[1] Zhou, Hang, et al. \"Unisolver: PDE-Conditional Transformers Towards Universal Neural PDE Solvers.\" Forty-second International Conference on Machine Learning."}, "questions": {"value": "- Could you clarify the motivation for using LoRA? How large is your model? If it is relatively small, why was full model fine-tuning not considered as an alternative?\n\n- How does this method scale to 3D PDEs?\n\n- In the Abstract, it is better to cite the DISCO paper there to avoid confusion.  \n\n- On Page 9, line 440, there is a citation issue for Figure ??."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bQWy9dSApQ", "forum": "vZOFjAvekt", "replyto": "vZOFjAvekt", "signatures": ["ICLR.cc/2026/Conference/Submission19311/Reviewer_2BLA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19311/Reviewer_2BLA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19311/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761797622378, "cdate": 1761797622378, "tmdate": 1762931258431, "mdate": 1762931258431, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a test-time adaptation strategy for neural PDE surrogates that enables zero-shot generalization to out-of-distribution dynamics. The method builds on DISCO, extracting a dictionary of neural operators from training trajectories, then uses beam search with operator splitting at test time to compose these operators and approximate unseen dynamics. The approach is evaluated on parameter extrapolation and physics composition tasks across three benchmarks. Results demonstrate significant improvements over baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The core idea of combining a learned dictionary of neural operators with classical operator splitting at test time is, to my knowledge, highly novel. This is a well-motivated approach of bringing forth test-time computation to the realm of PDE surrogate modeling, drawing clever parallels to LLM inference techniques (beam search, best-of-N sampling).\n- A valuable feature of this formulation is the interpretability aspect. By analyzing the selected operator combinations, we can perform zero-shot parameter estimation.\n- The benchmarks performed demonstrate strong performance achieving order of magnitude improvements over the baselines considered."}, "weaknesses": {"value": "- While operator splitting has theoretical foundations for classical numerical methods, there's no analysis of when/why it works for learned neural operators. What's the role of the approximation error of the individual operators? Have you tried to study the convergence behavior of these splitting schemes (Lie or Strang)? How does the approximation error of the individual neural operators interact with the splitting error of the numerical scheme?\n- While computational complexity is stated, actual runtime comparisons with baselines are absent. How does test-time compute compare to simply fine-tuning?\n-  Training only on single-operator dynamics seems like a constraint. How would the method perform if training included some operator combinations? Additionally, it seems like the framework is restricted to purely additive composition. Can the method ever isolate a pure diffusion operator if its dictionary only contained reaction-diffusion and reaction operators?"}, "questions": {"value": "Please address weaknesses. Additionally:\n- While the method is impressive with the reaction-diffusion case that's demonstrated, can you possibly extend this to other cases? I'd like to see this being extended to other problems of interest. If the model were trained on a dictionary containing operators for the Euler equations (inviscid flow) and a separate set of operators for viscous diffusion, could the test-time search successfully discover this composition to approximate solutions to the full Navier-Stokes equations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xjy1DPgUHa", "forum": "vZOFjAvekt", "replyto": "vZOFjAvekt", "signatures": ["ICLR.cc/2026/Conference/Submission19311/Reviewer_T1WF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19311/Reviewer_T1WF"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19311/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761881990130, "cdate": 1761881990130, "tmdate": 1762931257870, "mdate": 1762931257870, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents an approach for Physics based on test time splitting. The primary idea is to create a library of neural operators using NODE and then combine them during test time."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The problem that the paper is trying to solve is relevant and timely, and will have a significant impact. The paper is general is well written."}, "weaknesses": {"value": "Despite the fact that the problem statement is extremely relevant, there are several problems as highlighted below:\n(a) The literature review is incomplete. There are works that has previously attempted to solve this problem. For example, ICON (https://www.pnas.org/doi/10.1073/pnas.2310142120), NCWNO (https://www.sciencedirect.com/science/article/pii/S0010465525003844). In fact the idea of combining previously learned solution is something NCWNO has explored previously (although the strategy of combining is slightly different). There also exists Poseidon, which is also in the same space.\n(b) As the literature review is incomplete, so is the benchmarking in results section.\n(c) The example selected are too simple. Solving such simple problem is not convincing.\n(d) The fact that the final operator is a lienar combination of two operators (from dictionary) is somewhat limiting in my opinion."}, "questions": {"value": "a) Why the final operator was considered to be a linear combination of learned operator?\nb) In scientific computing, the objective is to predict given the boundary condition and initial condition. While I acknowledge that many previous work has considered time step data as input, this is not that useful as those data will not be available unless a numerical simulator is used. Will the proposed approach work in case we only give initial and boundary condition as input during testing. It seems to me it wont as forming the loss for selecting (through Beam search) the operators from the dictionary will not be possible in such cases."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "D5wGdDRGHY", "forum": "vZOFjAvekt", "replyto": "vZOFjAvekt", "signatures": ["ICLR.cc/2026/Conference/Submission19311/Reviewer_jMxQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19311/Reviewer_jMxQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19311/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761961267871, "cdate": 1761961267871, "tmdate": 1762931257387, "mdate": 1762931257387, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}