{"id": "xuxIViH3Gy", "number": 23834, "cdate": 1758349111442, "mdate": 1759896794787, "content": {"title": "Robust GNN Watermarking via Implicit Perception of Topological Invariants", "abstract": "Graph Neural Networks (GNNs) are valuable intellectual property, yet most watermarks use backdoor triggers that break under common model edits and create ownership ambiguity. To tackle this challenge, we present InvGNN-WM, which ties ownership to a model’s implicit perception of a graph invariant, enabling trigger-free, black-box verification with negligible task impact. A lightweight head predicts normalized algebraic connectivity in an owner-private carrier set; a sign-sensitive decoder outputs bits, and a calibrated threshold $\\tau(\\alpha)$ controls the false-positive rate. Across diverse node and graph classification datasets and backbones, InvGNN-WM matches clean accuracy while yielding higher watermark accuracy than trigger- and explanation-based baselines. It remains strong under unstructured pruning, fine-tuning, and post-training quantization; plain knowledge distillation (KD) weakens the mark, while KD with a watermark loss (KD+WM) restores it. We provide guarantees for imperceptibility and robustness, and prove that exact removal is NP-complete.", "tldr": "", "keywords": ["Graph neural networks", "Model watermarking", "Ownership verification", "Topological invariants"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/271ba3846c782fb5946148cbfd61e99b911cf64a.pdf", "supplementary_material": "/attachment/c7f68b0c369b8b2a54317f78f8b1735bf17658be.zip"}, "replies": [{"content": {"summary": {"value": "The paper presents a black-box watermarking scheme for graph neural networks. The watermark is evaluated through predicting the algebraic connectivity on a particular carrier-set of graphs using a perception module. The watermark is embedded through an additional loss term during training. Theoretical arguments are provided for why the watermark is imperceptible, robust, unique, and unremovable under certain assumptions."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "* The idea to predict a graph invariant for watermarking is interesting. \n* Theoretic arguments underpin the watermarks' properties.\n* Experiments are exhaustive, comparing many datasets and backbone GNNs. Furthermore, ablations are provided.\n* Detailed code attached for reproducability."}, "weaknesses": {"value": "i) My main concern for this paper is its presentation, which has multiple issues affecting the general understanding of the paper:\n\n  1.  I do not see how Equation (3) or (4) have anything to do with duality, thus calling this a dual-objective is misleading.\n 2.  Critical definitions / references to the appendix missing: A local Polyak-Lojasiewicz condition is critical to the theory of the paper. But the text does not provide information on what a \"Polyak-Łojasiewicz\"-condition (or locality in this context) is or how it looks mathematically (neither in the preliminaries, nor in Section 5). I discovered the definition \"by accident\" in Appendix C - A.1, which was never referenced).\n  3. Line 226 talks about a stationary point. A stationary point of what?\n  4. A proof sketch for Theorem 5.1 is provided, but not a full proof. I discovered the proof by accident in Appendix C, which was not referenced. Where are the full proofs for Theorems 5.2 & 5.3?\n  5.  $\\theta$ is ambiguous. It is first introduced as the parameters of a GNN and later introduced as the parameters of the scalar perception head, which I understood as different to the general GNN. However, it is unclear to what it refers in Theorem 5.1. To me, it does not makes sense to train the scalar perception head on the general task loss, as this requires a classification output and line 129 explicitly notes that a scalar perception head is only used to predict the normalized invariant from the graph embedding? (Which also contradicts however, the definition of the scalar perception head that is defined as a function from the graph to [0,1], and not from a graph embedding.) \n  6. The downstream task setting for the GNN is not specified. Is it graph classification? Node classification? Both?\n  7. The experimental setup (Section 6.1) is not written as full sentences but rather as notes, making it hard to follow and gives the manuscript a reader-feeling of an early draft stage. What should just \"Node:\" or \"Graph:\" imply? Be explicit. The experimental results in Section 6.2 have the same issue (e.g., one finds notes such as \"Full constants and per-setting gaps: Appendix G.4 (Table 6).\"\n 8. It is not clear how to read Figures 1a & b. It is not explained what Task ACC and WM ACC are (due to the issues with Section 6.1). Do you mean test accuracies? Then, is task ACC the baseline accuracy and WM ACC the accuracy of a model with the WM, or are both referring to the WM model but its prediction acc. is reported separately w.r.t. the downstream task and the carrier sets - but then, what is the baseline, there is no label for it? From the usage in the experiment section, it at some point becomes clear that the same model is meant, but this should be explicit in the text.\n9.  Section 6.2 (C) is not referencing any result tables or figures. Also, what should \"21~33\" denote?\n\n  10. Introduction reads unconnected. The first paragraph highlights how trigger-based watermarks fail to achieve good watermarking performance (i.e., watermark preservation/robustness). However, the followed research question talks about the utility of the model, which I understood as downstream performance, not watermark-robustness, which are two different goals. \n\nii) It is not mentioned how to ensure Assumption 3.2 about the correlation in the carrier graphs, critical for Thm. 5.2 & 5.3.\n\niii) Task (training) loss and model performance are not necessarily connected. Thus, it is not clear if Thm 5.1 indeed ensures imperceptability as claimed."}, "questions": {"value": "1. Why choose the algebraic connectivity and not another graph invariant?\n2. I don't understand how Assumption 3.1 (that the support of the carrier graph set and task data is disjoint) should be enforced in practice. If I publish my model, I do not have control over D_task anymore.\n3. Why would one choose the 5th and 95th percentiles to normalize lambda_2 instead of just lambda_min and lambda_max? Wouldn't this lead to violating the assumption that $\\tilde{\\lambda}_2 \\in [0,1]$ as used e.g., to prove Theorem. 5.2?\n4. Given the theory on imperceptibility concerns the training losses, can you show the behavior of Thm 5.1 on the training losses?\n\nMinor:\n* Related work: Lines 91-93, provide references for the broader work mentioned.\n* Provide references for the Preliminaries 3.1 and 3.2. There are also many statements which should be backed-up with references, especially for readers not that familiar with graph spectral theory, such as \"The Laplacian spectrum captures global structure\" Line 120, or why the \"algebraic connectivity is stable and interpretable\" (Line 122)?\n* Presentation: Introduce normalized algebraic connectivity before using it in the text (e.g. Line 178)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mEzlzbsTrp", "forum": "xuxIViH3Gy", "replyto": "xuxIViH3Gy", "signatures": ["ICLR.cc/2026/Conference/Submission23834/Reviewer_NgqV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23834/Reviewer_NgqV"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23834/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760800557633, "cdate": 1760800557633, "tmdate": 1762942825022, "mdate": 1762942825022, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces InvGNN-WM, a new watermarking framework for Graph Neural Networks (GNNs). The core idea is to move away from \"backdoor trigger\" based watermarks, which can be removed by fine-tuning, and instead embed the watermark by tying it to the model's ability to perceive a fundamental graph property—a topological invariant. Specifically, the authors train the GNN with an auxiliary loss that forces it to accurately predict the normalized algebraic connectivity of a set of private \"carrier graphs.\" Ownership is verified by querying the suspect model on these carrier graphs and checking if its predictions align with the pre-computed invariant values. The paper provides theoretical guarantees for imperceptibility (minimal impact on task performance) and robustness, and proves that exact watermark removal is NP-complete. Empirically, the method is evaluated on node and graph classification tasks and is shown to maintain high watermark accuracy under model edits like pruning and quantization."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea of binding a watermark to a model's internal reasoning about a graph invariant, rather than an exogenous trigger, is a novel and interesting conceptual shift in the GNN watermarking space.\n\n2. The paper provides some theoretical analysis for imperceptibility, robustness, uniqueness, and unremovability. \n\n3. The method is tested across multiple datasets, backbones, and a variety of model edits."}, "weaknesses": {"value": "**1. Fundamentally Poor Writing and Confusing Notation**\n\nThe paper is difficult to read and hard to follow. The notation is inconsistent and often undefined in the main text (e.g., s_\\theta, \\tilde{\\lambda}_2), forcing the reader to scavenge through appendices. Key concepts are introduced without clear explanation, and the flow of ideas is frequently disrupted. This severely undermines the paper's ability to communicate its contributions effectively.\n\n**2. Lack of Extensive Comparison with Prior Work**\n\nWhile the paper lists several baseline methods (TRIG, NAT, EXPL, COS), it provides no quantitative comparison of robustness against these baselines. Table 2 only compares clean task and watermark accuracy. The claim of superior robustness is primarily supported by a single, qualitative figure (Fig. 2) without corresponding numerical results in the main text. A reader cannot determine if the proposed method is genuinely more robust than existing techniques.\n\n**3. No Direct Attacks on the Watermarking Method** \n\nThe paper only evaluates robustness against benign model edits (pruning, fine-tuning) and a single, non-adaptive attack (KD). It does not test against any adaptive, white-box attacks where an adversary knows the watermarking scheme and actively tries to remove it. For example:\n\n- Fine-tuning on a mixture of task data and carrier graphs to deliberately unlearn the invariant perception.\n\n- Training an \"invariance-spoofing\" adversarial head that predicts the correct invariant for the carrier set without being tied to the model's core parameters.\n\n- Model Extraction Attacks: Training a surrogate model on the watermarked model's outputs to see if the watermark transfers.\nThe NP-completeness result is a theoretical strength, but without testing against practical, adaptive adversaries, the empirical claims of robustness are weak.\n\n**4. Unconvincing Ablations and Justification** \n\nThe choice of algebraic connectivity (λ₂) as the invariant is not sufficiently justified against other potential invariants. The ablation in Table 4 is minimal and does not explore why λ₂ is the best choice or what happens if an adversary uses a different invariant to create an ambiguous ownership claim."}, "questions": {"value": "1. The presentation is currently a major barrier to understanding. The paper needs a significant revision (texts, notations) to make it readable.  \n\n2. The paper claims superior robustness, but this is not demonstrated quantitatively against baselines under attack.\n\n3. The current evaluation lacks any adaptive, watermark-aware attacks. The authors need to demonstrate their method's robustness against a more realistic (adaptive) adversary.\n\n4. The method relies on the secrecy of the carrier set and the chosen invariant. What prevents an adversary from claiming ownership using a different set of carrier graphs and a different, but equally plausible, graph invariant? How does InvGNN-WM mitigate the risk of such ambiguous ownership claims compared to trigger-based methods?\n\n5. The NP-completeness proof is a strong theoretical point, but it relies on a specific \"monotone decoder\" design. Could the authors discuss whether this decoder is a practical constraint or a theoretical convenience? Have they explored if the watermark remains hard to remove with a more standard, non-monotone decoder head?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RKy1gUw3Op", "forum": "xuxIViH3Gy", "replyto": "xuxIViH3Gy", "signatures": ["ICLR.cc/2026/Conference/Submission23834/Reviewer_767q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23834/Reviewer_767q"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23834/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761799060324, "cdate": 1761799060324, "tmdate": 1762942824495, "mdate": 1762942824495, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduced a framework InvGNN-WM that can embed ownership by training a GNN to perceive a topological invariant. The core of the method is a differentiable perception function that links the GNN’s parameters to a graph property."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1: The core innovation lies in coupling the ownership signature to the model’s fundamental reasoning process.\n\nS2: The conceptual leap is strongly supported by the work’s high quality, demonstrated through a powerful combination of theoretical rigor and extensive empirical validation."}, "weaknesses": {"value": "W1: A significant methodological concern lies in the scalability and generalizability of the chosen topological invariant.\n\nW2: The security model, while theoretically robust, may have practical vulnerabilities not fully addressed.\n\nW3: The paper would be more convincing if it included an adversarial analysis specifically targeting the secrecy of the carrier set, testing resilience against model inversion or membership inference attacks."}, "questions": {"value": "- The text mentions a differentiable perception function for algebraic connectivity (λ₂). Algebraic connectivity itself is not directly differentiable with respect to the graph structure or node features in a straightforward manner. What is the exact formulation of this function? Is it an approximation (e.g., via the Rayleigh quotient or power iteration), and if so, how does the approximation error impact on the stability and fidelity of the watermark?\n- The security heavily relies on an owner-private carrier set. What is the provenance and structure of this set? Is it a held-out subset of the training data, or a synthetically generated set of graphs? If synthetic, what generative process ensures these graphs are in-distribution enough to not be easily distinguishable by an adversary, yet possess the specific λ₂ properties needed for the watermark?\n- The results show that plain KD weakens the mark, but KD with a watermark loss (KD+WM) restores it. This raises critical questions: Does the KD+WM defense require the defender to have access to the original private carrier set during the distillation process? If so, this is a very strong assumption that may not be practical in a real attack scenario where the adversary is the one performing the distillation. How is the watermark loss incorporated into the student’s training objective? Is the student forced to perceive λ₂ on the same private carrier set, effectively transferring the watermark?\n- The method uses a calibrated threshold to control the false-positive rate. What is the statistical methodology for this calibration (e.g., based on a validation set of non-watermarked models)? How sensitive is the verification outcome to the exact value of this threshold?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rTQFieMCVY", "forum": "xuxIViH3Gy", "replyto": "xuxIViH3Gy", "signatures": ["ICLR.cc/2026/Conference/Submission23834/Reviewer_TAqe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23834/Reviewer_TAqe"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23834/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761849322457, "cdate": 1761849322457, "tmdate": 1762942823912, "mdate": 1762942823912, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the significant vulnerability of existing Graph Neural Network (GNN) watermarks, which often rely on backdoor triggers and are easily broken by common model edits like pruning, fine-tuning, and distillation. To solve this, the authors propose InvGNN-WM, a novel, trigger-free watermarking framework. The core idea is to move away from exogenous triggers and instead tie the GNN's ownership signature to its \"implicit perception of a graph invariant\". Specifically, the method embeds the watermark by training the GNN to perceive a topological property, which is the normalized algebraic connectivity, on a private set of \"carrier graphs\". Extensive experiments show InvGNN-WM matches the task accuracy of clean models while achieving state-of-the-art watermark accuracy. It demonstrates strong robustness to pruning, fine-tuning, and quantization, and shows that while plain knowledge distillation (KD) weakens the mark, it can be restored via KD+WM."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper's primary strength is its conceptual novelty. Shifting the watermarking paradigm from exogenous triggers to functionally-integrated invariants is a major contribution. \n- The paper is clearly and logically structured. It begins by defining the problem (fragile triggers), presents its core idea (invariant perception), details the method, provides the theoretical guarantees, and then validates all claims with targeted experiments. The writing is precise, and the figures effectively illustrate the key trade-offs."}, "weaknesses": {"value": "I have several concerns about this manucript. See below for more details."}, "questions": {"value": "- The method requires the GNN to learn to perceive $\\tilde{\\lambda}$, while simultaneously solving the main task. Did you observe a difference in the utility/watermark trade-off based on the backbone's expressiveness? For instance, did a simpler model like SGC struggle more to learn the invariant (requiring a higher $\\beta_{wm}$ that hurt task accuracy) compared to a more expressive model like GIN?\n- The robustness analysis shows that plain KD weakens the mark, but \"KD+WM\" restores it. This KD+WM modification seemingly requires the entity performing the distillation to have the owner's private carrier set $\\mathcal{G}_W$ to compute the $\\mathcal{L}$_wm. This implies the attacker has the key, which contradicts the threat model. Could you clarify the practical scenario for this experiment? Is it intended to show that the watermark is transferable via distillation if desired (e.g., by the owner), or is it meant as a defense/recovery mechanism?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "EmTCx0PRQH", "forum": "xuxIViH3Gy", "replyto": "xuxIViH3Gy", "signatures": ["ICLR.cc/2026/Conference/Submission23834/Reviewer_pvyy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23834/Reviewer_pvyy"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23834/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761917287157, "cdate": 1761917287157, "tmdate": 1762942823677, "mdate": 1762942823677, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}