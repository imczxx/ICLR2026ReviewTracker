{"id": "feOrSQdD9Y", "number": 14096, "cdate": 1758228470397, "mdate": 1759897389975, "content": {"title": "Convergence Analysis of Tsetlin Machines for Basic Boolean Operators under Noise-Free and Noisy Training Conditions", "abstract": "The Tsetlin Machine (TM) is an innovative machine learning algorithm grounded in propositional logic, achieving state-of-the-art performance in a variety of pattern recognition tasks. While previous studies have analyzed its convergence properties for the 1-bit operator under both noisy and noise-free training conditions, as well as for the XOR operator under noise-free conditions, this work extends the theoretical analysis to the AND and OR operators, thereby providing a more comprehensive analysis of fundamental Boolean operations. We show that the TM almost surely converges to correctly represent the AND and OR operators when trained on noise-free data over an infinite time horizon. Notably, our analysis of the OR operator reveals a distinct characteristic: the TM is capable of representing two sub-patterns jointly within a single clause, which contrasts with its behavior in the XOR case. Furthermore, we investigate the TM‚Äôs behavior when learning AND, OR, and XOR operators under noisy training conditions, including the presence of mislabeled samples and irrelevant input variables. In the presence of incorrect labels, the TM does not converge to the exact target operators but remains capable of learning efficiently. In contrast, when irrelevant variables are present, the TM still converges almost surely to the correct operators. Together, these results offer a comprehensive theoretical foundation for understanding the convergence behavior of TMs across basic Boolean operators.", "tldr": "", "keywords": ["Tsetlin Automata", "Propositional Logic", "Tsetlin Machine", "Convergence Analysis", "Basic Boolean Operators"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/adaafe403693c61bc21608ff73b1ee39476a20e6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "A theoretical study of the probabilistic training convergence of Tsetlin Machines for basic logical operators with and without noise."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Paper is reasonably clear although the presentation could be improved in parts. For example, a figure would shorten and clarify the setup in Section 2.   It would help to explicitly state that Tables 1 and 2 are transition probabilities to bring along readers who are not already familiar with the material."}, "weaknesses": {"value": "The paper, plus 30 pages of appendix, is a detailed treatise on the convergence of Tsetlin machines for basic logical operators.  It is impossible to estimate the validity of the theorems without a deep study of the lengthy appendix.\n\nWhile the results are of theoretical interest,  we cannot arrive at any conclusions on practical significance without experiments on real-world data sets.   In the absence of such experiments, the paper might be better suited for a refereed journal."}, "questions": {"value": "How about some experimental results on substantive real data sets? \nHow can you convince the audience that Tsetlin machines may be practical alternatives to deep neural networks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sLpGe4oeBk", "forum": "feOrSQdD9Y", "replyto": "feOrSQdD9Y", "signatures": ["ICLR.cc/2026/Conference/Submission14096/Reviewer_ThEH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14096/Reviewer_ThEH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14096/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760968561933, "cdate": 1760968561933, "tmdate": 1762924572752, "mdate": 1762924572752, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work provides detailed proofs on the convergence properties of Tsetlin Machines (TMs). Given that existing literature only discussed TMs convergence in 1-bit settings for the Identity/NOT operator and in 2-bit settings for the XOR operator only, it extends the current theoretical understanding of TMs by providing (1) a noise-free (almost surely) convergence proof for the AND operator in a 2-bit setting, (2) a noise-free (almost surely) convergence proof for the OR operator in a 2-bit setting, (3) (almost surely) convergence/recurrence analysis of AND, OR, XOR operators in a 2-bit setting with noisy data (under two random noise types: mislabeled samples and irrelevant input variables)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "S1: strong motivation is given for improving the theoretical ground of TMs properties, with a clear identification of the gap (what was already shown in the literature, and what was missing).\n\nS2: self-contained notation for setting up the TM functionalities, consistent notations used throughout proofs.\n\nS3: a complete proof provided for (1), and high level proof sketches provided for (2,3) where complex reasoning involves (proof details are presented in the appendix). Figure 2 helps the reader understand the proof structure.\n\nS4: key findings on the OR operator where it is shown to be able to learn joint sub-patterns, which is novel.\n\nS5: the convergence analysis on TM's behaviour with noisy data is particularly valuable as real-world data is more than often quite noisy."}, "weaknesses": {"value": "W1: limited scope - this work explores the 2-bit settings, however, it is missing the discussion of how this work may contribute to analysis of TMs behaviours at a larger scale (in the real deployment of TMs, it is often at a much larger scale). Or more generally, missing discussion on how the theoretical improvements relates to practical usage of TMs.\n\nW2: Section 6 seems to be weaker than section 3&4, partially due to the defer of (almost all) proof details to the appendix and only leaving the statements in the main text. The key rationales behind these findings could be partially included to enhance the strengths of these statements."}, "questions": {"value": "Q1: The definition of the hyper-parameter \"T\" does not seem to be well presented. It was not clear to the reader what type of values it takes (it was briefly mentioned in one of the proofs that T is an integer, but no formal definition for T is found in the notation section) and what is its range. It would be nice if the authors can present the definition of T better in revisions as it is heavily used in the proofs.\n\nQ2: as discussed in W1, can the authors explains a bit more on how this work influence the practical usage of TMs? Any insights that we can draw from these analysis to be applied to real world scenarios?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GAUqs8Qd51", "forum": "feOrSQdD9Y", "replyto": "feOrSQdD9Y", "signatures": ["ICLR.cc/2026/Conference/Submission14096/Reviewer_PyEi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14096/Reviewer_PyEi"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14096/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966825604, "cdate": 1761966825604, "tmdate": 1762924572318, "mdate": 1762924572318, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the convergence behavior of Tsetlin Machines (TM) on basic Boolean operators. It proves almost-sure convergence for AND and OR under noise-free data, clarifies how the resource parameter T is necessary for OR (due to recurrent dynamics without it), and revisits XOR to contrast why clauses must include both literals there. The paper then analyzes learning under two noise models, mislabeled samples (non-convergence / recurrence) and irrelevant input variables (preserving almost-sure convergence with suitable T). Experiments on synthetic setups illustrate the theorems and qualitative behaviors."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe paper has good theoretical novelty: Clear separation of behaviors for AND vs. OR vs. XOR, including why OR needs ùëá to exit recurrence, and why XOR forces inclusion of both literals (Type II feedback pressure).\n\n2.\tIt has rigorous clause/TA-state analyses leading to a unique absorbing state for AND and a family of absorbing conditions for OR. The use of absorbing-state arguments vs. stationary distributions is a neat angle."}, "weaknesses": {"value": "1.\tThe theory focuses on 1‚Äì2-bit settings. While justified as foundational, readers may want a clear roadmap for extending these techniques to higher-arity clauses and multi-bit operators beyond AND/OR/XOR, or to real datasets with structured features. (Some remarks suggest feasibility, but formal generalizations are not provided.)\n\n2.\tConvergence is asymptotic (‚Äúinfinite time‚Äù). Finite-time/sample complexity bounds or rates (even coarse) would materially strengthen the results and their practical import. The empirical section shows good convergence in practice, but theory doesn‚Äôt quantify this.\n\n3.\tExperiments are primarily synthetic and ablation-style. Comparisons to classical concept learning or bandit baselines learning conjunctions/disjunctions (more related work) would better support the empirical importance."}, "questions": {"value": "1.\tCan you provide high-level bounds (even loose) on expected time to absorption under noise-free AND/OR as a function of m,T,s,N and input distribution?\n\n2.\tWhich steps in the proofs rely critically on the 2-bit structure? Do you foresee analogous absorbing-state conditions for k-bit conjunctions/disjunctions and for multi-clause compositions? Any obstacles beyond combinatorial explosion?\n\n3.\tCan you add guidance on the qualitative effect of s (granularity) and N (TA states per action) on convergence speed/stability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "88ZMkv4AhU", "forum": "feOrSQdD9Y", "replyto": "feOrSQdD9Y", "signatures": ["ICLR.cc/2026/Conference/Submission14096/Reviewer_aVVF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14096/Reviewer_aVVF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14096/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989505483, "cdate": 1761989505483, "tmdate": 1762924571933, "mdate": 1762924571933, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}