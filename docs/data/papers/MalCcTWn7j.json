{"id": "MalCcTWn7j", "number": 1792, "cdate": 1756930658269, "mdate": 1759898186451, "content": {"title": "Bayesian-LoRA: Gaussian Process Modeling for Large Language Models", "abstract": "Pre-trained LLMs are often reasonably calibrated on pre-training like distributions, but fine-tuning them for specific domains often causes a substantial deterioration in calibration, especially on small datasets, leading to overconfident predictions. Although existing Bayesian approaches alleviate this degradation, their computational cost is prohibitive at LLM scale. In this work, we introduce Bayesian-LoRA, which applies a Sparse Gaussian Process (SGP) to the Low-Rank Adaptation (LoRA) fine-tuning approach and integrates a normalizing flow to stabilize the training process, thereby substantially improving calibration in fine-tuned LLMs. We conduct extensive experiments on the LLaMA 2-7B model across a set of commonsense reasoning benchmarks. With only approximately 0.42M additional parameters over LoRA, Bayesian-LoRA reduces the calibration error (ECE) and Negative Log-Likelihood (NLL) without sacrificing accuracy, for both in-distribution and out-of-distribution (OOD) evaluations, while retaining the LoRA’s parameter efficiency and incurring only modest extra training/memory overhead.", "tldr": "", "keywords": ["Gaussian Process", "LLM", "Uncertainty Quantification"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cdbd836a1a3dec61c72271ab3c13bb01b46106c6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes Bayesian-LoRA, integrating Sparse Gaussian Process (SGP) into LoRA with normalizing flow (adding ~0.42M params) to stabilize training . It improves LLM calibration (reduces ECE/NLL) post-fine-tuning (avoids overconfidence) while retaining LoRA’s efficiency . Experiments on LLaMA 2-7B across 6 commonsense benchmarks and WikiText-2 show it outperforms baselines in accuracy/calibration."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.The paper is well organized and well written.\n\n2.The authors present a well-motivated approach.\n\n3.It conducts numerous experiments, validates the experimental results on models of various series and sizes, and covers a wide range of evaluation tasks"}, "weaknesses": {"value": "1. In line 53, the abbreviation “MAP” should be explained when it first appears, for instance as *Maximum A Posteriori*, to help readers better understand the term.\n\n2. The paper lacks experiments on larger-scale models.\n   Evaluating the proposed method on models of different or larger scales would help demonstrate its robustness and practical applicability.\n\n3. According to Table 3, the proposed method incurs approximately 1.2× higher training cost and 1.5–2.7× higher inference cost compared to LoRA. When compared with deterministic PEFT methods such as AdaLoRA[1], DoRA[2], and PiSSA[3], the proposed approach does not seem to provide clear advantages. Since the paper does not include direct comparisons with these methods, it remains unclear whether the proposed approach has distinct limitations or strengths. The authors are encouraged to include more detailed comparisons and analysis to clarify this point.\n\n[1] AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning\n\n[2] DoRA: Weight-Decomposed Low-Rank Adaptation\n\n[3] PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models"}, "questions": {"value": "see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Lu2HL6BV1g", "forum": "MalCcTWn7j", "replyto": "MalCcTWn7j", "signatures": ["ICLR.cc/2026/Conference/Submission1792/Reviewer_Sx7d"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1792/Reviewer_Sx7d"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1792/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761653380027, "cdate": 1761653380027, "tmdate": 1762915891966, "mdate": 1762915891966, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of calibration deterioration in LLMs following PEFT, such as LoRA, especially on small datasets. The authors propose Bayesian-LoRA, a method that applies a Sparse Gaussian Process (SGP) to the LoRA update mechanism. This approach models the distribution over the low-rank update weights using a small set of inducing variables. To improve the flexibility of the variational posterior, the SGP is integrated with a normalizing flow. Experiments fine-tuning LLaMA 2-7B on several benchmarks show that Bayesian-LoRA improves calibration metrics without sacrificing accuracy. The method maintains parameter efficiency, adding only ~0.42M parameters, and incurs modest computational overhead compared to standard LoRA."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1: Fine-tuned LLMs often become miscalibrated and overconfident, especially in safety-critical use cases. Addressing this behavior has high practical relevance.\nS2: Introducing Bayesian modeling into the LoRA subspace is conceptually appealing and improves scalability, addressing limitations of parameter-space Bayesian methods.\nS3: Normalizing Flow enriches the posterior family. This avoids overly restrictive Gaussian assumptions and allows the posterior to capture multi-modal or heavy-tailed structures — a thoughtful design choice."}, "weaknesses": {"value": "W1: Method complexity and stacking of components. The proposed approach combines LoRA + SGP + Normalizing Flow. While innovative, the contributions of each component are not fully disentangled. More fine-grained ablations are needed.\nW2: The experimental evaluation is limited in scale, primarily using mid-sized models (e.g., 7B). Additional results on larger models (e.g., 13B or 70B) would strengthen the paper’s claims regarding scalability and general applicability to LLM fine-tuning.\nW3: The connection between the \"Variational Sparse Inducing Weight Model\" preliminaries (Sec. 2.2) and the final Bayesian-LoRA method (Sec. 3.1) is confusing. Section 2.2 defines the SGP as modeling the conditional mean $M_W(U)$ of the full weight matrix $W$ (Eq. (4), (6)). However, Section 3.1 and Figure 1 imply the SGP is used to model the LoRA matrices $A$ and $B$, which compose the update $\\Delta W$. This is a critical disconnect. Also, algorithm 1 deepens this confusion. It suggests that both $\\bar{A}l$ and $\\bar{B}l$ are generated from the same inducing variable sample $U^{(s)}$ using different projection matrices ($T^A$, $T^B$). This implementation detail is not derived or explained in the main text, making it unclear how $U$ is shared and why this is the correct formulation.\nW4: The rank $r$ of the baseline LoRA (MAP) model (listed at 4.48M parameters in Table 3) is not specified.\nW5: The paper needs to explicitly state: is the SGP applied to $A$ and $B$ separately, or jointly from one $U$? The current presentation, mixing preliminaries on $W$ (Sec 2.2) with an implementation on $A$ and $B$ (Alg. 1), is difficult to follow."}, "questions": {"value": "Please refer to Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N.A."}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RInLXiYJ3k", "forum": "MalCcTWn7j", "replyto": "MalCcTWn7j", "signatures": ["ICLR.cc/2026/Conference/Submission1792/Reviewer_3vY8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1792/Reviewer_3vY8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1792/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761656242226, "cdate": 1761656242226, "tmdate": 1762915891826, "mdate": 1762915891826, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Bayesian-LoRA: instead of a deterministic LoRA update, it introduces a SGP over an inducing variable (U) defined in the low-rank LoRA subspace. A Kronecker structure along row/column dimensions maps (U) to the means of (A,B)."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Probabilizing LoRA’s low-rank update via a Kronecker SGP and correcting with a small flow is clean. Compared to parameter-space Laplace/VI (LA/LLLA, BLoB), this leans toward a more “function-space-like” view, with a simple closed-form KL and a straightforward training recipe."}, "weaknesses": {"value": "To be honest, I am not familiar with the core knowledge involved in the paper. Perhaps for professionals in the field, this is an excellent paper, so I am willing to refer to other reviewers' opinions to adjust my score. The following are just some personal suggestions of mine.\n\n- Add at least one modern backbone (e.g., Llama-3-8B-Instruct) and 1–2 broader benchmarks (HellaSwag, GSM8K, or full MMLU). Report ACC/NLL/ECE and latency vs. number of samples?\n\n- Although the paper aims to move away from parameter-space approximations, the method still samples weight updates (albeit structured) rather than directly ensuring parameterization-invariant function perturbations. The “function-space advantage” needs either stronger theory (e.g., demonstrating invariance benefits under reparameterization) or targeted experiments (e.g., holding a function-distance budget constant across methods)?"}, "questions": {"value": "see weekness above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "WtStdAVETs", "forum": "MalCcTWn7j", "replyto": "MalCcTWn7j", "signatures": ["ICLR.cc/2026/Conference/Submission1792/Reviewer_pPT1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1792/Reviewer_pPT1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1792/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761881864234, "cdate": 1761881864234, "tmdate": 1762915891704, "mdate": 1762915891704, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on addressing LLM overconfident predictions, especially when LLMs are fine-tuned on small datasets or experience domain shifts. The authors propose Bayesian-LoRA, combining a sparse Gaussian Process (SGP) and normalizing flow. They fine-tune LLaMA-2-7B on commonsense reasoning tasks (e.g., WinoGrande-S, ARC-C/E, OBQA, BoolQ) and generative tasks (WikiText-2), reporting improvements in calibration metrics without sacrificing accuracy and without introducing significant additional cost."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper focus on uncertainty and calibration, which is important for safety-critical domain.\n2. The method is concepttally novel. combining a sparse Gaussian Process (SGP) and normalizing flow.\n3. The added training time and memory overhead are modest (training time ~1.2×, adding only ≈ 0.42M parameters) \n4. They reporting improvements in calibration metrics without sacrificing accuracy and without introducing significant additional cost. They also test out-of-distribution generalization (i.e., robustness when input distributions shift)"}, "weaknesses": {"value": "**1. Weakness in Method:**\n  - The reported improvements are marginal. For example, in Table 5, the reported ECE outperforms baselines on only 3 out of 6 OOD tasks and does not perform well on ID tasks.\n  - The paper recommends $S = 2-4$ to avoid cost, but does not quantify how predictive quality (ACC/NLL/ECE) degrades for small $S$ or how latency/throughput scale for larger $S$. Only a qualitative statement (`\"slight improvement with higher $S$\") is given. This makes the accuracy–latency trade-off hard to judge in practice. It also calls into question the effectiveness of the method, in general, more samples should yield more accurate uncertainty estimation.  \n  - Deeper flows ($L > 1$) give limited gains at extra cost, and the paper defaults to $L = 1$. This raises the question of when (if ever) the flow is truly beneficial compared to the base SGP.  \n  - Can this method be applied to full fine-tuning? Or to broader adapter families?\n\n**2. Weakness in Evaluation:**  \n  - Evaluation is limited to six small MCQ benchmarks (WinoGrande-S/M, ARC-C/E, OBQA, BoolQ) and WikiText-2 for language modeling. More practical and challenging tasks, e.g., instruction-following, math reasoning, and coding which also require calibration, are missing.  \n  - Experiments are restricted to LLaMA-2-7B, more models should be included.  \n  - Only ECE and NLL are reported, offering little insight. Additional metrics / case studies / visualization should be provided.  \n  - The impact of different hyperparameters (e.g., LoRA rank, learning rate, training steps) on performance and efficiency is not well studied. Calibration and accuracy may depend strongly on the low-rank dimension $r$, and on the interaction between $r$ and other hyperparameters.\n\n**3. Weakness in Writing:** \n  - The writing in the paper is confusing. The paper labels standard LoRA as \"MAP\" without explicit reason.\n  - Background on calibration is too brief for non-specialists. Readers unfamiliar with calibration may struggle to interpret the metrics and their practical meaning.  \n  - The specific role of each component, the rationale for choosing them, and how they interact are unclear. The method reads like two techniques simply stacked together."}, "questions": {"value": "See Weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "iYFTpbJPnB", "forum": "MalCcTWn7j", "replyto": "MalCcTWn7j", "signatures": ["ICLR.cc/2026/Conference/Submission1792/Reviewer_SG6J"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1792/Reviewer_SG6J"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1792/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992809175, "cdate": 1761992809175, "tmdate": 1762915891499, "mdate": 1762915891499, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}