{"id": "ZxYkPHacJT", "number": 1265, "cdate": 1756868339953, "mdate": 1759898218220, "content": {"title": "Classification vs. Deep Feature Learning in Normalized Spaces with Different Scaling", "abstract": "In supervised scenarios, deep feature learning is typically implemented through the training of classification models. However, it should be noted that classification reflects the sample-wise local properties of models on a dataset, while deep feature learning aims to learn features with good sample-independent global properties such as intra-class compactness and inter-class separability on the dataset. This paper conducts an in-depth comparison of classification and deep feature learning in normalized spaces. We first reformulate the binary cross-entropy (BCE) loss aligning with the fundamental requirements of feature learning; then, we theoretically analyze and compare its minima with that of the cross-entropy (CE) loss used for classification tasks. Informed by the above analysis, we explore the convergence behavior of the two losses when the scale factor $\\gamma$ changes, revealing the differences between classification and deep feature learning. Specifically, when $\\gamma$ increases linearly, the convergence rates of the two losses decay exponentially, resulting in poor feature properties for the trained models, although it does not affect their classification. As $\\gamma$ decreases, the losses more readily reaches their minima, which helps to improve the feature properties. However, if $\\gamma > 0$ decreases linearly and approaches zero, the convergence rate of the losses decay linearly, leading to unsatisfactory feature properties and making the models' classification highly sensitive to minor disturbances. Our experiments fully validate these conclusions. The experimental results also demonstrate the advantages of BCE over CE in more challenging scenarios such as long-tailed recognition and open-set recognition.", "tldr": "We in-depth compare the tasks of classification and deep feature learning by analyzing the minima of CE and BCE losses in normalized space.", "keywords": ["Classification", "Deep Feature Learning", "Scaling Factor", "Neural Collapse"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8c742f1772f5b731247bfe5e7aa94fac43f55ec1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper first propose a loss function for deep feature learning based on global constraints—the binary cross-entropy (BCE) loss, applied to multi-class tasks. Then the authors perform a detailed comparison between cross-entropy (CE) and BCE losses in the normalized space, showing that normalized BCE can also achieve neural collapse (NC). As a last contribution, the authors highlight the key differences between classification and deep feature learning by analyzing how the convergence rates of CE and BCE vary with the scale factor. The authors conduct experiments and show that compared to the CE loss, their proposed BCE loss achieves better results on long-tailed recognition and open-set recognition."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The main strengths of the paper can be summarized as follows:\ni) The authors propose a method that use binary cross-entropy (BCE) loss function (unfortunately the method is not novel) and provide a detailed comparison against the classical cross entropy (CE) loss. \nii) The authors analyse how the loss functions CE and BCE behaves with varying scale factor $\\gamma$.\niii) Conducted experiments show that their proposed BCE loss achieves better results on long-tailed recognition and open-set recognition compared to CE loss."}, "weaknesses": {"value": "The primary weakness of the paper lies in its lack of novelty. Both the proposed loss functions and the analyses concerning the scale factor are not new contributions. My detailed comments are as follows:\n\nThe authors conduct an extensive analysis on the scale factor. However, this concept merely represents the radius of the hypersphere on which data are distributed in methods such as ArcFace and CosFace. This same hypersphere also contains the regular simplex in deep simplex classifiers [R2, R3], all of which pursue the same objective as neural collapse. The choice of hypersphere radius has been thoroughly investigated in the literature. For instance, the CosFace paper [R1] provides a theoretical lower bound for the radius based on the number of classes and the minimum posterior probability of class centers (see Eq. 6 in their paper). In practice, larger datasets with more classes benefit from larger radius values, and this is theoretically linked to the feature dimension. ArcFace, for example, fixes the radius at 64 for datasets with thousands of identities, a value shown to work well on large-scale benchmarks. Similarly, as stated in [R2], data samples theoretically lie on the surface of an expanding hypersphere as the feature dimension increases. Thus, smaller radii may suffice for low-dimensional illustrative experiments, but larger values are required for high-dimensional cases with high-dimensional spaces. There are also experimental results with varying scale factors in [R2] . Overall, the relationship between the scale factor and hypersphere radius is already well-established, making this part of the paper non-novel.\n\nRegarding the proposed methodology, there exist closely related approaches in prior work. The proposed loss is highly similar to the Dot-Regression Loss in [R3], while [R2] presents an even simpler loss function that also induces neural collapse. Numerous other loss functions targeting neural collapse have been proposed, yet the authors neither cite nor compare against these alternatives.\n\nFinally, the proposed method has a critical limitation that restricts its applicability to large-scale datasets. When d<C−1, the class centers cannot be arranged on the vertices of a regular simplex. This condition commonly arises in modern large-scale datasets, rendering the proposed approach impractical. The authors should therefore suggest modifications or alternatives that can address such cases.\n\nIn conclusion, while the paper aligns with the broader line of research on neural collapse, its contributions are incremental. The authors fail to provide compelling justification for why their method should be preferred over many existing alternatives.\n\nMinor Issues: i) There are some typos and English Grammar mistakes that must be corrected, e.g., page 3, libe 155, ... implemented by divided with ...\nii) I did not get the part that is related to unique global minimum. In neural collapse, there are many global minimums that can be simply obtained by rotating the regular simplex.\n\n\n[R1] H. Wang, Y. W. Z. Zhou, X. Ji, D. Gong, J. Zhou, Z. Li, and W. Liu, ‘‘Cosface: Large margin cosine loss for deep face recognition,’’ in IEEE Society Conference on Computer Vision and Pattern Recognition (CVPR), 2018.\n[R2] H. Cevikalp, H. Saribas, B. Uzun, “Reaching nirvana: Maximizing the margin in both Euclidean and angular spaces for deep neural network classification,” IEEE Transaction on Neural Networks and Learning Systems, vol. 36, 2025.\n[R3] Y. Yang, S. Chen, X. Li, L. Xie, Z. Lin, and D. Tao, “Inducing neural collapse in imbalanced learning: Do we really need a learnable classifier at the end of deep neural network?” in Proc. Adv. Neural Inf. Process. Syst., 2022, pp. 37991–38002."}, "questions": {"value": "I raised some questions in Weaknesses part. I really appreciate if the authors answer them."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "C3axpsJz6n", "forum": "ZxYkPHacJT", "replyto": "ZxYkPHacJT", "signatures": ["ICLR.cc/2026/Conference/Submission1265/Reviewer_bo89"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1265/Reviewer_bo89"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1265/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761409009046, "cdate": 1761409009046, "tmdate": 1762915722785, "mdate": 1762915722785, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents Neural Collapse (NC) based analysis (using the unconstrained features model setup) for cross entropy (CE) and Binary CE (BCE) losses and feature normalization (to unit norm). Based on this, the authors make some claims on feature learning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The writing is OK but I have concerns about the novelty, motivation, and relevance for the study of \"feature learning\"."}, "weaknesses": {"value": "1. \nStronger NC, which is typically measured on training data, may degrade generalization, e.g., when the training set is small and/or in case of distribution shift and/or transferability to other tasks. Thus, it is not an indication for good feature learning.\n\n2. \nI believe that \"intra-class compactness\" is not a desirable property for general feature learning, which should be transferable between tasks. Extreme compactness can be good in classification setups where NC is desirable, but then there is no difference between \"feature learning\" that is supervised and \"classification\" (which also includes feature learning).\n\n3. \nDue to focusing on the unconstrained features model, the analysis does not imply anything on generalization (which is necessary for analyzing feature mappings).\n\n4. \nPlease provide detailed discussion on the differences between the current work and (Li et al. 2025) (\"BCE vs. CE in deep feature learning\"), which also analyzed unconstrained features models.\n\n5. \nPlease point to supervised learning references where the normalization model (z=\\gamma Wh-b, with unit ||u||,||w||) has been used exactly.\n\n6. \nIn feature/representation learning, the goal is to learn good transferable embeddings that would perform well on new tasks/classes. The final layer of the downstream task need not be related to the classes of the samples during the feature learning. Thus, the arguments in Section 3.2 seem wrong, as they assume that the features will only be used for the same classification task.\n\n7. \nThe motivation for studying the BCE loss should be improved as it does not scale well with the number of classes. Also, as the goal is good feature learning, I suggest contrasting it with supervised contrastive loss and self-supervised approaches.\n\n8. \nTheorem 1 seems to be extremely related to existing results in the literature on NC. \n\n9. \nIs there technical novelty in the proof of Theorem 2 compared to the proof of Theorem 1?\n\n10. \nThe discussions below Theorems 5 and 6 are not clear enough. State formally the convergence rates in the different cases.\n\n11. \nThe experiments section is not satisfactory.  \nIn Table 1 the classification accuracy and the quality of the features should be computed on the test set and not on the train set.\nIf motivation of the paper is to study \"deep feature learning\" it should more deeply examine transfer learning, distribution shifts, etc., and compare BCE+normalization with representation/feature learning approaches.\n\n12. \nCompare BCE and CE with normalization with BCE and CE with small weight decay instead of normalization."}, "questions": {"value": "Stated above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WtQ77JOZd0", "forum": "ZxYkPHacJT", "replyto": "ZxYkPHacJT", "signatures": ["ICLR.cc/2026/Conference/Submission1265/Reviewer_ozw4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1265/Reviewer_ozw4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1265/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761864212317, "cdate": 1761864212317, "tmdate": 1762915722653, "mdate": 1762915722653, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper gives a neat, self-contained theoretical and empirical study of the gap between classification and deep feature learning (DFL) in a very specific regime: supervised, normalized, closed-set classification under UFM-style assumptions. The central idea is to decouple two objectives that are often conflated: (i) achieving nearly perfect, sample-wise local classification, and (ii) achieving a global feature geometry (NC and ETF-like) that enforces intra-class compactness and inter-class separability. To make this separation concrete, the paper associates standard CE with the local objective and reformulates BCE as a better proxy for the global DFL objective, arguing that, unlike CE’s shift-invariant bias, the BCE bias has a unique, substantial optimum that actually shapes the learned geometry.\n\nA key contribution is the analysis of the scaling factor $\\gamma$: the paper shows that as $\\gamma$ increases linearly, the convergence toward the desired NC geometry decays exponentially. This creates a tension: large $\\gamma$ can drive classification to 100% but stall feature-quality convergence; very small $\\gamma$ improves geometric convergence but hurts accuracy. Experiments suggest a moderate $\\gamma$ balances the two, and BCE-trained features transfer better to long-tailed recognition and open-set recognition."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper clearly separates two confused goals: getting samples classified correctly vs. learning a good feature geometry.\n- Within the stated regime (supervised, normalized, closed-set, UFM), the analysis is coherent, and the CE/BCE/NC/ETF relationships are tied together convincingly.\n- The role of the scaling factor $\\gamma$ is articulated concretely, showing how increasing $\\gamma$ creates a trade-off by speeding up classification but slowing convergence to the NC/ETF geometry.\n- The paper makes a useful point that, in this setup, the BCE bias is not incidental but actually shapes the feature geometry."}, "weaknesses": {"value": "## 1. The applied scope is narrow and should be made explicit\nThe core Theorems [1-6] are all derived under a stylized configuration: fully supervised learning, a closed label set of size $K$, and feature and classifier normalization. This is essentially the NC (Neural Collapse) theory world. In such a context, using ETF-like target geometries and measuring feature–weight alignment is legitimate. However, today's deep feature learning is primarily driven by contrastive self-supervised methods, which aim for open-set vocabularies, class-weight ($w$)- agnostic batches, and sample-sample semantic alignment. These regimes do not satisfy the paper's core assumptions. The current paper sometimes slides from “we showed this under UFM + fixed-\\(K\\) + normalization” to “therefore this is how deep feature learning behaves”. This should be tightened. A fairer statement would be:\n> “We provide a self-contained analysis for normalized, supervised, closed-set classification with fixed $K$; outside this regime, the behavior may differ.”\n\n## 2. The advantage of bias in BCE can act as a constraint\nThis paper argues that BCE is superior to CE because the bias $b$ in BCE is substantial and unique, while the bias in CE is somehow useless due to its shift-invariance in softmax. However, we can have some opposite opinions:\n- The shift-invariance of bias in CE can be a robustness property that makes the model not over-sensitive to the absolute scale of logits;\n- The biases in BCE (Eq. 11) are a clean object only because we are in the aforementioned stylized settings. It is also tightly tied to the training-time number of classes $K$;\nTherefore, the same thing the paper calls an advantage can also be read as a strong label-dependent constraint. This constraint removes the translation robustness of CE and locks the optimal geometry to the training value of $K$ in BCE in class-agnostic regimes.\n\n## 3. On the \"exponential decay\" narrative\nThis paper claims that, for large $gamma$, the convergence rate decays exponentially; therefore, the model cannot reach the desired NC/ETF geometry. This is one possible reading, but there is also a very natural alternative: a large $gamma$ makes the optimization goal into a simpler one. Since it can make the data separably classified with high confidence ($P \\to 1$), SGD can quickly succeed at this easier goal. Once this easy goal is reached, gradients necessarily get tiny (since $1-P \\to 0$). What we observe as “exponential decay” is a symptom of success on the easy goal, not a cause of failure on the hard geometric goal. In other words, the paper currently treats a post-separability slowdown as evidence that \"large $gamma$ harmed feature learning\". However, a post-separability slowdown is expected once the “critical conditions” (I (Eq. 14) and II (Eq. 15) in the paper) are satisfied. Those conditions are themselves local separability conditions, inducing slower dynamics.\n\n\n## 4. The Math Issue\nTo begin with, I'd like to say that the theoretical section would benefit from tightening the assumptions and motivating the key inequality from the problem structure, rather than presenting a long algebraic chain.\n\nThe most serious mathematical issue in this paper appears in the BCE part of the appendix, where the authors reuse an AM–GM type inequality but violate its own stated precondition. In Appendix E.2, the authors attempt to derive a lower bound for the BCE loss by invoking the standard AM–GM type inequality: $u^\\top v \\le \\frac{c}{2}\\|u\\|_2^2 + \\frac{1}{2c}\\|v\\|_2^2, \\text{for } c > 0.$ They explicitly require $c > 0$ for this inequality to hold.\n\nHowever, in the tightness part of the argument, where they try to make the inequality achieve equality and at the same time recover the NC/ETF-like structure, the derivation effectively enforces $h_i^{(k)} = - c_4 \\gamma w_k$, and, combined with the target condition $h_i^{(k)} = w_k$, this forces $c_4 = -\\frac{1}{\\gamma} < 0$. That is, to make the proof work, the authors end up choosing a negative value for the constant, which must be positive according to the inequality they cited. This is a direct violation of the premise $c > 0$. As a result, the corresponding lemma (and the theorem that depends on it) does not currently have a valid proof in the appendix."}, "questions": {"value": "- The theory in this paper is derived in a strict NC-style setting (supervised, normalized, closed-set, fixed $K$). What is the concrete insight or usefulness of your results for current self-supervised contrastive feature learning, which does not satisfy these assumptions?\n- The most serious issue is the one in weakness #4. This breaks the stated condition and renders Lemma 12 invalid as written. Please clarify or fix it.\n- Please also address the other weaknesses.\n\nOne tricky point is that, under today’s dominant self-supervised contrastive deep feature learning, the practical value of this paper’s classification-based setup is limited. That said, given ICLR’s openness to theory, I am willing to accept the authors’ chosen supervised closed-set feature learning framework; within this framework, the result that BCE can be preferable to CE is meaningful. However, the mathematical issue in Weakness #4 (violation of the inequality’s own precondition) affects Lemma 12 and is critical. I therefore currently place the paper below the acceptance threshold. If the authors can fix this issue, and if other reviewers are comfortable with the restricted learning paradigm, I would be happy to raise my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ui2BLhpDtn", "forum": "ZxYkPHacJT", "replyto": "ZxYkPHacJT", "signatures": ["ICLR.cc/2026/Conference/Submission1265/Reviewer_62s4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1265/Reviewer_62s4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1265/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761887147771, "cdate": 1761887147771, "tmdate": 1762915722460, "mdate": 1762915722460, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors analyze cross entropy (CE) and binay cross entropy (BCE)\nin normalized spaces for classification and feature learning.  In\nnormalized spaces, both feature (h) and weight vectors (w_j) are\nnormalized with norm 1.  The decision vector (z) is adjusted with a\nscaling factor (gamma), where z = gamma*Wh - b.  For classification,\nclass probabilities are obtained via softmax and the loss function is\ncross entropy (CE).  For feature learning, intra-class compactness and\ninter-class separation are considered.  For inter-class compactness,\nmin{w_k . h_i} is greater than some threshold.  Similarly for\ninter-class separation, max{w_j . h_i} is less than some threshold.\nBinary Cross Entropy (BCE) is used as is in multi-class classification.\n\nBased on a number of assumptions, the theoretical analysis indicates\nthat normalized CE and BCE lead to neural collapse (NC) when minimum\nis achieved.  The CE loss cannot enhance compactness and separability\nand has many minima.  However, normalized BCE, which incorporates\ncompactness and separability, has only one minimum.\n\nFor normalized spaces, another analysis shows that when gamma is very\nlarge, classification performs well while feature learning performs\npoorly.  When gamma is very small, both classification and feature\nlearning perform poorly.\n\nFor empirical analysis, they use 2 existing network architecture over\n3 datasets.  The use existing NC metrics to measure NC progress.  When\ngamma is 8, the empirical results indicate that both BCE and CE can\nlead to NC when they reach the minimum.  On varying gamma values, both\nCE and BCE perform poorly when gamma is less than 1.  Both CE and BCE\nperforms well when gamma is larger than 1.  When gamma < 8,\nconvergence can be achieved.  As expected BCE generally has better\ncompactness and convergence.  On long-tailed recognition and open-set\nrecognition, BCE performs better than CE."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.  Analyzing CE and BCE in normalized spaces is interesting.\n\n2.  The theoretical analysis shows that CE and BCE under certain\nassumptions can lead to NC, and larger gamma is useful for\nclassification.\n\n3.  The empirical analysis indicates that the results roughly follow\nthe theoretical analysis."}, "weaknesses": {"value": "1.  Since BCE explicitly incorporates compactness and separability,\nBCE has better feature learning is expected."}, "questions": {"value": "p8: \"In contrast, when gammaγ = 32 or 64, the models’ accuracies reach\n100%, while the intra-class compactness and inter-class separability\nof their features are comparatively poor and worse than that learned\nwith small\" Why compactness and separability did not further improve?\nIs it because convergence was not achieved?\n\nHow would BCE perform without incorporating compactness and separability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "n/a"}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gUBJ7tirX3", "forum": "ZxYkPHacJT", "replyto": "ZxYkPHacJT", "signatures": ["ICLR.cc/2026/Conference/Submission1265/Reviewer_pBJ8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1265/Reviewer_pBJ8"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1265/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761951958514, "cdate": 1761951958514, "tmdate": 1762915722302, "mdate": 1762915722302, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}