{"id": "S93SnUsO8c", "number": 17010, "cdate": 1758271147830, "mdate": 1762942946948, "content": {"title": "From Code to Action: Hierarchical Learning of Diffusion-VLM Policies", "abstract": "Imitation learning for robotic manipulation often suffers from limited generalization and data scarcity, especially in complex, long-horizon tasks. In this work, we introduce a hierarchical framework that leverages code-generating vision-language models (VLMs) in combination with low-level diffusion policies to effectively imitate and generalize robotic behavior. Our key insight is to treat open-source robotic APIs not only as execution interfaces but also as sources of structured supervision: the associated subtask functions - when exposed - can serve as modular, semantically meaningful labels. We train a VLM to decompose task descriptions into executable subroutines, which are then grounded through a diffusion policy trained to imitate the corresponding robot behavior. To handle the non-Markovian nature of both code execution and certain real-world tasks, such as object swapping, our architecture incorporates a memory mechanism that maintains subtask context across time. We find that this design enables interpretable policy decomposition, improves generalization when compared to flat policies and enables separate evaluation of high-level planning and low-level control.", "tldr": "", "keywords": ["Hierarchical Imitation Learning", "Vision-Language Models", "Diffusion Policies", "Code Generation", "Robotic Manipulation", "Memory-Augmented Policies"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/79c7a78f1bba3b58b1641d2e5b5e8206d7660437.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a hierarchical framework for robotic imitation learning designed to improve generalization and data efficiency on complex manipulation tasks. The core idea is to decompose the learning problem into two stages: \"thought imitation\" and \"action imitation.\" First, a code-generating Vision-Language Model (VLM) is trained to act as a high-level policy. This VLM learns to imitate the \"thoughts\" of an oracle (a scripted API-based policy) by mapping a high-level natural language instruction and visual observation to the specific, semantically meaningful API code (e.g., pick(...), place_on_actor(...)) that an expert would execute . Second, a low-level diffusion policy is trained to perform \"action imitation\" by learning to execute these VLM-generated code snippets to produce low-level robot actions."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper is well-written, and the proposed hierarchical framework is explained clearly. The core concept of \"Thought Imitation\" (VLM-based code generation) and \"Action Imitation\" (code-conditioned diffusion policy) is intuitive and well-illustrated by Figure 1."}, "weaknesses": {"value": "1. Over-engineered and Handcrafted Framework: The entire method is critically dependent on the pre-existence of a comprehensive, scripted, open-source robotic API that can already solve the tasks. This is an extremely strong assumption that does not generalize. The framework does not learn to decompose tasks; it learns to mimic a human-engineered decomposition provided by the API (e.g., get_actor, pre_pick_ee_pose, place_on_actor, etc.) . This shifts the entire burden of task decomposition from the model to a human programmer, which is the opposite of scalable skill discovery.\n\n2. Brittleness of the System: The approach is laden with handcrafted components that limit its applicability. For example, the system relies on a complex, rule-based memory mechanism (l^{cache}) that requires a custom regex parser (Algorithm 1) to scan the generated code strings for stateful information (e.g., pose_dict['.*?']) . This is a brittle, non-learned, and highly-engineered solution for state tracking. The system can only function within the rigid syntax of its pre-defined API, making it incapable of handling any task or object interaction not explicitly defined by that API.\n\n3. Limited Novelty: The concept of using a VLM to generate code as a high-level plan (\"Code as Policies\") is well-established (e.g. as cited by the authors, Liang et al., 2023; Singh et al., 2023) . The paper's main claim to novelty is that it also learns the low-level policy via diffusion, rather than just executing the oracle API code. However, this \"distillation\" of a perfect, scripted oracle into a learned diffusion policy is of questionable value; the experiments (Table 1) show this learned policy (VLM+DP, 63.95% avg) is significantly worse than just executing the VLM's plan with the oracle API in the first place (VLM+Oracle, 80.78%). Furthermore, the broader concept of hierarchical policies with intermediate representations is a very active area, and the paper fails to compellingly argue why API code is a superior representation to learned latent plans (Bjorck et al., 2025) or natural language sub-goals (Shi et al., 2025).\n\n4. Unfair Experimental Comparison: The primary baseline is a \"flat\" diffusion policy (DP) conditioned only on the high-level natural language prompt. This is a strawman argument. The hierarchical \"VLM+DP\" policy receives detailed, step-by-step, correct code instructions at each phase of the task, while the \"flat\" policy receives a single, ambiguous, long-horizon goal. This experiment does not prove that a hierarchical policy is better than a flat one; it proves that a policy given step-by-step guidance is better than a policy given none. A fair baseline would have been a flat policy also conditioned on VLM-generated natural language sub-goals, or a comparison to other state-of-the-art hierarchical methods."}, "questions": {"value": "1. The framework's success seems entirely contingent on having an existing, expert-programmed, scripted API for all tasks. How do you propose this method would be applied to novel tasks or domains where no such API exists? Does this not simply shift the difficulty from data collection to manual, expert-level API engineering?\n\n2. The paper's main novelty claim is distilling the low-level API functions into a learned diffusion policy. However, your results in Table 1 show that the performance of the full \"VLM+DP\" system (63.95% average) is dramatically lower than the \"VLM+Oracle\" system (80.78%). Given that the oracle API already exists and performs better, what is the practical motivation for replacing it with a less effective learned diffusion policy?\n\n3. The main baseline (\"Task Prompt Only (DP)\") is a flat policy conditioned on a single, high-level task description. This seems like an unfair comparison against your hierarchical policy, which receives granular, step-by-step code instructions. Could you justify this baseline choice? How do you think your method would compare against a flat policy that was also given intermediate, VLM-generated natural language sub-goals?\n\n4. The memory system for handling non-Markovian state (l^{cache}) relies on a regex parser (Algorithm 1) to find specific variable assignments in the generated code string . This seems very brittle. Why was this hand-engineered approach chosen over a more standard, learned memory mechanism, such as simply passing the VLM's hidden state to the diffusion policy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "0lSO0ledyu", "forum": "S93SnUsO8c", "replyto": "S93SnUsO8c", "signatures": ["ICLR.cc/2026/Conference/Submission17010/Reviewer_871p"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17010/Reviewer_871p"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17010/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761947793496, "cdate": 1761947793496, "tmdate": 1762927034282, "mdate": 1762927034282, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "We would like to withdraw our submission. While we appreciate the time invested by the reviewers, we believe the reviews did not accurately reflect the motivation or contribution of our work. Several critiques focused on assumptions that were either explicitly addressed in the paper or are common in related literature, while overlooking the core research question we aimed to explore.\n\nSome comparisons requested by reviewers (e.g., against unrelated architectures or baselines that do not share our design goals) would not have been fully meaningful within the scope of our study. Our intention was to isolate and analyze the architectural implications of hierarchy and code as state, not to compete on raw performance in uncontrolled settings. Unfortunately, this distinction was not recognized in the feedback.\n\nWe will take this opportunity to revise the manuscript to better clarify the motivation, strengthen the experimental design, and explicitly position our work relative to existing approaches.\n\nThank you for your consideration."}}, "id": "PpmUP8kwGX", "forum": "S93SnUsO8c", "replyto": "S93SnUsO8c", "signatures": ["ICLR.cc/2026/Conference/Submission17010/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17010/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762942946172, "cdate": 1762942946172, "tmdate": 1762942946172, "mdate": 1762942946172, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Leverage a VLM to generate code that uses either an oracle or diffusion policy to take action in the environment. By building up a robot state in a code-cache, the model has history which is not otherwise captured in the visual state. A code-captioning objective can then be used which is presumably simpler to train than modern architectures. A simplified task space with perfect proprioception is used in the experiments."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The motivation to have hierarchy and to explore the abstractions required for robotics is a useful pursuit."}, "weaknesses": {"value": "*Motivation*\nI broadly understand the goal of induced hierarchy, particularly as it pertains to enabling long-horizon planning, and of \"code as state\". I however do not see the resulting hierarchy clearly explained in the actual approach which only discussed rather simple and seemingly flat tasks.\n\n*Presentation*\nI found this paper surprisingly hard to parse, having to constantly cross reference or guess at the meanings of what seem like extraneous variables in the math. Even the data used -- whose functions are essential to understanding the scope of this paper -- requires reading another paper (for environments) and the appendix (sort of, as the code listed doesn't capture what's in the figures).\n\n*Experiments*\nThe design of the experiments, particularly as they differ dramatically from what is common in the field or what is used in most of the related work, needs to be better argued.  This includes L0,L1 but also the task itself. It's possible that even just having better figures for showing varying depth hierarchies and horizons or performance by trajectory length would assist here.\n\n*Comparisons*\nThere are no comparisons to current models in the space (either VLAs or VLM based models) which also makes the results hard to interpret. If the idea is a focus on architecture and controlled experiments, as alluded to in the related work, then justification and verbiage aligning the results to those of other architectures should be included. For example, CLIP-RT, does not have hierarchy but is a very simple VLM style approach"}, "questions": {"value": "Please clarify the points above regarding \n- why comparisons were not included\n- why these tasks were appropriate \n- why it was important to simplify the evaluation domain\n- how the papers results will be applicable to more realistic settings."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "prSaKjfuxC", "forum": "S93SnUsO8c", "replyto": "S93SnUsO8c", "signatures": ["ICLR.cc/2026/Conference/Submission17010/Reviewer_KD5Y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17010/Reviewer_KD5Y"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17010/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761956417531, "cdate": 1761956417531, "tmdate": 1762927033829, "mdate": 1762927033829, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents an innovative hierarchical framework for robot policy learning, designed to address the poor generalization often seen in traditional \"flat\" imitation learning approaches when applied to long-horizon, compositional tasks. The core concept is realized through a two-tier architecture: 1) a high-level Vision-Language Model (VLM) that transforms natural language instructions into structured Pythonic code plans, and 2) a low-level diffusion policy that executes the generated code to produce accurate robot actions. To validate the code-as-policy concept, the authors conduct a quantitative analysis on the feature extraction capabilities. Extensive experiments on the ClevrBench benchmark demonstrate the proposed method's effectiveness in achieving compositional generalization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The key insight of leveraging code as a structured intermediary representation is innovative.\n2. The paper provides a good evaluation with the demonstration of compositional generalization being evidence.\n3. The intuition of separating high-level planning from low-level control is impressive."}, "weaknesses": {"value": "1. The method's effectiveness is intrinsically tied to the quality of the underlying scripted policies, raising significant questions about its transferability to real-world scenarios without such pre-existing structures.\n2. The paper would be strengthened by comparisons with other recent hierarchical methods that use different intermediate representations to better establish the advantage of using code.\n3. The lack of validation on a physical robot platform is one of the major limitations."}, "questions": {"value": "Regarding the methodological and experimental design:\n1. The proposed method heavily relies on a predefined API vocabulary, which may limit its generalization to novel objects or actions not covered in the API. What are the advantages of this code-based approach compared to other possible intermediate representations?\n2. The memory mechanism only caches historical code instructions without verifying the actual physical state, how does the method handle potential error accumulation caused by state discrepancies?\n3. Since the paper doesn't provide a thorough analysis of error propagation across the cascaded VLM-planning and policy-execution modules, how does the method clarify the bottlenecks of the entire system?\n\nRegarding the comparisons and evaluations:\n1. The generalization tests appear focused on known task compositions. How does the approach ensure rigorous validation of compositional generalization without testing zero-shot generalization to unseen task combinations?\n2. Without including comparisons to state-of-the-art hierarchical methods, why is the method only compared with a flat diffusion policy baseline?\n3. Given that experimental validation was conducted entirely in a simulated environment, how do the authors justify the practical applicability of the method, considering the absence of real-world robot experiments? \n\nOverall, although the paper has major limitations in comparative benchmarking and the absence of real-world validation, it presents a novel and promising hierarchical framework. I recommend accept at this stage."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7mK4VGQQpx", "forum": "S93SnUsO8c", "replyto": "S93SnUsO8c", "signatures": ["ICLR.cc/2026/Conference/Submission17010/Reviewer_HmxB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17010/Reviewer_HmxB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17010/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977474221, "cdate": 1761977474221, "tmdate": 1762927033358, "mdate": 1762927033358, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel hierarchical framework in the field of robot manipulation. The first phase leverages Vision-Language Models (VLM) to generate code for robot execution. In the second phase, the code is used as a condition for the low-level diffusion policy, ultimately resulting in execution actions. The authors validate the effectiveness of their approach using the CleverSkills benchmark."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This work provides a detailed exposition of the two-phase \"code to policy\" paradigm. An interesting aspect is the authors' discovery that using code as a condition for diffusion can yield improved performance. To address non-Markovian tasks, the authors designed a memory module to record historical robot states. Additionally, they introduced an auxiliary loss to assist in the training of Vision-Language Models (VLMs). The overall pipeline of the method is well-structured and clear."}, "weaknesses": {"value": "1.The core issue lies in the motivation. The authors argue that an oracle policy inherently possesses the ability to decompose tasks, allowing for the segmentation into multiple subtasks without additional annotation. However, this ability seems to be limited to the settings provided by the ClevrSkills benchmark proposed by the authors. What about benchmarks that lack such an oracle policy, like the commonly used manipulation simulation benchmarks Calvin[1] and Libero[2]?\n2.The paper lacks experiments with real-world robots. In real environments, even using code, manual annotation remains necessary, which seems to contradict the authors' claim that an oracle policy reduces annotation costs. This step appears unavoidable. Additionally, even in ClevrSkills, the authors mention the need to filter out unsuccessful trajectories, which seemingly increases the manual annotation workload.\n3.The experiments are insufficient. It would be valuable to compare this code-layering paradigm, which integrates sub-task language instructions into diffusion policy (dp), with alternatives. This comparison could demonstrate that using code as a condition is more easily learned by the dp for low-level policy compared to using sub-task language instructions as a condition.\n\n[1]CALVIN: A Benchmark for Language-Conditioned  Policy Learning for Long-Horizon Robot  Manipulation Tasks\n[2]LIBERO: Benchmarking Knowledge Transfer for Lifelong Robot Learning"}, "questions": {"value": "Please see the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "b9xqE2ZOrP", "forum": "S93SnUsO8c", "replyto": "S93SnUsO8c", "signatures": ["ICLR.cc/2026/Conference/Submission17010/Reviewer_pnGb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17010/Reviewer_pnGb"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17010/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762055107661, "cdate": 1762055107661, "tmdate": 1762927032906, "mdate": 1762927032906, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}