{"id": "6wd6p1lpwm", "number": 12094, "cdate": 1758205662125, "mdate": 1759897534217, "content": {"title": "MMGeoLM: Hard Negative Contrastive Learning for Fine-Grained Geometric Understanding in Large Multimodal Models", "abstract": "Large Multimodal Models (LMMs) typically build on ViTs (e.g., CLIP), yet their training with simple random in-batch negatives limits the ability to capture fine-grained visual differences, particularly in geometric scenarios.\nTo address this challenge, we propose a novel hard negative contrastive learning framework for the vision encoder, which combines image-based contrastive learning using generation-based hard negatives created by perturbing diagram generation code, and text-based contrastive learning using rule-based negatives derived from modified geometric descriptions and retrieval-based negatives selected based on caption similarity.\nWe train a vision encoder (CLIP) using our hard negative training method, namely MMCLIP (Multimodal Math CLIP), and subsequently train an LMM for geometric problem-solving. Experiments show that our trained model, MMGeoLM, significantly outperforms other open-source models on three geometric reasoning benchmarks. Even with a size of 7B, it can rival powerful closed-source models like GPT-4o.\nWe further conduct ablation studies to analyze three key factors: \nhard negative types, the efficiency of image-based negatives, and training configurations.\nThese analyses yield important insights into optimizing the training pipeline of vision encoder for fine-grained geometric reasoning tasks.", "tldr": "", "keywords": ["Multimodality", "Hard Negative", "Geometric Understanding"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ec6022f6c4bcae9b85812bd09be741242cb93422.pdf", "supplementary_material": "/attachment/e6a261c1161ea74caf5341e13301e45e04aafae6.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces MMGeoLM, a large multimodal model for geometric mathematical reasoning, built upon a novel hard negative contrastive learning framework (MMCLIP). The method enhances fine-grained geometric understanding by constructing two types of structured hard negatives: (1) text-based (retrieval- and rule-based) negatives that modify geometric relations or attributes, and (2) image-based negatives generated by perturbing LLM-produced diagram code. Trained with these negatives, the vision encoder significantly improves alignment quality, leading MMGeoLM to achieve state-of-the-art performance on four geometry reasoning benchmarks, even surpassing GPT-4o on MM-Math."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- This paper addresses the overlooked issue of geometric fine-grained perception in LMMs through a principled and generalizable hard negative framework.\n\n- The code-perturbation strategy for generating image-based negatives is elegant, efficient, and produces semantically meaningful supervision.\n\n- Strong performance across multiple benchmarks, detailed ablations, and robustness analyses clearly demonstrate the method’s effectiveness and scalability."}, "weaknesses": {"value": "- The introduction and Figure 1 clearly diagnose the major issue of existing LMMs: a.hallucinating non-existent geometric elements or b. misinterpreting spatial relationships. However, the experiments only report overall accuracy without any qualitative or quantitative evaluation of whether MMGeoLM actually reduces such hallucinations. This leaves the key claim unverified.\n\n- The evaluation omits several sub-benchmarks in MathVista, despite it being a comprehensive multimodal reasoning dataset. This selective testing weakens the evidence for broad generalization and comparability with prior works.\n\n- Both training and evaluation focus narrowly on geometry-related math images. The paper does not explore whether the proposed hard negative framework benefits other structured visual domains—such as tables, charts, or diagrams—where fine-grained spatial reasoning is also required. This raises concerns about the model’s generalization beyond in-domain settings.\n\n- The proposed hard-negative loss remains a variant of the standard InfoNCE formulation. The work does not explore introducing structural constraints (e.g., graph-based or relation-aware embeddings) to explicitly model geometric relationships, which could more directly address fine-grained spatial reasoning."}, "questions": {"value": "same as weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6F1e6tUJc2", "forum": "6wd6p1lpwm", "replyto": "6wd6p1lpwm", "signatures": ["ICLR.cc/2026/Conference/Submission12094/Reviewer_q6Rm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12094/Reviewer_q6Rm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12094/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761628647663, "cdate": 1761628647663, "tmdate": 1762923062564, "mdate": 1762923062564, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MMCLIP, a hard negative contrastive learning framework designed to improve visual encoders for geometric reasoning. The method constructs both image-based hard negatives and text-based hard negatives, derived from rule-based modifications or caption retrieval. The trained encoder is then used to build MMGeoLM, a 7B LMM that shows improvements over open-source baselines on three geometric reasoning benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper targets an important  challenge—enhancing geometry-specific visual encoders for reasoning tasks.\n\nThe proposed hard negative generation approach is conceptually sound and improves the visual encoder’s fine-grained discrimination."}, "weaknesses": {"value": "The main contribution lies in applying hard negative contrastive learning to geometric visual encoders, which, while useful, represents an incremental improvement (more like technic report) rather than a fundamentally new research direction. The approach primarily involves building a domain-specific dataset, generating hard negatives, and training with standard architectures and loss functions, without methodological innovation in model design or learning objectives.\n\nMoreover, geometry-specific vision encoders have already been explored in multiple prior works, including GEOX, GeoDANO, and Primitive Vision. These works similarly addressed fine-grained geometric perception using both image-level encoders (e.g., CLIP, SigLIP, MAE, VQ-GAN) and object-level detectors (e.g., Grounding DINO/Faster R-CNN). \n\n\n**References**\n\n[1]  GEOX: GEOMETRIC PROBLEM SOLVING THROUGH UNIFIED FORMALIZED VISION-LANGUAGE PRE- TRAINING \n\n[2]  GeoDANO: Geometric VLM with Domain Agnostic Vision Encoder \n\n[3]  Primitive Vision: Improving Diagram Understanding in MLLMs"}, "questions": {"value": "The experimental scope is also limited. The evaluation is conducted only on smaller-scale models (7B parameters), without examining performance scalability or testing on more complex benchmarks such as DynaMath, which assesses reasoning under visual dynamics and temporal changes."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "WktnVA472N", "forum": "6wd6p1lpwm", "replyto": "6wd6p1lpwm", "signatures": ["ICLR.cc/2026/Conference/Submission12094/Reviewer_xduf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12094/Reviewer_xduf"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12094/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761809384809, "cdate": 1761809384809, "tmdate": 1762923062102, "mdate": 1762923062102, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the poor performance of Large Multimodal Models (LMMs) on fine-grained geometric reasoning tasks. The authors argue that standard contrastive learning fails because it relies on general descriptions, lacking geometric precision.\n\nThe authors introduce a hard negative contrastive learning framework to train the vision encoder (CLIP). This framework generates high-difficulty negative samples:\n- Image-based Hard Negatives: They generate diagram code and then perturb this code to create images that are visually similar to the original but geometrically incorrect (e.g., wrong angles, broken parallelism).\n- Text-based Hard Negatives: They use rule-based methods to alter geometric descriptions to be incorrect.\n\nExperiments on three geometric reasoning benchmarks show that MMGeoLM outperforms other open-source models and reportedly rivals closed-source models like GPT-4o."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper introduces a practical method for improving geometric reasoning in MLMMs. The core idea of using perturbed diagram generation code to create high-quality image-based hard negatives is technically sound.\n\n- The proposed approach (MMGeoLM) demonstrates significant performance gains, reportedly outperforming similarly sized open-source models on three relevant geometric reasoning benchmarks."}, "weaknesses": {"value": "- The core novelty is a clever data generation/curation technique. The method of perturbing code to create image negatives and using rules for text negatives is a form of data augmentation. While effective, the contribution is fundamentally a sophisticated form of data augmentation or data engineering, which limit its conceptual novelty and contribution.\n- The empirical evaluation could be significantly strengthened. The chosen baselines are not fully representative of the current state-of-the-art; many comparisons are against models from 2024 or early 2025. Key contemporaneous works (e.g., MiMo-VL https://arxiv.org/abs/2506.03569) are notably absent, making it difficult to accurately assess the method's relative advantage. Furthermore, the evaluation would be more comprehensive if it included other challenging, relevant benchmarks, such as MathVision (https://huggingface.co/datasets/MathLLMs/MathVision), to fully validate the model's geometric reasoning capabilities."}, "questions": {"value": "- To accurately contextualize the paper's strong results, I suggest that the authors provide a comparison against more recent and powerful open-source LMMs, such as MimoVL and any other relevant SOTA models from 2025. Besides, I encourage the authors to evaluate MMGeoLM on the MathVision benchmark. This is a well-regarded and challenging benchmark for fine-grained visual-mathematical reasoning that would provide a more comprehensive validation of the proposed method.\n- What is the performance if using a \"simpler\" hard negative (e.g., random visual perturbations, or negatives from a standard CLIP retrieval) compared to the proposed code-perturbation method? How critical is the combination of both image-based and text-based hard negatives? What is the performance with only one of them?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "oBs1lNhdY9", "forum": "6wd6p1lpwm", "replyto": "6wd6p1lpwm", "signatures": ["ICLR.cc/2026/Conference/Submission12094/Reviewer_47ne"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12094/Reviewer_47ne"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12094/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969287741, "cdate": 1761969287741, "tmdate": 1762923061630, "mdate": 1762923061630, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces MMGeoLM, a Large Multimodal Model (LMM) designed to enhance fine-grained geometric understanding through a novel hard negative contrastive learning framework. This framework integrates image-based contrastive learning using generation-based hard negatives and text-based contrastive learning employing rule-based and retrieval-based negatives. The authors train a vision encoder (CLIP) with this method, resulting in MMGeoLM, which demonstrates superior performance on three geometric reasoning benchmarks, even at a 7B parameter scale, rivaling models like GPT-4o. Ablation studies provide insights into optimizing the training pipeline for geometric reasoning tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper presents a novel hard negative contrastive learning framework that effectively addresses the challenge of capturing fine-grained visual differences in geometric scenarios. By combining image-based and text-based contrastive learning, the approach enhances the model's ability to understand complex geometric relationships.\n2. The integration of generation-based hard negatives and rule-based and retrieval-based text negatives is a unique contribution."}, "weaknesses": {"value": "1. While the model performs well on the selected benchmarks, the paper does not discuss its performance on a broader range of geometric reasoning tasks. It would be beneficial to understand how MMGeoLM generalizes to other problem domains.\n2. The paper lacks comparisons with other state-of-the-art models in the field. Including such comparisons would provide a clearer context for evaluating MMGeoLM's performance and highlight its relative advantages."}, "questions": {"value": "1. Can you provide more details on the generation-based hard negatives and how they are created?\n2. How does MMGeoLM perform on geometric reasoning tasks beyond the three benchmarks presented?\n3. What are the computational requirements for training MMGeoLM, and how does it scale with larger datasets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hA2krW8SRH", "forum": "6wd6p1lpwm", "replyto": "6wd6p1lpwm", "signatures": ["ICLR.cc/2026/Conference/Submission12094/Reviewer_GgP3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12094/Reviewer_GgP3"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12094/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996669364, "cdate": 1761996669364, "tmdate": 1762923061019, "mdate": 1762923061019, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}