{"id": "O7q6UcYQHq", "number": 17055, "cdate": 1758271657438, "mdate": 1759897201615, "content": {"title": "Rose-TTA: Reliable Online Structural Enhancement for Test-Time Adaptation", "abstract": "Large-scale vision-language models like CLIP exhibit remarkable zero-shot generalization but suffer significant performance degradation under real-world distribution shifts. Although recent cache-based test-time adaptation (TTA) methods mitigate the issues, they are limited by: (i) unreliability in cache construction, as entropy-based sample selection is insufficient under distribution shifts; and (ii) incomplete cache information at inference, with both imbalanced category information caused by sequential online updates and insufficient sample-specific information for next online instance. To address these limitations, we propose ROSE-TTA (Reliable Online Structural Enhancement for Test-Time Adaptation), a unified framework that enhances both cache construction and utilization for more reliable and stable adaptation. For construction, we introduce a noise-aware uncertainty measure that combines entropy with perturbation-based prediction stability to robustly select cache entries. To complete the cache information for utilization, we develop a graph-based structural completion strategy, which effectively mitigates class imbalance and completes global information by transferring information between text embeddings and cached features. Additionally, we introduce a sample-specific refinement mechanism to dynamically update cache features and incorporate local information of each online test sample. Experiments on 15 widely used datasets demonstrate the effectiveness of our method.", "tldr": "", "keywords": ["Test-Time Adaptation", "Vision-Language Models", "CLIP", "Training-free"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/04137358efe72aadcc6e1e1841e1dc1d0d25fc16.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Existing cache-based test-time adaption algorithms face several challenges, including unreliable cache by selecting test samples via entropy minimization, class imbalance in cache caused by random test example and insufficient sample-specific information for next test example. To address these issues, this paper proposes ROSE-TTA, a reliable online structural enhancement for test-time adaptation, by integrating several new techniques, including a noise-aware uncertainty measure for selecting cache entries, a graph-based structural completion strategy for mitigating class imbalance and completes global information and a sample-specific refinement mechanism for incorporating local information of each test example. The effectiveness of ROSE-TTA is verified by extensive experiments."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* This paper clearly explains the limitations of existing cache-based test-time adaption algorithms.\n\n* This paper proposes several new techniques for cache-based test-time adaption algorithms which might be of independent interest."}, "weaknesses": {"value": "I mainly concern the experimental results which are not sufficient.\n\n* There is a lack of comparison on the cache accuracy of the proposed cache method on different datasets. Specifically, it is better to show the experimental results similar to Figure (a) and Figure (b), and compare it with the cache accuracy of existing methods. Similarly, the category and accuracy statistics (i.e., Figure (c), Figure (d)) of the proposed cache method should also be given and compared with existing cache methods. \n\n* In section 2.2, the authors point out that the online test examples often arrive in random order in practice, naturally introducing class imbalance. Thus it is better to verify the robustness of the proposed algorithm to the random permutation of test examples. For instance, we can permute the test examples $N$ times, and report the average prediction performance and the standard derivation.\n\n* There is a lack of comparison on the testing time. In the inference phase, the proposed algorithm computes $\\hat{G}$, $P_{text}$ and $P_{image}$ which requires multiple matrix multiplication operations. It is better to verify the efficiency of the proposed algorithm with existing algorithms."}, "questions": {"value": "Are the two conditions in (5) consistent? If not, it is possible that the two conditions can not be satisfied simultaneously. In this case, (5) is invalid."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GFIfTCacwy", "forum": "O7q6UcYQHq", "replyto": "O7q6UcYQHq", "signatures": ["ICLR.cc/2026/Conference/Submission17055/Reviewer_7oFc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17055/Reviewer_7oFc"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17055/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760666591554, "cdate": 1760666591554, "tmdate": 1762927068133, "mdate": 1762927068133, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper targets the limitations of cache-based test-time adaptation (TTA) for vision-language models under real-world distribution shifts. It introduces a noise-enhanced uncertainty criterion that combines entropy with prediction stability under noise, so the cache selects samples that are both low-entropy and robust to perturbations. To enable reliable cache utilization on unpredictable test streams, the method builds a graph modeling relationships between text embeddings and cached features, and performs sample-specific refinement to incorporate not only class-level but also instance-level information into the final prediction. Across 15 datasets, ROSE-TTA is compared against computationally heavy TPT-style baselines and lightweight cache-based TTA methods, showing good average performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Compared to prior cache-based TTA, the method appears more stable and practical, demonstrated by rapid early-stage accuracy gains (Figure. 5) and noise-robust cache selection.\n\n- The idea of leveraging Gaussian noise to measure prediction stability and improve cache reliability is novel and well-motivated."}, "weaknesses": {"value": "- Narrow problem framing and incremental contribution. Improving the limitations of cache-based TTA feels like a small-scope problem rather than a new or consequential one, so the contribution reads as incremental rather than foundational.\n\n- Modest and inconsistent empirical gains. Although the paper compares against two baseline families (TPT and prior cache-based methods) on 15 benchmarks, the improvements are not uniform across datasets and are often small in magnitude, so the overall effect feels weak.\n\n- Missing analysis of cache dynamics and system overhead. Since the method centers on cache selection and utilization, please quantify replacement frequency over progress, cache hit ratio, and eviction reasons, as well as latency and memory usage from noise augmentation, graph construction, and sample-specific refinement. In particular, the noise augmentation design appears to require multiple forward passes per test sample, for example n=1 to n=20, which likely increases per-sample latency and compute cost. A table similar to [r1] Table 3 that reports accuracy together with runtime and memory under varying n would enable a fair comparison.\n\n- Noise analysis does not make the gains visible. In Figure 4, varying the number of noise-augmented features from n=1 to 20 does not show a clear improvement, and most bars overlap within error ranges, so the claimed robustness gain is not evident. Including an n=0 no-noise baseline and reporting per-dataset deltas from n=0 would likely make the contribution of noise-based stability clearer and more compelling.\n\nReferences: \n[r1] Zhou, L., Ye, M., Li, S., Li, N., Zhu, X., Deng, L., Liu, H., & Lei, Z. (2025). Bayesian Test-Time Adaptation for Vision-Language Models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2025)."}, "questions": {"value": "Q1. Figure 5 plots progress curves versus TDA, but Tables 1 and 2 show cases where BCA outperforms TDA. Why not include BCA in the progress comparison as well? If TDA was chosen intentionally, please clarify the rationale.\n\nQ2. For cache methods, replacement frequency itself can introduce overhead. Could you report how often cache replacement occurs over progress, and compare noise-aware selection against entropy-only in terms of replacement rate and the associated time/memory overhead? This matters especially in real-world deployments where the update frequency of the cache directly impacts latency and compute cost.\n\nQ3. In Table 3, the criteria for dataset selection are unclear. What was the selection rule? For fairness, would you report averages separately for the OOD benchmarks and for the cross-dataset suite rather than mixing them?\n\nTypo. Tables 1 and 2 appear to mix the terms ROSE-TTA and ROSE-TDA. Which is the correct name? Please standardize the terminology throughout the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SMenxpGyVY", "forum": "O7q6UcYQHq", "replyto": "O7q6UcYQHq", "signatures": ["ICLR.cc/2026/Conference/Submission17055/Reviewer_PpY7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17055/Reviewer_PpY7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17055/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761877592269, "cdate": 1761877592269, "tmdate": 1762927067578, "mdate": 1762927067578, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "ROSE-TTA is a training-free, online TTA method for CLIP that (1) keeps only reliable cache items (improves sample selection for cache), (2) completes class info with a class graph, and (3) does a light per-sample refinement. It shows some gains on cross-dataset/OOD tests, but not uniformly."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**s1: Originality**\nNice idea that combines noise-aware cache selection, class-graph completion, and per-sample refinement in a training-free, online setting.\n\n**s2: Quality**\nThe paper includes multiple ablations that isolate the effect of each component, which makes the method much more convincing.\n\n**s3: Practicality**\nNo backprop at test time, works with batch = 1, and seems like an efficient and deployable approach."}, "weaknesses": {"value": "**w1: Consistency**\nImprovements are not universal across all datasets, even though the method is usually competitive (often first or second).\n\n**w2: Sensitivity** Results likely depend on cache size/noise/refinement hyperparameters.\n\n**w3: Efficiency discussion**\nThe paper could more explicitly highlight and quantify its efficiency (runtime, memory) compared to other TTA baselines."}, "questions": {"value": "**q1: Pseudo-gradient vs true gradient**\nI am not fully sure how the pseudo-gradient you use compares to the actual gradient. Could you either prove this more explicitly or show empirical comparisons (e.g., against a small true-gradient baseline) to clarify how close it is?\n\n**q2: Efficiency**\nSince the method is training-free and online, could you report wall-clock time and memory usage versus other TTA methods, and maybe highlight efficiency as a main selling point in the discussion?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Oil2trjiYD", "forum": "O7q6UcYQHq", "replyto": "O7q6UcYQHq", "signatures": ["ICLR.cc/2026/Conference/Submission17055/Reviewer_rmg6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17055/Reviewer_rmg6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17055/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969006005, "cdate": 1761969006005, "tmdate": 1762927066987, "mdate": 1762927066987, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ROSE-TTA, a cache-based test-time adaptation framework designed to improve the robustness of vision-language models (specifically CLIP) under distribution shifts. The method integrates a noise-aware uncertainty measure for more reliable cache construction, a graph-based structural completion strategy to address class imbalance, and a sample-specific refinement mechanism to enhance local adaptation. Extensive experiments across 15 datasets demonstrate the effectiveness and efficiency of the proposed approach."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The dual use of global structural completion and local instance-aware refinement shows thoughtful architectural design.\n2. Extensive experiments on the cross-dataset and out-of-distribution (OOD) benchmark demonstrate the effectiveness of the proposed method."}, "weaknesses": {"value": "1. To more convincingly demonstrate the effectiveness and robustness of the proposed method, it is recommended to include experiments on standard OOD corruption benchmarks, such as ImageNet-C, CIFAR-10-C, and CIFAR-100-C.\n2. In the Implementation Details, the authors state that “The coefficient $\\alpha$ is tuned individually for each dataset to adapt to the specific scenario.” It would be helpful to include an ablation study or sensitivity analysis of $\\alpha$ (e.g., varying $\\alpha$ over a reasonable range) to show how sensitive the performance is to this hyper-parameter.\n3. Some descriptions are unclear. For example, in Eqn. (3), it is not specified how $\\sigma$ is defined or estimated. Please clarify the exact meaning of $\\sigma$.\n4. In Lines 240–241, the authors claim that the introduced textual embedding “is leveraged to complete the insufficient class information and mitigate class imbalance.” It remains unclear why or how incorporating textual embeddings complements class information and alleviates class imbalance. Providing a more detailed explanation or additional empirical evidence (e.g., analysis or ablations) would make this argument more convincing."}, "questions": {"value": "Please refer to the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "z2AmlxjSSR", "forum": "O7q6UcYQHq", "replyto": "O7q6UcYQHq", "signatures": ["ICLR.cc/2026/Conference/Submission17055/Reviewer_2VNJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17055/Reviewer_2VNJ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17055/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762172839305, "cdate": 1762172839305, "tmdate": 1762927066510, "mdate": 1762927066510, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}