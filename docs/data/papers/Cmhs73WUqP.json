{"id": "Cmhs73WUqP", "number": 21534, "cdate": 1758318623866, "mdate": 1759896917113, "content": {"title": "A Reality Check on Robust Bandit Algorithms for Buffer-Aware Early Exits", "abstract": "Early-exit neural networks (EENNs) reduce inference cost by allowing inputs to terminate at intermediate layers when classification confidence exceeds a threshold. However, practical deployments must operate under stochastic arrivals, limited device resources, and finite buffers, where the backlog directly impacts performance. This paper provides a systems-oriented study of buffer-aware EENNs and introduces new learning algorithms for threshold selection. First, we report results from real testbed experiments on heterogeneous devices, showing that incorporating buffer state into early-exit decisions substantially improves throughput and accuracy under load. Second, we extend policy gradient methods by integrating the Tsallis-softmax parameterization, which yields tunable exploration, robustness to high-variance rewards, and connects recent advances in the $q$-exponential family for policy optimization to practical scheduling in EENNs. Third, we propose contextual bandit algorithms that exploit the natural monotonic relationship between backlog and urgency via parametrized thresholds, reducing sample complexity and enabling generalization across system loads. Together, these contributions highlight that early exits are not only a model-design mechanism but also a systems scheduling problem, bridging theory and practice for robust and efficient inference in resource-constrained environments.", "tldr": "we treat early exits in neural networks as a queue-aware scheduling problem, and solve it with robust bandit algorithms", "keywords": ["early-exit deep neural networks", "multi-armed bandits", "edge computing"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ec76fad4e842127625bb6256ebb13fa5208b450c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper investigates early-exit decisions in edge-cloud inference as an online decision-making problem where the controller observes the backlog, makes a decision on the early-exit confidence threshold and achieves a queue-length dependent reward. Two algorithm-families are studied: Tsallis-regularized policy gradient methods, and UCB-style methods. The non-stationary nature of the problem is incorporated affinely into the threshold. Experiments on testbeds are provided for numerical evaluation."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper studies an interesting problem, and takes the approach of queue-dependent exit decisions, which seems to be a good fit.\n- The bandit formulation makes sense.\n- Empirical evaluations are compelling."}, "weaknesses": {"value": "- The paper can be better positioned in the bandit literature. The backlog and buffer capacity are playing a similar structural role of a capacity-limited (due to the buffer) resource, reminiscent of bandits with knapsacks (BwK) by (Badanidiyuru, 2018) and related budgeted-bandits (Xia et al., 2015). There is an extensive literature on this subject. The affine penalty looks like a static Lagrangian relaxation of the original setting, indeed, an additional discussion could make it easier for bandit community to grasp the ideas in this work. Additionally, this paper has unique features, like this context-like and time-dependent backlog $q_t$, and these can be expressed to position the paper better.\n\n- Related to the above point and this paper, there is prior work on budgeted-bandits with interrupts and right-censored feedback (e.g., Cayci et al., 2019), where an early-exit amounts to an interrupt that leads to forgoing a costly arm-pull and its instantaneous reward under capacity constraints. The model may be relevant to the discussion here. My impression is that the non-stationarity in this paper via queue-length dynamics as a state that evolves according the past actions distinguish the problem from the existing models, but this distinction is not clearly articulated.\n\n- The experiments could be enriched. For instance, a sliding-window UCB can be a good fit for this non-stationary problem setting with the workload drift.\n\n- The penalty in the experiments is affine with a single slope. In order to see the impact of the slope and also non-linearity, it may be insightful to consider steeper affine penalties or convex penalties.\n\n**References**\n\nBadanidiyuru, Ashwinkumar, Robert Kleinberg, and Aleksandrs Slivkins. \"Bandits with knapsacks.\" Journal of the ACM (JACM) 65, no. 3: 1-55, 2018.\n\nXia, Yingce, Haifang Li, Tao Qin, Nenghai Yu, and Tie-Yan Liu. \"Thompson sampling for budgeted multi-armed bandits.\" In Proceedings of the 24th International Conference on Artificial Intelligence, pp. 3960-3966, 2015.\n\nCayci, Semih, Atilla Eryilmaz, and Rayadurgam Srikant. \"Learning to control renewal processes with bandit feedback.\" Proceedings of the ACM on Measurement and Analysis of Computing Systems 3, no. 2: 1-32, 2019."}, "questions": {"value": "See _Weaknesses_ above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vzZquzvExI", "forum": "Cmhs73WUqP", "replyto": "Cmhs73WUqP", "signatures": ["ICLR.cc/2026/Conference/Submission21534/Reviewer_kMaL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21534/Reviewer_kMaL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21534/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761830298748, "cdate": 1761830298748, "tmdate": 1762941824606, "mdate": 1762941824606, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This submission studies the problem of dynamic threshold adaptation for early-exit models from a systems scheduling perspective, that considers the buffer size of inputs pending to be processed to relax the confidence requirements for early exiting of samples. The proposed solution employs delta-softmax policies to stabilize training under stochastic loads, while the proposed monotone parametric thresholds aid generalization at deployment time."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The systems perspective of the proposed approach, incorporating the number of pending tasks in the dynamic adaptation of thresholds for early-exiting is a novel and interesting approach, with practical applications.\n- The proposed solution is theoretically grounded, and combines several carefully crafted components, the contribution and effectiveness of which is supported by empirical evaluation results."}, "weaknesses": {"value": "The main drawback of this submission are the very restricting assumptions adopted throughout the methodology and experimental sections:\n- The focus on single early-exit models contradicts common practice that adopt multi-exit architectures offering diverse latency-accuracy characteristics (particularly as model depth is continuously growing). \n- The evaluation of the proposed approach in a single model, and additionally focusing solely on the outdated CiFAR-10 datasets, is also not on par with common practice in ML venues.\n- The focus of this work (throughout the manuscript) on the examined heterogeneous testbed, is not adequately justified by the technical contributions presented. It is unclear how the proposed method would perform in single-GPU or cloud-based settings, where the majority of AI-based workloads with queueing systems are deployed.  \n- Is the Poisson process used to model the request arrival a good proxy for real-world settings? Consider adding a reference to support this, as well as provide statistics about the queue length with and without the proposed solution."}, "questions": {"value": "Please consider replying on the comments raised in the weaknesses section above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "2rQjtnd9vg", "forum": "Cmhs73WUqP", "replyto": "Cmhs73WUqP", "signatures": ["ICLR.cc/2026/Conference/Submission21534/Reviewer_gh5Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21534/Reviewer_gh5Q"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21534/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761953637127, "cdate": 1761953637127, "tmdate": 1762941823833, "mdate": 1762941823833, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the problem of early-exit threshold selection in Early-Exit Neural Networks (EENNs), aiming to balance computational efficiency and inference accuracy. To address this, the authors propose a bandit-based framework for learning early-exit decision policies. Specifically, a policy gradient algorithm is developed using Tsallis-softmax parameterization for adaptive threshold learning, and a parameterized UCB algorithm is introduced to incorporate domain knowledge about the monotonic relationship between backlog and urgency. The proposed methods are empirically evaluated on a heterogeneous hardware testbed."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The strength of the paper is the real experiments on testbeds including Raspberry Pi and MiniPC."}, "weaknesses": {"value": "The weaknesses of this paper are listed below.\n\n- The paper lacks justification for adopting an online bandit formulation for learning early-exit thresholds.  The early-exit policy can be optimized offline using supervised or reinforcement learning methods, and the paper does not clearly explain why an online learning framework with exploration costs is necessary for this problem.\n \n- The bandit algorithm design appears conceptually weak. The policy design in Algorithm 1 is insufficiently motivated, and the choice of policy gradient methods for this setting is not theoretically sound.\n\n- The paper claims robustness of the proposed methods, yet no theoretical analysis or empirical evidence is provided to substantiate this claim. It remains unclear which components of the design contribute to robustness."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BivXITna7Y", "forum": "Cmhs73WUqP", "replyto": "Cmhs73WUqP", "signatures": ["ICLR.cc/2026/Conference/Submission21534/Reviewer_3rGZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21534/Reviewer_3rGZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21534/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762405079457, "cdate": 1762405079457, "tmdate": 1762941823597, "mdate": 1762941823597, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focus on the online scheduling of exiting threshold for early-exit neural networks (EENN), showing that fixed confidence thresholds fail under realistic queueing and resource constraints. By introducing buffer-aware bandit and policy-gradient algorithms—including a Tsallis-softmax variant and a monotonic UCB model—the authors demonstrate significantly improved accuracy–latency tradeoffs on a real heterogeneous client-server testbed."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "1. Strong practical motivation: The paper addresses an important and realistic problem: fixed early-exit thresholds degrade under real-world conditions such as buffer limits, queueing delays, and latency constraints. The motivation is well-grounded in deployment realities rather than purely theoretical considerations.\n2. Adaptive Early-exiting threshold control: The proposed algorithms combine bandit / policy-gradient methods with queue dynamics, offering a way to trade off accuracy and number of discarded samples in online environments.\n3. Empirical improvements:The proposed methods yield large reductions in loss ratio (up to 83%) and improve overall score and goodput, showing practical significance rather than incremental gains.\n4. scalability: can be extended to EENN with multiple exits."}, "weaknesses": {"value": "Overall: The motivation is strong, but the chosen online algorithms lack sufficient analysis and comparison.\n\n1. The metrics used in the paper are accuracy, loss ratio, and their derived formulas, which only measure how many samples are dropped due to buffer overflow and do not account for latency. Given that the backlog is fully observable before every early-exit decision, a simple naive or greedy policy—sending all samples to the final layer as long as the buffer is not full, and only early-exiting when approaching overflow—might achieve an even higher score or not, yet such a baseline is not evaluated.\n2. The authors formulate threshold adjustment as a bandit problem, but the paper does not clarify what is unique about this formulation in the context of EENNs or what particular issues or challenges arise, compared to other general bandit problems. \n3. The paper proposes four online algorithms, but lacks theoretical analysis, such as regret bounds or convergence rates. Most of the evidence relies on empirical results, and the comparison is mainly against static-threshold methods. Is there any other work on EENN also explored the dynamic threshold methods? \n4. The authors claim their methods are “robust” policy-gradient and “robust” UCB, but the analysis does not convincingly support this. For example, in the robust policy-gradient case, Tsallis-softmax seems to mainly increase exploration rather than robustness.\n5. The dataset used for evaluation is overly simple (only CIFAR-10). The offloading cost function chosen in experiment o(q)=0.1q−0.05 is seemingly hand-crafted without additional explanation or justification."}, "questions": {"value": "1. I think the policy gradient methods are also constrained to quantized threshold class space since you are using softmax for gradient ascent, which means in essence, its' a classification problem with finite classes (finite choice of threshold in this case).\n2. Typo in Algo 1 line12."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "d9dZgDmqQh", "forum": "Cmhs73WUqP", "replyto": "Cmhs73WUqP", "signatures": ["ICLR.cc/2026/Conference/Submission21534/Reviewer_B6xC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21534/Reviewer_B6xC"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission21534/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762508150194, "cdate": 1762508150194, "tmdate": 1762941823372, "mdate": 1762941823372, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper study early-exit neural networks (EENNs) as a buffer-aware scheduling problem. The controller sets a confidence threshold and receives reward $0$ on early exit and $r_t=\\max(C_L-C_I,0)-o(q)$ otherwise, with an affine queue penalty $o(q)=\\mu q-\\kappa$ that trades accuracy gains for congestion costs.  Two learning families are proposed: (i) a policy-gradient variant using a Tsallis/$\\delta$-softmax policy with a bespoke gradient update, and (ii) a structured UCB that enforces a monotone linear threshold.  Experiments use a Raspberry Pi MiniPC edge cloud testbed on CIFAR-10 with stationary and easy$\\leftrightarrow$hard blur regimes, reporting improvements in a custom Score and Goodput."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Clean queue-aware reward connecting information gain and backlog pressure; straightforward to implement. \n- Simple, interpretable monotone structure in UCB ($\\alpha$ increases with $q$). \n- End-to-end pipeline on real hardware with reproducibility notes/code link."}, "weaknesses": {"value": "- Limited theory. No regret or identification guarantees for the structured UCB class; no analysis for $\\delta$-softmax PG under queue-dependent and shifting rewards. Even a finite-arm discretization bound or a monotone-policy identification result would help.\n- Limited external validity. CIFAR-10 only, one mid-network exit, fixed Poisson arrivals. No stress tests with bursty/heavy-tailed inter-arrivals, multi-exit architectures, or different model families.  \n- Metric design. Heavy reliance on Score Accuracy LossRatio and Goodput without SLA/tail-latency metrics or ablations on the penalty function makes practical impact unclear.  \n- Modest novelty. The $\\delta$-softmax update is carefully derived yet reads like an engineering variant without broader theoretical insight or guarantees."}, "questions": {"value": "- Can you provide any regret or sample-complexity statement for the monotone UCB class—or explain why it is provably hard?\n-  What changes under nonlinear queue penalties (convex or SLA-style piecewise)? Does $\\alpha(q)$ change qualitatively? \n- Can $\\delta$ be adapted online with a principled objective, rather than tuned to $1.75$ on this setup? \n- How does the method behave with multiple exits and bursty arrivals (beyond Poisson)?\n- Please compare to stronger baselines: learned threshold regressors; richer contextual bandits; recent early-exit schedulers beyond tabular UCB/PG."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "119YG9Fcdd", "forum": "Cmhs73WUqP", "replyto": "Cmhs73WUqP", "signatures": ["ICLR.cc/2026/Conference/Submission21534/Reviewer_8B4Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21534/Reviewer_8B4Q"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission21534/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762538887176, "cdate": 1762538887176, "tmdate": 1762941822832, "mdate": 1762941822832, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}