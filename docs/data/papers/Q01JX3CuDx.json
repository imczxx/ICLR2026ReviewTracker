{"id": "Q01JX3CuDx", "number": 20096, "cdate": 1758302431159, "mdate": 1759897002082, "content": {"title": "On the Expressive Power of GNNs for Boolean Satisfiability", "abstract": "Machine learning approaches to solving Boolean Satisfiability (SAT) aim to replace handcrafted heuristics with learning-based models. Graph Neural Networks have emerged as the main architecture for SAT solving, due to the natural graph representation of Boolean formulas. We analyze the expressive power of GNNs for SAT solving through the lens of the Weisfeiler-Leman (WL) test. As our main result, we prove that the full WL hierarchy cannot, in general, distinguish between satisfiable and unsatisfiable instances. We show that indistinguishability under higher-order WL carries over to practical limitations for WL-bounded solvers that set variables sequentially. We further study the expressivity required for several important families of SAT instances, including regular, random and planar instances. To quantify expressivity needs in practice, we conduct experiments on random instances from the G4SAT benchmark and industrial instances from the 2024 SAT competition. Our results suggest that while random instances are largely distinguishable, industrial instances often require more expressivity to predict a satisfying assignment.", "tldr": "We study the expressive power of GNNs for SAT solving, showing that even the full Weisfeiler-Leman hierarchy cannot distinguish satisfiable instances from unsatisfiable, and that industrial instances often require more expressivity than random ones.", "keywords": ["SAT", "GNN", "Weisfeiler-Leman", "expressivity"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9110344a5ffba17d2455ea39fcdcc09f7a72a400.pdf", "supplementary_material": "/attachment/7d2a0a14c33b3336d867d07df05c55542f2c46fc.zip"}, "replies": [{"content": {"summary": {"value": "The paper analyzes the expressive capabilities of Graph Neural Networks (GNNs) in the context of SAT solving. The authors particularly look at the Literal-clause graphs with negation connections (LCNs), one of the standard representation used in GNNs for SAT solving. The authors then theoretically prove which families of problems GNNs can and cannot distinguish, using the Weisfeiler-Lehman (WL) test, a well known expressivity analysis technique for GNNs. With experiments, the authors assess whether WL-powerful architectures are, in principle, capable of predicting satisfying assignments on a wide range of benchmark instances including randomly generated and competition benchmark instances. The results show that while almost all random instances are WL-distinguishable, many SAT competition instances are indistinguishable, showing the limitations of GNNs for industrial SAT solving."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The theoretical results imply that with LCNs, any Message Passing Neural Network based models cannot fully distinguish between SAT and UNSAT instances for certain families of problems such as 3-SAT, even when given partial assignment information.\n- The authors conduct experimental results to determine whether instances in a benchmark set are WL-distinguishable or not, with the experiments being done on a wide range of benchmarks sets.\n- The paper provides insights into the limitations of GNNs for SAT solving, which is an important topic given the recent interest in using machine learning for combinatorial optimization problems."}, "weaknesses": {"value": "- The theoretical results are limited to LCNs, due to the limitations of expressivity analysis with WL tests as stated in the Appendix. While I understand LCNs to be a common approach of using GNNs for SAT solving such as in NeuroSAT, VCGs are also widely used such as in [1], and the paper would greatly benefit from discussing their insights, other than just briefly stating that it is not possible to perform expressivity analysis on them. I personally think that as VCGs incorporate polarity information directly into the graph edges, it allows them to distinguish graphs for formulas such as those in Figure 2.\n- The random instances from G4SATBench may not be as informative as ones from the SAT competition. To my understanding, this comes down to whether the benchmark was able to randomly produce any problem that is difficult to solve. If performing evaluations on random instances were the objective, the random track from the 2018 SAT competition may be better suited in this regard.\n- I see no reason to limit the experimental results to the 2024 SAT competition benchmarks. Including benchmarks from previous years would only strengthen the experimental contributions.\n\n[1] Yolcu, E., & Póczos, B. (2019). Learning Local Search Heuristics for Boolean Satisfiability. In H. M. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché‑Buc, E. B. Fox, & R. Garnett (Eds.), Advances in Neural Information Processing Systems 32 (NeurIPS 2019) (pp. 7990–8001).\n\n\nMinor issues:\n- The graph visualization in Figure 1 does not match up with the formula given. I believe that C6 should be C1, if we assign clause numbers in order of appearance.\n- Figure 2 seems to be in the middle of the references section.\n- Citations are not formatted correctly; they are missing parentheses. For example \"variables Heule et al. (2024)\" at L123 should be \"variables (Heule et al., 2024)\".\n- In L132 and L137, $\\chi^\\ell(v) := (\\chi^{\\ell-1}(v), \\{ \\{ \\chi^{\\ell-1}(v) : w \\in N(v) \\} \\})$ should be written as $\\chi^\\ell(v) := (\\chi^{\\ell-1}(v), \\{ \\{ \\chi^{\\ell-1}(w) : w \\in N(v) \\} \\})$ (the $v$ should be $w$ in the inner set).\n- In L412, it says \"the only family with some formulas that could not be solved by WL is the k-clique\", but Table 4 clearly shows k-vercov as another family that WL could not fully solve."}, "questions": {"value": "- Is it possible at all to extend the WL-test to allow for expressivity analysis of VCGs?\n- Are there other suitable graph representations of SAT problems that would be better than LCNs in terms of expressivity? What would the best representation look like, if any?\n- Why were harder instances (hard+, hard++) provided only for 3-SAT? Is it not possible to generate harder instances for other problems as well?\n- The experimental analysis were done on SAT instances only. Would it be possible to extend the analysis to UNSAT instances?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PuStUg5nKb", "forum": "Q01JX3CuDx", "replyto": "Q01JX3CuDx", "signatures": ["ICLR.cc/2026/Conference/Submission20096/Reviewer_2HM5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20096/Reviewer_2HM5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20096/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761689700515, "cdate": 1761689700515, "tmdate": 1762932991836, "mdate": 1762932991836, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The power of GNNs can be understood by studying WL-testing, which is basically a form of graph isomorphism testing. On a high level, GNNs cannot distinguish some graphs from each other and this is reliant on how the weisfeiler lehman kernel behaves on these graphs. The paper shows that even if GNNs were \"maxed out\" on the WL power hierarchy, there would be SAT instances that would be difficult for them since it is difficult for the WL process itself (this is actually not surprising, given that SAT is a hard problem) but more interestingly, it creates these hard instances constructively, which is better than showing that they exist. Empirically, it then studies real SAT instances. Probably as expected, random SAT instances can fall to WL , and contest SAT instances don't fall as easily."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper's contribution is mostly theoretical. One of the best aspects is that they actually construct the hard family of instances, which is likely to be useful for further work more than a simple proof of existence. Also, although the paper is about GNNs on paper, most of the results are about the WL kernel's suitability for SAT, which is technically a broader problem. In reality, the paper is about finding the \"blind spots\" of the WL kernel as a method."}, "weaknesses": {"value": "The empirical study is fairly surface level and misses the mark. We already expect that random instances are easy, contest instances are harder, and hard-by-construction instances are computationally hard. But the main problem is as follows. The power of a GNN is only upper bounded by the power of a WL test. Showing how well the WL test performs on various SAT instances, then, is meaningful only in one direction - if it fails, certainly we don't expect GNNs to succeed, but if it succeeds or performs in an intermediate manner, we *cannot actually confirm* that GNNs will follow ! Thus, the construction of the hard instances is meaningful \"back to GNNs\" though WL is being studied, but the studies on empirical \"actually existing\" instances are statements that only mean something wrt the WL kernel, not GNNs themselves."}, "questions": {"value": "It seems to me that the paper is actually about the suitability of the WL kernel to SAT, and can be thought of better that way. Do you agree ? From a GNN point of view, the empirical section is actually not meaningful (as pointed out under weaknesses)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MyzmVN8s93", "forum": "Q01JX3CuDx", "replyto": "Q01JX3CuDx", "signatures": ["ICLR.cc/2026/Conference/Submission20096/Reviewer_4PqT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20096/Reviewer_4PqT"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20096/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761697487119, "cdate": 1761697487119, "tmdate": 1762932991126, "mdate": 1762932991126, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper analyzes the expressive limits of GNNs on SAT problems using a literal–clause–negation (LCN) graph representation. It proves that even the full Weisfeiler–Lehman (WL) hierarchy cannot, in general, distinguish satisfiable from unsatisfiable 3-SAT formulas, via a parity-based construction. The authors further show that this limitation persists in sequential variable-assignment settings, linking theory to neural SAT solvers. They complement the negative results with positive findings (e.g., PlanarSAT identifiable by 4-WL) and empirical WL-color diagnostics on random and industrial benchmarks. The work provides a clear, rigorous theoretical contribution, though experiments remain illustrative rather than learning-based."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The presentation is clear and well-organized with logical progression from simple examples to full results, making complex theoretical concepts accessible while providing complete proofs in appendices. The analysis is nuanced, including both impossibility and positive results (e.g., PlanarSAT separability, random instances).\nThe authors are transparent about the scope of their results, clearly acknowledging that their experiments test only necessary conditions for expressivity and do not demonstrate actual learning performance.\nThe main theoretical contribution (Theorem 5.3) is rigorous, proving that even the full n-WL hierarchy cannot distinguish SAT/UNSAT formulas in general, and this limitation transfers to practical sequential solvers (Corollary 5.5), showing that even after Θ(n) variable assignments, the indistinguishability persists - meaningfully connecting fundamental expressivity limits to realistic GNN-based SAT solving approaches. The link to Tseitin formulas from proof complexity is noteworthy."}, "weaknesses": {"value": "The paper lacks any trained GNN experiments, making it unclear whether the theoretical limitations observed actually translate into performance gaps in practice.  The experiments are purely diagnostic and do not involve any trained GNNs, leaving the practical impact of the theoretical limits untested.\n \nLacks an explanation for why industrial instances require higher expressivity than random ones. The paper does not discuss possible ways to overcome the identified expressivity limits, leaving the reader without guidance on how future GNN architectures might address these shortcomings."}, "questions": {"value": "Given that the experiments are WL-diagnostic rather than learned, do you plan to test whether these expressivity limits manifest in actual trained GNN solvers?\n\nGiven that even n-WL cannot distinguish SAT/UNSAT in general, what architectural modifications beyond standard MPNNs (e.g., augmentations, auxiliary features, hybrid approaches) do you believe could address these expressivity bottlenecks while remaining scalable?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FrK5ylM4G8", "forum": "Q01JX3CuDx", "replyto": "Q01JX3CuDx", "signatures": ["ICLR.cc/2026/Conference/Submission20096/Reviewer_cb9V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20096/Reviewer_cb9V"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20096/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761943785630, "cdate": 1761943785630, "tmdate": 1762932990567, "mdate": 1762932990567, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper analyzes the expressiveness power of graph neural networks (GNNs) for the Boolean constraint satisfiability problems. The analysis is based on the observation that the power of GNNs is bounded by Weisfeiler-Leman (WL) test, which is designed to test graph isomorphism. Due to such fundamental limitation, GNNs are proved to be insufficient to solve NP-Complete problems. Furthermore, empirical evaluations are performed on the G4SAT benchmark and SAT Competition 2024."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- this paper consolidates many known theoretical results about GNNs and WL test as well as empirical datasets\n- background knowledge about SAT solving, GNNs, graph isomorphism, and WL tests are carefully illustrated"}, "weaknesses": {"value": "- the proposed analysis is not novel, since all reported results are either well-known or immediately implied by previous works. Particularly, Xu et al. (2019) has pointed out that GNNs are bounded by the WL-test, which cannot even solve the graph isomorphism problems that are not as strong as the NP-Complete problems like Boolean satisfiability. \n- the presented theoretical analysis is largely rephrasing previous known results therefore does not contribute new insights\n- there are some empirical observations regarding the number iterations for WL to converge, however, which does not provide meaning guidance on solving satisfiability problem with GNNs"}, "questions": {"value": "Besides consolidating previous known results, which is a meaningful contribution in the perspective of literature survey, what new insights either theoretical or empirical does this paper provide?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "zZBu3STjtk", "forum": "Q01JX3CuDx", "replyto": "Q01JX3CuDx", "signatures": ["ICLR.cc/2026/Conference/Submission20096/Reviewer_ZqMt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20096/Reviewer_ZqMt"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20096/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762465118506, "cdate": 1762465118506, "tmdate": 1762932990006, "mdate": 1762932990006, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}