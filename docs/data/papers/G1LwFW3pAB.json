{"id": "G1LwFW3pAB", "number": 9939, "cdate": 1758150828688, "mdate": 1759897684307, "content": {"title": "From Comparison to Composition: Towards Understanding Machine Cognition of Unseen Categories", "abstract": "Humans are known to acquire and generalize visual concepts through a natural compare–then–compose process. We ask whether this mechanism can provide principled conditions under which machines generalize existing knowledge to unseen categories. In this work, we formalize cognition of the unseen as two complementary mechanisms for deep learning models: comparison, which uncovers latent concepts by capturing cross-category variations among seen classes, and composition, which extrapolates these concepts continuously to unseen classes. Even without parametric assumptions, we establish identifiability guarantees for learning latent concepts and unseen categories via sufficient contrast and independent support separation, denoted as Comparison–C}omposition Cognition (C^3). Guided by these results, we instantiate a structurally constrained generative model mirroring our theoretical assumptions. Our results on simulated data corroborate our theoretical claims and the effectiveness of our proposed methodology. In the setting of visual cognition with unseen labels, aka On-the-fly Category Discovery, our instantiated approach improves state-of-the-art baselines by +3.8\\% average accuracy across fine-grained benchmarks. Taken together, our framework offers principled conditions and practical guidance for representational compositionality, offering a theory-to-practice path for generalization to unseen categories.", "tldr": "A provably representation learning framework for unseen category cognition with providing theoretical guarantees and estimation framework through comparison and composition.", "keywords": ["Concept Learning; Cognition Science; Novel Category Discovery;"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8ca85688747fcefc7b00c07a42b1e60eebfa29c9.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a new approach for the problem of online category discovery. It comprises two parts. In the first part, a theoretical formulation of the problem is presented. This is based on a stochastic model where old and new categories are modelled as sets of concepts. Statistical assumptions are given for model identifiability, as well as for the ability of the model to detect and recognise new categories as they are encountered in the data stream. The second part of the paper presents a practical deep learning formulation that is inspired by the first part. When assessed on standard benchmarks for this task, this new formulation performs well. Some ablations illustrate the importance of various elements of the formulation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Category discovery captures an important problem where machine learning still struggles. Online category discovery is a variant of this problem somewhat closer to a real-life application, where new data streams through and new categories must be detected and instantiated on the fly. These are difficult problems worth looking at.\n\n* Insofar as I can tell, the authors propose a reasonable formulation for online category discovery supported by a thorough formal analysis.\n\n* The practical instantiation of this formulation is shown to perform relatively well on canonical benchmarks in the area.\n\n* Ablations show the importance of at least some of the key design choices.\n\n* A long appendix provides many important aspects of the formulation and implementation that are missing in the main paper."}, "weaknesses": {"value": "The approach is rather complex, involving a number of regularisers and steps that would be difficult to reproduce based solely on the description in the paper (even once one considers the thorough appendix). The authors do not mention whether code will be released.\n\nOn a fundamental level, this paper assumes that categories map neatly to combinations of \"base concepts\", and that new categories are formed as new combinations of concepts that are, otherwise, already known. This sounds like a fundamental limitation which should probably be acknowledged and discussed a bit more.\n\nThere are no illustrations of what the concepts discovered by the algorithms are, particularly on the computer vision dataset. Are these interpretable in any way?\n\nThe main paper is not entirely self-contained and some critical information is missing, which makes it unnecessarily difficult to understand:\n\n* The problem formulation on line 264 is incomplete, and one *must* read the references to even understand what problem is being solved. Specifically, I could not understand the sentence [the model] \"classifies streaming query instances in real-time without access to labels from novel categories\" until reading Du et al. 2023. The task is poorly defined in the paper, and so are the evaluation metrics.\n\n* It would have been very helpful to expand on several of the introductory materials. What is a \"basis distribution\" in Eq. (1) (line 107)? Why does it make sense for $f$ to list $\\mathbf{z}$ both as an input and as an output (line 131)? How are Definition 1 and Eq. (1) connected? One is required to be familiar with prior work, and with Markov networks and other background, to fill in the gaps.\n\n* In Eq. (4), do you mean to say that $p(\\hat \\mathbf{c}|y)$ is independent of $y$?\n\n* In Eq. (5), is $[\\hat\\mathbf{c}_i]$ a vector? Line 106 suggests that it is a scalar instead. If so, why do you need a vector norm?\n\nMinor: Line 408 suggests that Table 1 reaches a peak at $n_s=24$, but the table ends at 24. How can you tell this is a peak?"}, "questions": {"value": "Please see the questions included in the \"weaknesses\" section above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xDZYuVxbJH", "forum": "G1LwFW3pAB", "replyto": "G1LwFW3pAB", "signatures": ["ICLR.cc/2026/Conference/Submission9939/Reviewer_MWi7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9939/Reviewer_MWi7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9939/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761484091825, "cdate": 1761484091825, "tmdate": 1762921389873, "mdate": 1762921389873, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes C3 (Comparison–Composition Cognition), a cognitive-inspired theoretical and practical framework for generalizing to unseen categories. The authors formalize human-like “compare–then–compose” reasoning into two complementary mechanisms: comparison, which extracts latent concepts by capturing cross-category variation, and composition, which recombines these concepts to recognize unseen categories. Experiments on eight fine-grained benchmarks under the On-the-Fly Category Discovery (OCD) setting demonstrate consistent performance improvements."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.This paper is mainly for providing formal identifiability guarantees for concept-based generalization. It features rigorous derivations, and its stepwise logic has a clear structure: first contextual separation, then semantic disentanglement, and ultimately compositional generalization.\n2.Framing unseen-category cognition as “from comparison to composition” offers a interpretable metaphor that aligns with cognitive science findings.\n3.Every theoretical assumption (A1–A6) is explicitly operationalized in the model (e.g., flow for smooth density, sparse MoE for structure, prototype and hashing losses for semantic contrast)."}, "weaknesses": {"value": "1.The exposition is heavy and unfocused. Many formulas are presented without sufficient intuition or geometric explanation. Readers must infer the motivation behind several derivations (e.g., partial derivatives of log-density in Theorem 2), making the theoretical contribution harder to follow.\n2.While the framework borrows cognitive terminology “compare–then–compose”, its connection to actual cognitive mechanisms is largely metaphorical. A clearer justification for how these processes correspond to neural computations would strengthen the interdisciplinary claim.\n3.Although the framework is complete, it feels assembled rather than organically derived. Each assumption leads to a separate engineering component.\n4.Empirically, results are solid but do not reveal new phenomena or insights. The performance gains are incremental, and no analysis shows why the comparison–composition pipeline generalizes better than alternative factorization approaches.\n5.The paper does not report computational efficiency, convergence stability, or scaling behavior; the additional flow and MoE modules could impose extra overhead."}, "questions": {"value": "1.How sensitive are the identifiability results to approximate violations of A1–A6? Are these conditions ever testable in real datasets?\n2.Could the use of multiple independent regularizers (flow likelihood, hashing, prototype contrast) lead to competing gradients that distort the latent structure?\n3.Would a simpler variational or contrastive formulation achieve similar results without flow modeling?\n4.How can the authors ensure that the claimed “composition” corresponds to interpretable recombination of learned semantic atoms, rather than a generic feature interpolation? Is there any visual or quantitative evidence to support this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "41bW6sbQ3g", "forum": "G1LwFW3pAB", "replyto": "G1LwFW3pAB", "signatures": ["ICLR.cc/2026/Conference/Submission9939/Reviewer_PD1H"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9939/Reviewer_PD1H"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9939/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761916634759, "cdate": 1761916634759, "tmdate": 1762921389428, "mdate": 1762921389428, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a new framework, Comparison–Composition Cognition (C3), inspired by human cognitive processes, to address the challenge of generalizing to unseen categories. The framework divides learning into two mechanisms: comparison, which uncovers latent concepts by contrasting within seen classes, and composition, which combines these concepts to predict unseen categories. The method is theoretically grounded, with identifiability guarantees for both learning latent concepts and for generalizing to novel categories. It is experimentally validated through On-the-fly Category Discovery (OCD) benchmarks, showing a 3.8% improvement in accuracy over state-of-the-art methods. The paper suggests that concept-based representations, following the compare-then-compose approach, can enable open-world generalization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Novel framework: Introduces a theoretically-grounded framework, C3, which mimics human cognition for unseen category recognition via comparison and composition.\n\n- Theoretical guarantees: Establishes identifiability results, providing confidence that latent concepts can be learned and generalized to unseen categories.\n\n- Solid experimental results: Achieves notable improvements over existing methods on OCD benchmarks, demonstrating the practical viability of the approach."}, "weaknesses": {"value": "- Incremental contribution: While the framework is innovative, it builds on existing concepts from the literature (e.g., contrastive learning, compositionality), making the contribution seem incremental.\n\n- Limited scalability discussion: The paper does not address how the proposed method might scale with larger models or datasets, especially in real-world applications.\n\n- Lack of detailed ablation study: The paper could benefit from a deeper ablation study to evaluate the individual contributions of comparison and composition mechanisms."}, "questions": {"value": "- How does the method perform when applied to datasets with a higher number of unseen categories?\n\n- What would be the impact of integrating this method with large-scale foundational models like GPT or CLIP?\n\n- How does the proposed C3 framework handle noisy or ambiguous data in unseen categories?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "bSZ4VeuEEZ", "forum": "G1LwFW3pAB", "replyto": "G1LwFW3pAB", "signatures": ["ICLR.cc/2026/Conference/Submission9939/Reviewer_Tdof"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9939/Reviewer_Tdof"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9939/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761946461838, "cdate": 1761946461838, "tmdate": 1762921388838, "mdate": 1762921388838, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework, named Comparison-Composition Cognition, for generalizing to unseen visual categories, inspired by human cognitive mechanisms. The authors formalize the problem as a two-step process: (1) comparison, which aims to identify disentangled semantic and contextual concepts from seen categories, and (2) composition, which recombines these learned concepts to recognize novel categories. The core contribution is a set of theoretical results that provide identifiability guarantees for these latent concepts under specific assumptions like sufficient data contrast and support separation. To operationalize this framework, the authors design a deep generative model for the On-the-fly Category Discovery (OCD) task."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is motivated by the human cognitive process of understanding new concepts through comparison and composition. It aims to build a principled framework for machine learning models to generalize to unseen categories by mimicking this process.\n\n2. It formalizes this process as Comparison-Composition Cognition. \"Comparison\" is framed as a latent variable identification problem to uncover disentangled concepts from seen data. \"Composition\" is the process of using these learned concepts to recognize unseen categories.\n\n3. The paper provides theorems establishing identifiability guarantees for latent concepts (both contextual and semantic) under specific conditions, such as sufficient cross-category contrast and sparse arrangements (Theorems 1 & 2). It also provides conditions for generalizing to unseen categories via composition, namely support separation and marginal coverage (Theorem 3).\n\n4. The theory is instantiated as a generative model for the On-the-fly Category Discovery  task. The model uses a frozen DINO encoder, a learnable mask to separate semantic and contextual features, a sparsely-gated Mixture-of-Experts (MoE) and a normalizing flow to model the structure of semantic concepts, and prototype/hashing losses to enforce discriminability and concept separation."}, "weaknesses": {"value": "1. The primary weakness of this paper lies in the tenuous connection between the ambitious theoretical framework and the practical implementation. The strong assumptions in the theorems are only loosely and indirectly addressed by the chosen technical components. The \"Sufficient Contrast\" assumption (A2, A3), which requires linear independence of vectors of log-density derivatives, is a highly specific mathematical condition. The paper claims this is satisfied by using a standard prototype-based supervised loss (L_proto). This link is weak and not justified; there is no guarantee that optimizing a prototype loss leads to the satisfaction of this complex condition.\n\n2. When stripped of its theoretical narrative, the proposed method appears to be a complex but incremental combination of existing techniques rather than a breakthrough.\n- The architecture is essentially a sophisticated VAE that uses a learnable mask for disentanglement (a common idea), a sparsely-gated MoE plus a normalizing flow for structured modeling (both well-established tools), and prototype/hashing losses for discriminability.\n- The core idea of using hashing and prototypes for category discovery has been explored by the main competitor this paper compares against (PHE: Prototypical Hash Encoding). The performance gain, while present, might be attributable to the increased complexity and more moving parts of the model rather than a fundamental conceptual advance.\n\n3. The \"Concept\" Framing is Not Empirically Validated: The paper is built around the idea of learning meaningful, disentangled concepts (e.g., \"white head,\" \"black wings\") like [2]. However, there is no qualitative or quantitative analysis to demonstrate that the learned latent variables z actually correspond to such interpretable concepts. The model might just be learning effective discriminative features. Without such evidence, the connection to human cognition and concept composition remains a compelling story but an unproven claim, diminishing the paper's main appeal.\n\n4. In the task of discovering general categories, there has already been similar work [1] that decomposes objects into combinations of various attributes (textual or visual) with MoE. I believe there needs to be more comparative discussion with the current work.\n\n[1] Dissecting Generalized Category Discovery: Multiplex Consensus under Self-Deconstruction. In ICCV, 2025.\n\n[2] OCRT: Boosting Foundation Models in the Open World with Object-Concept-Relation Triad. In CVPR, 2025."}, "questions": {"value": "1. The central narrative of the paper is about learning and composing concepts. Can you provide qualitative evidence (e.g., by traversing the learned latent space z and visualizing its effect on generated images) or quantitative analysis to show that the model is indeed learning disentangled and semantically meaningful concepts, as opposed to simply learning complex, entangled features that happen to be discriminative?\n\n2. The proposed method combines multiple advanced components (MoE, flows, hashing). The main competitor, PHE, also relies on prototypical hashing. Could you clarify the key technical innovation of your method that is responsible for the performance gain, beyond the theoretical framing and the increased architectural complexity? Is it the explicit separation of contextual/semantic factors, the structural modeling via flow, or another specific component?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "QQ81wIEB7M", "forum": "G1LwFW3pAB", "replyto": "G1LwFW3pAB", "signatures": ["ICLR.cc/2026/Conference/Submission9939/Reviewer_LNHk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9939/Reviewer_LNHk"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9939/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762059823899, "cdate": 1762059823899, "tmdate": 1762921388180, "mdate": 1762921388180, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}