{"id": "UFwgg44VZq", "number": 15455, "cdate": 1758251546928, "mdate": 1759897305883, "content": {"title": "ReTabAD: A Benchmark for Restoring Semantic Context in Tabular Anomaly Detection", "abstract": "In tabular anomaly detection (AD), textual semantics often carry critical signals, as the definition of an anomaly is closely tied to domain-specific context. However, existing benchmarks provide only raw data points without semantic context, overlooking rich textual metadata such as feature descriptions and domain knowledge that experts rely on in practice. This limitation restricts research flexibility and prevents models from fully leveraging domain knowledge for detection. ReTabAD addresses this gap by Restoring textual semantics to enable context-aware Tabular AD research. We provide (1) 20 carefully curated tabular datasets enriched with structured textual metadata, together with implementations of state-of-the-art AD algorithms—including classical, deep learning, and LLM-based approaches—and (2) a zero-shot LLM framework that leverages semantic context without task-specific training, establishing a strong baseline for future research. Furthermore, this work provides insights into the role and utility of textual metadata in AD through experiments and analysis. Results show that semantic context improves detection performance and enhances interpretability by supporting domain-aware reasoning. These findings establish ReTabAD as a benchmark for systematic exploration of context-aware AD.", "tldr": "We introduce ReTabAD, the first context-aware tabular anomaly detection benchmark, which provides semantically enriched datasets and a zero-shot LLM framework.", "keywords": ["Tabular Anomaly Detection", "Anomaly Detection Benchmark", "Large Language Models"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2a5f9aaa97c6dbb751395072fbf9e73cf9328bc1.pdf", "supplementary_material": "/attachment/f1267a74d8b02f5100730964fafff96fd2b508a0.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel benchmark for tabular anomaly detection, comprising 20 datasets from diverse fields, including healthcare, finance, and biology. Those datasets are provided with:\n- as little processing as possible of numerical features to preserve their semantic information, \n- categorical text restoration and, \n- useful metadata including (i) dataset-level descriptions, e.g., dataset name, purpose, description; (ii) human-readable column (feature) descriptions; (iii) label description.\n\nTo motivate these modifications and additions to the datasets, the authors test in a One-Class Classification setting, a zero-shot LLM model with and without the added metadata. Their experiments demonstrate that including this metadata significantly enhances the anomaly detection performance of different LLM models (e.g., GPT-4.1, Claude-3.7-sonnet). Additionally, the experiments conducted also emphasize how adding meta-information regarding features and the overall dataset significantly enhances the ability of the LLMs to provide interpretable results."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "**S1**: The paper is easy to follow, well-written, and properly structured.\n\n**S2**: The proposed work **addresses a relevant caveat** of existing benchmarks for tabular anomaly detection. In particular, authors emphasize the importance of favoring the quality of datasets over their quantity. As mentioned in section 3.1, the authors select datasets so that *too-easy* datasets that have previously been used in the literature are discarded.\n\n**S3**: Their extensive experiments and ablation demonstrate the relevance of including metadata in the case of LLMs."}, "weaknesses": {"value": "**W1**: Some relevant and recent approaches have not been included in the benchmarks, e.g. [1, 2, 3]. It might be worth including them in the benchmark. All three models are open source, and [1,2] have been applied to the ADBench benchmark in [4].\n\n**W2**: While metadata and other additions proposed in the present work appear relevant for LLM-based AD approaches, they appear limited for pure ML-based methods.\n\n\n[1] Anomaly Detection for Tabular Data with Internal Contrastive Learning. *Tom Shenkar, Lior Wolf*. ICLR 2022\n\n[2] Beyond Individual Input for Deep Anomaly Detection on Tabular Data. *Hugo Thimonier, Fabrice Popineau, Arpad Rimmel, Bich-Liên Doan*. ICML 2024.\n\n[3] Disentangling Tabular Data Towards Better One-Class Anomaly Detection. *Jianan Ye, Zhaorui Tan, Yijie Hu, Xi Yang, Guangliang Cheng, Kaizhu Huang*. AAAI 2025\n\n[4]  DRL: Decomposed Representation Learning for Tabular Anomaly Detection. *Hangting Ye, He Zhao, Wei Fan, Mingyuan Zhou, Dan dan Guo, Yi Chang*. ICLR 2025."}, "questions": {"value": "**Q1**: As mentioned in **W2**, these additions to existing datasets can be relevant but are mostly targeted for LLM-based approaches that could appear as overkill when it comes to anomaly detection on tabular data. Do you have other approaches in mind, apart from LLMs, that could benefit from such augmented datasets (apart from feature engineering)?\n\n**Q2**: A core contribution of the present work also lies in **removing too easy** datasets as mentioned in **S2**. Those datasets often bias the benchmark's overall results.\nNevertheless, the proposed datasets in your benchmark still display a high average AUROC (>0.75 for all models listed in Table 3), which seems quite high. Real-life settings where OCC AD methods apply often include severely imbalanced datasets, where such metrics are rarely obtained (e.g., fraud detection). Have you considered including more severely imbalanced datasets? As shown in Table 7, very few datasets have an anomaly share of less than 10%.\n\n**Q3**: An interesting addition to Table 3, in particular for overall rank comparison, would be your vanilla LLM-based method without the metadata (Type A in Table 5)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lqiJxUF46o", "forum": "UFwgg44VZq", "replyto": "UFwgg44VZq", "signatures": ["ICLR.cc/2026/Conference/Submission15455/Reviewer_7nvM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15455/Reviewer_7nvM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15455/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760979106738, "cdate": 1760979106738, "tmdate": 1762925741479, "mdate": 1762925741479, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The submission makes two main contributions:\n\n - It provides augmented versions of 20 tabular anomaly detection datasets by adding detailed information around the columns, in particular, their full names and unnormalized values, textual descriptions of the meanings of the dataset and the columns, and the definitions of normality in terms of the ranges/sets of the values. This has the advantage of making evaluation textually-interpretable, enabling the use of LLMs.\n\n - A subsequent method for using an LLM in a zero-shot manner for identifying anomalies, given the textual context around a dataset.\n\nExperiments showcase the advantages of using this semantic information when prompting an LLM to identify anomalies in the proposed dataset."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The augmented datasets appear thoroughly upgraded with detailed semantic information around the tabular data. The overall motivation of aligning the problem of certain anomaly detection tasks with the underlying semantics is intuitive and sensible.\n\nThe LLM-based setup is a reasonable first attempt at such zero-shot anomaly detection, when prompting LLMs for the task. The ablations are a clear demonstration of LLMs being able to use additional semantic information to improve performance at the task."}, "weaknesses": {"value": "1. Perhaps the precise advantages of using LLMs in such a setting could be made clearer. \n - For instance, if we take the time to explicitly \"hardcode\" the meaning of anomalies through specifying normal ranges and detailed textual descriptions, why not equivalently write out computational filters encoding this meaning? E.g. instead of saying \"LB: Normal Range (5-95 percentile) = [118, 146]\", we could equivalently encode this with a probabilistic function that could reflect the severity of lying outside the normal range, likely with greater calibration to the semantics of the task if we use further domain knowledge to specify the normality model.  It would be truly interesting if it turned out that LLMs are aware of the gold normality model given the task specification, and internally use such a computation, but this feels very unlikely given contemporary LLM capabilities.\n - Another advantage of explicit encoding might be the interpretability of the anomaly scores; to my knowledge, LLMs are not well-recognized to output meaningfully-calibrated probabilistic scores.\n - The comparisons between the different types of prompts seems hard to disentangle, since only Type D explicitly specifies how to use the normal ranges to identify anomalies in `### Numerical Analysis`, which I'd naively expect to be very helpful.\n\n2. Anomaly detection problems aren't universally ones where the nature of the anomaly is pre-specifiable. In settings such as scientific discovery, for example, one can look for new patterns in data that weren't identified as an interesting axis of variation previously. It would be interesting if such things can be done zero-shot as well."}, "questions": {"value": "* in the prompts, it says 5th - 9th percentile for normal ranges, confirming if this is accurate? (or should it have been 5th - 95th?)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "96rzPNc7YU", "forum": "UFwgg44VZq", "replyto": "UFwgg44VZq", "signatures": ["ICLR.cc/2026/Conference/Submission15455/Reviewer_NrBy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15455/Reviewer_NrBy"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15455/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761475784916, "cdate": 1761475784916, "tmdate": 1762925739836, "mdate": 1762925739836, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "ReTabAD makes a significant contribution by pushing tabular anomaly detection towards a more semantic-aware paradigm, excelling particularly in benchmark construction and the design of a zero-shot LLM framework."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Provide a high-quality, resource-rich Benchmark. Innovative introduction and validation of a zero-shot LLM framework, establishing a baseline for semantic utilisation."}, "weaknesses": {"value": "1. While the lack of semantic context in existing benchmarks is clearly highlighted, the paper does not sufficiently explain why traditional methods cannot be easily extended (e.g., by incorporating text embeddings) to address this gap. \n\n2. The proposed concept of the conditional distribution p(x∣M) is somewhat vague and lacks a rigorous mathematical definition or a concrete modelling framework. It serves more as a high-level conceptual goal than a formally grounded theory.\n\n3. Could the limited number of anomaly samples in certain datasets result in unstable evaluation outcomes and reduced statistical reliability?\n\n4. The reliability of the LLM-generated reasoning texts is not assessed through human evaluation or detailed error analysis. It's unclear how often the explanations are factually correct or truly insightful.\n\n5. Perform more granular ablation studies to disentangle the individual contribution of each metadata component (domain, feature description, statistics)."}, "questions": {"value": "The author is requested to respond to all the points mentioned under the \"Weaknesses\"."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FKMl3CfrfL", "forum": "UFwgg44VZq", "replyto": "UFwgg44VZq", "signatures": ["ICLR.cc/2026/Conference/Submission15455/Reviewer_jhCt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15455/Reviewer_jhCt"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15455/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761882283451, "cdate": 1761882283451, "tmdate": 1762925738609, "mdate": 1762925738609, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on providing a tabular anomaly detection benchmark, which contains more textual metadata compared to existing benchmarks. In addition, it provides a new zero-shot LLM baseline for this domain."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "S1: The studied problem of constructing a textual tabular anomaly detection benchmark is important, and it is useful for the future research.\n\nS2: This benchmark incorporates extensive advanced and classical tabular anomaly detection baseline methods.\n\nS3: The new baseline is simple and effective. \n\nS4: The paper is clear and easy to follow."}, "weaknesses": {"value": "**Datasets perspective:** \n\nW1: The benchmark comprises only 20 datasets, which is significantly fewer than established benchmarks such as ADBench (84 datasets). This limited scale may restrict the comprehensiveness and statistical power of the evaluation.\n \nW2: The decision to exclude datasets where performance is already saturated (Line 181) may be overly restrictive. While such datasets may offer limited room for performance improvement, they remain valuable for evaluating other aspects such as model interpretability, robustness, and consistency. Their exclusion could narrow the scope of the benchmark and limit its utility for holistic model assessment.\n\n\nW3: The authors will annotate anomalies for new datasets as illustrated in Line 183. However, the process for ensuring annotation accuracy and consistency is not clearly described. Is it trustable? Inaccurate anomaly labels can significantly mislead model evaluation and subsequent research.\n\nW4: It is unclear how categorical features are processed for classical and deep learning baselines. \n\n**Proposed new method perspective:**\n\nW5: Why the Gemini-2.5-pro performs such significantly better than other LLMs according to Table 4? Is there any reasonable explanations? It remains unclear whether the observed gains are due to the proposed framework or inherent model superiority. Moreover, when the LLM is set to GPT, the performance of this method is the worst among all the baseline methods.\n\n\nW6: Based on W5, it seems that the zero-shot LLM method heavily depends on the model’s pre-existing knowledge, which may limit its applicability in privacy-sensitive or domain-specific scenarios where such prior knowledge is unavailable or unreliable. In contrast, traditional methods rely solely on the data’s intrinsic distribution, offering better generalization in such settings. The authors should discuss the limitations of their approach in real-world deployments where LLM knowledge alignment cannot be assumed.\n \n\nW7: The proposed method would query LLM to output the anomaly score for each sample. This is much different from other baseline methods, which rely on training to compute the anomaly score. How to ensure the anomaly score is reliable?\n\nW8: Table 6 and Figure 4 present feature attribution results, but it is unclear whether these are based solely on Gemini-2.5-pro or averaged across multiple LLMs. To ensure the generalizability of the findings, the authors should report attribution performance across all evaluated LLMs and discuss whether the observed improvements hold consistently.\n\n\nW9: Why the reported performance is not consistent with that in their original papers? For example, MCM achieves the AUC-ROC of 0.8902 on Campaign, but the reported performance in this paper is 0.761."}, "questions": {"value": "Please see the weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7jHqDgs59d", "forum": "UFwgg44VZq", "replyto": "UFwgg44VZq", "signatures": ["ICLR.cc/2026/Conference/Submission15455/Reviewer_jF5m"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15455/Reviewer_jF5m"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15455/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761903229668, "cdate": 1761903229668, "tmdate": 1762925738077, "mdate": 1762925738077, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}