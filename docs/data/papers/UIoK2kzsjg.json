{"id": "UIoK2kzsjg", "number": 19603, "cdate": 1758297587589, "mdate": 1759897030932, "content": {"title": "Deep Adaptive  Cross Domain  Learning for Continuous Pressure Wave Signal Recovery", "abstract": "Mud pulse telemetry (MPT) enables real-time downhole data transmission by generating continuous pressure\nwave signals in drilling fluid, supporting measurement and control during drilling. However, the signals are vulnerable to noise from the downhole environment, mud channel, and surface equipment, causing attenuation, distortion, and phase errors that hinder accurate reconstruction. Recent advances in deep learning offer promising solutions to these challenges but typically requires large amounts of labeled data, which are difficult and costly to obtain in field conditions. To address this issue, this paper proposes the Deep Adaptive Cross Domain Learning Network (**DACDL**), a framework featuring a novel noise adaptation mechanism that transitions from model-level to input-level adaptation.  Our approach introduces three core innovations:\n(1) An Episodic Learning Framework (**EL-Framework**)  that simulates domain shift by alternately learning from simulated (gaussian) and real-world (real-world gaussian, pump or oilfield) domains, enhancing few-shot adaptation under label scarcity; \n(2) A lightweight Adaptive Noise Learning Block (**ANL-Block**) that introduces sample-specific perturbations to align target input noise distributions with the source domain, alleviating generalization collapse caused by unseen noise types; \n(3) A Frequency-aware Adversarial Alignment Block (**FAA-Block**) that explicitly aligns spectral characteristics between source and target domains, mitigating cross-domain frequency mismatches.\nMoreover, the proposed ANL-Block is model-agnostic and can be plug-and-play into most existing methods.\nExperimental results on three manually collected field datasets demonstrate the effectiveness of DACDL in practical field scenarios and highlight the model-agnostic adaptability of the ANL-Block.", "tldr": "An episodic learning framework incorporating a novel noise adaptation mechanism that progressively shifts from model-level to input-level adaptation", "keywords": ["Signal recovery", "episodic learning", "adaptive noise learning", "frequency-aware adversarial alignment."], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7c5d6198b4cec62f60102b3b46336ed869cb05a1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work proposes an episodic learning framework, which learns the shift from the simulated noise domain to the real pump noise domain, which alleviates scarcity of annotated noise data in mud pulse telemetry problem. Through the episodic learning framework, this work designs a lightweight Adaptive Noise Learning Block and A Frequency-aware Adversarial Alignment Block to reconstruct the noisy signal. Abundant experiments in datasets collected from the real world demonstrate that the proposed method achieves great performance."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThis work can achieve joint learning from simulated and real data by episodic learning to alleviate the issue of label data sparsity.\n2.\tThis work enhances the performance of signal reconstruction by enforcing spectral invariance through adversarial training in the Fourier domain."}, "weaknesses": {"value": "1.\tThe organization of the article is rather confused, making it difficult to quickly grasp the methodology pipeline.\n2.\tThe abbreviation FSL appears on line 125, but it is not explained until line 208.\n3.\tLack of research into relevant literature for the traditional signal denoise methods and episodic learning.\n4.\tThe meaning of S(u) in eq 3 is not specified. If it denotes $(\\mathcal{F}s)(u)$, please specify this explicitly in the main text.\n5.\tWaveU-Net is not cited and introduced.\n6.\tThere are some typos in the main text, e.g., the \"ti\" at line 255, the \"f(x))\" at line 281.\n7.\tThe meaning of y^u in eq 12 is not specified.\n8.\tS appears at eq 3 and eq 13, and their meanings seem to be different.\n9.\tLack of explanation regarding the model structure.\n10.\tLack of description of the dataset size.\n11.\tThe writing of this article is puzzling and the specific architectural design of the network is unknown.\n12.\tThe introduction of existing deep learning methods and traditional approaches is insufficient, making it difficult to fully understand the contribution of this article.\n13.\tWaveU-Net and LEDNet do not have citations. No explanation is given as to why it is reasonable. \n14.\tSome meanings of symbols have no explanations, e.g., S(u) in equation (3), y^u in equation (12), and some symbols are in disarray, e.g., S in equation (13) and in equation (3)."}, "questions": {"value": "1.\tWhat does \"feature generator\" at line 287 represent? Is it the same as \"feature extraction\" in section 4.2?\n2.\tWhat is the setting of the transformations at eq 12? Is it randomly assigned? Or does it have a specific practical meaning?\n3.\tIn ADL-block, is \\phi (eq 12) directly obtained for each sample through optimization methods? Or is a Phi-Net learned to map from y to \\phi? This is not specified in the text or training objective.\n4.\tThe method involves multiple modules (Phi-Net, Feature Extractor, and Classifier) and multiple training objectives (L_self, L_sft, L_D, L_adv), but the training pipeline remains unclear. Are they trained together or separately? If separately, what is the training sequence?\n5.\tThe methods compared in Table 1 are mostly techniques for 2-D image signal denoising, whereas the signals in this work are 1-D. For the completeness of this work, it is necessary to compare with the latest 1-D signal reconstruction methods.\n6.\tHow does DACDL compare against classic unsupervised domain adaptation methods?\n7.\tWhy select 500 length window on the line 132?\n8.\tI don't understand why a sampling and average pooling operation needs to be performed on the signal input at line 261?\n9.\tThe specific size of the test dataset?\n10.\tWhat is the input of feature extractor?\n11.\tWhat is the architecture of the pre-trained model for Phi-Net? How to pretrain this model?"}, "flag_for_ethics_review": {"value": ["Yes, Other reasons (please specify below)"]}, "details_of_ethics_concerns": {"value": "\"In prior work, we introduced WaveU-Net\" appears at line 184, which is the first mention of \"WaveU-Net\". I'm concerned that this violates the double-blind rule."}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QQo6nJHoPG", "forum": "UIoK2kzsjg", "replyto": "UIoK2kzsjg", "signatures": ["ICLR.cc/2026/Conference/Submission19603/Reviewer_k8S1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19603/Reviewer_k8S1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19603/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760960048160, "cdate": 1760960048160, "tmdate": 1762931466257, "mdate": 1762931466257, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DACDL, a Deep Adaptive Cross Domain Learning framework for recovering continuous pressure wave signals in Mud Pulse Telemetry (MPT) systems. The approach introduces three components:\n(1) an Episodic Learning Framework (EL-Framework) for alternating meta-learning between simulated and real domains;\n(2) a model-agnostic Adaptive Noise Learning Block (ANL-Block) that injects learnable perturbations to align noise distributions;\n(3) a Frequency-Aware Adversarial Alignment Block (FAA-Block) that aligns spectral characteristics across domains.\nExperiments on three proprietary datasets (Lab, Lab De-Pump, and Oilfield) show significant improvements compared with several signal denoising baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The combination of episodic meta-learning, adaptive noise perturbation, and frequency-domain alignment is conceptually coherent and well-implemented.\n2. The reported performance gains across all metrics (MSE, SNR, SSIM) and datasets are substantial.\n3. The ANL-Block’s plug-and-play design demonstrates some general utility.\n4. The methodology and ablation studies are clearly presented, and the reproducibility statement is detailed."}, "weaknesses": {"value": "1. The paper entirely relies on proprietary, non-public datasets from industrial partners. As a result, the experimental results cannot be independently verified by the community, which substantially weakens the empirical credibility and reproducibility expected for ICLR-level publications.\n2. The proposed framework is tailored specifically to mud pulse telemetry, which is an extremely narrow and specialized field in petroleum engineering. It is unclear whether DACDL can generalize to other signal recovery or cross-domain learning problems, such as audio denoising, seismic inversion, or sensor signal adaptation. Demonstrating results on a more general or publicly available dataset would be essential to justify broader impact.\n3. While technically well-executed, the paper’s core contribution lies in a highly application-specific engineering problem rather than a fundamental advance in representation learning, optimization, or general domain adaptation theory, which are the main focus areas of ICLR.\n4. The ANL-Block is claimed to be “model-agnostic,” but no evidence is shown on tasks beyond MPT signal denoising. Without cross-domain experiments in other modalities, this claim remains unconvincing."}, "questions": {"value": "1. Can DACDL be applied to more general domains (e.g., speech or vibration signal recovery)? If so, please show at least one cross-domain transfer experiment.\n2. Are the datasets or synthetic simulators intended to be released for reproducibility?\n3. How sensitive is the performance to the number of labeled samples in the target domain?\n4. Could the improvements stem mainly from dataset bias rather than genuine domain adaptation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "STVX6QQJU3", "forum": "UIoK2kzsjg", "replyto": "UIoK2kzsjg", "signatures": ["ICLR.cc/2026/Conference/Submission19603/Reviewer_Dqbx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19603/Reviewer_Dqbx"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19603/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761741412463, "cdate": 1761741412463, "tmdate": 1762931465819, "mdate": 1762931465819, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DACDL, a Deep Adaptive Cross-Domain Learning framework for denoising continuous pressure-wave signals in mud-pulse telemetry (MPT) systems. The goal is to improve model generalization from synthetic (Gaussian) to real (pump and field) noise environments. Experiments on three in-house datasets (Lab, De-Pump, Oilfield) show that DACDL improves SNR and SSIM over prior denoising baselines such as U-Net, FADFormer, and MLWNet."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper tackles a realistic and underexplored industrial problem.\n2. Showing performance improvement over selected baseline models.\n3. The proposed ANL-Block is designed to be model-agnostic, allowing seam-\nless integration with a wide range of existing methods."}, "weaknesses": {"value": "1. In Section 4.2 (Page 4, Line 184), the authors write “In prior work, we introduced WaveU-Net, a wavelet-enhanced U-Net that achieved strong results in signal restoration.” with first-person phrasing (“we introduced”). This may reveal the authors' identity and could therefore conflict with the double-blind policy.\n\n2. Lack of fair comparisons. The paper does not include comparisons with existing domain-adaptation or transfer-learning methods, limiting the validity of the claims.\n\n3. The meaning of model-level versus input-level adaptation is not formally defined.\n\n4. The paper lacks a section discussing related works, e.g., prior domain-adaptation, existing denoising methods, or cross-domain learning methods.\n\n5. The writing needs to be improved. For example: 1) Figure 1(b) contains little information, lacking legend and clarity. 2) Multiple typos and formatting issues appear (e.g., page 3 line 128, Eq.3 incomplete notation definition, page 5 line 256). 3) $y^{s\\to t}$ (page 5 line 243) used without definition. 4) Figure 3 is visually cluttered and lacks clear labeling.\n\n6. The proposed episode-based learning setup is quite unclear and the role of support and query sets is not explained."}, "questions": {"value": "1. Wwhy minimizing feature differences between two augmentations $(D_1, D_2)$ relates to correcting the domain deviation. In standard self-supervised learning, this kind of loss enforces invariance under data augmentations. Here, it's proposed to “align” distributions, but that connection isn't justified.  \n    \n2. $\\epsilon^{s\\to t}$ should be treated as a distribution rather than a single deterministic offset.\n       \n3. The motivation for conducting adversarial alignment in the frequency domain rather than the time or latent domain is not theoretically justified or empirically analyzed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "20SMlqxXkN", "forum": "UIoK2kzsjg", "replyto": "UIoK2kzsjg", "signatures": ["ICLR.cc/2026/Conference/Submission19603/Reviewer_WaSH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19603/Reviewer_WaSH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19603/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761951139563, "cdate": 1761951139563, "tmdate": 1762931465441, "mdate": 1762931465441, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}