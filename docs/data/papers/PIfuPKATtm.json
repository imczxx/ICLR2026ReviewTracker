{"id": "PIfuPKATtm", "number": 11377, "cdate": 1758197712755, "mdate": 1763712832925, "content": {"title": "station2radar: query‑conditioned gaussian splatting for precipitation field", "abstract": "Precipitation forecasting relies on heterogeneous data sets. Weather radar is accurate, but coverage is geographically limited and costly to maintain.  Weather stations provide accurate but sparse point measurements, while satellites offer dense, high-resolution coverage without direct rainfall retrieval. To overcome these limitations, we propose Query-Conditioned Gaussian Splatting (QCGS), the first framework to fuse automatic weather station (AWS) observations with satellite imagery for generating radar-like rainfall fields. Unlike conventional 2D Gaussian splatting, which renders the entire image plane, QCGS selectively renders only queried rainfall regions, avoiding unnecessary computation in non-precipitating areas while preserving sharp precipitation structures. The framework combines a radar point proposal network that identifies rainfall-support locations with an implicit neural representation (INR) network that predicts Gaussian parameters for each point. QCGS enables efficient, resolution-flexible rainfall field generation in real time. Through extensive evaluation with benchmark precipitation products, QCGS demonstrates over 50\\% improvement in RMSE compared to conventional gridded rainfall products, and consistently maintains high performance across multiple spatiotemporal scales.", "tldr": "We introduce Query-Conditioned Gaussian Splatting (QCGS) for generating gridded rainfall fields. Unlike standard 2D Gaussian splatting that renders the entire image, QCGS focuses only on queried regions, reducing wasted computation.", "keywords": ["climate change", "precipitation"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4b6e9307d9505741cb1d83cf4ea0ea60d5a750db.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a method for fusing sparse accurate measurements to complement the dense satellite imagery. The method belongs to radar-free precipitation forecasting, motivated by the cost of radars and their limited geographic coverage. For the reasons of computational efficiency, the authors use selective rendering, where they choose to render only areas with precipitation. They fuse dense satellite data with sparse raingauge data using a customised architecture of Graph Attention for sparse raingauge observations and convolutional architecture for the dense satellite imagery, and then they perform rendering using implicit neural representation (INR) based parameterisation, mapping satellite features and locations into Gaussian parameters (amplitude and covariance), which is used in a Gaussian splatting rendering. The advantage of such rendering is that it ensures that the results are scale-invariant."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper tackles an important topic of fusion between the sparse raingauge data and the dense satellite imagery. \n\nQuality: the paper is well written, and to the best of my knowledge, the methodology does not contain errors\n\nClarity: the paper is clearly written and seems to be reproducible\n\nSignificance: the proposed methodology is complementary to the existing ones using radar imagery"}, "weaknesses": {"value": "Originality: while the method looks to me original, there are a number of publications on similar topic, Fusion of satellite and gauge precipitation observations [1,3], as well as different but linked radar and rain gauge data fusion [2] (which is different from the topic yet it may be comparable methodologically). I would suggest the authors contrast the methodology, and importantly, problem statement to the proposed one.\n\nSignificance: while the method is sound, it is based on the successfully combined existing methods (graph attention network, convolutional model, implicit neural representations, Gaussian splatting), so it would be good it seems like the motivation hinges on the novelty of application. It is important therefore to outline explicitly, perhaps in the introduction, how the authors see the contributions\n\nQuality: while the authors are performing the ablation study removing rain gauges, it would be also quite beneficial to see if one can execute an ablation study removing the satellite imagery (i.e. removing the convolutional features from the Radar point proposal network). I would expect the quality to drop significantly, but it would be interesting to see for the completeness of analysis. \n\n[1] Ruan et al (2025) Fusion of satellite and gauge precipitation observations through coupling spatio-temporal properties with tree-based machine learning, Journal of Hydrology\n\n[2] Benoit (2020) Radar and Rain Gauge Data Fusion Based on Disaggregation of Radar Imagery\n\n[3] Curcio et al (2025) Towards a Spatiotemporal Fusion Approach to Precipitation Nowcasting, arXiv"}, "questions": {"value": "1. It would be interesting to know, given that the method also uses the dense satellite imagery, whether it is possible to use it in a radar imagery in a same way as for the satellite imagery.\n\nThe current rating reflects that there're outstanding questions related to the significance and comparison with the existing work. I would expect author to clarify upon these."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "132MTXBWan", "forum": "PIfuPKATtm", "replyto": "PIfuPKATtm", "signatures": ["ICLR.cc/2026/Conference/Submission11377/Reviewer_M5eP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11377/Reviewer_M5eP"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11377/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761759874021, "cdate": 1761759874021, "tmdate": 1762922501457, "mdate": 1762922501457, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes STATION2RADAR (QCGS) — Query-Conditioned Gaussian Splatting — a novel framework that fuses satellite imagery and automatic weather station (AWS) observations to generate high-resolution precipitation fields without radar data. Unlike conventional interpolation or satellite-only methods, QCGS treats each observation as a learnable Gaussian kernel whose parameters are predicted via an implicit neural representation (INR) conditioned on local satellite context. The model selectively renders only rainfall-support regions, enabling efficient and resolution-free precipitation field generation. Experiments show that QCGS reduces RMSE by over 50% compared to existing global precipitation products (IMERG, GSMaP, MSWEP) and outperforms deep learning baselines even when trained at lower resolution."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Novel cross-domain idea: Introduces Gaussian Splatting and INR concepts from computer vision into meteorology for efficient precipitation field synthesis.\n* Superior accuracy: Achieves substantially lower RMSE and higher spatial correlation than both operational satellite products and deep learning baselines.\n* This paper is well-written."}, "weaknesses": {"value": "* The comparison in Table 1 appears unfair. As stated in Lines 409–410, the baselines used for comparison are global coverage products, whereas QCGS is trained only within a regional domain (as mentioned in Lines 320–321). This makes the comparison not entirely appropriate. Including both (a) comparisons between QCGS-generated global precipitation fields and other global-scale products, and (b) comparisons between QCGS’s regional outputs and regional precipitation datasets, would make the claimed advantages of QCGS more convincing.\n\n* The generalization ability across different regions has not been demonstrated. Although QCGS takes only AWS and satellite imagery as inputs, its training ground truth (GT) is derived from regional radar precipitation fields. The paper only presents results within the radar-covered regions. Without evidence of cross-regional generalization, QCGS may lack real-world applicability — since regions with radar data can already rely on radar, and regions without radar would not benefit from QCGS if it cannot generalize beyond the training region. I suggest splitting the original dataset into four subregions, training on two of them, and testing on the other two to assess cross-regional transferability.\n\n* Minor comment: The claim in Lines 096–097 that the model “outputs a continuous precipitation field on an arbitrary scale” is not rigorous. Experimentally, the authors do not show that QCGS can reproduce weather phenomena at scales beyond those present in the GT data. Theoretically, since the GT is derived from 0.5 km resolution radar fields, there is no source of information for finer-scale phenomena."}, "questions": {"value": "In Stage 1, how does the inclusion or exclusion of station data affect the visual quality of the reconstruction? Similarly, how does adding or removing the Gaussian representation influence the visualization results? I encourage the authors to analyze and present these effects in future versions of the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "alvhFGygeR", "forum": "PIfuPKATtm", "replyto": "PIfuPKATtm", "signatures": ["ICLR.cc/2026/Conference/Submission11377/Reviewer_4rLn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11377/Reviewer_4rLn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11377/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761828218484, "cdate": 1761828218484, "tmdate": 1762922501047, "mdate": 1762922501047, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Query-Conditioned Gaussian Splatting (QCGS), an innovative framework for reconstructing high-resolution precipitation fields from heterogeneous data sources—sparse automatic weather station (AWS) observations and dense satellite imagery. QCGS employs a radar-point proposal network to identify rain-supporting regions and combines a rain-aware point sampling strategy to selectively sample query locations. Subsequently, an Implicit Neural Representation (INR) network, conditioned on local satellite features, predicts Gaussian parameters (amplitude and covariance) for each query point. Experimental results show that QCGS outperforms existing data-driven baselines and operational products across multiple metrics, particularly in preserving rainfall structure and enabling resolution-agnostic rendering."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1 Sound and Effective Fusion Mechanism: The method successfully uses sparse but accurate AWS point observations as anchors for rainfall intensity, integrating them with satellite imagery that provides dense contextual information. This design for fusing heterogeneous data sources mitigates the limitations of individual data types and improves the accuracy of the reconstructed field.\n\n2 Resolution Agnosticism: By leveraging INR-based parameterization and Gaussian Splatting (GS) rendering, the model enables resolution-agnostic field generation—models trained at lower resolutions can render high-resolution outputs (e.g., 0.5 km), significantly enhancing the method's practicality and scalability.\n\n3 Clarity and Thoroughness: The paper is well-structured, with detailed descriptions of methodological components (e.g., rain-aware sampling strategy, INR parameterization), making the approach clear and reproducible."}, "weaknesses": {"value": "1. Incomplete Baselines and Missing Assimilation Comparison: The current baselines mainly focus on direct image-to-image translation (e.g., Pix2PixHD, BBDM) and purely satellite-based forecasting (e.g., NPM). Given that the core task of this work—reconstructing precipitation fields from observations—falls more closely within the scope of data assimilation (DA) or objective analysis in meteorology, the paper should consider comparisons with deep learning-based DA methods designed for sparse or heterogeneous observations, such as DiffDA or 4DVarFormer. At minimum, the authors should clearly discuss the theoretical and experimental distinctions between QCGS and traditional objective analysis methods (e.g., Barnes Interpolation, Optimal Interpolation, or Kriging), and possibly include comparisons with more sophisticated classical interpolation techniques.\n\n2. Missing Key Meteorological Metrics: While RMSE and correlation coefficients measure overall field agreement, categorical (threshold-based) metrics are critical for evaluating the accurate detection of heavy precipitation events. Although the paper reports CSI, FSS, and Bias, it lacks essential categorical metrics for precipitation, such as Probability of Detection (POD) and False Alarm Ratio (FAR) at specific rainfall thresholds. We suggest explicitly including a breakdown of the CSI by rainfall intensity levels (graded CSI)."}, "questions": {"value": "1. Comparison with Baselines and Assimilation Methods: As noted in Weakness 1, could the authors explain why QCGS was not compared with deep learning data assimilation methods specifically designed for sparse observations, such as DiffDA or variants of 4DVarFormer? What are the fundamental differences between these approaches and QCGS in handling heterogeneous meteorological data?\n\n2. Evaluation on Heavy Rainfall Events: As noted in Weakness 2, can the authors provide detailed results for Probability of Detection (POD) and False Alarm Ratio (FAR) at different rainfall intensity thresholds (e.g., ≥ 50.0 mm/day or ≥ 200.0 mm/day), along with a breakdown of CSI by intensity level? Since RMSE can be overly sensitive to extreme values, these metrics are crucial for assessing the model’s ability to capture heavy rainfall events.\n\n3. Physical Interpretability of INR Parameters: The INR predicts Gaussian parameters {σₓ, σᵧ, ρ, α}. Does the covariance matrix Σ (determined by σₓ, σᵧ, ρ) of the Gaussian primitives have a clear physical interpretation in the context of precipitation fields—e.g., is it related to the spatial scale or shape of meteorological features? Were any physical constraints or regularizations applied to these parameters during training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "R58dX5sW01", "forum": "PIfuPKATtm", "replyto": "PIfuPKATtm", "signatures": ["ICLR.cc/2026/Conference/Submission11377/Reviewer_UPz5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11377/Reviewer_UPz5"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11377/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997414375, "cdate": 1761997414375, "tmdate": 1762922500562, "mdate": 1762922500562, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Query-Conditioned Gaussian Splatting (QCGS), a novel framework that generates high-resolution precipitation fields by fusing satellite imagery with sparse automatic weather station (AWS) data, eliminating the need for radar. Unlike traditional methods, QCGS selectively renders only rainfall-prone areas using learnable Gaussian kernels, which preserves sharp precipitation structures and improves computational efficiency. It combines a radar proposal network for locating rainfall areas with an implicit neural network that predicts Gaussian parameters. Evaluations show QCGS significantly outperforms existing gridded products and deep learning baselines, reducing RMSE by over 50% and maintaining high accuracy across various spatiotemporal scales."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "This paper presents a highly novel approach for directly generating high-quality precipitation maps from satellite and station image data by combining 2D Gaussian Splatting with predictions from a feed-forward network. Although similar methods have been widely used in the SVG domain, this application is relatively innovative in the field of meteorology, and the presented results appear to be effective."}, "weaknesses": {"value": "1. Figure 2 lacks clear identification of variables and models, which prevents a clear correlation with the methods section in the main text. The authors are strongly advised to revise Figure 2.\n\n2. The notation system in the Methods section is quite confusing. For example, the meanings of symbols such as *u* and *p* are not clearly defined. A more detailed explanation of the symbol system is required.\n\n3. Although the paper introduces a relatively novel hybrid representation (combining feed-forward network predictions with 2D Gaussian splatting for detail refinement), the overall description of the task is very unclear. Since ICLR is a broad interdisciplinary community where not all readers are meteorology experts, the presentation of the paper may cause significant confusion among readers."}, "questions": {"value": "Are the Radar Point Proposal Network and the Gaussian Reconstruction component trained separately? The description of this in the paper is quite confusing.\n\nWhere is the precipitation prediction that the paper consistently emphasizes? The proposed method does not demonstrate predictive functionality and appears more like a precipitation downscaling approach. The authors are requested to provide a detailed explanation.\n\nHow many 2D Gaussian disks are there per sampling point?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3Y0xQavDpI", "forum": "PIfuPKATtm", "replyto": "PIfuPKATtm", "signatures": ["ICLR.cc/2026/Conference/Submission11377/Reviewer_SZyX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11377/Reviewer_SZyX"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11377/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762278425594, "cdate": 1762278425594, "tmdate": 1762922499994, "mdate": 1762922499994, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}