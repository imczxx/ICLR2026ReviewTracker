{"id": "ssfwoqbg3H", "number": 8394, "cdate": 1758081342585, "mdate": 1759897787825, "content": {"title": "Concept-level Multimodal Reasoning via Semantic Representation for Intent Recognition", "abstract": "Multimodal intent recognition is a fundamental task in understanding human communication, aiming to infer intent from heterogeneous modalities and serving as a cornerstone for developing human-centric systems. However, existing methods face two key challenges. First, they rely on entangled and modality-specific features, which hinder the derivation of interpretable representations across modalities. Second, they lack explicit reasoning mechanisms, making it difficult to capture high-level semantic dependencies and systematically link multimodal evidence to complex intents. To address these issues, we propose a novel method (ConMR) that conducts concept-level multimodal reasoning by jointly learning semantic concept representations and modeling concept relations. Specifically, we first leverage the Large Language Model (LLM) to generate high-quality intent-related concepts, providing explicit semantic anchors beyond shallow features. By supervising multimodal feature mapping through activation alignment, these concepts yield interpretable and discriminative representations. Building on this foundation, the concept-level multimodal reasoning module models concept-to-intent relations through LLM-guided relevance scores and infers inter-concept relations from activation patterns. By jointly exploiting these relations, it guides transparent reasoning paths from concepts to intents, thereby enhancing both accuracy and interpretability. Extensive experiments on two challenging datasets show that ConMR outperforms state-of-the-art methods with superior robustness and interpretability, laying a new paradigm for multimodal intent recognition.", "tldr": "We introduce ConMR, a novel framework that advances multimodal intent recognition through concept-level reasoning, significantly enhancing both discriminative performance and interpretability.", "keywords": ["Concept Representation", "Multimodal Reasoning", "Multimodal Intent Recognition"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/141f771decef55af8900bb20e1558b0bee407995.pdf", "supplementary_material": "/attachment/7122c424c9b68b05e6f0ad9408f9db2ce8efeec8.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a Concept-level Multimodal Reasoning framework for intent recognition named ConMR. Specifically, ConMR includes two core modules: Concept Representation Learning and Concept-level Multimodal Reasoning. The Concept Representation Learning module leverages a large language model to automatically generate and filter intent-related concepts for text, video, and audio modalities, and maps multimodal features into a unified, interpretable concept space under activation alignment supervision from pretrained modality-specific encoders. The Concept-level Multimodal Reasoning module models both concept-to-intent relevance and inter-concept relations derived from activation patterns, enabling structured reasoning paths from concepts to intents.\n\nThe experimental evaluation in this paper assessed the performance of the proposed ConMR on two challenging multimodal intent recognition benchmarks (MIntRec and MIntRec2.0), comparing it with various state-of-the-art methods. The results indicate that the proposed ConMR achieved consistent performance improvements and superior interpretability, with notable gains in accuracy and F1-score across diverse intent categories."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The attempt to transform feature-level patterns into the explicit concept-level paradigm is valuable.\n- The experimental analysis is overall thorough; even the appendix is well-organized."}, "weaknesses": {"value": "- The quality of the entire concept space and the evaluation of intent relevance rely heavily on the capability and stability of the large language model. If the LLM‚Äôs understanding is inaccurate in specific domains or performs poorly in cross-lingual and cross-cultural scenarios, it may introduce noisy concepts and biased relevance scores.\n- The ablation study on the concept selection strategy is somewhat incomplete. For example, whether similarity filtering is necessary, whether submodular selection is applied, or how varying the number of concepts affects performance.\n- The paper lacks discussion on why SBERT, XCLIP, and CLAP were specifically chosen to compute association scores.\n- Concept-level reasoning mainly focuses on constructing and reasoning within the same modality; however, cross-modal concept connections often better reflect real intent (e.g., contradictions or alignments between visual expression and verbal tone). The current fusion mainly relies on concatenation and shared weights, lacking explicit modeling of cross-modal concept interactions.\n- Considering that the model itself requires an LLM and involves multiple encoders (SBERT, XCLIP, CLAP, PLM, Swin Transformer, WavLM), there is a complex coupling between these components, making it difficult to analyze the contribution of each model or conduct ablations on different combinations. Moreover, the combination of multiple models introduces additional computational burdens."}, "questions": {"value": "- It seems that the concept set is usually fixed before training and cannot be dynamically adjusted based on samples or contexts. Does this imply that a separate model must be prepared for each benchmark, thereby posing challenges for open-domain scenarios?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "DwUAzy3ZdI", "forum": "ssfwoqbg3H", "replyto": "ssfwoqbg3H", "signatures": ["ICLR.cc/2026/Conference/Submission8394/Reviewer_HBfx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8394/Reviewer_HBfx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8394/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761903679076, "cdate": 1761903679076, "tmdate": 1762920297815, "mdate": 1762920297815, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents ConMR, a novel framework for multimodal intent recognition that elevates reasoning from the feature level to the concept level. The core idea is to leverage LLM-generated concepts as semantic anchors, learn explicit concept representations from multimodal features, and then perform structured reasoning over concept-intent and inter-concept relations. The authors demonstrate state-of-the-art performance on two established benchmarks (MIntRec and MIntRec2.0) and provide extensive experiments, including ablation studies and case analyses, to validate their design choices."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This paper's principal strengths lie in its conceptual contribution. It proposes a concept level reasoning approach for multimodal intent recognition, effectively bridging the gap between low-level features and high-level intents to enhance both performance and, crucially, model interpretability. The proposed ConMR framework is meticulously designed, integrating LLM-based automatic concept generation, a supervised feature-to-concept transformation, and a dual-path reasoning module that models both concept-to-intent and inter-concept relations. This rigorous design is supported by compelling empirical evidence, including state-of-the-art results on two benchmarks, ablation studies that validate each component, and case analyses that demonstrate its transparent decision-making. Furthermore, the framework's robustness is confirmed by its consistent performance across different LLM, solidifying its value as a significant advancement towards trustworthy multimodal AI."}, "weaknesses": {"value": "see questions"}, "questions": {"value": "1. How would the framework perform in a low-resource setting where access to powerful LLMs like Gemini-2.5 is limited? Is there a fallback strategy or a lighter-weight alternative for concept generation?\n2. The failure case analysis in Appendix E.3 is excellent. Could the framework be extended to incorporate a feedback loop that uses such mis-predictions to iteratively refine the concept set?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gOgKrD3LOF", "forum": "ssfwoqbg3H", "replyto": "ssfwoqbg3H", "signatures": ["ICLR.cc/2026/Conference/Submission8394/Reviewer_dY2Z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8394/Reviewer_dY2Z"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8394/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761918115127, "cdate": 1761918115127, "tmdate": 1762920297459, "mdate": 1762920297459, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces ConMR, a concept-level multimodal reasoning model that uses LLM-generated concepts and relevance scores to supervise intent recognition training. The framework is clearly presented and shows consistent empirical improvements, with potential benefits in reducing inference time and cost compared to full MLLMs.\n\nHowever, its true novelty is minimal‚Äîthe method mainly distills MLLM priors through an additional MSE loss, while the underlying structure remains a standard CBM.\nThe claimed \"reasoning\" ability is in fact semantic alignment, not autonomous reasoning, and the paper overstates its originality.\nTherefore, this is a practical but not theoretically innovative work whose main value may lie in efficiency rather than conceptual contribution."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper proposes a two-stage intent understanding framework consisting of Concept Representation Learning and Concept-level Multimodal Reasoning. It transforms entangled multimodal features into explicit concepts and reasons over their relations, using LLM-generated semantic concepts as interpretable anchors. This design improves interpretability, enabling the model to produce concept-level activations that correspond to human-understandable semantic units.\n2. The experiments are conducted on two widely used benchmarks (MIntRec and MIntRec2.0), and the results are consistent across multiple evaluation metrics. The proposed method achieve the best performance compared with fusion-based methods and contrastive learning based methods.\n3. The manuscript is logically structured, clearly written, and easy to follow despite some overcomplicated exposition."}, "weaknesses": {"value": "1. Given that the proposed method already relies on LLMs for concept supervision and intent-relevance supervision, it is unclear why the authors do not directly employ LLMs for multimodal intent recognition (e.g., via zero-shot or fine-tuning approaches) instead of introducing additional concept reasoning layers.\nImportantly, the experiments do not include comparisons with LGSRR[1], which, according to the authors, is the first work leveraging LLMs for multimodal intent recognition in Line 54.\nThis paper only compares with traditional fusion-based methods (MulT, MAG-BERT, MISA, etc.) and contrastive approaches (TCL-MAP, MVCL-DAF, etc.), but lacks LLM-based baselines, including:\n* MLLM zero-shot/few-shot baselines, e.g., Gemini-2.5 directly predicting intents from multimodal inputs;\n\n* MLLM pseudo-labeled baselines, where MLLMs label training samples with / without CoTs and a lightweight model is then trained on those labels.\n\nSuch comparisons should be included to convincingly demonstrate that the improvement of ConMR comes from its structured semantic reasoning mechanism rather than merely relying on LLM priors.\n\n[1] Llm-guided semantic relational reasoning for multimodal intent recognition, Qianrui Zhou, et. al. 2025. arXiv \n\n2. Modern multimodal LLMs (e.g., Gemini 2.5, Qwen-VL-Series) are already capable of: (1) directly handling text, audio, and visual inputs,(2) producing explicit reasoning chains via prompting, and (3) generating concept-level explanations. Therefore, ConMR‚Äôs approach appears to distillate LLM capabilities to ConMR‚Äôs training stage.\nThe authors need to clarify what concrete advantages the ConMR provides in terms of performance or interpretability beyond what a capable MLLM can already achieve.\n\n3. This is a concern of the motiation.\n\nLines 56‚Äì61:\n\n> \"First, existing methods predominantly operate at the feature level, relying on entangled and abstract representations that leave a substantial gap between low-level multimodal signals and the nuanced semantics of human intent. Second, they lack explicit and structured multimodal reasoning mechanisms capable of modeling the interplay between high-level semantic representations, which makes it difficult to construct transparent and discriminative paths that bridge raw inputs to complex intents. \"\n\nHowever, these challenges are no longer valid in the LLM era, since current LLMs already perform feature disentanglement and explicit chain-of-thought reasoning for multimodal tasks. Thus, this argument cannot serve as a justification for proposing ConMR.\n\nAdditionally, lines 54‚Äì56: \n\n> \"while LGSRR Zhou et al. (2025) represents the first attempt to leverage Large Language Models (LLMs) to guide multimodal intent recognition. \"\n\nIf so, the authors must clearly articulate what limitations of LGSRR or other LLM-based approaches remain unsolved.\nThe two points raised in lines 56‚Äì61 describe issues of pre-LLM fusion methods, not of LLM-based methods.\nTherefore, the introduction currently fails to identify the real gap that ConMR aims to address in the post-LLM context.\n\n4. The novelty is overstated. \n\nLine 136-138:\n\n> \" Although CBM research has made notable strides in interpretability, it remains confined to surface-level contribution scores of concepts rather than capturing their intrinsic semantics, which fundamentally constrains its performance.\"\n\nThis claim is somewhat overstated.The real methodological novelty of ConMR lies only in introducing LLM-generated concept‚Äìintent relevance scores as explicit supervision via the MSE loss. Traditional Concept Bottleneck Models (CBMs) indeed learn a concept layer followed by a linear classifier to map the concepts and intent labels, where concepts are usually human-annotated or similarity-based matching. ConMR differs mainly in that: (1) the concept supervision is generated by an LLM (2) the concept-to-intent supervision also comes from the LLM‚Äôs semantic similarity scores. Therefore, for the method proposed in this paper, the structure is CBM-style, while the semantics come from the LLM. It is also explicitly shown:\n\n* KL $\\rightarrow$ concept-semantic consistency\n* MSE $\\rightarrow$ LLM-prior consistency\n* CE $\\rightarrow$ task-label consistency\n\nOnly the LLM-based semantic supervision is genuinely new. This is a practical innovation, not a theoretical one. It can be describe as a LLM-guided CBM method. This paper over-claims its methodological novelty. \n\n5. Ablation results largely reflect dependence on LLM priors rather than genuine reasoning ability. In Table 2, the ablation outcomes can be directly explained by removing or preserving access to the LLM-derived priors. \n\nLine 369-372:\n\n> \"Besides, a severe degradation is observed when the learnable transformation W is replaced with linear layers with activations (w/o W), with metrics on MIntRec2.0 dropping by more than 7%, which highlights the critical role in generating robust concept representations.\"\n\nLine 372-374:\n\n> \"In the concept-level multimodal reasoning module, removing LMSE (w/o LMSE) results in performance drops from 0.49% to 2.28% across all metrics on both datasets, confirming the importance of LLM-based intent relevance score supervision.\"\n\nLine 374-375:\n\n> \"Furthermore, ablating the concept-to-intent pathway (w/o Zconcept) causes a severe collapse, with accuracy on MIntRec dropping to 36.36% and F1 on MIntRec2.0 falling to 46.99%.\"\n\nW learns LLM-provided \"semantic ground truth\", and it is essentially a distillation of the LLM prior, not a discovery of new relationships among the data. \n\nSimilarly, line 372-375:\n\n> \"For concept-to-intent reasoning, intent-conditioned relevance scores generated by Gemini-2.5 are leveraged to guide a weighting network through MSE loss to selectively reinforce concept features.\"\n\nIt shows that removing $ùìõ_{MSE}$ or the concept-to-intent pathway $Z_{concept}$ leads to drastic performance drops (up to total collapse). The fact may be that removing these components effectively removes the LLM semantic channel. Therefore, the ablation study does not demonstrate autonomous concept-level reasoning, however, it shows that ConMR‚Äôs performance is driven by dependence on LLM-generated priors rather than self-learned reasoning capacity."}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8dnH3S2ITM", "forum": "ssfwoqbg3H", "replyto": "ssfwoqbg3H", "signatures": ["ICLR.cc/2026/Conference/Submission8394/Reviewer_XnHa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8394/Reviewer_XnHa"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8394/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762209915628, "cdate": 1762209915628, "tmdate": 1762920297030, "mdate": 1762920297030, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}