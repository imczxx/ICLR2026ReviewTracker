{"id": "6LFZreN1YX", "number": 900, "cdate": 1756822738554, "mdate": 1763123975265, "content": {"title": "AlignPrune: Robust Dynamic Data Pruning through Loss Trajectory Alignment", "abstract": "Existing dynamic data pruning methods often fail under noisy-label settings, as they typically rely on per-sample loss as the ranking criterion. This could mistakenly lead to preserving noisy samples due to their high loss values, resulting in significant performance drop. To address this, we propose AlignPrune, a noise-robust module designed to enhance the reliability of dynamic pruning under label noise. Specifically, AlignPrune introduces the Dynamic Alignment Score (DAS), which is a loss-trajectory-based criterion that enables more accurate identification of noisy samples, thereby improving pruning effectiveness. As a simple yet effective plug-and-play module, AlignPrune can be seamlessly integrated into state-of-the-art dynamic pruning frameworks, consistently outperforming them without modifying either the model architecture or the training pipeline. Extensive experiments on five widely-used benchmarks across various noise types and pruning ratios demonstrate the effectiveness of AlignPrune, boosting accuracy by up to 6.3% over state-of-the-art baselines. Our results offer a generalizable solution for pruning under noisy data, encouraging further exploration of learning in real-world scenarios.", "tldr": "", "keywords": ["Data Pruning", "Dynamic Data Pruning", "Efficient Learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/28185cac7e8a606b68ddfcc8c687936cb82fe376.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper targets dynamic data pruning under label noise. The central idea is to replace loss-magnitude–based ranking (vulnerable to retaining noisy examples) with a Dynamic Alignment Score (DAS) that measures the correlation between a sample’s loss trajectory over recent epochs and a clean reference loss trajectory; higher alignment implies a cleaner sample. DAS is plugged into existing dynamic pruning methods without altering architectures or training loops."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- Plug-and-play practicality. AlignPrune preserves the base method’s update rule (e.g., InfoBatch’s unbiased gradient rescaling) and requires minimal engineering."}, "weaknesses": {"value": "W1. Limited problem novelty / overlap with prior pruning-under-noise work\nThe paper positions itself as a study of data pruning under label noise; however, the core problem—robust pruning in the presence of noise—has been actively explored (e.g., Prune4ReL). In this sense, the problem framing is not novel; the incremental novelty is the specific trajectory-alignment criterion and its integration into dynamic pruning. The paper would benefit from clarifying the unique challenges of the setting that Prune4ReL (static) does not cover.\n\nW2. Baseline coverage omits the most directly relevant comparator in the main results\nPrune4ReL is listed among related works, but it is not shown in the results. Given that both AlignPrune and Prune4ReL target robust data selection under label noise, readers require a direct comparison of the two. \n\nW3. Presentation quality and missing visual aids\nThe manuscript’s exposition would benefit from stronger academic polish. In particular: Overlaid clean vs. noisy loss trajectories with their correlation to the reference."}, "questions": {"value": "Please refer to the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "p7ugw8cPPb", "forum": "6LFZreN1YX", "replyto": "6LFZreN1YX", "signatures": ["ICLR.cc/2026/Conference/Submission900/Reviewer_Wtgn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission900/Reviewer_Wtgn"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission900/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761036670759, "cdate": 1761036670759, "tmdate": 1762915638282, "mdate": 1762915638282, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "zxht99fX98", "forum": "6LFZreN1YX", "replyto": "6LFZreN1YX", "signatures": ["ICLR.cc/2026/Conference/Submission900/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission900/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763123974412, "cdate": 1763123974412, "tmdate": 1763123974412, "mdate": 1763123974412, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies dynamic data pruning under noisy-label settings.\nThe author proposes a dynamic alignment score (DAS) that introduces a clean reference subset to evaluate the original dataset.\nThis method improves the performance of the baselines (InfoBatch and SeTa) in noisy-label settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.The data pruning under noisy labels (addressed in this paper) is important and practical.\n\n2.The expression of this paper is clear and logical."}, "weaknesses": {"value": "The innovation of this paper is limited. It seems that only a clean reference set has been introduced based on InfoBatch (or SeTa) to solve the data pruning problem under noisy-label settings. However, there are many important pipeline comparisons missing (such as GLISTER [1], Prune4Rel with Re-labeling [2] on large-scale datasets)."}, "questions": {"value": "There are some important questions that the author needs to explain. The specific issues are as follows:\n\n1.The author claims to solve the problem of data pruning under noisy-label settings, but how does this method address the following two important issues？\n\n   (1) How does this method distinguish between hard samples and noisy samples?\n\n   (2) If there are still noise label samples in the selected subset, how does this method prevent overfitting?\n\n2.This paper uses some clean reference samples, but lacks compare with the data pruning method [1] that also uses clean label samples.\n[1] GLISTER: Generalization based Data Subset Selection for Efficient and Robust Learning \n\n3.The experimental results in Figure 3 appear suspicious. Why did using as many clean labeled samples as possible as the reference set have little impact on the final results? This is illogical. In noise learning method [3] that uses partially clean labels, the final result will improve as the number of clean samples increases.\n[3] Delving into Noisy Label Detection with Clean Data, ICML 2023\n\n4.This paper lacks theoretical analysis. It is hoped that the author analyzes how the number of clean samples affects the final results. From Figure 3, it appears that the impact of the number of clean labels on the performance of the method is not significant.\n\n[1] GLISTER: Generalization based Data Subset Selection for Efficient and Robust Learning. AAAI, 2021. \n\n[2] Robust data pruning under label noise via maximizing re-labeling accuracy. NeurIPS, 2023.\n\n[3] Delving into Noisy Label Detection with Clean Data, ICML 2023.\n\nI hope the author seriously consider and address these issues, as the current score still has room for fluctuation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QfbUlj2vvT", "forum": "6LFZreN1YX", "replyto": "6LFZreN1YX", "signatures": ["ICLR.cc/2026/Conference/Submission900/Reviewer_FANS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission900/Reviewer_FANS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission900/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761725978547, "cdate": 1761725978547, "tmdate": 1762915638164, "mdate": 1762915638164, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a dynamic data pruning method for noisy-label settings, which dynamically aligns the original dataset by introducing a clean label set. This method demonstrates consistent performance improvements over baseline methods (InfoBatch and SeTa)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is well-written.\n2. Extensive experiments are conducted on multiple benchmarks."}, "weaknesses": {"value": "1. The novelty is limited. This method introduces a clean $V_ref $in the baselines to solve the noise-label settings. However, this motivation has already been used in reference [1] which is a dynamic method.\n2. This method lacks theoretical analysis on how $V_ {ref} $ affects the pruning results.\n[1] GLISTER: Generalization based Data Subset Selection for Efficient and Robust Learning. AAAI, 2021."}, "questions": {"value": "1. This method seems to rely heavily on $V_ {ref} $ to distinguish noisy samples, but the results in Figure 3 show that this method appears robust to the size of $V_ {ref} $. I hope the author can provide the proportion of noisy samples in the subset selected by this method under different pruning rates and different sizes of $V_ {ref} $.\n\n2. I doubt about the results in Table B and C (Appendix B). Samples with smaller gradient values are more likely to be clean samples. Since samples with smaller gradient values are more likely to be clean, the SmallL method should theoretically select more clean samples. I hope the author can provide the proportion of noisy labels in the subset selected for each method in Table B.\n\n3. Table D (Appendix B) shows that when using re-labeling, this method outperforms Prune4ReL, which uses subset maximum re-labeling accuracy. Can the author explain why this method is more effective than subset maximization in relabeling accuracy? Since Prune4ReL has theoretical guarantees, its results seem to be reliable and effective. \n\n4. Could the author provide some results to show the number of noise samples in the selected subset?\n\n5. Compare with Reference [1]."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0zvk1MK1rp", "forum": "6LFZreN1YX", "replyto": "6LFZreN1YX", "signatures": ["ICLR.cc/2026/Conference/Submission900/Reviewer_fkSq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission900/Reviewer_fkSq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission900/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761807303002, "cdate": 1761807303002, "tmdate": 1762915638040, "mdate": 1762915638040, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a dynamic dataset pruning in a noisy label setting. The key idea of the approach is to measure the loss trajectory of the samples and then compare it againt a reference loss trajectory that comes from noise free data. The paper hinges on the assumption that noisy samples exhibit more erratic or inconsistent patterns compared to cleaner samples. Experiments are conducted on standard benchmarks and it is compared against some recent baselines both static and dynamic."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "Dynamic dataset pruning is very useful idea, particularly for large datasets. \nThe aproach proposed by the authors is very simple and intuitive. \nExperiments are done on standard datasets."}, "weaknesses": {"value": "The major weakness of the paper is that it stands on very simplistic assumptions. While I agree that the loss trajectory of nosiy samples are bit erratic, it can't be conclusivey said, because hard but correct samples also may not smooth loss trajectory. Neural nets hasv the tendency to fit the easy samples first and then the hard examples. Thus, it is very difficult to distinguish if a sample is noisy or hard. \n\nSecond comparing against mean loss from a clean validation set is also problematic. Distributional shift could be a real problem in this case. Examples could be nosiy and not noisy, but  non-noisy samples can be also from varying hidden sub-classes. This means a reference score does not reflect who they are. In my view this is going to be a serious issue. \n\nExperimental evaluation is also not up to the mark. Some recent methods like RS2 [Okanovic et al, 2024] or RCAP [Hassan et al, 2025] does very well even with 90% data pruning. Also they are specificaly tested on noisy labels, their performance are very good. Lack of comparison with these most recent works seem major ommission. It may happen that those methods do poorer than the proposed method. But we do not know."}, "questions": {"value": "Please see my weakness section for detailed commnets. These cover my main concerns."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Ge48Cipkaa", "forum": "6LFZreN1YX", "replyto": "6LFZreN1YX", "signatures": ["ICLR.cc/2026/Conference/Submission900/Reviewer_Aesr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission900/Reviewer_Aesr"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission900/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762430899272, "cdate": 1762430899272, "tmdate": 1762915637889, "mdate": 1762915637889, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}