{"id": "U616C5HpG2", "number": 2510, "cdate": 1757128908959, "mdate": 1759898143908, "content": {"title": "Optimizing User Profiles via Contextual Bandits for Retrieval-Augmented LLM Personalization", "abstract": "Large Language Models (LLMs) excel at general-purpose tasks, but personalizing their responses to individual users remains challenging.\n    Retrieval augmentation offers a lightweight alternative to fine-tuning by conditioning LLMs on user history records, yet existing strategies rely on heuristics (e.g., relevance to the query) that overlook the true contribution of records to personalization.\n    Through a systematic motivation study, we show that (i) relevance does not reliably predict utility, and (ii) utility is non-monotonic across records: the best user profile is not simply the combination of the best individual records, and adding more records can even hurt performance.\n    To address these limitations, we propose PURPLE, a contextual bandit framework that oPtimizes UseR Profiles for Llm pErsonalization.\n    PURPLE operates as a re-ranking layer over candidate records, balancing efficiency with personalization quality.\n    Across nine real-world personalization tasks spanning classification, regression, and short- and long-text generation, PURPLE consistently outperforms strong heuristic and retrieval-augmented baselines, establishing contextual bandit retrieval as a principled and scalable solution for personalized LLMs.\n    Our anonymized code is available.", "tldr": "", "keywords": ["Retrieval-augmented Generation", "Personalization", "Contextual Bandit"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/14377121c092b82092c3b7e6c3939b87c19131d3.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper studies personalization for LLMs when conditioning on user history. It argues that common heuristic retrieval (e.g., relevance to the query) does not faithfully capture the true utility of records for personalization, and that utility across records is non-monotonic—adding more “good” records can hurt. The authors propose PURPLE, a contextual bandit–based re-ranking layer over candidate user records that aims to optimize user profiles for downstream tasks. They report improvements over heuristic and retrieval-augmented baselines across classification, regression, and short/long text generation tasks, and position contextual bandit retrieval as a scalable path to personalized LLMs."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Framing RAG-based personalization as a contextual bandit problem is an interesting and potentially impactful idea.\n- The paper includes experiments on multiple datasets, aiming to demonstrate applicability across task types."}, "weaknesses": {"value": "1. The central empirical claims lack key analyses and breadth: despite the broader narrative, the core observations are effectively demonstrated on **a single model and a single dataset**, leaving generality unsubstantiated and the evidence shallow\n2. The claim that relevance ≠ utility lacks deeper analysis: the paper does not explain when/why alignment breaks, nor provide theoretical grounding for the observed non-monotonicity (e.g., conditions under which relevant records become non-useful or harmful).\n3. Baseline coverage is incomplete. Important personalized RAG methods are missing, such as [1,2]. In addition, comparisons against commonly used PAG methods are absent.\n\n[1] Retrieval Augmented Generation with Collaborative Filtering for Personalized Text Generation (SIGIR 2025)\n\n[2] Measuring What Makes You Unique: Difference-Aware User Modeling for Enhancing LLM Personalization (ACL Findings 2025)"}, "questions": {"value": "- The statement that “combining the records with the highest individual utility does not necessarily yield the best profile.” Why does PURPLE resolve this? Please clarify the mechanism or assumptions under which the proposed method overcomes this combinatorial non-monotonicity.\n\n- Whether there are concrete failure cases where “relevance alone” is a poor predictor of personalization benefit? What characteristics of the query/user/history drive these failures?\n\n- Is there any theoretical support for the key claims (e.g., relevance–utility misalignment, non-monotonicity), even under simplifying assumptions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TIX36yfZwj", "forum": "U616C5HpG2", "replyto": "U616C5HpG2", "signatures": ["ICLR.cc/2026/Conference/Submission2510/Reviewer_pkZa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2510/Reviewer_pkZa"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2510/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761916154515, "cdate": 1761916154515, "tmdate": 1762916261319, "mdate": 1762916261319, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper primarily explores how to construct user profiles more efficiently in large language model (LLM) personalization. The authors point out that traditional retrieval augmentation (RAG)-based personalization methods typically rely on \"relevance to the query\" to select user history records. However, this heuristic approach has two fundamental problems: ① relevance does not equal true personalization utility; ② the utility between different records is non-monotonic, and simply stacking the most relevant records may actually reduce performance. To address these issues, the paper proposes the PURPLE framework (\"oPtimizing UseR ProfiLes for llm pErsonalization\"), which models user record selection as a contextual bandit problem. Through policy gradient reinforcement learning optimization, it directly uses the performance of downstream generation tasks as reward signals, dynamically learning which record combinations best improve personalization results. Experiments on nine real-world tasks (classification, regression, short text generation, and long text generation) demonstrate that PURPLE significantly outperforms traditional heuristic retrieval, zero-shot re-rankers (such as RankGPT and ICR), and RAG variants (such as REPLUG and In-Context RALM) in both accuracy and efficiency. Research shows that context-based bandit-based retrieval optimization is a more scalable, interpretable, and efficient personalized LLM solution."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is well-written, and the figures are well-drawn. \n2. The model itself is lightweight, which is significant for personalized LLM research."}, "weaknesses": {"value": "1. The lack of comparison and discussion with personalized LLM methods, such as in brackets [], makes the experimental results less convincing.\n2. There is no further discussion on the method's design space, such as why this problem cannot be solved based on RL like [2].\n3. The model's performance and application are not discussed for new users or changes in user interests.\n4. The method has limited innovation. There are many previous methods for personalized recommendations using context bandit, and further discussion is needed on the differences and connections between these methods.\n\n[1] LaMP: When Large Language Models Meet Personalization\n\n[2] PREMIUM: LLM Personalization with Individual-level Preference Feedback\n\n[3] Personalized Pieces: Efficient Personalized Large Language Models through Collaborative Efforts\n\n[4] Personalized Language Modeling from Personalized Human Feedback"}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "n7HsT92Os6", "forum": "U616C5HpG2", "replyto": "U616C5HpG2", "signatures": ["ICLR.cc/2026/Conference/Submission2510/Reviewer_z1Zm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2510/Reviewer_z1Zm"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2510/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971386204, "cdate": 1761971386204, "tmdate": 1762916260875, "mdate": 1762916260875, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the author proposes Purple, a light-weight retrieval ranking algorithm for personalization. It pivots on the intuition that the retrieved user profiles will not be entirely useful for the language models, and with an effective ranking algorithm, the LLM can get better context when facing the generation task. Purple utilizes a contextual bandit framework that learns to select and rank user history records by optimizing directly for downstream task performance. The empirical results show moderate improvement over classic personalization datasets such as LaMP and LongLAMP."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1. Overall, the paper is clearly written, and the notation is clear. The idea of effectively leveraging the retrieved content is a crucial yet under-explored topic. Current frameworks focus on retrieving context and ignores the idiosyncrasies of the retrieved context. \n\nS2. The paper also present interesting findings in Figure 1 where the empirical results show mixed results on the inclusion of the retrieved content, which gives crucial insights to future researchers. \n\nS3. The problem formulation and method is technically sound and the idea of modeling the task of personalization as a contextual bandit optimization problem is novel."}, "weaknesses": {"value": "W1. Although the retrieved results might have different utility, the motivation is not well founded. Current language models are evolving towards increasingly better utilization of longer context [1]. Often the user profile does not exceed the context window limit, even for datasets such as LongLamp. The author only selects top 3 or top 5 user history, which can be arbitrary and not realistic. \n\nW2. The result improvement is marginal. In table 1, multiple results only have around 0.02 performance comparing to basic baselines. For Ratings improvement, the improvement is smaller as Phi-4-Mini demonstrates 0.004, Llama3-8b demonstrates 0.002, and Llama3-70-B demonstrates 0.005 improvement over baseline. Additionally, the performance improvement is even less consistent in the text generation task, as shown in the LaMP dataset (News, Scholar, Tweet) and LongLaMP dataset (Abstract, Topic, Review), with multiple baselines outperforming the proposed PURPLE framework. With the marginal improvement, the author should at least include standard deviation in the experiment reports. \n\nW3. More ablation study is needed. Although the framework is well justified from the design perspective, the specific component needs to be further studies. For example, the user can further explore the different effects of various encoders in the study. \n\nW4. Prior study has shown that semantic metrics alone cannot fully capture personalization [4]. We should include more advanced LLM-as-a-Judge evaluation [4] in the evaluation, as well as case studies on the generated text."}, "questions": {"value": "1.\tTo address weakness #1, the author could show results from longer context window. For example, investigating if setting k=15 can still maintain the performance improvement from PURPLE.  \n\n2.\tThe author needs to further refine the framework and improve the marginal performance gain, as well as provide additional standard deviation measurement in the experiment section. \n\n3.\tMissing citations [2, 3, 4]. \n\n4.\tPlease include LLM-as-a-Judge metrics as it has shown that semantic metrics alone cannot fully capture personalization. \n\n5.\tPersonalization is highly subjective, it would be helpful if the author can provide extensive case studies in the experiment section. \n\n[1] A Comprehensive Survey on Long Context Language Modeling. Liu, et al. \n[2] A Personalized Conversational Benchmark: Towards Simulating Personalized Conversations. Li, et al. \n[3] ExPerT: Effective and Explainable Evaluation of Personalized Long-Form Text Generation. Salemi, et al. \n[4] Personalized Language Modeling from Personalized Human Feedback. Li, et al."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QpSfLPJwXB", "forum": "U616C5HpG2", "replyto": "U616C5HpG2", "signatures": ["ICLR.cc/2026/Conference/Submission2510/Reviewer_gsBw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2510/Reviewer_gsBw"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2510/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980295642, "cdate": 1761980295642, "tmdate": 1762916260198, "mdate": 1762916260198, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}