{"id": "3UDlRUf1es", "number": 11852, "cdate": 1758204257747, "mdate": 1759897550791, "content": {"title": "DeCo-DETR: Decoupled Cognition DETR for efficient Open-Vocabulary Object Detection", "abstract": "Open-Vocabulary Object Detection (OVOD) plays a critical role in autonomous driving and human-computer interaction by enabling perception beyond closed-set categories. However, current approaches predominantly rely on multimodal fusion, facing dual limitations: multimodal fusion methods incur heavy computational overhead from text encoders, while task-coupled designs compromise between detection precision and open-world generalization. To address these challenges, we propose Decoupled Cognition DETR, a vision framework featuring a three-stage cognitive distillation mechanism: Dynamic Hierarchical Concept Pool constructs self-evolving concept prototypes using LLaVA-generated region descriptions filtered by CLIP alignment, aiming to replace costly text encoders and reduce computational overhead; Hierarchical Knowledge Distillation decouples visual-semantic space mapping via prototype-centric projection, avoiding task coupling to enhance open-world generalization; Parametric Decoupling Training coordinates localization and cognition through dual-stream gradient isolation, further optimizing detection precision. Extensive experiments on the common OVOD evaluation protocol demonstrated that DeCo-DETR achieves state-of-the-art performance compared to existing OVOD methods. It provides a new paradigm for extending OVOD to more real-world applications.", "tldr": "", "keywords": ["Open-Vocabulary Object Detection", "Knowledge Distillation", "Multi-modal"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/474895b5a20096523629afde32cd03c88006a49c.pdf", "supplementary_material": "/attachment/9a6d072717188275317d8a9cd4b5196498c8493b.zip"}, "replies": [{"content": {"summary": {"value": "This article introduces DeCo-DETR (Decoupled Cognition DETR), a novel open-vocabulary object detection (OVOD) framework designed to overcome the limitations of existing methods, particularly high computational overhead from text encoders and a trade-off between detection precision and open-world generalization."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This paper identifies certain issues in current large model-based OVD models, proposes a viable approach to address them, and conducts comprehensive experiments that can serve as a valuable reference for future research."}, "weaknesses": {"value": "The description on issues and challenges lacks persuasiveness, and the connection between the proposed method and the challenges it aims to address is weak. Furthermore, the explanation of the methodology lacks clarity, and the presentation of figures, tables, as well as certain parts of the writing, appears somewhat casual. Overall, the rigor of the work needs to be enhanced."}, "questions": {"value": "1. In Section 1, Paragraph 1, the authors assert that “the emergence of large language models (LLMs) has significantly enhanced detector generalization by providing richer and more nuanced semantic supervision,” yet no supporting citation is provided. Similarly, the authors claim that existing distillation methods face latency and generalization trade-offs, again without citing any references. It is recommended that relevant citations or quantitative results be added to substantiate these claims.\n\n2. In Section 1, Paragraph 2, the authors state that multimodal fusion designs inherently involve compromises, but they provide no explanation, citation, or quantitative evidence to support this claim. As a result, the argument lacks persuasiveness.\n\n3. In Section 1, Paragraph 3, the DHCP module is introduced without clarifying how it addresses the challenge outlined in the preceding paragraph. Moreover, the mention of “momentum updates with attention weighting” is confusing, and the authors should elaborate on its relationship with DHCP.\n\n4. A similar issue arises in Section 1, Paragraph 4, where the connection between the proposed design and the previously mentioned challenges is not clearly articulated.\n\n5. Due to the issues raised in points 1–4, the first contribution claim in Section 1—“We reveal two critical flaws in existing open-vocabulary detection”—does not appear sufficiently supported.\n\n6. In the second contribution statement in Section 1, the authors mention “dynamic concept pooling” and “hierarchical distillation and parametric isolation mechanisms” as solutions to the identified challenges. However, these terms appear only in this section and are likely referring to “DHCP” and “Hi-Know PDA” introduced later in the manuscript. The current wording is ambiguous and may cause confusion.\n\n7. In Figure 1, the bottom-left subfigure seems unnecessary. Additionally, the caption indicates that Hi-Know PDA is part of the framework diagram, but it is not visually represented.\n\n8. Several issues are present in Section 3. For instance, the “spectral clustering-based hierarchical compression algorithm” is mentioned for the first time in Section 3.1, yet its specific operation is not explained, nor is it illustrated in any figure or pseudocode.\n\n9. Certain references are missing throughout the manuscript. For example, LLaVA and DBSCAN are not cited.\n\n10. The results in Table 3 are unclear. DeCo-DETR does not appear to be the most efficient method according to the table. Moreover, comparing it with Deformable-DETR is confusing, as Deformable-DETR is not an open-vocabulary object detection (OVOD) method nor serves as the baseline for DeCo-DETR.\n\n11. In Section 4.3, Table 2, the benchmarks V-OVD, G-OVD, C-OVD, and WS-OVD are neither introduced nor cited. While these may originate from OVCOCO (Bansal et al., 2018), they are not referenced in the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "K8T3j076r5", "forum": "3UDlRUf1es", "replyto": "3UDlRUf1es", "signatures": ["ICLR.cc/2026/Conference/Submission11852/Reviewer_7QW3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11852/Reviewer_7QW3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11852/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923892806, "cdate": 1761923892806, "tmdate": 1762922867689, "mdate": 1762922867689, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DeCo-DETR, a framework for open-vocabulary object detection that aims to eliminate text encoder dependency during inference while improving generalization. The approach introduces three main components: (1) Dynamic Hierarchical Concept Pool (DHCP) that constructs visual prototypes using LLaVA-generated descriptions filtered by CLIP, (2) Hierarchical Knowledge Distillation (Hi-Know DPA) for visual-semantic alignment, and (3) Parametric Decoupling Training (PD-DuGi) with gradient isolation. The method achieves competitive results on OV-COCO and OV-LVIS benchmarks with low inference latency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Novel approach to eliminating text encoder dependency. The Dynamic Hierarchical Concept Pool is an interesting idea that pre-computes and maintains visual prototypes, eliminating the need for text encoders at inference time. \n- The results show strong empirical performance. The experiments demonstrates consistent improvements across multiple benchmarks and settings, achieving state-of-the-art result while maintaining reasonable computational cost."}, "weaknesses": {"value": "- There exists several misleading claims. 1) The paper claims to eliminate \"multimodal fusion\" but DHCP construction still heavily relies on LLaVA and CLIP. 2) The framework is only vision-only at inference, not overall.\n- Lack in-depth ablations. The ablation study in table 4 only compares 2 configurations, not isolating individual component contributions."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VUQacWJOrD", "forum": "3UDlRUf1es", "replyto": "3UDlRUf1es", "signatures": ["ICLR.cc/2026/Conference/Submission11852/Reviewer_G9cE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11852/Reviewer_G9cE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11852/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761937437258, "cdate": 1761937437258, "tmdate": 1762922867254, "mdate": 1762922867254, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This manuscript targets open-vocabulary object detection (OVOD) and proposes DeCo-DETR, a three-stage decoupled cognition pipeline."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "[1] DHCP: a dynamic, hierarchical concept pool that generates region descriptions with LLaVA and filters them with CLIP to build semantic prototypes (thus removing the text encoder at test time); \n\n[2] Hi-Know DPA: hierarchical knowledge distillation that projects decoder queries into the prototype space for prototype attention/alignment; \n\n[3] Parametric Decoupling Training: a dual-stream gradient isolation scheme that routes localization and semantic-alignment gradients separately. \n\n[4] DeCo-DETR reports strong gains (+3.5 to +7.2 AP on novel classes) while keeping inference at 135 ms/image."}, "weaknesses": {"value": "[1 ]Missing scale ablation on queries and prototypes：There is no systematic ablation for the number of decoder queries N=2000and the total number of prototypes M=M_1+M_2(with M_1=1203 coarse anchors and M_2=4800 fine units). In DETR-style models, increasing the number of queries and prototypes generally improves accuracy, but drives memory usage up linearly;\n\n[2] Fairness of the efficiency comparison (Table 3)：One of the paper’s main claims is removing multimodal computation at test time. For fairness, Table 3 should include methods with similar accuracy and comparable settings. As it stands, Table 3 under-represents strong multimodal fusion baselines near DeCo-DETR accuracy, making the efficiency story less convincing;\n\n[3] Isolating the independent contribution of Parametric Decoupling Training：Section 4.4 shows that the cosine annealing weight adds ~+1.6 AP_50, but this does not quantify the benefit of Parametric Decoupling Training itself."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "76bhpcH0kv", "forum": "3UDlRUf1es", "replyto": "3UDlRUf1es", "signatures": ["ICLR.cc/2026/Conference/Submission11852/Reviewer_pDPC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11852/Reviewer_pDPC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11852/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762048325443, "cdate": 1762048325443, "tmdate": 1762922866838, "mdate": 1762922866838, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DeCo-DETR, an open-vocabulary object detector that removes dependence on text encoders and improves both precision and generalization. It introduces a three-stage cognitive distillation mechanism—a dynamic concept pool from LLaVA-CLIP filtering, hierarchical knowledge distillation for decoupled visual-semantic mapping, and parametric dual-stream training for coordinated localization and recognition."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe paper introduces a three-stage cognitive distillation framework (DHCP, Hi-Know DPA, PD-DuGi) that provides a conceptually coherent and interpretable alternative to conventional multimodal fusion.\n2.\tThe model achieves improvements in both detection accuracy and inference efficiency, effectively reducing computational cost while maintaining strong open-vocabulary generalization."}, "weaknesses": {"value": "1.\tMain weakness – Metric inconsistency (Table 1). The reported AP50 values are higher than both APNovel50 and APBase50, which violates standard OVOD evaluation logic. Since AP50 includes both base and novel categories, its score should theoretically lie between them. This inconsistency casts doubt on the correctness of the evaluation protocol or result reporting, and substantially weakens the empirical credibility of the paper’s main claims.\n2.\tIncomplete ablation (Table 4). Table 4 is missing key variants and does not include an ablation isolating the proposed Dual-stream Gradient Isolation Mechanism, leaving its effectiveness unverified."}, "questions": {"value": "1.\tThe manuscript implicitly assumes the student prototypes A and teacher prototypes P share a one-to-one correspondence via the same M, but it is unclear how this mapping is defined or established, since A results from unsupervised clustering and P is text-derived."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "kslM9od73j", "forum": "3UDlRUf1es", "replyto": "3UDlRUf1es", "signatures": ["ICLR.cc/2026/Conference/Submission11852/Reviewer_Ttz9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11852/Reviewer_Ttz9"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11852/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762056088896, "cdate": 1762056088896, "tmdate": 1762922866305, "mdate": 1762922866305, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}