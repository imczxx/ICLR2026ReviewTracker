{"id": "I6j5fLdH80", "number": 466, "cdate": 1756741234086, "mdate": 1759898259076, "content": {"title": "RegionE: Adaptive Region-Aware Generation for Efficient Image Editing", "abstract": "Recently, instruction-based image editing (IIE) has received widespread attention. In practice, IIE often modifies only specific regions of an image, while the remaining areas largely remain unchanged. Although these two types of regions differ significantly in generation difficulty and computational redundancy, existing IIE models do not account for this distinction, instead applying a uniform generation process across the entire image. This motivates us to propose \\textbf{RegionE}, an adaptive, region-aware generation framework that accelerates IIE tasks without additional training. Specifically, the RegionE framework consists of three main components: 1) Adaptive Region Partition. We observed that the trajectory of unedited regions is straight, allowing for multi-step denoised predictions to be inferred in a single step. \nTherefore, in the early denoising stages, we partition the image into edited and unedited regions based on the difference between the final estimated result and the reference image. 2) Region-Aware Generation.  After distinguishing the regions, we replace multi-step denoising with one-step prediction for unedited areas. \nFor edited regions, the trajectory is curved, requiring local iterative denoising. To improve the efficiency and quality of local iterative generation, we propose the Region-Instruction KV Cache, which reduces computational cost while incorporating global information. \n3) Adaptive Velocity Decay Cache. \nObserving that adjacent timesteps in edited regions exhibit strong velocity similarity, we further propose an adaptive velocity decay cache to accelerate the local denoising process.\nWe applied RegionE to state-of-the-art IIE base models, including Step1X-Edit, FLUX.1 Kontext, and Qwen-Image-Edit. RegionE achieved acceleration factors of 2.57×, 2.41×, and 2.06×, respectively, with minimal quality loss (PSNR: 30.520–32.133). Evaluations by GPT-4o also confirmed that semantic and perceptual fidelity were well preserved.\nCode will be open-sourced.", "tldr": "", "keywords": ["Image Editing", "Efficient", "Diffusion Transformer", "Acceleration"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c526056c22a23481606c4ae5b12e7413a520b261.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper “RegionE: Adaptive Region-Aware Generation for Efficient Image Editing” proposes a training-free acceleration framework for instruction-based image editing (IIE). Unlike previous diffusion-based editing models that apply uniform denoising to all image regions, RegionE distinguishes between edited and unedited areas to eliminate spatial and temporal redundancy.\nThe system consists of three key modules:\n\n* Adaptive Region Partition (ARP) — identifies edited and unedited regions based on cosine similarity between estimated and instruction images.\n\n* Region-Instruction KV Cache (RIKVCache) — reuses cached key–value pairs from previous full computations to maintain global context while locally generating edited regions.\n\n* Adaptive Velocity Decay Cache (AVDCache) — models velocity decay across timesteps to accelerate iterative denoising."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The combination of ARP, RIKVCache, and AVDCache addresses both spatial and temporal redundancy coherently and without retraining.\n\n* Evaluations on three major IIE models with consistent metrics and ablations (on cache design and stage structure) convincingly support the claims.\n\n* The paper is technically detailed and easy to follow, with illustrative figures and pseudocode."}, "weaknesses": {"value": "* Pipeline complexity: The full system involves multiple interdependent stages (STS, RAGS, SMS) and caches, making implementation and integration non-trivial.\n\n* Limited discussion of efficiency factors: It remains unclear whether acceleration benefits scale with the size of the edited region—larger edits may reduce efficiency gains.\n\n* Lack of novelty: Although the combination of adaptive partitioning and caching is well-engineered, each component conceptually extends known acceleration ideas (e.g., residual cache, spatial redundancy) rather than introducing a fundamentally new principle.\n\n* Missing user/perceptual study: Although GPT-4o scoring is used, no human user study or subjective evaluation supports perceptual fidelity claims.\n\n* Potential failure cases not analyzed: No discussion of situations where region partitioning might misclassify boundaries or produce artifacts.\n\n* Incomplete citation coverage: Some prior works on region-aware or local editing (e.g., Blended Diffusion, Object-aware Inversion and Reassembly) are not cited or compared."}, "questions": {"value": "* How does the acceleration performance scale with the size or proportion of the edited region? Would larger editing areas significantly reduce the overall efficiency gains?\n\n* To what extent does the proposed method introduce conceptual novelty beyond existing acceleration ideas?\n\n* Have the authors considered conducting a user study or subjective perceptual evaluation to validate the visual quality beyond GPT-4o-based automatic scoring?\n\n* What are the potential failure cases of the proposed adaptive region partition? For example, could boundary misclassification between edited and unedited regions cause visible artifacts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9Nt1ISp02P", "forum": "I6j5fLdH80", "replyto": "I6j5fLdH80", "signatures": ["ICLR.cc/2026/Conference/Submission466/Reviewer_uJ7h"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission466/Reviewer_uJ7h"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission466/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760718195711, "cdate": 1760718195711, "tmdate": 1762915525986, "mdate": 1762915525986, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an acceleration framework for instruction-based image editing tasks. The authors identify two types of redundancy in existing methods: spatial redundancy and temporal redundancy. Spatially, certain image regions remain unchanged before and after editing, and the denoising process for these regions can be significantly accelerated. To address this, the authors design a region partition method to distinguish between fixed regions and editable regions, applying one-step generation to the fixed regions. Temporally, the authors observe strong similarity in velocity between adjacent denoising timesteps, enabling acceleration through a feature cache-based method. Due to the task-specific improvements in the framework's design, it achieves both efficiency and effectiveness enhancements on image editing benchmarks compared with existing acceleration methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- It effectively tackles both spatial and temporal redundancies. By partitioning images into edited and unedited regions and leveraging temporal similarities between timesteps, it achieves comprehensive speed improvements. \n- The proposed framework is specifically tailored for DiT-based instruction image editing. The authors provide some deep insights on DiT cache designs, which may encourage future works."}, "weaknesses": {"value": "- The region partition approach, while highly effective, may not be fundamentally novel. Previous inversion-based image editing methods have been using attention scores to extract masked regions for editing[1][2]. \n- The temporal acceleration method shares conceptual similarities with existing work in general-purpose diffusion acceleration.\n\n[1]Uniform Attention Maps: Boosting Image Fidelity in Reconstruction and Editing. WACV 2025.\n[2]DiffEdit: Diffusion-based semantic image editing with mask guidance. ICLR 2023."}, "questions": {"value": "- Please clarify the strengths of the proposed region partition method compared to previous partition methods in inversion-based editing methods. \n- The adaptive velocity decay cache is mainly based on velocity similarities. The results of cache reuse are not explored. For example, at the very early stage of denoising process, the L1 sim / cos sim are low, but the errors introduced by cache reuse may be re-corrected in later denoising process, thus applying cache strategy under low similarities can also be considered."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "kRF2UqIs2t", "forum": "I6j5fLdH80", "replyto": "I6j5fLdH80", "signatures": ["ICLR.cc/2026/Conference/Submission466/Reviewer_Npav"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission466/Reviewer_Npav"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission466/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760944798106, "cdate": 1760944798106, "tmdate": 1762915525877, "mdate": 1762915525877, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces RegionE, a training-free framework that accelerates instruction-based image editing by treating edited and unedited regions differently. It detects unedited areas with near-linear trajectories that can be estimated in one step, while edited regions are refined iteratively. Using adaptive region partitioning, cached attention features, and velocity decay reuse, RegionE achieves 2–2.6× faster inference on Step1X-Edit, FLUX.1 Kontext, and Qwen-Image-Edit with minimal quality loss and no retraining required."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Addresses an important and practical issue: the high inference cost of instruction-based image editing.\n- Proposes a training-free framework (RegionE) combining spatial and temporal acceleration strategies.\n- Demonstrates consistent 2–2.6× speedups across several strong IIE baselines with minimal perceptual degradation.\n- Includes solid ablation studies confirming the contributions of key components like RIKVCache and AVDCache.\n- The framework is model-agnostic and can be applied to different diffusion-based editors without retraining."}, "weaknesses": {"value": "- The approach is primarily engineering-oriented, integrating existing acceleration techniques (e.g., caching and region partitioning) into a coherent framework focused on practical efficiency.\n- Relies heavily on region partition accuracy; there is no ablation or sensitivity analysis of the Adaptive Region Partition (ARP)\n- The parameter choices for thresholds $\\eta$ and $\\delta$ are fixed heuristically, with no explanation or adaptive tuning strategy.\n- Limited discussion of computational trade-offs, such as memory footprint or the cost of region masking.\n- No discussion of failure cases, such as edits involving multiple or overlapping regions, or complex global changes that may break the region partition.\n- In addition to the previous point, the evaluation focuses on overall metrics, lacking analysis of cases where RegionE may underperform (e.g., subtle texture or lighting edits).\n\n(Minor)\n\n- The related work section misses recent region-aware diffusion editing methods such as LIME [1] and Focus on Your Instruction [2], which could better situate RegionE within related spatial editing research.\n\n[1] Simsar, E., Tonioni, A., Xian, Y., Hofmann, T., & Tombari, F. (2025, February). Lime: localized image editing via attention regularization in diffusion models. In WACV'25.\n\n[2] Guo, Q., & Lin, T. (2024). Focus on your instruction: Fine-grained and multi-instruction image editing by attention modulation. In CVPR'24."}, "questions": {"value": "1. How sensitive is RegionE to the partition threshold $\\eta$ and decay threshold $\\delta$? How did the authors determine these parameters in practice? Could they be learned adaptively from attention maps or reconstruction loss?\n2. How does ARP handle ambiguous or overlapping boundaries between edited and unedited regions, especially when the change is gradual or when multiple small edits occur in different parts of the image?\n3. Have the authors observed drift or accumulated errors from AVDCache over long denoising sequences, and is the forced full-image update mechanism sufficient to prevent visible artifacts?\n4. How does RegionE perform on global or style editing tasks that modify most of the image content? In such cases, does the region partition still provide computational benefits?\n5. What is the memory and runtime overhead of the caching mechanisms, and how does RegionE scale with image resolution or batch size compared to standard inference?\n\n\n\n(Minor - short discussion)\n\n6. Could the approach extend to video or 3D editing, where temporal/spatial coupling is stronger?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "t0WQ1gEiVo", "forum": "I6j5fLdH80", "replyto": "I6j5fLdH80", "signatures": ["ICLR.cc/2026/Conference/Submission466/Reviewer_nyRe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission466/Reviewer_nyRe"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission466/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762418455903, "cdate": 1762418455903, "tmdate": 1762915525711, "mdate": 1762915525711, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}