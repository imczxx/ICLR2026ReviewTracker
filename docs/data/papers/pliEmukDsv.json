{"id": "pliEmukDsv", "number": 20474, "cdate": 1758306577817, "mdate": 1763761052073, "content": {"title": "Column Thresholding: Bridging the Computational-Statistical Gap in the Sparse Spiked Wigner Model", "abstract": "We study the sparse spiked Wigner model, where the goal is to recover an $s$-sparse unit vector $\\mathbf{u} \\in \\mathbb{R}^d$ from a noisy matrix observation $\\mathbf{Y} = \\beta \\mathbf{u} \\mathbf{u}^\\top + \\mathbf{W}$. While the information-theoretic threshold is $\\beta = \\widetilde{\\Omega}(\\sqrt{s})$, existing polynomial-time algorithms require $\\beta =  \\widetilde{\\Omega}(s)$, yielding a substantial computational-statistical gap. We propose a column thresholding method that attains the $\\widetilde{\\Omega}(\\sqrt{s})$ scaling for estimation and support recovery under the condition $\\|\\mathbf{u}\\|_\\infty = \\Omega(1)$. Building on this initializer, we further develop a truncated power method that iteratively refines the estimate with provable linear convergence. Experiments validate our theoretical guarantees and demonstrate superior performance in estimation accuracy, support recovery, and computational efficiency.", "tldr": "", "keywords": ["spiked Wigner model", "spectral method", "diagonal thresholding", "truncated power method"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6af93500ac6e674c1697b9d186963563d9e720d4.pdf", "supplementary_material": "/attachment/171d322e4bb07120fe907092412f8aaad5aa6f72.zip"}, "replies": [{"content": {"summary": {"value": "The paper considers the sparse spiked Wigner model, i.e the task to detect an $s$-sparse vector $u$ from an observation of the process $Y=\\beta uu^* + W$, where $W$ is drawn from the Gaussian orthogonal ensemble, and $\\beta>0$ is a signal strength factor ( $\\Vert{u}\\Vert=1$ by convention). The hardness of this problem is interesting: If $\\beta \\sim s$, the vector can easily be estimated (e.g. through spectral methods, or so-called diagonal thresholding), but if $\\beta\\preccurly \\sqrt{s}$, it is information theoretically impossible to retrieve it - it will always drown in the $W$-noise. In between those threshold, it is widely believed that it should be \\emph{computationally} hard to solve the problem -- in particular, no known algorithms of polynomial complexity exists.\n\nThe authors show that under an additional 'peakiness condition' -- one entry is 'uniformly large in $s$ and $d$', $\\Vert u \\Vert_\\infty >c$, recovery can be secured using column thresholding. In essence, the idea is to first find that uniformly large entry through diagonal thresholding -- which is simple given it is large -- and then only look at the corresponding column in $Y$, and find the correct entries of $u$ by thresholding in that column. The latter problem is 'easy', and it will succeed for $\\beta\\sim \\sqrt{s\\log(d)}$.\n\nThe authors also discuss how their column-threshold algorithm can be used as an initialization step for the truncated power algorithm."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This manuscript has a lot of strengths. It addresses a timely problem and is easy to read. The algorithm is well-described, and the numerical experiments are reasonable. It in particular is interesting to see that it seems to fare well compared to SOTA approaches even without the peakiness condition (figure 4)"}, "weaknesses": {"value": "There is not much to say here, in my opinion. The paper is quite solid. One possible complaint is that while the theoretical result is nice and interesting, I am unsure how much it helps the 'probing of the computationally hard $H$-area' in Figure 1. Assuming that $u$ has a large entry fundamentally changes the challenge of retrieving $u$ from $Y$."}, "questions": {"value": "Figure 4 seems to suggest that their algorithm does better than known 'simple' algorithms for determining $u$ also in the case of uniform amplitudes. I think it would be interesting to investigate this further. Can similar plots like figure 2 and 3 be made for column-thresholding-initialized truncated power algorithm in the setting described in section 4.2, i.e., with uniform amplitudes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "ub0hhZkVDy", "forum": "pliEmukDsv", "replyto": "pliEmukDsv", "signatures": ["ICLR.cc/2026/Conference/Submission20474/Reviewer_ccPS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20474/Reviewer_ccPS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20474/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761667882352, "cdate": 1761667882352, "tmdate": 1762933914862, "mdate": 1762933914862, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the spiked Wigner model, where the goal is to recover a s-sparse unit vector u \\in \\reals^d from a noisy matrix observation. There is a known statistical-computational gap in the signal parameter \\beta lying between \\sqrt{s} and s. The authors propose a column thresholding algorithm that seems to close this gap under the additional condition that the entries of u do not vanish. They combine this with existing truncated power methods to yield methods with provably linear convergence. They support their theoretical findings with experiments."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The authors seem aware of the literature, important papers in the field are cited and the associated regimes are mentioned correctly. The authors clarify the gap they are addressing, and in what cases their solution is significant or not. \n\nThe work is original in that it provides a new (although clearly inspired by the existing covariance thresholding) method for solving the problem, which shows certain benefits. The author’s theoretical work demonstrate that they bridge the gap under the additional condition that the entries of u not vanishing which, combined with the unit norm assumption, implies that the theorem is most useful when the entries of u are non-vanishing but square-integrable, such as having power law coefficients. \n\nThe paper is fairly clear, I understood the contributions and the gap they are addressing, and papers are well cited. \n\nThe work has a level of significance to it, they demonstrate favourable performance of their method experimentally and give theoretical justification for improved sample size in the more restricted scenario of non-vanishing signals that are square integrable (ex. power law distributed)."}, "weaknesses": {"value": "- There needs to be a better explanation of the past results on the stat comp gap in spiked wigner: I was not sure whether you were claiming that you closed the stat-comp gap until nearly halfway. It would be good to state precisely the Brennan-Bresler or other results, and stating precisely their assumptions, and why you don’t contradict their algorithmic lower bound but instead circumvent it by incorporating an additional assumption.\n- The assumption that u has non-vanishing entries is more restrictive than it seems: the authors must remind the reader that u is also assumed to have unit norm. This causes the only interesting priors on u to be that of square-integrable functions supported on the support of u: such as power law functions. These have their motivations in machine learning, but maybe one should make clear that u has to be unit norm and that hence we are still in the same scaling as in other papers. I am also not thoroughly convinced of the applicability/pervasiveness of sparse and power-law distributed signals.\n- If the power law example is the main motivation for the benefit of this work, how do other methods do when a power law and unit prior is used on u? Does covariance thresholding fail in that case, or is that just an artifact of previous proofs which did not consider this specific prior?\n- Can you suggest more examples of priors for u for which your theorems bridge the stated stat-comp gap, beyond power law priors?\n- Grandiose language seems unjustified: “column thresholding algorithm provides a breakthrough” 2/3’s down of page 6.\n- The experimental results claim to validate the method’s theoretical guarantees. I want to note that various papers have mentioned that laptop-scale experiments are generally unable to validate stat-comp gaps experimentally (see [Lovig,Zadik 2024], [Iliopoulos, Zadik 2021], [Coja-Oghlan, Ghebard, Hahn-Klimroth, Wein, Zadik 2022], for example). Therefore, I do not find the claims of “breaking” statistical-computational gaps via experiment convincing. If you wish to keep these claims in the paper, then clarify that they do are not guaranteed to validate your theoretical results.  I do, however, find it convincing that this method outperforms others experimentally in certain settings, and that should indeed be highlighted, I just want to check that these experiments against other methods were done at the correct scalings of \\beta, u, W that the other methods expect?"}, "questions": {"value": "- Asked in the \"Weaknesses\" section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "37SuguGXd9", "forum": "pliEmukDsv", "replyto": "pliEmukDsv", "signatures": ["ICLR.cc/2026/Conference/Submission20474/Reviewer_GbRG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20474/Reviewer_GbRG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20474/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761944217690, "cdate": 1761944217690, "tmdate": 1762933913993, "mdate": 1762933913993, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the sparse spiked Wigner model. \n\nIn Section 2, the authors introduce two column-thresholding methods for recovering the signal vector $u$. The core idea is that the diagonal entries $Y_{ii}$ with $i$ being in the true support tend to be larger. Algorithm 1 first applies thresholding to estimate the support and then computes the principal eigenvector. Algorithm 2 simplifies the procedure by omitting the eigenvector computation, yet still achieves competitive performance.\n\nSection 3 incorporates an iterative refinement scheme using hard thresholding to further improve the estimator. Section 4 presents experimental results, and Section 5 concludes the paper."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is overall quite solid.\n2. I have not checked every detail of the proofs, but I randomly sampled several arguments and can confirm that the steps I examined appear correct."}, "weaknesses": {"value": "1. The topic is well-studied, particularly in the context of sparse PCA.\n\n2. The main contribution lies in Section 2. The results in Section 3 follow in a fairly automatic manner: in the non-convex optimization setting, the central requirement is convergence to the true signal given a sufficiently good initialization (Show the initial point satisfy the Equation 10 and then the proof is completed by invoking the results in Yuan & Zhang 2013). \n\nThis paper essentially proposes an alternative method for obtaining such an initialization. However, the procedure for selecting the initial point is also fairly standard: one first analyzes the expected behavior and then uses concentration inequalities to show that the empirical value is close to its expectation. (To the best of my knowledge, the oldest paper that adopts the idea is in  Phase Retrieval via Wirtinger Flow: Theory and Algorithms published in 2014 [https://arxiv.org/pdf/1407.1065] See algorithm 1.  A tutorial of this framework is Nonconvex Optimization Meets Low-Rank Matrix Factorization: An Overview. Published in 2019.). \n\n3. Some of the notation is not entirely consistent. For example, at the beginning of Section 3, the sparsity parameter changes from $s$ to $k$ (In equation 7, 8, 9). In Section A, Equation (12) uses $\\rho(B, s)$, which should be $\\rho(B,\\ell)$."}, "questions": {"value": "Please see the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "j533NaSrgJ", "forum": "pliEmukDsv", "replyto": "pliEmukDsv", "signatures": ["ICLR.cc/2026/Conference/Submission20474/Reviewer_GA36"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20474/Reviewer_GA36"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20474/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761985128124, "cdate": 1761985128124, "tmdate": 1762933913496, "mdate": 1762933913496, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the sparse spiked Wigner model and proposes an extremely simple column thresholding method for recovering the sparse vector $u$. The authors claim that, under the assumption $|u|_\\infty = \\Omega(1)$, their method achieves recovery at signal strength $\\beta = \\tilde{\\Omega}(\\sqrt{s})$, thus “bridging the computational–statistical gap” between the information-theoretic limit and the best known polynomial-time algorithms (which require $\\beta = \\tilde{\\Omega}(s)$).\n\nThe method consists of two steps: (i) selecting the index of the largest diagonal entry of $Y$, then (ii) thresholding the corresponding column to obtain a support estimate, followed by either (a) computing the leading eigenvector on the selected submatrix or (b) normalizing the column directly. A subsequent truncated power method (TPM) refinement is analyzed and empirically shown to improve accuracy.\n\nThe paper provides theoretical guarantees for estimation error and support recovery, with matching empirical phase transitions. The presentation is clean and the algorithm indeed performs well in small-sparsity regimes."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Clarity and Simplicity: The proposed method is remarkably simple and easy to implement. The authors provide clean, reproducible experiments.\nRigorous Analysis (within its scope): The concentration bounds and proof techniques are mathematically sound for the finite-$s$ regime.\nComputational Efficiency: $O(d\\log d + s^3)$ complexity makes the method appealing for small $s$.\nEmpirical Validation: The experimental phase transition agrees with the derived scaling $\\beta \\sim \\sqrt{s\\log d}$.\n\nThe paper is clearly written and well organized. The main algorithm is easy to understand, and the comparison with diagonal and covariance thresholding is nicely presented. Figures are readable and the empirical validation is convincing within the tested range"}, "weaknesses": {"value": "Incorrect framing of the main claim. The “bridging of the computational–statistical gap” is only valid in a regime where no such gap exists. In the true proportional-sparsity regime, the algorithm does not apply and would fail.\n\nDependence on a strong assumption. The guarantee $|u|_\\infty = \\Omega(1)$ implies highly non-uniform signal amplitudes, unlike the uniform sparse prior $u_i = \\pm 1/\\sqrt{s}$ under which hardness results are known. This assumption essentially trivializes support recovery.\n\nLack of connection to planted clique hardness. The paper repeatedly references the “hard phase” diagram but does not clarify that the reduction to planted clique holds only for uniform sparse vectors in the proportional regime.\n\nLimited novelty. Column thresholding is a small conceptual variation of diagonal thresholding; the key insight (using off-diagonal information) is incremental rather than groundbreaking.\n\nMisleading interpretation. The paper risks confusing readers into believing that the planted-clique-based hardness barrier has been broken, which is not the case. The authors should explicitly acknowledge this."}, "questions": {"value": "While the proofs are internally consistent, the central claim—that the algorithm bridges the computational–statistical gap—is misleading in scope. The theorems are proven under the condition $|u|_\\infty = \\Omega(1)$ and rely heavily on $s$ being finite or sub-extensive (e.g., $s = O(1)$ or $s = O((\\log d)^k)$). In this regime, the problem is not believed to exhibit a genuine computational–statistical gap.\n\nThe well-known hardness conjectures for sparse PCA (e.g., Brennan et al., COLT 2018; Lesieur et al., ISIT 2015) and the connection to the planted-clique problem hold in the proportional-sparsity regime, where $s = d^{\\phi}$ with $0 < \\phi < 1$. In that setting, the gap between $\\beta_{\\mathrm{IT}} = \\tilde{\\Theta}(\\sqrt{s})$ and $\\beta_{\\mathrm{poly}} = \\tilde{\\Theta}(s)$ is conjectured hard, and no polynomial-time algorithm is known to close it.\n\nThus, the analysis here does not contradict existing hardness results—it simply applies to a different scaling where those results do not apply. The proofs rely on concentration arguments valid only when $s \\ll d$, and the key step (identifying the largest diagonal element) fails when $s$ grows with $d$.\n\nSaid difffernt: the paper’s analysis assumes $s$ is finite or grows sub-logarithmically with $d$, in which case the sparse PCA problem is already computationally easy. Indeed, when $s$ is constant, an exhaustive search over all $\\binom{d}{s}=O(d^s)$ possible supports is polynomial-time in $d$, and thus achieves the information-theoretic optimum without any algorithmic barrier. In this finite-$s$ regime, there is no genuine computational–statistical gap to bridge, since both brute force and simple thresholding succeed. The “hard” region of sparse PCA, connected to the planted-clique conjecture, emerges only when $s$ scales proportionally with $d$ (e.g., $s=d^{\\phi}$, $0<\\phi<1$). Consequently, while the proposed algorithm is mathematically sound, its asymptotic significance is limited to a regime where the problem is already tractable. \n\nBuilding on this clarification, I encourage the authors to address the following specific points:\n\n* Clarify the scaling regime.\nPlease state explicitly the intended asymptotic regime for $s$. Does your theorem hold when $s = d^{\\phi}$ for $\\phi > 0$?\nIf not, please clarify that your analysis focuses on finite or sub-extensive sparsity levels, outside the proportional regime where the computational–statistical gap is conjectured to exist (Lesieur et al., 2015; Brennan et al., 2018).\n\n* Connection to the planted-clique hardness.\nThe “hard phase” boundary in Figure 1 of your paper coincides with the region predicted to be intractable under the planted-clique hypothesis (Hopkins et al., FOCS 2017; Brennan et al., COLT 2018).\nCould you explicitly discuss why your result does not contradict this reduction? In particular, is it correct that your guarantees hold only in a setting where $s$ is too small—or $|u|_\\infty$ too large—for the planted-clique mapping to apply?\n\n* Role of the $\\ell_\\infty$ assumption.\nThe requirement $|u|_\\infty = \\Omega(1)$ implies a strong amplitude imbalance in the spike. This makes support recovery much easier and arguably removes the “hard phase.”\nCan you comment on whether your algorithm (and proof technique) could extend to the uniform case $u_i = \\pm 1/\\sqrt{s}$? If not, please emphasize that the success hinges on non-uniform amplitudes rather than a breakthrough in the proportional sparse PCA regime.\n\n* Growing-$s$ behavior.\nIt would be very helpful to include a discussion—or ideally, experiments—showing how the algorithm’s performance deteriorates as $s$ increases toward proportional scaling ($s \\sim d^{\\phi}$).\nFor example, at what growth rate of $s$ do the concentration bounds in your proofs fail, and the “largest diagonal element” trick cease to identify a true support element?\nA quantitative analysis of this transition would clarify precisely where the benefits of column thresholding disappear.\nCould you provide numerical experiments for $s$ growing with $d$ (e.g., $s = d^{1/2}$ or $s = 0.1,d$)?\n\n* Comparison to optimal limits in the proportional regime\nThe information-theoretic limits for sparse PCA in the proportional regime are rigorously analyzed in\n\nBarbier et al: https://proceedings.neurips.cc/paper_files/paper/2016/file/621bf66ddb7c962aa0d22ac97d69b793-Paper.pdf\nLelarge & Miolane (2017), COLT 2017: “Fundamental limits of symmetric low-rank matrix estimation.”\n\nYour result $\\beta = \\tilde{\\Omega}(\\sqrt{s})$ matches this optimal scaling only when $s$ is small. The gap discussed in these paper remains. Please clarify whether you see your contribution as an extension of these works or as a complementary result focusing on a different asymptotic regime.\n\n* Possible extensions to subspace clustering.\nSince your method essentially performs a one-shot column-based support estimation, could it be extended to more structured problems—such as Gaussian mixtures or subspace clustering under proportional scaling—like those studied in Pesce, Loureiro, Krzakala & Zdeborová (2022), arXiv:2205.13527?"}, "flag_for_ethics_review": {"value": ["No ethics review needed.", "Yes, Unprofessional behaviors (e.g., unprofessional exchange between authors and reviewers)"]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6Y1Gouhtkz", "forum": "pliEmukDsv", "replyto": "pliEmukDsv", "signatures": ["ICLR.cc/2026/Conference/Submission20474/Reviewer_MQMy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20474/Reviewer_MQMy"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20474/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992561393, "cdate": 1761992561393, "tmdate": 1762933912907, "mdate": 1762933912907, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}