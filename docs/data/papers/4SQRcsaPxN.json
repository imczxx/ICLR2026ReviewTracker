{"id": "4SQRcsaPxN", "number": 13091, "cdate": 1758213489675, "mdate": 1759897466024, "content": {"title": "GUIDE : Generalized-Prior and Data Encoders for DAG Estimation", "abstract": "Modern causal discovery methods face critical limitations in scalability, computational efficiency, and adaptability to mixed data types, as evidenced by benchmarks on node scalability (30, $\\leq50$, $\\geq70$ nodes), computational energy demands, and continuous/non-continuous data handling. While traditional algorithms like PC, GES, and ICA-LiNGAM struggle with these challenges, exhibiting prohibitive energy costs for higher-order nodes and poor scalability beyond 70 nodes, we propose GUIDE, a framework that integrates Large Language Model (LLM)-generated adjacency matrices with observational data through a dual-encoder architecture. GUIDE uniquely optimizes computational efficiency, reducing runtime on an average by $\\approx$ 42\\% compared to RL-BIC and KCRL methods, while achieving an average $\\approx$ 117\\% improvement in accuracy over both NOTEARS and GraN-DAG individually. During training, GUIDE’s reinforcement learning agent dynamically balances reward maximization (accuracy) and penalty avoidance (DAG constraints), enabling robust performance across mixed data types and scalability to $\\geq70$ nodes—a setting where baseline methods fail.", "tldr": "", "keywords": ["Casual Discovery", "LLM", "Reasoning"], "primary_area": "causal reasoning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fb13ace4c16f3533d29b641cb2d027ecceec1787.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a method named GUIDE. It employs a dual-encoder architecture to effectively integrate domain knowledge generated by Large Language Models with statistical patterns learned from observational data, leveraging Reinforcement Learning to guide the generation of the causal graph."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "It integrates domain knowledge from Large Language Models, serving as a prior, with statistical patterns learned from observational data to guide the generation of the causal graph."}, "weaknesses": {"value": "1.  The framework's effectiveness heavily relies on the quality of the prior provided by the LLM. However, the paper's analysis of this core component is far from adequate. The performance of GUIDE when the LLM prior is incorrect or biased remains uninvestigated. Appendix C mentions an adaptive weight `β`, but its effectiveness in mitigating the impact of erroneous priors is not experimentally validated. Furthermore, the reliance on GPT-4o, a powerful closed-source model, raises concerns about the method's generalizability and reproducibility, as the potential performance degradation when using weaker, open-source models is not discussed.\n\n2.  The paper claims to handle complex non-linear relationships using a neural network-based discovery module. However, the final, crucial pruning step utilizes simple linear regression coefficients to assess edge importance. This creates a methodological contradiction, as linear coefficients may not accurately reflect the strength of true non-linear causal relationships, undermining the consistency between the framework's core assumption and its implementation.\n\n3.  The reward function is a weighted sum of three terms with hyperparameters (λ1, λ2, β). The paper does not specify how these hyperparameters were selected, nor does it provide a sensitivity analysis regarding their impact on performance. Additionally, the description of the adaptive `β` mechanism in Appendix C is too brief to be fully understood or reproduced.\n\n4.  The authors heavily rely on a self-proposed metric, TP/NNZ, to demonstrate the superiority of their method. However, as shown in Figure 2, while GUIDE excels on TP/NNZ across several datasets, its performance on the standard Structural Hamming Distance (SHD) metric is often inferior to baselines like GES. This suggests a potential trade-off that is not adequately discussed, and a more comprehensive presentation of results is needed to substantiate the claims of effectiveness."}, "questions": {"value": "1.  What is the performance of GUIDE when its LLM prior contains a significant proportion of errors? Could you please provide results from this crucial ablation study?\n2.  Can you provide experimental evidence that the adaptive weight `β` mechanism, mentioned in Appendix C, effectively mitigates the impact of conflicting priors and thus ensures the model's robustness?\n3.  How much does performance degrade when replacing the proprietary GPT-4o with a publicly available, open-source LLM within the GUIDE framework?\n4.  Your model is designed to discover non-linear relationships, yet the pruning step relies on linear regression coefficients. Could you justify this design choice and clarify whether it compromises the ability to recover non-linear structures?\n5.  Your reward function depends on several hyperparameters (λ1, λ2, β). Could you provide details on the selection process for these parameters and an analysis of the model's sensitivity to their variations?\n6.  GUIDE shows superior performance on TP/NNZ but is not always optimal on SHD. Could you elaborate on this apparent trade-off between high precision and potentially lower recall, and argue why TP/NNZ should be considered a more critical metric in these scenarios?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "RA3nREpYDF", "forum": "4SQRcsaPxN", "replyto": "4SQRcsaPxN", "signatures": ["ICLR.cc/2026/Conference/Submission13091/Reviewer_M16o"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13091/Reviewer_M16o"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13091/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760773370068, "cdate": 1760773370068, "tmdate": 1762923817702, "mdate": 1762923817702, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to address the key limitations faced by modern causal discovery methods in terms of scalability, computational efficiency, and handling of mixed data types. The authors propose a novel framework named GUIDE, which integrates adjacency matrices generated by Large Language Models (LLMs) with statistical features from observational data through a dual-encoder architecture.\n\nThe core of this framework is a reinforcement learning (RL) agent, which is trained in an environment to optimize a composite reward function. This reward function dynamically balances data-fit, graph acyclicity, and penalties for consistency with prior knowledge. In this way, GUIDE aims to leverage the domain knowledge provided by LLMs to guide and constrain the RL agent's search space, thereby improving computational efficiency and accuracy while handling high-dimensional and mixed data type problems."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper proposes an architecture that integrates LLMs, dual encoders, and reinforcement learning, which is a very novel and timely attempt . Using LLMs as a source of \"generative priors\" and fusing them with data-driven features (Encoder-1) via a specific encoder (Encoder-2)  provides a promising avenue for injecting domain knowledge into causal discovery.\n\n2. The authors compare GUIDE with various mainstream methods, covering constraint-based (PC), score-based (GES), FCM-based (LINGAM), gradient-based (NOTEARS, GraNDAG), and RL-based (RL-BIC, KCRL) algorithms . This comprehensive comparison increases the credibility of the experimental results.\n\n3. Section 3.5 and Figure 4 of the paper provide a strong ablation analysis. The findings clearly show that using generative priors (ICL) alone or prior constraints alone both lead to performance improvements, while using both in combination produces a synergistic effect."}, "weaknesses": {"value": "1. The paper's core contribution is not prominent and seems exaggerated. The abstract mentions \"achieving an average $\\approx117\\%$ improvement in accuracy over both NOTEARS and GraN-DAG individually\". This \"accuracy\" metric is very vague. What does it refer to? Is it SHD? Or TPR? Or the newly proposed TP/NNZ? I also did not find this 117% description in the main text. Judging from the results shown in Figure 2 of the paper, GUIDE does not comprehensively surpass the baselines on different datasets (e.g., on datasets like LUCAS, ALARM).\n\n2. The paper suffers from serious confusion regarding the definition of \"prior\". The \"Require\" section of Algorithm 1 simultaneously lists \"Prior Adjacency Matrix $A_{Prior}$\" and \"LLM generated adjacency $A_{LLM}$\". However, in Step 3 of the algorithm, $A_{LLM}$ is fed into encoder E2; but in the reward function in Step 11, $A_{Prior}$  is used instead. What is the relationship between $A_{Prior}$ and $A_{LLM}$? Are they the same thing, or two different priors?\n\n3. The paper repeatedly claims in the abstract, introduction, and contributions that GUIDE can handle \"mixed data types\" and \"complex non-linear relationships\". However, in the methodology in Section 2, the authors never explain how GUIDE achieves this. The data encoder E1 is described as an MLP, and the reward function uses the BIC score (which is usually model-specific, e.g., for linear Gaussian models). Furthermore, the datasets used in the experiments (Sachs, Asia, Lucas, Alarm, Dream) are standard benchmarks, and the authors do not state whether mixed-data versions of these datasets were used. This is a core claim that is completely unsupported by the methodology and experiments. More specifically, the paper claims to handle non-linear relationships, but its post-processing \"PruneWeakEdges\" step explicitly uses linear regression coefficients to prune edges. This is confusing and logically inconsistent."}, "questions": {"value": "1. The authors are requested to carefully revise the paper in response to the weaknesses raised. This includes, but is not limited to: clearly clarifying the difference between $A_{LLM}$ and $A_{Prior}$, and clearly explaining which component achieves the handling of mixed data and non-linear relationships, etc.\n\n2. The quality of the LLM-generated $A_{LLM}$ is crucial to GUIDE's performance. The authors mention using GPT-4o 40, but the output of LLMs is stochastic and highly sensitive to prompts. It is necessary to add results from comparative experiments using multiple different LLMs.\n\n3. The ablation study shows that prior knowledge is very important. However, if the prior provided by the LLM is incorrect or of poor quality (LLMs frequently hallucinate), what would GUIDE's performance be? Appendix C mentions \"prior calibration\", but this mechanism is not further discussed or experimented with.\n\n4. The method appears to use two types of acyclicity constraints: a soft penalty $h(A)$ during training (Algorithm 1, line 11) and a hard post-processing step RemoveCycles (Algorithm 1, line 16). Why are both necessary? Does the soft penalty $h(A)$ truly help the RL agent explore better graph structures during training? Or could it be removed entirely, relying solely on the post-processing RemoveCycles step to ensure the final output is a DAG?\n\n5. The readability of the paper is really not outstanding, and the design of figures and tables could be more aesthetically pleasing. For example: the width of figures should align with the text, the row heights in Table 1 are inconsistent, and the green font has too low contrast against the white background. The formulas in this paper are also not numbered. These are all areas that need improvement. There may be some grammatical issues, which I have not checked carefully."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ycjq3tNTZh", "forum": "4SQRcsaPxN", "replyto": "4SQRcsaPxN", "signatures": ["ICLR.cc/2026/Conference/Submission13091/Reviewer_bEny"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13091/Reviewer_bEny"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13091/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761173886077, "cdate": 1761173886077, "tmdate": 1762923817313, "mdate": 1762923817313, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the limitations of current causal discovery methods in scalability, computational efficiency, and handling of mixed data types by proposing a new framework called GUIDE. GUIDE incorporates the adjacency matrix generated by LLM as prior knowledge and combines reinforcement learning with a dual-encoder architecture to optimize the search process for causal graph structures. Experiments demonstrate that GUIDE significantly improves runtime and accuracy (TP/NNZ) on multiple benchmark datasets compared to existing methods. It performs particularly well on medium-sized graphs and demonstrates good generalization."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "For the first time, the \"generative priors\" generated by the LLM are integrated with observed data through a dual encoder, overcoming the limitations of traditional methods that rely on single data-driven or expert priors. This approach leverages the domain knowledge coverage of the LLM to reduce the exploration burden while ensuring statistical reliability through the data encoder, achieving an effective balance between \"knowledge guidance\" and \"data adaptation.\"\n\nCompared to existing methods, GUIDE achieves breakthroughs in scalability (supporting ≥70 nodes), computational efficiency, and data adaptability (accommodating both continuous and non-continuous data and nonlinear relationships), filling a technological gap in causal discovery with high-dimensional mixed data. Table 1 clearly contrasts the shortcomings of existing methods, highlighting its advantages.\n\nThe experimental setup is reasonable, and the baseline selected is representative, covering a wide range of representative datasets."}, "weaknesses": {"value": "Lack of theoretical analysis: There is no theoretical analysis of Markov Equivalence Classes when fusion generates adjacency matrix representations. When generating A based on threshold filtering, MEC conflicts may occur. For example, if the ground truth is A->B->C, using Bernoulli sampling may result in A->B<-C. Furthermore, the paper acknowledges that performance degrades in the presence of unobserved confounding variables, but the proposed mitigation measures have not been fully validated in experiments.\n\nThe sources of error in the LLM-generated priors and their quantitative analysis are unclear: Performance depends on the quality of the LLM-generated priors and may underperform when the priors are inaccurate or domain knowledge is limited. The paper only mentions that the LLM provides an \"initial adjacency matrix\" but does not explain the robustness of GUIDE when the LLM priors are incorrect. Nor does it compare the impact of different LLM-generated priors on the final results, making it difficult to assess the stability of the prior quality.\n\nFurthermore, the use of linear weights in post-processing is not universally applicable. Despite the use of numerous modules and techniques, GUIDE does not perform particularly well on traditional performance metrics on test data.\n\nThe core of the paper is its ability to efficiently handle high-dimensional mixed data scenarios, ultimately simplifying it to a fusion of BIC and a penalty term. There is no special explanation or introduction as to why the model can cope with high-dimensional mixed data scenarios. While this approach is empirically very practical, it lacks any theoretical guarantees."}, "questions": {"value": "How do we handle errors or biases in LLM priors? Are there mechanisms to dynamically calibrate or reject unreliable prior edges? How does GUIDE maintain stability in the presence of strong unobserved confounding? Is it necessary to compare the effectiveness of different LLM priors?\n\nWhen the prior causal graph output by the LLM is combined with the data-driven initial graph, the weights and fusion parameters may differ across different datasets. How can this be addressed?\n\nThe paper mentions that GUIDE can handle nonlinear relationships, but the BIC penalty in its reward function is based on the linear regression assumption. Does this assumption conflict with nonlinear scenarios?\n\nAre the hyperparameters in the reward function (such as λ₁, λ₂, and β) sensitive? Are there any automated parameter tuning strategies?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "y4iLHrR5IV", "forum": "4SQRcsaPxN", "replyto": "4SQRcsaPxN", "signatures": ["ICLR.cc/2026/Conference/Submission13091/Reviewer_Eunw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13091/Reviewer_Eunw"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13091/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761468992543, "cdate": 1761468992543, "tmdate": 1762923816985, "mdate": 1762923816985, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "GUIDE proposes a dual-encoder causal discovery framework that fuses (i) LLM-generated adjacency priors and (ii) observational data representations within a reinforcement-learning (RL) loop. A data encoder captures statistical dependencies, a prior encoder processes LLM-derived adjacency matrices, and a policy head predicts edge probabilities. A REINFORCE-style optimizer maximizes a composite reward (BIC fit + acyclicity penalty + prior consistency). A pruning stage using regression coefficients yields the final DAG.\n\nExperiments on six benchmarks (ASIA, SACHS, LUCAS, ALARM, HEPAR, DREAM41) show GUIDE outperforming NOTEARS, GraN-DAG, RL-BIC, and KCRL on several small-to-medium datasets and maintaining scalability up to ≈ 100 nodes. Ablations indicate that combining generative priors and prior constraints improves edge recall ≈ 80 % over the baseline without priors."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1) The RL reward and pruning pipeline are clearly specified and reproducible. Mathematical details (acyclicity term) and pseudocode are correct and consistent with prior art. Unified design with a combination of generative (LLM) and observational priors in a single learning loop.\n2) The paper is well structured, self-contained, and supported by appendices detailing datasets, code availability, and prompt templates.\n3) Provides a computationally efficient RL variant, reporting significant runtime reduction over RL-BIC/KCRL.\n4) Scalability: runs successfully on approx. 100 nodes where several baselines fail."}, "weaknesses": {"value": "1) The use of the BIC term presumes causal sufficiency and linear-Gaussian SEMs; behavior under hidden confounders is only qualitatively discussed. \n2) The prior weighting heuristic βₜ lacks formal justification beyond empirical calibration. The dependence on LLM quality where prior generation and calibration depend on prompt engineering; potential hallucinations or bias propagation are not quantified.\n3) Baselines: lacks comparison with amortized or generative approaches that also combine expert priors with graph sampling (recent works for example about using gflownets for causal discovery and causal discovery with LLM's [1,2]).\n4) Metric novelty vs. adoption: TP/NNZ and RP are intuitive but non-standard; comparison with accepted metrics beyond SHD (e.g., precision-recall) would aid interpretation.\n\n[1] Expert-Aided Causal Discovery of Ancestral Graphs https://arxiv.org/pdf/2309.12032 .\n\n[2] Bayesian Structure Learning with Generative Flow Networks. https://arxiv.org/abs/2202.13903"}, "questions": {"value": "1) How sensitive is performance to incorrect or noisy LLM priors (e.g., swapped directions)?\n2) Can the dual-encoder be pre-trained across datasets for amortized inference?\n3) How would GUIDE behave under non-i.i.d. or time-series data?\n4) Could the authors provide wall-clock and token costs for the LLM prior generation step?\n5) How does GUIDE compare empirically to generative-model-based samplers (e.g., GFlowNet-based DAG learners)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VB52iObl4N", "forum": "4SQRcsaPxN", "replyto": "4SQRcsaPxN", "signatures": ["ICLR.cc/2026/Conference/Submission13091/Reviewer_c1cb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13091/Reviewer_c1cb"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13091/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762619090833, "cdate": 1762619090833, "tmdate": 1762923816174, "mdate": 1762923816174, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}