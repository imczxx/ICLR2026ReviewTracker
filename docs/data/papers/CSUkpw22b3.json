{"id": "CSUkpw22b3", "number": 2415, "cdate": 1757077507467, "mdate": 1759898149681, "content": {"title": "RAAG: RATIO AWARE ADAPTIVE GUIDANCE", "abstract": "Flow-based generative models have achieved remarkable progress, with classifier-free guidance (CFG) becoming the standard for high-fidelity generation. However, the conventional practice of applying a strong, fixed guidance scale throughout inference is poorly suited for the rapid, few-step sampling required by modern applications. In this work, we uncover the root cause of this conflict: a fundamental sampling instability where the earliest steps are acutely sensitive to guidance. We trace this to a significant spike in the ratio of conditional to unconditional predictions—a spike that we prove to be an inherent property of the training data distribution itself, making it a almost inevitable challenge. Applying a high, static guidance value during this volatile initial phase leads to an exponential amplification of error, degrading image quality. To resolve this, we propose a simple, theoretically grounded, adaptive guidance schedule that automatically dampens the guidance scale at early steps based on the evolving ratio. Our method is lightweight, incurs no inference overhead, and is compatible with standard frameworks. Experiments across state-of-the-art image (SD3.5, Qwen-Image) and video (WAN2.1) models show our approach enables up to 3x faster sampling while maintaining or improving quality, robustness, and semantic alignment. Our findings highlight that adapting guidance to the sampling process, rather than fixing it, is critical for unlocking the full potential of fast, flow-based models.", "tldr": "", "keywords": ["generation task", "flow model", "classifier free guidance"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/293fd2d7875e0b7c6f742aa8170425d6dff6e1c4.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work analyses the dynamics under classifier-free guidance of flow-based models, drawing attention to the sampling instability due to a fixed guidance scale. The authors further introduce RAAG - an adaptive guidance schedule - which penalises high ratio of conditional velocity to unconditional velocity, especially during the initial phase. Much like CFG, the approach is essentially plug-and-play for flow-based models when pretrained conditional and unconditional networks are available. Experiments are provided on image benchmarks such as SD3.5 and Qwen, and video benchmark (WAN2.1) to demonstrate benefits of RAAG."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "--- The motivation for this work is strong, and the overall presentation is nice. \n\n--- Establishing the insufficiency of fixed guidance scale to data distribution (instead of a particular flow model) is appealing.   \n\n---  The authors are transparent about the limitations of the proposed approach (e.g., issues with diffusion models).\n\n--- Sampling speedups are noteworthy."}, "weaknesses": {"value": "--- Dynamically adjusting the ratio between the magnitude of the velocity gap and the unconditional velocity could potentially induce issues such as distributional shift (relative to data distribution) due to sampling bias. Experiments do not report widely used metrics such as FID, PSNR, Inception Score, LPIPS, precision, and recall (e.g., for CIFAR10).  This makes it objectively hard to assess the performance of the method. \n\n--- A particularly relevant recent work [1], not discussed in the paper, has formalised why/when (adaptively) scaling the (conditional) velocity vector, including the earlier time-steps, influences the detail in image generation in flow models. CGF can be viewed as an affine combination of conditional and unconditional vector fields, and RAAG as an adaptive affine combination. However, it is unclear whether or to what extent theoretical and empirical findings with respect to RAAG are consistent with respect to, or extend beyond, the formalism and results in [1].\n\n[1] Karczewski et al. Devil is in the Details: Density Guidance for Detail-Aware Generation with Flow Models. ICML 2025. \n\n--- RAAG does not seem to work for diffusion models."}, "questions": {"value": "--- Could you please quantify performance with respect to the evaluation metrics that I mentioned under the weaknesses? Ideally, you could take readily available pretrained conditional and unconditional models from a repository like NVLabs EDM, and compare RAAG with CFG across these metrics on CIFAR-10, FFHQ, ImageNet etc. \n\n--- Could you address my other concern with respect to reference [1] under the weaknesses section?\n\n--- Clearly, the optimal adaptive guidance scale in diffusion models does need exhibit exponential decay with respect to ratio. But how about utilising the corresponding probabilistic flow ODE? Also, perhaps a non-monotonic decay schedule (e.g., dampened cosine) might be required to extend RAAG to diffusion models."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YCvhc8yBFN", "forum": "CSUkpw22b3", "replyto": "CSUkpw22b3", "signatures": ["ICLR.cc/2026/Conference/Submission2415/Reviewer_5JgS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2415/Reviewer_5JgS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2415/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971775951, "cdate": 1761971775951, "tmdate": 1762916229180, "mdate": 1762916229180, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper focuses on classifier-free guidance, arguing that the earliest steps in flow-based generators are sensitive to the guidance scale.  It provides a theoretical analysis explaining why early over-steering harms trajectories, formalizing the effect via the gap between conditional and unconditional velocities. Building on this, the authors introduce a RATIO-aware adaptive schedule that down-weights guidance early and relaxes it later, speeding up conditional generation without degrading sample quality."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper provides a theoretical explanation of the impact of early-step guidance.\n\n- The proposed adaptive guidance schedule (Eq. 8) is closed‑form, training‑free, and easy to integrate into standard rectified flow pipelines."}, "weaknesses": {"value": "- There are inconsistencies in core definitions or result labels (see Questions below). These inconsistencies severely affect the technical rigor of the paper and cause confusion.\n\n- Line 90 claims 'The schedule is parameter-free at test time', while $\\alpha$ and $w_{max}$ are hyperparameters for the method. It is unclear how the authors define `parameter-free' in this context.\n\n- The paper asserts the initial RATIO is a dataset property rather than model‑dependent. However,  the measurement is only after SD3.5 VAE encoding (Appendix C.1), so it is entangled with the latent representation/model. This does not establish a model-agnostic, distribution-level inevitability.\n\n- The theoritical results rely on restrictive assumptions (e.g. $\\lambda$>0 , $\\sigma$>0, ) and uses heuristic inequalities."}, "questions": {"value": "-  Line 133 defines $v_{u}(x_{t})=E[x_0 -x_1 |x_t,\\emptyset]$ and $v_{c}(x_{t},c)=E[x_1 -x_0 |x_t,c]  $. However, Eq. 3 writes $v_{c}(x_{t},c)=E[x_0 -x_1 |x_t,c]  $.  What is the correct definition? \n\n-  Line 304 gives Proposition 3.1, while Line 435/740 mentions Theorem 3.1. What is the correct label of the results?\n\n-  Is there any justification for the assumptions in Proposition 3.1, such as the positiveness of $\\lambda$ and $\\sigma$?\n\n-  What broader cross-model/cross-dataset evidence demonstrates that the early-step RATIO spike is “inherent” to the training distribution?\n\n- What is the relationship between the theoretically optimal solution $w=1/\\rho$ and the exponential decay rule in Equation 8? Is the exponential rule near-optimal across models?\n\n- Could the authors please explain the underperformance on classic diffusion (e.g., SD-v2)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "KKFeOySw0o", "forum": "CSUkpw22b3", "replyto": "CSUkpw22b3", "signatures": ["ICLR.cc/2026/Conference/Submission2415/Reviewer_zzXF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2415/Reviewer_zzXF"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2415/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761975879568, "cdate": 1761975879568, "tmdate": 1762916228844, "mdate": 1762916228844, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors study classifier-free guidance in flow-based models. The authors focus their analysis on the relative difference of conditional and unconditional drifts and refer to it as RATIO. The authors propose an adaptive guidance schedule and demonstrate its empirical performance."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "I believe that the problem that authors tackle is an important one, i.e. trying to better understand classifier-free guidance and its empirical performance."}, "weaknesses": {"value": "1. The theoretical claims are not convincing for two reasons.\n\nFirst, they are not presented well. For example, it is not even clear to me what the authors are trying to prove with their theoretical analysis. The main result is Proposition 3.1, which provides a lower bound (not really a bound, because they use the symbol $\\gtrsim$, which means \"greater than or approximately equal to\") on the distance between two arbitrary trajectories. I don't think this is relevant to the problem of classifier-free guidance. The authors try to minimize this bound, but I don't understand why this is something that should be done or how it is supposed to solve any of the problems raised earlier in the paper.\n\nSecondly, they do not seem to lead to practical algorithms that improve over CFG. For example, the method that directly uses the theoretical results is presented in Figure 9 and the resulting generations are clearly distorted. Therefore, the authors resort to a heuristic. The heuristic works for some models, but for some yields significantly worse results than the standard CFG. The formalism and the proof suggest that the approach should work for any flow-based model. However, tables 2 and 3 show that the proposed method, when applied to some diffusion models, is significantly worse than the standard CFG on both analyzed metrics, and the authors do not propose an explanation of this.\n\nTherefore, I do not see merit in the proposed work. The theoretical analysis is fundamentally flawed in my opinion. The quantity analyzed (the difference between trajectories or its approximate lower bound) is not motivated and does not lead to useful algorithms.\n\n2. The paper largely uses imprecise wording and notation. For example\n    * line 79 - \"Because standard pipelines apply a fixed guidance scale w throughout sampling, their effective control term of sampling errors is [...] \". What do authors mean by \"control term of sampling errors? Why is it related to the ratio?\n    * line 181 - \"We prove this stems inherently from data distributions\". What does this mean?\n    * Line 315 - \"which could amplify initial perturbations and increase the error lower bound\" what error? Distance between trajectories is not an error\n    * Line 363 - \"does not guarantee reduced actual sampling error\". The authors refer to a distance between trajectories as \"sampling error\". \n    * What is $\\rho$? I think the first time this symbol appears is in line 274 as $\\rho_{max}$, which is not defined, and I assumed it means just some arbitrary constant defined for the purpose of the proof. Later, $\\rho$ appears in the formula in Proposition 3.1 without defining what it is. Later, from context, it seems like the authors use \"RATIO\" and $\\rho$ interchangeably. Is it supposed to depend on $x_t$? It in mathematical expressions is seems like it's constant, but I don't understand then what it refers to. There should also be two ratios. One for $x_t$ and one for $y_t$. Is it supposed to be one of those?\n    * Line 364. \"$Var (1/\\rho) \\propto 1/\\rho^4$\". I don't know what authors meant to say here. This is a very imprecise notation. It seems to imply that $\\rho$ is a random variable (LHS) and a real number (RHS) at the same time.\n    * Line 422 - \"We attribute this to the inherent model corrections compensate for earlier suboptimal conditions\". \"conditions\"? This really feels LLM generated."}, "questions": {"value": "Please see the weaknesses I raised above. Unfortunately, I do not see how this paper can be improved. I believe the approach is fundamentally flawed, as the theoretical analysis does not seem motivated, and the resulting algorithm (after heuristic tweaks) improves performance for some models but degrades quality for others."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mamTc41Vqs", "forum": "CSUkpw22b3", "replyto": "CSUkpw22b3", "signatures": ["ICLR.cc/2026/Conference/Submission2415/Reviewer_yNBK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2415/Reviewer_yNBK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2415/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762046810329, "cdate": 1762046810329, "tmdate": 1762916228591, "mdate": 1762916228591, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the tendency of a classifier-free guidance to have strong discrepancy between the conditional and unconditional velocity. The paper proposes an adaptive weighting scheme that reduces this, and shows higher sampling quality from this."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper studies an interesting and novel issue in CFG. The ratio phenomena is well characterised and comprehensively presented. The results are impressive, and this work likely has lasting significance."}, "weaknesses": {"value": "I'm not totally sold on the technical analysis of the paper. I'm not sure if the ratio is the key quantity to explain this phenomena. I wonder if it is enough to understand this solely by the ratio.\n\nI'm not sure I get the Prop 3.1: it seems to state that different initial noises can arrive at different images. Isn't this how a denoiser is supposed to work? Why is this a bad thing?\n\nIt also seems that the theoretical analysis does not align with the empirical weight tuning, which seems a bit adhoc."}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "AztVzZ7FaD", "forum": "CSUkpw22b3", "replyto": "CSUkpw22b3", "signatures": ["ICLR.cc/2026/Conference/Submission2415/Reviewer_5ds5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2415/Reviewer_5ds5"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2415/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762461860828, "cdate": 1762461860828, "tmdate": 1762916228361, "mdate": 1762916228361, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}