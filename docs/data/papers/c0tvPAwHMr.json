{"id": "c0tvPAwHMr", "number": 20346, "cdate": 1758304962421, "mdate": 1759896982458, "content": {"title": "Conceptual Belief-Informed Reinforcement Learning", "abstract": "Reinforcement learning (RL) has achieved significant success but is hindered by inefficiency and instability, relying on large amounts of trial-and-error data and failing to efficiently use past experiences to guide decisions. However, humans achieve remarkably efficient learning from experience, attributed to abstracting concepts and updating associated probabilistic beliefs by integrating both uncertainty and prior knowledge, as observed by cognitive science. Inspired by this, we introduce Conceptual Belief-Informed Reinforcement Learning to emulate human intelligence (HI-RL), an efficient experience utilization paradigm that can be directly integrated into existing RL frameworks. HI-RL forms concepts by extracting high-level categories of critical environmental information and then constructs adaptive concept-associated probabilistic beliefs as experience priors to guide value or policy updates. We evaluate HI-RL by integrating it into various existing value- and policy-based algorithms (DQN, PPO, SAC, and TD3) and demonstrate consistent improvements in sample efficiency and performance across both discrete and continuous control benchmarks.", "tldr": "", "keywords": ["Reinforcement Learning", "Conceptual Learning", "Belief Representation"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0a25250e7ef328744574b0d9e94cb5b5407e7ee2.pdf", "supplementary_material": "/attachment/12ae0d375c37bba02ed8e21b61b9bf9ae2f7dbbd.pdf"}, "replies": [{"content": {"summary": {"value": "The paper is difficult to follow as it tries to ground methodological development on cognitive science concepts such as \"conceptual abstraction\" and \"probabilistic priors\", but which are superficially discussed. Concept learning is an old ML technique (with well-known limitations) and probabilistic priors is so broad term that it needs careful definition.\n\nWhat I understand (mainly from Figure 1) is that \"concept\" is a specific environment and its description is formed by clustering its states. It is unclear how the concept vector is generated during learning, but the \"prior\" is formed by summing the observed state and concept descriptor. Furthermore, it is unclear how the concept 1...K is selected during training."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "I cannot judge since many important details missing or definitions are confusing"}, "weaknesses": {"value": "**Major:**\n\n - The idea of using \"concepts\" suggests that there exist previous environments agent has explored to form the concepts. This, on the other hand, means that the correct context of this work is domain adaptation or meta RL where past experiences are used to boost learning. \n\n - Results are reported only for the two baselines, DQN and SAC, that rather old methods and there have been many improvements for them. Even then, it is unclear in which cases the results are statistically significant as the variances are large. \n\n - It is unclear what environments are used to form the concepts in the experiment - and since other methods do not use them, is the comparison fair at all? The method should be compared to domain transfer and meta RL methods.\n\n - Writing is very difficult to follow - since the idea is rather simple, writing should be simple as well. As an example, the two contributions are so verbose that it is difficult to understand what do they really mean\n\n**Moderate:**\n\n - C_k in Definition 4 are not defined. The definition S=Union of all C suggests that C_k:s are same as the states. The short description below the definition further suggests that C_k are formed by clustering the observed states to K clusters. All these should be clarified. Moreover, this approach has been used in offline RL methods.\n\n - Section 4.2 is unclear. Description is complex, e.g., \"For given state s in S, we first identify its concept index c(s) such that s in C_c(s), and then fuse the signals\" - does this simply mean that the closest cluster is identified by search and its mean vector added to the current state. It is a complicated way to say simple things.\n\n\n**Minor:**\n\n - Try to reduce the amount of mathematical terms that can be defined using already existing ones\n\n - The PDF seems to be a binary dump instead of a normal text PDF. Therefore I cannot highlight any parts of the text and links do not work. Authors should instead produce a normal PDF where all these work."}, "questions": {"value": "I think this method cannot be compared to standard RL methods, but methods that utilize past experiences to speed up training. Therefore, the context is wrong. Can you change my mind?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "n/a"}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "T0Q5EvzgOg", "forum": "c0tvPAwHMr", "replyto": "c0tvPAwHMr", "signatures": ["ICLR.cc/2026/Conference/Submission20346/Reviewer_5dyR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20346/Reviewer_5dyR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20346/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761635309147, "cdate": 1761635309147, "tmdate": 1762933806242, "mdate": 1762933806242, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Conceptual Belief-Informed Reinforcement Learning (HI-RL), a framework that aims to improve sample efficiency in RL by organizing experiences into categories and forming adaptive probabilistic beliefs. The approach partitions states into concepts using clustering (K-means), maintains a belief distribution over actions for each concept based on historical experience, and combines these beliefs with the learning target in standard RL algorithms (DQN, PPO, SAC, TD3). The authors evaluate HI-RL across discrete and continuous control tasks, demonstrating improvements in sample efficiency and final performance compared to baseline methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed method is algorithm-agnostic. The authors demonstrate its ability to integrate with multiple RL algorithms (Q-learning, PPO, SAC) demonstrates versatility.\n2. The mathematical formulation is generally correct and the integration mechanism is well-defined. I appreciate the derivation of convergence guarantee on the proposed smoothed Bellman Operator in the appendix.\n3. Experimental evaluation spans multiple domains and algorithms, showing consistency.\n4. I appreciate the good motivation from cognitive science literature to solve an important RL challenge (sample efficiency)."}, "weaknesses": {"value": "1. As the main claim of the submission is to propose a new “experience utilization paradigm,” the critical comparison baselines should be comparing to other methods aimed at improving experience utilization, including replay methods (e.g. HER and its prioritized variants), episodic memory models (NEC), and state abstraction methods such as bi-simulation and contrastive learning (Patil et al, 2024). The current comparison baselines use only the base RL algorithms, which do not seem to be reasonable and interesting comparisons. This is perhaps the major weakness of this submission.\n2. No ablation studies/ sensitivity analysis were performed. Unclear what the critical hyper parameter values were (the limiting weight beta^*, the number of categories k), and how their presence/ value affect the results. The concept formation definition (Definition 4.1) requires predetermined k but provides no guidance on selection.\n3. Since the concept formation is trained using k-means clustering, it is unclear whether the clusters become “semantically coherent category”, as the authors claimed. If the k-means are done on the pixel space, it seems unlikely a simple k-means clustering will render task-relevant, semantically-meaningful categories. (Please provide more evidence on this if any.) Given this, I’d be hesitant to call the proposed algorithm “concept formation.” Also, no discussion on how concept quality affects downstream performance.\n4. Experiment results reporting should be better presented. Some improvements could be within noise (e.g. on CartPole, 499.78+/-0.22 seems not significantly different from 499.17+/-0.83). If proper statistical tests were done, please report the results. Otherwise use bold for all comparable performance\n5. The naming of adaptive belief is somewhat misleading/ confusing. As belief is more commonly used in RL within POMDP context to refer to the posterior of environment states given all the history; in contrast, in this submission, what the authors called belief is actually “the integrated action preferences of all states within the same category.” It’d be better to use other terms for this marginal distribution to prevent confusion."}, "questions": {"value": "1. Can you provide visualizations of the learned concepts? Do they correspond to meaningful task structure/ semantics (e.g., in Atari, do concepts capture semantic game states)?\n2. Have you experimented with other clustering methods or learned representations? Why is K-means sufficient?\n3. The fusion mechanism seems to be ad-hoc weighted averaging. Can you provide an explanation on why this is designed in this way? β scheduling (β* with β^t) seems to introduce additional hyperparameters without principled justification.\n4. What is the effect of different β scheduling schemes? \n5. What is the computational overhead compared to baselines? How does this scale with buffer size and state dimensionality? \n6. In what scenarios does HI-RL perform worse than baselines? Can you characterize when conceptual priors mislead learning?\n7. Unsure if this only happens to the files I downloaded, but the pdf was image based (not able to select or highlight text), making it hard to review the submission materials. Please upload a functional file is possible."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XxuYrNQMpH", "forum": "c0tvPAwHMr", "replyto": "c0tvPAwHMr", "signatures": ["ICLR.cc/2026/Conference/Submission20346/Reviewer_6pJc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20346/Reviewer_6pJc"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20346/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982922453, "cdate": 1761982922453, "tmdate": 1762933805809, "mdate": 1762933805809, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "HI-RL proposes to enhance RL by introducing conceptual abstractions (state clustering via K-means) and belief-informed updates (combining per-cluster priors with the current policy/Q-values).  \nIn practice, the method defines clusters (“concepts”) in the state space, aggregates action statistics within each, and then fuses those distributions with the agent’s instantaneous estimates using a weighting factor. \nThis structure is applied to several base algorithms (DQN, PPO, SAC, TD3). The empirical results are surprisingly strong, showing consistent gains across multiple benchmarks despite the conceptual simplicity."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- **Simple yet effective regularization:** The belief blending smooths updates, reduces variance, and improves sample efficiency.\n- **Experience reuse:** Clustering allows shared learning across similar states, enhancing generalization.\n- **Stability and transfer:** Beliefs act as priors, providing memory and consistency across episodes.\n- **Broad applicability:** Can be plugged into existing algorithms (DQN, PPO, SAC, TD3) without major architectural changes.\n- **Empirically strong:** Demonstrates substantial performance improvements over standard baselines, suggesting practical value despite theoretical simplicity."}, "weaknesses": {"value": "- **Conceptually shallow:** Essentially applies K-means for context extraction and a Bayesian-style weighted update; not a fundamentally new algorithm.\n- **Lack of fair baselines:** Compared to plain SAC/PPO/TD3 but not to other context-aware approaches.\n- **Overuse of cognitive/“neuroscience” framing:** Adds narrative flair but little real mechanism.\n- **Concept formation quality:** If clustering fails to align with true behavioral modes, the priors can mislead learning.\n- **Hyperparameter sensitivity:** Performance depends on the number of clusters (K), β-schedule, and distance metric.\n- **Scalability:** K-means and per-concept beliefs may not scale well to large, high-dimensional environments.\n- **Non-stationarity:** Fixed clusters may become outdated as the policy distribution shifts.    \n- **Computational overhead:** Maintaining and updating beliefs adds additional bookkeeping."}, "questions": {"value": "1. How can the concepts evolve online rather than staying fixed after initial clustering?\n2. How does this approach interact with **latent-space representation learning**. Could clustering be done in learned embeddings?    \n3. Can the concept-belief mechanism **transfer** across tasks or domains, not just within one environment?\n4. What happens if concept boundaries are learned end-to-end instead of using K-means?\n5. Would combining this with **contrastive encoders** yield more meaningful concepts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5CI7lzbvVe", "forum": "c0tvPAwHMr", "replyto": "c0tvPAwHMr", "signatures": ["ICLR.cc/2026/Conference/Submission20346/Reviewer_kNCF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20346/Reviewer_kNCF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20346/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988780771, "cdate": 1761988780771, "tmdate": 1762933803999, "mdate": 1762933803999, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}