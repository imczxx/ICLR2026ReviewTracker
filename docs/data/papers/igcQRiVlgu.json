{"id": "igcQRiVlgu", "number": 11642, "cdate": 1758202755535, "mdate": 1759897563226, "content": {"title": "Don't Throw Away Your Beams: Improving Consistency-based Uncertainties in LLMs via Beam Search", "abstract": "Consistency-based methods have emerged as an effective approach to uncertainty quantification (UQ) in large language models. These methods typically rely on several generations obtained via multinomial sampling, measuring their agreement level. However, in short-form QA, multinomial sampling is prone to producing duplicates due to peaked distributions, and its stochasticity introduces considerable variance in uncertainty estimates across runs. We introduce a new family of methods that employ beam search to generate candidates for consistency-based UQ, yielding improved performance and reduced variance compared to multinomial sampling. We also provide a theoretical lower bound on the beam set probability mass under which beam search achieves a smaller error than multinomial sampling. We empirically evaluate our approach on six QA datasets and find that its consistent improvements over multinomial sampling lead to state-of-the-art UQ performance.", "tldr": "A new family of consistency-based uncertainty quantification methods for LLMs using beam search candidates", "keywords": ["LLM", "Large Language Model", "Uncertainty Quantification", "Beam Search"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ed4f24e32df98a966b240f6ad3ff720b0076e28f.pdf", "supplementary_material": "/attachment/c6f20668de5ea43562027fa0d091514dc90dea4f.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose replacing multinomial sampling with beam search sampling for consistency-based UQ methods. They show that it's even theoretically less erroneous in low-sampling regimes. They verify the proposed method's effectiveness on various datasets and various methods."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper focuses on an important topic with a neat, focused contribution. \n- The paper is well written.\n- The proposed replacement of multinomial sampling with beam search definitely makes sense.\n- The idea is supported by a clean, small, but necessary theory.\n- Very good ablations and additional experiments with different temperatures and sampling ideas.\n- Clear demonstration of the effectiveness of the idea on various consistency-based methods."}, "weaknesses": {"value": "- I don't see any major weaknesses, but the impact of the work is probably limited to the UQ community."}, "questions": {"value": "- Do you have any results for when you combine your idea with other methods that do sampling but use probabilities, such as SE and SAR?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "9BR3nfzVpU", "forum": "igcQRiVlgu", "replyto": "igcQRiVlgu", "signatures": ["ICLR.cc/2026/Conference/Submission11642/Reviewer_fdB8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11642/Reviewer_fdB8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11642/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761523458340, "cdate": 1761523458340, "tmdate": 1762922708287, "mdate": 1762922708287, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper targets uncertainty quantification (UQ) for short-form QA where consistency-based methods aggregate multiple generations to estimate confidence. It argues that the standard practice to generate samples via multinomial sampling under a small budget produces many duplicates in peaky distributions. This results in high variance and unstable UQ. The authors propose to use beam-search with probability weighting to obtain samples for the consistency estimator. Experiments across several QA datasets report consistent gains in UQ metrics."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper clearly motivates the problem and proposes a simple drop-in replacement for multinomial sampling in consistency-based UQ via probability-weighted beam search. It provides a bias–variance analysis with an interpretable beam-mass condition. Experiments on multiple short-form QA datasets show consistent gains, including extensive ablation studies. Moreover, the probability-weighted beams consistently improve other UQ baselines (e.g., semantic entropy), suggesting broader applicability."}, "weaknesses": {"value": "The improvements appear strongest for short answers, the coverage of probability mass by top-M beams degrades with length (Fig. 3). It’s unclear whether the advantages vanish or even reverse for longer outputs. An additional discussion or experiments on benchmarks with longer outputs could help to clarify."}, "questions": {"value": "* For what answer lengths and budget M does beam-weighted consistency cease to outperform sampling? Any failure cases? \n* Could you discuss whether there are use cases in which beam search produces suboptimal predictions which may lead to unreliable uncertainty estimates?\n* Figure 4 indicates that even for M=1, the PRR of the beam search is comparable with the multinomial sampling with up to M=15 (dissimilarity) and M=5 (eccentricity). Could you explain why the beam search with such small beam width is performing so well? \n* The related works section is relatively short. Work of Hashimoto et al. (2025) is mentioned where different decoding strategies are compared in terms of UQ for different tasks. How is the beam search approach performing in those evaluations? Is the main difference and gain in this paper the combination of beam search with weighted consistency scores?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ewyTnn3fOf", "forum": "igcQRiVlgu", "replyto": "igcQRiVlgu", "signatures": ["ICLR.cc/2026/Conference/Submission11642/Reviewer_1K6A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11642/Reviewer_1K6A"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11642/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761837204583, "cdate": 1761837204583, "tmdate": 1762922707907, "mdate": 1762922707907, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a new uncertainty quantification scheme for LLMs that leverages the sequence probabilities of the multiple beams obtained during the generation phase of the response. This is in contrast to existing consistency-based approaches that typically rely on generating multiple sample responses from the distribution represented by the LLM. The basic idea behind the proposed uncertainty estimator is to weight the disimilarity measure of each sequence by it' s corresponding normalised probability. Furthermore, the paper also shows that several consistency based estimators such as those based on eccentricity or eigenvectors dissimilarity can be expressed in terms of the probabilities of the beams. The experimental evaluation is restricted to QA benchmark datasets and 3 open models from the Llama, Qwen and Gemma families. The results show indeed improved performance over the corresponding UQ schemes that rely on multinomial sampling."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Uncertainty quantification for LLM is currently a hot topic and therefore advances in this area are warranted.\n\n- The quality of the presentation is overall quite good and therefore the paper is relatively easy to follow even by readers outside this research area. Most of the technical details presented in the paper are discussed in a relatively clear manner."}, "weaknesses": {"value": "- The experimental evaluation considers only one generative task, namely QA, where responses are typically fairly short. LLMs are applied to a much wider range of tasks, and therefore it would be very interesting to see how the proposed approach performs in other tasks, such as for example summarisation or text-to-SQL translation.\n\n- The performance improvements appear to be just marginal over the standard multinomial sampling e.g., 0.543 vs 0.505 in Table 3. Standard deviations appear to be missing from the table, and these need to be included to account for the noise. Also, for such mediocre performance bumps, statistical significance tests are mandatory.\n\n- The proposed method assumes access to sequence probabilities and therefore it is not applicable to closed models such as GPT or Gemini. I think this limitation should be made clearer in the presentation."}, "questions": {"value": "- I would be interested to get your perspective if I am to apply your method in summarisation tasks where sequences are longer. How would that affect the sequence probabilities?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LG38gPmImC", "forum": "igcQRiVlgu", "replyto": "igcQRiVlgu", "signatures": ["ICLR.cc/2026/Conference/Submission11642/Reviewer_jkE6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11642/Reviewer_jkE6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11642/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761928655661, "cdate": 1761928655661, "tmdate": 1762922707614, "mdate": 1762922707614, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "They propose a new family of UQ methods based on beam search, using importance-weighted estimators to produce distinct candidate outputs. The authors provide a theoretical analysis alongwith an empirical analysis across multiple datasets and models."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is generally well written, well structured and easy to understand.\n\n- It proposes a new way of leveraging beam search for UQ, going beyond routine sampling or decoding tweaks."}, "weaknesses": {"value": "- The focus is primarily on short QA tasks. It’s not clear how well the approach would generalize to long-form or structured generation, or to tasks with less peaked probability distributions.\n\n- An deeper study on beam width and similarity function for semantic entropy is missing.\n\n- A more intuitive summary and visualization of the main theorem’s impact would increase accessibility."}, "questions": {"value": "- How does the method scale to tasks involving longer generations, where the probability mass may be less concentrated on a few beams?\n\n- How does it compare to multinomial sampling technique with averaging of confidence instead of just doing maximal voting?\n\n- How to set beam width for different tasks or LLMs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "22D6t2yo46", "forum": "igcQRiVlgu", "replyto": "igcQRiVlgu", "signatures": ["ICLR.cc/2026/Conference/Submission11642/Reviewer_SuGS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11642/Reviewer_SuGS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11642/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996846659, "cdate": 1761996846659, "tmdate": 1762922707302, "mdate": 1762922707302, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Uncertainty quantification is an important topic for LLMs. This paper focuses on the consistency-based methods that measure agreement among multiple generations. The authors argue that multinomial sampling often produces duplicate short answers and high run‑to‑run variance, especially in short‑form QA. They propose replacing samples with beam‑search candidates and computing importance‑weighted consistency scores over the beam set (top‑M). The goals were to reduce duplication, lower estimator variance and achieve efficiency and effectiveness with 'no extra cost', since beam search is already used for decoding."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**Interesting problem and good motivation**\n\n> The paper pinpoints a concrete weakness of consistency‑based UQ in short QA: duplicates and variance from multinomial sampling, with evidence (e.g., duplicate rates 30–50% for 2–4 token outputs in TriviaQA with 10 samples) and intuitive illustrations (Fig. 1 and Fig. 2). The proposed beam‑weighted estimator is simple and broadly applicable across prior consistency‑based methods. \n\n**Theoretical analysis**\n\n> The paper provided comparison analysis, covering the MSE of the multinomial MC estimator (unbiased, variance) against the deterministic beam‑weighted estimator (bias from top‑M truncation, but no sampling variance). The resulting condition, for example beam mass $m_B$​ above a threshold (e.g., >0.842 for M=10), is interpretable and aligns with short‑form QA, where top few beams often capture most probability mass. This work shows this condition holds for a sizable subset and more often for short outputs. \n\n**Empirical findings**\n\n> Six datasets spanning closed‑book, open‑book, and multiple‑choice QA, six popular LLMs (base and instruct), and comparisons to a large set of information‑based and consistency‑based baselines implemented via LM‑Polygraph. The principal metric PRR (normalized AURC with AlignScore quality) follows recent UQ benchmarking recommendations."}, "weaknesses": {"value": "**Limitation in theory**\n\n> While the paper has provided comparison condition, it heavily rely on unknown “inside‑outside” gap and assumed similarity. The estimator is deterministic given a fixed beam set, but it still inherits the bias from top‑M truncation. \n\n**Limitation in scope**\n\n> Most gains are for short answers; the paper itself shows the advantage shrinks as outputs lengthen (Fig. 5). It is unclear whether the approach still helps long‑form generation (summarization, step‑by‑step reasoning), where beam search can become less diverse and costlier.\n\n**Further report on cost claims**\n\n> The paper states UQ is “essentially free” when beam search is already run; however, many UQ pipelines today do not decode with beam for generation (often nucleus/temperature sampling). The paper reports total GPU‑days, but not per‑query latency nor a direct throughput comparison between beam(M) and sampling(M) under matched compute.\n\n**Sensitivity analysis**\n\n> Although STS vs. NLI ablations are shown, results do shift on some datasets (Table 8). The paper also introduces a mass floor $\\epsilon$ for stability, but the “best $\\epsilon$” is case‑dependent (Table 5).\n\n**Baselines selection**\n\n> While diverse beam and temperature sampling are ablated, a natural question is how nucleus/temperature sampling with semantic deduplication (e.g., cluster‑then‑subsample) fares as a competing “low‑variance” sampler for short QA. The hybrid beam+sampling table suggests potential, but a semantic‑dedup sampling baseline would make the case stronger."}, "questions": {"value": "Further on the questions raised in Weakness, please also answer my following questions.\n\n1. Can you report per‑query latency/throughput comparisons for beam vs. multinomial sampling at the same MMM, both when (a) beam is not used for generation and when (b) it is used (to support the “free” claim)?\n\n2. Beyond the sufficient bound, can you measure mBm_BmB​ and provide scatter plots of PRR gain vs.  $m_B$​? Any proxy to estimate the truncation bias on real data?\n\n3. Do the gains persist for longer generations (e.g., multi‑sentence answers, summarization)? If not, why?\n\n4. Can you include exact‑match (or normalized string match) for TriviaQA/WebQ and choice accuracy for MC to corroborate PRR conclusions that rely on AlignScore?\n\n5. Given the sensitivity in Table 8, do you recommend NLI vs. STS depending on task type (factoid vs. conversational vs. MC)? How stable are results across different NLI models?\n\n7. One claimed benefit is reduced run‑to‑run variance. Can you report std/CI of PRR over multiple runs for sampling‑ vs. beam‑based estimators at fixed M?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "Public datasets"}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wpiN8ZZk3w", "forum": "igcQRiVlgu", "replyto": "igcQRiVlgu", "signatures": ["ICLR.cc/2026/Conference/Submission11642/Reviewer_mkAX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11642/Reviewer_mkAX"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission11642/-/Official_Review"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762945505960, "cdate": 1762945505960, "tmdate": 1762945505960, "mdate": 1762945505960, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}