{"id": "hVOsm02Bsb", "number": 10470, "cdate": 1758172536411, "mdate": 1759897648848, "content": {"title": "Self-explainable Molecular Property Prediction via Multi-view Hypergraph Learning", "abstract": "Explainable molecular property prediction plays a critical role in drug discovery and materials science. Existing graph neural network (GNN)-based approaches usually rely on pairwise atomic interactions for molecular modeling and interpretation. However, such atom-centered modeling often neglects the cooperative effects of atomic groups and lacks the guidance of chemical rules, thereby limiting both prediction accuracy and interpretability. To address these challenges, we propose a multi-view **Hyper**graph learning method for **S**elf-**E**xplainable **M**olecular property prediction(HyperSEM). Our method introduces a hyperedge-driven explanation paradigm, where atomic groups are explicitly modeled as hyperedges to capture high-order cooperative effects, and multi-view hypergraphs are constructed to jointly integrate chemical rules and data-driven signals. Furthermore, we design a molecular structure-informed hypergraph convolution to preserve both high-order atomic-group interactions and low-order structural features, and an information-bottleneck-guided self explanation to jointly generate predictions and explanations. Extensive experimental results show that HyperSEM outperforms existing state-of-the-art methods on seven benchmark datasets, demonstrating dual advantages in prediction accuracy and interpretability.", "tldr": "", "keywords": ["Hypergraph", "Explainable AI", "Molecular Properties Prediction"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9289106f3456085494ee4915283984ed489b8dd4.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces HYPERSEM, a novel multi-view hypergraph learning framework for molecular property prediction designed to provide self-explainability by modeling atomic groups as hyperedges. This model integrates chemical rules and data-driven signals using structure-informed hypergraph convolutions and an information bottleneck module for interpretable predictions and explanations. Experimental results demonstrate competitive accuracy and interpretability across seven benchmark datasets."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "HYPERSEM achieves strong predictive performance, showing state-of-the-art results in benchmark comparisons"}, "weaknesses": {"value": "- The notation is dense and can be difficult to follow, with technical details scattered and some steps (especially implementation details) missing; this can impede reader understanding and reproducibility\n- For interpretability benchmarks, the model is only compared against post-hoc explainers (e.g., GradCAM, GNNExplainer), not against other self-explainable approaches (PxGNN (Dai et al., 2025), PGIB (Seo et al., 2023), PiGNN (Ragno et al., 2021), GIP (Wang et al., 2024), KerGNNs (Feng et al., 2022), and IMPO (Ragno et al., 2025)). The chosen baselines are not always clearly detailed, and it's unclear which models the post-hoc explainers operate on.\n- Table 1 conflates results for several methods but does not specify the metric used (ROC-AUC is only generally mentioned for the datasets in the appendix). Table 3 refers to \"AUC\" without stating which curve it is (likely ROC, but not specified), and whether it is for predictions, explanations, or another measure.\n- Implementation transparency is lacking: there is no code or model artifact released, and crucial hyperparameters are under-specified, which hinders reproducibility and independent comparison. Hyperparameter sensitivity is summarized but not operationalized (Appendix C). Scientific standards require code availability for complex models like HYPERSEM.\n- The ablation study uses unexplained acronyms (e.g., CGHC, ANHC, DHC, SE, IB) and does not detail them in the appendix or main text, limiting clarity for readers unfamiliar with the specific modules or experiment setup.\n- The efficiency results (Table 4) indicate that HYPERSEM has higher inference time than GradCAM, which is surprising for a self-explainable approach, as explanations should ideally be simultaneous with predictions. The paper claims convolution complexity as the dominant cost, but does not offer implementation-level details or explicit justification."}, "questions": {"value": "Could the notation and methodology steps be streamlined and clarified, possibly with a running example and more explicit definitions?​\n\nWhy are no self-explainable interpretability baselines considered, and which models are used for post-hoc interpretability comparisons?​\n\nWhat exact metric is reported in Table 1 and 3? Is \"AUC\" always ROC-AUC, and is it used for explanation fidelity or prediction accuracy?​\n\nIs the code or minimal reproducible artifact available/planned, with precise hyperparameter choices for all datasets and ablation experiments?​\n\nWhat do the ablation acronyms stand for, and can these be defined for clarity?​\n\nWhy is HYPERSEM slower than GradCAM in inference, given that explanations are purportedly built-in? Can implementation specifics or bottlenecks be detailed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Qgx9Q0D6ZJ", "forum": "hVOsm02Bsb", "replyto": "hVOsm02Bsb", "signatures": ["ICLR.cc/2026/Conference/Submission10470/Reviewer_LWZa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10470/Reviewer_LWZa"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10470/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761512925288, "cdate": 1761512925288, "tmdate": 1762921767589, "mdate": 1762921767589, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper aims to improve the expressiveness and explainability of GNNs through multi-view hypergraph learning. The proposed method, HYPERSEM, constructs a multi-view hypergraph with three types of edges: (1) chemical rule-guided molecular hypergraph construction, (2) atom-centered neighborhood molecular hypergraph construction, and (3) dynamic molecular hypergraph construction. A convolutional network is proposed to encode structural information and pass messages between nodes and hyperedges. To provide graph explanations jointly with predictions, an information bottleneck-guided self-explanation module is introduced. Experiments on molecular property prediction and explanation tasks demonstrate the effectiveness of the proposed method."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe paper focuses on inherently interpretable models that provide explanations while predicting molecular properties, which is an important and valuable direction to explore. The idea of using hyperedges to enhance interpretability is interesting.\n\n2.\tThe methodology section is well organized, making the technical part relatively easy to follow.\n\n3.\tExperiments on both classification and explanation datasets demonstrate the effectiveness of the proposed method."}, "weaknesses": {"value": "1. The research problem statement is not clearly defined. The paper claims that existing explanation methods are data-driven and ignore chemical rules. However, several prior works use fragments for explanation [1–4]. Although the proposed method introduces the BRICS decomposition method to generate hyperedges, it also employs other hyperedge generation methods that do not align with chemical rules. Moreover, the lack of evaluation by chemical practitioners makes it difficult to assess the interpretability of the final explanations.\n\n2. The lack of comparison with related hypergraph-based methods obscures both the limitations of existing works and the novelty of the proposed approach [1, 5]. While some related work is mentioned in Sec. 2, the limitations of existing works and the novelties of the proposed work are not clearly stated.\n\n3. Several technical details are missing, making the method difficult to evaluate. The meanings of $N_{i,m}(e), r(z_{\\text{mol}})$, the calculation of $\\mathcal{L}_{\\text{vib}}$, the parameter setting of $\\tau$, and the budget for final explanatory subgraphs are not clearly stated.\n\n4. Some statements lack sufficient detail, making them difficult to understand. For example, in line 99, the authors state: “To alleviate the degradation of topological resolution commonly introduced by high-order hypergraph connections…” — but no supporting details or references are provided.\n\n5. Some statements are ambiguous. For instance, in Eq. (3), the process of constructing hyperedges with soft assignments is unclear. It is not specified whether all edges belong to one hyperedge and how this process aligns with chemical knowledge, which raises interpretability concerns.\n\n6. The criteria for selecting baseline methods are not clearly explained. In Sec. 2, the authors mention three methods that can provide interpretations jointly with predictions in an end-to-end manner, but these are not included in the comparisons.\n\n7. Some modifications to compared methods are made without clear statements. For example, in Fig. 4, GNNExplainer and PGExplainer originally explain graphs through edge-level importance, but the visualizations show node-level importance.\n\n[1] Yu, Z. and Gao, H., 2024. MAGE: Model-level graph neural networks explanations via motif-based graph generation. arXiv preprint arXiv:2405.12519.\n\n[2] Kokate, A. and Fern, X., MOSE-GNN: A Motif-Based Self-Explaining Graph Neural Network for Molecular Property Prediction. In The Third Learning on Graphs Conference.\n\n[3] Yu, Z. and Gao, H., 2022. Motifexplainer: a motif-based graph neural network explainer. arXiv preprint arXiv:2202.00519.\n\n[4] Liu, X., Luo, D., Gao, W. and Liu, Y., 2025, July. 3dgraphx: Explaining 3d molecular graph models via incorporating chemical priors. In Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V. 1 (pp. 859-870).\n\n[5] Bouritsas, G., Frasca, F., Zafeiriou, S. and Bronstein, M.M., 2022. Improving graph neural network expressivity via subgraph isomorphism counting. IEEE Transactions on Pattern Analysis and Machine Intelligence, 45(1), pp.657-668."}, "questions": {"value": "1. Could the authors specify the computational cost of hyperedge generation in terms of both time and resources?\n\n2. How are the first-level node embeddings $x_i^1$ derived?\n\n3. Could the authors provide the chemical evaluation of the final explanation results? Additionally, could the authors report the proportions of the three types of hyperedges in the whole graphs and the explantory subgraphs?\n\n4. In line 390, why are some methods using SMILES strings as input chosen, instead of those using the same type of molecular graph input for a fair comparison?\n\n5. What metric is used for comparison in Table 1?\n\n6. For visualization, could the authors clarify what the “chemical prior annotations” are and how they are obtained?\n\n7. What are the budget settings for explanations? Why does the number of edges differ across methods in Fig. 4?\n\n8. Which parameter settings are used for the experiments in Tables 1 and 2?\n\n9. Could the authors define all mathematical symbols and their shapes from Eq. (5) to Eq. (9)?\n\n10. Could the authors compare the results with substructure-based explanation methods [1–3]?\n\n[1]. Lin, W., Lan, H. and Li, B., 2021, July. Generative causal explanations for graph neural networks. In International conference on machine learning (pp. 6666-6679). PMLR.\n\n[2]. Bui, N., Nguyen, H.T., Nguyen, V.A. and Ying, R., 2024. Explaining graph neural networks via structure-aware interaction index. arXiv preprint arXiv:2405.14352.\n\n[3]. Yuan, H., Yu, H., Wang, J., Li, K. and Ji, S., 2021, July. On explainability of graph neural networks via subgraph explorations. In International conference on machine learning (pp. 12241-12252). PMLR."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WKOCQBBpKi", "forum": "hVOsm02Bsb", "replyto": "hVOsm02Bsb", "signatures": ["ICLR.cc/2026/Conference/Submission10470/Reviewer_fcrj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10470/Reviewer_fcrj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10470/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761606357961, "cdate": 1761606357961, "tmdate": 1762921767177, "mdate": 1762921767177, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces HYPERSEM, a self-explainable molecular property prediction framework that models molecules as multi-view hypergraphs to capture cooperative effects among atom groups while integrating chemical rules through BRICS fragmentation. The method constructs hyperedges from chemical rules, atom-centered neighborhoods, and dynamically learned connections, followed by a structure-informed hypergraph convolution that preserves molecular topology. An information bottleneck-guided module jointly produces predictions and interpretable substructure-level explanations by identifying informative hyperedges. Experiments on multiple molecular benchmarks demonstrate improved predictive accuracy and chemically meaningful explanations compared with existing GNN-based explainers."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper presents a clear framework (HYPERSEM) that integrates multi-view hypergraph modeling and information bottleneck-guided self-explanation for molecular property prediction.\n\n2. The approach achieves competitive results across multiple molecular benchmarks and provides detailed ablation and visualization studies.\n\n3. The idea of combining BRICS-based chemical rule-driven hyperedges with dynamic data-driven hyperedges offers a structured way to infuse domain knowledge into GNN interpretability.\n\n4. The paper is well-presented and the experiments are comprehensive."}, "weaknesses": {"value": "1. Motivational insufficiency. The two claimed limitations motivating this work, (1) neglect of atom groups, and (2) ignorance of chemical rules, are not comprehensively validated. Many prior works already address functional group or motif-level reasoning within molecular GNNs, including hyperstructure-based GNNs (e.g., DHKH [1]) and motif-based explanation frameworks (e.g. MOSE-GNN[2] ). The paper should provide a more rigorous comparison to these approaches to substantiate novelty.\n\n2. Limited novelty of BRICS integration. The use of the BRICS fragmentation algorithm for constructing chemically meaningful motifs is not new. Similar BRICS-based or functional-group decomposition strategies have appeared in previous molecular hypergraph and interpretable-GNN literature (e.g., MAGE[3]). The contribution here mainly lies in combining known strategies rather than introducing a fundamentally new mechanism.\n\n3. Technical opacity. The explanation generation process lacks precise details. The paper mentions hyperedge importance scoring but omits the selection rule, whether Top-K substructures or thresholding is applied. For fair comparison, it should be clarified how the number of selected nodes or edges is normalized across different explainers.\n\n4. Bias in explanation quality. The interpretability advantage may be partly induced by the BRICS-based hyperedge construction. Since BRICS fragments coincide with chemically meaningful motifs, explanations formed from these fragments inherently align with chemical intuition, creating an inductive bias rather than true learned interpretability. This limitation should be acknowledged and discussed explicitly. Moreover, there are a lot of molecules that BRICS can not work for, how to tackle this problem?\n\n5. A small typo: Page 6 line 320: \"$z_{mol}$\" appears incorrectly.\n\n[1] Kang, Xiaojun, et al. \"Dynamic hypergraph neural networks based on key hyperedges.\" Information Sciences 616 (2022): 37-51.\n[2] Kokate, Apurva, and Xiaoli Fern. \"MOSE-GNN: A Motif-Based Self-Explaining Graph Neural Network for Molecular Property Prediction.\" The Third Learning on Graphs Conference.\n[3] Yu, Zhaoning, and Hongyang Gao. \"MAGE: Model-level graph neural networks explanations via motif-based graph generation.\" arXiv preprint arXiv:2405.12519 (2024)."}, "questions": {"value": "See weakness.\n\nI am willing to modify my score after further revision and discussion."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8G0khm0BYL", "forum": "hVOsm02Bsb", "replyto": "hVOsm02Bsb", "signatures": ["ICLR.cc/2026/Conference/Submission10470/Reviewer_b3mD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10470/Reviewer_b3mD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10470/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761676192584, "cdate": 1761676192584, "tmdate": 1762921766589, "mdate": 1762921766589, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new framework that models molecules as hypergraphs instead of simple atom–bond graphs to better capture atomic group effects (e.g. functional groups) and provide interpretable predictions. It constructs three complementary types of hyperedges, rule-based (using BRICS chemical fragmentation), atom-centered local neighborhoods, and dynamic data-driven hyperedges, to encode both chemical priors and learned structural relations. A molecular structure-informed hypergraph convolution with shortest-path-based structural encoding enables bidirectional message passing between atoms and atom groups, while an information-bottleneck-guided self-explanation module selects the most informative hyperedges to yield both accurate predictions and chemically meaningful explanations."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Their methods yields good results based on what the authors report\n\n2. The paper is roughly easy to follow and well-written\n\n3. The use of a rule-based fragmentation (e.g., BRICS) is interesting. It is a way to integrate known chemical knowledge."}, "weaknesses": {"value": "1. The baselines for interpretability seem very old. The newest one is from 2023, while most are even from 2020 or pre 2020. \n\n2. The motivation of this paper seems conceptually problematic. The authors argue that existing methods suffer from two main drawbacks: (1) neglect of atom groups and (2) ignorance of chemical rules. However, the fundamental goal of an explanation method is to reveal how a neural network makes its decisions and to assess whether those decisions make sense or align with human knowledge. If human knowledge, such as chemical rules and functional group structures, is already explicitly incorporated into the model or explanation mechanism, then it becomes unclear what the method is actually explaining. In such a case, the explanation may simply reflect the prior knowledge injected into the system, rather than providing genuine insight into the model’s reasoning process.\n\n3. In addition to the motivation, without the consideration of model explanation, there are already existing works on hyperstructure-based GNNs. \n\n4. The experimental comparison can be unfair. The reported interpretability gains may partly stem from the use of BRICS-based hyperedge construction rather than genuine model reasoning. Because BRICS fragments naturally correspond to chemically meaningful motifs, explanations derived from these predefined fragments are predisposed to align with chemical intuition, introducing a strong inductive bias rather than demonstrating truly learned interpretability. This potential bias should be explicitly acknowledged and discussed. Furthermore, many molecules cannot be effectively decomposed by BRICS, raising concerns about how the method would generalize to such cases and what strategies could be used to address this limitation."}, "questions": {"value": "1. The explanation mechanism relies on minimizing the information bottleneck loss, yet the resulting substructures that achieve this objective are not necessarily chemically meaningful. The authors could test this by exhaustively or combinatorially evaluating finite substructure combinations to verify whether those minimizing the IB loss correspond to valid and interpretable chemical groups.\n\n2. The paper positions HYPERSEM as self-explainable. In what sense is it “self-explainable” beyond simply outputting attention scores or IB-derived importance weights?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lEJ2zKbid3", "forum": "hVOsm02Bsb", "replyto": "hVOsm02Bsb", "signatures": ["ICLR.cc/2026/Conference/Submission10470/Reviewer_AC1y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10470/Reviewer_AC1y"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10470/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761763025834, "cdate": 1761763025834, "tmdate": 1762921766198, "mdate": 1762921766198, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a multi-view hypergraph learning framework for self-explainable molecular property prediction. The key innovation is using hyperedges to model atomic groups and functional groups, moving beyond traditional node/edge-based explanations. The method combines three types of hyperedges: chemical rule-guided (BRICS), atom-centered k-hop neighborhoods, and dynamically learned hyperedges. A molecular structure-informed hypergraph convolution and information bottleneck-guided self-explanation module are designed to jointly generate predictions and explanations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper clearly identifies two critical limitations of existing explainable GNN methods for molecular property prediction: 1) neglect of cooperative effects among atomic groups, and 2) ignorance of chemical domain knowledge."}, "weaknesses": {"value": "- Is there a potential issue of K-hop Neighborhood Redundancy? For example, in the k-hop hyperedges (Eq. 2), for a molecule with N atoms, you create N hyperedges (one per atom). With k = 2, many of these hyperedges will have massive overlap (e.g., in a benzene ring, the 2-hop neighborhoods of all 6 atoms cover the entire ring). Would this lead to O(N²) redundant information? How could this redundancy be mitigated?\n\n- In Eq. 7, the authors aggregate node structural encodings to the hyperedge level using mean aggregation. Have you tried other aggregation methods, such as sum, max, or attention-weighted aggregation?\n\n- If the attention mechanism in Eqs. 8-9 are replaced with simple averaging. How much would the performance drop?\n\n- MoleculeNet includes eight commonly used classification datasets. Why do you select only three of them? Also, could you include MoleculeNet regression datasets in your experiments?"}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VJ85voIasP", "forum": "hVOsm02Bsb", "replyto": "hVOsm02Bsb", "signatures": ["ICLR.cc/2026/Conference/Submission10470/Reviewer_nzLU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10470/Reviewer_nzLU"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission10470/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761964410198, "cdate": 1761964410198, "tmdate": 1762921765610, "mdate": 1762921765610, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}