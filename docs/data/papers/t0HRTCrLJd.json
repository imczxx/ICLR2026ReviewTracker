{"id": "t0HRTCrLJd", "number": 1508, "cdate": 1756888255302, "mdate": 1759898205455, "content": {"title": "Struct2Real: A Systematic Framework for Accurate and Efficient Structure-Grounded Object Image Generation", "abstract": "Recent advances in image generation have enabled the creation of high-quality visual content with impressive semantic fidelity. However, generating object images under fine-grained structural constraints, particularly preserving topology and spatial layout,  remains an open challenge. We propose Struct2Real, a novel framework for structure-grounded object image generation that combines explicit structural control with photorealistic generation, consisting of twofold. 1) we develop a novel structure modeling system that enables users to create a 3D structural representation named StructMap — an object structure abstraction composed of geometric primitives and their spatial layouts. 2) We design a modular image generation algorithm and combine this algorithm with multimodal large language models (MLLMs), harnessing their superior performance to generate realistic object images under structural constraints encoded in StructMap.\nExtensive experiments demonstrate that Struct2Real achieves strong performance in structure-grounded object image generation while ensuring low user effort required for this task, highlighting the practicality and effectiveness of our method. Please refer to more details in our appendix and supplementary material.", "tldr": "This paper introduces Struct2Real, a framework that enables realistic and structurally faithful object image generation from StructMap.", "keywords": ["Controllable Image Generation", "Topology and Spatial Layout Constraints", "Multimodal Large Language Models"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2d823cdd2b673b9e0051e9faae6d1b0def02d11e.pdf", "supplementary_material": "/attachment/54b4930db416bf195d86eca1e110518fb30d5e99.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces Struct2Real, a novel framework for generating photorealistic object images under stringent structural constraints, specifically preserving object topology and spatial layout. The framework consists of two main modules: 1) A structure modeling system centered around StructMap, an explicit 3D representation composed of geometric primitives that encode the object's topology and spatial layout. 2) A modular image generation algorithm leveraging Multimodal Large Language Models (MLLMs). Extensive qualitative and quantitative experiments demonstrate that Struct2Real surpasses text, lineart, and scribble-based controllable generation methods in both visual realism and structural fidelity, while requiring lower creation effort."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Struct2Real introduces a cognitively inspired, part-based 3D abstraction framework named StructMap, which models objects through geometric primitives and their spatial relationships. The design achieves a strong balance between expressiveness and usability, enabling users to specify complex structures intuitively. Moreover, the authors provide a visual design and interaction interface that allows users to construct and inspect StructMaps directly, greatly enhancing interpretability and accessibility.\n\n2. The integration of the StructMap representation with the structure-consistency feedback loop offers a principled mechanism to enforce explicit topology and spatial layout. This feedback-driven process effectively guarantees structural fidelity even under complex geometric configurations, overcoming a key limitation faced by traditional sketch- or layout-based approaches.The modular condition-augmentation and consistency-discriminator design exploits MLLM reasoning to maintain geometric correctness.\n\n3. The overall framework is modular, combining condition augmentation, image generation, and consistency discrimination into a unified process. By leveraging the reasoning capability of multimodal large language models, the system maintains high geometric consistency while synthesizing photorealistic textures, achieving both controllability and realism in structure-grounded image generation."}, "weaknesses": {"value": "1. The method relies heavily on commercial MLLMs such as GPT-4o, which raises reproducibility concerns and may limit open evaluation.\n\n2. The dataset covers only about 30 object categories with 3,000 samples, which restricts scalability and domain generalization. Broader testing on complex scenes or organic, non-rigid objects would strengthen the conclusions.\n\n3. The StructMap representation is inherently constrained by its predefined primitive library. The current examples focus mainly on simple mechanical or geometric shapes, leaving its expressive capacity for more complex structures insufficiently demonstrated.\n\n4. The proposed feedback loop requires multiple rounds of MLLM inference, which could introduce significant computational overhead. A quantitative analysis of runtime and system cost would clarify the method’s practical feasibility.\n\n5. The quantitative evaluation focuses mainly on comparisons with large text-to-image models. It should include comparisons with other structure-aware or 3D-conditioned generation methods that address similar tasks."}, "questions": {"value": "1. Could StructMap be automatically learned or inferred from existing 3D data or multi-view images, rather than being manually constructed?\n\n2. How scalable is the StructMap creation process when modeling complex or deformable objects such as plants, animals, or articulated human figures?\n\n3. What is the computational cost of the full feedback loop? Please quantify the average number of iterations required by the discriminator for convergence.\n\n4. Could the authors quantify the contribution of each component in the modular pipeline through ablation or error propagation analysis?\n\n5. How well does Struct2Real generalize across viewpoints or lighting conditions? Can a single StructMap be used to render consistent multiview outputs, potentially linking to 3D-aware diffusion pipelines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CwkH1Gqxhn", "forum": "t0HRTCrLJd", "replyto": "t0HRTCrLJd", "signatures": ["ICLR.cc/2026/Conference/Submission1508/Reviewer_Bgc9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1508/Reviewer_Bgc9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1508/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761825715264, "cdate": 1761825715264, "tmdate": 1762915787794, "mdate": 1762915787794, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Struct2Real, a framework for structure-grounded object image generation. It introduces a new 3D structural representation called StructMap, composed of geometric primitives encoding object topology and spatial layout. The framework includes:\n(1) a structure modeling system allowing users to assemble StructMaps via an interactive interface, and\n(2) an image generation algorithm that combines StructMaps with multimodal large language models (MLLMs) to produce photorealistic images faithful to the provided structure.\nExperiments compare Struct2Real with text, lineart, and scribble-based conditioning under various baselines (OmniGen, ControlNet++, T2I-Adapter, etc.), evaluated by FID and human MOS ratings."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This work presents a clear motivation for structure-grounded control in object image generation, supported by cognitive inspiration (Recognition-by-Components theory).\n\n\n2. This work introduces StructMap, a clean, interpretable representation that enables explicit structural input.\n\n3. Demonstrates broad evaluation—multiple baselines, diverse conditioning modalities, and human studies on both realism and structural alignment.\n\n4. Visual examples are compelling and show genuine improvements in both realism and structure control."}, "weaknesses": {"value": "1. The paper relies solely on MOS for assessing structure–image alignment (Sec. 4.1 → A.2.5). This weakens objectivity.\n\n\n2. In Fig. 4, the iterative consistency-checking process is central, yet there is no evidence on iteration counts, failure cases, or convergence stability.\n\n3. The claimed “3000 samples, 30 categories” dataset is newly built but lacks public availability or validation diversity. Examples of StructMap complexity (number of primitives, topology variety) are missing.\n\n4. The proposed StructMap indeed provides a more accurate and explicit representation of object structures. However, since it relies on specific geometric priors and requires a dedicated software interface for creation, its applicability remains somewhat limited in terms of flexibility and accessibility, especially when compared to more lightweight and widely usable inputs such as text or scribble conditions."}, "questions": {"value": "1. How is the “structure consistency discriminator” implemented—purely via LLM reasoning or also via visual feature comparison? How many regeneration rounds are typically required before convergence?\n\n2. Could StructMap be automatically extracted from existing CAD or mesh data? If yes, how scalable is the user-creation interface beyond toy-level examples?\n\n3. Have you evaluated Struct2Real on multi-object scenes or non-rigid categories? Does the geometric-primitive abstraction generalize beyond single rigid objects?\n\n4. Is there a possibility to learn a StructMap-to-latent alignment (e.g., via adapter or encoder) instead of relying entirely on prompting?\n\n5. Will you release the structure-prior dataset and interface tools for reproducibility?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6eiJYAEcwo", "forum": "t0HRTCrLJd", "replyto": "t0HRTCrLJd", "signatures": ["ICLR.cc/2026/Conference/Submission1508/Reviewer_eGEB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1508/Reviewer_eGEB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1508/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761929300524, "cdate": 1761929300524, "tmdate": 1762915787630, "mdate": 1762915787630, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Struct2Real, a framework for structure-grounded object image generation that leverages explicit 3D structural priors (called StructMap) and integrates multimodal large language models (MLLMs) for photorealistic image synthesis under topology and spatial layout constraints. The work addresses a long-standing challenge in controllable generation — maintaining structural fidelity while achieving high realism. The proposed system includes (1) a structure modeling interface for creating StructMaps, (2) a condition augmentation and reasoning pipeline using MLLMs, and (3) a structure-consistency discriminator for iterative refinement. Experiments show consistent improvements over text, lineart, and scribble-based baselines in both realism (FID, MOS-R) and structure alignment (MOS-A)."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. a 3D composition of geometric primitives encoding topology and layout is conceptually elegant and practically useful. It provides a middle ground between coarse 2D conditions (e.g., lineart) and complex 3D CAD models.\n2. qualitative evaluations shows good performance in both realism and structure preservation."}, "weaknesses": {"value": "1. while StructMap is new, the image generation algorithm primarily relies on prompting existing MLLMs (e.g., GPT-4o). There is little discussion of model-specific innovations or learnable components beyond prompt design."}, "questions": {"value": "1. Line 192-193 \"these conditions are often coarse-grainedor ambiguous,making it difficult to accurately reflect the object’s structure\" do you have an exmple? can you explain?\n2. the paper talk a lot on 3D structure, it can generate novel view? \n3. can you suggest new way of controllability? in manner no one done before?\n4. Could Struct2Real generalize to articulated or deformable objects? new concepts objects?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FYOAB6i1Y5", "forum": "t0HRTCrLJd", "replyto": "t0HRTCrLJd", "signatures": ["ICLR.cc/2026/Conference/Submission1508/Reviewer_zjTn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1508/Reviewer_zjTn"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1508/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762068327430, "cdate": 1762068327430, "tmdate": 1762915787511, "mdate": 1762915787511, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of generating high-quality, photorealistic object images under fine-grained structural constraints—specifically preserving an object’s topology and spatial layout. Unlike existing controllable image generation methods that either offer only coarse structural guidance or require high professional skills, this work focuses on balancing precise structural control, visual realism, and user-friendliness, ensuring low effort for users while maintaining structural fidelity.\nTo tackle this challenge, the authors propose Struct2Real, a two-module framework integrated with multimodal large language models (MLLMs), featuring:\n- a structure modeling system centered on \"StructMap\"—a 3D structural representation built from geometric primitives and their adjustable properties . StructMap explicitly encodes an object’s topology and spatial layout, and the accompanying interactive interface lets users assemble StructMaps without specialized skills;\n- a modular image generation algorithm that works with MLLMs to translate StructMaps into photorealistic images, including three core components:\n  1. a Condition Augmentation Module that converts StructMap images into detailed textual descriptions to bridge the gap between structural inputs and language-preferred generative models, highlighting key structural details like part count, connections, and spatial arrangement;\n  2. an Image Generator that uses MLLMs to produce images conditioned on both StructMap images and their textual descriptions, preserving structural constraints while adding realistic textures, materials, and fine details. Users can also add optional style prompts to customize appearance;\n  3. a Structure Consistency Discriminator that forms a feedback loop—MLLMs compare generated images with StructMaps to identify structural inconsistencies, provide reasoning for mismatches, and guide the generator to regenerate until the image aligns with the input structure;\n- compatibility with multiple MLLMs to ensure generality across different multimodal model backends.\nExperiments on a manually constructed \"structure-prior dataset\" show this method outperforms state-of-the-art baselines: it delivers better image realism and structural alignment than text, lineart, and scribble-based methods; StructMap balances accessibility and performance; and ablation studies confirm the framework’s generality across MLLMs and the necessity of each component for strong results."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is well written and easy to follow. The figures are clear, visually appealing, and effectively support the explanations.\n- The experimental results are impressive and convincingly demonstrate the effectiveness of the proposed framework.\n- The overall approach is conceptually sound and logically consistent—it makes good sense and aligns well with the problem formulation."}, "weaknesses": {"value": "- Although the authors claim that their 3D structural representation is easy to obtain, this holds mainly for objects with relatively simple geometry. The method becomes less practical for complex shapes, which limits its applicability to more intricate or detailed structures.\n- While the system design is reasonable and well engineered, it lacks strong conceptual novelty. The work feels more like a comprehensive engineering integration rather than a fundamentally new algorithmic contribution.\n- The proposed pipeline, though effective, seems somewhat over-engineered for the task. The overall process could be viewed as unnecessarily complicated relative to the problem’s scale.\n- Some of the line-art examples used in the experiments appear to be of relatively low quality. When high-quality line-art conditions are used, the performance gap between baseline methods and the proposed approach becomes much smaller, which raises questions about the fairness of the dataset and evaluation setup."}, "questions": {"value": "1. The generated objects in your paper are mostly structurally simple. Could you provide more challenging examples that better demonstrate the capability and generalization of your method? While your structural control is indeed impressive, the simplicity of the examples limits the practical significance. Designing such simple shapes (e.g., cups) may not justify the relatively complex pipeline you propose—in some cases, manually sketching might even be more efficient.\n2. In Figure 5, don’t you think some of your geometry conditions are excessively detailed, while certain line-art conditions appear overly coarse? Regardless of how difficult these inputs are to obtain, could you show what would happen if one directly traced the geometric components to create line-art conditions? This would clarify whether the gap stems from representation quality rather than the generation method itself.\n3. Could you provide a quantitative estimate of the time required to construct geometric conditions? For instance, how long would it take to build the geometry condition for a simple object like a cup? And how would this time scale with more complex shapes—does the modeling effort grow significantly with geometric complexity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wfFwgIIbF7", "forum": "t0HRTCrLJd", "replyto": "t0HRTCrLJd", "signatures": ["ICLR.cc/2026/Conference/Submission1508/Reviewer_YmnD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1508/Reviewer_YmnD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1508/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762145238920, "cdate": 1762145238920, "tmdate": 1762915787364, "mdate": 1762915787364, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}