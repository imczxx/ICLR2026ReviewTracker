{"id": "DjNli4PdZx", "number": 5428, "cdate": 1757908554469, "mdate": 1759897976016, "content": {"title": "LiLAW: Lightweight Learnable Adaptive Weighting to Meta-Learn Sample Difficulty and Improve Noisy Training", "abstract": "Training deep neural networks in the presence of noisy labels and data heterogeneity is a major challenge. We introduce Lightweight Learnable Adaptive Weighting (LiLAW), a novel method that dynamically adjusts the loss weight of each training sample based on its evolving difficulty level, categorized as easy, moderate, or hard. Using only three learnable parameters, LiLAW adaptively prioritizes informative samples throughout training by updating these weights using a single mini-batch gradient descent step on the validation set after each training mini-batch, without requiring excessive hyperparameter tuning or a clean validation set. Extensive experiments across multiple general and medical imaging datasets, noise levels and types, loss functions, and architectures with and without pretraining demonstrate that LiLAW consistently enhances performance, even in high-noise environments. It is effective without heavy reliance on data augmentation or advanced regularization, highlighting its practicality. It offers a computationally efficient solution to boost model generalization and robustness in any neural network training setup. Code in Supplementary Material.", "tldr": "lightweight method that adaptively reweights samples by difficulty to boost robustness under noise", "keywords": ["reweighting", "noise", "mislabels", "lightweight", "adaptive", "meta-learning", "difficulty"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2e6dbe5b93283d5ac932f152409655fb987ad601.pdf", "supplementary_material": "/attachment/e688e8d101a69e84de17bcdafef914a149b2327c.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces a new method, LiLAW, that improves deep neural network training in challenging conditions like noisy labels and data heterogeneity. It dynamically adjusts loss weights based on sample difficulty using three learnable parameters. LiLAW prioritizes informative samples by updating weights with a mini-batch gradient descent step on the validation set after each epoch, requiring minimal hyperparameter tuning and no clean validation set. Extensive experiments show LiLAW enhances model performance. It’s computationally efficient, doesn’t heavily rely on data augmentation or advanced regularization, and is applicable to various datasets, noise levels, loss functions, and model architectures."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The method is computationally efficient, doesn’t heavily rely on data augmentation or advanced regularization, and is applicable to various datasets, noise levels, loss functions, and model architectures."}, "weaknesses": {"value": "Indeed, I reviewed this paper for ICML 2025. In my previous review, I noted that the experimental evaluation was insufficient, as several commonly used datasets were missing from the comparison. However, these datasets are still not included in the current version, and the authors have not provided any explanation for their exclusion."}, "questions": {"value": "None."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QbElEx7eNb", "forum": "DjNli4PdZx", "replyto": "DjNli4PdZx", "signatures": ["ICLR.cc/2026/Conference/Submission5428/Reviewer_H71v"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5428/Reviewer_H71v"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5428/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761641423427, "cdate": 1761641423427, "tmdate": 1762918056184, "mdate": 1762918056184, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The article introduces LiLAW, a lightweight meta-learning method designed to improve the training of deep neural networks under noisy and heterogeneous data conditions. The proposed method dynamically adjusts the loss weight of each training sample based on its evolving difficulty, categorized as easy, moderate, or hard, using three learnable parameters (\\alpha, \\beta, and \\delta). Extensive experiments across multiple datasets, noise types, and architectures validate the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The proposed method demonstrates versatility and is applicable to multiple domains, such as, natural images, medical images, and time-series tasks. The proposed method is model-agnostic and can be applied to different benchmarks. The adaptive learning mechanism avoids the need for extensive hyperparameter tuning."}, "weaknesses": {"value": "- The issue of noisy labels in classification is a widely studied problem. However, this paper lacks comparisons with classical noisy label learning methods in the experiments.\n- Applying meta-learning techniques to learn the sample weights is a typical approach in noisy label learning. Authors are suggested to clarify the distinctive advantages of their proposed method compared to such meta-learning approaches and include comparative experiments.\n- The approach of using noisy data as the validation set contradicts the theoretical analysis of prior meta-learning reweighting methods. This point is supported solely by empirical evidence and lacks theoretical interpretations.\n- Using meta-learning method will obviously increase the calculation time. Authors are suggested to compare the proposed method with the vanilla method in time."}, "questions": {"value": "- What are the physical meanings of the meta-learned \\alpha, \\beta and \\delta, and what is their mechanism of impact with respect to the sample weights?\n- In the method section, the paper proposes to initialize \\alpha<\\beta<\\delta. However, in the experiments, why the paper chooses to set \\alpha=10, \\beta=2, \\gamma=6?\n- The proposed method is designed to address label noise. What is the underlying reason for its effectiveness in handling input noise, as demonstrated in Table 1?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ooHk1TIwGX", "forum": "DjNli4PdZx", "replyto": "DjNli4PdZx", "signatures": ["ICLR.cc/2026/Conference/Submission5428/Reviewer_AJ6J"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5428/Reviewer_AJ6J"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5428/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761789836825, "cdate": 1761789836825, "tmdate": 1762918055770, "mdate": 1762918055770, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper propose a re-weighting strategy for training with noise label. It assign different weights to cases with different confidence and correctness levels using three additional hyperparameters, which are optimized using meta learning. The experiments are conducted on dataset with different noise levels and show better results on defending the noise. The method is also tested on different kind of dataset to proof the generalizability. However, some necessary ablations and comparisons are missing, which are important for understanding why this method performs better."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The proposed method is simple and easy to understand and implement. And it provides an effective strategy of defending noise in label at different levels. However, there are some necessary ablations and comparisons missing to better understand the superiority of this method."}, "weaknesses": {"value": "See the questions part below for concerns"}, "questions": {"value": "1. The claim \"\"s_i[\\hat{y_i}] < max(s_i) implies an incorrect prediction when \\hat{y_i}=y_i\" is correct. But how to know whether \\hat{y_i}=y_i given the noisy target only? The motivation is to assign weights to samples with different confidence and correctness level, but the definition of correctness is unable to verify. \n\n2. Is the noise level of validation set changing according to the training set? Or it is fixed? Have you tried using a clean validation set to see how the noise level of validation set affect the results?\n\n3. Please explain the claim\" easy, moderate, hard examples activate W_alpha, W_beta, W_delta respectively\" in chapter 3. The sentence after \"Geometrically, ...\" is hard to understand. like \"Wβ when β is small and/or...\" \nThe three hyper parameters jointly define the final weights as the total weight is a sum of W_alpha, W_beta, W_delta, I don't see how they can separately correspond to different type of examples.\n\n4. What is the definition of easy, moderate, hard examples\n\n5. Are there any ablations showing the difference of using different combination of W_alpha, W_beta, W_delta? That will help understand each part\n\n6. The design of different form of W_beta seems redundant.  Actually W_beta(beta) = 1- W_alpha(beta)\n\n7. Using confidence is a common way of defending noise, like assigning more weights to cases with more confidence. How is the comparison with such methods.\n\n8. About complexity analysis, the paper claims the LiLAW keeps the same complexity but from the algorithm, LiLAW requires two times of forward and two times of backward for each mini-batch, which sounds like a doubled time.  Even the second backward only changes three parameters, that doesn't mean it only cost O(3) time in the actual implementation. Is there any actual time cost comparison with/without LiLAW?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5GCZMQM1Kg", "forum": "DjNli4PdZx", "replyto": "DjNli4PdZx", "signatures": ["ICLR.cc/2026/Conference/Submission5428/Reviewer_YYaE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5428/Reviewer_YYaE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5428/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761861471980, "cdate": 1761861471980, "tmdate": 1762918055290, "mdate": 1762918055290, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}