{"id": "kx3txPrC2B", "number": 3218, "cdate": 1757377498848, "mdate": 1759898101572, "content": {"title": "Effective Model Pruning", "abstract": "We introduce Effective Model Pruning (EMP), a context-agnostic, parameter-free rule addressing a fundamental question about pruning: how many entries to keep. EMP does not prescribe how to score the parameters or prune the models; instead, it supplies a universal adaptive threshold that can be applied to any pruning criterion: weight magnitude, attention score, KAN importance score, or even feature-level signals such as image pixel, and used on structural parts or weights of the models. Given any score vector $s$, EMP maps $s$ to a built-in effective number $N_{eff}$ which is inspired by the Inverse Simpson index of contributors. Retaining the $N_{eff}$ highest scoring entries and zeroing the remainder yields sparse models with performance comparable to the original dense networks across MLPs, CNNs, Transformers/LLMs, and KAN, in our experiments. By leveraging the geometry of the simplex, we derive a tight lower bound on the preserved mass $s_{eff}$ (the sum of retained scores) over the corresponding ordered probability simplex associated with the score vector $s$. We further verify the effectiveness of $N_{eff}$ by pruning the model with a scaled threshold $\\beta N_{eff}$ across a variety of criteria and models. Experiments suggest that the default $\\beta=1$ yields a robust threshold for model pruning while $\\beta\\neq1$ still serves as an optional adjustment to meet specific sparsity requirements.", "tldr": "Instead of prescribe how to score and prune the parameters, this paper supplies a universal adaptive threshold that can be paired with any current pruning criterion supported by a theoretical guaranteed lower bound of the retained mass.", "keywords": ["Model Pruning"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b2ecd20430cf00f3b7ed52496a1eeabd0648c41b.pdf", "supplementary_material": "/attachment/0798cc6908dc9325029e18ad2b455640036bbfce.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes Effective Model Pruning (EMP), a method to automatically determine the number of parameters to retain during pruning without manually setting a sparsity level. EMP estimates the effective number of parameters based on the distribution of importance scores, inspired by measures from ecology and statistical physics. The authors present a theoretical analysis linking model performance to the retention ratio, and conduct numerical experiments on convolutional neural networks, multilayer perceptrons, Kolmogorov–Arnold networks (KANs), and large language models."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "(1) The main strength of this paper is that the authors redefine the pruning problem at a higher level. Instead of seeking better performance under a fixed sparsity level, they raise a meta question about what degree of sparsity a model should naturally have, making sparsity part of the objective itself. \n\n(2) The authors also draw inspiration from ecology and statistical physics by introducing the concepts of effective number and participation ratio as new tools for analyzing model redundancy."}, "weaknesses": {"value": "(1) The motivation of this work is not fully convincing. Model pruning is primarily designed to meet specific hardware and deployment constraints, aiming for concrete compression targets. Automatically deciding the sparsity level overlooks this practical objective and may not align with real compression needs.\n\n(2) The introduction of the scaling factor \\beta substantially weakens the theoretical contribution, since \\beta can arbitrarily affect the final sparsity. In practice, this is not fundamentally different from manually choosing a desirable sparsity level.\n\n(3) Although the experiments cover multiple network architectures, the baseline methods are not as diverse as the authors claim, and the results do not convincingly demonstrate the superiority of the proposed approach. Lower sparsity naturally leads to higher accuracy, which reflects a trade-off rather than a genuine performance improvement. More importantly, some experiments even show simultaneous drops in both sparsity and accuracy, further weakening the credibility of the empirical findings."}, "questions": {"value": "(1) The paper contains many fixed and absolute parameter or threshold choices, although such quantities are often relative in nature, which makes their justification somewhat unclear. In addition, the pruning settings compared in the experiments each also have their own advantages. The reviewer encourages the authors to minimize the influence of subjective preferences in these aspects.\n\n(2) In the KAN experiments, EMP is combined with the existing importance criterion rather than used independently. Could the authors provide an ablation study to clarify EMP’s standalone contribution?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "r521bAfIuD", "forum": "kx3txPrC2B", "replyto": "kx3txPrC2B", "signatures": ["ICLR.cc/2026/Conference/Submission3218/Reviewer_KhLi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3218/Reviewer_KhLi"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3218/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761703902641, "cdate": 1761703902641, "tmdate": 1762916605681, "mdate": 1762916605681, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes EMP, a method to decide how many weights to prune given a saliency as given by weight magnitude or others criteria, such as the well-known LLM pruning criterion Wanda. EMP takes in such a score vector s and then computes a number N of weights that, to the best of my understanding, should best be pruned. The authors derive this number theoretically and validate their claims on a series of small-scale experiments."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The topic is generally interesting and not so common in the pruning literature. Typically, pruning papers try to find the best possible mask for a given sparsity level. Here however, the authors take a different route: Given a saliency, find the sparsity that keeps the error below a certain threshold.\n- The paper is generally well written.\n- While I am not particularly sure whether I understand the derivation correctly, the final criterion, as presented in Algorithm 1, is easy to understand."}, "weaknesses": {"value": "- The computational study is limited to small-scale experiments and not done thoroughly. For instance, I am not sure which LLAMA models are used in the LLM experiments. The study is not very convincing.\n- I currently fail to see the benefit of using EMP, nor the insights it provides. Take for instance Table 2. Magnitude pruning is a questionable metric for LLMs, as various papers have shown: perplexity explodes when pruning to medium-range sparsities, and some even argue that it is no better than random pruning. So let us compare Wanda: according to Table 2, Wanda perplexity increases by roughly 0.8 when pruning to 50% sparsity. Using EMP-Wanda, the perplexity increases \"only\" by 0.67, roughly a 17% improvement over Wanda. At the same time however, EMP-Wanda induces a sparsity of 40%, and hence a 20% reduction compares to Wanda. What am I supposed to conclude from this? Why doesn't this table contain the information when using Wanda to prune to exactly 40%?\n- Clearly, when using a lower sparsity level, the performance will improve. So what point are the authors trying to make? If you argue that you have found a better way of selecting which weights to prune, you should compare to other methods at a lower sparsity level.\n\n\n### Minor Remarks\n- I am not very fond of the title. This is of course up to the authors, but I think \"Effective Model Pruning\" is very broad and not very descriptive.\n- There are some language issues. For instance, the sentence on lines 127-128 is grammatically incorrect."}, "questions": {"value": "- The Score matrix of EMP, is that given globally for all weights or per layer? If its globally given, I am very certain that this will not work for LLMs, as it will ignore the well-known activation outliers in some layers."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pv2lJcOmwL", "forum": "kx3txPrC2B", "replyto": "kx3txPrC2B", "signatures": ["ICLR.cc/2026/Conference/Submission3218/Reviewer_GnoB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3218/Reviewer_GnoB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3218/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761900403353, "cdate": 1761900403353, "tmdate": 1762916605410, "mdate": 1762916605410, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new method for assigning sparsity ratios for pruning algorithms, given a vector of saliency scores. The proposed method is agnostic to the choice of saliency as well as the nature of the pruning method (i.e. unstructured, N:M block sparstiy, and structured pruning). The key idea of this method is the derivation of the *effective mass* of the saliency vector, with which a principled approach for obtaining the number of weights/components to be retained, $N_{eff}$ is proposed (specifically Proposition 1). This sparsity allocation technique is applied to a variety of models, including simple CNNs and fully connected models, LLMs (Llama family), and KANs."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "S1. The paper addresses an interesting problem of how to allocate sparsity when pruning models.\n\nS2. The the (tight) lower bound on $N_{eff}$ and $s_{eff}$ (stated in Prop 1 and Thm 2) appear to be correct, and to the best of my knowledge, is the first results of their kind.\n\nS3. The writing of the paper is generally clear, though perhaps the discussion in Sections 4.1-4.3 could be made more clear."}, "weaknesses": {"value": "Broadly speaking, while the premise of this work is interesting, and the derived lower bounds are potentially very useful to practitioners, I feel the investigation needs to be made deeper. I point out specific points below.\n\nW1. While a wide array of models and datasets are used, the experiments themselves are somewhat unconvincing. For instance, in Table 2, the change in perplexity when using EMP is roughly the same as that when using a fixed sparsity allocation, despite pruning roughly 10% fewer parameters. This raises an obvious question about the utility of the method (see 'Questions section') \n\nW2. The authors also neglect to mention what the nature of the pruning being done in the experimental section actually is. A comparison between the two would have been very useful to readers and practitioners.\n\nW3. While the lower bound on $N_{eff}$ is interesting, it is presented almost as a mechanical result. There is no insight as to how $N_{eff}$ might change provided different saliency measures (i.e. gradient vs weight magnitude vs discriminative capacity). \n\nW4. Despite the proposed method being applied to a fairly wide array of models and datasets, the empirical study does not seem particularly deep. Several avenues for investigation that would have yielded useful insights have been ignored. Moreover, the point of the experiments is also unclear: as mentioned earlier, the true value of optimal sparsity allocation is not addressed properly, as the experiments themselves repeatedly suggest that fixing a sparsity ratio and pruning is every bit as good as using the optimal allocation.\n\nW5. In the appendix, specifically in Tables 6 and 7, the sparsity of the models should be stated, and if they are the same as used in Table 5, then that needs to be made clear."}, "questions": {"value": "Q1.  What is the utility of this method, when just fixing the sparsity ratio achieves a sparsity-accuracy tradeoff that is almost as good as the optimal sparsity allocation proposed in this work?\n\nQ2. Is structured or unstructured sparsity used in the experiments section, or is some sort of N:M block sparsity being used?\n\nQ3. How does the optimal allocation perform when using structured vs unstructured sparsity?\n\nQ4. Can the proposed method be used to identify which *layers* in a network are more important for predictions? \n\nQ5. How does sparsity allocation vary across layers for different saliency measures (given a dataset/model), and what insights does that reveal? Does applying the sparsity using $N_{eff}$ in a layerwise manner yield sparser and more accurate models than just setting the sparsity *a priori*?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FfMy0Acc2A", "forum": "kx3txPrC2B", "replyto": "kx3txPrC2B", "signatures": ["ICLR.cc/2026/Conference/Submission3218/Reviewer_cuU9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3218/Reviewer_cuU9"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3218/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761904034539, "cdate": 1761904034539, "tmdate": 1762916605205, "mdate": 1762916605205, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a pruning method designed to work for any pruning criterion which can be formalised as a tuple of values (e.g. global unstructured pruning would be the tuple of all weights and biases in a given network). It works by providing a simple definition of N_eff, the effective number of parameters of the tuple, based on the inverse Simpson index. The paper then provides a lower bound on the magnitude of the mass lost to pruning in terms of N_eff (I’m skipping some details here, Theorem 2). Finally the submission shows the result of pruning up to N_eff on a wide range of architectures and for a wide range of pruning criteria and shows the optimality of N_eff for certain models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "There is potential in the idea of bringing in ideas from information theory to the problem of providing a context-agnostic pruning threshold.\nThe experiment in Fig 3 could be convincing with some adjustments. If the result was show empirically, then the scientifically interesting could be tackled: why does N_eff work? That's where the meat is."}, "weaknesses": {"value": "I have some serious reservations about this work.\n\nConceptual reservation: This work relies on a quantity related to the inverse Simpson index (which I had never heard of). The latter is described in 3 lines (057-059) and the reader is referred to a paper on political studies and a textbook on information theory. Ideas from information theory may be relevant, but the reader is given no further explanation or motivation as to why this particular notion might be relevant to the problem of pruning. The entire approach is predicated on accepting the premise that N_eff is useful for the problem at hand, this is imposed by fiat without any discussion or motivation. N_eff might or might not be useful, but the onus is on the authors to convince the readers that it is. A plausible mechanism explaining why N_eff may be useful (perhaps based on information-theoretic considerations) would do that. \n\nMathematical reservations: \n- I’m not sure that there is much point in Theorem 2 as in practice it will not improve the bound much beyond the simpler bound \\rho<=s_eff. Pruning usually achieves N_eff in the range of, say, N/10 to N/3 without loosing too much accuracy. For this kind of values, theorem 2 gives a correction factor to \\rho between 1-sqrt(9/N) and 1-sqrt(3/N). Since N is very large, this is typically a tiny multiplicative gain over just using \\rho. I therefore don’t see the point of this result, particularly in this context where everything is quite imprecise anyway.\n- Equation (18) and the line that precedes it is problematic. How can the limit as N\\to\\infty make any sense? N_eff is built from a fixed vector s (sec 4.1) of fixed dimension N. If we were to take N\\to\\infty, then we need a sequence of vectors (s_i) of increasing dimensions. There is no reason to assume that the expression between (17) and (18) would converge to anything in this scenario. Take s_n of dimension n, with s_n=(1,0,…0) if n is odd and s_n=(1/n,…,1/n) is n is even, then N_eff will oscillate between 1 and n as n\\to\\infty and there is no sense in which the expression between (17) and (18) can converge to anything.\n\nSpecific comments: \n-p3: || M ||_0 is not completely standard notation, it should be defined.\n-p3: what is a “pruning object”?\n-p3,4,5: I’m not sure I understand the equation labelling convention. Almost every inline equation is labelled but never referred to, but the definition of N_eff, which should be referred to further on, isn’t. \n-p4, the invariance of N_eff under permutation is a trivial consequence of the commutativity of addition. \n-p5, sec 4.3, first sentence: Why?\nP7, 5.1: Are you doing global unstructured pruning here? It’s not explained very clearly.\n-p8, fig3: The experiment makes a lot of sense and would be convincing if it was more fine-grained around \\beta=1. Here the increments are very large (N_eff/4), and it would be perfectly possible that when \\beta=2 we get \\beta*N_eff \\approx N and so we know that 1.5*\\beta will be almost as good as N too. Moreover, it isn’t clear how stable each of these curves are to different pre-training initialisations, I would have expected some kind of average over many initialisations. \n-p8, fig 3: The legend is really hard to see. You should explain block vs global, it’s not explained in Appendix B either.\n-p9,Table 2: The two 50.00% with std =0.00 rows look suspicious or something is not explained as it should."}, "questions": {"value": "Why N_eff and not something else?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "drz7dpWYNk", "forum": "kx3txPrC2B", "replyto": "kx3txPrC2B", "signatures": ["ICLR.cc/2026/Conference/Submission3218/Reviewer_6Nkf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3218/Reviewer_6Nkf"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3218/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762198514564, "cdate": 1762198514564, "tmdate": 1762916604956, "mdate": 1762916604956, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}