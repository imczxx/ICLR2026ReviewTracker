{"id": "Sr0btZuwBi", "number": 20678, "cdate": 1758308911986, "mdate": 1759896964553, "content": {"title": "VeriTrail: Closed-Domain Hallucination Detection with Traceability", "abstract": "Even when instructed to adhere to source material, language models often generate unsubstantiated content – a phenomenon known as “closed-domain hallucination.” This risk is amplified in processes with multiple generative steps (MGS), compared to processes with a single generative step (SGS). However, due to the greater complexity of MGS processes, we argue that detecting hallucinations in their final outputs is necessary but not sufficient: it is equally important to trace where hallucinated content was likely introduced and how faithful content may have been derived from the source through intermediate outputs. To address this need, we present VeriTrail, the first closed-domain hallucination detection method designed to provide traceability for both MGS and SGS processes. We also introduce the first datasets to include all intermediate outputs as well as human annotations of final outputs’ faithfulness for their respective MGS processes. We demonstrate that VeriTrail outperforms baseline methods on both datasets.", "tldr": "We introduce VeriTrail, the first closed-domain hallucination detection method designed to provide traceability for processes with any number of generative steps, and demonstrate that it outperforms baseline methods in hallucination detection.", "keywords": ["hallucination detection", "faithfulness", "fact-checking", "traceability", "provenance", "error localization"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b6cee478457f8caf5bfee53e56393cb74442e378.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "**Summary**\n\nThe paper introduces an algorithm for detecting hallucinations and provide traceability in processes with multiple generative steps (MGS). Processes with multiple generative steps involve multiple calls to an LLM and typically involve feeding output of a step as the input of a subsequent step. In the context of the paper, traceability includes identifying the source from which a claim was derived and also, in which subprocess any error(s) were introduced.\n\n**Contributions**\n- An algorithm for detecting hallucinations in processes with MGS\n- Two new datasets for faithfulness of LLM outputs that include outputs of intermediate steps"}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper addresses an important and underserved area of combating hallucinations in LLM outputs. Namely, in complex tasks that involve several LLM calls with potential chaining from output of one call to the input of another. \n- I commend the clarity with which they have described their framework.\n- I understand that in newer research directions, it can be challenging to find strong benchmarks/baselines to compare. So, I appreciate the effort in making their own datasets (FABLES+, DiverseSumm+)."}, "weaknesses": {"value": "- As the authors state at the end of the paper, VeriTrail is a reference-based method, meaning that it relies on relevant source text and compares claims with this source text. So, its applicability is inherently limited to transformative tasks like summarization (and not, say, to question-answering when the LLM is relying on its internal knowledge). Even the benchmarks that are used in the experiments are both essentially summarization tasks. While I don't mind a method limited in applicability, this limitation should be presented clearly.\n- None of the baselines assume or use the DAG of the generative process with MGS. IMO, this makes them weak baselines for comparison.\n- The prompts used in VeriTrail have some examples or clarifications. How were these chosen? The effect of these on the performance of VeriTrail is unclear. I am afraid that if they were added in an ad-hoc fashion, would these necessarily translate to other tasks or benchmarks?\n\nUltimately, I am giving the paper a score of 2 due to the above reasons."}, "questions": {"value": "- With regard to the weakness 1 mentioned above, do you think VeriTrail is applicable to tasks other than summarization? If yes, please mention them and how would you apply VeriTrail in such tasks?\n- What was the rationale for each step in VeriTrail being done with a large monolithic prompt? Have you considered breaking it down into smaller steps with more specific instructions? I am asking this because I see that the prompts in the appendix are written in a step-by-step fashion, asking the LM to do one after the other in a single prompt.\n- I am curious to see if using something like DSPy [1] for optimizing the prompts would lead to better performance. \n\n**References:**\n\n[1] DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines (Khattab et al: [https://arxiv.org/abs/2310.03714](https://arxiv.org/abs/2310.03714))"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3xNLibXr9m", "forum": "Sr0btZuwBi", "replyto": "Sr0btZuwBi", "signatures": ["ICLR.cc/2026/Conference/Submission20678/Reviewer_xtw1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20678/Reviewer_xtw1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20678/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761918676303, "cdate": 1761918676303, "tmdate": 1762934062259, "mdate": 1762934062259, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors analyze hallucination detection in generations of autoregressive LLMs in a closed-domain setting. As opposed to just single-step generation (such as with RAG), the paper analyses hallucinations in a more complex and challenging setting, involving multiple generative steps (MGS). Toward this, the authors propose VeriTrail, which assesses the faithfulness, as well as provenance tracing and error localization using a multi-stage graph-based framework. The method begins with the final output and uses backward traversal to identify the stage at which hallucinations may have been introduced. The paper further introduces two new datasets FABLES+ and DiverseSumm+, and demonstrates the efficacy of VeriTrail over existing baselines like RAG and long-context models toward hallucination detection."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1) The paper studies a pertinent problem of detecting hallucinations in the generations of autoregressive LLMs, while also focusing on provenance tracing and error localization with multiple-generation steps, which is highly relevant given complex, multi-agent systems that have gained prominence in recent times. By identifying the intermediate stage at which hallucinations are introduced in a closed-domain setting, specific and actionable modes of improvement can be identified and undertaken in these complex systems in a transparent manner.\n\n2) The DAG-based framework adopted by VeriTrail is principled, and helps assess the veracity of claims and sub-claims in a systematic manner. Furthermore, selective verification helps reduce unnecessary and wasteful computation over nodes that correspond to uninformative texts relative to the primary claim. \n\n3) A significant and notable contribution of the paper is the introduction of two new datasets, FABLES+ and DiverseSumm+, that are specific to the MGS setting, and include intermediate outputs as well as human-annotated evaluations on faithfulness. Furthermore, the proposed method VeriTrail is shown to be effective, and out-performs strong existing baselines on these datasets."}, "weaknesses": {"value": "1) The proposed method VeriTrail is not simple, and requires a fairly complex setting up of the generative process as a DAG, and ensure that each intermediate output is carefully produced and analyzed in a multi-step manner with verification by an LLM. This also places a constraint on its scalability in practice for real-time applications, given the need for multiple LLM calls for each claim/sub-claim in the final output. Could the authors also kindly provide some metrics with respect to the actual average runtime required for the overall verification pipeline, and compare with more standard approaches like RAG itself?\n\n\n2) This complexity also manifests in the computational overheads and costs involved for improved performance. For instance, as presented in Appendix D, when comparing with the same LLM model (gpt-4o-2024-0806), VeriTrail  appears to cost 5x-9x more than RAG itself. These added costs can further limit practical usage in several real-world settings. \n\n\n3) The quality of VeriTrail's analysis depends critically on the decomposition of the final output into factual claims, using Claimify. Given this critical dependance, if Claimify makes an ambiguous phrasing of a claim, or introduces an error in itself, the proposed method cannot recover in a meaningful manner.\n\n\n4) Stage-assignment analysis: Must this setup for stage-assignment logic be explicitly programmed by a developer for each new MGS system, or does the framework offer any mechanism to automatically infer or propose a logical stage hierarchy from the process graph itself? Furthermore, how sensitive is the accuracy and utility of the 'error stage' localization to the granularity of this breakdown? Would this be more dependent on the actual facts presented, as opposed to the stage-specific assignments given the closed-domain setup?"}, "questions": {"value": "Kindly refer to the questions mentioned in the weaknesses section above. I would be happy to raise my score further if these could be adequately addressed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "oBTjXDVzQ1", "forum": "Sr0btZuwBi", "replyto": "Sr0btZuwBi", "signatures": ["ICLR.cc/2026/Conference/Submission20678/Reviewer_8wrP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20678/Reviewer_8wrP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20678/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984555709, "cdate": 1761984555709, "tmdate": 1762934061870, "mdate": 1762934061870, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses closed-domain hallucination in complex, multi-step generative (MGS) processes, where error risk is amplified. The authors argue that simple detection is insufficient for MGS and propose \"traceability\", the ability to pinpoint where errors are introduced. They present a novel method that models the generation process as a graph to achieve both detection and traceability. To evaluate this, new datasets with intermediate steps were created. Experiments show the proposed method outperforms baselines in detection while also providing this novel traceability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper tackles the critical problem of error propagation in MGS processes. The focus on \"traceability\" beyond simple detection is a key conceptual contribution.\n\nThe method is tested against strong, comprehensive baselines."}, "weaknesses": {"value": "A primary weakness of this method is its recursive reliance on Large Language Models (LLMs). Core steps of VeriTrail, including sub-claim decomposition, evidence selection, and final verdict generation, are all dependent on LLMs. This creates a fundamental \"verifier's dilemma\": the LLM used for verification may itself hallucinate or make faulty inferences.\n\nThe paper's own error analysis in Appendix G concedes that the verification model itself can make \"invalid inferences\" or improperly use \"parametric knowledge.\" This directly undermines the claimed reliability of the detection method, as the verification process itself may introduce new errors."}, "questions": {"value": "Please refer to the previous section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5UmvfmMMDD", "forum": "Sr0btZuwBi", "replyto": "Sr0btZuwBi", "signatures": ["ICLR.cc/2026/Conference/Submission20678/Reviewer_xoWU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20678/Reviewer_xoWU"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20678/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762157853890, "cdate": 1762157853890, "tmdate": 1762934061554, "mdate": 1762934061554, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a hallucination detection framework for multi-step generation process. It models the tracibility of generated content (the chain of rationale) with a directed acyclic graph and convert the hallucination detection of the final problem to a traverse on graph. Experiments on book summary and news summary shows that it outperforms previous method."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "+ The paper proposes a new framework for hallucination detection in multi-generation process.\n+ It curates two datasets for faithfulness evaluation in MGS based on previous benchmarks.\n+ The proposed VeriTrail framework shows a substaintial improvement over previous baseline."}, "weaknesses": {"value": "+ Missing intermediate results. The ablation analysis In Appendix E shows that evidence selection using language model plays an important role in final performance so it would be necessary to include the accuracy of the evidence selection in evaluation.\n\n+ Since VeriTrail uses stage-by-stage verfiication and does not have to always checks the source materials if the verfiication process exits early, I would suggest analyzing the API token cost of VeriTrail and comparing with the baseline method.\n\n+ a minor comment is to use vector graph in Figure 1 for better readability."}, "questions": {"value": "See the weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "r36z8DUs0J", "forum": "Sr0btZuwBi", "replyto": "Sr0btZuwBi", "signatures": ["ICLR.cc/2026/Conference/Submission20678/Reviewer_1wLF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20678/Reviewer_1wLF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20678/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762175604017, "cdate": 1762175604017, "tmdate": 1762934061146, "mdate": 1762934061146, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}