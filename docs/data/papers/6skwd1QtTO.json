{"id": "6skwd1QtTO", "number": 8048, "cdate": 1758055075137, "mdate": 1759897811764, "content": {"title": "CORRECT: COndensed eRror RECognition via knowledge Transfer in multi-agent systems", "abstract": "Multi-agent systems (MAS) are increasingly capable of tackling complex real-world tasks, yet their reliance on inter-agent coordination, tool use, and long-horizon reasoning makes error recognition particularly challenging. Minor errors can propagate across agents, escalating into task failures while producing long, intertwined execution trajectories that impose significant costs for both human developers and automated systems to debug and analyze. Our key insight is that, despite surface differences in failure trajectories (e.g., logs), MAS errors often recur with similar structural patterns. This paper presents CORRECT, the first lightweight, training-free framework that leverages an online cache of distilled error schemata to recognize and transfer knowledge of failure structures across new requests. This cache-based reuse allows LLMs to perform targeted error localization at inference time, avoiding the need for expensive retraining while adapting to dynamic MAS deployments in subseconds. To support rigorous study in this domain, we also introduce CORRECT-Error, a large-scale dataset of over 2,000 annotated trajectories collected through a novel error-injection pipeline guided by real-world distributions, and further validated through human evaluation to ensure alignment with natural failure patterns. Experiments across seven diverse MAS applications show that CORRECT improves step-level error localization up to 19.8\\% over existing advances while at near-zero overhead, substantially narrowing the gap between automated and human-level error recognition.", "tldr": "CORRECT distills MAS failures into reusable schemas, enabling LLMs to pinpoint errors instantly without retraining while adapting to new deployments in subseconds.", "keywords": ["Multi-agent systems", "Error detection", "Knowledge transfer"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a216a900592f0c22c56fe24246dc706b3f4de4d2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses the important and challenging problem of \"decisive error recognition\" in Multi-Agent Systems (MAS). The authors propose CORRECT, a novel, training-free framework that leverages knowledge transfer to identify the root cause of task failures. The core idea is to distill lengthy and noisy failure trajectories into compact, reusable \"error schemata.\" These schemata are then retrieved at inference time to guide an LLM in diagnosing new, similar failures. To facilitate research in this area, the authors also introduce CORRECT-Error, a large-scale benchmark of over 2,000 annotated failure trajectories created via a novel error-injection pipeline. Experiments conducted on the new benchmark and the existing WHO&WHEN dataset show that CORRECT improves error localization accuracy over several baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The discussed topic is important and timely. The problem of error attribution in increasingly complex and long-horizon MAS is both critical for reliability and under-explored.\n\n2. The central idea of abstracting away from noisy, full-length trajectories into condensed \"error schemata\" is insightful and novel. This schema-guided approach is a clever way to perform knowledge transfer without the prohibitive context length requirements or computational costs of naive ICL or fine-tuning.\n\n3. Extensive Experimental Evaluation: The authors conduct a thorough evaluation across two major benchmarks (WHO&WHEN and their new CORRECT-Error), seven diverse sub-tasks (e.g., HotpotQA, GAIA, Math500), and a wide range of open-source and proprietary models. The ablation studies on cache size and the number of retrieved schemata provide valuable insights into the framework's behavior."}, "weaknesses": {"value": "1. A major weakness of the proposed framework is its critical dependence on a highly capable and proprietary LLM (GPT-5 is mentioned) for the offline schema extraction phase. The quality of the entire system hinges on the ability of this \"teacher\" model to generate high-quality schemata.\n\n2. The dynamic schema management system (expansion and distillation) is described at a high level, but practical details are sparse. The process of \"replaying\" candidate schemas against prior trajectories to select the best one  sounds computationally intensive, especially as the number of trajectories and schemas grows.\n\n3. Baselines center on generic LLM-as-a-judge and naive ICL. The paper does not pit CORRECT against specialized verification pipelines which could also reduce long-context noise without relying on learned schemas.\n\n4. The schema idea is also central to the benchmark generation (semantic matching + schema-like error patterns). While the human study is encouraging, the pipeline may implicitly bias toward the kinds of failures that schemas capture well, potentially inflating CORRECT’s advantage. The paper does not quantify how often decisive errors in natural logs deviate from the assumed, reusable “pattern” structure."}, "questions": {"value": "1. How exactly are decisive-step labels produced in both WHO&WHEN (human-crafted/algorithm-generated) and CORRECT-Error? Do you perform counterfactual replay that replaces step k and re-executes to confirm flip-to-success, or rely on annotator judgment?\n\n2. What happens when top-k retrieval deliberately includes partially mismatched schemas (e.g., same tool family but different failure signature)? Could you report accuracy as a function of retrieval noise or add a hard negative experiment?\n\n3. Have you tried a causal-replay baseline that toggles a small set of suspect steps (e.g., tool-call deltas) to find the earliest flip-to-success point? Even if expensive, a smaller-scale study would clarify whether schemas offer gains over more explicit verification.\n\n4. The paper claims the framework is \"training-free\", yet it relies heavily on LLMs for both schema generation and final diagnosis. While it avoids fine-tuning, it is not independent of trained models. Could you clarify this claim or rephrase it to more accurately reflect that the method is \"fine-tuning-free\" but dependent on powerful pre-trained models?\n\n5. Could you elaborate on the computational cost and practical implementation of the \"schema distillation\" process? How expensive is it to replay schema candidates on prior trajectories, and how does this scale as the cache grows?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LQHQAD8T3a", "forum": "6skwd1QtTO", "replyto": "6skwd1QtTO", "signatures": ["ICLR.cc/2026/Conference/Submission8048/Reviewer_yo98"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8048/Reviewer_yo98"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8048/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761107251596, "cdate": 1761107251596, "tmdate": 1762926050165, "mdate": 1762926050165, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces CORRECT, a training-free framework that detects the earliest decisive error in long multi-agent trajectories by caching and reusing compact “error schemata.” A clustering step extracts representative schemas offline. At inference they are retrieved by semantic similarity and supplied to an LLM that pinpoints the responsible agent-step. Experiments on WHO&WHEN and CORRECT-Error show step-level accuracy gains up to 20 points over baselines while incurring no additional training cost."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper addresses a timely issue in the filed of MAS. The proposed idea of distilling reusable failure patterns into short templates is novel and can avoid costly re-training.\n2. The empirical evaluation demonstrates strong performance gain."}, "weaknesses": {"value": "1. My major concerns about the paper lie in the presentation, specifically many techical details are left out:\n- The fine-tuning baseline is only named. The paper never explains how the instruction-tuning dataset was built, whether the model was trained to output just the failure-step index or a reasoning trace accompanied, and whether supervised fine-tuning or RLHF was used. Hyper-parameters are missing, even from the appendix.\n- In Stage 2 of Section 4.1, the text says GPT-5 “adapts the error pattern while preserving core semantics,”. But the paper provides no prompt, no definition of “error pattern,” and no description of the source.\n- Many trajectories exceed 32k tokens, but the method relies on BERT embeddings, whose context window is far shorter. The paper does not mention how embedding is done to handle the length. \n\n2. Algorithm 1 is under-explained. The pseudo-code drives the whole framework, but the main text never walks through its lines. Key variables (e.g., $\\delta$ , $\\theta_{hot}$, cache replacement policy) and their interaction with Sec. 3 concepts are left implicit. I could not map each step to Sections 3.1/3.2 without guessing. A major rewrite is needed for clarity.\n3. The method invoke proprietary models at test time, the api cost and wall-clock time are not reported.\n4. There is limited discussion of failure cases. Where does CORRECT mis-fire? Examples of erroneous schema matches or degenerate clusters would strengthen the paper.\n5. The paper does not discuss [1], which is another concurrent work with Who&When. How the method transfers to the error recoginition dataset proposed in [1] requires further discussion.\n\n[1] Why Do Multi-Agent LLM Systems Fail?"}, "questions": {"value": "1. Regarding the cache management, what are the empirical values of $\\delta$ , $\\theta_{hot}$, and how sensitive are results to them?\n2. Have you observed cases where an irrelevant but high-similarity schema misleads the detector? How is this mitigated?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "I8hEvEIGH2", "forum": "6skwd1QtTO", "replyto": "6skwd1QtTO", "signatures": ["ICLR.cc/2026/Conference/Submission8048/Reviewer_BG9L"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8048/Reviewer_BG9L"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8048/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761938550278, "cdate": 1761938550278, "tmdate": 1762920040729, "mdate": 1762920040729, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces CORRECT, a schema-guided framework that identifies key recurrent multi-agent system (MAS) failures without requiring additional training. It also presents CORRECT-ERROR, a large-scale benchmark that models realistic error patterns for evaluating MAS reliability. Together, these tools improve the accuracy, interpretability, and scalability of MAS deployment across diverse tasks and systems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This paper presents a large-scale, human-verified benchmark specifically designed for multi-agent system (MAS) error attribution. The benchmark captures realistic and diverse error patterns observed in MAS deployments, providing a valuable resource for evaluating and comparing model robustness and interpretability. Its human validation ensures high fidelity and reliability, making it a strong contribution that can serve as a foundation for future research in this area\n\nThe authors propose a schema-guided framework for MAS error attribution that leverages a schema and schema-cache mechanism to systematically identify and interpret recurrent error patterns. The framework operates on a retrieval-augmented principle, where previously learned error schemata are reused to analyze new failures efficiently without additional training.\n\nThe paper supports its contributions through extensive experiments conducted across a wide range of tasks, models, and deployment scenarios. The empirical results demonstrate that the proposed CORRECT framework significantly outperforms existing baselines in accuracy, generalization, and computational efficiency."}, "weaknesses": {"value": "While the proposed framework demonstrates strong performance across static evaluation settings, a notable limitation is the absence of experiments in a streaming or online deployment scenario. In real-world MAS applications, systems often operate in a dynamic environment where the schema cache starts empty and must adapt incrementally as new error cases emerge. Evaluating CORRECT under such a cold-start or streaming setting would provide deeper insights into its practical robustness, adaptability, and scalability over time. Without this, it remains unclear how efficiently the framework can learn and reuse schemata in continuously evolving contexts.\n\nAnother limitation is that the framework relies on user confirmation or supervision during the cache-building process. While this human-in-the-loop component ensures higher accuracy in schema construction, it also introduces additional overhead and dependency on expert input, which may limit scalability in fully automated or large-scale deployments. Future work could explore strategies for automated or semi-supervised schema validation to reduce reliance on manual confirmation while maintaining interpretability and reliability.\n\nAlso note that the idea of using human-verified cache to improve model exists in the literature, eg, EcoAssistant."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "2Pvd7xeOZQ", "forum": "6skwd1QtTO", "replyto": "6skwd1QtTO", "signatures": ["ICLR.cc/2026/Conference/Submission8048/Reviewer_bUB3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8048/Reviewer_bUB3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8048/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979350538, "cdate": 1761979350538, "tmdate": 1762920040279, "mdate": 1762920040279, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the challenge of error recognition in MAS execution, finding the root cause of failure in a long trajectory. The paper builds upon the insight that while the specifics of the failure trajectory appear unique, they stem from recurring structurally similar patterns.\n\nWith this, the authors' propose CORRECT, a training-free framework, that builds an \"error schemata\" by offline analysis of failure trajectories, identifying the signature pattern and context of errors. During online inference, it retrieves the most relevant schemata from a cache, providing them to LLM-as-judge, enabling targeted and accurate error localization without fine-tuning.\n\nThe paper also introduced CORRECT-Error, a large-scale benchmark of annotated failure trajectories."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper proposes a technique that is initialized with offline analysis of failure trajectories, but can also update the schemata/cache online, to identify new failure modes as they occur during deployment\n- The paper shows evidence of human alignment with bootstrapped trajectories\n- Evaluation across diverse benchmarks and models, demonstrating accuracy improvements in MAS with the intervention"}, "weaknesses": {"value": "- The primary baselines are naive ICL, zero-shot LLM-as-judge and finetuning. Since the proposed approach is about context intervention through a cache, could the authors comment on prompt optimization techniques like MIPRO as a baseline?\n- The dataset is built by corrupting successful trajectories through error injection. Could the authors' discuss the effect of sampling bias by only selecting from task instances for which an existing MAS is able to successfully bootstrap a valid solution. What about domains with close to 100% failure rates?"}, "questions": {"value": "- Could the author's provide examples of schema generated by CORRECT in offline and online phases? While one of the emphasis of CORRECT is inference-time schema inference, could the authors' discuss how is the offline mode different from the application of a static human curated taxonomy like MAST?\n- Could the authors' address the impact of starting from successful trajectories, what about domains with high failure rates?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YyX8MPh8cH", "forum": "6skwd1QtTO", "replyto": "6skwd1QtTO", "signatures": ["ICLR.cc/2026/Conference/Submission8048/Reviewer_m16n"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8048/Reviewer_m16n"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8048/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762118335776, "cdate": 1762118335776, "tmdate": 1762920039785, "mdate": 1762920039785, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}