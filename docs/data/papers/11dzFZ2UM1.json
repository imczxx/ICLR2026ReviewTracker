{"id": "11dzFZ2UM1", "number": 15831, "cdate": 1758255825573, "mdate": 1759897279103, "content": {"title": "Model Already Knows the Best Noise: Bayesian Active Noise Selection via Attention  in Video Diffusion Model", "abstract": "The choice of initial noise strongly affects quality and prompt alignment in video diffusion; different seeds for the same prompt can yield drastically different results. While recent methods use externally designed priors (e.g., frequency filtering or inter-frame smoothing), they often overlook internal model signals that indicate inherently preferable seeds.\nTo address this, we propose ANSE (Active Noise Selection for Generation), a model-aware framework that selects high-quality seeds by quantifying attention-based uncertainty. At its core is BANSA (Bayesian Active Noise Selection via Attention), an acquisition function that measures entropy disagreement across multiple stochastic attention samples to estimate model confidence and consistency.\nFor efficient inference-time deployment, we introduce a Bernoulli-masked approximation of BANSA that estimates scores from a single diffusion step and a subset of informative attention layers. Experiments across diverse text-to-video backbones demonstrate improved video quality and temporal coherence with marginal inference overhead, providing a principled and generalizable approach to noise selection in video diffusion.", "tldr": "Training-free noise selection with ANSE improves video quality across diverse video diffusion backbones with minimal overhead.", "keywords": ["Video Diffusion Model", "Active Noise Selection"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/dbdc213ff2633f0c1c92c0ae7a85391c0f801b0e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents ANSE, a framework for active noise selection in video diffusion models using BANSA, an attention-based acquisition function that identifies noise seeds yielding consistent and confident generations. BANSA adapts the BALD principle to attention space with lightweight, efficient inference. Experiments across multiple text-to-video backbones show that ANSE may enhance video quality and prompt alignment with slight overhead."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "* The paper is clearly written.\n\n* The accompanying website includes excellent figures and animations, which are much appreciated.\n\n* The experiments and ablation studies are detailed and thorough."}, "weaknesses": {"value": "1. **Ensemble Size**  \n   - In Table 7, the metrics consistently improve as the ensemble size $K$ increases.  \n   - Could the authors provide results with even larger $K$ values?  \n\n2. **Denoising Steps**  \n   - What is the number of denoising steps used for each model?  \n   - It appears to be 50 based on the appendix, but this is only explicitly mentioned for the CogVideoX-5B backbone (L839).  \n\n3. **Computation Budget (NFE)**  \n   - From a neural function evaluation (NFE) perspective, the total cost is effectively $M + 50$ (or the actual number of denoising steps).  \n   - What would happen if the baseline methods were also given an equivalent $M + 50$ computation budget?  \n\n4. **Ablation on Bernoulli-Masked Attention**  \n   - Please include ablation results for the Bernoulli-masked attention mechanism, particularly analyzing the effect of the masking probability parameter $p = 0.2$.  \n\n5. **Evaluation Metrics**  \n   - Consider including additional motion-specific metrics, such as FVMD [1], to better assess the claimed improvements.  \n   - The sample videos on the website look good and visibly outperform the baseline. A human evaluation could further validate these qualitative improvements, as VBench—while comprehensive—may have limitations in capturing perceptual quality.  \n\nRef:\\\n[1] Liu, J., Qu, Y., Yan, Q., Zeng, X., Wang, L. and Liao, R., 2024. Fr'echet Video Motion Distance: A Metric for Evaluating Motion Consistency in Videos. arXiv preprint arXiv:2407.16124."}, "questions": {"value": "Please see the [Weakness] section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "T5d2vFZQZD", "forum": "11dzFZ2UM1", "replyto": "11dzFZ2UM1", "signatures": ["ICLR.cc/2026/Conference/Submission15831/Reviewer_YgYi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15831/Reviewer_YgYi"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15831/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761652906917, "cdate": 1761652906917, "tmdate": 1762926059839, "mdate": 1762926059839, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses noise selection in video diffusion models by introducing a metric called BANSA, which utilizes attention information to estimate model confidence and consistency. It also proposes a Bernoulli-masked approximation to efficiently compute scores from a single diffusion step."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "+ A novel metric is defined to guide noise selection.\n+ The paper is well-organized and presents the idea clearly."}, "weaknesses": {"value": "- Would the method remain effective when applied to a powerful base video model (e.g., WAN 2.2/2.1 14B), or when the video model has undergone post-training procedures such as RL or DPO?\n- There is a lack of visualizations showing the score distributions for different prompts and samples from different noise inputs.\n- How does the Bernoulli masking affect the score distribution? Is there a significant difference between using and not using the mask?\n- It would be helpful to show generated samples from the same prompt but with different scores, to help validate the effectiveness of the proposed metric.\n- What is the underlying reason that using this score leads to improvements in motion, composition, and artifact reduction? More insight into the mechanism would be valuable."}, "questions": {"value": "Please refer to the strengths and weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "8O3UKtuQfw", "forum": "11dzFZ2UM1", "replyto": "11dzFZ2UM1", "signatures": ["ICLR.cc/2026/Conference/Submission15831/Reviewer_KjHH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15831/Reviewer_KjHH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15831/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761801130718, "cdate": 1761801130718, "tmdate": 1762926058901, "mdate": 1762926058901, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ANSE (Active Noise Selection for Generation), an inference-time framework that improves text-to-video diffusion by selecting the initial noise seed that minimizes a new attention-based epistemic uncertainty measure, BANSA (Bayesian Active Noise Selection via Attention). This method improves video quality and temporal coherence across various T2V backbones and is approximated efficiently via Bernoulli-masked attention and layer truncation chosen by correlation analysis to keep overhead low."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The central idea of using attention-based uncertainty as an internal signal to guide noise selection is innovative. It shifts the paradigm from relying on external, often heuristic-based priors to a principled method that is aware of the model's own confidence.\n2. Through approximations (Bernoulli masking, layer truncation), authors make the consistent quality gains with a reasonable inference overhead. Demonstrates robust generalization and real-world viability."}, "weaknesses": {"value": "1. Lack of statistical confidence reporting. Improvements are modest in absolute terms; without standard deviations/CI or significance tests, it’s hard to assess robustness and effect sizes across prompts/seeds.\n2. Lack of Sensitivity Analysis for Key Hyperparameters. The method relies on several key hyperparameters, notably the Bernoulli masking probability p (set to 0.2) . The paper does not provide a sensitivity analysis for these values. It is unclear how the optimal choices were determined and how robust the method's performance is to variations in these parameters."}, "questions": {"value": "1. The paper mentions that BANSA can be applied to cross-, self-, or temporal attention. Did the authors investigate which type of attention map is most predictive of final video quality?\n2. The Classifier-Free Guidance (CFG) scale is a crucial parameter for controlling prompt alignment in diffusion models. How does the choice of noise seed, as guided by BANSA, interact with different CFG values? Is it possible that a high BANSA score could be improved by using a higher CFG scale, or does the initial noise fundamentally constrain the quality regardless of the guidance strength?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "4X8fzEBN0b", "forum": "11dzFZ2UM1", "replyto": "11dzFZ2UM1", "signatures": ["ICLR.cc/2026/Conference/Submission15831/Reviewer_CXmX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15831/Reviewer_CXmX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15831/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761824005447, "cdate": 1761824005447, "tmdate": 1762926058449, "mdate": 1762926058449, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}