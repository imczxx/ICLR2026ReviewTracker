{"id": "ETT804iVAt", "number": 4447, "cdate": 1757682305138, "mdate": 1763551100763, "content": {"title": "Momentum Steering: Activation Steering Meets Optimization", "abstract": "Activation steering has emerged as a powerful approach for controlling large language models (LLMs), with prominent methods such as ActAdd, Directional Ablation, and Angular Steering relying on difference-in-means activations from contrastive prompts across layers. These differences are typically treated as candidate feature directions, later refined into optimal steering vectors or planes. In this work, we reinterpret these candidate directions as gradients of an underlying optimization problem. Building on this perspective, we propose Momentum Steering, a momentum-based framework for activation steering in LLMs. Unlike traditional difference-in-means methods, our framework generates a richer family of candidate directions through momentum updates, enabling more expressive steering. We first introduce a non-causal variant that accumulates difference-in-means signals via momentum, producing enhanced candidate directions. We then develop a causal variant, where future layer statistics are recursively influenced by previously applied momentum directions, explicitly modeling the causal effects of interventions on downstream activations. This recursive formulation yields more stable and consistent steering dynamics. Momentum Steering is lightweight and modular, making it easily compatible with state-of-the-art steering methods. We empirically demonstrate that Momentum Steering delivers consistently stronger, more robust, and more reliable behavioral control than existing approaches across diverse LLM families and benchmarks.", "tldr": "We propose Momentum Steering, a momentum-based framework for activation steering in LLMs.", "keywords": ["activation steering", "momentum", "alignment", "behaviour control", "mechanistic interpretability", "representation engineering", "optimization"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f3f4c279b54afdfe46d6c268dbccefab3ab46472.pdf", "supplementary_material": "/attachment/e44fec6c5b22b6d1dbf9533953b9c3971686837c.zip"}, "replies": [{"content": {"summary": {"value": "The authors reframe activation steering in LLMs as an optimization problem and propose momentum-based steering that incorporates momentum from gradient-based optimization into the computation of steering vectors. Rather than using simple difference-in-means between contrastive prompts, they accumulate these differences across layers via momentum updates. The authors show that popular methods like ActAdd and Mean-AcT can be derived as (projected) gradient descent updates in their framework, then extend this framework with momentum and an Adam-based variants. Experiments on jailbreaking and toxicity mitigation tasks show improvements over baselines across multiple model families."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- reinterpreting activation steering as PGD is creative and provides a principled framework for understanding existing methods\n- consistent improvements across diverse models (Qwen, Gemma, Llama with 3b-32b params) and tasks\n- seems easy to integrate with existing steering methods without significant computational overhead\n- provides stability analysis and connects to well-established optimization literature"}, "weaknesses": {"value": "1. Poor presentation: multiple typos (e.g., \"zero k\" line 233), inconsistent notation, and unclear writing throughout\n  - switches between $x(k)$ and $x(t)$ without explanation; unclear distinction between $\\mathbf{q}$ and $\\mathbf{p}$ in sections 2.1-2.2; unexplained notation like $k=[K]$\n  - see questions for more unclarity\n2. no statistical significance shown: no error bars on experiments, making it impossible to assess significance given that results are expected to have significant variance\n3. Questionable experimental choices: randomly initialized model uses unrealistic architecture (150 layers), why not use actual trained models for validation?"}, "questions": {"value": "1. Am I correct in understanding that the calculations for the steering functions (including momentum-based updates) are only when constructing the steering vectors -- when applying the steering vectors, the calculations stay the same as in ActAdd? Or are the you also changing the calculations done during inference? \n2. Why choose Bregman divergence over other divergence functions?\n3. Can you provide intuition about how different choices of $h$ in the Bregman divergence lead to different feature maps and steering behaviors?\n4. How does this relate to matrix-based steering methods ([Postmus & Abreu, 2025](https://arxiv.org/abs/2410.16314)) or flow-based methods ([Rodríguez et al, 2024](https://arxiv.org/html/2410.23054v1))?\n5. For the randomly initialized model experiments (Appendix B):\n   - Why use such unrealistic architecture (150 layers)?\n   - Why not validate on actual trained models?\n   - Would the trends persist from initialization to final trained models?\n6. In equation 2.3, are you averaging over time? At which tokens do you extract activations and where do you apply them?\n7. What explains the inconsistent notation between $x(k)$ and $x(t)$, and between $\\mathbf{q}$ and $\\mathbf{p}$?\n8. What does $k=[K]$ mean before equations 1 and 2?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "b6je33nzgI", "forum": "ETT804iVAt", "replyto": "ETT804iVAt", "signatures": ["ICLR.cc/2026/Conference/Submission4447/Reviewer_VGaF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4447/Reviewer_VGaF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4447/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761938643375, "cdate": 1761938643375, "tmdate": 1762917370412, "mdate": 1762917370412, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents Momentum Steering, an optimization-inspired framework for activation steering in LLMs. In contrast with traditional methods, this method treats each layer independently, ignoring inter-layer dependencies and the temporal structure of representation formation. The authors formulate activation steering as a projected gradient descent (PGD) process that minimizes the Bregman divergence between activations for source and target prompts. From this optimization viewpoint, they introduce Momentum Steering, which incorporates momentum updates across layers to accumulate past feature directions\n\nTwo variants are proposed: Non-causal momentum steering, which aggregates difference-in-means statistics across layers. Causal momentum steering, which recursively updates future activations based on previous momentum directions, capturing causal dependencies.\n\nExperimental results are reported across multiple benchmarks (e.g., ADVBENCH, RealToxicityPrompts, tinyBenchmarks) and model families (Gemma2, Qwen2.5, Llama3)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Frames activation steering as a gradient-based optimization process, providing a clear theoretical foundation for a previously heuristic technique.\n\n- The introduction of momentum accumulation across layers is conceptually interesting and well-motivated.\n\n- The distinction between causal and non-causal formulations adds depth and flexibility, enabling adaptive control depending on task needs.\n\n- Tests on a broad spectrum of models (3B–14B parameters) and tasks (toxicity mitigation, jailbreaks, and general benchmarks).\n\n- Requires no retraining or fine-tuning, only modifying activation computations at inference time."}, "weaknesses": {"value": "- While Appendix D mentions a stability analysis, it lacks detailed formal proofs or explicit convergence bounds for the momentum dynamics.\n\n- Momentum accumulation, especially in causal sequential mode, increases computation during inference; efficiency metrics are not quantitatively reported.\n\n- The link between optimization theory and steering behavior, might be an overkill for a traditionally cheap-compute task.\n\n- The work focuses on quantitative results but lacks qualitative examples or visualization of how momentum steering alters model representations or outputs."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2ICJTwWLt8", "forum": "ETT804iVAt", "replyto": "ETT804iVAt", "signatures": ["ICLR.cc/2026/Conference/Submission4447/Reviewer_vAxe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4447/Reviewer_vAxe"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4447/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762043895765, "cdate": 1762043895765, "tmdate": 1762917369942, "mdate": 1762917369942, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Momentum Steering, a new framework for activation steering in LLMs. Activation steering refers to the manipulation of hidden activations at inference time (e.g., with methods like Activation Addition or Directional Ablation) to control model behavior without retraining.\n\nThe authors propose viewing traditional steering methods (based on difference-in-means activations between contrastive prompts) as instances of an optimization problem solvable via projected gradient descent ((P)GD), for which they provide a proof.\n\nBased on this insight, they incorporate momentum into the process of constructing steering vectors, enabling the accumulation of information across layers. They further generalize the idea to Adam Steering, which applies Adam-style updates to steering vectors.\n\nEmpirical results across mutliple LLMs (Qwen2.5, Llama3, Gemma2) and tasks (jailbreaking task, toxicity reduction, and general language performance) show that Momentum and Adam Steering produce stronger behavioral control, while maintaining general model performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- **Comprehensive evaluation**: The authors test across a wide variety of models and multiple tasks, which supports the generality of their claims.\n- **Empirically strong results**: Momentum Steering consistently improves behavioral control, while maintaing general language performance. Given the importance of LLM alignment problems, this seems like a significant result.\n- **Conceptual novelty**: Reducing activation steering to a gradient descent-based optimization problem, thereby allowing for the usage of momentum mechanism, is an oroginal and interesting idea."}, "weaknesses": {"value": "- **Missing citation**: Please provide a citation for the claim in line 53, as it is central to your paper: \"This design can overlook valuable structure across layers, producing unstable or underpowered feature directions, especially in deeper models or tasks requiring fine-grained control.\"\n- **Clarity of the (P)GD proof**: The proof that activation steering methods reduce to (projected) gradient descent updates should be clearer. It's a bit difficult to follow in its current state.\n\t- Notation for equations 1 and 2 is not consistent with equation in line 104: x(k, p) vs x(k)(p)\n\t- The \"Sequential Refinements\" section lacks clarity. It's not evident from the equations how Mean-AcT introduces feedback and the change in dataset notation (D^{(train)}) in comparison to line 105 is not explained.\n\t- Lines 150-152: the variable $p$ is used for prompts from different datasets, which can cause confusion. Additionally, introducing symmetric notation (e.g., x_{src} and x_{tg}) would improve readability.\n\t- Line 184: The introduction of the convex constraint set into the optimization in Eqn. 9 is non-trivial and deserves more intuition or justification.\n\t- Line 198: The hypothesis that the layer function $f(k)$ implicitly performs the projection $P_C$ is non-trivial and unproven. Since this step appears to be an important element in the reduction to activation steering, additional theoretical or empirical support would be important.\n- **Experimental baseline**: The paper should more explicitly define what the baseline is in the jailbreaking experiment. Is it standard activation steering (e.g. based on Turner et al. 2023) or the (P)GD-based approach? Direct comparisons to existing and established methods that do not rely on the optimization framing would make the empirical results more interpretable (similar to what you do in section 4.3).\n- **Minor issues and typos**\n\t- Typo in line 112 \"Meant-AcT\" --> \"Mean-AcT\"\n\t- Line 125: should read \"uses\" or \"incorporates\"\n\t- Line 363: should read \"might require significantly more time\""}, "questions": {"value": "I discuss this primarily in the weaknesses section, but the proof that activation steering methods reduce to (projected) gradient descent updates is not yet entirely convincing. Addressing the points mentioned above would help clarify this argument, particularly the assumption that the layer function implicitly performs the projection step.\n\nIn addition, the “Empirical Evidence” section could be expanded to strengthen this claim. For example, showing that the steering vectors derived from your optimization-based reduction are sufficiently similar to those obtained from existing methods such as ActAdd (e.g., via geometrical or downstream performance comparisons) would make the theoretical correspondence much more compelling."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "sc69tAr8kB", "forum": "ETT804iVAt", "replyto": "ETT804iVAt", "signatures": ["ICLR.cc/2026/Conference/Submission4447/Reviewer_xjsN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4447/Reviewer_xjsN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4447/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762808552364, "cdate": 1762808552364, "tmdate": 1762917369730, "mdate": 1762917369730, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Summary of Revision"}, "comment": {"value": "After integrating the suggestions provided from all reviewers, we summarize the revisions made to our manuscript below:\n\n1. We have updated the section containing the missing citations to include the relevant citations.\n2. We have revised Sections 2 and 3 to improve the presentation and clarity of our notation, background, and theory related to our optimization framework.\n3. We have added an additional ablation study on the role of the momentum coefficient, $\\beta$, on Gemma2-9B-Instruct and Gemma2-27B-Instruct performed under the setting of the jailbreaking experiment. The results for this are presented in Tables 5 and 8 of Section 4.4 and Appendix D, respectively, in our revised manuscript.\n4. We have revised our Stability Analysis in Appendix E (previously Appendix D in our original manuscript) such that the discrete dynamical system agrees with the choice of $h$ in Section 3. We have also included a sufficient condition for convergence along with the corresponding proofs in the revised manuscript.\n5. We have compiled a set of responses in Table 9, Appendix F, generated from Gemma2-9B-Instruct, on a prompt used from the test set of our jailbreaking experiment. The table shows the different responses the model gives when there is no steering, steering using Angular Steering without Momentum Steering, or steering using Angular Steering with Momentum Steering. \n6. We have added plots of the norms of the steering vectors (computed sequentially) from the pretrained models Llama3.2-3B-Instruct and Llama3.1-8B-Instruct in Figures 4 and 5, respectively, under Appendix G.\n7. We have conducted an additional experiment on the jailbreaking task using ActAdd instead of Angular Steering as our method of intervention during inference, and have reported the results in Table 10, Appendix H, in our revised manuscript.\n8. We have fixed the typos pointed out in the reviews and added minor revisions across the manuscript for better clarity.\n\nWe will update this summary in our next response once we have obtained additional experimental results.\n\n---"}}, "id": "N76p3rpW6b", "forum": "ETT804iVAt", "replyto": "ETT804iVAt", "signatures": ["ICLR.cc/2026/Conference/Submission4447/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4447/Authors"], "number": 15, "invitations": ["ICLR.cc/2026/Conference/Submission4447/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763556410546, "cdate": 1763556410546, "tmdate": 1763560724163, "mdate": 1763560724163, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}