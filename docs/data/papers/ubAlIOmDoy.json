{"id": "ubAlIOmDoy", "number": 25017, "cdate": 1758363210348, "mdate": 1759896738043, "content": {"title": "Finding the Thread: Context-Driven Incremental Compression for Multi-Turn Dialogue", "abstract": "Modern conversational agents condition on an ever-growing dialogue history at each turn, incurring redundant re-encoding and attention costs that grow with conversation length. To enhance the efficiency, naive truncation or summarization degrades fidelity, and existing context compressors lack mechanisms for cross-turn memory sharing or revision, causing information loss and compounding errors over long dialogues. We revisit the context compression under conversational dynamics and empirically present its fragility. To address both the efficiency and robustness problems, we introduce Context-Driven Incremental Compression (C-DIC), which treats a conversation as interleaved contextual threads and stores revisable per-thread compression states in a single, compact dialogue memory. At each turn, a lightweight retrieve → revise → write-back loop shares information across turns and corrects stale memories, stabilizing behavior over long term dialogue. A lightweight, \\emph{gradient-free} policy is proposed to dynamically manage this memory, adapting on-the-fly as conversational contexts evolve without test-time optimization.\nIn addition, we adapt truncated backpropagation-through-time (TBPTT) to our multi-turn setting, learning cross-turn contextual dependencies without full-history backpropagation.\nExtensive experiments on long-form dialogue benchmarks demonstrate superior performance and efficiency of C-DIC, supporting a scalable path to high-quality dialogue modeling.", "tldr": "", "keywords": ["multi-turn dialogue", "context compression"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/21051c71061a2f7b76250673f52b2a917289cc5b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces Context-Driven Incremental Compression (CDIC), a context compression approach. It maintains  a compressed state at each turn using a memory module performing three basic operations: retrieve, revise, and write-back. The approach selectively retrieve the context relevant to the current turn instead  of re-encoding the entire history. The module is trained with truncated BPTT. It outperforms existing baselines such as truncation, summarization, and static compression."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- CDIC is a lightweight approach that does not required updating the parameters of the base model. \n- There is an ablation that emphasizes the contribution of each component of the approach. \n- CDIC is compared with diverse baselines.. It outperforms these existing baselines and generalizes out of distribution."}, "weaknesses": {"value": "- Unlike some of the baselines, CDIC requires an additional fine-tuning \n- The main problem that the paper aims to address is processing long-context input. However, the proposed approach is not evaluated on any recent long-context benchmarks (for example LoCoMo, MemoryBank, DuLeMon, PerLTQA, LongMemEval, MemBench ...). It is not known how models augmented with CDIC behave on very long contexts. \n- The paper only evaluates using perplexity or metrics based on content matching. It i unclear whether CDIC allows the model to answer questions with exact answers (facts, math.coding, question answering)."}, "questions": {"value": "- How does the method perform on long-context benchmark compared to existing baselines?\n- Does the model generalize on datasets from other domains (for example factual QA, math, coding) or is it required to perform fine-tuning on all these domains?\n- Does CDIC affect the other capabilities of the model? Is ther catastrophic forgetting?\n- Does R-TBPTT allow to train on very long inputs? How does the required memory increase as a function of input length?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GU0RhTo9Qy", "forum": "ubAlIOmDoy", "replyto": "ubAlIOmDoy", "signatures": ["ICLR.cc/2026/Conference/Submission25017/Reviewer_QNTu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25017/Reviewer_QNTu"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25017/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761295296097, "cdate": 1761295296097, "tmdate": 1762943286487, "mdate": 1762943286487, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "To address the challenges in multi-turn dialogue, such as inefficiencies in processing full dialogue history, static compression/truncation, and poor fidelity, this study introduces the Context-Driven Incremental Compression (C-DIC) framework. This framework conceptualizes dialogue as interleaved contextual threads and maintains a compact memory that stores revisable thread-level compression states. In each dialogue turn, the memory is updated through a lightweight cycle of \"retrieval → revise → write-back\". For model training, retrieval-aware Truncated Back-propagation Through Time (TBPTT) is employed to reduce computational costs. Validation on the Multi-Session Chat (MSC) dataset and in the zero-shot setting on the REALTALK dataset demonstrates that C-DIC outperforms baseline methods in metrics such as Perplexity (PPL) and BLEU. Additionally, its latency remains stable at 3–3.5 seconds, and it is the only method capable of supporting up to 428 dialogue turns, achieving a balance between efficiency and coherence."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.Balancing Efficiency and Fidelity: The use of threaded memory and incremental compression avoids redundant full-history encoding. The retrieval mechanism focuses on the context relevant to the current dialogue, ensuring stable performance in multi-turn dialogues. While static compression leads to a 1900% increase in Perplexity (PPL), C-DIC achieves a 70% reduction in PPL.\n\n2.Innovative Cross-Turn Mechanism: The core process of \"retrieval → revise → write-back\" supports dynamic memory updates, addressing the issues of \"non-revisable\" and \"cumulative errors\" in static compression, and adapts to the dynamic evolution of dialogues.\n\n3.Efficient Training and Inference: Memory updates during inference are gradient-free, ensuring that latency does not increase with dialogue length. During training, retrieval-aware TBPTT only backpropagates gradients along effective threads, avoiding the computational burden of full-history calculations."}, "weaknesses": {"value": "1.Balancing Efficiency and Fidelity: The use of threaded memory and incremental compression avoids redundant full-history encoding. The retrieval mechanism focuses on the context relevant to the current dialogue, ensuring stable performance in multi-turn dialogues. While static compression leads to a 1900% increase in Perplexity (PPL), C-DIC achieves a 70% reduction in PPL.\n\n2.Innovative Cross-Turn Mechanism: The core process of \"retrieval → revise → write-back\" supports dynamic memory updates, addressing the issues of \"non-revisable\" and \"cumulative errors\" in static compression, and adapts to the dynamic evolution of dialogues.\n\n3.Efficient Training and Inference: Memory updates during inference are gradient-free, ensuring that latency does not increase with dialogue length. During training, retrieval-aware TBPTT only backpropagates gradients along effective threads, avoiding the computational burden of full-history calculations.\n\nWeakness:\n1.Methodology: The framework focuses on optimizing the compressor and compression tokens while keeping the response generator fixed. However, the rationale for this design choice is not thoroughly justified. The study relies on initializing the compressor with a pretrained checkpoint from ICAE (Ge et al., 2024) to support this approach, which results in a lack of comprehensive logical grounding.\n\n2.Experiments: The datasets employed are limited to two daily chitchat corpora—Multi-Session Chat (MSC) and REALTALK—without incorporating domain-specific or multilingual data, leaving the model's generalization capabilities untested. Furthermore, the study utilizes a pretrained ICAE checkpoint for initializing the compressor but does not adequately explain how this initialization adapts to multi-turn dialogue scenarios or specify the criteria for parameter tuning, which affects the reproducibility of the results.\n\n3.Conclusion: The paper does not address the inherent limitations of the C-DIC framework, such as its performance boundaries in extremely long dialogues, nor does it discuss potential future applications, resulting in a lack of a forward-looking perspective.\n\n4.Appendix: The hyperparameters, such as the retrieval threshold (τ = 0.8) and decay rate (α = 0.05), are set as fixed values without a strategy for dynamic adjustment. There is no mathematical or experimental justification provided for these settings, and the study does not clarify whether manual optimization of these hyperparameters is necessary, which undermines the scientific rigor of the design."}, "questions": {"value": "see the weakness part"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QMfQfnKfN0", "forum": "ubAlIOmDoy", "replyto": "ubAlIOmDoy", "signatures": ["ICLR.cc/2026/Conference/Submission25017/Reviewer_cWNR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25017/Reviewer_cWNR"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25017/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761786441627, "cdate": 1761786441627, "tmdate": 1762943286200, "mdate": 1762943286200, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the efficiency and coherence challenges of multi-turn dialogue by proposing Context-Driven Incremental Compression (C-DIC), which treats conversations as interleaved contextual threads and maintains a compact memory of revisable per-thread compressed states. The key contributions are: (1) demonstrating that static compression methods degrade under multi-turn dynamics with perplexity increasing approximately 1900% from single-turn to multi-turn evaluation, (2) introducing a retrieve→compress→write-back framework where a similarity-based retrieval mechanism fetches relevant thread states, a compressor produces updated states conditioned on retrieved context, and a gradient-free policy either inserts new threads or revises existing ones based on a similarity threshold, and (3) proposing retrieval-aware truncated BPTT that backpropagates gradients only through actually-retrieved memory states. Experiments on MSC and REALTALK datasets show C-DIC achieves perplexity of 8.43 (vs. 27.7 for ICAE one-shot) on MSC and 9.79 (vs. 21.4) on REALTALK, while maintaining approximately 3-3.5 second latency up to 428 turns. The method is evaluated using perplexity, BLEU, and ROUGE metrics, with ablations demonstrating the importance of incremental compression, retrieval-aware TBPTT, and memory-based context threading."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "### 1. Addresses an important practical problem with clear problem formulation\nThe paper tackles a genuine challenge in deploying conversational AI systems: managing computational costs and maintaining coherence across long multi-turn interactions. The problem formulation is well-articulated---treating dialogue as interleaved contextual threads requiring revisable memory rather than static compression---and represents a thoughtful reframing of multi-turn challenges. Figure 1 provides suggestive evidence that existing static compression methods may struggle when applied repeatedly across conversation turns, with perplexity increasing sharply after 3-4 consecutive compressions. While this uses the same metrics that limit the paper's evaluation overall, it does motivate investigating alternative approaches designed specifically for conversational dynamics. The paper clearly explains both efficiency concerns (quadratic costs from re-encoding) and coherence concerns (semantic drift over long conversations), establishing why this research direction matters for practical deployment.\n\n### 2. Demonstrates concrete efficiency gains with strong scalability \nThe efficiency results are well-measured and represent genuine practical contributions. C-DIC maintains approximately constant 3-3.5 second latency regardless of conversation length up to 428 turns, while baseline methods experience out-of-memory errors at 20-40 turns (Figure 3, Table 3). At 30 turns, C-DIC is roughly 2.4× faster than full prompting, with negligible compression overhead. The system is the only method tested that successfully handles 428-turn conversations. The ablation study (Table 2) systematically validates component importance: removing incremental compression causes significant degradation (PPL 9.4→25.5), confirming core design choices matter. Zero-shot transfer to REALTALK (trained on MSC, tested on much longer WhatsApp conversations) suggests the approach may generalize across domains and lengths. While the evaluation has limitations in validating context tracking claims, the efficiency and scalability results are concrete, reproducible, and address real deployment constraints for conversational systems."}, "weaknesses": {"value": "### 1. Evaluation does not validate claimed context tracking capabilities\nThe paper evaluates using perplexity, BLEU, and ROUGE, which measure how well the model matches human reference responses under teacher-forcing (at each turn, the model generates a response, metrics compare it to the reference, then evaluation continues with the human's actual next turn). These metrics could indirectly validate context tracking if the reference responses require retrieving and using information from distant turns. However, the paper provides no analysis demonstrating that the datasets actually demand this capability.\n\n**Missing dataset characterization**: We don't know (1) what percentage of responses require long-range context (>10 turns back) vs. local context (last 2-3 turns), (2) whether the references could be matched with generic conversational responses that don't require true thread tracking, or (3) the distribution of context dependencies across the 66-utterance (MSC) and 894-utterance (REALTALK) conversations. Without this characterization, strong metric performance could reflect either genuine context tracking or simply learning conversational patterns without the claimed thread awareness.\n\n**Teacher-forcing limitations**: The evaluation never tests whether the model's outputs remain coherent when deployed in closed-loop (where the model must respond to its own previous generations rather than human responses). This masks potential error compounding over long conversations, which is critical for validating the claimed stability across 400+ turns.\n\n**No direct measurement of core claims**: The paper claims \"thread awareness\" and \"contextual fluency\" but never directly measures whether the system retrieves correct thread states or uses planted information appropriately. The qualitative example (Figure 6) shows the model making a factual error about which food caused an injury, suggesting the system can fail at context tracking even when generating fluent responses.\n\nThe paper should either: (1) provide dataset analysis showing that references require the claimed long-range context tracking (via annotation studies quantifying context dependencies), or (2) add controlled synthetic evaluations where context requirements are explicit (e.g., needle-in-haystack tests where facts planted at turn 5 must be retrieved at turn 50, measuring retrieval precision/recall directly). Also consider LLM-as-judge evaluation and/or human preference studies.\n\n### 2. Technical contribution lacks rigor and key design choices are inadequately explored\nBeyond the evaluation issues, the paper's technical contribution is primarily system engineering (combining existing components: ICAE compressor, cosine similarity retrieval, truncated BPTT) without theoretical analysis or comprehensive empirical validation of design choices. Critical hyperparameters lack justification: threshold τ=0.8 shows high sensitivity (Table 4: τ=0.85 increases PPL to 10.1) but no principled selection method is provided; 128 compression tokens are never ablated despite being a capacity bottleneck; the replacement-based write-back policy (Equation 6) completely discards old states without comparison to alternatives like exponential moving average or gating mechanisms. The retrieval-aware TBPTT is presented as a contribution but lacks gradient flow analysis, convergence proofs, or comparison to standard fixed-window TBPTT. \n\nAdditionally, the experimental scope is limited: no statistical significance testing across multiple runs, evaluation only on Llama-2-7B without validation on modern models, REALTALK has only 10 conversations, and the related work section inadequately positions the contribution relative to memory-augmented methods (Compressive Transformers, RMT). The catastrophic failure of ICAE (incremental) at PPL 513 is used as motivation but never investigated---is this a fundamental limitation or implementation issue? While these issues are individually addressable, they collectively indicate that the work requires substantial additional development before publication."}, "questions": {"value": "1. Why was there no direct evaluation of context tracking and retrieval accuracy?\n\n2. How were critical hyperparameters selected, and have you compared alternative design choices?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "J6Yai59VWl", "forum": "ubAlIOmDoy", "replyto": "ubAlIOmDoy", "signatures": ["ICLR.cc/2026/Conference/Submission25017/Reviewer_ebdh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25017/Reviewer_ebdh"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25017/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977066838, "cdate": 1761977066838, "tmdate": 1762943285519, "mdate": 1762943285519, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenges of efficiency and fidelity in model context management during multi-turn conversations by proposing the C-DIC framework, which treats dialogues as interleaved context threads. It employs a \"retrieval-revision-rewrite\" cycle to manage modifiable compressed memory and incorporates retrieval-aware TBPTT for optimized training."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The results showed that C-DIC outperformed all metrics comprehensively, including PPL, BLEU, and ROUGE, with only 3.36 seconds required to process 428 rounds of dialogue. It also demonstrated strong zero-shot transferability. Ablation studies confirmed the necessity of each component, providing an efficient and scalable solution for long-range dialogue modeling, with notable innovation and practicality.\n2. The study validates the effectiveness of the gradient-free memory management strategy in dynamic conversations, achieving a balance between reasoning efficiency and contextual fidelity."}, "weaknesses": {"value": "1. Lack of experiments with multiple pedestal models: The main experiment was only conducted on Llama2-7B, lacking more extensive pedestal models, including experimental results from more advanced models.\n2. These experiments were mainly conducted on two daily corpus databases. Can they generalize to a wider range of dialogue data, such as multilingual data, or specific domain dialogues, such as dialogues in the medical field and debates."}, "questions": {"value": "Please refer to the weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QEJs3A6LEq", "forum": "ubAlIOmDoy", "replyto": "ubAlIOmDoy", "signatures": ["ICLR.cc/2026/Conference/Submission25017/Reviewer_DQty"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25017/Reviewer_DQty"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25017/-/Official_Review"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763649242595, "cdate": 1763649242595, "tmdate": 1763649242595, "mdate": 1763649242595, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}