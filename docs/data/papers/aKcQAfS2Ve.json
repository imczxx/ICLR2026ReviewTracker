{"id": "aKcQAfS2Ve", "number": 13192, "cdate": 1758214916259, "mdate": 1763107423174, "content": {"title": "Does MIM cheat? Exploring Semantic Invariance in Self-Supervised ViT Representations", "abstract": "In this work, we analyze patch-level embeddings and show that MIM objectives bias representations toward non-semantic cues, limiting their effectiveness in inference. To probe this effect, we introduce a model-agnostic counterfactual score that quantifies \n*semantic invariance* by comparing principal component responses to real inputs and noise, providing a novel measure to directly characterize the tradeoff between semantic information and structural noise in ViT embeddings. Building on this measure, we propose Semantic Orthogonal Projection (SOaP), a post-hoc method using simple Gram–Schmidt orthogonalization that suppresses invariant components in patch representations. Our experiments show that SOaP consistently improves performance on multiple downstream tasks across state-of-the-art MIM-based models.", "tldr": "We analyze embeddings of state-of-the-art ViTs to uncover semantically invariant features for all MIM-based models, and propose a new model agnostic projection for post-hoc denoising of representations.", "keywords": ["Self-Supervised Learning", "Representation Learning", "Computer Vision"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/8e65cd3407316ddd4bee5e7834f1d7111a5d9df4.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors demonstrate that Masked Image Modeling (MIM) objectives tend to bias learned representations toward non-semantic cues. To address this, they introduce a model-agnostic counterfactual score that quantifies semantic invariance, enabling a clearer characterization of the tradeoff between semantic content and structural noise in Vision Transformer (ViT) embeddings. Building on this insight, they propose Semantic Orthogonal Projection (SOaP), a post-hoc method that enhances performance on downstream tasks across a range of state-of-the-art MIM-based models."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* The authors conduct an in-depth analysis of structural noise in Vision Transformer (ViT) token representations across state-of-the-art Masked Image Modeling (MIM) and contrastive learning models.\n\n* Their evaluation spans a diverse set of models, enhancing the generality and robustness of their findings."}, "weaknesses": {"value": "In Section 3.2, the authors assume that the patch embedding can be approximated as a linear projection. However, they do not provide sufficient justification for the validity of this approximation, leaving its soundness in practical settings unclear."}, "questions": {"value": "* The rationale centers on using PCD to extract semantic information for guiding MIM. However, why is a relatively simple method like PCD capable of effectively guiding more sophisticated MIM models?\n\n* In Figure 1, why is structural noise observed only in MIM models, while non-MIM models appear unaffected? What underlying factors contribute to this discrepancy?\n\n* Could you clarify how to interpret Figure 3? Specifically, what are the key differences between the first and second rows?\n\n* In the experimental setup described in Section 4.2, why is the linear probe metric omitted from the evaluation? Including it could offer additional insight into representation quality."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MUgcCkhrS4", "forum": "aKcQAfS2Ve", "replyto": "aKcQAfS2Ve", "signatures": ["ICLR.cc/2026/Conference/Submission13192/Reviewer_QSBR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13192/Reviewer_QSBR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13192/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761021922247, "cdate": 1761021922247, "tmdate": 1762923887670, "mdate": 1762923887670, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "We wish to withdraw our submission, as we believe the paper requires additional refinement before publication.\n\nBest regards,\nThe authors"}}, "id": "tEUPbIYSh5", "forum": "aKcQAfS2Ve", "replyto": "aKcQAfS2Ve", "signatures": ["ICLR.cc/2026/Conference/Submission13192/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13192/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763107421970, "cdate": 1763107421970, "tmdate": 1763107421970, "mdate": 1763107421970, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper considers the representations of image patches made by Masked Image Models (MIM). \nIt describes how the representations of MIMs contain both semantic information, e.g. information about which categories the content of the image falls into, \nand non-semantic information, e.g. position of the image patch in relation to the full image. \n\nThe paper introduces a semantic invariance (SI) score, which can be used to measure how much non-semantic information is captured in certain directions of \nthe representations. It also proposes a method called Semantic Orthogonal Projection (SOaP) for supressing the non-semantic directions of the representations. \nSOaP is related to the RASA method from [1] in the sense that this paper finds non-semantic directions using PCA and removes them using Gram-Schmidt,\nwhile RASA finds the non-informative directions using a small trained model and then also removes them using Gram-Schmidt. \n\nThey run experiments on how much SOaP improves performance on the two downstream tasks salient segmentation (on 3 datasets) and \nk-nearest neighbour (kNN) classification (on 1 dataset) for six MIM trained and two non-MIM trained models. \nThey find some improvement for the segmentation task for MIM models and no real change for the kNN task. \nThey also compare using SOaP with using RASA from [1] on a single model on a single dataset for each task. They find improvement on the segmentation \ntask, but no change on the kNN classification. \n  \n  \n[1] Shashanka Venkataramanan, Valentinos Pariza, Mohammadreza Salehi, Lukas Knobel, Spyros Gidaris,\nElias Ramzi, Andrei Bursuc, and Yuki M. Asano. Franca: Nested matryoshka clustering\nfor scalable visual representation learning. arXiv preprint arXiv:2507.14137, 2025."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**S1:** Figuring out how to extract the desired properties from representations for use in downstream tasks is very relevant. \nEspecially with the large number of pre-trained models now available."}, "weaknesses": {"value": "**W1:** The mathematical part of the paper is confusing, since notation is used without being introduced and many choices are not well-motivated. \nSee questions **Q1, Q2, Q4-Q7**.\n\n\n**W2:** A lot of information is lacking with respect to the experimental setup. \nFor example: \n- It is not explained how the hyperparameters for equation 7 are chosen. \n- It does not say what $\\beta$ is used in their $F_{\\beta}$ measure. \n- There are no descriptions of the datasets used. \n- For segmentation, it says they use TokenCut (Line 362), but there is no proper description of how this method works (there are two sentences in appendix E.1 which is not referenced).   \n\n\n**W3:** The results are not convincing: Only two downstream tasks are tested and in only one of them does SOaP show any real effect. \nIn the segmentation case, it seems there is some effect (table 2) since results improve for all models which somehow include MIM. \nHowever, the size of the effect is not possible to estimate from these results, especially since there is only one \nseed per model type. Table 3 about kNN classification does not show enough change to make any conclusion. \n\n\n**W4:** The paper is very unclear in several places: Sometimes references are used with no clear reason why the reference is relevant \nto this part of the text. Captions for figures and tables are also lacking in explanations. See questions **Q3, Q8-Q10**."}, "questions": {"value": "This submission is very unclear both with respect to explaining the theoretical foundation and how one might reproduce the results. \nI therefore recommend rejection. \n\n\n**Questions:**\n\n\n**Q1:** Line 160: What is $\\mathcal{Z}$ here? Do you mean $z\\in \\mathcal{Z} \\subseteq \\mathbb{R}^D$, where $D$ is the dimension of the embeddings?\n\n\n**Q2:** Line 161: Are you saying that you use Welford's online algorithm to calculate the eigendecomposition? Welford's is an algorithm for \ncalculating the variance of an entire dataset using batches. It does not give you the eigenvectors.    \n\n\n**Q3:** Figure 3: How did you choose which components to pick? Is this related to figure 5?\nIn the bottom row for DINOv2, iBOT and MAE, it looks like there is a rough segmentation going on which is not exclusively top/bottom based.\nDo you have a comment on this? \n\n\n**Q4:** Equation 2: Should the inequality with $\\tau$ not be strict? If seems strange to say there is an \"activation\" when the projection of \nthe representation onto the eigenvector is zero. Especially when you in line 244 say that similar activation vectors for inputs should \nmean that they have similar behaviour with respect to the eigenvector. \n\n\n**Q5:** Line 192: Why not just set $\\tau = 0$ here? Why define it as a dot-product? \n\n\n**Q6:** Line 193: You have not introduced $B$. I assume $B = \\vert \\Omega\\vert$? \n\n\n**Q7:** Line 223: \"increasing the coefficient $\\theta_{\\rho}$ at the expense of the semantic coefficient $\\theta_{\\phi}$.\" \n\tWhy do you say there is a trade-off? In your equation 3, $\\theta_{\\rho}$ and $\\theta_{\\phi}$ are not linked, that is, \n\t$\\theta_{\\rho}$ can go up without $\\theta_{\\phi}$ going down. \n\tDo you mean that if $\\theta_{\\rho}$ is large compared to $\\theta_{\\phi}$ it is more difficult to pick out \n\t$\\theta_{\\phi}$ from the representation?  \n\n\n**Q8:** Line 231: You reference [1] as a source for semantic invariance, but your definition of semantic invariance seems \nto differ from the one in [1]. If you claim they are the same, could you explain how? \n\n\n**Q9:** Line 264: You reference [2] after \"Gram–Schmidt based projection\", why is this? I would guess it is because they \nalso use Gram–Schmidt in [2] to remove the non-informative directions? However, this is not clear in the text. \n\n\n**Q10:** Equation 7: How is this function related to a Fermi window? How do you choose $\\mu$ and $\\tau$ in your experiments?\nAlso, you already used $\\tau$ for your threshold in equation 2, so you should find a different name for this new hyperparameter.  \n\n\n\n\n\n**Additional Feedback (no effect on recommendation):**\n\n**F1:** Saying that MIM \"cheats\" when it puts information about position into its embeddings, I find slightly misleading, \nsince position is very important information when considering the training objective. \nAs such, I am not fond of the \"Does MIM cheat?\" part of the title.  \n\n\n**F2:** Remember to always introduce an abbreviation before you use it. \nFor example in the first line of the abstract write \"masked image modeling (MIM)\" instead of just MIM. \n\n\n**F3:** Figure 1 + 2: Please be more clear about the objective in these figures. In figure 1: Is the blue patch supposed to cover only the pyramids? \nOr the entire foreground, pyramids + sand? Does IJEPA simply not mark any pixels in either case? \nIn figure 2: Is the objective to separate foreground and background or to mark the object for classification? \nI am assuming that marking the chicks is the objective, since you mark this as correct in the figure, but please be more clear about it in the caption.\nWhen I read this, I did not know what TokenCut was. Make sure to add a reference in the caption, also to your appendix E.1.    \n\n\n**F4:** Table 2 and 4: Make sure to write in the caption or at least somewhere in the paper what you are measuring. \nFor example, what is max $F_{\\beta}$? \n\n\n\n\nTypos:\n\nLine 088: \"improved representations for downstream-cf.\", I think it should say \"downstream tasks\".\n\nLine 096: \"and are able to\" -> \"and is able to\"\n\nLine 102: \"has a extensive\" -> \"has an extensive\" \n\nLine 147: \"sheds insights to decompose\" -> \"sheds light on how to decompose\"\n\nLine 257: \"With SI score (5)\" -> \"With the SI score (5)\"\n\nLine 263: \"is then defined following Gram–Schmidt based\" -> \"is then defined following a Gram–Schmidt based\" \n\n\nReferences:\n\n\n\n[1] Bo Yuan, Danpei Zhao, and Zhenwei Shi. Learning at a glance: Towards interpretable data-limited\ncontinual semantic segmentation via semantic-invariance modelling. IEEE Transactions on Pattern\nAnalysis and Machine Intelligence, 46(12):7909–7923, 2024.\n\n[2] Shashanka Venkataramanan, Valentinos Pariza, Mohammadreza Salehi, Lukas Knobel, Spyros Gidaris,\nElias Ramzi, Andrei Bursuc, and Yuki M. Asano. Franca: Nested matryoshka clustering\nfor scalable visual representation learning. arXiv preprint arXiv:2507.14137, 2025."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "r4l9Jv2hK0", "forum": "aKcQAfS2Ve", "replyto": "aKcQAfS2Ve", "signatures": ["ICLR.cc/2026/Conference/Submission13192/Reviewer_Daow"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13192/Reviewer_Daow"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13192/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761130556382, "cdate": 1761130556382, "tmdate": 1762923887315, "mdate": 1762923887315, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the adverse effect of MIM objectives in driving ViT to learn non-semantic “structural” information. In particular, the authors (1) design a model-agnostic semantic invariance (SI) score to quantify this tradeoff and (2) propose Semantic Orthogonal Projection (SOaP), a post-hoc projector based on Gram–Schmidt with a Fermi window weighting that helps remove non-semantic information from the patch embeddings. The experiments on several ViT-based MIM models show that SOaP improves the performance in downstream tasks (TokenCut salient segmentation & kNN classification, with less improvement for the latter). The analysis serves as a step forward to quantify this important trade-off in MIM training and points out a gap in learning semantically relevant information."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The problem is very relevant to several active research areas (e.g. SSL, spurious correlations, inductive bias in OOD generalization). It is framed and motivated clearly. Subsequently, the model-agnostic, label-free SI score is derived in an intuitive and conceptually clean way. \n* The experiments show empirical performance gain and cover popular SSL families; the proposed methods are fairly straightforward and easy to implement."}, "weaknesses": {"value": "* **Oversimplifying Assumption**: The theoretical justification relies on the assumption that we can linearly decompose the embedding into semantic and structural information. However, if structural and semantic factors are nonlinearly entangled, the boundary becomes “blurry”, and suppressing top PCs could also remove useful features (see next part). For simplicity in theory, this assumption is reasonable to me, but the central claim “MIM cheats by encoding structure” would benefit from more complementary studies. \n\n* **Degradation in non-MIM models**: From Table 2, we can see that while SOaP improves the performance on saliency segmentation for MIM models. For DINO, it also degrades all the metrics by a large gap, which suggests that the method can also remove relevant semantic information about the embeddings. Also the improvements on kNN classification seem very incremental to me. \n\n* **Limited Experiments**: The evaluation covers TokenCut saliency and kNN as the main downstream tasks. The method would become more convincing if it leads to improvement on other tasks like linear probing. The authors did partially justify this in the Limitations section that many tasks require more than raw embeddings, but the potential existence of confounders limits the generalizability of this work. Would a preliminary investigation into confounding be possible?"}, "questions": {"value": "Most questions are raised in the Weakness section. Additionally, \n\n1. The non-semantic distribution is a specific type of synthetic data (detailed in the appendix). Have you tried other counterfactual designs? \n\n2. How are the hyperparameters selected for the Fermi window? Are they purely empirical or do we have some heuristics? \n\n3. Figure D.2 should be labeled more clearly. \n\nI am happy to raise my score if the above concerns are addressed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "o1DOqV5mH0", "forum": "aKcQAfS2Ve", "replyto": "aKcQAfS2Ve", "signatures": ["ICLR.cc/2026/Conference/Submission13192/Reviewer_VW5d"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13192/Reviewer_VW5d"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13192/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761893498426, "cdate": 1761893498426, "tmdate": 1762923887004, "mdate": 1762923887004, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new measure of structural noise (a generalisation of positional noise) in ViTs and uses it to design a training-free post-hoc method to non-informative content from patch embeddings. The authors begin by observing that, as reported in previous studies, MIMs encode positional information, which hinders their performance on downstream tasks. Assuming that patch embeddings can be linearly decomposed into positional and semantic components, they perform a PCA on a set of patch embeddings and compute the (binary) activations one would obtain by multiplying the patch embeddings by the previously obtained PCs. After observing that spatial patterns emerged in MIMs (but not in other ViTs) when averaging these activations across images, the authors hypothesized that PCs representing structural information should be similarly activated in semantic and non-semantic images. They measured the similarity between activation distributions obtained from a semantically meaningful image and one devoid of semantic content (e.g., white noise) and used the obtained score to attribute a higher weight to non-semantic components and remove them from the patch embeddings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is clear, easy to follow, and well-structured.\n- I like the idea of a training-free post hoc method to remove structural noise from patch embeddings. It is simple, elegant, and seems to perform well.\n- SOaP appears straightforward to apply and could be beneficial for any practitioner using ViT embeddings in downstream tasks. I could definitely see myself using it in my research.\n- SOaP outperforms existing methods (RASA) and generalises well to various ViT models and datasets."}, "weaknesses": {"value": "While I like the overall idea of the paper, my main concern is that some design choices seem unnecessarily complex, and their need is not entirely justified in the paper (see questions 1-4). For example, if a generalisation of positional noise is required, did the authors identify other types of non-positional structural noise?  Yes, SOaP outperformed RASA, but how can we be sure that it is because RASA only captures positional noise? Similarly in 3.3, I didn't understand why specifically choosing Dice-Sørensen until I read appendix C and I am still not sure why we need Fermi window at all for 3.4 as I didn't see any results showing that SOaP didn't work well using $s_d$ directly.\n\nOther comments:\n- In 3.1, the mathematical notation in 3.1 could be improved. There are some inconsistencies between upper and underscript $b$ (see minor comments).\n- Figure 5 and D2 could be improved (see minor comments)\n- There are a few stray typos (see minor comments)"}, "questions": {"value": "1. I understand that positional noise is a generalisation of structural noise, but could the authors explain why it is needed? Can we definitively attribute the better performances of SOaP over RASA are imputable to this generalisation? Did the authors observe other types of structural noise in MIMs? If so, could they describe them?\n2. Could the authors put the part about Dice-Sørensen metric penalisation of uncertainty from App. C in 3.3? It was quite frustrating to have a justification for this so late in the paper. Also, in which case would there be such uncertainty in the current setup?\n3. Could the authors provide the results obtained by SOaP without Fermi window (e.g., using $s_d$ instead of $w_d$)? If the results are worse, it would justify the need for a more complex strategy. However, depending on how well that version of SOaP performs compared to RASA, it may invalidate the theory that RASA is underperforming because it only takes into account positional noise. \n4. In 3.1., why did the authors choose $\\nu = 0$ ? Was it because this led to better results? Setting $\\nu = 0$ implies that we have $\\tau=0$, correct? If so, and if $\\nu \\neq 0$ leads to poor results, why not directly use $\\tau = 0$ instead of doing an additional inner product? It would be great to have these results in the appendix for completeness.\n5. What is the impact of the number of samples $z$ used to compute the covariance matrix? Did the authors observe important changes in SOaP performances when varying this?\n6. In C.1., the authors emphasise that they compute the norms and inner products of $s_d$ over the support set. How is that implemented in practice?\n\nMinor comments\n=============\n- in 3.1 the authors used $z^{(b)}$ but $x_b$. This inconsistency hampers the reading, as one may think that these two $b$ indicate different things. I would suggest replacing $x_b$ by $x^{(b)}$ and changing $x^c \\sim \\mathcal{X}^c$ to $\\tilde{x} \\sim \\tilde{\\mathcal{X}}$ in Eq. 4 to make the notation more consistent.\n- l.85 representaitons should be representations\n- l. 246 $Q_{d,n}$ and  $Q_{d,n}$ should be  $P_{d,n}$ and  $Q_{d,n}$\n- Fig. 5 is conmfusing because 5(a) lacks an x axis. Furthermore, these are not continuous data and they would be better represented by point plots.\n- Could the authors provide a legend for the 2 y-axis and the x-axis of Fig. D2?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ys7kRh0vfU", "forum": "aKcQAfS2Ve", "replyto": "aKcQAfS2Ve", "signatures": ["ICLR.cc/2026/Conference/Submission13192/Reviewer_Hkga"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13192/Reviewer_Hkga"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13192/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761911381576, "cdate": 1761911381576, "tmdate": 1762923886662, "mdate": 1762923886662, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}