{"id": "fu0NN8GRQ7", "number": 13034, "cdate": 1758212884339, "mdate": 1759897469788, "content": {"title": "VAE-CycleGAN: Variational Latent Representation for Unpaired Image-to-Image Translation", "abstract": "Image-to-image translation plays a central role in computer vision, enabling applications such as style transfer, domain adaptation, and image enhancement. While recent advances have achieved strong paired translation results, learning mappings in unpaired settings remains challenging. In this work, we present a systematic comparison of autoencoder and variational autoencoder (VAE) variants for unpaired image-to-image translation, using paired data solely as a reference baseline. To capture distributional uncertainty, we introduce VAE-CycleGAN, a unified probabilistic framework that integrates variational inference into the CycleGAN architecture. Our method combines adversarial training and cycle-consistency with a VAE’s probabilistic latent space, allowing the model to approximate the true posterior distribution. Further, the architecture achieves a 256x spatial compression, efficiently compressing the input into a compact latent representation. Empirical results across the satellite-to-map benchmark dataset demonstrate that VAE-CycleGAN generates high-quality translated images (FID: 69.25, KID: 0.0378) and achieves superior reconstruction fidelity (MSE: 0.0011, PSNR: 29.67 dB, SSIM: 0.7804) comparable to state-of-the-art deterministic approaches without hyperparameter tuning.", "tldr": "We review autoencoder and variational autoencoder (VAE) variants for unpaired image-to-image translation and introduce VAE-CycleGAN to sample the posterior distribution.", "keywords": ["GAN", "cycleGAN", "autoencoder", "variational autoencoder", "VAE", "unpaired data", "cycle consistency", "adversarial", "translation", "reconstruction", "perception", "distortion", "satellite", "maps", "aerial", "review"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/46cc93ffdf19e7278b8e0d7e3757dbbafd579eff.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper conducts a comparison of variational and adversarial approaches to perform image translation via cycle consistency. In addition, VAE-CycleGAN is proposed, which is a hybrid VAE-GAN model that combines variational and adversarial objectives for unpaired image translation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "* It is refreshing to see a GAN/VAE paper in the era of diffusion models! The paper offers a different perspective on variational cycle consistency.\n* Theoretical justification."}, "weaknesses": {"value": "* Introduction is very short and is not entirely convincing and motivating regarding the problem the paper tackles. It also misses a lot of recent work on generative modeling and ignores the diffusion models literature.\n* Figure 1: should provide a short description of the pipeline, not just “VAE-CycleGAN”.\n* The qualitative results are not entirely convincing, and the visual fidelity does not seem high.\n* Quantitatively, it seems that the proposed VAE-CycleGAN is outperformed by the autoencoder variants, even on generative metrics like FID. In that case, what is the significance of the proposed model? What is its advantage and why would one choose to use it?\n* Section 5 is poorly written and hard to understand.\n* Only one dataset.\n* Overall, the manuscript reads like a “technical project report”. It is not entirely clear what the contribution is.\n* Missing related work:\n\n[1] [Jha, Ananya Harsh, et al. \"Disentangling factors of variation with cycle-consistent variational auto-encoders.\" Proceedings of the European conference on computer vision (ECCV). 2018.](https://arxiv.org/abs/1804.10469)\n\n[2] [Kim, Beomsu, et al. \"Unpaired Image-to-Image Translation via Neural Schrödinger Bridge.\" The Twelfth International Conference on Learning Representations.](https://openreview.net/forum?id=uQBW7ELXfO)\n\n[3] [Zhao, Min, et al. \"Egsde: Unpaired image-to-image translation via energy-guided stochastic differential equations.\" Advances in Neural Information Processing Systems 35 (2022): 3609-3623.](https://arxiv.org/abs/2207.06635)\n\n[4] [Sasaki, Hiroshi, Chris G. Willcocks, and Toby P. Breckon. \"Unit-ddpm: Unpaired image translation with denoising diffusion probabilistic models.\" arXiv preprint arXiv:2104.05358 (2021).](https://arxiv.org/abs/2104.05358)"}, "questions": {"value": "* What is the role of $\\mathcal{L}_{\\text{identity}}$? It seems very counter-intuitive. Has it been ablated?\n* Stability: how stable is the training of the model? How prone is it to mode collapse?\n* Open-source code and reproducibility: is it the authors’ intention to publish an open-source code?\n* What is the role of this kind of model compared to recent diffusion models? Why would one choose this type of model instead of a diffusion model? I would like the authors to clarify their contribution with regard to the missing related work I mentioned above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RfTPEP6WT0", "forum": "fu0NN8GRQ7", "replyto": "fu0NN8GRQ7", "signatures": ["ICLR.cc/2026/Conference/Submission13034/Reviewer_WRrf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13034/Reviewer_WRrf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13034/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760988225445, "cdate": 1760988225445, "tmdate": 1762923768455, "mdate": 1762923768455, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposed VAE-CycleGAN for unpaired image-to-image translation. It combines VAE and cyclegan architecture to estimate posterior distribution for unpaired image-to-image translation task, which is a classical task for image generation. It evaluates various Autoencoder and VAE variants on satellite-to-image task. No diffusion-based methods are evaluated and compared."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper provides a systematic and comprehensive comparison of different model variants (AE, VAE, AE-GAN, VAE-GAN, VAE-CycleGAN, and so on).\n\n- Empirical results across the satellite-to-map benchmark show that VAE-CycleGAN generates high-quality translated images."}, "weaknesses": {"value": "- missing comparison with SOTA. as diffusion models are current mainstream generative models and show unprecedent performance on image-to-image translation, why not compare with some diffusion-bsed methods? Are there any advantages over diffusion-based methods, such as Flux-Context and Qwen-ImageEdit? Motivations are needed to be further clarified.\n\n\n- Insufficient evalution. this work proposeds an unpaired image-to-image translation method, but only perform evaluation on satellite to image task. I would suggest evaluating on more tasks (such as those in cyclegan paper) to justify the effectiveness of proposed method. The current experimental settings are not sufficicient to support the claim for unpaired image-to-image translation.\n\n\n- writing can be improved. for example, the introduciton is too short, making it hard for readers to quickly understand. More insights and analysis are prefered in method section.\n\n- As training process of GAN is usually unstable, how important of hyperparameter tuning in the proposed method?"}, "questions": {"value": "see above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Xyw4lRabsY", "forum": "fu0NN8GRQ7", "replyto": "fu0NN8GRQ7", "signatures": ["ICLR.cc/2026/Conference/Submission13034/Reviewer_SgCj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13034/Reviewer_SgCj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13034/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761298784164, "cdate": 1761298784164, "tmdate": 1762923768162, "mdate": 1762923768162, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper considers the problem that existing deterministic models (such as CycleGAN) cannot handle ill-posed or multimodal tasks, and developed VAE-CycleGAN."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Integration of VAE into cycleGAN is technically solid;\n2. Several analyses and visualization results are provided;\n3. This paper conducts a comprehensive ablation study on 10 different AE and VAE variants."}, "weaknesses": {"value": "1. Following the related work in the paper, integration of VAE with GAN helps to improve the generation quality. As a result, it might be straightforwad idea to introduce VAE into CycleGAN for improvement, which is the main technical contribution of the work. Therefore, the contribution and novelty of the work might not be sufficient for acceptance.\n2. The experiments are performed on a single dataset (satellite to map), while most works also evaluate translation capacities on other datasets or tasks. Thus, the experimental evaluaiton is not sufficient.\n3. The comparison methods are limited. For another, it seems that the proposed method does not achieve the superior performance on all the metrices, could the authors provide the corresponding explanation?\n4. The organization of the work can be further improved. The Introduciton does not analyze the motivations of the work in detail.\n5. Some statements are not clear,"}, "questions": {"value": "Refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "F5zIB2Lqin", "forum": "fu0NN8GRQ7", "replyto": "fu0NN8GRQ7", "signatures": ["ICLR.cc/2026/Conference/Submission13034/Reviewer_CgmW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13034/Reviewer_CgmW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13034/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993857952, "cdate": 1761993857952, "tmdate": 1762923767702, "mdate": 1762923767702, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper combines the VAE, GAN and cycle consistency ideas to create a VAE-Cycle-GAN. As such, the ideas are similar to MUNIT/UNIT, and various other works that featured thereafter (e.g. VQ-VAE). \n\nThe general idea is to combine the best qualities of the VAE (latent space meaningfulness) with GANs (crisp samples), together with cycle consistency (for unpaired data). In that sense the paper succeeds in showing the effectiveness of the model. \n\nResults are shown for standard metrics (e.g. LPIPS, FID, SSIM) to show performance on standard datasets (CityScapes and Horse-Zebra/Monet, etc.) for this type of work."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "In nearly every setting, the work shows improved results over AE/VAE/GAN/CycleGAN settings. The model is able to show crispness attributable to a GAN and keeps the latent space qualities of the VAE. \n\nThe narrative generally makes sense."}, "weaknesses": {"value": "- It is very unfortunate that I say this, but the work reads more like a recipe than an advancement. That is to say, novelty is quite limited. It might have been different if it were 2017-18. \n- I am generally in agreement with the points in the paper otherwise."}, "questions": {"value": "Have the authors considered attempting this on more modern architectures (e.g. diffusion models)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "2jhFc8Kw3f", "forum": "fu0NN8GRQ7", "replyto": "fu0NN8GRQ7", "signatures": ["ICLR.cc/2026/Conference/Submission13034/Reviewer_muvi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13034/Reviewer_muvi"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13034/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762215121146, "cdate": 1762215121146, "tmdate": 1762923767384, "mdate": 1762923767384, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}