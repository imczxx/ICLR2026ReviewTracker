{"id": "GN9otzf5o6", "number": 11042, "cdate": 1758187636163, "mdate": 1763727925205, "content": {"title": "Inlier-Centric Post-Training Quantization for Object Detection Models", "abstract": "Object detection is pivotal in robotics, but its immense computational demands make the models slow and power-hungry, underscoring the need for quantization. However, when the quantization is applied in practice, cluttered backgrounds and irregular object morphologies cause redundant activations (or anomalies) that inflate precision requirements and waste bit capacity, hindering the preservation of informative features. Moreover, without a clear criterion for defining such anomalies, attempts to exclude or mitigate them often distort useful features. To address this problem, we present InlierQ, an inlier-centric post-training quantization approach that establishes a general criterion to differentiate anomalies from informative inliers. Specifically, InlierQ computes gradient-aware volume saliency scores, classifies each volume as an inlier or outlier, and fits a posterior distribution over these scores using the Expectation–Maximization (EM) algorithm. This design effectively suppresses the influence of outliers while preserving informative inlier features. InlierQ is a label-free, drop-in method and uses only 64 samples for calibration. Experiments on the COCO and nuScenes benchmarks demonstrate consistent reductions in quantization errors across camera-based (2D and 3D) and LiDAR-based (3D) object detection.", "tldr": "Estimation of Inlier set for Post-Training Quantization of Object Detection Models", "keywords": ["Quantization", "Object Detection", "Efficiency"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a48a035b6d15eb0272d7bafb09c9b0e5ec4d6c18.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes InlierQ, a post-training quantization (PTQ) method tailored for object detection models. The approach introduces a saliency-driven inlier/anomaly decomposition to prioritize quantization precision for task-relevant activations while suppressing noisy or outlier features. InlierQ uses a gradient-based volume saliency score, fits an EM-based posterior over the score, and uses this to define inlier sets per layer. Empirical results on COCO and nuScenes benchmarks for 2D and 3D detection show that InlierQ offers modest but consistent reductions in quantization errors and improved accuracy over BRECQ and LiDAR-PTQ, especially at low bit-widths."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The central insight—distinguishing inlier from anomaly activations using a saliency score—addresses a notable gap in previous PTQ approaches that treat all activations equally. The probabilistic EM-based classification is straightforward yet effectively leverages gradient information.\n2. Experiments span both 2D (COCO) and 3D (nuScenes) detection tasks with multiple modalities (camera and LiDAR), covering several state-of-the-art detection architectures. Results in Table 1 show consistent improvements of up to 2 mAP over BRECQ on challenging low-bit settings.\n3. The derivation connecting the Hessian of the custom loss function to the Fisher Information Matrix provides a solid theoretical grounding."}, "weaknesses": {"value": "1. A key ablation study is missing. I would like to see the performance of the quantization loss directly weighted by the saliency map.\n2. In equation 7, the H is the k-th largest heatmap value. I cannot get the meaning of the $k$. The whole proof has no $k$ in it, then how is equation 7 equivalent to the FIM? The effect of $k$ should also be evaluated by ablation study."}, "questions": {"value": "See weakness 2."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mYxRBYHGwM", "forum": "GN9otzf5o6", "replyto": "GN9otzf5o6", "signatures": ["ICLR.cc/2026/Conference/Submission11042/Reviewer_N4RF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11042/Reviewer_N4RF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11042/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761742098175, "cdate": 1761742098175, "tmdate": 1762922222213, "mdate": 1762922222213, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "InlierQ introduces an inlier centric PTQ framework that computes gradient aware volume saliency, classifies activations into inliers and outliers with EM, and concentrates quantization on the inlier subspace. It is label free, needs only 64 calibration samples, and consistently cuts quantization error while preserving detection accuracy on COCO and nuScenes for both camera and LiDAR detectors."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Conceptually novel with clear theoretical grounding, using an inlier-centric optimization that allocates bit precision to task-relevant activations.\n2. Strong engineering practicality, since it is label-free and training-free, and as a plug-in PTQ module it needs only 64 calibration samples.\n3. Broad applicability across modalities and architectures, covering camera-based 2D detection, camera-based 3D detection, and LiDAR-based 3D detection."}, "weaknesses": {"value": "1. Gains are limited at higher bits. Under W8A8 the performance is close to full precision or baseline PTQ, so the advantage is less pronounced.\n2. Sensitivity to hyperparameters and unresolved robustness questions. The threshold τ controls the inlier ratio and the final accuracy, which may require retuning across datasets and detection heads.\n3. Modest improvement on 2D detection tasks. Ablations indicate that Inlier and Anomaly Sets are less separable in 2D, which reduces the benefit."}, "questions": {"value": "Please address my concerns in Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "0vHJjH5LbP", "forum": "GN9otzf5o6", "replyto": "GN9otzf5o6", "signatures": ["ICLR.cc/2026/Conference/Submission11042/Reviewer_gEWM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11042/Reviewer_gEWM"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11042/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761826055433, "cdate": 1761826055433, "tmdate": 1762922221179, "mdate": 1762922221179, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes InlierQ, a post-training quantization approach that separates activations into inliers and anomalies using a “volume saliency score.” The authors claim that existing quantization methods treat all activations uniformly, thus failing to account for this distinction.  The idea of this paper is to allocate quantization bit capacity to informative activations (inliers) while suppressing noisy or anomalous ones. Experiments on COCO (2D detection) and nuScenes (3D detection) show consistent but moderate performance improvements."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The method is clearly described with equations and an algorithmic flow (Algorithm 1), making the paper easy to follow and reproduce.\n- The results cover both 2D and 3D object detection models (COCO, nuScenes), showing robustness under different modalities and architectures.\n- The authors identify that quantization error can be dominated by high-magnitude anomalies or uninformative background activations, which is indeed an important real-world problem for low-bit quantization in detection models. In practice, InlierQ can be applied as a drop-in PTQ refinement module without retraining."}, "weaknesses": {"value": "- The claim that existing quantization approaches treat all activations uniformly is inaccurate. A substantial body of prior work has explicitly or implicitly modelled activation importance. Although the authors mention outlier-suppression methods such as SmoothQuant, QDrop, and SVDQuant in Related Work, the distinction they claim is that these works only relax amplitudes while their method decomposes activations into inliers and anomalies.\n\nHowever, many existing PTQ methods already model activation importance and distribution heterogeneity through gradient-weighted or low-rank mechanisms (e.g., BRECQ, Adaround, SVDQuant). Thus, I think the proposed “inlier decomposition” represents a rephrase of known ideas rather than a novel quantization paradigm.\n\n- The EM-based decomposition into “inliers” and “anomalies” in the Method Section is heuristic and lacks theoretical justification. Thus, it does not introduce a new optimization or probabilistic framework beyond existing adaptive scaling methods.\n\n- The improvements (mAP on COCO / nuScenes) are modest and within the range of normal variance. Thus, it is unclear whether the improvement arises from the “inlier” modelling or simply from additional regularization during calibration. No ablation on this factor is performed.\n\n- While some baselines (SmoothQuant, QDrop) are mentioned in related work, they are not included in experiments. The claim of superiority over “outlier suppression” is not directly supported. \n\n- It is unclear how InlierQ performs under extremely low bitwidth (e.g., 2–3 bits) when compared to adaptive rounding or Hessian-based PTQ."}, "questions": {"value": "- Is the inlier detection performed per-layer, per-channel, or per-sample?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "abdYusn5qM", "forum": "GN9otzf5o6", "replyto": "GN9otzf5o6", "signatures": ["ICLR.cc/2026/Conference/Submission11042/Reviewer_pWqE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11042/Reviewer_pWqE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11042/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996217384, "cdate": 1761996217384, "tmdate": 1762922220435, "mdate": 1762922220435, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "1. Motivation: Quantization is a crucial technique for model compression. Existing quantization methods treat all activations uniformly, but in object detection tasks, background activations (task-irrelevant activations) are both numerous and can exhibit anomalously high values. This uniform treatment leads to substantial waste of bit precision, especially under low-bit quantization settings.\n\n2. Method: The authors propose Inlier-Centric Quantization (InlierQ). First, they compute volume saliency scores based on gradients and then use a Gaussian Mixture Model (GMM)-based posterior probability to partition the feature space into inlier and outlier regions. Quantization optimization is applied exclusively to the inlier region. To further emphasize task-relevant features, the authors design a top-K heatmap-based loss, which concentrates the Hessian computation on the most discriminative channels.\n\n3. Experiments: Experimental results demonstrate that InlierQ achieves superior performance in both 2D and 3D object detection quantization tasks, particularly under low-bit settings."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is presented fairly clearly.\n\n2. The motivation is well-articulated, and the proposed InlierQ method is reasonably designed."}, "weaknesses": {"value": "1. In Equation (7), is the supervision applied to the top-$K$ entries for each channel of the heatmap? If so, the summation indices over $K$ and $C$ might be reversed in the equation.\n\n2. Equation (12) is described as “explicitly discards anomalous activations and focuses only on the curvature of inlier distributions.” Does this imply that in Equation (6), $\\lambda_I = 1$ and $\\lambda_O = 0$? If so, by directly discarding background activations and focusing only on high-gradient regions, could the quantization range be overly compressed? Might this lead to an increase in false positive detections in the quantized model? The authors should ideally provide experimental results on precision to support this claim.\n\n3. In the experimental setup, the authors do not specify the backbones used. Referring to experiments in BRECQ and AQD, it is recommended that the method be evaluated on additional detection algorithms (e.g., RetinaNet) and more backbones (e.g., MobileNetV2) to demonstrate its generality."}, "questions": {"value": "As shown in Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pIUVmbXVNU", "forum": "GN9otzf5o6", "replyto": "GN9otzf5o6", "signatures": ["ICLR.cc/2026/Conference/Submission11042/Reviewer_t1mq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11042/Reviewer_t1mq"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11042/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762058002587, "cdate": 1762058002587, "tmdate": 1762922219389, "mdate": 1762922219389, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}