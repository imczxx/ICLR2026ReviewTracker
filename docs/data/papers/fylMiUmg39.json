{"id": "fylMiUmg39", "number": 6143, "cdate": 1757954424440, "mdate": 1759897933234, "content": {"title": "Towards Quantifying Long-Range Interactions in Graph Machine Learning: a Large Graph Dataset and a Measurement", "abstract": "Long-range dependencies are critical for effective graph representation learning, yet most existing datasets focus on small graphs tailored to inductive tasks, offering limited insight into long-range interactions. Current evaluations primarily compare models employing global attention (e.g., graph transformers) with those using local neighborhood aggregation (e.g., message-passing neural networks) without a direct measurement of long-range dependency. In this work, we introduce $\\texttt{City-Networks}$, a novel large-scale transductive learning dataset derived from real-world city road networks. This dataset features graphs with over $10^5$ nodes and significantly larger diameters than those in existing benchmarks, naturally embodying long-range information. We annotate the graphs based on local node eccentricities, ensuring that the classification task inherently requires information from distant nodes. Furthermore, we propose a model-agnostic measurement based on the Jacobians of neighbors from distant hops, offering a principled quantification of long-range dependencies. Finally, we provide theoretical justifications for both our dataset design and the proposed measurement—particularly by focusing on over-smoothing and influence score dilution—which establishes a robust foundation for further exploration of long-range interactions in graph neural networks.", "tldr": "We introduce a large-scale transductive learning dataset for testing long-range dependencies in GNNs, and propose a measurement with theoretical justifications.", "keywords": ["Graph Neural Networks", "Long-range dependency"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/519cca5a0eec83c4f50e292f23816bf84a8a967f.pdf", "supplementary_material": "/attachment/bc9e8de6e34b0c7b451a6fe386776a2629babd1f.zip"}, "replies": [{"content": {"summary": {"value": "The paper suggests a new graph dataset that is clearly based long-range dependencies. The graphs are based on city road networks of four major cities with the target to compute the furthest distance one can travel passing 16 junctions. In addition, they provide a measurement that computes the influence of far-away nodes, highlighting that indeed the constructed graphs contain long-range dependencies."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The paper addresses an important open problem in graph learning as currently good benchmarks for long-range dependencies are missing even though we know (or rather assume) that long-range dependencies exist in many real-world tasks. The construction of the dataset is very clear and the provided metric improves upon the main existing alternative (Bamberger et al 2025) in terms of speed and possibly accuracy. The theoretical justification is non-trivial and makes a sound impression. The paper is well-written and easy to follow."}, "weaknesses": {"value": "Not exactly strong weaknesses, but rather points that I would have liked:\n- a more detailed comparison to the metric by Bamberger et al which I did expect to be mentioned in the introduction as well (e.g. in 107 I did expect that reference)\n- a more concrete statement in 125ff that the appendix contains the exact list of features that made it into the dataset. The description in the main paper is a little to vague here for my personal taste.\n- the conclusion states that LRGB's claim for long-range is solely based on the performance gap while the paper also talks about larger (even though not large) graphs and larger diameter."}, "questions": {"value": "see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6djsSFtvjM", "forum": "fylMiUmg39", "replyto": "fylMiUmg39", "signatures": ["ICLR.cc/2026/Conference/Submission6143/Reviewer_NW7j"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6143/Reviewer_NW7j"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6143/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761137069919, "cdate": 1761137069919, "tmdate": 1762918497889, "mdate": 1762918497889, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes a real-world, attributed, transductive benchmark consisting of four city networks, where the task is to classify each junction’s \"urban accessibility\", defined via a local eccentricity measure with radius 16. This, they argue, creates non-trivial long-range task dependencies. They also explore other radii values: smaller ones make the task too easy, while larger ones suffer from uninformativeness of the graph structure. They compare several network metrics with existing graph datasets and show that their city networks have larger diameters but are sparser and more grid-like; this mitigates over-smoothing and makes them better suited for benchmarking long ranges. They benchmark both GNNs and graph transformers and find that, on their dataset, performance consistently improves with depth, whereas on common benchmarks it typically plateaus or drops. Finally, they introduce a measure of long-range dependency that examines the layer-wise and cumulative influence of distant nodes on predictions. On their dataset, this influence is stronger and decays much more slowly than on the others."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper introduces a transductive benchmark built from real road networks, and moves beyond the small citation-like graphs that dominate current GNN evaluations of long range tasks.\n- On their benchmark, all models improve with depth, which is not the case on most standard datasets, and is thus a good indicator that the task needs long-range interactions. They furthermore support it with theory on over-smoothing, showing why this is possible on this kind of structure.\n- Road networks are an important application area of graph learning, so a benchmark based on them is very welcome."}, "weaknesses": {"value": "1. I am not fully convinced by the benefits of the proposed long-range influence metric. It does not seem strictly model-agnostic, since the influence values still depend on the trained parameters and even change across models (cf. Table 2). It mostly answers \"did this model use long-range information?\" rather than \"is this dataset inherently long-range?\"\n2. I think the limitation of this metric on dense graphs is too important to be buried in the appendix; it should be brought into the main text and discussed more lengthily and explicitly.\n3. While it is a good point to test graph transformers on large graphs for scalability, I am not sure this setting is the most revealing for getting insights. I.e. failure cases on smaller graphs are often more informative because there are fewer confounding factors. This benchmark awkwardly sits between being realistic and being revealing.\n4. The defined task is not necessarily informing about the accessibility of a city area. For instance, in practice longer and faster highways can make areas more accessible and not less. The task is still a synthetic one defined on top of a real graph structure.\n5. Fixing the ground-truth radius at 16 and mostly benchmarking models up to that depth is not entirely fair. The other tasks can make models suffer from over-smoothing from having more layers than required. Apart from a single point in Fig. 8, I would like to see more results with deeper models than the target radius."}, "questions": {"value": "1. It would help to see how the influence measurement behaves on synthetic long-range tasks (1). In a setting without real-world noise and with fully controlled dependencies, does the influence become more stable across models, or do we still observe the same variability?\n2. The paper states that \"graphs with long-range dependencies are expected to have higher proportional influence between more distant nodes\", but this assumes a monotone growth of influence with distance. In practice a task could depend on radius 0 and on exactly radius R, and your global metric would average it out. Can this happen for your task, and could models overfit to intermediate radii in a way that even distorts the per-hop measurement?\n3. How does the theoretical argument about sparsity and slower over-smoothing relate to phenomena like the Braess paradox, where removing edges can increase leading eigenvalues, and to empirical findings that sparsity can reduce measured over-smoothing even when the leading eigenvalue grows (2)?\n\n(1) GLoRa: A Benchmark to Evaluate the Ability to Learn Long-Range Dependencies in Graphs. Dongzhuoran Zhou et al., ICLR 2025.\n\n(2) Spectral Graph Pruning Against Over-Squashing and Over-Smoothing. Adarsh Jamadandi et al., NeurIPS 2024."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "tSuTNf2f3G", "forum": "fylMiUmg39", "replyto": "fylMiUmg39", "signatures": ["ICLR.cc/2026/Conference/Submission6143/Reviewer_e2fb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6143/Reviewer_e2fb"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6143/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761908378403, "cdate": 1761908378403, "tmdate": 1762918497494, "mdate": 1762918497494, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces City-Networks, a new benchmark dataset designed to evaluate long-range dependency handling in graph learning models. It consists of large real-world road networks (100k–569k nodes) from four global cities and labels nodes by computing local eccentricity over large hop distances (k=16 layers). The task is transductive node classification; models must incorporate information from far-away neighborhoods to succeed.\n\nThe authors also propose a model-agnostic Jacobian-based influence measure that quantifies how much distant nodes contribute to predictions. They show deeper GNNs and graph transformers consistently improve on these datasets and provide theoretical justification linking dataset topology to reduced over-smoothing and emphasizing influence dilution in grid-like graphs."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. **Novel Benchmark Contribution**: Introduces a real-world long-range benchmark on large graphs.\n\n2. **Task Design**:\n- Long-range target signal (local eccentricity) is explicitly tied to graph distance, not just node features.\n- Sensible justification for choosing k=16 to require long-range aggregation.\n\n3. **Good Empirical Study**: Systematic layer-depth experiments show deeper message passing helps.\n\n4. **Theoretical Support**: Spectral argument connecting large diameter & low degree to slower over-smoothing."}, "weaknesses": {"value": "1. **More Clarity Needed on Task Setup**:\n- Distribution of quantile labels — class imbalance?\n- Exact splits and sampling details\n\n2. **Transductive-only Setting**: Dataset is transductive; how will the ideas generalize to inductive settings?\n\n3. **Label Leakage and Spatial Bias Concerns**: Although the authors argue against pure geographical dependence, node features include latitude & longitude and spatially-derived attributes. It is not fully demonstrated that models can't rely largely on spatial features alone. Stronger evidence is needed to show that spatial coordinates alone cannot solve most of the signal."}, "questions": {"value": "1. Can you please defend and answer the questions or concerns raise in **Weaknesses**?\n2. How sensitive is performance to the inclusion of geographic features (lat/long)? Can you report results where positional coordinates are removed?\n3. Can models exploit spatial coordinates alone (that is consider separately MLP with coordinates only and GNNs with coordinates masked)?\n4. What is the runtime overhead of Jacobian measurement on a single city graph?\n5. Can you please provide a Table with accuracy results you presented in Figure 3 for k=16? It will be more easier to compare the results.\n6. How would your model perform on heterephilic datasets (Texas, Wisconsin, Cornell, Roman-Empire, etc)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "nqcw74BuYD", "forum": "fylMiUmg39", "replyto": "fylMiUmg39", "signatures": ["ICLR.cc/2026/Conference/Submission6143/Reviewer_ckYP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6143/Reviewer_ckYP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6143/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988366048, "cdate": 1761988366048, "tmdate": 1762918497127, "mdate": 1762918497127, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}