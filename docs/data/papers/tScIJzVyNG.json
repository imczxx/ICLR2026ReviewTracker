{"id": "tScIJzVyNG", "number": 17705, "cdate": 1758279509227, "mdate": 1759897159394, "content": {"title": "Optimizing Operations on B-Trees Using Proximal Policy Optimization and Hierarchical Attention-Based Models", "abstract": "Modern database management systems often rely on B-trees to achieve indexing in an efficient manner. If stored on slow permanent storage devices, write and read operations can become a significant performance factor, as transactional databases require regular additions and deletions. We propose to use a reinforcement learning setup to optimize the write performance of deletes and inserts by aggregating them and optimizing their order of execution. This achieves the goal of minimizing write times during tree updates. We present a small hierarchical attention-based model to parse the content of the tree efficiently. The new architecture allows for level-wise parallel computation and includes caching to improve the inference speed. Our evaluation verifies the applicability and the potential of the proposed framework. We show that we can efficiently compute an embedding in a hierarchical dataset and that the embedding can be used to achieve noticeable performance improvements in B-tree operation scheduling in comparison to accepting operations in their order of arrival.", "tldr": "A hierarchical attention-based model is presented with the goal of optimizing operation scheduling on dynamically managed B-trees.", "keywords": ["Reinforcement Learning", "Optimization", "Databases", "Attention", "B-Trees"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/af2593d9fa46008e7bbad947fd6282ce789e6873.pdf", "supplementary_material": "/attachment/7af2b3dd176a61497471794baeb2d18a53415263.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes a reinforcement learning framework to optimize the ordering of insert and delete operations on B-trees to minimize write costs. The authors introduce a hierarchical attention-based neural network architecture that recursively embeds B-tree structures and uses PPO to learn an operation scheduling policy. The approach includes a caching mechanism to reduce computational overhead during inference. Experiments on small B-trees (24 values, b=4) demonstrate 55% improvement over random execution and outperformance of simple heuristics."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "**S1**- Novel Problem Formulation: The paper addresses a practical problem—optimizing batch operations on B-trees—from an RL perspective, which is relatively unexplored.\n\n**S2**- Practical Caching Mechanism: The invalidation-based caching system is well-motivated for real-world deployment, recognizing that most operations affect only local tree regions.\n\n**S3**- Open-Source Commitment: The authors promise to release their simulation toolkit."}, "weaknesses": {"value": "**Major Issues**\n\n**W1**-\tThe core premise is questionable: Do real database systems actually benefit from reordering buffered operations? The paper provides no empirical evidences from actual database benchmarks (for example TPC-C, YCSB).\n\n**W2**-\t All experiments use small trees (24 values, b=4). Real-world B-trees contain millions of entries with b≥100. Also, in general the b-tree systems operation is between 100-500 ns, and in worse case goes to micro-seconds but the GPU dispatching and model forward is in order of milliseconds. B+tree by satelliting data improve the speed evenmore.\n\n**W3**-\tModern databases already use sophisticated buffering and write-ahead logging. The assumption that operations can be buffered and reordered contradicts transactional consistency requirements (ACID property) in most database systems or MVCC systems where operation order affects correctness. No comparison with existing database optimization techniques like bulk loading, LSM-trees or B\\epsilon-trees which are designed specifically for write optimization.\n\n**W4**- The \"baselines\" (alternating, insert-first, delete-first) appear arbitrary and are not motivated by database literature. No comparison with existing B-tree bulk operation algorithms from database literature (for example Jannink 1995's or Learned indexes (Kraska et al. 2018) works cited but not compared or Bulk loading algorithms). Missing comparison with sorted insertion order, which is known to be optimal for many B-tree scenarios.\n\n**W5**- Equal numbers of inserts and deletes (6 each) is not representative of real workloads. Random tree initialization may not reflect realistic data distributions. Reward function (Equation 3) weights are not justified: why is $p\\ne q$ for leaf vs internal operations? Gamma=0.999 means agent heavily discounts future rewards, contradicting the claim that operation order matters equally. Moreover, the implementation on python is not a perfect development tool for systems specially for time sensitive designs.\n\n**W6**- Regression experiments (Section 4) predict cost on pre-generated trees but dont validate if this prediction ability translates to better scheduling. The \"no tree\" agent achieves -3.1 average reward, only 29% worse than the full model (-2.17), suggesting tree information provides marginal benefit. No ablation study on critical design choices (e.g., number of attention heads, embedding dimension).\n\n**Minor Issues**\n\n**W7**-\t Inference time measurements(Table 5) only considered for forward pass, ignoring tree reading costs which the paper claims are expensive. Storage space improvements (Section 6.3, Figure11) are temporary. No wall-clock time comparison showing net benefit after accounting for inference overhead.\n\n**W8**-\tStatistical Rigor: Figure 5 shows variance without confidence intervals. Also, only 1,000 trees tested for quantile analysis (Figure 6) insufficient for robust conclusions. \n\n**W9**-\tPresentation Issues: Some notations presented without clear definitions (like p, q in Equation 3 introduced without values). Figures 9 and 10 show chery-picked examples without systematic analysis of failure modes. Missing related works on write-optimized data structures beyond brief mentions."}, "questions": {"value": "Addressing W1,W2, W4,W5\n\n**Q1**- How does your approach integrate with transaction management, concurrency control, and crash recovery in actual database systems?\n\n**Q2**- $10^8$ episodes over 6-8 hours—how does this training cost amortize in practice? How frequently must models be retrained as data distributions change?\n\n**Q3**- **Failure analysis**: Figures 9 and 10 show dramatic performance variance. Can you characterize when and why the agent fails?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "977VC2AvcJ", "forum": "tScIJzVyNG", "replyto": "tScIJzVyNG", "signatures": ["ICLR.cc/2026/Conference/Submission17705/Reviewer_PV9B"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17705/Reviewer_PV9B"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17705/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761253662529, "cdate": 1761253662529, "tmdate": 1762927544131, "mdate": 1762927544131, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper highlights a key challenge in B-trees: insertions may cause node overflows requiring splits, while deletions may lead to node underfill and trigger merges. Both operations can induce local or even cross-level structural modifications, which are costly and complex.\n\nTo address this, the authors propose a tree representation that can be efficiently updated during modifications and leverage it to automatically train an agent to determine the optimal execution order. They adopt PPO as the optimizer and employ a hierarchical attention encoder to efficiently embed large hierarchical datasets within the tree structure."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper clearly identifies the main challenges of B-trees and proposes an effective solution.\n\n2. The introduced hierarchical parallel computing and caching mechanism is highly valuable for reproducibility and future research."}, "weaknesses": {"value": "Overall, the paper studies B-trees, a topic more relevant to database research (e.g., SIGMOD, VLDB, ICDE), which may not attract significant interest from the ICLR audience.\n\n1. In Chapter 3.1, although the hierarchical model architecture is described, providing examples or figures illustrating specific steps would help enhance the reader’s understanding. The methodology section currently lacks formulas and visual aids to support the explanation.\n\n2. The overall structure of the paper could be improved. I suggest combining Chapter 4 and Chapter 5, with clear explanations, so that readers can better understand the connection between the regression experiments and the reward function.\n\n3. Including the pseudocode for PPO in Chapter 5 would further clarify the methodology.\n\n4. The paper mainly compares the proposed approach with random order and several hand-crafted heuristic methods, but lacks comparisons with state-of-the-art strategies in real systems or established database baselines. It is therefore difficult to demonstrate that the proposed method outperforms mature engineering practices."}, "questions": {"value": "Please address the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YAmQeJ5Q5q", "forum": "tScIJzVyNG", "replyto": "tScIJzVyNG", "signatures": ["ICLR.cc/2026/Conference/Submission17705/Reviewer_p98N"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17705/Reviewer_p98N"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17705/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761324897710, "cdate": 1761324897710, "tmdate": 1762927543768, "mdate": 1762927543768, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes to optimize B-tree insert and delete operations by learning an execution order through a reinforcement learning framework (PPO) combined with a hierarchical attention-based encoder. The goal is to minimize costly node splits and merges when B-trees are stored on slow persistent storage. Empirical results demonstrate that the learned policy outperforms several heuristic baselines and achieves up to 55% improvement over random operation ordering on small-scale B-trees."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper focuses on applying reinforcement learning method  (PPO)  to fine-grained B-tree operations, which is interesting.\n2. Reducing write cost and rebalancing overhead in persistent storage is a relevant systems problem."}, "weaknesses": {"value": "- The introduction of RL methods appears contrived  and fails to demonstrate domain knowledge modeling of the index structure. The so-called “hierarchical attention encoder” is essentially similar to the normal recurrent transformer, lacking novelty.\n\n- How scalable is the hierarchical encoder—what is the computational cost with respect to tree size and branching factor?\n\n- The reported “reward” does not necessarily translate to true performance gains. The claimed improvement  (approximately 55% better than random operations) was measured in a simplified synthetic environment using a manual cost function—How about actual runtime metrics in a controlled setting? Show similar results would significantly enhance the credibility of this paper. \n\n- Baselines in this paper is overly simple; while claiming scalability to larger tree structures, no convincing proof is provided (while the paper claims scalability to larger B-trees, the results show a sharp performance degradation as tree size increases, with no convincing analysis or mitigation strategy)."}, "questions": {"value": "As stated above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "RaXA2roDAO", "forum": "tScIJzVyNG", "replyto": "tScIJzVyNG", "signatures": ["ICLR.cc/2026/Conference/Submission17705/Reviewer_TKb3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17705/Reviewer_TKb3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17705/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762235953577, "cdate": 1762235953577, "tmdate": 1762927543405, "mdate": 1762927543405, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}