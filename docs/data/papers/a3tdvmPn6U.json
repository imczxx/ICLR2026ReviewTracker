{"id": "a3tdvmPn6U", "number": 7358, "cdate": 1758017670619, "mdate": 1759897857478, "content": {"title": "Vascular Information-Guided Automated Conversion Between OCT and OCTA", "abstract": "Optical Coherence Tomography (OCT) and Optical Coherence Tomography Angiography (OCTA) provide complementary perspectives for retinal disease assessment—OCT captures structural layers while OCTA visualizes microvascular networks. However, their synergistic use is limited by OCTA's specialized equipment requirements and higher costs, particularly in resource-constrained settings. Moreover, clinical scenarios often require cross-validation between modalities to verify vascular-structural correlations or to compensate for artifacts and missing data.\n\nWe propose a bidirectional conversion framework that enables seamless transformation between OCT and OCTA modalities, facilitating comprehensive multi-modal analysis from single-modality inputs. Our approach integrates generative adversarial networks with wavelet decomposition and attention mechanisms to preserve both morphological coherence and diagnostic fidelity. The framework consists of three synergistic components: a 3D Cross-Modal Transformer for volumetric synthesis, a Vessel Structure Matcher for vascular topology preservation, and Hierarchical Feature Calibration for layer-specific refinement.\n\nExtensive validation on the OCTA-500 dataset demonstrates superior performance with PSNR of 30.58, SSIM of 90.64\\%, and MAE of 0.0199 for OCT-to-OCTA synthesis. Clinical disease classification experiments show that combining real OCT with synthesized OCTA achieves 75.06\\% accuracy, surpassing single-modality baselines by up to 29\\%. This bidirectional capability not only addresses accessibility barriers but also enables cross-modal validation essential for artifact disambiguation and comprehensive diagnostic assessment, ultimately advancing precision medicine in ophthalmology.The code is available in the supplementary materials.", "tldr": "We develop a bidirectional framework for OCT-OCTA conversion that enables OCTA-equivalent vascular imaging using standard OCT equipment, improving diagnostic accessibility in clinical settings.", "keywords": ["Optical Coherence Tomography (OCT)", "Optical Coherence Tomography Angiography (OCTA)", "Image Translation", "Modality Translation"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7f30d211843b474735bd9a3ff479182cd6c5a89b.pdf", "supplementary_material": "/attachment/d1e256bb4e3981642f1894574449cbc6350ffb9f.zip"}, "replies": [{"content": {"summary": {"value": "The paper presents a wavelet enhanced deep learning framework for bidirectional conversion between OCT and OCTA"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The designed framework is complete."}, "weaknesses": {"value": "con: \n\nThe paper does not have novlety in machine leanring, maybe consider it as an application. \n\nExperiement is too simple, please consider to test more datasets."}, "questions": {"value": "Maybe more data to test so we can have a complete discussion about the method."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XMUqR6hG2V", "forum": "a3tdvmPn6U", "replyto": "a3tdvmPn6U", "signatures": ["ICLR.cc/2026/Conference/Submission7358/Reviewer_TRGb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7358/Reviewer_TRGb"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7358/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761401147841, "cdate": 1761401147841, "tmdate": 1762919493402, "mdate": 1762919493402, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper starts from bidirectional OCT-to-OCTA generation for considering the inverse transformation’s clinical value. In this regard, the authors propose the first comprehensive architecture for both OCT-to-OCTA and OCTA-to-OCT transformation, enabling true multi-modal synergistic analysis from single-modality inputs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper provides an interesting perspective, i.e.,  bidirectional OCT-to-OCTA generation for considering the inverse transformation’s clinical value.\n2. Although the proposed method seems to be incremental from existing works, the integration of the projection-to-projection transformation is novel to me.\n3. The disease classification experiments are informative and helpful to verify the quality of the generated images. \n4. Codes are available."}, "weaknesses": {"value": "1. The vessel segmentation models may be hard to access for a new scenario.\n2. The details of how to achieve bidirectional OCT-to-OCTA generation are unclear. More details are necessary."}, "questions": {"value": "1. What is the composition of the test set in the CLINICAL DISEASE CLASSIFICATION tasks? Does it only contain OCT or OCTA real images?\n2. What is the performance of using only synthesized OCT or OCTA?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "wQpBVpL5xo", "forum": "a3tdvmPn6U", "replyto": "a3tdvmPn6U", "signatures": ["ICLR.cc/2026/Conference/Submission7358/Reviewer_RPw9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7358/Reviewer_RPw9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7358/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761625192432, "cdate": 1761625192432, "tmdate": 1762919492738, "mdate": 1762919492738, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a bidirectional OCT <-> OCTA image conversion framework, utilizing a 3D wavelet-based transformer with the Vessel Structure Matcher (VSM) and Hierarchical Feature Calibration (HFC) techniques. The framework achieves high quantitative metrics."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1) The clinical disease classification shows that the synthetic images can improve the performance of the downstream classification task. \n(2) The paper evaluates the proposed framework on a public dataset"}, "weaknesses": {"value": "(1) When analysing the quality of the synthetic images, the authors only use PSNR, SSIM, and MAE. Perceptual and structural metrics are needed for comprehensive evaluation. \n(2) The paper lacks qualitative analysis. Some examples of the synthetic images are needed to demonstrate the performance of the framework."}, "questions": {"value": "The authors may consider adding safety analysis to the proposed framework. Using the proposed framework, will there be any risk of false positives/negatives in the downstream classification task?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GYWQUk2WEB", "forum": "a3tdvmPn6U", "replyto": "a3tdvmPn6U", "signatures": ["ICLR.cc/2026/Conference/Submission7358/Reviewer_KPh4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7358/Reviewer_KPh4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7358/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761880585897, "cdate": 1761880585897, "tmdate": 1762919492228, "mdate": 1762919492228, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper describes a generative framework for converting optical coherence tomography (OCT) images to and from OCT-angiography (OCTA). This is accomplished by three modules, a GAN-like model, a feature matching model, and a calibration model. The backbone models are all taken from well-known established architectures such as U-NET encoder/decoder models, 3D wavelet transforms, and other segmentation tools. In addition to the lack of originality and novelty, the paper has a multitude of shortcomings that makes it unsuitable for acceptance.\n\n1) Lack of novelty: The paper claims that the architectural innovations is in integration of wavelets with attention guided reconstruction. However, there is no clear outline of how this is achieved, or a clear theoretical support for its ability to provide optimal solutions. In addition, the tools used to accomplish this integration are rather well established in their own domains,  e.g. Wavelets from (Phung, et al. 2023), multi-scale attention from (Ouyang et al., 2023). The generative model is also a well known encoder/decoder. The pretraining model used for vessel structure matching is also from (Li et al. 2024a). \n\n2) Theoretical issues: The paper has major issues with theoretical soundness of its claims. The paper purports to have developed a novel bi-directional synthesis framework. However, the technical details of the paper do not present a clear and theoretical framework for its bi-directionality. Rather, it appears that the bi-directionality is achieved by inputting OCT images to produce OCTA, and then inputting OCTA to produce OCT. This is still a uni-directional approach, and far from achieving a truely bi-directional model. Moreover, the theory behind the utility of wavelet-guided features are not developed. For example, how does one distinguish between high-frequency features that are due to micro structures, as opposed to pathological anomalies. There is also no theoretical details on how the morphological preservation is achieved. The paper also claims that its approach is multi-model. However, both OCT and OCTA data are 3D structures of the same modality. This is a grave misrepresentation of the core contribution of the paper.\n\n3) Unsupported and false claims: There are many unsupported claims (either by theory or empirically). For example, integration of wavelets enables morpholoigical coherence. This claim is neither supported by theory or empirically. The claim that this approach is bidirectional is completely false. The claim that the approach is multi modal is also completely false. The claim that the multi-scale attention module selectively emphasizes clinically relevant structures is also completely unsupported. Claim that wavelets maintain microvascular structures and other global and pathological features is also not supported. It is important to note that many structural and pathological features have representations in multiple frequency and spatial bands. There is no theoretical foundation about that supports the decompositional disentaglement purported here."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "None noted."}, "weaknesses": {"value": "Presented in the summary."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "xsMBoIiNvm", "forum": "a3tdvmPn6U", "replyto": "a3tdvmPn6U", "signatures": ["ICLR.cc/2026/Conference/Submission7358/Reviewer_7qwq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7358/Reviewer_7qwq"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7358/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762135815660, "cdate": 1762135815660, "tmdate": 1762919491816, "mdate": 1762919491816, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}