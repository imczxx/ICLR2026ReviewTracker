{"id": "713ywmTZHv", "number": 2209, "cdate": 1757027837603, "mdate": 1763430422563, "content": {"title": "PE-SGD: Differentially Private Deep Learning via Evolution of Gradient Subspace for Text", "abstract": "Differentially Private Stochastic Gradient Descent (DP-SGD) and its variants like DP-Adam ensure data privacy by injecting noise into per-sample gradients. Although effective with large private datasets, their performance degrades significantly when private training data is limited. Recent works leverage public data to learn a gradient subspace and project noisy private sample gradients on to this subspace, achieving improved performance. However, they have overlooked two crucial aspects: the limitation of using a fixed projection subspace throughout training and the importance of choosing where to inject noise. Therefore, we propose Private Evolution aided Stochastic Gradient Descent (***PE-SGD***), a differentially private training framework effective for scenarios with limited private data. ***PE-SGD*** uses an evolutionary strategy to update the gradient projection subspace during training process. We also identify a more effective noise injection point for better alignment between approximate DP-protected gradient and real private gradient. This enables ***PE-SGD*** to outperform DP-SGD and other baselines, particularly in the regime of limited private data and small privacy budget.", "tldr": "", "keywords": ["Differential Privacy", "Private Evolution", "Generation Model"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/484863d176aee3a27e6038b00c34bd2362cb2a62.pdf", "supplementary_material": "/attachment/0a843a68873c1ad4d2f3cc00165e47b67c5b38da.zip"}, "replies": [{"content": {"summary": {"value": "DP-SGD and its variants often suffer from degraded performance when the number of private samples is limited. Prior work attempts to address this issue by computing a gradient projection subspace from public data and adding perturbations within that subspace. However, there is a mismatch between the fixed projection subspace and the dynamically evolving training process, which hampers model performance. Moreover, the optimal location for injecting noise within the projection process remains underexplored.\n\nThis paper proposes PE-SGD, which dynamically updates the non-private dataset based on the evolving model during training, thereby reducing the L2 distance between the approximate gradients and the real gradients. In addition, the paper systematically compares different noise injection strategies and finds that adding noise to the final projection coefficients yields more stable and superior performance than injecting noise at other stages. Extensive experiments demonstrate the effectiveness of PE-SGD, particularly in improving performance on long-tailed samples within the private dataset."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper identifies an important limitation in existing gradient projection approaches: the fixed projection subspace is incompatible with the dynamic nature of training. Figure 1 effectively illustrates how the subspace derived by prior methods diverges from the true gradient subspace as training progresses, revealing a key reason behind their performance degradation.\n- Methodologically, the work integrates the strengths of gradient projection and differentially private synthetic data approaches (e.g., PDP-SGD and Aug-PE). It introduces a novel design that computes the projection subspace using dynamically generated samples, achieving lower next-token prediction loss and higher next-token prediction accuracy on text generation tasks.\n- The paper provides comprehensive experiments to explain why PE-SGD outperforms prior methods. For example, analyses of long-tailed samples before and after training highlight that PE-SGD captures richer knowledge from private data and mitigates the long-tail issue. Moreover, per-step update experiments clearly demonstrate that PE-SGD achieves a larger decrease in loss compared to DP-SGD."}, "weaknesses": {"value": "- In the SynDataGeneration component, the authors employ VARIATIONAL_API to generate synthetic data. However, the paper lacks an evaluation of the quality of these generated samples, such as their textual quality and diversity. This step is crucial for future extensions of the work, as insufficient diversity in data generated by VARIATIONAL_API could lead to performance degradation when applied to other datasets."}, "questions": {"value": "- The reviewer would like to understand why, in the right plot of Figure 3(a), some data points appear to lie on the same diagonal line. Is this phenomenon due to numerical precision issues, or does it reflect certain regularities inherent in the data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pH4AdLzEZr", "forum": "713ywmTZHv", "replyto": "713ywmTZHv", "signatures": ["ICLR.cc/2026/Conference/Submission2209/Reviewer_v9H2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2209/Reviewer_v9H2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2209/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761834490066, "cdate": 1761834490066, "tmdate": 1762916138965, "mdate": 1762916138965, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents an approach based on subspace projection using public data, namely using gradients evaluated on synthetic data that is generated using a public model. The DP-SGD algorithm is modified so that the gradients ar first projected in a certain way using these public gradients, the noise is added only to the small-dimensional objects which are then afterwards projected back to the high-dimensions. Experiments support the benefits of this approach."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Interesting and a novel approach of using synthetic data to generated gradient projection bases. While there are lot existing works considering the projection of DP-SGD with public bases to reduce the amount of added noise, I am not aware of this specific approach in the literature, i.e., using public models to generate synthetic data for this task."}, "weaknesses": {"value": "- the work overlooks several relevant and important prior studies, e.g., the work by [Gu et al., 2025](https://arxiv.org/pdf/2303.01256) and many others works that consider adding noise only to projected DP-SGD gradients. Existing works study different aspects of these methods. E.g., Gu et al. provide tools for privately estimating which public basis is most suitable for private gradients, an aspect highly relevant to the current paper’s methodology, yet not discussed at all.\n\n- It remains unclear, why is the projection carried out the way it is done in Alg. 1. In  many existing projection methods the projection is carried out using orthonormal bases which is arguably much more stable alternative. There are no comparisons.\n\n- The scales in the experiments are very narrow: the differences in the performance are in absolute sense small (look e.g. at Fig. 6,7,8). As the contribution is purely heuristical, the experimental part should be stronger and done much more carefully.\n\n- No theoretical support for the proposed method."}, "questions": {"value": "In  many existing projection methods the projection is carried out using orthonormal bases which is arguably much more stable alternative. Why this version?\n\nHow do you know which part of the generated synethic data is useful for the gradient projection? Why aren't there methods to filter out the most useful public data / gradients?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2QwqAMQmyk", "forum": "713ywmTZHv", "replyto": "713ywmTZHv", "signatures": ["ICLR.cc/2026/Conference/Submission2209/Reviewer_zNzf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2209/Reviewer_zNzf"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2209/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761856926584, "cdate": 1761856926584, "tmdate": 1762916138595, "mdate": 1762916138595, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes PE-SGD, a framework for differentially private (DP) training that combines gradient subspace projection with an evolving synthetic dataset. The authors argue that existing projection-based DP methods (e.g., PDP-SGD, GEP) suffer from (1) fixed projection subspaces that fail to adapt during training, and (2) unclear choices of where to inject DP noise. PE-SGD addresses these by (a) updating the projection subspace via synthetic data generated by a pre-trained model at each iteration, and (b) empirically identifying that injecting noise into the final projection coefficients yields better performance. Experiments on text fine-tuning tasks with three pre-trained models show moderate improvements over prior methods under tight privacy budgets."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper tackles a practically relevant problem of improving DP-SGD performance when private data is limited, and situates itself within a growing body of work on gradient subspace methods.\n\n2. The algorithm is presented clearly, and the privacy analysis (Appendix B.2) formally ensures that the DP guarantee remains equivalent to standard DP-SGD.\n\n3. The implementation details, reproducibility statement, and visualizations are carefully documented."}, "weaknesses": {"value": "1. Lack of depth in problem diagnosis\n\nThe paper highlights two “overlooked” issues in prior work --- fixed projection subspaces and unclear noise placement --- but does not provide a fundamental analysis or theoretical insight into either:\n\n- For the fixed subspace issue, the paper only shows that in one experimental setup, the ℓ₂ distance between the private gradient and the projected noisy gradient increases with training (Fig. 1). This is a narrow empirical observation, not a principled explanation. There is no discussion of why the subspace mismatch arises (e.g., due to model drift, curvature changes, or gradient manifold evolution), nor analysis of whether this holds in general or depends on the dataset, model, or training regime.\n\n- For the noise placement issue, the paper claims prior work lacked rationale --- but it likewise fails to provide one. The finding that adding noise to the final projection coefficients works best is purely empirical, without any theoretical justification or conceptual understanding.\n\nHence, although the paper frames itself as addressing two conceptual gaps, it mostly reiterates them experimentally rather than resolving them.\n\n2. Weak connection between motivation and experiments\n\nThe paper’s motivation centers on differentially private training, yet all experiments are limited to fine-tuning pre-trained models using LoRA. This is a much narrower and simpler regime than full DP training from scratch. Consequently, the experimental evidence does not convincingly demonstrate the method’s broader applicability to general DP optimization, nor its scalability to large models or high-dimensional gradient spaces.\n\n3. Overstated claims of originality\n\nBoth key ideas --- evolving a projection subspace and empirically selecting a noise placement --- are relatively incremental extensions of existing work rather than conceptually new mechanisms. The “evolution” is implemented via synthetic data regeneration using a generative model API, but there is no evidence that this evolution is guided or optimal, beyond heuristic sample resampling. The connection between this process and gradient-space adaptation remains speculative.\n\n4. Limited theoretical depth\n\nThere is no analysis of convergence, bias-variance trade-offs, or the statistical efficiency of evolving subspaces under DP noise. The privacy argument relies entirely on post-processing invariance, which sidesteps the deeper question of whether iterative synthetic data generation introduces new privacy risks or affects gradient alignment stability.\n\n5. Experimental limitations\n\nWhile quantitative results show small gains under ε = 1.0, improvements are modest and primarily on fine-tuning tasks. There is no ablation for computational cost or efficiency, nor experiments beyond text data. The results, though positive, do not convincingly demonstrate a substantial advance in the state of the art."}, "questions": {"value": "1. Can the authors provide any theoretical intuition for why fixed projection subspaces fail — e.g., does the private gradient manifold evolve significantly during fine-tuning, or is it a data-distribution drift effect?\n\n2. Is the proposed “evolutionary” process guaranteed to improve gradient alignment, or could it destabilize the subspace under noise?\n\n3. How is the additional synthetic data generation cost handled? Does this make PE-SGD slower than DP-SGD or PDP-SGD?\n\n4. Since experiments only involve fine-tuning with LoRA, can the method extend to full-model DP training?\n\n5. Can the authors provide at least a conceptual analysis of why adding noise to the projection coefficients yields better performance than to the raw gradients?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "9HEAmAiTC6", "forum": "713ywmTZHv", "replyto": "713ywmTZHv", "signatures": ["ICLR.cc/2026/Conference/Submission2209/Reviewer_FYzi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2209/Reviewer_FYzi"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2209/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762102792153, "cdate": 1762102792153, "tmdate": 1762916135887, "mdate": 1762916135887, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an improved subspace projection-based DP-SGD like training algorithm, with the idea of identifying the subspace of gradient using data generated by the model being trained itself. Experiments show the proposed algorithm can achieve better performance when privacy budget is limited where DP-SGD tends to fail."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The algorithm is built on a simple and neat idea of using samples generated by model itself to identify the gradient subspace, removing the need of a in-distribution public dataset and mitigate the potential issue of misaligned gradient subspace.\n2. The algorithm achieves better empirical performance than baselines when epsilon is relatively small."}, "weaknesses": {"value": "1. The proposed algorithm need additional computation to sample new dataset across iterations, which could make the algorithm relatively slow.\n2. The algorithm performance may depends on the quality of generated data itself, which may imply the original model quality and capability performs a role here. There is a lack of discussion and ablation on this topic."}, "questions": {"value": "1. Could the authors comment on how generated data quality and original model capability could affect final model performance?\n2. Did authors visualized how the subspace of projection obtained from synthetic data compared with subspace of the model gradient? Also how does prompt template of data generation affect the subspace difference and final performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "EKe3dejrNL", "forum": "713ywmTZHv", "replyto": "713ywmTZHv", "signatures": ["ICLR.cc/2026/Conference/Submission2209/Reviewer_eNfj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2209/Reviewer_eNfj"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2209/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762132520759, "cdate": 1762132520759, "tmdate": 1762916135673, "mdate": 1762916135673, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}