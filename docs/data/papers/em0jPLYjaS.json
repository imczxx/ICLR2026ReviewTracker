{"id": "em0jPLYjaS", "number": 2412, "cdate": 1757076953696, "mdate": 1763296412844, "content": {"title": "QuaMo: Quaternion Motions for Vision-based 3D Human Kinematics Capture", "abstract": "Vision-based 3D human motion capture from videos remains a challenge in computer vision.\nTraditional 3D pose estimation approaches often ignore the temporal consistency between frames, causing implausible and jittery motion.\nThe emerging field of kinematics-based 3D motion capture addresses these issues by estimating the temporal transitioning between poses instead.\nA major drawback in current kinematics approaches is their reliance on Euler angles.\nDespite their simplicity, Euler angles suffer from discontinuity that leads to unstable motion reconstructions, especially in online settings where trajectory refinement is unavailable.\nContrarily, quaternions have no discontinuity and can produce continuous transitions between poses.\nIn this paper, we propose QuaMo, a novel Quaternion Motions method using quaternion differential equations (QDE) for human kinematics capture.\nWe utilize the state-space model, an effective system for describing real-time kinematics estimations, with quaternion state and the QDE describing quaternion velocity.\nThe corresponding angular acceleration are computed from a meta-PD controller with a novel acceleration enhancement that adaptively regulates the control signals as the human quickly change to new pose.\nUnlike previous work, our QDE is solved under the quaternion geometric constraints that results in more accurate estimations.\nExperimental results show that our novel formulation of the QDE with acceleration enhancement accurately estimates 3D human kinematics with no discontinuity and minimal implausible artifact.\nQuaMo outperforms comparable state-of-the-art methods on multiple datasets, namely Human3.6M, Fit3D, SportsPose and a subset of AIST.\nThe code is made available upon acceptance.", "tldr": "", "keywords": ["human", "kinematics", "quaternion", "motion", "vision"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f190f2ed395af280b2f125239b86fa0d548f0a2c.pdf", "supplementary_material": "/attachment/e40827e920f3c5d6efb62ca862b4e16d6d60baf2.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes QuaMo, an online kinematics module that replaces Euler-angle dynamics with a quaternion differential equation (QDE) solved exactly on the unit sphere $S^3$, coupled with a meta-PD controller augmented by a second-order acceleration enhancement term. Given per-frame vision priors (e.g., TRACE, HMR2.0), QuaMo predicts angular velocities and integrates quaternions via the Hamilton product to reduce the motion jitter and produce temporally consistent motion from the monocular videos."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- A key strength of QuaMo is its fully online state-space formulation, which does not rely on future observations, enabling real-time refinement of off-the-shelf 3D pose estimators through iterative updates of angular velocity and quaternion states.\n- Unlike integration approximation methods, which risk moving the estimated quaternion outside the unit sphere $S^3$ and therefore require normalization to mitigate this issue, this work uses the Hamilton product between the quaternion representation of the rotation matrix and the current $q_t$. This leads to more accurate estimations, since normalization in previous approaches turns the quaternion into a direction that does not correspond to the true rotation and distorts the trajectory.\n- The proposed acceleration enhancement $\\alpha$ is computed from the second-order quaternion difference of the last three reference poses. It boosts control only when the reference is changing quickly (i.e., during true fast movement) and dampens as the target is reached. This allows QuaMo to treat fast, intended motion and jitter differently.\n- For evaluation, the work reports both local and global metrics (MPJPE, P-MPJPE, Accel, global MPJPE/GRE, global jitter, and foot-skating) and provides error bars across random seeds. Evaluating the proposed QuaMo using TRACE and HMR2.0 as baselines, the results show that incorporating QuaMo significantly reduces acceleration errors. While the improvements in joint-based errors for HMR2.0 in camera coordinates are marginal, the method substantially decreases errors in the world coordinate system."}, "weaknesses": {"value": "- As shown in table 3, although the proposed acceleration term $\\alpha$ enhances the joint-based errors, it increases the acceleration error. It would be useful to clarify when to disable/attenuate the term to prevent the rise of acceleration error.\n- Although the addition of Euler integration for root translation shows an improvement in GRE, it is a first-order numerical integration method, and I suspect that small errors could accumulate over time. A figure or analysis of translation error versus time would be useful.\n-  There are minor ambiguities in the writing. First, $f_\\omega$ is introduced as a function of $q_t$ and $\\omega_t$. Then, at line~240, the term $b_t$ is introduced as an approximation of $f_\\omega$, but $b_t$ is the output of the ControlNet, which receives additional inputs.\n- Minor writing issues:\n  - line 240 misses close parenthesis\n  - line 236 has redundant comma after imaginary\n  - line 290 mentions $\\kappa_I$ of Eq. 5 that does not exist.\n  - In table 1 and 2, Foot skating is mentioned as FS while in table 3 FK is used."}, "questions": {"value": "- Given that the input $\\hat{q}_t$ is noisy and the acceleration enhancement term uses a second-order difference, it can inherently amplify high-frequency noise. How is noise propagation controlled? Is it handled by ControlNet by assigning an appropriate $\\kappa_A$ depending on the level of noise present in $\\hat{q}_t$?\n- Can the QuaMo method be applied to per-frame approaches that estimate MANO parameters, such as HaMeR [1]? If so, what modifications would be required to adapt the quaternion-based kinematic formulation to hand-specific articulations?\n\n[1] Pavlakos, Georgios, Dandan Shan, Ilija Radosavovic, Angjoo Kanazawa, David Fouhey, and Jitendra Malik. \"Reconstructing hands in 3d with transformers.\" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9826-9836. 2024."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jYjsvk1Szf", "forum": "em0jPLYjaS", "replyto": "em0jPLYjaS", "signatures": ["ICLR.cc/2026/Conference/Submission2412/Reviewer_qvAF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2412/Reviewer_qvAF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2412/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761424050091, "cdate": 1761424050091, "tmdate": 1762916225653, "mdate": 1762916225653, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents QuaMo, an online 3D human kinematics capture framework from monocular video. The method replaces Euler angles with a quaternion differential equation (QDE) under a unit-sphere constraint to avoid discontinuity and gimbal lock. It further combines a meta-PD controller with a second-order acceleration term to better handle fast motion changes. Experiments on four benchmarks (Human3.6M, Fit3D, SportsPose, AIST) indicate improved accuracy and smoother motion over several online kinematics baselines, with ablation results supporting each component."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Clear articulation of the discontinuity/gimbal lock problem and why Euler angles are problematic in online capture.\n\nCorrect quaternion-based formulation with integration respecting the unit-sphere constraint.\n\nAdaptive acceleration term adds responsiveness to the PD controller, helping in fast motion regimes.\n\nSolid empirical evaluation across multiple datasets, and thorough ablation on rotation representations and pipeline components."}, "weaknesses": {"value": "Novelty: Quaternions for rotation representation are standard in robotics, graphics, and physics simulation. The specific QDE formulation and its integration here are sound, but not a fundamentally new concept.\n\nNo cost analysis: The paper doesn’t compare training/inference speed, memory usage, or computational overhead with Euler/axis-angle setups. The practical trade-off is unclear.\n\nInput dependency: Performance varies greatly depending on upstream reference pose quality (TRACE vs HMR2.0). There is no robustness study under noisy or degraded inputs.\n\nEvaluation scope: Benchmarks target relatively clean, single-person motions. Multi-person, occlusion-heavy, or contact-rich scenarios are not tested."}, "questions": {"value": "1. What is the training/inference time cost relative to Euler or axis-angle versions? Does the quaternion formulation require higher compute/latency?\n\n2. How does the method perform when reference poses are distorted or noisy? Any filtering or noise-robust adaptation tested?\n\n3. Could the approach be extended to longer-horizon online settings (multiple future poses) without sacrificing latency?\n\n4. Would the method benefit from incorporating environment contacts (as mentioned in future work) into the controller?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4d0pHGq7qj", "forum": "em0jPLYjaS", "replyto": "em0jPLYjaS", "signatures": ["ICLR.cc/2026/Conference/Submission2412/Reviewer_BjYh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2412/Reviewer_BjYh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2412/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761720947859, "cdate": 1761720947859, "tmdate": 1762916225516, "mdate": 1762916225516, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper targets the challenging problem of 3D human motion capture based on visual input. To address the problem of implausible and jittery motion due to the representation of Euler angles, the paper propose to use Quaternion motions instead and an effective system based on QDE  is utilized. The experiments on several benchmarks like Human3.6M, Fit3D, SportsPose and AIST validate the effectiveness of the proposed algorithm."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The paper targets the challenging problem of 3D human motion capture based on visual input, which is of great importance to the industry applications. \n\n* The idea of using quaternion differential equations for human kinematics capture is intersting. \n\n* It reports reasonable results on several benchmarks like Human3.6M, Fit3D, SportsPose and AIST."}, "weaknesses": {"value": "* It should include the recent references published in the recent two years. Currently, there is no reference published in 2025.\n\n* For the experiments, there are several releated works which are not compared. For example, [R1] is referenced in the paper but not compared in Table 1. By checking the results report in [R1], it would have obviously better results compared with the prposed algorithm. Please involve more papers published in the recent two years (2024-2025) for comparisons. \n\n[R1] Jihua Peng, Yanghong Zhou, and PY Mok. Ktpformer: Kinematics and trajectory prior knowledge-\nenhanced transformer for 3d human pose estimation. In CVPR, pp. 1123–1132, 2024\n\n* In Section 4.2, there are several implementation details reported in the paper. As there are many hyper-parameters defined in the paper, is there possible to provide more ablations on the setting of these hyper-parameters?"}, "questions": {"value": "Please address the questions raised in the weakness section. More specifically, please provide more comparisons in Table 1 to validate the effectiveness of the proposed algorithm against the state-of-the-art algorithms."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zd8ov1DWEj", "forum": "em0jPLYjaS", "replyto": "em0jPLYjaS", "signatures": ["ICLR.cc/2026/Conference/Submission2412/Reviewer_6eiP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2412/Reviewer_6eiP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2412/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761743465973, "cdate": 1761743465973, "tmdate": 1762916225371, "mdate": 1762916225371, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General response"}, "comment": {"value": "First of all, we would like to express our gratitudes to all reviewers for their efforts on providing us insightful comments and feedback to our paper QuaMo.\nWe are glad that the contributions of QuaMo towards the task of online 3D human motion capture is recognized as stronng (qvAF), clear and correct (BjYh), and interesting (6eiP).\nFor further clarity about our paper, we provide answers and complimentary experiments as requested to each reviewer in their respective comment sections."}}, "id": "WNBibVys8t", "forum": "em0jPLYjaS", "replyto": "em0jPLYjaS", "signatures": ["ICLR.cc/2026/Conference/Submission2412/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2412/Authors"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission2412/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763296265388, "cdate": 1763296265388, "tmdate": 1763296265388, "mdate": 1763296265388, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}