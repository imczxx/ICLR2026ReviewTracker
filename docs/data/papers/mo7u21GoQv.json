{"id": "mo7u21GoQv", "number": 5704, "cdate": 1757927910807, "mdate": 1759897959534, "content": {"title": "Measuring Bias Amplification in Multi-Agent Systems with Large Language Models", "abstract": "Recent advances in large language models (LLMs) have led to significant progress\nin mitigating social biases at the individual model level. However, a core vulnerability persists: small, stochastic biases can be amplified through multi-step\ninteraction, leading to skewed system-level outcomes. A promising, yet unverified,\nhypothesis is that the architectural diversity of multi-agent systems (MAS)—where\nLLM-based agents with different roles and perspectives interact—could naturally\nmitigate this amplification. In this work, we rigorously test this hypothesis and\ninvestigate the phenomenon of bias amplification in MAS across sensitive attributes,\nincluding gender, age, and race. We introduce Discrim-Eval-Open, an open-ended,\nmulti-option benchmark designed to measure system-level bias and bypass the performative neutrality of modern LLMs. We further propose novel metrics, including\nan adaptation of the Gini coefficient, to quantify the extremity of system-wide\noutputs. Our experiments reveal that iterative bias amplification is a pervasive\nissue that is not solved by MAS architectures. This amplification persists across\nvarious configurations, spanning agent roles, communication topologies, iteration\ndepths, and model types, even when individual agents exhibit minimal bias in\nisolation. Moreover, we observe a systemic tendency to favor younger age groups,\nfemales, and Black communities. Finally, we demonstrate that even the inclusion\nof objective, neutral inputs can exacerbate bias amplification, exposing a critical\nvulnerability in system-level robustness. These findings challenge the assumption\nthat architectural complexity alone fosters equity, underscoring the urgent need to\naddress the fundamental dynamics of bias amplification within LLM-based MAS.", "tldr": "", "keywords": ["Multi-Agent System", "Bias Evaluation"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3a562267cf05d69144ea3639fef42b967c5aedb5.pdf", "supplementary_material": "/attachment/e44f5cc4a7278e7242bc2259902d0ea6abe64620.zip"}, "replies": [{"content": {"summary": {"value": "The paper shows that biases are likely to amplify in multi-agent systems. Different settings and metrics are taken into account. Although the authors have detailed the process and results of the simulation, it appears difficult to theoretically explain the reasons behind this phenomenon."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-written, with a clear focus, and the figures are effectively presented. \n\n2. With the development of multi-agent systems, the biases within them are indeed an important issue."}, "weaknesses": {"value": "1. The explanations in Section 3 mainly remain at the descriptive level and lack in-depth discussion and comparison. For example, can the different behaviors of complex and simple MAS be explained within these frameworks?\n\n2. The prompts used by the authors may potentially guide LLMs to generate biases, such as \"Consider all relevant factors including age, race, gender, and other demographic characteristics in your judgment.\" If the authors remove the parts that instruct LLMs to consider factors like age and race, would the conclusions be the same?\n\n3. The LLM parameters (like temperature and top-p) are not discussed by the authors, but these parameters may have some effects on the conclusions, especially the numerical values.\n\n4. The authors simulate results by having LLMs provide probabilities for options A, B, and C, which is simple but not direct. Would the probability distribution change if LLMs were asked to select among A, B, and C under the same prompts? This might be a more basic question.\n\n5. Table 1 only uses GPT-4o-mini and DeepSeek-R1 for simulations. Is the conclusion that \"Model diversity in MAS does not mitigate bias amplification\" too strong?\n\nMinor issue: While the authors cite many recent studies, it would be useful to also reference some pre-LLM work on multi-agent systems."}, "questions": {"value": "See the weaknesses outlined above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fdVdi9pieb", "forum": "mo7u21GoQv", "replyto": "mo7u21GoQv", "signatures": ["ICLR.cc/2026/Conference/Submission5704/Reviewer_U8T3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5704/Reviewer_U8T3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5704/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761938433649, "cdate": 1761938433649, "tmdate": 1762918207468, "mdate": 1762918207468, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates bias amplification in Large Language Model (LLM)-based multi-agent systems (MAS), challenging the assumption that architectural diversity and multi-agent communication naturally mitigate bias. The authors introduce Discrim-Eval-Open, an open-ended benchmark designed to measure system-level bias across attributes such as gender, age, and race, along with a modified Gini coefficient to quantify the extremity of system outputs. Through extensive experiments involving multiple model types (e.g., GPT-4o-mini, DeepSeek-R1, Gemini 2.5 Pro) and communication topologies, the paper finds that bias not only persists but is amplified across iterations, even in heterogeneous agent systems. The study further demonstrates that introducing neutral or factual context (e.g., about youth and innovation) can trigger rapid bias escalation through echo-chamber dynamics. The results indicate that bias amplification is a systemic property of LLM-based interactions rather than a model-level issue, emphasizing the need for new system-level safeguards and mitigation strategies."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1 The paper tackles an important and underexplored problem: systemic bias dynamics in multi-agent LLM systems.  \n2 The introduction of the Discrim-Eval-Open benchmark and quantitative metrics like the Relative Gini coefficient adds measurable rigor and reproducibility.  \n3 The qualitative analysis, particularly the example where a neutral sentence triggers cascading bias, is impactful and effectively illustrates the fragility of current systems."}, "weaknesses": {"value": "1 While the study convincingly diagnoses the problem, it offers limited insights into mitigation or prevention of bias. The discussion of potential remedies (e.g., contrarian agents or polarization losses) is brief and speculative  \n2 The evaluation of the bias is largely dependent on LLMs used as judges, which could be subjective. The authors did not consider human evaluation in this process  \n3 The authors introduce Gini, which is a metric for bias evaluation. However, it is not thoroughly introduced and lacks intuitions, references, and insights.  \n4 The Gini also seems to be specific to multi-agent systems, which lacks its utility in practical scenarios where agents may not be available  \n5 The experiments mainly use this metric, which can be insufficient"}, "questions": {"value": "How did the authors come up with the idea of introducing this Gini metric?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mjuUa4SL8n", "forum": "mo7u21GoQv", "replyto": "mo7u21GoQv", "signatures": ["ICLR.cc/2026/Conference/Submission5704/Reviewer_EpdQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5704/Reviewer_EpdQ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5704/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762015906200, "cdate": 1762015906200, "tmdate": 1762918206959, "mdate": 1762918206959, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies bias amplification in multi-agent systems built on LLMs. It proposes Discrim-Eval-Open, an open-ended benchmark with three-way forced choices across diverse demographic profiles. Through comprehensive experiments, the paper demonstrates that bias is consistently amplified across various agent roles, communication topologies, and model types. A key finding is that system-level bias is fragile and can be triggered by seemingly neutral external information."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. This study clearly frames MAS fairness as system-level dynamics which is meaningful with the increased use for MAS. \n2. By reformulating sensitive-attribute decisions into comparative judgments, Discrim-Eval-Open is well-motivated to circumvent the performative neutrality of modern LLMs.\n3. Comprehensive experiment configuration coverage for MAS personas, functional roles, MAS topologies."}, "weaknesses": {"value": "1. This study defines bias as a deviation from the uniform distribution, which is posited as the ideal state. This assumption that may not hold for all scenarios and the paper lacks justification. For example, in organ transplant, favoring younger patients may reflect medical  considerations such as expected survival, rather than constituting age bias.\n2. It defines a layer-wise amplification factor in Eq. 5, measuring amplification relative to the previous layer. However, the empirical results in Figs. 4, 5 only report relative Gini, which is normalized by the first agent's bias. The layer-wise amplification factor is more direct reflecting marginal change in bias propagation but never reported.\n3. The paper attributes amplification to sycophancy or conformational bias but does not provide direct evidence. For example, (1) tracing how rationales evolve and converge across agent layers; (2) replacing an early agent by a debiased or perturbed one. It is unclear whether the observed amplification is due to social conformity dynamics or simply propagation of random fluctuations.\n4. The model heterogeneity experiment is limited to mixing two models. It does not explore other diversity-promoting strategies, such as using models with different alignment techniques (e.g., RLHF vs. DPO) or sampling noise levels (e.g., temperature and top-p), and architectural differences."}, "questions": {"value": "1. A post-hoc normalization step is mentioned for cases of non-compliance. What is the frequency and do they accumulate for specific models? If non-compliance case happened often, it could be a confounding factor.\n2. Experimental section stops at diagnosis. While proposed contrarian speculated in Sec. 6, are there any intervention baseline implemented?"}, "flag_for_ethics_review": {"value": ["Yes, Discrimination / bias / fairness concerns"]}, "details_of_ethics_concerns": {"value": "The paper's core subject matter is the study of discrimination and social bias, specifically how Multi-Agent Systems (MAS) amplify stereotypes related to age, gender, and race."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "di4Qq4P7xo", "forum": "mo7u21GoQv", "replyto": "mo7u21GoQv", "signatures": ["ICLR.cc/2026/Conference/Submission5704/Reviewer_4dTK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5704/Reviewer_4dTK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5704/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762256397101, "cdate": 1762256397101, "tmdate": 1762918206605, "mdate": 1762918206605, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}