{"id": "Fxz0aaGSNY", "number": 735, "cdate": 1756778674618, "mdate": 1763707959067, "content": {"title": "Efficient Multi-modal Dataset Distillation via Analytic Parameter Matching", "abstract": "Multi-modal dataset distillation (MDD) seeks to compress the large-scale multi-modal data, \\eg, images and text, into a compact set of synthetic pairs. Existing methods typically employ a bi-trajectory distillation framework to align the trajectories of expert and student models within each modality. Although effective, this paradigm incurs significant storage and computational overhead due to the large number of checkpoints and the need for double backpropagation, limiting its efficiency and scalability. To overcome these limitations, we propose analytic parameter matching (APM), which directly matches the analytic parameters of the modal projectors rather than the entire trajectory, offering two key advantages: First, instead of storing multiple checkpoints, APM only caches two matrices, which significantly reduces the storage budget. Second, APM avoids the bi-level optimization, as the analytic parameters can be computed in a single forward pass. Theoretically, we establish the connection between these analytic parameters and matrix whitening, clarifying their benefits for MDD.\nEmpirically, APM achieves up to 65$\\times$ storage reduction, 9.6$\\times$ distillation speedup, and scales to 1000 synthetic pairs. Extensive experiments on Flickr30k and MS-COCO demonstrate the effectiveness of APM in cross-modal retrieval tasks, \\eg, 12.8 IR@1 and 17.8 TR@1 under 100-pairs, outperforming existing MDD methods in most scenarios.", "tldr": "", "keywords": ["Dataset Distillation", "Multi-modal"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/71666065b9ae403bb09454db498c28806cce7e35.pdf", "supplementary_material": "/attachment/58123acbf14501733e68e62520338e58ced22801.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces Analytic Parameter Matching (APM), a new and efficient method for multi-modal dataset distillation (MDD). MDD aims to compress large datasets of paired data into a much smaller, synthetic set that can train models effectively."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The strengths of this paper are:\n1. It proposes APM, which replaces the expensive inner-loop model optimization and trajectory storage of previous methods with a direct analytic computation.\n2. Compared to previous methods like LoRS, APM achieves up to a 65x reduction in storage and a 9.6x speedup in distillation time by avoiding the need to store checkpoints and perform double backpropagation.\n3. Extensive experiments on the Flickr30k and MS-COCO datasets show that APM achieves state-of-the-art or competitive performance in cross-modal retrieval tasks, especially with small synthetic dataset sizes."}, "weaknesses": {"value": "The weaknesses of this paper are:\n1. The derivation in Equation 4 simplifies the standard InfoNCE contrastive loss to a least-squares problem, i.e., $\\mathcal{L}_{MCL}$. This simplification ignores the temperature parameter $\\tau$ and the softmax normalization over negative samples, which are fundamental to modern contrastive learning. The paper does not provide sufficient justification for why this simplified objective is a valid proxy. The performance of InfoNCE is known to be highly sensitive to the number of negative samples and the temperature setting.\n2. The entire method is predicated on the image and text projectors ($f_P$, $g_P$) being simple linear transformations. While this holds for the original CLIP architecture, it limits the method's applicability to more complex or future multi-modal models that might employ non-linear projectors (e.g., MLPs) to increase expressive power.\n3. To handle datasets like MS-COCO where one image has five captions, the paper creates five sub-datasets and cyclically selects one during distillation to calculate the real analytic parameters. This strategy is presented without justification or comparison to alternatives. \n4. The paper identifies both $(H_{I}^{\\top}H_{I})^{-1}H_{I}^{\\top}$ and $V(V^{\\top}V)^{-1}$ as whitening operations. However, the standard definition of a whitening transform (e.g., ZCA whitening) produces data with an identity covariance matrix and typically involves the inverse square root of the covariance matrix (i.e., $(H_{I}^{\\top}H_{I})^{-1/2}$). The term $(H_{I}^{\\top}H_{I})^{-1}H_{I}^{\\top}$ is the Moore-Penrose pseudoinverse of $H_I$. While it does decorrelate the data, its properties are not identical to a full whitening transformation."}, "questions": {"value": "Rebuttal questions:  \n1. The paper's core theoretical leap is replacing the standard InfoNCE contrastive loss with a least-squares objective i.e., $\\mathcal{L}_{MCL}$. What is the theoretical or empirical justification for this simplification? Why should this least-squares objective be considered a valid proxy for the InfoNCE loss, whose performance is known to be highly sensitive to $\\tau$ and the number of negative samples?\n2. In Section 3.1, the authors derive a clean analytic solution (Eq. 5) . However, in Section 3.2, the authors introduce a significantly more complex objective (Eq. 7) based on matching centered covariance matrices, citing instabilities like embedding shift, scale explosion, and rank deficiency. Were these instabilities empirically observed? Could you quantify the performance degradation when matching the simpler Eq. 5 directly? The jump in complexity from Eq. 5 to Eq. 7 feels substantial and requires strong justification.\n3. For datasets like Flickr-30k and MS-COCO, the authors handle the 1:5 image-to-caption ratio by creating five sub-datasets and cyclically selecting one sub-dataset to compute the real analytic parameters. What was the motivation for this specific cyclic strategy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics review needed."}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "tbQWvI5L4M", "forum": "Fxz0aaGSNY", "replyto": "Fxz0aaGSNY", "signatures": ["ICLR.cc/2026/Conference/Submission735/Reviewer_kpau"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission735/Reviewer_kpau"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission735/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761027060948, "cdate": 1761027060948, "tmdate": 1762915592826, "mdate": 1762915592826, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces APM, a novel and efficient framework for multi-modal dataset distillation. Unlike prior trajectory-matching-based MDD methods that require storing many model checkpoints and performing costly double backpropagation, APM directly aligns analytic parameters of linear modal projectors between real and synthetic datasets. This approach eliminates the need for trajectory storage and bi-level optimization, significantly improving scalability and efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The analytic parameter matching formulation is a creative alternative to trajectory matching, offering a new theoretical and algorithmic perspective on MDD by connecting it with matrix whitening.\n2. APM addresses major scalability and efficiency bottlenecks in multi-modal dataset distillation, achieving substantial computational and storage reductions while maintaining or improving performance. This has high practical relevance for large-scale multimodal learning."}, "weaknesses": {"value": "1. Main concern: APM assumes linear modal projectors (e.g., CLIP-style architectures). Extending it to nonlinear or generative models remains an open challenge, which slightly limits its general applicability.\n2. While results on Flickr30k and MS-COCO are strong, additional evaluation on more diverse multi-modal domains (e.g., video–text or audio–text) could better demonstrate generality.\n3. The paper could provide deeper analysis of why APM performs better under small budgets, and explore whether whitening-based isotropy fully explains the performance gains."}, "questions": {"value": "see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "USdDSAT5CR", "forum": "Fxz0aaGSNY", "replyto": "Fxz0aaGSNY", "signatures": ["ICLR.cc/2026/Conference/Submission735/Reviewer_qAEJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission735/Reviewer_qAEJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission735/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761731053084, "cdate": 1761731053084, "tmdate": 1762915592660, "mdate": 1762915592660, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a novel Analytic Parameter Matching (APM) framework for multi-modal dataset distillation, which replaces traditional bi-trajectory matching with a direct analytic alignment of modal projectors. This approach is both original and practical, as it eliminates the need for storing multiple checkpoints and performing double backpropagation, thereby achieving substantial gains in computational and storage efficiency. The approach is theoretically grounded, as the authors derive a closed-form solution for linear projectors and demonstrate its equivalence to matrix whitening, offering a clear statistical interpretation of the method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The method is theoretically well-grounded: the authors derive a closed-form solution for linear projectors and establish its equivalence to matrix whitening, offering a clear statistical interpretation of the proposed formulation.\n\n* Empirically, APM demonstrates strong performance and scalability across Flickr30k and MS-COCO, achieving up to 65$\\times$ reduction in storage and 9.6$\\times$ speed-up compared to the previous work while maintaining competitive retrieval accuracy. Overall, the work combines theoretical clarity, implementation simplicity, and practical significance, providing a meaningful advance toward efficient multi-modal data distillation."}, "weaknesses": {"value": "* While the proposed framework is elegant and efficient, it relies heavily on the assumption of linear modal projectors. This restricts its applicability to modern multi-modal models that employ non-linear or attention-based projection mechanisms.\n* The comparison is limited to trajectory-based distillation baselines such as LoRS and RepBlend. The paper omits recent generative distillation approaches, notably EDGE [1], which also address efficiency and scalability through generative priors.\n\n[1] Zhao, Zhenghao, et al. \"Efficient Multimodal Dataset Distillation via Generative Models.\" arXiv e-prints (2025): arXiv-2509."}, "questions": {"value": "* (with W1)\nSince the analytic formulation assumes linear projectors, could the authors discuss whether APM can generalize to a simple non-linear setting, for example, one involving a single activation layer?\n* (with W2)\nAs EDGE also demonstrates an efficient distillation process, could the authors provide an explicit comparison between EDGE and APM in Tables 1 and 2?\n* The evaluation currently focuses exclusively on cross-modal retrieval. It would be informative to test APM-distilled datasets on other downstream tasks, such as VQA or zero-shot classification on different datasets, to further assess their semantic generalization capability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "urIflEoill", "forum": "Fxz0aaGSNY", "replyto": "Fxz0aaGSNY", "signatures": ["ICLR.cc/2026/Conference/Submission735/Reviewer_q6bY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission735/Reviewer_q6bY"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission735/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761805293660, "cdate": 1761805293660, "tmdate": 1762915592522, "mdate": 1762915592522, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response from Authors"}, "comment": {"value": "We thank all reviewers for the valuable feedback and suggestions. We have addressed most of the questions and suggestions in the revised paper (highlighted in blue). \n\nWe respond to the common concerns here and reply to individual reviewers for other questions.\n\n&nbsp;\n\n> **Exploring non-linearity in APM**\n\nIn the revision, we provide a new theoretical analysis of the non-linearity in multi-modal contrastive learning. We give the detailed proofs in **Appendix B** and briefly introduce the conclusions below.\n\n&nbsp;\n\n``Conclusion 1: InfoNCE loss with softmax activation has similar analytic solutions with regression loss``\n\nInfoNCE loss is widely used in multi-modal contrastive learning, and we simplify it into a regression loss $||UV^{\\top} - I||$, which has analytic solutions. Now, we can also obtain the analytic parameters of InfoNCE. Below is the derivation process.\n\n- Previous literature [1, 2] gives the analytic solution of a linear layer with softmax activation in the multi-class classification task. Specifically, the probability that a sample belongs to a certain class is defined as: $p(i|x) = \\frac{\\exp(xw_i^{\\top} + b_i)}{\\sum_{i=1}^{k} \\exp(xw_i^{\\top} + b_i)},$ where $x$ is the sample, and $w_i$ and $b_i$ denote the weight and bias of the $i$-th class, respectively. The analytic solutions of $w_i$ and $b_i$ are defined as:\n$$w_i = \\mu_i \\Sigma^{-1}, \\quad b_i = {\\ln p_i} - \\frac{1}{2}\\mu_i \\Sigma^{-1} \\mu_i^{\\top},$$ where $p_i$ is the ratio of the $i$-th class, $\\mu_i$ is the mean value of the data embeddings in the $i$-th class, and $\\Sigma = \\hat{\\Sigma} + \\hat{\\mu}^{\\top}\\hat{\\mu} + \\sum_i p_i \\mu_i^{\\top} \\mu_i.$ ($\\hat{\\mu}$ and $\\hat{\\Sigma}$ denote the mean and covariance of $x$)\n\n- The InfoNCE loss $\\mathcal{L}\\_{\\text{NCE}}= - \\sum_i \\log \\frac{\\exp(u_i v_i^{\\top}/\\tau)}{\\sum_{j=1}^{M} \\exp(u_i v_j^{\\top}/\\tau)}$ can also be viewed as a multi-class classification function, where each pair is a class. In this case, **$u_i$ can be seen as the sample and $v_i^{\\top}$ denotes the weight in the $i$-th class.** Therefore, we can directly obtain their analytic solutions:\n$$U^* = \\frac{1}{\\tau} V \\Sigma_V^{-1}=\\frac{N}{2\\tau}V(V^{\\top}V)^{-1}, \\quad V^* = \\frac{1}{\\tau} U \\Sigma_U^{-1} = \\frac{N}{2\\tau} U(U^{\\top}U)^{-1}.$$\n\n- On the other hand, the analytic solution of the regression loss is defined as:\n$$U^* = V(V^{\\top}V)^{-1}, \\quad V^* = U(U^{\\top}U)^{-1}.$$\n\nWe can observe that the analytic parameters of InfoNCE and regression loss are similar, the difference being a scaling constant $\\frac{N}{2\\tau}$.\n\n&nbsp;\n\n``Conclusion 2: Non-linear projectors also have analytic parameters``\n\nFor the non-linear projectors $U=\\sigma(H_IW_I)$ and $V=\\sigma(H_TW_T)$, we have $\\sigma(H_IW_I)=V(V^{\\top}V)^{-1}$ and $\\sigma(H_TW_T)=U(U^{\\top}U)^{-1}$.\n\nSince we have obtained the optimal results of $U$ and $V$, and the activation $\\sigma$ is an element-wise function, we can directly use its inversion function to calculate the analytic parameters:\n$$W_I^* = (H_I^{\\top}H_I)^{-1}H_I^{\\top} \\sigma^{-1}(V(V^{\\top}V)^{-1}), \\quad W_T^* = (H_T^{\\top}H_T)^{-1}H_T^{\\top} \\sigma^{-1}(U(U^{\\top}U)^{-1}).$$\n\nWe list some commonly used activation functions and their inverses below.\n\n| Activation |  $\\sigma(x)$ | $\\sigma^{-1}(y)$ |\n|-----------|--------------|------------------|\n| **Sigmoid** | $$\\sigma(x)=\\frac{1}{1+e^{-x}}$$ | $$\\sigma^{-1}(y)=\\ln \\left(\\frac{y}{1-y}\\right)$$ |\n| **Tanh** | $$\\sigma(x)=\\tanh(x)=\\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}$$ | $$\\sigma^{-1}(y)=\\operatorname{arctanh}(y)=\\frac{1}{2}\\ln \\left(\\frac{1+y}{1-y}\\right)$$ |\n| **LeakyReLU** | $$\\sigma(x)=\\begin{cases}x, & x\\ge 0 \\\\\\\\ \\alpha x, & x<0\\end{cases}$$ | $$\\sigma^{-1}(y)=\\begin{cases}y, & y\\ge 0 \\\\\\\\ y/\\alpha, & y<0\\end{cases}$$ |\n\n[1] [Does logistic regression have an analytical solution?](https://spaces.ac.cn/archives/8578)\n\n[2] [Easy Logistic Regression with an Analytical Solution](https://towardsdatascience.com/easy-logistic-regression-with-an-analytical-solution-eb4589c2cd2d/)"}}, "id": "4wIxe5gIbs", "forum": "Fxz0aaGSNY", "replyto": "Fxz0aaGSNY", "signatures": ["ICLR.cc/2026/Conference/Submission735/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission735/Authors"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission735/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763706139689, "cdate": 1763706139689, "tmdate": 1763706139689, "mdate": 1763706139689, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an efficient method for multimodal dataset distillation by bypassing double backpropagation computation. This was achieved by leveraging an analytic solution of the image/text projection head of the vision-language model."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "- Simple, novel, and reasonable method \n  - The proposed method is conceptually simple and novel, and nicely addresses the efficiency issue of existing methods by leveraging an analytic solution.\n- Insightful experiments\n  - The authors provide experiments on the standard benchmark suite as well as interesting analysis on SVD entropy, trying to validate their method on multiple perspectives."}, "weaknesses": {"value": "- Reader-unfriendly presentation and weak logical flow of writing\n  - Figure 1 does not help in understanding the essence of trajectory matching and the proposed method. Even after fully reading this paper and understanding the proposed method, I don't think this figure helps a smooth introduction to naive readers. It seems like the authors' visualization was motivated by that of Figure 2 in Wu et al. 2024, but I think that visualization from Wu et al. 2024 is also not that informative. It would be better to add more annotations, as done in Figure 3 of Cazenavette et al. 2022. And the author should emphasize how their method is different from the trajectory matching.\n  - In line 073, the authors mentioned the double backpropagation issue of the previous method without any short description of what it means. Since the core contribution of this work is addressing that problem, I think the authors should elaborate on what the double backpropagation is from the introduction (at least briefly). Although they mentioned that in L134 again, the detail is missing -- please elaborate on one backprop for what, and another one for what.\n  - In line 144, \"propose to align the optimal parameters\" align between which parameters? -- It would be better to explicitly spell out (e.g., align the optimal parameters of the model trained on real and the model trained on synthetic).\n  - In line 175, \"cosine similarity for searching, which requires an isotropic distribution\" -- this is not true. Cosine similarity-based retrieval itself does not require anything, but the authors say as if it is a necessary property.\n  - In line 187, \"As the modal projectors contain whitened embeddings, ..., as a surrogate of MDD.\"\n    - Since the modal projectors are just conceptual components, the authors should specify them further, like \"As the optimal solution parameters of the modal projectors contain ~\"\n    - a surrogate of MDD? This is also a very imprecise expression --> Surrogate of [XXX] in MDD would be a better expression where [XXX] can be the entire model parameters, something like that.\n  - In Section 3.2, the authors point out that the derived analytic solution in Eq. (5) does not truly achieve the whitening due to the lack of zero mean centering. Then, why do they pretend that it is whitening in Eqs (5) and (6)? It would be better the carefully mention this subtle difference in advance.\n- Limited scope of validation, their effectiveness, and reliability\n  - As the authors mentioned in L107, the goal of dataset distillation is to achieve comparable performance to the original dataset with far fewer samples. However, they do not provide a comparison with the full dataset results done in Cazenavette et al. 2022.\n  - This makes it hard to infer how significantly the proposed method reduces the performance gap between the existing methods and the upper bound method (full dataset).\n  - It is worth noting that the authors borrow performance metrics of baseline methods in Table 7 (scalability experiments with 1000 and 2000 data pairs) from a previous work.\n  - Compared to the performance obtained from the 500 data pairs in Table 2, which the authors might reproduce themselves, 1000 pairs and 2000 pairs cases in Table 7 show poorer performance of LoRS. Therefore, the reliability of Table 7 results is questionable.\n- Lack of discussion on the methodology design\n  - The authors made a lot of tweaks to derive their loss $\\mathcal{L}_{APM}$ from the true analytic solution in Eq. (5).\n  - However, they do not discuss how this tweak makes the proposed final loss term $\\mathcal{L}_{APM}$ deviate from the original analytic solution, and why it is still valid to be used as a proxy of an iterative optimization-based solution.\n- Lack of discussion on the observed performance\n  - In Table 2 at a 500-pairs setup, the proposed method underperforms a competitive baseline, but the authors do not provide a detailed discussion on why their proposed method shows limited data size scalability compared to RepBlend.\n  - As Table 7 does not contain RepBlend, I am further speculating on the scalability of APM compared to RepBlend.\n\n\n---\n\n> Reference\n\n- Cazenavette et al. 2022. \"Dataset Distillation by Matching Training Trajectories\"\n- Wu et al. 2024. \"Vision-Language Dataset Distillation\""}, "questions": {"value": "See the weaknesses section, please.\n\nIf there is any misunderstanding from me, feel free to point out."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lAeP2Kcz8H", "forum": "Fxz0aaGSNY", "replyto": "Fxz0aaGSNY", "signatures": ["ICLR.cc/2026/Conference/Submission735/Reviewer_teJU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission735/Reviewer_teJU"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission735/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982437668, "cdate": 1761982437668, "tmdate": 1762915592320, "mdate": 1762915592320, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Analytic Parameter Matching (APM), a new framework for efficient multi-modal dataset distillation (MDD). Instead of aligning entire optimization trajectories between expert and student models, APM directly matches the analytic parameters of linear modal projectors in CLIP-style models. This design removes the need for trajectory storage and double backpropagation, cutting both storage and computation costs. The authors connect these analytic parameters to matrix whitening, showing they improve the alignment across modalities. Empirically, APM achieves large efficiency gains while maintaining or improving performance over prior MDD methods on benchmarks like Flickr30k and MS-COCO."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed APM method reduces both computational and storage costs by eliminating trajectory storage and double backpropagation, achieving impressive speedup and compression ratios.\n\n- The authors provide an analytic formulation linking APM to matrix whitening, offering intuitive insight into why the method improves cross-modal isotropy and alignment. APM achieves strong empirical results across multiple datasets and model architectures.\n\n- The method scales to larger synthetic datasets and demonstrates strong cross-architecture generalization, highlighting robustness and practicality for real-world multi-modal distillation tasks."}, "weaknesses": {"value": "- The method primarily focuses on linear projectors e.g., CLIP-style models, which may limit its applicability to architectures with non-linear projection heads or more complex fusion mechanisms.\n\n- The experiments are limited to cross-modal retrieval; the work does not explore other multi-modal downstream tasks such as captioning to test broader generalization.\n\n- The paper could provide more discussion on potential trade-offs when applying to more complex datasets."}, "questions": {"value": "How well does APM generalize to multi-modal models with non-linear or transformer-based projection heads, where analytic parameter computation may not be straightforward?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RKxrjPDPSJ", "forum": "Fxz0aaGSNY", "replyto": "Fxz0aaGSNY", "signatures": ["ICLR.cc/2026/Conference/Submission735/Reviewer_P2Ji"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission735/Reviewer_P2Ji"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission735/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762122830122, "cdate": 1762122830122, "tmdate": 1762915592186, "mdate": 1762915592186, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}