{"id": "6KxnHj50uQ", "number": 15331, "cdate": 1758250343413, "mdate": 1759897313178, "content": {"title": "NeuroSketch: An Effective Framework for Neural Decoding via Systematic Architectural Optimization", "abstract": "Neural decoding, a critical component of Brain-Computer Interface (BCI), has recently attracted increasing research interest. Previous research has focused on leveraging signal processing and deep learning methods to enhance neural decoding performance. However, the in-depth exploration of model architectures remains underexplored, despite its proven effectiveness in other tasks such as energy forecasting and image classification. In this study, we propose NeuroSketch, an effective framework for neural decoding via systematic architecture optimization. Starting with the basic architecture study, we find that CNN-2D outperforms other architectures in neural decoding tasks and explore its effectiveness from temporal and spatial perspectives. Building on this, we optimize the architecture from macro- to micro-level, achieving improvements in performance at each step. The exploration process and model validations take over 5,000 experiments spanning three distinct modalities (visual, auditory, and speech), three types of brain signals (EEG, SEEG, and ECoG), and eight diverse decoding tasks. Experimental results indicate that NeuroSketch achieves state-of-the-art (SOTA) performance across all evaluated datasets, positioning it as a powerful tool for neural decoding.", "tldr": "We propose an effective framework, NeuroSketch, for neural decoding via systematic architectural optimization.", "keywords": ["Neural Decoding", "Architectural Optimization", "Brain Signals"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/35ab2a20c0758844a1e30c110da00efc83858789.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces NeuroSketch, a framework for neural decoding tasks achieved via systematic architectural optimization. The authors investigate various neural network backbones (CNNs, GRUs, Transformers, hybrids) in detail, perform macro- and micro-level optimizations (e.g., latent space transformations, convolutional choices), and gradually distill these principles into the NeuroSketch design, which is an enhanced CNN-2D-based model. NeuroSketch is validated on eight neural decoding tasks spanning three modalities (speech, visual, auditory), three signal types (EEG, SEEG, ECoG), and is shown to outperform a suite of state-of-the-art baselines across multiple datasets and tasks."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. This study presents a comprehensive evaluation, validating the proposed model across eight datasets and three distinct recording modalities: EEG, sEEG, and ECoG.\n\n2. After extensive tuning of model hyperparameters, the model surpasses other models.\n\n3. The authors provide open-source reproducibility commitments and dataset transparency."}, "weaknesses": {"value": "1. The implementation details of baselines are missing. The performance of Conformer on Du-IN in Table 4 significantly underperforms the reported value in the Du-IN paper. We need specific details of the baseline implementation to ensure the reliability of the conclusions of the overall work and fair comparison.\n\n2. The CNN-2D introduces translation invariance, which seems to be uncommon in brain signal modeling. It would be useful to include more analysis about the features obtained by the models (e.g., spatial locality), helping us understand the effectiveness of CNN-2D-based BCIs.\n\n3. The framework appears largely a product of empirical exploration, with each step optimized via benchmark wins (cf. Table 2 and Table 3). While this is valuable, the paper does not elevate its findings to generalizable new principles for neural decoding. For example, the manner in which CNN-2D exploits spatial locality is discussed but not quantified, and the underlying reason for Transformer's poor performance isn’t deeply analyzed or theoretically unpacked. The reader is left with “what works” but not always “why” -- limiting the scientific insight provided."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AxEtzGfBI8", "forum": "6KxnHj50uQ", "replyto": "6KxnHj50uQ", "signatures": ["ICLR.cc/2026/Conference/Submission15331/Reviewer_q1SR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15331/Reviewer_q1SR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760777110917, "cdate": 1760777110917, "tmdate": 1762925626549, "mdate": 1762925626549, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a framework for systematic architecture optimisation. Starting with exploring various model types and then with the best design going to a macro-micro-analysis, the paper introduces a model with competitive performance compared to other deep and foundation model baselines."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper is well-structured and it follows a nice step-by-step analysis on how specific details were implemented in the final architecture. It’s the first time I see an analysis like this one. Most papers just introduce a new architecture without any design justifications."}, "weaknesses": {"value": "The paper fails to provide more comparisons with better models (deep learning and foundation models). In addition, although thorough the analysis does not provide interpretable insights behind the choices.\n\nWriting:\nPaper is well-written and good structured.\n\nOverall:\nThe paper shows some merits but it would be vital to have my questions answered."}, "questions": {"value": "1. I wonder if the initially tested architectures - like CNN or transformer - get deeper or if more / less data is used during training for each model (for example, transformer based models need more data), would that affect the initial observations ?\n2. How about other more compact advanced deep baselines like EEGInception and Brainwave scattering net in table 4?\n3. How about other foundation models like LaBraM, NeuroGPT, EEGPT etc. in table 4 ? It seems the foundation models section is not very well represented. \n4. How about the number of parameters of these models as well  ? Any relationship between the number of parameters and performance ?\n5. Is there any actual meaning behind the design choices ? For example, EEGNet provides interpretable insights. In other words, is it just black box or is there an actual neurological meaning why these design choices do work?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hMaAqU95Lu", "forum": "6KxnHj50uQ", "replyto": "6KxnHj50uQ", "signatures": ["ICLR.cc/2026/Conference/Submission15331/Reviewer_s4VP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15331/Reviewer_s4VP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761619084068, "cdate": 1761619084068, "tmdate": 1762925626236, "mdate": 1762925626236, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces NeuroSketch, a neural decoding framework that enhances the performance of decoding multiple types of brain signals (EEG, SEEG, ECoG) through systematic architectural optimization—from basic architecture selection to macro- and micro-level structural improvements. The authors conducted over 5,000 experiments across eight tasks (covering visual, auditory, and speech modalities), demonstrating that NeuroSketch achieves state-of-the-art (SOTA) performance on multiple benchmarks. The core contribution of this framework lies in its ability to model the spatiotemporal characteristics of brain signals, with step-by-step optimizations showing consistent performance gains."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Systematic Architectural Exploration with a Clear Optimization Path:\nThe paper begins with a comparison of basic architectures (CNN-1D/2D, GRU, Transformer, etc.) and progressively delves into macro (latent space transformation) and micro (convolution operation optimization) levels of design. This forms a complete and logically rigorous optimization roadmap, offering high interpretability and methodological value.\n\n2. Large-Scale, Multi-Modal Experimental Validation:\nExtensive validation was performed across three modalities (visual, auditory, speech), three brain signal types (EEG, SEEG, ECoG), and eight tasks. The experimental scale is substantial (over 5,000 experiments), making the results highly credible and demonstrating strong generalization capability.\n\n3. Tailored Modeling of Brain Signal Characteristics:\nThe work explicitly addresses the transient temporal dynamics and spatial locality inherent in neural decoding tasks. Designs such as CNN-2D, group convolution, and early downsampling (Pagoda approach) effectively capture these characteristics, reflecting a deep understanding of the nature of neural signals.\n\n4. Effective Balance Between Computational Efficiency and Performance:\nThe optimization process considers not only performance improvement but also computational cost (e.g., GFLOPs comparison). Proposed strategies like the Step approach, Pagoda approach, and Group Convolution significantly reduce computational burden while maintaining or even improving performance."}, "weaknesses": {"value": "1. Lack of Discussion on Neurophysiological Interpretability:\nAlthough the model performs excellently, the paper does not deeply analyze whether the neural representations learned by NeuroSketch are interpretable from a neuroscience perspective (e.g., correspondence to brain region activation or cognitive processes). This is an important dimension in BCI research.\n\n2. Insufficient Comparison with Some Existing Neural Decoding-Specific Models:\nWhile comparisons are made against several general time-series models and some brain-specific models, the comparison with certain recent architectures specifically designed for EEG/SEEG [1,2] is not comprehensive enough. This might fail to fully demonstrate its advantages over the best methods in the field.\n\n3. Insufficient Exploration of Multi-Modal Fusion and Cross-Modal Generalization:\nAlthough tested on multiple modalities, the paper does not explore the model's generalization ability across modalities (e.g., transferring a model trained on visual tasks to auditory tasks), nor does it attempt multi-modal fusion decoding, which holds significant value for future BCI systems.\n\n4. Inadequate Analysis of Individual Differences and Cross-Subject Generalization:\nAlthough experiments were conducted on data from different subjects, the systematic analysis of the model's ability to handle individual differences and its cross-subject decoding capability is relatively limited. Results for cross-subject unified training or adaptation strategies are not provided.\n\n5. Ablation Studies are Not Comprehensive Enough:\nAlthough the step-by-step optimization process is presented, a systematic ablation study on the independent contribution of each component in the final NeuroSketch model (e.g., GeM pooling, residual connections) is lacking. This makes it difficult to judge the specific impact of each part on the final performance.\n\n**References:**\n\n[1] Singh, A., Thomas, T., Li, J., Hickok, G., Pitkow, X., & Tandon, N. (2025). Transfer learning via distributed brain recordings enables reliable speech decoding. *Nature Communications, 16*(1), 8749.\n\n[2] Chen, X., Wang, R., Khalilian-Gourtani, A., Yu, L., Dugan, P., Friedman, D., ... & Flinker, A. (2024). A neural speech decoding framework leveraging deep learning and speech synthesis. *Nature Machine Intelligence, 6*(4), 467-480."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics concerns are apparent. The public datasets are used appropriately."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GTQbD81OKX", "forum": "6KxnHj50uQ", "replyto": "6KxnHj50uQ", "signatures": ["ICLR.cc/2026/Conference/Submission15331/Reviewer_jvHa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15331/Reviewer_jvHa"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761821523615, "cdate": 1761821523615, "tmdate": 1762925625853, "mdate": 1762925625853, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}