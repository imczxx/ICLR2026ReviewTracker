{"id": "RI3SmeizL2", "number": 6833, "cdate": 1757997286883, "mdate": 1759897890237, "content": {"title": "Guaranteed Bounding Meshes Extraction from Neural Implicit Surfaces via Neural Network Verification", "abstract": "Geometric queries on neural implicit surfaces, such as ray tracing and collision detection, present a significant challenge since they require explicit spatial reasoning over neural networks. This work addresses this challenge by connecting these geometric queries to neural network verification problems. Inspired by the state-of-the-art neural verification tools, we propose a new framework utilizing linear bound propagation-based verifiers to solve these queries in real time, enabling applications such as real-time rendering and physics simulation with soundness guarantees. Instead of naively running neural network verifiers on-the-fly, we first classify a 3D input domain into multiple regions of interest, which can then assist in subsequent verifications. We achieve this objective by constructing explicit bounding volumes and then leveraging linear bounds generated by SOTA neural network verifiers to guide the generation of \\emph{sound piecewise linear bounding meshes}. In this paper, we propose Guaranteed Inner-and-Outer Meshes (GIOM), which can serve as bounding volumes and merge seamlessly with existing explicit geometry processors to accelerate queries on neural implicits. As tight and \\emph{sound} bounding meshes, GIOM enables accelerated neural SDF queries without sacrificing quality. With GIOM, we develop accelerated neural implicit ray casting, collision detection, and constructive solid geometry methods (CSG), achieving up to a 300\\% speedup in real-time rendering, a 500\\% speedup in physics simulation, and an optimization-free neural CSG procedure. \nExperiments show that GIOM significantly outperforms existing methods in the speed-quality trade‑off.", "tldr": "", "keywords": ["Neural Verification", "Bounding Volume", "Rendering", "Simulation"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/431c52d2d8b1ea3490b41c7b4e2a2e5f513a2a3e.pdf", "supplementary_material": "/attachment/e6a8faaf98289f6c8de3061095ec4dcaf94683e8.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes Guaranteed Inner-and-Outer Meshes (GIOM), a new algorithm for computing bounding meshes for neural implicit surfaces (especially neural signed distance functions (SDFs)). They treat SDF queries as neural network verification problems, enabling the use of CROWN, a linear bound propagation method, to compute affine upper and lower bounds on the SDF output over voxel regions. As a result, the method can obtain an explicit mesh representation that (1) guarantees correctness, (2) adapts to surface complexity, and (3) integrates directly with traditional mesh-based rendering and physics engines.\n\nGIOM is demonstrated on three tasks: neural rendering, collision detection, and constructive solid geometry (CSG). It shows up to 3× faster rendering, 5× faster physics simulation, and 10× lower reconstruction error in CSG compared to baselines such as Adaptive Shells, Spelunking the Deep, and CSG-nSDF."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper introduces a novel perspective by framing geometric queries on neural implicit surfaces as neural network verification problems, which in turn leads to the subsequent proposed GIOM algorithm.\n- The paper is technically sound. It offers a clear mathematical derivation of how affine upper and lower bounds (from CROWN-style linear bound propagation) can be used to construct certified inner and outer meshes.\n- The empirical results are strong. It demonstrates three applications in neural rendering, physics-based collision detection, and constructive solid geometry (CSG), and achieves significant performance gains in all cases.\n- Finally, the paper is also well-written and easy to follow."}, "weaknesses": {"value": "- While the paper reports timing metrics such as FPS for rendering and milliseconds per frame for physics simulation, it omits the time required to construct the inner and outer meshes. When the underlying network of the implicit surfaces is MLPs, which is very common, each voxel’s bound computation entails a full backpropagation through the entire network. This step can become computationally expensive if the network is deep or if many voxels require refinement, and may result in higher costs in total than direct forward queries.\n\n- The idea of representing an object as multiple surfaces is not rare in literature and can be further discussed in the related works. For example, in [1][2][3].\n\n- If I am understanding correctly, CROWN’s linear relaxation could still potentially result in loose bounds (maybe for highly nonlinear or deep architectures), and there are only theoretical guarantees for the correctness of the bounds but not the tightness. It would be valuable to include an ablation showing how the error varies with subdivision depth. \n\n- In addition, no explicit failure cases are shown where GIOM’s bounds might degrade or where the linear approximation becomes visually noticeable. A discussion of such scenarios would improve completeness without undermining the paper’s overall contributions.\n\n[1] Esposito et. al. Volumetric Surfaces: Representing Fuzzy Geometries with Layered Meshes\n\n[2] Wang et. al. A Simple Approach to Differentiable Rendering of SDFs\n\n[3] Seyb etl. al. From microfacets to participating media: A unified theory of light transport with stochastic geometry"}, "questions": {"value": "- Do the MLPs used in the paper include positional encodings (e.g. fourier or sinusoidal embedding)? If not, supplementing these features would be important for evaluating real-case implicit surfaces.\n\n- Could the authors report the actual time and memory consumption for the construction of the meshes before downstream applications?\n\n- How does GIOM compare in terms of time and memory with classical bounding-volume hierarchies such as octrees or BVHs, which also subdivide space adaptively?\n\n- Can the authors supplement and discuss some failure cases?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "AmCl8aT4bS", "forum": "RI3SmeizL2", "replyto": "RI3SmeizL2", "signatures": ["ICLR.cc/2026/Conference/Submission6833/Reviewer_pNRh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6833/Reviewer_pNRh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6833/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761515024956, "cdate": 1761515024956, "tmdate": 1762919097108, "mdate": 1762919097108, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes to represent geometric queries for neural signed distance functions as verification problems using linear bound propagation. The objective is to compute inner and outer bounding meshes that contain the zero-level set. It does that by performing a probably very costly grid-based preprocessing (to be verified in the rebuttal discussion). The process consists of:\n\n1) Voxelizaton;\n2) Computation of two polyhedral volumes (positive and negative) for each voxel;\n2.1) Classification of voxels as positive, negative or unknown based on linear bound propagation via CROWN;\n2.2) Voxel trimming by reusing the linear bounds and performing a subdivision scheme;\n2.3) Union of all positive, negative, and unknown voxels: the polyhedral meshes are merged.\n\nThe paper also proposes a way to extract the zero-level set mesh based on the bounding meshes and shows applications in rendering, collision detection, and CSG operation."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The presentation is its stronger trait. Even though an overview image of the method is missing, it is easy to follow."}, "weaknesses": {"value": "## The contribution is incremental:\n\nSpelunking the Deep [1] first established that geometric queries on neural implicit representations can be framed as range-bound computations over the activation domain, yielding certified guarantees via affine arithmetic.\nThe proposed method extends this same conceptual formulation but replaces affine-arithmetic bounds with linear bound propagation techniques from neural network verification (CROWN-style relaxations), leading to tighter yet analogous certified bounds. While this substitution improves tightness, it remains largely consistent with the prior framework. The contribution is therefore incremental in conceptual novelty, driven mainly by deploying a more advanced bound-propagation backend.\n\n## Motivation for trading SDFs for boundary meshes\n\nThe approach proposed in the paper has an important drawback in comparison with directly applying the neural implicit SDF for the geometric queries. As pointed by the fact that the approach does not impose an eikonal regularization and that it computes the normals for rendering using finite differences, the representation loses higher order differentiability. Being able to analytically (or with autodiff) compute differential surface properties is one of the most appealing traits of neural SDFs. It is possible to compute normals and curvature directly from a SIREN [2] SDF. Grid-based approaches struggle to maintain that differentiability because they rely on voxel interpolation. If those properties are lost in the process, why would we care about training a neural SDF from a point cloud in the first place?\n\n## The preprocessing is not evaluated\n\nAs discussed in the Summary, the preprocessing of the proposed method is extensive. I am skeptical that its cost is not prohibitive. The paper mentions efficiency but I could not find any evaluation in this regard. Even if this pipeline focuses on post-training certified performance, an end-to-end runtime comparison against fast neural implicit methods (e.g., SIREN, Instant-NGP, NGLOD, BACON) would help contextualize the practicality of the approach. Shallow SIRENs are a good initial baseline (SIRENs only work with a small number of hidden layers because of the frequency composition generated by the successive multiplications of the periodic activation functions, which may introduce noise as the number of hidden layers increase). Given that the proposed method is a grid-based approach, Instant-NGP [3] is also a candidate comparison for the rendering task. It is unclear whether the proposed approach could surpass those methods since SIRENs train very fast and Instant-NGP trains instantaneously.\n\n## The evaluation lacks diversity\n\nDeveloping a little bit more on the discussion started about the preprocessing, the paper followed an evaluation approach similar from Spelunking the Deep. However, such evaluation does not sufficiently demonstrate robustness or scalability to diverse real-world shapes.. The presented examples are very simple. For more challenging examples, please see NGLOD and Instant-NGP. They evaluate the Stanford Dataset and a subset of Thingy-10k, a more diverse set of examples.\n\nThe presented average numbers can hide problems on specific SDFs. Showing per-SDF metrics would strengthen the evaluation.\n\nAdditional metrics are missing. At least the chamfer distance of the generated meshes should be presented.\n\n## Assessment\n\nThe current weaknesses are essential and numerous to be fixed in a rebuttal. This is why I recommend rejection.\n\n## References\n\n[1] Sharp, Nicholas, and Alec Jacobson. \"Spelunking the deep: Guaranteed queries on general neural implicit surfaces via range analysis.\" ACM Transactions on Graphics (TOG) 41.4 (2022): 1-16.\n\n[2] Sitzmann, Vincent, et al. \"Implicit neural representations with periodic activation functions.\" Advances in neural information processing systems 33 (2020): 7462-7473.\n\n[3] Müller, Thomas, et al. \"Instant neural graphics primitives with a multiresolution hash encoding.\" ACM transactions on graphics (TOG) 41.4 (2022): 1-15.\n\n[4] Takikawa, Towaki, et al. \"Neural geometric level of detail: Real-time rendering with implicit 3d shapes.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2021.\n\n[5] Lindell, David B., et al. \"Bacon: Band-limited coordinate networks for multiscale scene representation.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022."}, "questions": {"value": "No additional questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "RCmh2WMh2V", "forum": "RI3SmeizL2", "replyto": "RI3SmeizL2", "signatures": ["ICLR.cc/2026/Conference/Submission6833/Reviewer_JhSZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6833/Reviewer_JhSZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6833/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761604048113, "cdate": 1761604048113, "tmdate": 1762919096677, "mdate": 1762919096677, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The manuscript follows AdaptiveShell that constructs inner and outer shells which envelope an implicit surface. These shells are rasterized to identify intervals intersecting the surface, and samples are drawn within these intervals for volumetric rendering. Claimed contributions include tightening the inner/outer shells, guaranteeing the enveloping relation, introducing an adaptive split grid for mesh extraction, and demonstrating applications."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The high-level idea is reasonable: tighter bounds can reduce wasted samples.\nFigures are clear and visually compelling.\nThe motivation to tighten the bounding shells is sound."}, "weaknesses": {"value": "Writing:\n1. There are many equations used to explain the idea, but some appear to be incorrect and could severely impact understanding. For example, in Equation (5) the ≤ symbol likely should be ≥; on line 262 it should be 0, not o; and on line 277 r should be a vector, not a scalar.\n\nContribution compared with AdaptiveShell:\nThe method closely follows AdaptiveShell, and the core contributions relative to AdaptiveShell are unclear.\n1. If the contribution is ensuring the enveloping relationship between the shells and the implicit surface, then one could refine AdaptiveShell’s shells simply by moving shell grid points along SDF directions. Moreover, the error in Figure 1(b) seems caused by low mesh resolution rather than by SDF erosion/dilation itself.\n2. If the contribution is the adaptive split grid, prior work has explored similar ideas, e.g., ACORN [1], so this does not seem to be a core novelty.\n3. If the contribution is a tighter bound, Figure 1 shows regions where AdaptiveShell yields a smaller (tighter) bound, such as around the tail.\n\nExperiments:\n1. The only main difference from AdaptiveShell is how the inner/outer shells are sampled. This alone does not explain the lower PSNR in Table 2. As an extreme case, reducing the sample density within the interval would lower rendering accuracy (thus PSNR) but also reduce the number of samples, leading to faster rendering.\n2. In Figure 4, the number of sample points appears to differ greatly—possibly by more than 10×—which does not align with the reported 3× faster rendering speed.\n3. There is no ablation, such as the meshing resolution.\n\nMissing Compared Methods:\nOther methods [2-4] that accelerate rendering for implicit representations exist but are not discussed. \n\n[1] ACORN: Adaptive Coordinate Networks for Neural Scene Representation\n[2] Gaussian Frosting: Editable Complex Radiance Fields with Real-Time Rendering\n[3] Volumetric Rendering with Baked Quadrature Fields\n[4] Volumetric Surfaces: Representing Fuzzy Geometries with Layered Meshes"}, "questions": {"value": "I could be convinced if the authors address the following:\n\nWhat are the exact differences from AdaptiveShell, and why are they important? (Ablation required)\nHow does the method compare with the aforementioned approaches?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jBPMAjXfz5", "forum": "RI3SmeizL2", "replyto": "RI3SmeizL2", "signatures": ["ICLR.cc/2026/Conference/Submission6833/Reviewer_UH7b"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6833/Reviewer_UH7b"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6833/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761897682868, "cdate": 1761897682868, "tmdate": 1762919096316, "mdate": 1762919096316, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of extracting meshes from neural implicit surfaces by exploring neural network verification.\nThe key insight is that deriving formal guarantees for neural signed distance functions (SDFs) can be framed as a verification problem for neural networks [L48].\n\nThe proposed method, GIOM, accelerates SDF inference by partitioning the domain into regions using an octree-based bounding scheme. Specifically, GIOM constructs envelopes of the zero-level set through a combination of the CROWN bounding propagation method and voxelized spatial representations.\n\nThe method is evaluated on real-time rendering, collision detection, and constructive solid geometry (CSG) operations. However, the motivation for the real-time rendering task could be made clearer."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is clearly written and well structured.\n\nFigure 7 shows that GIOM significantly outperforms the CSG-nSDF baseline in terms of reconstruction speed and error, while maintaining comparable query times."}, "weaknesses": {"value": "[L88] Please clarify what is meant by the “specific sound connection” between NN verification and neural implicits.\n\n\n[L107] Note that 3D Gaussian Splatting (3DGS) does not rely on neural SDFs. Instead, related works such as SuGAR or Gaussian Pull might be more appropriate references.\n\n\n[L183] It seems GIOM learns two planes per voxel, with the zero-level set lying between them. How large does this octree representation become in practice? It seems potentially expensive, please include memory and speed comparisons.\n\n\n[L196] Clarify how  M_{-} and M_{+}​ are computed.\n\n\n[L483] ReLU-based networks may be a limiting factor. That is why all the reconstructions are low resolution piece-wise linear surfaces. This may be a major limitation.\n\n[L767] Additionally, if the proposed verification method is restricted to ReLU networks, it may limit the application of standard INR regularization terms.. For example, the derivative of a ReLU MLP is piecewise constant, preventing the use of the Eikonal constraint, which is commonly used to fit NNs as SDFs (see relevant INR works).\n\n[L108] In the “3D Modeling” section, consider citing dynamic SDF works, e.g.:\nNovello et al. “Neural Implicit Surface Evolution.” ICCV 2023.\nYang et al. “Geometry Processing with Neural Fields.” NeurIPS 2021.\nAdditionally,\nSilva et al. “Neural Implicit Mapping via Nested Neighborhoods.” arXiv 2022,\n Is a relevant preprint related to this notion of inner and outer bounds for neural isosurfaces.\n\nThe paper “Efficient Neural Network Robustness Certification with General Activation Functions” is listed twice.\n\nIs Figure 2 referenced in the text."}, "questions": {"value": "Why is there no comparison against Spelunking?\n\nHow are the neural SDF and its zero-level set shells trained?\nAre they optimized jointly, or is the shell construction a post-training step? If separate, how long does the shell computation take?\n\n\nWhy not simply extract the mesh using marching cubes and render it using standard real-time mesh-based pipelines?\n\n\nIn Eq. (3), could you evaluate the neural SDF at the octree vertices and then apply marching cubes for comparison?\n\n\nThe geometric examples are relatively simple. Consider including more complex models (e.g., Lucy, Asian Dragon, Thai Statue from the Stanford 3D Scanning Repository) to better demonstrate scalability and visual quality."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RdSyhoSnsh", "forum": "RI3SmeizL2", "replyto": "RI3SmeizL2", "signatures": ["ICLR.cc/2026/Conference/Submission6833/Reviewer_6vyi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6833/Reviewer_6vyi"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6833/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761939038901, "cdate": 1761939038901, "tmdate": 1762919095775, "mdate": 1762919095775, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}