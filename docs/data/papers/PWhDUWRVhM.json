{"id": "PWhDUWRVhM", "number": 512, "cdate": 1756743300487, "mdate": 1759898256320, "content": {"title": "Inference-Time Dynamic Modality Selection for Incomplete Multimodal Classification", "abstract": "Multimodal deep learning (MDL) has achieved remarkable success across various domains, yet its practical deployment is often hindered by incomplete multimodal data. Existing incomplete MDL methods either discard missing modalities, risking the loss of valuable task-relevant information, or recover them, potentially introducing irrelevant noise, leading to the discarding-imputation dilemma. To address this dilemma, in this paper, we propose DyMo, a new inference-time dynamic modality selection framework that adaptively identifies and integrates reliable recovered modalities, fully exploring task-relevant information beyond the conventional discard-or-impute paradigm. Central to DyMo is a novel selection algorithm that maximizes multimodal task-relevant information for each test sample. Since direct estimation of such information at test time is intractable due to the unknown data distribution, we theoretically establish a connection between information and the task loss, which we compute at inference time as a tractable proxy. Building on this, a novel principled reward function is proposed to guide modality selection. In addition, we design a flexible multimodal network architecture compatible with arbitrary modality combinations, alongside a tailored training strategy for robust representation learning. Extensive experiments on diverse natural and medical datasets show that DyMo significantly outperforms state-of-the-art incomplete/dynamic MDL methods across various missing-data scenarios. Our code will be available at https://github.com/anonymous.", "tldr": "We propose DyMo, a novel inference-time dynamic modality selection framework that adaptively selects and integrates reliable recovered modalities for each test sample, maximizing task-relevant information in incomplete multimodal data.", "keywords": ["Multimodal Learning", "Dynamic Neural Network", "Missing Modality"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/58022940a4474f4f25bd4d6342fefc6dfcb924e6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "**Summary**\nTo address the discard-fill dilemma faced by multimodal deep learning (MDL) in real-world scenarios due to modality loss， discarding the missing modality easily loses task-critical information, while filling the modality easily introduces low-fidelity/semantic misalignment noise. This paper proposes DyMo, a dynamic modality selection framework for inference, which aims to balance the utilization of missing modal information and noise avoidance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**Strength**\n1. The motivation is clear and convincing\n2. The dataset and tasks are comprehensive. It covers five significantly different datasets, digital classification, attribute classification, disease diagnosis, and missing scenarios, fully verifying DyMo's adaptability in different scenarios."}, "weaknesses": {"value": "**Weakness**\n1. The primary concern is whether the noise in cross-modal generated data actually harms, especially with the advancement of diffusion model generation technology in recent years. The author should discuss and compare his work with the related recovery-based methods[1][2][3].\n\n2. The comparison method is a bit outdated, and the author should consider comparing it with more 2024s methods of incomplete multimodal learning. \n\n3. The experiments should contain some classical multimodal datasets, such as CMU-MOSI or CREMAD, for a fair comparison. especially the CMU-MOSI, in which the text is the dominant modality, when it misses the performance degree. This can help to verify the effectiveness of the DyMo.\n\n4.The method requires the label information to select the modality, but when the modality is missing, the prediction will be very incorrect. How can the performance of the model be guaranteed? The representation prototypes also cannot avoid the problem of representations being misclassified.\n\n\n\n[1] Yuanzhi Wang.  Incomplete Multimodality-Diffused Emotion Recognition NIPS\n[2] S Wei. Mmanet: Margin-aware distillation and modality-aware regularization for incomplete multimodal learning CVPR\n[3] Yuntao Shou. GSDNet: Revisiting Incomplete Multimodality-Diffusion Emotion Recognition from the Perspective of Graph Spectrum"}, "questions": {"value": "see the weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Je4hH8aU9x", "forum": "PWhDUWRVhM", "replyto": "PWhDUWRVhM", "signatures": ["ICLR.cc/2026/Conference/Submission512/Reviewer_LF6X"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission512/Reviewer_LF6X"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission512/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761654721506, "cdate": 1761654721506, "tmdate": 1762915535356, "mdate": 1762915535356, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a Dynamic Modality selection method, DyMo, for the missing modality machine learning setting. The key insight is that existing approaches either discard missing modalities (losing valuable information) or recover all missing modalities (potentially introducing noise), creating a fundamental trade-off the authors refer to the discarding-impuattion dilemma. DyMo overcomes this by adaptively selecting only the reliable recovered modalities that provide task-relevant information for each test sample.​\n\n- Core Innovation: A Multimodal Task-Relevant Information Reward (MTIR) function that estimates incremental information gain from each recovered modality using task loss as a tractable proxy​\n\n- Theoretical connection: MTIR is based in a connection between mutual information I(Y;Z) and classification loss, enabling inference-time selection without ground-truth labels​\n\n- Evaluation: Extensive experiments on 5 datasets (PolyMNIST, MST, CelebA, DVM, UKBB) showing significant improvements, especially under severe missing scenarios​"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Strong Problem Formulation: This work substantiates discarding-imputation dilemma in incomplete multimodal learning providing a strong motivation for DyMo\n\n- Comprehensive Technical Design: MTIR reward function handles both low-fidelity and semantically misaligned recovered modalities​ (e.g. when the image is blurry or the recovered image is not representative of the class)\n\n- Strong additional features: Intra-class similarity calibration enhances reward reliability​, iterative modality selection to minimize noise, incomplete simulation training, auxiliary contrastive loss tested with 2 distance functions\n\n- Extensive Experimental Validation: Evaluation across diverse domains (natural images, medical data, synthetic benchmarks)​, Consistent improvements over 12 baseline methods​, particularly strong performance under severe missing scenarios (e.g., 13.12% improvement on PolyMNIST with 80% missing modalities)​\n\n- Thorough Analysis: Comprehensive ablation studies and visualization analyses (Figure 4 with the TSNE and PCA visualizations were particularly convincing that DyMo’s MNITR successfully adds recovered modality features when helpful and does not use them when it would hurt performance."}, "weaknesses": {"value": "- Limited Recovery Method Diversity: While claiming generalizability, experiments primarily use VAE-based recovery methods (MoPoE, MMVAE+, CMVAE from Table S5) with limited evaluation of fundamentally different recovery approaches​\n\n- Computational Overhead: The authors claim DyMo introduces minimal additional parameters and relies on a relatively simple training scheme. However, it seems give the features of the method including computing the MITR, which includes intra-class similarity calibration, and with iterative selection (average 1.38 iterations per sample from  appendix C.3), DyMo would be more computationally intensive. The inference-time latency, parameter count, or training time computational cost were not thoroughly analyzed​ in this work.\n\n- Calibration Term Limitations: The intra-class similarity calibration shows inconsistent benefits across datasets (improves some tasks but hurts CAD/Infarction performance), suggesting the approach may not be universally optimal​\n\n- Limited Analysis of Edge Cases and limitations: Insufficient discussion of common failure modes or limitations of when DyMo performs poorly or what assumptions DyMo makes."}, "questions": {"value": "- Recovery Method Dependencies: How sensitive is DyMo's performance to the quality of the underlying recovery method? Could you provide analysis on performance degradation when recovery methods produce consistently low-quality reconstructions? For example, if the recovery method always produces noise how would DyMo perform. If it produces accurate recoveries 50% of the time, how well would DyMo perform?\n\n- Computational Scalability Concerns: How does the computational overhead scale with the number of modalities and missing patterns? What is the practical upper limit for real-time applications?\n\n- Hyperparameter Sensitivity: The framework introduces several hyperparameters (temperature t=0.1, calibration threshold alhpa). How sensitive is performance to these choices, and how should they be set for new domains?\n\n- Theoretical Limitations: The mutual information lower bound assumes bounded loss values with conservative upper bound G. How is G estimated in practice, and how does this choice affect the bound's tightness?\n\n- Class Imbalance: How does DyMo perform on highly imbalanced datasets where the equal class prior assumption may be violated? Could you provide analysis or modifications for such scenarios?\n\n- Generalization Beyond Classification: While focused on classification, could this approach be extended to other multimodal tasks like regression, generation, or structured prediction? What modifications would be required?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JOOPLDawna", "forum": "PWhDUWRVhM", "replyto": "PWhDUWRVhM", "signatures": ["ICLR.cc/2026/Conference/Submission512/Reviewer_eaDt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission512/Reviewer_eaDt"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission512/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761670168212, "cdate": 1761670168212, "tmdate": 1762915535161, "mdate": 1762915535161, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles incomplete multimodal classification by explicitly framing the discarding–imputation dilemma and proposing DyMo, an inference‑time dynamic modality selection framework. The method recovers missing modalities via any recovery model, then iteratively selects only those recoveries that yield positive task‑relevant information according to a reward grounded in a connection between mutual information and cross entropy, refined with an intra‑class similarity (ICS) calibration, and implemented through a lightweight greedy procedure. The paper pairs this with a transformer‑based multimodal backbone that accepts arbitrary modality subsets and a simple incomplete‑modality simulation training scheme. Extensive experiments on five datasets (natural and medical) show consistent gains, especially at high missing rates."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- This paper perceptively identifies discarding–imputation dilemma in incomplete multimodal learning, which is an interesting and practical research problem.\n\n- Selection criterion grounded in standard MI-CE relations and rendered computable via prototype‑based energies (Eq. 5–7), yielding an interpretable \"move‑toward‑the‑prototype\" test. \n\n- Broad empirical coverage with competitive results on five datasets, strong robustness under severe missingness, and ablations demonstrating the contribution of each component. \n\n- Good practicality: recovery‑method agnostic with positive results across MoPoE/MMVAE+/CMVAE and modest extra inference steps on average."}, "weaknesses": {"value": "- Prototype posterior in Eq. 5–6 presumes Bregman divergences; the cosine distance used in $\\text{DyMo}_c$ lacks that guarantee, and the authors claim that both $\\text{DyMo}_c$ and $\\text{DyMo}_e$ achieved similar results, indicating that DyMo is robust to the choice of distance metric. However, as shown in the results of Table 1, the performance of  $\\text{DyMo}_c$ and $\\text{DyMo}_e$ across different settings (datasets/missing rates/metrics) does not seem to be consistent. \n\n- Sub-optimality of the greedy strategy: The algorithm relies on a greedy approach, selecting at each step the single modality that currently yields the highest reward. This strategy cannot guarantee finding the optimal combination of all missing modalities. There can be scenarios in which adding modality A alone is less beneficial than adding modality B, yet adding the combination of modalities A and C yields far greater gains than adding B alone. The effect of this kind of modality synergy can be significant in different medical imaging modalities. A greedy selection would overlook such combinatorial effects, leading to a sub-optimal subset of modalities.\n\n- The author acknowledges that TIP has an upper limit for full-table reconstruction and uses this to explain why it performs on par with or worse than CONCAT in certain scenarios. However, this means that the \"selection strategy\" capability becomes strongly constrained by the reconstruction quality bottleneck. I highly recommend to include at least one alternative reconstructor in DVM/UKBB."}, "questions": {"value": "- Could the authors provide a more in-depth analysis of the choice of distance metric, either theoretical or empirical?\n\n- Please justify the selection of the greedy approach.\n\n- Would the selection mechanism remain effective independent of the chosen reconstructor?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Nf1dfVcDyp", "forum": "PWhDUWRVhM", "replyto": "PWhDUWRVhM", "signatures": ["ICLR.cc/2026/Conference/Submission512/Reviewer_V4dA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission512/Reviewer_V4dA"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission512/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977174025, "cdate": 1761977174025, "tmdate": 1762915534982, "mdate": 1762915534982, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles incomplete multimodal classification. It introduces an inference-time dynamic modality selection framework that (i) reconstructs missing modalities with an external recovery model, then (ii) selects only the “reliable” reconstructions to fuse with available modalities. The key idea is a multimodal task-relevant information reward (MTIR) as a proxy for information gain, plus a latent-space metric calibration to guard against low-fidelity reconstructions. Experiments show gains over both recovery-free and recovery-based baselines, especially in severe missingness."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Clear problem framing (“discarding–imputation dilemma”) and a practical angle: selecting only useful reconstructions instead of always discarding or always imputing.\n2. The method is grounded in an information-theoretic heuristic that links mutual information and cross-entropy\n3. The method has flexible architecture and straightforward training recipe. \n4. Experiments cover five datasets and multiple missing-modality regimes. Reported gains are meaningful in high-missingness settings."}, "weaknesses": {"value": "1. Loose MI–CE bound.\n(a) Heuristic bound. The proposed lower bound linking task-relevant information I(Y;Z) to the empirical CE loss is very loose and largely heuristic. The bound involves constants G, yet G can be arbitrarily large since the CE loss is unbounded in practice. As a result, the lower bound can collapse to a small or even meaningless value. Moreover, a reduction in CE loss does not necessarily imply increased mutual information.\n(b) Dataset-level rather than per-sample validity.\nThe high-probability guarantee in the bound applies to the randomness of the training dataset \\mathcal{D}, not to individual test samples. It does not provide theoretical support for the per-sample reward computation used during inference without many further assumptions.\n\n2. Dependency on recovery quality.\nDyMo’s selection quality depends entirely on the fidelity of recovered modalities. When all reconstructions are poor, the model effectively reverts to observed modalities while still incurring extra inference cost. \n\n3. Task scope.\nThe method is evaluated for classification. Since many multimodal applications are detection/segmentation/seq-to-seq, a short discussion of what’s needed to extend MTIR beyond CE classification would strengthen the impact."}, "questions": {"value": "1. In Section 3.1, could the “dummy token” embeddings still introduce bias into positional encodings if not learned or masked carefully?\n\n2. In Section 3.2, the computation of class prototypes as arithmetic means assumes locally Euclidean and unimodal feature geometry. This assumption may not hold in practice. Could you provide statistics or visualizations showing that class cluster means are representative?\n\n3. Why model intra-class distances with a truncated normal distribution? Heavy-tailed or multi-modal classes may violate it. Have you explored nonparametric alternatives (e.g., kernel density) to avoid this assumption? Is there empirical evidence that ICS meaningfully quantifies the representativeness of z within its class cluster?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XxAR1Q8Uto", "forum": "PWhDUWRVhM", "replyto": "PWhDUWRVhM", "signatures": ["ICLR.cc/2026/Conference/Submission512/Reviewer_orCx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission512/Reviewer_orCx"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission512/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762156143428, "cdate": 1762156143428, "tmdate": 1762915534878, "mdate": 1762915534878, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}