{"id": "Wt6K1uoMPQ", "number": 14005, "cdate": 1758226754079, "mdate": 1759897396845, "content": {"title": "Deep Positive-Unlabeled Anomaly Detection for Contaminated Unlabeled Data", "abstract": "Semi-supervised anomaly detection has attracted attention,\nwhich aims to improve the anomaly detection performance by using a small amount of labeled anomaly data in addition to unlabeled data.\nExisting semi-supervised approaches assume that most unlabeled data are normal,\nand train anomaly detectors by minimizing the anomaly scores for the unlabeled data\nwhile maximizing those for the labeled anomaly data.\nHowever, in practice, the unlabeled data are often contaminated with anomalies.\nThis weakens the effect of maximizing the anomaly scores for anomalies,\nand prevents us from improving the detection performance.\nTo solve this,\nwe propose the deep positive-unlabeled anomaly detection framework,\nwhich integrates positive-unlabeled learning with deep anomaly detection models such as autoencoders and deep support vector data descriptions.\nOur approach enables the approximation of anomaly scores for normal data using the unlabeled data and the labeled anomaly data.\nTherefore,\nwithout labeled normal data,\nour approach can train anomaly detectors by minimizing the anomaly scores for normal data while maximizing those for the labeled anomaly data.\nOur approach achieves better detection performance than existing approaches on various datasets.", "tldr": "We propose a semi-supervised anomaly detection framework that can effectively handle contaminated unlabeled data.", "keywords": ["Semi-Supervised Anomaly Detection", "Positive-Unlabeled Learning", "Autoencoder", "DeepSVDD"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7f2b7cc650d76cb4fba56abdf297301e5e081165.pdf", "supplementary_material": "/attachment/87e77aa4791d16281ebd94296214e335ea57f459.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel method for semi-supervised anomaly detection where training data consisits unlabeled data and labeled anomaly data. Specially, the method assumes the distribution of unlabeled dataset is a combination of normal and anomalous data distribution, and then uses PU learning to minimize the anomaly score of normal data in the unlabeled dataset while maximizing the anomaly score of anomalous data in the unlabled dataset."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well written and easy to follow.\n- The proposed method is simple yet effective."}, "weaknesses": {"value": "- Lcak of novelty. The method seems like a direct use of the objective function $\\hat{R}_{abs-PU}(g)$ in [1].\n- No theoritical analysis is provided. \n- The baselines are not novel enough. Many AD methdos for the comtinated datasets and semi-supervised AD are proposed recently. For instance, [2], [3] and [4].\n- The evaluation is merely on image datasets. More evaluation on popular benchmark like ADbench [5] should be included. Also, it seems that the anomaly ratio in unlabeled data is fixed to 10%, evaluation on datasets with different anomaly ratio  should be included to evaluate the effectiveness of the proposed method.\n- In experiment part, a validation set is created, but usually in AD, there is no such validation set. What is the reason for such a validation set, and is it reasonable?  \n- In hyperparameter analysis, it seems that the performance of method is sensitive to change of $\\alpha$ in some datasets. In experimental setup,  $\\alpha$ is set to be the anomaly ratio. But in real application, the anomaly ratio usually can not be obtained which restricts the use of this method. \n- The experimental setup is weak. In experimental setup, you mentioned 'select one normal class from the remaining 9 classes', but in previous research like [6], each class is treated as normal once a time and 10 experiments is conducted for every dataset. Also, what is the reason for subsampling 2000 samples from the original test set as your test set?\n\n[1] Hammoudeh Z, Lowd D. Learning from positive and unlabeled data with arbitrary positive shift[J]. Advances in Neural Information Processing Systems, 2020, 33: 13088-13099.\n\n[2] Durani, Walid, et al. \"Weakly Supervised Anomaly Detection via Dual-Tailed Kernel.\" Forty-second International Conference on Machine Learning.\n\n[3] Pang, Guansong, et al. \"Deep weakly-supervised anomaly detection.\" Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2023.\n\n[4] Xu, Hongzuo, et al. \"RoSAS: Deep semi-supervised anomaly detection with contamination-resilient continuous supervision.\" Information Processing & Management 60.5 (2023): 103459.\n\n[5] Han, Songqiao, et al. \"Adbench: Anomaly detection benchmark.\" Advances in neural information processing systems 35 (2022): 32142-32159.\n\n[6] Ruff, Lukas, et al. \"Deep semi-supervised anomaly detection.\" arXiv preprint arXiv:1906.02694 (2019)."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tRBngEwJVk", "forum": "Wt6K1uoMPQ", "replyto": "Wt6K1uoMPQ", "signatures": ["ICLR.cc/2026/Conference/Submission14005/Reviewer_4853"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14005/Reviewer_4853"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14005/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761013634150, "cdate": 1761013634150, "tmdate": 1762924500279, "mdate": 1762924500279, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a deep positive-unlabeled (PU) anomaly detection framework to address contaminated unlabeled data in semi-supervised anomaly detection. The approach integrates unbiased PU learning (Kiryo et al., 2017) with deep anomaly detectors, specifically autoencoders (PUAE) and DeepSVDD (PUSVDD). The key idea is to approximate anomaly scores for normal data using the relationship: $(1-\\alpha)p_N(x) = p_U(x) - \\alpha p_A(x)$, where $\\alpha$ is the contamination rate. Experiments on 8 datasets demonstrate improvements over existing methods, including SOEL (Li et al., 2023)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "*Clear presentation:* The paper is well-written with clear mathematical derivations. Figure 1 effectively illustrates the conceptual differences between methods, and the problem formulation is easy to follow.\n\n*Practical problem:* The work addresses the realistic scenario where unlabeled data contain unidentified anomalies, which is common when labeling all anomalies is prohibitively expensive.\n\n*Thorough baseline comparisons:* The paper compares against a comprehensive set of methods spanning unsupervised (IF, AE, DeepSVDD, LOE), semi-supervised (ABC, DeepSAD, SOEL), and PU learning approaches.\n\n*Robustness analysis:* Figure 2 demonstrates that PUSVDD exhibits greater robustness to $\\alpha$ misspecification compared to SOEL across multiple datasets, which is a valuable property."}, "weaknesses": {"value": "*1. Limited Technical Novelty*\n\nThe core methodology is a direct application of the unbiased PU learning framework from Kiryo et al. (2017). The mathematical framework (Eq. 6-13) follows the standard PU learning derivation without significant modification. The main adaptation is substituting different base loss functions ($\\ell_{BCE}$ for PUAE, $\\tilde{\\ell}_{SAD}$ for PUSVDD) into the established PU learning objective. While applying PU learning to anomaly detection is useful, the technical contribution is primarily an application rather than a methodological innovation.\n\n*2. Missing α Estimation Mechanism*\n\nThis represents a fundamental gap that severely limits practical applicability:\n\n- **SOEL (Li et al., 2023) provides an adaptive α estimation mechanism** using importance-weighted estimators that automatically estimate contamination rates from data with theoretical guarantees. This is a core contribution of SOEL.\n\n- **PUSVDD lacks any α estimation implementation.** The paper states that \"$\\alpha$ can be estimated... in conventional PU learning approaches\" (Line 197) but provides neither implementation nor experimental validation.\n\n- **All experiments assume known α = 0.1.** Tables 1-2 compare PUSVDD and SOEL under identical settings where $\\alpha$ is given as ground truth. This comparison does not reflect SOEL's capability to automatically estimate $\\alpha$, creating an incomplete picture of relative performance.\n\n- **Practical deployment requires knowing α.** Without automatic estimation, users must manually tune $\\alpha$ or implement separate estimation methods, significantly limiting the method's practical utility compared to SOEL.\n\n*3. Incomplete Experimental Validation*\n\n**Limited scope of sensitivity analysis:**\n- Figure 2 only examines scenarios where true contamination is 10%, varying the algorithm's $\\alpha$ parameter from 0.1 to 0.5.\n- Missing: experiments with different true contamination rates (e.g., 1%, 5%, 10%, 20%) to validate generalizability.\n- A more informative analysis would test multiple combinations of (true α, estimated α) across key datasets.\n\n**No end-to-end evaluation:**\n- The paper should demonstrate: α estimation → model training → evaluation, comparing PUSVDD and SOEL when both methods must estimate $\\alpha$ from data.\n- Current results only show PUSVDD is more robust to α misspecification, but do not demonstrate whether this advantage persists when $\\alpha$ is unknown and must be estimated in practice.\n\n*4. Modest Performance Improvements*\n\nWhile PUSVDD achieves best results in most cases, improvements over SOEL are often marginal:\n- CIFAR100: 0.637 vs. 0.633 (0.4% improvement)\n- OCT: 0.857 vs. 0.856 (0.1% improvement)\n- FashionMNIST: 0.948 vs. 0.936 (1.2% improvement)\n\nGiven the lack of α estimation and limited technical novelty, these incremental gains are insufficient to demonstrate substantial advancement over the current state-of-the-art."}, "questions": {"value": "1. **α estimation implementation:** Can you implement at least one α estimation method (e.g., Elkan & Noto 2008, Christoffel et al. 2016, or SOEL's importance-weighted estimator) and provide experimental results? This is essential for demonstrating practical applicability and enabling fair comparison with SOEL.\n\n2. **Extended sensitivity analysis:** Can you provide experiments with varying true contamination rates beyond 10%? For example, prepare datasets with true α ∈ {0.01, 0.05, 0.1, 0.2} and evaluate performance under different estimated α values to comprehensively assess robustness.\n\n3. **End-to-end comparison:** What is the performance when both SOEL and PUSVDD must estimate α from data (i.e., neither method is given the ground truth)? This would provide a fair comparison that accounts for SOEL's adaptive estimation capability and PUSVDD's claimed robustness advantage."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics review needed."}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dj3rhly9tY", "forum": "Wt6K1uoMPQ", "replyto": "Wt6K1uoMPQ", "signatures": ["ICLR.cc/2026/Conference/Submission14005/Reviewer_qX5f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14005/Reviewer_qX5f"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14005/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761618980305, "cdate": 1761618980305, "tmdate": 1762924499823, "mdate": 1762924499823, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a framework for \"deep positive-unlabeled anomaly detection,\" which focus on the practical and significant challenge of contaminated unlabeled data in semi-supervised anomaly detection. The core idea is to integrate the principles of Positive-Unlabeled (PU) learning with established deep anomaly detection models like Autoencoders (AE) and Deep SVDD. The authors present a solution demonstrated to be empirically effective in handling scenarios where the unlabeled set contains hidden anomalies."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper tackles a critical and often overlooked limitation of traditional semi-supervised anomaly detection methods, which typically assume that the unlabeled dataset is 'clean' (i.e., contains only normal samples). This assumption rarely holds in real-world settings. By directly addressing the issue of contaminated unlabeled data, this work has strong practical relevance and significant potential for real-world applications."}, "weaknesses": {"value": "While the paper addresses an important problem and the empirical results are promising, I have a few concerns regarding its novelty and theoretical depth that I believe should be addressed to strengthen the contribution.\n\n1. The core contribution appears to be the application of a well-established theoretical framework—unbiased PU learning (Du Plessis et al., 2014; Kiryo et al., 2017)—to existing deep anomaly detection models (AE and DeepSVDD). The key derivations presented in Equations (6)-(11) seem to follow the standard risk reformulation process from the PU learning literature. While the application to this specific problem is new, the work lacks a fundamental innovation to either the PU learning theory itself or the architecture of the deep detectors. As such, the contribution feels more like an effective integration of existing components rather than the proposal of a fundamentally new methodology, which may limit its perceived novelty.\n2. The use of an absolute value in the final objective function (Eq. 13) to prevent divergence, while citing prior work, feels somewhat like an ad-hoc fix. This practical necessity might suggest an underlying instability when combining the unbiased PU risk estimator with highly complex models like deep neural networks. The paper would be more impactful if it included a deeper analysis of why this instability occurs and the theoretical implications of this absolute value \"patch.\""}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "527gXXTl1o", "forum": "Wt6K1uoMPQ", "replyto": "Wt6K1uoMPQ", "signatures": ["ICLR.cc/2026/Conference/Submission14005/Reviewer_KjdH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14005/Reviewer_KjdH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14005/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762058273592, "cdate": 1762058273592, "tmdate": 1762924499008, "mdate": 1762924499008, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose to apply the assumptions of PU learning to outlier detection. They derive a reweighted loss based on the assumption that one knows approximately the contamination rate of the unlabeled data.  They derive a stabilized version of the loss in eq (13).   They apply it to autoencoder loss and to SVDD. They compare it on several datasets against several baselines. They measure experimentally the sensitivity to mismatch of the assumed contamination rate. They evaluate against seen and unseen anomalies."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Clear idea\n- Easily readable paper\n- Evaluation of different contamination rates\n- Evaluation against seen and unseen anomalies\n- Application of the idea for more than one baseline\n- reasonable performance, limitations are discussed"}, "weaknesses": {"value": "- some of the datasets (mnist, fashionmnist, cifar-10) are abit outdated and simplistic as of 2025 \n- the idea was tried with two rather old baselines. it would be good to try it out with a newer approach"}, "questions": {"value": "na"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OdzHXZnCp6", "forum": "Wt6K1uoMPQ", "replyto": "Wt6K1uoMPQ", "signatures": ["ICLR.cc/2026/Conference/Submission14005/Reviewer_Q8eX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14005/Reviewer_Q8eX"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14005/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762069081948, "cdate": 1762069081948, "tmdate": 1762924498480, "mdate": 1762924498480, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}