{"id": "q5TSIEE7WM", "number": 23648, "cdate": 1758346754465, "mdate": 1763045394551, "content": {"title": "Gradients with Respect to Semantics Preserving Embeddings Tell the Uncertainty of Large Language Models", "abstract": "Uncertainty quantification (UQ) is an important technique for ensuring the trustworthiness of LLMs, given their tendency to hallucinate. Existing state-of-the-art UQ approaches for free-form generation rely heavily on sampling, which incurs high computational cost and variance. In this work, we propose the first gradient-based UQ method for free-form generation, SemGrad, which is sampling-free and computationally efficient. Unlike previous gradient-based methods developed for classification tasks, we propose to operate in semantic space rather than parameter space. Our method builds on the key intuition that a confident LLM should maintain stable output distributions under semantically equivalent input perturbations. We interpret the stability as the gradients in semantic space and introduce a Semantic Preservation Score (SPS) to identify embeddings that best capture semantics, with respect to which gradients are computed. We further propose HybridGrad, which combines the strengths of SemGrad and parameter gradients. Experiments demonstrate that both of our methods provide efficient and effective uncertainty estimates, achieving superior performance than state-of-the-art methods, particularly in settings with multiple valid responses.", "tldr": "", "keywords": ["Uncertainty Quantification; Large Language Models; Hallucination"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ef72b33688efacc8b1b8507b8f07fb603f5dec97.pdf", "supplementary_material": "/attachment/3390971843e90486d831a8befd960e4079601171.zip"}, "replies": [{"content": {"summary": {"value": "This work introduces SemGrad, which utilizes gradient information in semantic space for uncertainty estimation for hallucination detection.\nTo that end, it further introduces the SPS to identify embeddings that cary semantic information.\nFinally, the paper introduces a hybrid approach - HybridGrad - that interpolates between SemGrad and gradient information w.r.t. the parameters, which I will refer to for this review as ParamGrad for simplicity. Both methods are evaluated across multiple benchmark datasets and LLMs."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is well organized and clearly written.\n- The idea of using gradient information of the LLM for hallucination detection is a straightforward idea and the extention to gradient w.r.t. semantic embeddings is an interesting and novel idea.\n- A good selection of baselines methods on three LLMs in the 7B range.\n- Very interesting investigation with SPS, analyzing the specifics of the different used LLMs regarding what layer and token is most useful to extract semantic information. This is useful even for competitor methods like INSIDE that rely on embedding information.\n- Thoughtful ablation studies, rationalizing many of the choices for implementing the method."}, "weaknesses": {"value": "- The BEM evaluation metric should be complimented with LLM-as-a-judge (Zheng et al.) as correctness metric, which has emerged as the de-facto standard for correctness evaluation for hallucination detection.\n- AUROC is widely used as an evaluation metric in those experiments, other metrics such as PRR (Malinin & Gales) would provide a more complete picture.\n- I find the deduction that SemGrad operates in semantic space (line 417) not entirely convincing, I either suggest toning down the claim or provide more convincing evidence.\n- The motivation from using the parameter gradient norm is understandable, albeit a bit weak. I agree that at the true model it has the correct behavior is expressing complete certainty, yet there is no guarantee on monotonicity or am I mistaken? That is, why do we know that one prediction with a higher gradient norm than another is more uncertain? All the argument around Eq.(1) and (2) tells us is, that under true model parameters the gradient norm will be zero.\n\nNotes:\n- Equation references should use \\eqref\n- I would prefer a single-color colormap for figures 2-4, the used one suggests correlated - neutral - anticorrelated \n- The findings of the usefulness of embeddings within the layers appears strongly related to the findings of Chen et al. 2024, which would be worthwile to discuss.\n- Shouldn't line 418 state \"semantic *preserving* perturbations\"?\n\n---\nZheng, Chiang, ... (2023) Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena, NeurIPS\n\nMalinin, Gales (2021) Uncertainty Estimation in Autoregressive Structured Prediction, ICLR\n\nChen, liu, ... (2024) INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection, ICLR"}, "questions": {"value": "- What is the performance of ParamGrad alone? SemGrad and HybridGrad have been evaluated in the main experiments in Table 1, yet not the ParamGrad component. I know that ExGrad is similar, yet lacking the token-entropy weighting which would be interesting to evaluate as a standalone.\n- I wonder about the justification of adding up SemGrad and ParamGrad to form HybridGrad, I would like to see a comparison if they are usually within similar ranges. For me it is not clear that they should be, as gradient norms in parameter space and semantic embedding space might be in completely different ballparks. Could one also consider a multiplicative \n- I would ask for an elaboration on when the particular weighting between SemGrad and ParamGrad in Eq.(5) is expected to work. What I really like about it is its input dependency, yet the exact values for the entropies depend on a lot of things that are not particularly discussed in the present work. For example different vocabulary sizes or different precisions or stability tricks for calculating the next token distribution could change it drastically. In my opinion, there should be an explicit temperature hyperparameter (i.e. $e^{-\\bar{w}/\\tau}$) making this dependency more verbose and allowing for systematic study of the impact of this weighting.\n- Do you observe any length-dependency in the metrics and if yes how strong? Would there be any merit in length-normalization as widely used in prior work, e.g. in many of the discussed baselines, or in using the weighting introduced in the work on SAR?\n- Are the negative answers featured in the TruthfulQA dataset used for evaluation?\n- How are the semantically equivalent paraphrases generated? Was there any investigation into how well this additional generated sequences preserve semantics?\n- Apart from increased runtime, does the weighting based on thrid party models as in e.g. Duan et al. further improve the method compared to the token-entropy based weighting?\n- What codebase was used to estimate semantic entropy? The original one from Kuhn et al. or the corrected estimator from Aichberger et al.? Note that the codebase from the Nature version of Semantic entropy (Farquhar et al.) also uses this corrected estimator.\n- I would further include just PE and also LN-SE to disentangle the effect of length-normalization, or is there a reason why this was not included?\n\n---\nAichberger, Schweighofer, ... (2024) Improving Uncertainty Estimation through Semantically Diverse Language Generation, ICLR\n\nFarquhar, Kossen, ... (2024) Detecting hallucinations in large language models using semantic entropy, Nature"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "9vlItF4ZYP", "forum": "q5TSIEE7WM", "replyto": "q5TSIEE7WM", "signatures": ["ICLR.cc/2026/Conference/Submission23648/Reviewer_QuTT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23648/Reviewer_QuTT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23648/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760737389254, "cdate": 1760737389254, "tmdate": 1762942747351, "mdate": 1762942747351, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes gradient based uncertainty estimation for natural language generation problems. \nThey first introduce the Semantic Preservation Score (SPS), which is later used to determine the parts of the gradient of the model/intermediate states most correlated with semantics. \nThen two gradient based uncertainty estimation methods are introduced: SemGrad and HybridGrad.\nThe former uses the gradient with respect to hidden states and the latter additionally incorporates model weight gradients, which was already done in prior work.\nThe authors perform evaluation of the proposed approach to verify its utility."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This work explores uncertainty quantification by gradient, the role of model parameter and hidden state gradients. \nThe concept of using the KV cache gradients is generally appealing and interesting, although a lot of heuristics are involved.\nMany good recent method for UE are compared to in the evaluation. \nAuthors acknowledge the limitation of applicability of their method to only the white-box scenario and perform several ablations."}, "weaknesses": {"value": "1. The term \"semantic\" is mentioned 112 times in the paper. \"Semantics\" are used in arguments and even backpropagated through. I believe a paragraph of discussion of what is \"semantic\" deserves to be in the introduction or preliminaries.\n2. The SPS motivation (i.e. why should we do it this way, why not some other way, i.e. through an embedding model or so) does not feel well conducted.\n3. Figure 1: Technically and lexically awkward labels: \"Certain input\", \"Uncertain input\". In line 144 it is the same: \"For a certain input x\" - does it now mean that we have a fixed input x or that the input x is supposed to be \"certain\". \n4. Experimental validation.\n    1. Experimental suite is narrow (3 models / 3 datasets, all short answer QA), for a method that is heavily heuristic driven, the breadth of evaluation is important. \n    2. The selective prediction experiments hinge on a single, not very commonly used correctness function - BEM. This is prone to skew the results on QA datasets (see [1][2]).\n    3. Line 316: \"Many of the questions in TruthfulQA are open-ended (e.g., “What happens to you if you eat watermelon seeds?”), which naturally introduces a high degree of aleatoric uncertainty.\" TruthfulQA correctness has little to do with aleatoric risk (i.e. the risk of model just decoding the wrong thing) and more with training data selection / order during pretraining. I view connecting it to aleatoric risk as a bad practice. \n\n### References\n1. Ielanskyi, M., Schweighofer, K., Aichberger, L. & Hochreiter, S. Addressing Pitfalls in the Evaluation of Uncertainty Estimation Methods for Natural Language Generation. Preprint at https://doi.org/10.48550/arXiv.2510.02279 (2025).\n2. Santilli, A. et al. Revisiting uncertainty quantification evaluation in language models: Spurious interactions with response length bias results. in Proceedings of the 63rd annual meeting of the association for computational linguistics (volume 2: Short papers) (eds Che, W., Nabende, J., Shutova, E. & Pilehvar, M. T.) 743–759 (Association for Computational Linguistics, Vienna, Austria, 2025). doi:10.18653/v1/2025.acl-short.60."}, "questions": {"value": "1. Could you provide a more detailed explanation on the type of uncertainty in TruthfulQA? How would risk of decoding one option from the training set vs another option be correlated to the aleatoric risk?\n2. What motivated the choice of BEM as a correctness metric for selective prediction experiments? Would results look different with e.g. AlignScore or LLM as a Judge? \n3. Why does the method appear to underperform on Mistral-Nemo-Instruct 12B?\n4. How does the methods compare in terms of compute and, more importantly, memory requirements compared to prior works?\n5. Fig. 2 shows what I would view as a a sink token effect - the 'technical' tokens eat up a lot of attention mass. How is this accounted for in SemGrad?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fWpodCM9Cu", "forum": "q5TSIEE7WM", "replyto": "q5TSIEE7WM", "signatures": ["ICLR.cc/2026/Conference/Submission23648/Reviewer_hgm6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23648/Reviewer_hgm6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23648/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761826891539, "cdate": 1761826891539, "tmdate": 1762942746975, "mdate": 1762942746975, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose SemGrad, a gradient-based UQ method that operates in semantic space to estimate uncertainty for NLG tasks. The method first identifies the highest semantic preserving token of an input (expected highest value of the proposed metric SPS), whose embeddings best represents the entire input’s semantics. Then it computes the gradient of the log-likelihood of the output sequence with respect to the top half layer embeddings of the identified semantic preserving token. This measures how sensitively the model’s output sequence changes when perturbing the input while preserving its semantics.\nAdditionally, the authors also propose HybridGrad, a combination of SemGrad and parameter gradients."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is very well written and has a clear structure\n- The motivation for SemGrad is clear and neat (sections 3.1 and 3.2 are well preparing for the methods)\n- The ablations are insightful"}, "weaknesses": {"value": "**Method**: \n- The paper’s central argument is that NLG tasks require a fundamentally different treatment from classification tasks. The authors claim that using parameter gradients as a proxy for uncertainty “does not extend to the ground-truth distribution of natural language” (line 156) and that “the parameter gradient norm can be misleading” (line 159). The main premise is therefore to \"overcome the limitations of the parameter gradient\" (line 164), with substantial effort devoted to motivating, deriving, and analyzing the Semantic Preservation Score (SPS) and the resulting SemGrad method. My main concern is that the authors subsequently reintroduce parameter gradients in the HybridGrad variant, presented only briefly at the end of the methodology section. The justification for this addition is unconvincing and lacks theoretical grounding. It is unclear why, from a conceptual standpoint, switching to parameter gradients when the model’s predictive distribution is already sharp and stable should provide any benefit over SemGrad alone. While HybridGrad empirically improves performance, this improvement contrasts with the earlier theoretical motivation and raises questions about whether the empirical evaluation fully isolates the intended effect.\n- Another technical concern is that the entropy weights $w_t$ depend on the same predictive distribution as the log-likelihood terms. Unless the authors explicitly detach these values from the computation graph, the weighting would alter the gradient itself. On the other hand, if the entropy weights are detached, it would ignore the entropy’s own sensitivity to the embeddings.\n\n\n**Evaluations**: The baselines should be extended by UQ methods that also do not require sampling multiple output sequences (e.g., G-NLL [1]). \n\n---\n[1] Lukas Aichberger, Kajetan Schweighofer, and Sepp Hochreiter. Rethinking uncertainty estimation in natural language generation. arXiv preprint arXiv:2412.15176, 2024."}, "questions": {"value": "- Why does the \"intuition that uninformative tokens (e.g., stopwords or subwords) always exhibit low output entropy\" (line 282) motivate the use of the above mentioned entropy weights? On the one hand, in the sentence “I think it’s going to rain,” the token “think” carries little factual meaning. However, a model might assign high entropy since many similar verbs could fit (“guess”, “believe”, “assume”, “suppose”). On the other hand, in the sentence “The capital of Australia is Sydney,” the token “Sydney” might have low entropy if the model is confidently wrong."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XAgX8kLmIG", "forum": "q5TSIEE7WM", "replyto": "q5TSIEE7WM", "signatures": ["ICLR.cc/2026/Conference/Submission23648/Reviewer_C28m"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23648/Reviewer_C28m"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23648/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761844524207, "cdate": 1761844524207, "tmdate": 1762942746688, "mdate": 1762942746688, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}