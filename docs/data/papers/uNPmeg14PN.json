{"id": "uNPmeg14PN", "number": 25226, "cdate": 1758365469221, "mdate": 1758868905217, "content": {"title": "Learning meaningful geological fields representations by self-supervised methods", "abstract": "Geological fields are challenging to model as they reflect complex multi-scale sedimentation processes during the whole history of Earthâ€™s existence. The geological objects that can be found in such fields have very different nature and scale and are often represented by statistical means. In this work we investigate the possibility to obtain meaningful representations for geological fields of different kinds with the help of self-supervised learning (SSL). Specifically, we adapt a self-supervised vision transformer architecture DINOv2 to a dataset of more than twenty thousands synthetic 3D geological cubes describing four sedimentary environments to learn their representations without labels. We show that learned embeddings cluster by sedimentary environment type and have high correlation with important geostatistical properties, such as variograms. When used as features for classification and regression, they match or exceed the performance of supervised CNNs trained from scratch. Our results demonstrate that SSL can capture meaningful geological structure in 3D geological data and serve as a strong foundation for downstream tasks, reducing the need for expensive labeled datasets in geological modeling.", "tldr": "Learning meaningful self-supervised representations of geological fields helps to train better generative models for downstream tasks", "keywords": ["self-supervised learning", "geological modeling", "geological representations", "learning representations"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/17b5920d65174617bbf7a4cfebc621034fccbeb6.pdf", "supplementary_material": ""}, "replies": [], "withdrawn": true}