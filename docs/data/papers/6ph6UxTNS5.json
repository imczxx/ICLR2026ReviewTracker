{"id": "6ph6UxTNS5", "number": 2335, "cdate": 1757059228521, "mdate": 1758806380468, "content": {"title": "TinyVGGT: Lossless Post-Training Quantization for Visual Geometry Grounded Transformer", "abstract": "The Visual Geometry Grounded Transformer (VGGT) represents a significant advancement in 3D computer vision, demonstrating state-of-the-art performance in inferring key 3D attributes such as camera parameters, depth maps, and point clouds directly from images. However, its substantial model size poses a significant barrier to its deployment on resource-constrained edge devices like unmanned aerial vehicles (UAVs), limiting its real-world applicability. To address this limitation, we introduce TinyVGGT, a tailored quantization framework designed to compress VGGT. Our approach starts from the observation that transformer blocks within VGGT exhibit heterogeneous sensitivity to quantization. We thus propose a performance-aware quantization strategy that applies layer-wise mixed precision quantization to minimize the cumulative error. Furthermore, we design a specialized calibration scheme to smooth the distribution of camera tokens to preserve the high-precision geometric information. Finally, to systematically align quantization with the 3D prediction task, we propose a scale search mechanism, where candidate scales are evaluated not only by per-head reconstruction error but also by enforcing geometric consistency among camera poses, depth maps, and point maps. Extensive experiments on various geometry perception benchmarks demonstrate our method achieves lossless 4-bit quantization, preserving the performance of all 3D attributes prediction while reducing the overall model size by more than 50%. This work makes the deployment of high-fidelity 3D reconstruction on edge platforms feasible, unlocking real-world applications with limited resource.", "tldr": "", "keywords": ["model quantization", "3D computer vision"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "", "supplementary_material": ""}, "replies": [], "withdrawn": true}