{"id": "NHuyk9KsG6", "number": 9184, "cdate": 1758114449877, "mdate": 1759897738985, "content": {"title": "Horseshoe Splatting: Handling Structural Sparsity for Uncertainty-Aware Gaussian-Splatting Radiance Field Rendering", "abstract": "We introduce Horseshoe Splatting, a Bayesian extension of 3D Gaussian Splatting (3DGS) that jointly addresses structured sparsity in per-splat covariances and delivers calibrated uncertainty. While neural radiance fields achieve high-fidelity view synthesis and 3DGS attains real-time rendering with explicit anisotropic Gaussians, existing pipelines do not explicitly encode structural sparsity in the covariance—e.g., axis-wise variances or pairwise correlations—leaving noise-dominated components insufficiently regularized. Uncertainty is likewise essential for trustworthy and robust novel-view prediction, yet most 3DGS variants remain deterministic. We place a global-local Horseshoe prior on the covariance scales, whose spike-at-zero and heavy-tails adaptively shrink irrelevant directions while preserving the salient structure. We fit the model with a factorized variational inference scheme that mirrors the Horseshoe's inverse-Gamma augmentation, enabling Monte Carlo rendering and pixel-wise posterior uncertainty with minimal overhead. Theoretically, we establish posterior contraction rates for the scale parameters and transfer them to the rendered image via a local Lipschitz mapping, providing guarantees that estimation error and predictive uncertainty diminish with data. Empirically, Horseshoe Splatting produces high-quality uncertainty maps while matching state-of-the-art 3DGS visual fidelity and runtime, yielding a practical, uncertainty-aware renderer that is robust to structured sparsity in the radiance field.\nThe code is anonymously available at https://anonymous.4open.science/r/hs-25C5/README.md.", "tldr": "We introduce Horseshoe Splatting, a Bayesian extension of 3D Gaussian Splatting (3DGS) that jointly addresses structured sparsity in per-splat covariances and delivers calibrated uncertainty.", "keywords": ["Bayesian Neural Network", "Gaussian splatting", "Horseshoe Prior", "Structural Sparsity", "Uncertainty"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f5df5bb47217fb8d499886e4db0ff9233b186d9b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Horseshoe Splatting, a Bayesian extension of 3DGS for radiance field rendering. The key idea is to introduce a global–local Horseshoe prior over per-splat covariance scales, allowing the model to encode structured sparsity in the Gaussian footprints while also providing pixel-wise uncertainty estimates.  Empirically, the proposed method achieves state-of-the-art image quality and well-calibrated uncertainty on the LF and LLFF benchmarks, outperforming both prior NeRF- and 3DGS-based uncertainty modeling methods, while maintaining real-time rendering speed."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper introduces a conceptually clear global–local Horseshoe for 3DGS uncertainty estimation while keeping sufficient efficiency.\n\n- Theoretical derivations are provided to support the method. \n\n- Strong performance is shown on LF and LLFF."}, "weaknesses": {"value": "- It is unclear whether the observed benefits are specific to the Horseshoe, or simply due to introducing any sparsity prior. Also, the ablation only reports improved metrics on the datasets, not how much structural sparsity was actually induced. Thus, the paper lacks quantitative evidence that the prior truly enforces the claimed structural sparsity. It should be further verified whether Horseshoe is necessary and essential.\n\n- The assumption of scaling sparsity places priors on covariance scales, which has not been well verified whether this is sufficiently generalizable for various scenes. Also, as it does not rely on color or opacity, the effectiveness may be limited in scenes dominated by photometric ambiguity rather than geometric uncertainty, such as non-Lambertian surfaces.\n\n- The experiments regarding active view selection may be too ideal. Considering there initially does not contain too many views in the LF dataset, starting with 10% of views may be too sparse and seems to be a toy study that can hardly match the real-world application. Would like to see if the method can still work in more scenarios."}, "questions": {"value": "See the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Q4813uQMIs", "forum": "NHuyk9KsG6", "replyto": "NHuyk9KsG6", "signatures": ["ICLR.cc/2026/Conference/Submission9184/Reviewer_W9qb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9184/Reviewer_W9qb"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9184/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761562929300, "cdate": 1761562929300, "tmdate": 1762920859169, "mdate": 1762920859169, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Horseshoe Splatting, a Bayesian variant of 3D Gaussian Splatting (3DGS) that explicitly models structural sparsity and uncertainty in radiance field rendering. The method places a global–local Horseshoe prior on per-splat covariance scales to suppress noisy or redundant directions while retaining key anisotropic structures. A variational inference framework enables Monte Carlo rendering and pixel-wise uncertainty estimation with little computational cost. Experiments on Light Field and LLFF datasets show that the approach achieves state-of-the-art image quality and well-calibrated uncertainty, while maintaining real-time rendering performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Innovative Bayesian extension of 3DGS that meaningfully incorporates structural sparsity and uncertainty estimation.\n  2. Solid theoretical grounding, with posterior contraction guarantees linking model uncertainty to data consistency.\n  3. Strong empirical validation, outperforming prior methods on fidelity and uncertainty metrics without slowing inference.\n  4. Clear writing and presentation, with convincing visual and quantitative results."}, "weaknesses": {"value": "1. Limited Conceptual Novelty Beyond Integration. While the Horseshoe prior is applied creatively to 3DGS, the overall contribution is more of a principled integration of known Bayesian shrinkage techniques rather than a fundamentally new rendering paradigm. The work’s novelty thus lies mainly in adaptation, not invention.\n  2. Dependence on Heavy Computational Infrastructure. The approach relies on large-scale Gaussian Splatting models and variational inference, which may limit reproducibility and accessibility. It’s unclear how well the method scales down to smaller datasets or lightweight hardware settings.\n  3. Lack of Diversity in Experimental Scenarios. Experiments are limited to static and relatively clean datasets (LF, LLFF). The paper does not demonstrate how the model behaves under dynamic scenes, noisy inputs, or severe view sparsity — conditions where uncertainty modeling would be most critical.\n  4. Insufficient Analysis of Practical Utility of Uncertainty. While uncertainty maps are visually convincing, the paper provides little quantitative evidence of how uncertainty benefits downstream tasks, beyond one active view selection experiment. More demonstration of practical value would strengthen the impact."}, "questions": {"value": "1. Generalization and Robustness – How does Horseshoe Splatting perform on dynamic or large-scale outdoor scenes where scene sparsity and motion are more complex?\n  2. Computational Cost – What is the training time and memory overhead compared to vanilla 3DGS? Could this method realistically run on commodity GPUs?\n  3. Ablation on Horseshoe Hierarchy – How sensitive is performance to the hierarchical prior choice? Would simpler priors (e.g., Laplace or Gaussian scale mixtures) achieve similar uncertainty quality?\n  4. Downstream Use of Uncertainty – Beyond visualization, have the authors tested whether the uncertainty maps improve robustness in active learning or out-of-distribution detection?\n  5. Scalability and Model Release – Are there plans to release pretrained models or a lighter implementation for reproducibility?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TZ2Nhafteq", "forum": "NHuyk9KsG6", "replyto": "NHuyk9KsG6", "signatures": ["ICLR.cc/2026/Conference/Submission9184/Reviewer_QC4h"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9184/Reviewer_QC4h"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9184/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761864014327, "cdate": 1761864014327, "tmdate": 1762920858715, "mdate": 1762920858715, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Horseshoe Splatting, which applies a global–local Horseshoe shrinkage prior to the covariance scales of each Gaussian in 3D Gaussian Splatting (3DGS) to encode structured sparsity. Using an inverse-gamma augmentation equivalent to the half-Cauchy prior, the method builds a factorized variational family for Monte Carlo rendering and pixel-wise uncertainty estimation. The authors also provide theoretical guarantees on posterior contraction under Lipschitz assumptions and validate the method on LF/LLFF datasets with improved view and uncertainty quality."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper’s exploration of uncertainty modeling in 3DGS is valuable. Incorporating both uncertainty and structured sparsity is novel, as most existing 3DGS uncertainty modeling focuses on geometry, semantic fields, or Fisher information approximations, with little direct regularization on covariance structures.\n2. The experiments are comprehensive, jointly evaluating RGB and depth uncertainty (e.g., NLL, AUSE) and active view selection scenarios, with ablations (Gaussian vs. Horseshoe) demonstrating the benefit of the proposed prior."}, "weaknesses": {"value": "1. The local Lipschitz assumption may be fragile since 3DGS rendering involves depth sorting and α-blending, which can cause discontinuities around occlusion or visibility changes. More clarification or evidence on how local neighborhoods avoid these discrete transitions would strengthen the theory section.\n2. The active-view selection strategy lacks details — the paper mentions adding one view every 500 steps until 30%, but the convergence criterion, acquisition function, and budget alignment across methods are not clearly defined."}, "questions": {"value": "It would be helpful if the authors could validate the method on more wild or challenging scenes, such as MipNeRF or Tanks and Temples, to demonstrate broader applicability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "w2Yl2dsMHG", "forum": "NHuyk9KsG6", "replyto": "NHuyk9KsG6", "signatures": ["ICLR.cc/2026/Conference/Submission9184/Reviewer_xYVt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9184/Reviewer_xYVt"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9184/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982609466, "cdate": 1761982609466, "tmdate": 1762920858384, "mdate": 1762920858384, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Horseshoe Splatting, a Bayesian extension of 3D Gaussian Splatting (3DGS) that addresses structural sparsity in per-splat covariances while providing calibrated uncertainty estimates. The key innovation is the application of a global-local Horseshoe prior on covariance scales, which adaptively shrinks noise-dominated directions while preserving salient anisotropic structure. The authors develop a factorized variational inference scheme that enables Monte Carlo rendering with pixel-wise posterior uncertainty estimation. Theoretically, they establish posterior contraction rates for scale parameters and propagate these guarantees to rendered images via local Lipschitz mapping. Empirically, the method achieves state-of-the-art visual fidelity on standard benchmarks while producing high-quality uncertainty maps with minimal computational overhead."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper addresses a genuine limitation of existing 3DGS methods: the lack of explicit structural sparsity encoding in per-splat covariances and the absence of principled uncertainty quantification\n- The observation that noise-dominated components in covariance structures remain insufficiently regularized is well-articulated and demonstrated through visualizations (Figure 1)\n- The choice of Horseshoe prior is well-justified by its spike-at-zero and heavy-tail properties, which are precisely what is needed for adaptive sparsification\n- The method achieves state-of-the-art uncertainty estimation (Table 1: average AUSE of 0.18 on depth, NLL of -0.74 on RGB for LF dataset)\n- Novel view synthesis quality is not sacrificed for uncertainty: PSNR of 30.05 on LF dataset, outperforming baselines by significant margins"}, "weaknesses": {"value": "- LLFF are small, static, and relatively clean. No tests on large‑scale, outdoor, high‑specular, or out-of-distribution(OOD) settings (e.g., Tanks&Temples, Mip‑NeRF360)\n- The paper does not give a clear motivation for using 3DGS to model uncertainty in the storyline. So it's hard for me to understand why radiance field rendering needs uncertainty quantification. Also authors should provide comparison with SOTA non-radiance field based uncertainty methods. Please include more discussion in introduction and related work section."}, "questions": {"value": "- Only covariance scales are stochastic; opacity, color (SH), and positions appear deterministic. Are there failure modes where scale uncertainty alone is insufficient?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wu5GOLh2hk", "forum": "NHuyk9KsG6", "replyto": "NHuyk9KsG6", "signatures": ["ICLR.cc/2026/Conference/Submission9184/Reviewer_WvZK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9184/Reviewer_WvZK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9184/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984871887, "cdate": 1761984871887, "tmdate": 1763018132667, "mdate": 1763018132667, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}