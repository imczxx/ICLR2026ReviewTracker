{"id": "30e3LnZzmI", "number": 14546, "cdate": 1758238534915, "mdate": 1759897363372, "content": {"title": "Reimagining Agent-based Modeling with Large Language Model Agents via Shachi", "abstract": "The study of emergent behaviors in large language model (LLM)-driven multi-agent systems is a critical research challenge, yet progress is limited by a lack of principled methodologies for controlled experimentation. To address this, we introduce Shachi, a formal methodology and modular framework that decomposes an agent's policy into core cognitive components: Configuration for intrinsic traits, Memory for contextual persistence, and Tools for expanded capabilities, all orchestrated by an LLM reasoning engine. This principled architecture moves beyond brittle, ad-hoc agent designs and enables the systematic analysis of how specific architectural choices influence collective behavior. We validate our methodology on a comprehensive 10-task benchmark and demonstrate its power through novel scientific inquiries. Critically, we establish the external validity of our approach by modeling a real-world U.S. tariff shock, showing that agent behaviors align with observed market reactions only when their cognitive architecture is appropriately configured with memory and tools. Our work provides a rigorous, open-source foundation for building and evaluating LLM agents, aimed at fostering more cumulative and scientifically grounded research. Code: https://anonymous.4open.science/r/bench-2E1D/", "tldr": "Shachi is a modular LLM-ABM framework (Configs, Memory, Tools, LLM) enabling reproducible studies, emergent behavior analysis, and enabling novel exploratory studies across three complexity levels.", "keywords": ["Agent-based modeling", "Large language model", "Social science"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/52945a5ece00f2f020a3d82cfe64994a743b2755.pdf", "supplementary_material": "/attachment/46fd651ce6a0f5db2b3455cd26f70d391f01faa7.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces Shachi, a formal methodology and modular framework designed to address the fragmentation and lack of reproducibility in LLM-based agent-based modeling (ABM). The core contribution is a principled decomposition of an agent's policy into four modular components: a reasoning engine (LLM), intrinsic traits (Configs), contextual persistence (Memory), and expanded capabilities (Tools), orchestrated through a standardized agent-environment interface. This architecture enables systematic analysis of how specific cognitive components influence emergent behaviors."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Shachi's core strength lies in its formal decomposition of an agent's cognitive architecture. By standardizing components (LLM, Configs, Memory, Tools) and the agent-environment interface, the framework directly addresses the field's reproducibility crisis.\n2. The inclusion of a 10-task benchmark, thoughtfully structured across three levels of increasing social complexity, provides a much-needed standardized testbed for the community."}, "weaknesses": {"value": "1. The inclusion of a 10-task benchmark, thoughtfully structured across three levels of increasing social complexity, provides a much-needed standardized testbed for the community.\n2. The inclusion of a 10-task benchmark, thoughtfully structured across three levels of increasing social complexity, provides a much-needed standardized testbed for the community.\n\n\nMissing reference:   \nJunyu Luo et al., Large language model agent: A survey on methodology, applications and challenges, arXiv 2025."}, "questions": {"value": "Please see the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "I2fgtmSyoG", "forum": "30e3LnZzmI", "replyto": "30e3LnZzmI", "signatures": ["ICLR.cc/2026/Conference/Submission14546/Reviewer_qpSQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14546/Reviewer_qpSQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14546/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761623465701, "cdate": 1761623465701, "tmdate": 1762924935355, "mdate": 1762924935355, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Shachi, a modular framework for LLM-based ABM that decomposes agent policy into four components (Configs, Memory, Tools, LLM). The authors claim this principled architecture enables systematic, reproducible analysis of emergent behavior, validating it with a 10-task benchmark and a real-world tariff shock simulation to demonstrate external validity."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "1.\tNovel Modular Framework: The paper proposes a clear, modular abstraction for agent design. This is a valuable contribution that moves the field away from ad-hoc scripts and toward a standardized, reproducible, and systematic methodology.\n\n2.\tGood Presentation: The paper is well-written, clearly structured, and easy to follow. Figures and visualizations are clear and effectively communicate the authors' core contributions and experimental results."}, "weaknesses": {"value": "1.\tWeak Theoretical Grounding: The paper presents the decomposition of (Configs, Memory, Tools, LLM) as a “formal methodology” or “principled architecture”.  In practice, this looks more like a conceptual abstraction or a software-engineering style decomposition than a framework derived through rigorous theoretical justification. The paper does not conduct a formal analysis of this, which makes the claim of a \"formal methodology\" seem somewhat exaggerated. But it is indeed a well-structured framework.\n\n2.\tWeak Support for Generalization Claims: In cross-task generalization research, the performance differences between StockAgent with complete components and Sotopia Agent with only Memory across tasks are very slight (0.99 vs 0.92, 0.93). The strong contextual reasoning ability of the LLM itself may be the main driving force for generalization. \n\n3.\tWeak External Validity: In the external validity experiment (Section 4.2.3), the results mainly show that Shachi’s outputs can be effectively controlled through the inputs of Memory and Tools. However, this only reflects the framework’s configurability rather than its predictive capacity. The experiment does not convincingly demonstrate that Shachi can robustly handle or generalize to real-world scenarios beyond the information explicitly provided to the agents."}, "questions": {"value": "1.\tHow is “Formality” Defined in This Methodology? The paper repeatedly describes Shachi as a “formal methodology”, but the framework is primarily an implementation protocol. \n\n2.\tIn Shachi, the agent is decomposed into four components—Configs, Memory, Tools, and LLM. Since both retrieved memory content and tool outputs are provided to the LLM in textual form, potential conflicts or negative interference between these inputs may occur. As a formal methodology, how does Shachi ensure that such inconsistencies or interference are systematically prevented or mitigated at the architectural level?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CjUEDdFayM", "forum": "30e3LnZzmI", "replyto": "30e3LnZzmI", "signatures": ["ICLR.cc/2026/Conference/Submission14546/Reviewer_zhc3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14546/Reviewer_zhc3"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14546/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761752833577, "cdate": 1761752833577, "tmdate": 1762924934724, "mdate": 1762924934724, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents Shachi, a principled and modular framework for large language model–based agent-based modeling (ABM). It standardizes agent design by decomposing each agent’s policy into four cognitive components: Configs, Memory, Tools, and an LLM reasoning engine, and provides a three-level benchmark suite for systematic evaluation. Experiments show that Shachi reproduces existing results, supports cross-task generalization, enables novel studies such as memory transfer and multi-world simulations, and achieves external validity by modeling real-world market reactions to a U.S. tariff shock."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Originality: The paper is original in proposing a unified and modular methodology for LLM-based agent-based modeling (ABM).  Rather than introducing a new agent or task, it formalizes how agents and environments should interact, filling an existing methodological gap in the field.\n\nQuality: The experimental design is broad and novel, including real world task and new case studies such as memory transfer, multi-world interaction, and market simulations.  These diverse experiments support the framework’s robustness and generality.\n\nClarity: The paper shows a clear motivation and unifying perspective. The introduction, method and proposed framework are logically connected and easy to follow.\n\nSignificance: The work establishes a solid methodological foundation for future research on LLM-driven multi-agent systems. By standardizing interfaces and modularizing agent cognition, Shachi has the potential to become a reference framework for reproducible, scientific simulation studies using large language models."}, "weaknesses": {"value": "1) Simplistic baselines and weak comparisons.\nThe baselines are mainly random agents or plain LLMs without modular components. That is too limited to fully substantiate Shachi’s methodological advantages.  More meaningful comparisons could include systems that also use LLM + Memory but lack Shachi’s standardized interface, or other existing LLM-based ABM frameworks reimplemented under the same conditions.  In addition, the current results omit statistical indicators such as variance, confidence intervals, and significance tests, making it difficult to evaluate robustness and reproducibility.  Incorporating richer baselines and proper statistical reporting would greatly strengthen the empirical evidence.\n\n2) Presentation and clarity issues.\nThe paper’s organization is dense, with technical details scattered between sections and appendices. Some details, figures and tables could be better integrated with the main text, and clearer explanations of evaluation metrics and experimental settings would improve readability."}, "questions": {"value": "1) How scalable is the Shachi framework in practice, including LLM calls, time scalability with increasing agent numbers, and space scalability? \n2) Could the authors report variance, confidence intervals, or significance tests to substantiate the reliability of these results?\n3) How sensitive are the reproduction outcomes to the choice of backend LLMs and prompts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SzQSd5xwWL", "forum": "30e3LnZzmI", "replyto": "30e3LnZzmI", "signatures": ["ICLR.cc/2026/Conference/Submission14546/Reviewer_u6ZH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14546/Reviewer_u6ZH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14546/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762002122895, "cdate": 1762002122895, "tmdate": 1762924934165, "mdate": 1762924934165, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Shachi, a formal methodology and modular framework for LLM-based agent-based modeling (ABM). The authors propose decomposing an agent's policy into four core components: Configuration (intrinsic traits), Memory (contextual persistence), Tools (extended capabilities), and an LLM reasoning engine. The framework is validated on a 10-task benchmark suite spanning three levels of social complexity (single-agent, non-communicative multi-agent, and communicative multi-agent)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1, Well-motivated problem: The paper addresses a genuine issue in LLM-based ABM research - the lack of standardized methodology leading to fragmented, irreproducible results. This is an important problem for the field.\n\n2, Principled architecture design: The decomposition of agent policy into Configuration, Memory, Tools, and LLM is intuitive and grounded in cognitive science principles. The separation of agent architecture from environment through a standardized interface is a solid engineering contribution.\n\n3, Strong empirical validation: The reproduction study (Table 1) shows low MAE across all tasks, demonstrating the framework's ability to faithfully replicate prior work. The external validity experiment with the U.S. tariff shock is particularly compelling.\n\n4, Novel exploratory studies: The \"carrying memory to next life\" and \"living in multiple worlds\" experiments showcase creative applications enabled by the modular design, though they could benefit from deeper analysis."}, "weaknesses": {"value": "1, Limited theoretical novelty: While the engineering contribution is solid, the conceptual decomposition (LLM + config + memory + tools) is relatively straightforward and has been implicitly used in prior agent frameworks. The paper doesn't provide strong theoretical justification for why this particular decomposition is optimal or complete.\n\n2, Insufficient comparison with existing frameworks: The paper mentions AutoGen, Concordia, and EDSL but dismisses them too quickly without detailed empirical comparison. A systematic comparison showing Shachi's advantages would strengthen the contribution. The claim that these frameworks are \"not designed for reproducible social simulation\" needs more substantiation.\n\n3, Cross-task generalization results are underwhelming: Table 2 shows that most agents perform similarly across tasks (scores ≈ 1.0), which undermines the claim about the importance of modular components. The only clear difference is when tools are missing for tool-requiring tasks, which is unsurprising.\n\n4, Limited discussion of failure modes: The paper doesn't adequately discuss when the framework might fail or produce unrealistic behaviors. For instance, what happens when agents face novel situations not covered by their configuration or tools?\n\n5, Missing important implementation details:\n\n- How are conflicts between tools and memory resolved when both could apply?\n- What are the computational costs of the framework compared to alternatives?\n- How sensitive are results to LLM temperature, prompt variations, and other hyperparameters?\n- The \"two-stage parsing\" strategy (Appendix D.4) seems like a workaround but its necessity and implications aren't discussed"}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LJ8rsu0t7N", "forum": "30e3LnZzmI", "replyto": "30e3LnZzmI", "signatures": ["ICLR.cc/2026/Conference/Submission14546/Reviewer_NkDa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14546/Reviewer_NkDa"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14546/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762174411754, "cdate": 1762174411754, "tmdate": 1762924933623, "mdate": 1762924933623, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}