{"id": "OPZyJCdRvs", "number": 9797, "cdate": 1758140942503, "mdate": 1758812320255, "content": {"title": "Circuit Mechanisms for Spatial Relation Generation in Diffusion Transformers", "abstract": "Although Diffusion Transformers (DiTs) have greatly advanced text-to-image generation, models still struggle to generate the correct spatial relations between objects as specified in the text prompt. Although mechanistic interpretability studies have been adopted to explain neural networksâ€™ behavior in language and vision transformers from the perspective of the internal computation of representations, they have not yet been used to study how a DiT can generate correct spatial relations between objects. In this study, we investigate this open problem in a controlled setting. We train, from scratch, DiTs of different sizes with different text encoders to learn to generate images containing two objects whose attributes and spatial relations are specified in the text prompt. We find that, although all the models can learn this task to near-perfect accuracy, the underlying mechanisms differ drastically depending on the text encoder. When using random text embeddings, we find that the spatial-relation information is passed to image tokens through a two-stage circuit, involving two cross-attention heads that separately read the spatial relation and single-object attributes in the text prompt. When using a pretrained text encoder (T5), we find that the DiT uses a different circuit that leverages information fusion in the text tokens, reading spatial-relation and single-object information together from a single text token. We further show that, although the in-domain performance is similar for the two settings, their robustness to out-of-domain perturbations differs, potentially suggesting the difficulty of generating correct relations in real-world scenarios.", "tldr": "Different Text encoder of T2I diffusion leads to different circuit mechanism for relational object generation.", "keywords": ["Circuit analysis", "Diffusion models", "Causal interventions", "Relational representation", "scene composition", "generalization"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/90bddc7117b5e1a9d80a271b7d5234a4eaa5f650.pdf", "supplementary_material": ""}, "replies": [], "withdrawn": true}