{"id": "04JkPDiCnp", "number": 830, "cdate": 1756820032542, "mdate": 1759898239693, "content": {"title": "InternAgent-DR: Advancing deep research with dynamic structured knowledge flow", "abstract": "Deep research is an inherently challenging task that demands both breadth and depth of thinking. It involves navigating diverse knowledge spaces and reasoning over complex, multi-step dependencies, which presents substantial challenges for agentic systems. To address this, we propose InternAgent-DR (Deep Research), a multi-agent framework that actively constructs and evolves a dynamic structured knowledge flow to drive subtask execution and reasoning. InternAgent-DR is capable of strategically planning and expanding the knowledge flow to enable parallel exploration and hierarchical task decomposition, while also adjusting the knowledge flow in real time based on feedback from intermediate reasoning outcomes and insights.  InternAgent-DR achieves state-of-the-art performance on both general and scientific benchmarks, including GAIA, HLE, GPQA and TRQA, demonstrating its effectiveness in multi-disciplinary research scenarios and its potential to advance scientific discovery.", "tldr": "", "keywords": ["deep research", "multi-agent", "reasoning model"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1733de55f54fb9280e4bfee98aaf47ded2d07fd1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces InternAgent-DR, a multi-agent deep-research framework that models scientific reasoning as a dynamic structured knowledge flow. Instead of relying on a linear task sequence, InternAgent-DR represents research workflows as directed acyclic graphs whose nodes correspond to subtasks such as search, solve, and answer, and whose edges encode knowledge dependencies. The system integrates three major components: a Knowledge Flow Planner that incrementally expands the research graph, a Knowledge Collector that executes outermost nodes through LLM-based agents equipped with tools, and a Knowledge Flow Refiner that dynamically modifies the graph based on intermediate results. This design enables both hierarchical decomposition and adaptive refinement of complex research tasks. Extensive experiments on GAIA, GPQA-diamond, HLE, and TRQA benchmarks demonstrate that InternAgent-DR achieves state-of-the-art performance, surpassing existing open- and closed-source deep-research systems such as OpenAI-DR, OWL, and Manus. Ablation studies confirm the effectiveness of structured planning and flow refinement, and case studies show interpretability and reproducibility advantages."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper proposes a conceptually original formulation of deep research as a dynamic, graph-based reasoning process.\n2. The methodology is technically rigorous, with clearly formalized planner, collector, and refiner modules.\n3. Empirical evaluations on GAIA, GPQA, HLE, and TRQA show strong and consistent performance improvements over state-of-the-art baselines."}, "weaknesses": {"value": "1. The framework appears to be a recombination of existing ideas rather than a fundamentally new approach. The so-called “dynamic structured knowledge flow” closely parallels the workflow-graph paradigms already used in OWL, MiroFlow, and OpenAI Deep Research, where subtasks and dependencies are explicitly represented in similar ways. The three modules essentially re-label the standard planning–execution–reflection loop without introducing new reasoning mechanisms or learning algorithms. The contribution is primarily in system packaging and terminology, not in conceptual or methodological innovation.\n2. The paper lacks theoretical grounding and algorithmic depth. There is no formal analysis of convergence, scalability, or computational complexity. Claimed adaptivity and generalization advantages remain qualitative.\n3. The prompt design inside each agent plays a crucial role in determining performance, yet this factor is not systematically studied. Different baselines may use distinct prompting templates or instruction strategies, which can drastically affect outcomes. Without prompt-controlled ablations and prompt unification across baselines, it is unclear whether performance gains come from the proposed system design or from better prompt engineering.\n4. The evaluation setting lacks fairness control. The authors compare to several proprietary systems but do not ensure identical resource budgets, prompt contexts, or tool access, making the comparison potentially biased."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "F0Sq86M0oo", "forum": "04JkPDiCnp", "replyto": "04JkPDiCnp", "signatures": ["ICLR.cc/2026/Conference/Submission830/Reviewer_sJkB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission830/Reviewer_sJkB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission830/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761918635819, "cdate": 1761918635819, "tmdate": 1762915622522, "mdate": 1762915622522, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces InternAgent-DR, a multi-agent system for complex scientific reasoning and problem-solving. It models research as a dynamic structured knowledge flow, where nodes represent subtasks and edges encode dependencies, enabling adaptive planning, reasoning, and refinement. The framework integrates three modules—Knowledge Flow Planner, Knowledge Collector, and Flow Refiner—to iteratively expand, execute, and adjust research plans. Experiments on benchmarks such as GAIA, GPQA, HLE, and TRQA show state-of-the-art performance, suggesting improved adaptability and reasoning depth compared to both single-agent and static multi-agent systems"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Representing a deep research task as a graph is interpretable and flexible - and it avoids common issues with single-/multi-agent issues about serial plan execution\n- The pretty comprehensive evaluation benchmark results demonstrate great performance improvements"}, "weaknesses": {"value": "- Issues for fair comparison in evaluation: for an open-sourced agentic framework, I'd expect the authors to use the same model OWL/MiroFlow used to compare with them. We can't infer from the figure directly which model these open-source baselines used\n- Limited information about prompting: It is unclear how the system works in detail from reading this paper, since no exact prompts for each stage were included. It will be helpful if the authors can share the prompts for each component in the appendix.\n- The InternPlanner is trained via distillation on ~10k examples derived from Wikipedia-based or synthetic graphs, yet the paper offers little evidence of out-of-distribution robustness. Without evaluation on unseen domains or unseen question distributions, it is unclear whether the planner generalizes beyond GAIA-like setups.\n- Also, it is unclear to me whether *training the planner* is strictly necessary -- my guess is that it could work out of the box by prompting with a stronger model. I think some experiments for \"prompting+strong base model\" would help justify the need for a trained planner"}, "questions": {"value": "- How is the InternPlanner’s generalization evaluated beyond its distillation source domain? Have you tested it on novel task types or unseen topics?\n- Can you share more details about the prompts for each components\n- I'd love to see an ablation justifying the need of \"training the planner\", eg replace the trained planner by simplying prompting a stronger LLM and measure the end performance"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "snn8W0Ai2l", "forum": "04JkPDiCnp", "replyto": "04JkPDiCnp", "signatures": ["ICLR.cc/2026/Conference/Submission830/Reviewer_hqXd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission830/Reviewer_hqXd"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission830/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761945510456, "cdate": 1761945510456, "tmdate": 1762915622172, "mdate": 1762915622172, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes InternAgent-DR, a deep-research system that constructs and evolves a dynamic structured knowledge flow. Instead of linear task pipelines, the method builds a DAG-structured research graph to explicitly model subproblem dependencies, support parallel exploration, and adapt structure during execution. The system includes (i) a flow planner, (ii) a knowledge collector with tool-augmented LLM agents, and (iii) a flow refiner for graph-level self-revision. Experiments on GAIA, GPQA, HLE, and TRQA show state-of-the-art or competitive performance. Ablations indicate benefits from both structured planning and dynamic refinement."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Introduces a dynamic DAG-based research flow that evolves during execution, distinct from fixed linear pipelines. Emphasizes reflective graph refinement, paralleling execution and iterative plan refinement.\n\n2. Strong empirical results across diverse and challenging benchmarks. \n\n3. Good ablations isolating planner and refiner effects, trained planners outperform base models.\n\n4. Case studies demonstrate interpretability and node-level execution traceability.\n\n5. Presents a coherent and well-structured formulation of the system mechanism and workflow design."}, "weaknesses": {"value": "1. **Methodology and Limitations**\n- The method lacks theoretical grounding. It is unclear why the knowledge-flow refinement should systematically improve deep-research trajectories, and what precisely is being optimized during refinement (structure? retrieval quality? evidence routing?). The contribution currently rests largely on empirical results without a principled justification.\n\n- The core idea of dynamic plan adjustment based on execution status is compelling. However, the paper fails to discuss or compare its approach with other methods that employ similar reflective mechanisms. For instance, Aworld utilize \"guard reasoning\" for dynamic reflection and plan expansion, which might be a more cost-effective approach. While the proposed method may achieve higher accuracy, a comparative discussion is necessary to position its contribution accurately.\n\n- The paper lacks a discussion of the method's potential limitations and failure scenarios.\nFor example, does frequent plan refinement introduce prohibitive computational overhead? On challenging problems, could the agent get trapped in refinement loops or even diverge from a correct solution? If an execution error is caused by a faulty tool call, could the subsequent plan adjustments lead the agent further astray? \n\n- A clear analysis of failure cases and the system's fault tolerance mechanisms is currently missing.\n\n\n2. **Analysis of the Refiner**\n\n- The ablation study identifies the Refiner as the source of the largest performance gains, yet the analysis of its effectiveness is not enough. the analysis of its effectiveness is insufficient and does not provide a deep dive into its mechanism. \n\n- Moreover, I am curious about the performance improvement on GAIA Level-1 tasks, as they typically have clearer execution paths. As practices from other agents like Skywork-DR suggest, a robust planner should handle such tasks effectively without extensive refinement. This raises serious questions about the baseline Flow Planner used in the study; its design may be suboptimal, thereby inflating the perceived contribution of the Refiner.  Stronger planner baselines or cross-agent planner comparisons are required to isolate the true contribution.\n\n3. **Collector–Refiner Interface Not Specified**\n\nThe paper does not clearly describe what form the collected information is provided to the Refiner in(e.g., raw tool traces, distilled node summaries,or full textual context). Without clarity on representation and conditioning, it is difficult to understand how the Refiner:\n\n- incorporates execution signals,\n\n- avoids being misled by noisy tool outputs, and maintains reasoning fidelity during refinement.\n\nGreater transparency here would improve interpretability and reproducibility.\n\n4. **Knowledge Collector Reliability**\n\nExecution correctness in deep-research settings is not binary. Search tools may “succeed” but return irrelevant text; browser automation may execute actions that do not advance reasoning. The paper does not clarify:\n\n- How execution quality is evaluated beyond binary success/failure\n- How noisy or irrelevant evidence is suppressed\n- How incorrect tool outputs are prevented from influencing refinement\n\nThe paper lacks theoretical innovation and is primarily an engineering-driven empirical system contribution."}, "questions": {"value": "1. How does the Refiner theoretically improve reasoning? What objective or latent structure is being optimized?\n\n2. Why does refinement boost GAIA-Level-1 task, does this imply a weak baseline planner?\n\n3. How do you prevent refinement loops, over-expansion, or divergence under noisy tool execution?\n\n4. How are node execution signals summarized and fed into the Refiner? Are there safeguards to identify knowledge quality before refinement?\n\n5. Can you add comparisons with AWorld / Skywork-DR and clarify base model settings for all agent baselines?\n\n6. What is the compute overhead per refinement cycle, and is there a refinement-budget policy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qJmSCE5pAH", "forum": "04JkPDiCnp", "replyto": "04JkPDiCnp", "signatures": ["ICLR.cc/2026/Conference/Submission830/Reviewer_mnNE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission830/Reviewer_mnNE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission830/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761985575160, "cdate": 1761985575160, "tmdate": 1762915622026, "mdate": 1762915622026, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes InternAgent-DR **,** a multi-agent deep research system that builds and continually refines a knowledge flow (planner → collector → refiner) to coordinate subtasks and dependencies. Experiments on GAIA, HLE, GPQA, and TRQA report strong or SOTA results, with ablations showing benefits from structured planning and dynamic refinement."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* Clear, principled formulation of a dynamic knowledge DAG.The paper formalizes nodes (typed subtasks with state/context) and edges (dependency relations) and argues this captures non-linear dependencies while enabling parallelism and verifiable execution; the end-to-end loop (planner/collector/refiner) is well-motivated.\n* Compelling empirical results across diverse benchmarks. InternAgent-DR (especially with o4-mini) achieves leading scores on GAIA and HLE and strong performance on GPQA/TRQA; ablations isolate gains from the flow planner and  flow refiner .\n* Reasonably transparent system details and tooling. The paper lists concrete tool wrappers used by the Knowledge Collector and describes a two-mode summarizer for QA vs. report generation—useful for reproducibility and for readers attempting to re-implement."}, "weaknesses": {"value": "## Major Weaknesses\n\n1. **Fragmented main results and missing agentic baselines.** Table 1 shows many unreported entries (“–”) across GAIA/GPQA-diamond/HLE, resulting in fragmented and unfair evaluations. Notably, several agentic frameworks lack GPQA-diamond results in the table (e.g., OpenAI-DR has GAIA/HLE but no GPQA), so comparisons on this science-heavy benchmark fall back to base models rather than agentic systems. This weakens claims about advantages over agents on GPQA-diamond.\n2. **Baseline pool under-represents the field and conflates categories.**\n   The comparison set mixes a few proprietary/open frameworks with many base models, but omits a broad slate of contemporary DR agents. Please distinguish and cover both categories: (a) Open-source DR models: WebDancer, WebSailor, DeepResearcher, WebShaper etc. The authors mentioned WebDancer in related work but did not evaluate it. (b) Open-source DR frameworks : JoyAgent, OAgents, WebWeaver, DeerFlow, AFlow, Skywork etc.\n3. **Limited methodological novelty beyond well-known agent paradigms**. The core pipeline—Planner → Collector → Refiner running over a node-edge knowledge flow/DAG —largely mirrors prevalent graph-orchestrated agent patterns (orchestrator/worker, iterative refinement) rather than introducing a fundamentally new algorithmic idea. The paper formalizes incremental graph expansion and a set of graph edits (Add/Remove/Modify node/edge) but these are standard graph transforms; there is no new planning/search objective, scheduler, or learning signal that makes the “knowledge workflow” qualitatively different from prior graph-based agent stacks (e.g., LangGraph-style DAG orchestration or ToT/GoT/AoT-like task decomposition). This makes the contribution feel engineering-centric rather than conceptually novel.\n4. **Attribution of gains is underspecified, ablations are narrow.** The ablation isolates “structured planning” and “refinement,” but remains confined to GAIA/GPQA and does not disentangle improvements due to (a) planner prompting/training, (b) tool repertoire, or (c) execution policy (parallelism/scheduling). Table 2 and Table 3 show benefits from the Flow Planner/Refiner and from the fine-tuned InternPlanner, but there is no head-to-head against graph-driven agents with matched backbones/tool budgets to attribute gains to the proposed workflow rather than to planner quality or base model capacity. A stronger attribution study is needed (e.g., same backbone, same tools, replacing only the orchestration logic).\n\n## Minor Weaknesses\n\n1. **Reporting gaps on cost, reliability, and failure modes.** There is little quantification of compute/tool-usage cost, latency, or robustness (e.g., tool failure rates, noisy retrieval) under the dynamic DAG loop, and no human evaluation of usability or interpretability for researchers\n2. **Claims of general superiority outpace evidence; scheduling/efficiency untested.** The text asserts that a general-purpose, knowledge-flow agent “outperforms specialized systems” (e.g., on HLE), and repeatedly describes parallel execution and dynamic refinement as efficiency enablers, but provides no quantitative analysis of scheduler behavior (throughput/latency), failure recovery costs, or scaling vs. graph size. Without such evidence (speedups, queueing, deadlock avoidance, token/compute budgets per node type), the efficiency narrative remains claim-level rather than experimentally supported.\n3. **Dataset and generalization concerns**. The InternPlanneris distilled from o4-mini on synthetic Wikipedia-derived graphs; the paper provides limited analysis of transfer to open-domain research beyond the chosen benchmarks and limited discussion of potential training-data leakage/contamination.\n4. **Lack of significance analysis**. Due to network/tool latency, API nondeterminism (e.g., retrieval variance, page dynamics), and sampling randomness of the backbone LLMs, DR agents typically exhibit high run-to-run variance. Their experiments report single-point scores without confidence intervals or multi-seed statistics; no paired significance tests are provided to establish that the reported gains are robust rather than noise."}, "questions": {"value": "The appendices list tool wrappers and the two-mode summarizer, and the planner dataset (10k) is described, but the paper does not clearly commit to releasing code, prompts, or the planner dataset, limiting external verification and community adoption. A precise release plan (what/when) would materially strengthen the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2JPa5Z3Bum", "forum": "04JkPDiCnp", "replyto": "04JkPDiCnp", "signatures": ["ICLR.cc/2026/Conference/Submission830/Reviewer_FiJa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission830/Reviewer_FiJa"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission830/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989766869, "cdate": 1761989766869, "tmdate": 1762915621805, "mdate": 1762915621805, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}