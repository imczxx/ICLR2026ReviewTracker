{"id": "ZmGfCj1n2P", "number": 19085, "cdate": 1758293480884, "mdate": 1759897061553, "content": {"title": "A robust PPG foundation model using multimodal physiological supervision", "abstract": "Photoplethysmography (PPG), a non-invasive measure of changes in blood volume, is widely used in both wearable devices and clinical settings. Although recent work has explored PPG foundation models using large-scale intensive care unit (ICU) datasets, these efforts often assume the need for clean and high-quality signals. In contrast, we argue that the inherent noise and variability in ICU datasets can be harnessed to build more robust and generalizable representations. To address this, we propose a PPG foundation model that leverages accompanying electrocardiogram and respiratory signals in ICU datasets to select contrastive samples during pretraining. Our approach allows the model to retain and learn from noisy PPG segments, improving robustness without requiring multimodal inputs at inference. Our model, pretrained on 3x fewer subjects than existing state-of-the-art approaches, achieves performance improvements of up to 36\\% in classification and 42\\% in regression on 14 out of 15 diverse downstream tasks, including stress and heart rate prediction. Our results demonstrate that multimodal supervision can leverage clinical data to enable the development of robust, unimodal foundation models for both clinical and consumer-level data.", "tldr": "", "keywords": ["Photoplethysmography (PPG)", "health", "ubiquitous computing", "foundation model", "wearables", "representation learning", "multimodal", "self-supervised learning", "time series", "physiology"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ac46dea38037fc923116b84388becf7d9cf07481.pdf", "supplementary_material": "/attachment/c8a7357b3b272c6331a67ca4aac32070341a462b.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes a robust PPG foundation model that leverages ECG and respiratory signals to guide sample selection during contrastive learning. The paper emphasizes that by integrating complementary biosignal modalities, the proposed approach effectively mitigates the limitations of unimodal, morphology-based contrastive targets, resulting in substantially improved robustness, generalization, and downstream task performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper’s focus on multi-modal supervision is well-motivated, particularly given that health is inherently multi-modal while most existing foundation models remain unimodal.\n- In general, the ablation and case studies offer meaningful insights and contribute to understanding the model’s behavior and robustness.\n- The paper is clearly written, well-organized, and easy to follow."}, "weaknesses": {"value": "**Method:** The proposed approach employs five key physiological metrics from ECG and RESP: HR, RMSSD, RR, RA, and RV to guide multi-modal supervision during pre-training, enabling the model to learn corresponding representations in the latent space. However, many of the downstream tasks evaluated (e.g., HR, BP, and activity recognition) are directly related to these same input measures. This raises concerns about potential task overlap and limited generalization. How can this design choice be justified? If the input features and downstream tasks are closely aligned, it becomes unclear whether the learned representations truly generalize beyond the pre-training objectives. Perhaps, consider evaluations on tasks that are novel and not previously explored. \n\n**Experimental Design**: \nThere are two major concerns with the experimental design: **(1) the choice of baseline** and **(2) the use of derived metrics for training**.\n\nFirst, the experiments rely heavily on PaPaGei as the sole baseline. While PaPaGei is a reasonable point of comparison, it cannot be the only one. The key issue is that PaPaGei is trained exclusively on PPG signals, whereas the proposed model leverages multi-modal supervision, including ECG and respiratory signals. Comparing a unimodal foundation model with a multi-modal supervised one introduces an inherent imbalance and may not provide a fair assessment of performance gains.\n\nSecond, the rationale for using derived physiological metrics (HR, RMSSD, RR, RA, and RVT) during pre-training needs stronger justification, especially since these metrics are closely correlated with several downstream tasks. It remains unclear whether their inclusion in pre-training offers benefits beyond what could be achieved by incorporating them at the linear probing stage alongside the learned embeddings. More fundamentally, how would a simple baseline model trained directly on these five derived features perform on the same downstream tasks? Addressing this question would help clarify the true contribution of the proposed approach.\n\n**Minor:**  \nFigure 3 — The comparison of UMAP plots for heart rate may not be meaningful, as the proposed approach uses heart rate as part of its pre-training objectives, whereas the baseline models do not. Consequently, it is expected that the proposed model exhibits a clearer gradient structure in the latent space, which limits the interpretive value of this comparison.\n\n**Ablation Study:** It would be valuable to analyze the individual contribution of each computed metric derived from the co-recorded signals. Specifically, examining the effect of using HR, RMSSD, RR, RA, and RVT during pre-training, either by incorporating one metric at a time or by comparing groups of metrics (e.g., ECG-based vs. respiratory-based). This could provide deeper insights into which modalities or features most influence model performance.\n\n**Open-Source**: The models and code are not publicly released, even though the proposed approach is trained and evaluated on open-source datasets. This limits the reproducibility of the work and weakens its overall contribution, particularly given that other open-source PPG foundation models already exist [1, 2].\n\nOverall, the main contribution of this work appears to be the inclusion of additional biosignal modalities during contrastive pre-training, which improves the performance of a PPG foundation model. While this idea is interesting, the contribution is not sufficiently significant, as prior studies have already explored unimodal versus multimodal representations in similar contexts [3, 4]. Importantly, given the limitations in the experimental design, methodological justification, and lack of open-source release discussed above, I lean toward a weak reject recommendation.\n\n[1] Pillai, A., Spathis, D., Kawsar, F., & Malekzadeh, M. (2024). Papagei: Open foundation models for optical physiological signals. _arXiv preprint arXiv:2410.20542_.\n\n[2] Saha, M., Xu, M. A., Mao, W., Neupane, S., Rehg, J. M., & Kumar, S. (2025). Pulse-ppg: An open-source field-trained ppg foundation model for wearable applications across lab and field settings. _Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies_, _9_(3), 1-35.\n\n[3] Zhou, Y., Khasentino, J., Yun, T., Biradar, M. I., Shreibati, J., Lai, D., ... & Hormozdiari, F. (2025). Applying multimodal AI to physiological waveforms improves genetic prediction of cardiovascular traits. _The American Journal of Human Genetics_.\n\n[4] Ezzameli, K., & Mahersia, H. (2023). Emotion recognition from unimodal to multimodal analysis: A review. _Information Fusion_, _99_, 101847."}, "questions": {"value": "- Are there other ECG and RESP metrics that can be used during contrastive pre-training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "uDDB9noDXN", "forum": "ZmGfCj1n2P", "replyto": "ZmGfCj1n2P", "signatures": ["ICLR.cc/2026/Conference/Submission19085/Reviewer_PDvh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19085/Reviewer_PDvh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761808722518, "cdate": 1761808722518, "tmdate": 1762931108755, "mdate": 1762931108755, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a PPG foundation model pretrained on multimodal ICU data, where synchronized ECG and respiratory signals guide contrastive learning to derive robust and generalizable PPG representations. Compared with prior single-modality approaches (e.g., PaPaGei), the model leverages noise and signal variability more effectively, achieving substantial performance gains on 14 out of 15 downstream tasks across six unseen datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This study leverages ECG and respiratory signals to enhance PPG representation learning, demonstrating a solid understanding of the physiological mechanisms underlying PPG.\n2. It evaluates both cross-subject and within-subject settings, providing a comprehensive view of the model’s generalization performance.\n3. The proposed model achieves significant performance improvements over PaPaGei across multiple downstream tasks."}, "weaknesses": {"value": "Key Concerns:\n1. The study compares the proposed model only with PaPaGei, which limits the comprehensiveness of the evaluation. It is recommended to include additional self-supervised or pretrained baselines (e.g., SimCLR, PulsePPG) to strengthen the experimental validity.\n2. The paper claims that the inherent noise and variability in ICU data can be leveraged to improve model robustness. However, the proposed pretraining approach relies on five contrastive objectives computed from synchronized ECG and respiratory signals. It remains unclear how the authors ensure that these auxiliary signals remain reliable when the PPG signal quality deteriorates (e.g., due to patient motion). As a result, this claim may be somewhat overstated, since the method appears to focus more on multimodal assistance for PPG representation learning rather than on directly addressing signal quality issues.\n3. Although the proposed model performs well on downstream tasks, concerns remain regarding its cross-dataset generalization. The model is pretrained solely on the MIMIC dataset, while larger and more diverse publicly available datasets such as MESA or VitalDB could have been incorporated to build a more comprehensive pretraining corpus. Although the authors mention that sleep or anesthesia data may contain relatively stationary signals, incorporating more heterogeneous datasets could capture a wider range of physiological patterns and improve the model’s robustness and generalization.\n4. The method employs only derived features from ECG and respiratory signals instead of the raw multimodal inputs, which may constrain the model’s ability to capture complex temporal dependencies.\n\nMinor Concerns: \n1. Although the number of subjects used is one-third of that in PaPaGei, the total number of data segments is comparable, thus the claim of higher data efficiency is not entirely justified.\n2. The method employs only derived features from ECG and respiratory signals instead of the raw multimodal inputs, which may constrain the model’s ability to capture complex temporal dependencies.\n3. Table 1 does not report the number of subjects and total samples for each downstream dataset, which makes it somewhat difficult to fully assess data balance and generalization stability."}, "questions": {"value": "1. Could the authors clarify whether the auxiliary signals (ECG and respiration) remain reliable for contrastive supervision when the PPG signal quality is low, for instance due to patient motion?\n2. Would it be possible to include additional self-supervised baselines such as SimCLR, BYOL, or PulsePPG for a more comprehensive comparison?\n3. Could the authors elaborate on the rationale for using derived metrics instead of full multimodal inputs, and whether any experiments were conducted to validate this design choice?\n4. It would be helpful to provide statistics on the number of subjects and total samples for each downstream dataset, to better contextualize task scale and model performance.\n5. Incorporating downstream tasks related to cardiac arrhythmias (e.g., atrial fibrillation) could further demonstrate the model’s ability to handle abnormal cardiac patterns."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LV7HqoG7kG", "forum": "ZmGfCj1n2P", "replyto": "ZmGfCj1n2P", "signatures": ["ICLR.cc/2026/Conference/Submission19085/Reviewer_zKep"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19085/Reviewer_zKep"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761829875780, "cdate": 1761829875780, "tmdate": 1762931108177, "mdate": 1762931108177, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a PPG foundation model pretrained on noisy ICU PPG by using ECG and respiration only during pretraining to compute HR, RMSSD, breathing rate, breathing amplitude, and RVT. A rank-n-contrast loss then pulls PPG embeddings closer when the targets are similar, aiming to learn noise-robust representations."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Clear, physiologically grounded supervision: Using ECG/RESP to form targets avoids brittle PPG morphology extraction, yet preserves unimodal inference. The target set (HR, RMSSD, RR, RA, RVT) is plausible for 10-s windows and filtered for physiological ranges."}, "weaknesses": {"value": "- The contribution of the method is trivial and uses the common infoNCE loss. The authors only consider the physiological parameters to decide the positive and negative pairs.\n- The robustness of HR/RMSSD/RR/RA/RVT estimation on 10-s windows (detectors, failure handling, thresholds) is crucial; more explicit error rates/quality filters would strengthen claims about the stability of the metric space.\n- The final backbone checkpoint is chosen by VitalVideos systolic BP probe performance for practicality. This could inadvertently bias toward that dataset/task; a small sensitivity analysis (random/earliest/best-avg across a subset) would help.\n- The final backbone is ~28.8M params vs PaPaGei’s ~5–5.7M. The architecture ablation shows gains even when the architecture differs, but fully disentangling capacity from supervision remains tricky without equal-capacity baselines for all comparisons.\n- No fine-tuning heads or end-to-end adaptation are reported; it’s unclear how the model behaves under modest supervised finetuning, which is typical in practice."}, "questions": {"value": "Please see the weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xvsg1yN8mg", "forum": "ZmGfCj1n2P", "replyto": "ZmGfCj1n2P", "signatures": ["ICLR.cc/2026/Conference/Submission19085/Reviewer_ye6c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19085/Reviewer_ye6c"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19085/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762501092209, "cdate": 1762501092209, "tmdate": 1762931107366, "mdate": 1762931107366, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}