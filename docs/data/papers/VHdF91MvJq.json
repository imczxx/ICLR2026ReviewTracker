{"id": "VHdF91MvJq", "number": 18687, "cdate": 1758290114632, "mdate": 1759897087529, "content": {"title": "On Measuring Influence in Avoiding Undesired Future", "abstract": "When a predictive model anticipates an undesired future event, a question arises: what can we do to avoid it? The key to resolving this forward-looking challenge lies in determining the right variables that influence the result, moving beyond statistical correlations typically exploited for prediction. In this paper, we introduce a novel framework for evaluating the influence of alterable variables in successfully avoiding the undesired future. We quantify influence as the degree to which the probability of success can be increased by altering variables based on the principle of maximum expected utility. A crucial insight from our analysis is that the most influential variables may not necessarily be those with inherently strong causal effects on the future event. In fact, it can be highly beneficial to alter a weak causal ancestor, or even a variable that is not a causal ancestor at all. Furthermore, to overcome the practical challenges of exact computation, we provide a Monte-Carlo method for efficiently assessing influence using observational data. Experiments demonstrate the empirical performance of the proposed framework.", "tldr": "We provide a principled framework for measuring influence in avoiding undesired future.", "keywords": ["avoiding undesired future", "rehearsal learning", "causal learning"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9a80c4388a12f60626ac09ecba09e8ff665d68a3.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces the notion of influence power, a measure of the potential\nimportance of a variable for preventing a system from leading to an undesirable\noutcome. This notion is related to, but is shown to differ, to that of average\ncausal effects. The paper also introduces a UCT-based Monte-Carlo Tree Search\nestimator (from noiseless observational data). Theoretical support is provided\nfor the consistency of the estimator in the unconfounded case, as well as\nempirical support on three toy tasks with noiseless data."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "**Originality**: to the best of my knowledge, the contribution is novel. It\nis definitely related to work in utility maximization and possibly algorithmic\nrecourse, but it is also different enough -- as clarified by the authors.\n\n[**Q**] Could you please clarify the points of difference with works in causal\nalgorithmic recourse? E.g., the works by Karimi and colleagues.  I'm sure this\nwould help the readers.\n\n**Quality**:\n\n**Clarity**: The text is well written and easy to follow.  All key definitions\nand arguments are accompanied by illustrative examples, which help a lot.\n\n**Significance**: I am not the most well versed in algorithmic decision making,\nbut I think this paper provides a useful contribution mixing elements from causality and decision making, and it could open the door to further research.\n\nI'm curious to know what the other reviewers think."}, "weaknesses": {"value": "Focus on constructive and actionable insights on how the work could improve\ntowards its stated goals.\n\n**Clarity**: No major complaints on my end, but I did notice a handful of small\nlinguistic idiosyncrasies, such as:\n\n- Title: I'm not a native English speaker, but the sentence \"avoiding\n  undersired future\" sounds off to me. What about \"Avoiding undesirable future\n  events\"? This is how it's written in the abstract and it works just fine.\n\n- \"alterable variable\" also sounds off to me -- what about \"actionable variable\"?\n\n- Section 2, Notation: I don't think the notation {\\cal M}_{V_i} used\n  elsewhere in the text, it can probably be removed. Especially because it\n  looks incorrect: I suspect it should be {\\cal M}_{v_i} instead (lower case,\n  constant).\n\n- Section 2, Problem Definition: no need to repeat that \\Delta_{V_i} is the\n  alterable domain. This was already introduced previously.\n\n- Section 3.2: \"an alterable variable are worth\" -> is worth.\n\n- Section 3.3: \"Also, a variable such as...\" - why \"also\"? I'd drop it.\n\n- Above Example 4: \"it is not a causal\" -> \"not being a causal\".\n\nA minor issue is it's not immediately obvious to see the difference between\nthe two main terms in the main equation (at the end of p 3): one contains an\nintervention, the other an observation, but they are marked as \"a\" and \"o\",\nwhich are quite difficult to recognize as different. Perhaps use color to\nhelp the reader? The equation is much easier to understand once one spots this\notherwise tiny difference ;-)\n\n**Significance**: [**Q**] It'd be good to report the runtime difference between the\nthree algorithms (the baselines and the MCTS estimator). The results indicate\nthe estimator outperforms the baselines, which is good, but without\nunderstanding the its computational cost it's difficult to gauge whether the\nbenefits are worth it. This is my only major complaing with the work.\n\n[**Q**] It'd also be good to clarify from the get go - as soon as the introduction -\nthat Proposition 1 works only for unconfounded models (\"independent background\nnoises\"), which can be a strong assumption in practice, for clarity."}, "questions": {"value": "I'd appreciate if the authors could comment on the points I've marked as [**Q**] above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "4layzQcGw6", "forum": "VHdF91MvJq", "replyto": "VHdF91MvJq", "signatures": ["ICLR.cc/2026/Conference/Submission18687/Reviewer_rkWZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18687/Reviewer_rkWZ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18687/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761884684773, "cdate": 1761884684773, "tmdate": 1762928388339, "mdate": 1762928388339, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present a novel approach to the AUF (avoiding undesirable future) problem\nwhich improves on SOTA (one-alteration and all-alteration). Their approach can also capture negative\ninfluence, ie changes which are strictly bad with respect to a given target. They use a Monte Carlo\nalgorithm to make estimating their measure more efficient (than brute force). They evaluate their\nmethod on three standard(?) problems and show that their measure allows them to compute\ninterventions which increase the chances of the model reaching the desired target region."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "I quite like this paper, I'd give it a weak accept. It's far from perfect, the novelty (while\nthere) is not earth-shattering and most of the worked\nexamples are little more than toys, but I enjoyed reading it."}, "weaknesses": {"value": "I quite like this paper, I'd give it a weak accept. It's far from perfect, the novelty (while\nthere) is not earth-shattering and most of the worked\nexamples are little more than toys, but I enjoyed reading it. See the questions below."}, "questions": {"value": "(numbers are line numbers)\n\n089 how much is nearly negligible?\n103 it is assumed that all variables are alterable? How strong is this assumption?\n- it feels like a very strong assumption to me, as any variable on the causal path (or off of it)\n  can be directly manipulated. This certainly does not reflect real world limitations.\n\n104 \"desired region\" feels a little vague. S is a subset of the possible values of Y?\n107 \"as much as possible\" is also rather vague. Is there an implicit threshold or ratio here?\n\nI don't think that eq 2 implies that all variables *must* be altered, only that they can be altered.\nAfter all, the equation simply states that we must go over all variables and set their values, but\nit does not state that the values must be **different** from observed. So the criticism on l.139 does not hold.\n\n133 do not use contractions\n\n155 I don't like the way this is presented. k = d comes out of nowhere, and the MEP and AUF\nequations appear to be identical at this point. It's only later that it becomes (slightly) more\nobvious that this is deliberate.\n\n158 eq 3 is not well formatted. =o, unlike =a, has not been previously defined. Presumably it means\nsetting V_k to its actual value in the context. But wait, we get the definition on l.164. This is\nbackwards and very hard to read. Why not use <- for alteration, and = for observation?\n\n173 Def 1: clearly related to average causal effect. Is it a generalisation?\n\n211 causality need not be transitive. See Halpern for a detailed discussion.\nIt is also not that surprising that a alterable variable be non-influential. After all, the variable\nmay cause an exact value of Y in S, but not have sufficient influence to move out of S.\n\n200 notation for \\tau is really buried in the text here.\n\n226 this is a slightly forced example, as X and Z are essentially independent, they are both on the\ncausal path, but X is not a cause. However, it's good to see that IP can detect this.\n\n245 here we have the problem of talking about negligible ACE, as 0.08 is surely very low. Is this\nnegligible (see comment above)?\n\n262 again, not a surprising result. And the influence (271) is small.\n\n274 small note, but it should read \"considering altering\", not \"considering to alter\"\n\n278 \"despite it not being a causal ancestor\"\n\nExample 4. I do not understand your explanation. It is not intuitive (to me) and seems quite\nan important point. This needs clarification.\n\nEq (9) is the \\delta embedded in the equation standard notation for something?\nWhat is A hat? The MC approximation of A at any point?\n\n420 \"repeat experiment _with_ ten times\"\n\n421 I looked at Appendix A. I'm slightly disappointed by how small/simple the examples are. I wonder\nhow well the MC sampling approach would work on bigger/more difficult models. Moreover, they are\nlargely identical to your examples. I think you could just merge this together, name the examples\nappropriately, highlight differences if they exist, and remove the appendix. It would make it much\neasier to read.\n\n438 \"demosntrating\"\n\nFigure 2 is very small and quite difficult to read. Please replot or make larger for camera ready.\n\nTable 1 does not show how much work is required for your MC method. Your results are already better\nat T=10. I'd like an idea of how much comparable work is performed by Max-One and Max-All.\nI'm assuming (because it's not in the comment at least) that these are mean values. While I'm not in\nfavour of unnecessary statistical analysis, some might be appropriate here. Perhaps a box plot might\nbe more revealing here, as the standard deviations are quite large for all the tools, and this is\nsomeone obscured by presenting the data as a table.\n\nThe results seems to follow a logaritmic curve... why is this? Is this a limitation of the the MC\nmethod? After all, it should be possible, if all variables in V are alterable, to always guarantee Y\nin S? Or is this a result of the fact that you cannot alter variables before some point d?\n\nConclusion section. \"intriguing possibility...\" but I do not understand why this happens, and your\nintuition above is not (to me) intuitive. I could perhaps see the sharing of information via mutual\ninformation at play, but this is non-directional. Is this not instead revealing a limitation in\n(Pearl's conception of) SCMs based on probabilities? It's probably always possible to construct\nthese pathological examples (because they are divorced from real data producing systems) but do they\nreally tell us anything interesting, other than to look at for these potential errors?\n\n_Questions_:\n  * distance of alterations from outcome Y. Are they usually proximate or far away?\n  * are interventions consecutive or disjoint in general?\n  * are there any patterns/implications in distance from Y?\n\n  * frequency of achieving S in your simulations?\n      + S is always limited to one outcome I think, so the entire thing is boolean. Will this scale\n    to non-boolean settings.\n  * size of alterations vs frequency of S?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GCbt6Wh9Yh", "forum": "VHdF91MvJq", "replyto": "VHdF91MvJq", "signatures": ["ICLR.cc/2026/Conference/Submission18687/Reviewer_NVBs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18687/Reviewer_NVBs"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18687/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761922091574, "cdate": 1761922091574, "tmdate": 1762928387974, "mdate": 1762928387974, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces *Influence Power*, a metric aimed at quantifying how altering a variable affects the probability that an outcome variable falls within a predefined desired region ($P(Y\\in S)$).\n\nThe authors build on a Bellman-style recursive formulation and define Influence Power as the difference between the optimal success probability under intervention and the expected success under natural observation. They then propose a Monte-Carlo tree search (MCTS) approach to approximate influence power using observational data.\n\nExperiments on small synthetic SCMs suggest that the proposed MCTS approach outperforms trivial baselines in increasing $P(Y\\in S)$."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- Influence power is a novel metric that combines ideas of potential intervention effect and value-of-information analysis.\n- The recursive Bellman-inspired formulation is a creative way to connect causal reasoning with sequential decision making. If done right, this could be impactful.\n- Examples 1-4 clearly illustrate the core intuitions (but their extended form could be moved to the Appendix)."}, "weaknesses": {"value": "- Conceptual confusion: counterfactual vs. interventional reasoning\n\nThe AUF problem is framed as counterfactual (\"given that the world will look like X, what if we changed Z?\"), but the paper only computes interventional and observational probabilities. This gap violates the Causal Hierarchy Theorem [1]: interventional data alone cannot answer counterfactual queries. For example, in lines 11-12: \"When a model predicts an undesired outcome, it is often crucial to determine what we can change to avoid it.\". Posed this way, it is theoretically impossible to solve the AUF problem (at least exactly). The formulation in the paper, though, is closer to a sequential decision process (or a planning problem) than to counterfactual inference. The authors likely need to just write their problem more formally to make this clear. See more points below around assumptions and the concept of time.\n\n[1] Bareinboim et al. \"On Pearl's Hierarchy and the Foundations of Causal Inference\", 2020\n\n\n- Ambiguous use of time and ordering\n\nThe paper implicitly assumes a temporal sequence of variables $(V_1,\\dots,V_d,Y)$ but **SCMs are static**.\nPhrases such as \"subsequent variables\" or \"before Y is finalized\" suggest temporal evolution, yet this is never formalized (no explicit time, transition, or policy definition).\nThe authors effectively simulate time by imposing a topological order, conflating causal order with temporal decision order (see below for discussion of ACE suitability to this setting). To resolve this ambiguity, the authors need to formalize their problem within a framework that supports time (Example unclear question: Are all variables observed before Y is realized? I would guess yes, but it's very unclear). \n\n\n- Unclear problem definition and assumptions\n\nKey assumptions are not clearly stated:\n\n1. Causal sufficiency (no hidden confounders) seems assumed but contradicted by examples involving an unobserved $U$. For instance, in example 4 the agent must choose $X$ without access to $U$, even though $U$ influences both $X$ and $Y$. From the decision-maker's perspective, $U$ acts as a hidden confounder, creating an inconsistency with the assumption of causal sufficiency (the time dimension is what makes this so complicated).\n2. Is the causal order taken as known? (I assume yes after reading Proposition 1)\n3. Positivity/overlap conditions for feasible alterations are unstated.\n4. The predictor $h(x)$ is mentioned in preliminaries but never used formally.\n\nThe absence of assumptions makes the formal objective of the AUF problem ambiguous.\n\n\n- Misinterpretation of causal relationships\n\nSeveral claims conflict with standard causal semantics. Some examples:\n\n1. *Example 2:* the paper concludes that altering $X$ is \"counterproductive\" despite a positive ACE. In standard SCMs, this is impossible. The claim arises only because intervening on $X$ destroys information useful for later decisions (N.B. SCMs don't support time and order of decisions).\n2. *Example 4:* a non-ancestor variable $W$ is said to have positive influence on $Y$. In causal terms, $do(W)$ cannot affect $Y$ at all. The \"influence\" is because of the effect of $W$ on how informative later observations are, not on the data-generating process itself.\n\nHence, \"influence\" in this paper measures more like *policy utility* rather than *causal effect* (which is also why comparing to ACE is not very suitable, see next point).\n\n\n- Over-reliance on ACE comparisons and why ACE is unsuitable for the current formulation.\n\nThe paper repeatedly contrasts Influence Power with ACE.\nACE is defined for **static SCMs**.\nComparing it to a metric that implicitly models information propagation over time is conceptually inconsistent. If the SCM were explicitly **unrolled over time** (with one variable per time step) and ACE were computed in that temporal formulation (e.g., changing $W_0$ and measuring its effect on $Y_t$), the comparison would then be meaningful, and $W_0$ would indeed be a causal ancestor of $Y_t$, even though it's not a causal ancestor of $Y_0$.\n\nAdditionally, ACE measures the *expected* change in $Y$ when a binary variable flips from 0 to 1. It is not informative when the goal is to increase the probability that $Y$ falls within an arbitrary region (even in a counterfactual setting, such reasoning is on an individual level, while ACE is population level) or when variables are non-binary. This comparison adds little insight and occasionally misleads (e.g., claiming that a variable with negligible ACE may still be \"highly influential\").\n\n- Toy experiments and limited validation\n\n1. The experiments involve only tiny binary SCMs, no non-linear or continuous settings are tested.\n2. The baselines (\"max-one\", \"max-all\") are trivial (and arguably not suited for this problem without SCM unrolling), so improvement isn't that unsurprising. There should also be a comparison to a baseline that only observes.\n3. No runtime analysis or sensitivity tests ($\\alpha$ parameter, wrong topology, data size). For example, MCTS becomes expensive as the number of alterable variables grows, since the tree expands exponentially.\n4. The claim that \"a rough approximation suffices\" lacks evidence.\n\nFurthermore, the experiments evaluate success in expectation over the entire data-generating process rather than at the level of individual contexts.\nIn each task, the authors compute ($P(Y\\in S)$) under different alteration strategies averaged across all exogenous realizations. This measures population-level effects but not the per-instance decision problem implied by the AUF formulation (\"given this particular observation, what should be altered to avoid the undesired future?\"). Consequently, the experiments do not validate whether influence power improves decision-making for specific predicted outcomes. They only show population-level improvements. This is misaligned with what AUF is framed as, a context-specific (conditional) decision problem.\n\n- The paper includes no reproducibility statement or supplementary material. Although not strictly required, this limits my ability to verify the reported experimental results."}, "questions": {"value": "- Are you solving a *counterfactual* question (\"what if we changed X in this observed world?\") or a *decision-theoretic* question (\"which variable should we alter next to maximize expected success\")?\n\n- Are all variables observed before Y is realized?\n\n- Clarify the formal problem and specify all assumptions clearly.\n\n- Improve the experimental design. \n\nIf you choose to use ACE, unroll the SCM over time to make it fair. Consider also adding the following:\n1. Add tasks with non-binary variables, nonlinear or multiplicative mechanisms, or denser graphs.\n2. Add a baseline that only observes.\n3. Include sensitivity analysis for $\\alpha$, order errors, and sample size.\n4. Report runtimes and sensitivity tests\n\n- How stable is influence estimation across multiple Monte Carlo seeds or data resamples?\n\n- Do you think that, given the exponential growth of the search tree in MCTS, the method is inherently limited to a small number of alterable variables (which is likely partly why the experiments use small toy models)? Perhaps you have future work in mind on sampling or pruning strategies to improve scalability?\n\n- Notes on improving notation (minor):\n1. The notation $(V_i^a=v_i) / (V_i^o=v_i)$ is non-standard. The paper introduces both this notation and the standard *do*-notation (lines 87-88). Ideally, introduce only one and use it consistently.\n2. Keep observed context (x) explicit in all conditional expressions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Z2cFgRjz5C", "forum": "VHdF91MvJq", "replyto": "VHdF91MvJq", "signatures": ["ICLR.cc/2026/Conference/Submission18687/Reviewer_KrbU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18687/Reviewer_KrbU"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18687/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927216396, "cdate": 1761927216396, "tmdate": 1762928387525, "mdate": 1762928387525, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework for the “avoiding undesired future” (AUF) problem, which aims to identify which variables should be changed to prevent a predicted negative outcome. The authors introduce a metric, called influence power, to measure how useful each variable is to achieving this goal. They claim that influence power differs from traditional causal measures such as the average causal effect,  since variables with strong causal effects may have little or even a negative influence. In contrast, weakly causal or non-causal variables may still have a positive impact. The paper also introduces a Monte Carlo Tree Search (MCTS) method to estimate influence power using observational data."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper tackles a relevant and important conceptual problem: moving from passive prediction to proactive intervention to avoid undesired outcomes. The motivation is to develop a principled approach to determine which variables to alter. I liked the connection between causal reasoning and utility-based decision theory, specifically through the principle of maximum expected utility and a Bellman-style recursive definition."}, "weaknesses": {"value": "* The notion of \"influence power\" should be compared and contrasted with similar intervention-based approaches: for example, actual causes [1] (smallest set of variables that can be altered to change an outcome), counterfactual explanations [2] (set of interventions that optimise a counterfactual outcome), or the paper [3] on agent incentives (which also uses utility to evaluate interventions, and discusses a related notion of value of control).\n\n* The experimental section is limited to three toy models (trader, farmer, and doctor). The baseline comparisons focus on simple strategies (altering the highest probability variables or altering all variables); it'd be good to compare against a selection of the above-recommended approaches.\n\n\n[1] Halpern, Joseph Y. \"A modification of the Halpern-Pearl definition of causality.\" arXiv preprint arXiv:1505.00162 (2015).\n\n[2] Tsirtsis, Stratis, Abir De, and Manuel Rodriguez. \"Counterfactual explanations in sequential decision making under uncertainty.\" Advances in Neural Information Processing Systems 34 (2021): 30127-30139. \n\n[3] Everitt, Tom, Ryan Carey, Eric D. Langlois, Pedro A. Ortega, and Shane Legg. \"Agent incentives: A causal perspective.\" In Proceedings of the AAAI conference on artificial intelligence, vol. 35, no. 13, pp. 11487-11495. 2021."}, "questions": {"value": "* Can the authors clarify how their \"influence power\" notion and overall framework relate to the above-suggested approaches?\n\n* Given the computational intensity and large number of Monte Carlo simulations required to achieve meaningful results, can the authors clarify how their method scales in practice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "w0MoOLVeXW", "forum": "VHdF91MvJq", "replyto": "VHdF91MvJq", "signatures": ["ICLR.cc/2026/Conference/Submission18687/Reviewer_eoMz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18687/Reviewer_eoMz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18687/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762021025990, "cdate": 1762021025990, "tmdate": 1762928386977, "mdate": 1762928386977, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}