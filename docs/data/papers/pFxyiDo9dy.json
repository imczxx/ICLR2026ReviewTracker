{"id": "pFxyiDo9dy", "number": 3359, "cdate": 1757409163181, "mdate": 1763738727675, "content": {"title": "A LoD of Gaussians: Unified Training and Rendering for Ultra-Large Scale Reconstruction with External Memory", "abstract": "Gaussian Splatting has emerged as a high-performance technique for novel view synthesis, enabling real-time rendering and high-quality reconstruction of small scenes. However, scaling to larger environments has so far relied on partitioning the scene into chunks - a strategy that introduces artifacts at chunk boundaries, complicates training across varying scales, and is poorly suited to unstructured scenarios such as city-scale flyovers combined with street-level views. Moreover, rendering remains fundamentally limited by GPU memory, as all visible chunks must reside in VRAM simultaneously.\nWe introduce A LoD of Gaussians, a framework for training and rendering ultra-large-scale Gaussian scenes on a single consumer-grade GPU - without partitioning. Our method stores the full scene out-of-core (e.g., in CPU memory) and trains a Level-of-Detail (LoD) representation directly, dynamically streaming only the relevant Gaussians. A hybrid data structure combining Gaussian hierarchies with Sequential Point Trees enables efficient, view-dependent LoD selection, while a lightweight caching and view scheduling system exploits temporal coherence to minimize the loading overhead. Together, these innovations enable seamless multi-scale reconstruction and interactive visualization of complex scenes - from broad aerial views to fine-grained ground-level details.", "tldr": "Out-of-core memory can be used to expand the scale of 3D Gaussian Splatting training without requiring scene partition.", "keywords": ["Gaussian Splatting", "Neural Rendering", "Level of Detail", "city-scale", "Sequential Point Trees"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b01e6c620df3a08fb7c573e5f1c7aa97cc029093.pdf", "supplementary_material": "/attachment/485cccb9f410a30134dc29673644e1e1dfcf896f.zip"}, "replies": [{"content": {"summary": {"value": "His paper presents A LoD of Gaussians, a method that overcomes GPU memory limitations in city-scale 3D Gaussian Splatting by introducing a hierarchical LoD system combined with external memory management."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The core technique is novel and interesting in its details.\n2. The paper includes careful analysis of memory usage."}, "weaknesses": {"value": "1. I believe the experimental section is insufficient. First, the paper lacks detailed descriptions of the training settings. Second, the comparative experiments are incompleteâ€”methods such as Grendel-GS and OccluGaussian, which are specifically designed for large-scale reconstruction, are not included for comparison. Moreover, the evaluation is performed on a very limited set of datasets, which restricts the generalizability of the conclusions.\n2. The paper lacks references to important related work on Level of Detail (LOD) and large-scale rendering. The authors should consider citing the following works:\n    - *OccluGaussian: Occlusion-Aware Gaussian Splatting for Large Scene Reconstruction and Rendering*\n    - *Virtualized 3D Gaussians: Flexible Cluster-based Level-of-Detail System for Real-Time Rendering of Composed Scenes*\n3. This paper presents a relatively detailed design of a 3DGS-based reconstruction framework for large-scale scenes, covering aspects from methodology to memory management. However, I find the novelty of the proposed method limited. The LoD framework is quite similar to HierarchicalGS, and the strategy of dynamically loading data from CPU to GPU has also been explored in prior work."}, "questions": {"value": "please see the weakness above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KtIvqigsNw", "forum": "pFxyiDo9dy", "replyto": "pFxyiDo9dy", "signatures": ["ICLR.cc/2026/Conference/Submission3359/Reviewer_s64K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3359/Reviewer_s64K"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3359/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760953915543, "cdate": 1760953915543, "tmdate": 1762916688715, "mdate": 1762916688715, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a major limitation of Gaussian Splatting: its difficulty in scaling to large, multi-scale environments (like a city with both aerial and street views). Current methods divide the scene into \"chunks,\" which causes artifacts at boundaries, complicates training, and hits GPU memory limits. The authors propose \"A LoD of Gaussians,\" a framework that enables the training and rendering of massive Gaussian scenes on a single consumer-grade GPU without any partitioning."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Efficient large-scale scene reconstruction and rendering are of great significance. The clarity is also fine."}, "weaknesses": {"value": "1. The experiments are far from sufficient. The authors provide no ablations of method design and provide little illustration of the details for scaling up compared models to the large-scale scenes. So there is no guarantee about the fairness of the comparison, showing a lack of respect for the conference. Besides, the qualitative comparison is also limited to two datasets. I would strongly recommend rejecting the paper. \n2. The innovation is limited. The proposed techniques are mostly a combination of existing methods or engineering efforts, making it insufficient to be accepted as an ICLR paper."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "t1Wt5fchAw", "forum": "pFxyiDo9dy", "replyto": "pFxyiDo9dy", "signatures": ["ICLR.cc/2026/Conference/Submission3359/Reviewer_9WiM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3359/Reviewer_9WiM"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3359/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761384202263, "cdate": 1761384202263, "tmdate": 1762916688338, "mdate": 1762916688338, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes A LoD of Gaussians, a unified framework for out-of-core training and rendering of ultra-large-scale 3D Gaussian Splatting scenes without spatial chunking. The core idea is to store the full scene in CPU memory, build a dynamic Level-of-Detail hierarchy, and use Hierarchical Sequential Point Trees (HSPT) to efficiently generate LoD cuts for view-dependent rendering and training. A GPU-side caching and view scheduling mechanism further reduces data transfer overhead and stabilizes training."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Eliminates chunk partition issues (ghosting, bleeding, merging artifacts).\n\n2. Scales to tens of millions of Gaussians on a single GPU, a highly impactful result.\n\n3. HSPT is a clever and elegant hybrid between hierarchy BFS and parallel SPT cutting.\n\n4. Strong qualitative and quantitative improvements on city-scale datasets."}, "weaknesses": {"value": "1. CPU memory remains the true bottleneck; the method is not actually hardware-light.\n\n2. Initialization assumes good camera poses and geometry, performance may collapse otherwise.\n\n3. The method is less advantageous when scale variation is small (single-height aerial sets).\n\n4. Some ablation discussions are descriptive rather than analytical, more measurements would clarify causality.\n\n5. The training speed per step is slower; the improvement is in iteration count, not iteration efficiency."}, "questions": {"value": "1. Could the hierarchy be partially stored on SSD with async prefetch to reduce RAM pressure?\n\n2. How sensitive is HSPT cut correctness to the surface-area-based md metric? Any cases of cut instability?\n\n3. Does caching introduce systematic bias in reconstructed local texture, e.g., does cache reuse correlate with oversharpening?\n\n4. Could joint pose refinement in early stages reduce reliance on precise COLMAP input?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "w4kQ2UmMzv", "forum": "pFxyiDo9dy", "replyto": "pFxyiDo9dy", "signatures": ["ICLR.cc/2026/Conference/Submission3359/Reviewer_phrf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3359/Reviewer_phrf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3359/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761652395183, "cdate": 1761652395183, "tmdate": 1762916687880, "mdate": 1762916687880, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes a 3DGS pipeline that avoids scene partitioning by storing the full scene out-of-core (CPU RAM) and streaming view-relevant Gaussians to the GPU."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Clear systems contribution for scaling 3DGS without chunking; the combination of LoD + HSPT + out-of-core streaming is well motivated and addresses real bottlenecks.\n2. Practical details on hierarchy maintenance during training and scheduling/caching, with results on large multi-scale scenes."}, "weaknesses": {"value": "1. ML novelty is limited: contributions are primarily data-structure/streaming/systems optimizations around standard 3DGS training; the learning component itself is not substantially new for ICLR.\n2. While large-scale results are discussed, Lack comparisons (Training time, FPS, GPU consumption) against recent large-scene 3DGS(Octree-GS CityGaussin Momentum-GS CityGS-X).\n3. Can you report sensitivity curves for cache size and LoD cut parameters vs. image quality and FPS?"}, "questions": {"value": "This paper makes significant efforts to improve the underlying rendering and training logic of 3D-GS. It would be interesting if the authors could also discuss how their approach might be applied to models like Grendel-GS, which are more sensitive to communication latency."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "EjXvxTHSpx", "forum": "pFxyiDo9dy", "replyto": "pFxyiDo9dy", "signatures": ["ICLR.cc/2026/Conference/Submission3359/Reviewer_5wAV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3359/Reviewer_5wAV"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3359/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986659559, "cdate": 1761986659559, "tmdate": 1762916686313, "mdate": 1762916686313, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Revised Paper Uploaded and Request for Feedback"}, "comment": {"value": "We thank the reviewers for their comments and have aimed to address their concerns with the revision to the manuscript. Here is an overview of the changes in the revision:\n- Rewrote the ablations chapter to be more analytical by providing more measurements (Section A.3)\n- Added FPS/LoD sensitivity curves (Section A.3)\n- Added FPS/Cache Size sensitivity curves (Section A.3)\n- Added Citations for OccluGaussian and Virtualized 3D Gaussians (Section 2)\n- Moved some details for scaling up compared works from appendix to main paper\n- Moved Figure 1 from appendix to main paper\n- Fixed Typos\n\nWe have also posted detailed responses to each of your individual reviews and would greatly value your feedback on these updates to ensure a productive discussion. If there are any remaining issues preventing you from reconsidering your score, please let us know so we can address them before the revision deadline on 26.11."}}, "id": "iXK0MrDyZv", "forum": "pFxyiDo9dy", "replyto": "pFxyiDo9dy", "signatures": ["ICLR.cc/2026/Conference/Submission3359/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3359/Authors"], "number": 9, "invitations": ["ICLR.cc/2026/Conference/Submission3359/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763739659083, "cdate": 1763739659083, "tmdate": 1763739659083, "mdate": 1763739659083, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}