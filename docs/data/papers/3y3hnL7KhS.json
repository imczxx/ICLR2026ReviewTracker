{"id": "3y3hnL7KhS", "number": 943, "cdate": 1756824675388, "mdate": 1763714734604, "content": {"title": "AEGIS: Adversarial Target–Guided Retention-Data-Free Robust Concept Erasure from Diffusion Models", "abstract": "Concept erasure helps stop diffusion models (DMs) from generating harmful content; but current methods face robustness-retention trade-off. **Robustness** means the model fine-tuned by concept erasure methods resists reactivation of erased concepts, even under semantically related prompts. **Retention** means unrelated concepts are preserved so the model’s overall utility stays intact. Both are critical for concept erasure in practice, yet addressing them simultaneously is challenging, as existing works typically improve one factor while sacrificing the other. Prior work typically strengthens one while degrading the other—e.g., mapping a single erased prompt to a fixed safe target leaves class-level remnants exploitable by prompt attacks, whereas retention-oriented schemes underperform against adaptive adversaries. This paper introduces AEGIS (Adversarial Erasure with Gradient-Informed Synergy), a retention-data-free framework that advances both robustness and retention. First, AEGIS replaces handpicked targets with an Adversarial Erasure Target (AET) optimized to approximate the semantic center of the erased concept class. By aligning the model’s prediction on the erased prompt to an AET-derived target in the shared text–image space, AEGIS increases predicted-noise distances not just for the instance but for semantically related variants, substantially hardening the DMs against state-of-the-art adversarial prompt attacks. Second, AEGIS preserves utility without auxiliary data via Gradient Regularization Projection (GRP), a conflict-aware gradient rectification that selectively projects away the destructive component of the retention update only when it opposes the erasure direction. This directional, data-free projection mitigates interference between erasure and retention, avoiding dataset bias and accidental relearning. Extensive experiments show that AEGIS markedly reduces attack success rates across various concepts while maintaining or improving FID/CLIP versus advanced baselines, effectively pushing beyond the prevailing robustness–retention trade-off. The source code is in the supplementary.", "tldr": "", "keywords": ["Adversarial Learning; Prompt Injection Attacks; Adversarial Defending"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/41a79a92e3e52302a7cc4be3c0cbde08f282c28f.pdf", "supplementary_material": "/attachment/53f11fb85eb625c69f3e6c96fd3d5a98200c5375.zip"}, "replies": [{"content": {"summary": {"value": "Concept erasure helps stop diffusion models (DMs) from generating harmful content; but current methods face robustness–retention trade-off. This paper introduces a novel method, Adversarial Erasure with Gradient-Informed Synergy (AEGIS), aimed at enhancing the robustness of concept erasure under adversarial prompt attacks (APAs). Extensive experiments show that AEGIS markedly reduces attack success rates across various concepts while maintaining or improving FID/CLIP versus advanced baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper conducts extensive experiments and demonstrates significant improvements over existing methods.\n2. The paper provides both empirical and theoretical support for the proposed method."}, "weaknesses": {"value": "1. Placing the related work section in the main body of the paper would improve readability. In addition, it is difficult to understand some details when reading only the main text.\n2. Some fine-tuning details are missing, such as the amount of data used and the required memory.\n3. Are all the results in Table 10 obtained using 8 × 80GB H800 GPUs?\n4. Typographical error: “¿” in line 1432.\n\n\nOverall, this paper is of good quality. However, since I am not very familiar with this research field, I set my confidence level to 1."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "b1d8tm0dYK", "forum": "3y3hnL7KhS", "replyto": "3y3hnL7KhS", "signatures": ["ICLR.cc/2026/Conference/Submission943/Reviewer_XpvQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission943/Reviewer_XpvQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission943/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760606077046, "cdate": 1760606077046, "tmdate": 1762915646688, "mdate": 1762915646688, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed retention-data-free framework for the robust concept erasure of diffusion models. To be more specific, the adversarial erasure target (AET) is obtained through optimization instead of handpicking and retention data is avoided by finetuning with gradient regularization projection (GRP) to achieve better trade-off between robustness and retention."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Well-formulated motivation: This paper identifies a key weakness in existing concept erasure methods, which overrely on the single-instance erasure targets.\n2. Retention-data-free: It is necessary to avoid the usage of additional datasets to maintain the model utility which might involve hidden bias.\n3. Extensive experiments are convincing: This paper evaluates multiple baselines through three adversarial prompt attacks.\n4. Good ablation study to isolate the effect of AET, PR and DGR."}, "weaknesses": {"value": "1. The integration of AER and GRP is novel, however, both ideas are drawn from well-known paradigms: adversarial target optimization and gradient surgery. It is good to further clarify the differences compared to existing paradigms.\n2. Insufficient analysis on computational overhead. Computation reduction brought by AET is mentioned in the paper, however, the paper lacks detailed computation \n3. Evaluation scope somewhat narrow. Only three representative concepts (nudity, Van Gogh, Church) are analyzed.\n4. Limited interpretation of semantic centers. Visualization or embedding analysis of AET would be beneficial."}, "questions": {"value": "1. How stable is the AET optimization process? \n2. Scalability to large models (e.g., SDXL): The experiments focus on SD v1.4/v2.1. Have the authors attempted to extend AEGIS to higher-capacity models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AhAnLPHvU5", "forum": "3y3hnL7KhS", "replyto": "3y3hnL7KhS", "signatures": ["ICLR.cc/2026/Conference/Submission943/Reviewer_hz7A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission943/Reviewer_hz7A"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission943/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761692009321, "cdate": 1761692009321, "tmdate": 1762915646546, "mdate": 1762915646546, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper AEGIS proposes a robust defense algorithm against adversarial attack on concept-erased diffusion models. It shows the trade-off between erasure robustness and quality preservation, by Adversarial Erasure Target and Gradient Regularization Projection separately. AET approximates the semantic center of the concept to be erased, enables class-level removal instead of single prompt. GRP preserves the quality using parameter regularization and a novel gradient surgery technique that selectively projects away retention gradients conflicting with the erasure objective. Author's experiments show AEGIS significantly reduces attack success rates by 5.31~24% across various concepts and state-of-the-art attacks like P4D and UnlearnDiffAtk, while maintaining or improving image quality over baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Instead of defending a single prompt, AEGIS dynamically optimizes a target prompt to approximate the semantic center of the concept being erased. With both AEGIS and GRP, it claims to achieve better tradeoff and supported by experiment results.\n2. Experiment is thorough - it validates its method across multiple concept types (object, style, nudity), model versions (SD v1.4, v2.1), and against a suite of strong adversarial attacks (P4D, UnlearnDiffAtk), proving its generalizability and robustness."}, "weaknesses": {"value": "1. it looks like it's sensitive to hyper-parameters such as w in 5.3 ablation study. how to pick the best value for unlearning a new concept?\n2. how to scale if the model needs to unlearn many concepts or objects?"}, "questions": {"value": "1. what about attack in the input image or even embeddings?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "OeYIk4YMam", "forum": "3y3hnL7KhS", "replyto": "3y3hnL7KhS", "signatures": ["ICLR.cc/2026/Conference/Submission943/Reviewer_G3SD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission943/Reviewer_G3SD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission943/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761805040107, "cdate": 1761805040107, "tmdate": 1762915645856, "mdate": 1762915645856, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the problem of robust concept erasure in diffusion models. The paper proposes Adversarial Erasure with Gradient-Informed Synergy (AEGIS), improving erasure robustness and retain performance after unlearning."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The robustness of diffusion model unlearning is a highly important problem. The idea of adversarial erasure target (AET) is novel and well-motivated, and the authors provide detailed and solid explanations for their proposed methods.\n\nThe robustness of AEGIS is validated on multiple attacks. The authors also compare AEGIS with multiple baselines.\n\nThe figures and illustrations are of good quality."}, "weaknesses": {"value": "1. The paper lacks comprehensive evaluations on the retain performance. Currently, FID and the CLIP score are used. However, common DM unlearning benchmarks such as UnlearnCanvas [1] include evaluation metrics such as in-domain retain accuracy (IRA) and cross-domain retain accuracy (CRA). Since the authors claim AEGIS has great robustness–retention trade-off, a more comprehensive retention evaluation is needed.\n\n2. The motivation of Parameter Regularization (PR) and Directional Gradient Rectification (DGR) seems unclear. It seems that AET alone can achieve concept erasure while retaining model utility, and PR and DGR can be added upon any unlearning methods, and they are not specifically related to AET. Possibly, AET seriously degrades the model's utility, so PR and DGR are employed to balance retention performance. However, this motivation still seems weak: why not try other methods that do not incur additional computation costs, such as tuning the retain loss coefficient, or adjusting the learning rate?\n\n3. For the baselines, the paper did not include more recent methods on robust concept erasure, such as STEREO [2]. This CVPR 2025 paper addresses the same problem as yours, and I think it should be mentioned and compared.\n\n4. The paper lacks run-time and GPU memory comparison between different methods. I am concerned about the increased computation cost brought by AEGIS, particularly the DGR part. Could the authors discuss this possible trade-off?\n\n[1] UNLEARNCANVAS: A Stylized Image Dataset for Enhanced Machine Unlearning Evaluation in Diffusion Models\n\n[2] STEREO: A Two-Stage Framework for Adversarially Robust Concept Erasing from Text-to-Image Diffusion Models"}, "questions": {"value": "1. Can the authors explain why they employ the CLIP score to evaluate retention? As shown in Table 2-3, the CLIP score has very little changes before and after unlearning. Besides, all the unlearning methods have similar CLIP scores (ranging from 0.29 to 0.31). This gives me the impression that the CLIP score is slightly affected by the unlearning process. In this case, how can it serve to faithfully evaluate the retention performance of different methods?\n\n2. Why and how does Directional Gradient Rectification (DGR) contribute to robustness? In Table 6, 'AEGIS w/o DGR' has significantly higher ASR compared to AEGIS. This result is somehow confusing to me: in theory, DGR serves to improve retention performance by resolving the confliction between forget gradient and retain gradient. However, the authors did not explain how it contributes to the robustness gain.\n\n3. For DGR, have the authors tried using the moving average of gradients in the gradient projection process? This might yield better performances, according to [1].\n\n[1] GRU: Mitigating the Trade-off between Unlearning and Retention for LLMs"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "s6YfxD7Vpr", "forum": "3y3hnL7KhS", "replyto": "3y3hnL7KhS", "signatures": ["ICLR.cc/2026/Conference/Submission943/Reviewer_Tzbr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission943/Reviewer_Tzbr"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission943/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761828569768, "cdate": 1761828569768, "tmdate": 1762915645683, "mdate": 1762915645683, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a framework called Adversarial Erasure with Gradient-Informed Synergy (AEGIS) to improve the robustness of concept erasure in diffusion models against adversarial prompt attacks (APAs).\n\nThe paper demonstrates that the vulnerability of concept erasure is closely tied to the choice of the target concept (i.e., the concept that the to-be-erased concept is mapped to). If the target is semantically close to the to-be-erased concept, the erasure performance degrades.\nTo address this, the paper proposes the AEGIS framework with two main components:\n\n•\tAdversarial Erasure Target (AET): Guides the erasure by selecting a target concept that is semantically close to the original, while also maximizing the output difference between the old and new models on the same concept.\n\n•\tGradient Projection: Mitigates gradient conflict between the erasing and preserving tasks"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "-\tThe problem of machine unlearning is an emerging and important area in the machine learning community.\n-\tThe paper focuses on an important sub-problem — robustness in unlearning, which is gaining increasing attention.\n-\tThe experimental setup appears comprehensive, and the results are promising"}, "weaknesses": {"value": "There are several concerns about the paper’s novelty. More specifically:\n\n•\tThe first contribution—\"the vulnerability of concept erasure stems from an inappropriately chosen learning target. In particular, if the target lies too close to the semantic center – formed by words semantically related to the erased concept – the concept information cannot be fully removed\"—has already been studied in prior work [AGE, 1]. Specifically, AGE (Section 4) showed that the choice of the target concept significantly affects both erasing and retaining performance. AGE further suggests that a good target should be semantically related to, but not similar to, the to-be-erased concept—an insight that is more general and comprehensive than what is presented in this paper.\n\n•\tThe proposed min-max optimization in Equation 7 is very similar to that in AGE, with the only difference being the retention loss (regularization). In AGE, the preservation loss measures the output difference between the new and old models on the same input concept. While this paper propose to minimize the change of model parameter\n\n•\tThe idea of using gradient projections to mitigate conflict between erasing and preserving tasks has already been proposed in several works [2, 3, 4]. Yet, the paper lacks any discussion or comparison with these related methods.\n\n1: Fantastic Targets for Concept Erasure in Diffusion Models and Where To Find Them\n\n2: Erasediff: Erasing data influence in diffusion models\n\n3: Scissorhands: Scrub Data Influence via Connection Sensitivity in Networks\n\n4: GDR-GMA: Machine Unlearning via Direction-Rectified and Magnitude-Adjusted Gradients"}, "questions": {"value": "•  Could the authors provide a discussion on how their proposed method differs from previous works such as [1, 2]?\n\n•  Given that the core claim of the paper is improved robustness against adversarial or recovery attacks, could the authors include experiments using the recent Random Probe recovery attack proposed in [4], which perturbs the text encoder to confuse generation and recover unlearned concepts\n\n[5] Lu, Kevin, et al. \"When Are Concepts Erased From Diffusion Models?.\" NeurIPS 2025"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HnMmzTJ5ws", "forum": "3y3hnL7KhS", "replyto": "3y3hnL7KhS", "signatures": ["ICLR.cc/2026/Conference/Submission943/Reviewer_2cHk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission943/Reviewer_2cHk"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission943/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762141877666, "cdate": 1762141877666, "tmdate": 1762915645497, "mdate": 1762915645497, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Rebuttal Summary"}, "comment": {"value": "Dear Reviewers and AC,\n\nWe sincerely appreciate the time and effort the reviewers have dedicated to evaluating our manuscript. Below, we summarize the key responses to the reviewers' suggestions and questions.\n\n---\n### **To Reviewer Reviewer 2cHk**\n\n1. **Clarifying Contributions and Novelty:**\n   We address concerns regarding the comparison between AEGIS and AGE [1] with a detailed explanation in **Table A.1** and comparison in **Table A.2**. \n   > See **R1** for AEGIS's contribution to AGE, and **R2** for differences in Min-Max mechanisms for Reviewer 2cHk.\n\n2. **On Relation to Gradient Surgery:** \n   To clarify the significant differences between our Gradient Regularization Projection (GRP) and ED [2], SH [3], and GDR-GMA [4], we detail these methods in **Table A.3**.\n   > See **R3** and **RQ1** for Reviewer 2cHk.\n\n3. **Experiments of Random Probe Attacks:** \n   To demonstrate AEGIS's effectiveness, we present comprehensive results against Random Probe Attacks in **Table A.4**.\n   > See **RQ2** for Reviewer 2cHk.\n\n---\n\n### **To Reviewer Tzbr**\n\n1. **Retention Metrics and Evaluation**\n   In response to suggestions and concerns of Reviewer Tzbr, we have conducted experiments to evaluate IRA and CRA within UnlearnCanvas in **Table B.1**, and provided explanations of current retention metrics .\n   > See **R1** regarding IRA and CRA, and **RQ1** concerning CLIP Score to Reviewer Tzbr.\n\n2. **Motivation of Gradient Regularization Projection (GRP)** \n   As per Reviewer Tzbr recommendations, we explain the motivation behind GRP and perform experiments to clarify the functions of Parameter Regularization (PR), Directional Gradient Rectification (DGR), and dynamic weight in **Table B.2.1** and **Table B.2.2**.\n   > See **R2** to Reviewer Tzbr.\n\n3. **Extra Baseline STEREO** \n   Following the suggestion of Reviewer Tzbr, we add experiments to compare AEGIS with STEREO  in **Table B.3**.\n   > See **R3** to Reviewer Tzbr.\n    \n4. **More Explations and Clarification of DGR**\n  To address the confusion of Reviewer Tzbr regarding the DGR, we show time and memory consumpation in **Table B.4**, and explain the role of DGR in model robustness with AEGIS. Moreover, we add experiments incorporating moving average in DGR in **Table B.5**.\n   > See **R4** refering time and memory, **RQ2** regarding role of DGR within AEGIS, and **RQ3** involving DGR moving average to Reviewer Tzbr.\n  \n\n---\n\n### **To Reviewer G3SD**\n\n1. **Setting of Parameter $\\omega$**\n In response to the confusion of Reviewer G3SD, we further explain the dynamic updating mechanism of $\\omega$.\n   > See **R1** to Reviewer G3SD\n\n2. **Scalability to Many Concept Erasure**\n To answer the question of Reviewer G3SD, we present methodologies for erasing multiple concepts.\n   > See **R2** to Reviewer G3SD\n \n3. **Attacks in Other Space**\n To address the confusion of Reviewer G3SD, we explain that our work aims to protect the model from adversarial prompt attacks in text-to-image tasks.\n   > See **R3** to Reviewer G3SD\n\n---\n### **To Reviewer hz7A**\n\n1. **Clarification of AET and GRP**\n   In response to hz7A's suggestions, we further clarify our AET and GRP, and present their comparison with existing methods.\n   > See **R1** to Reviewer hz7A.\n\n2. **More Details of AET** \n   As per Reviewer hz7A recommendations, we have added timing information in **Table D.1**, clarify details of AET. Moreover, we analyze the AET optimization process and provide evidence for its stability.\n   > See **R2** refering timing, **R4** regarding more details, and **RQ1** involving to AET optimization of Reviewer hz7A.\n\n3. **More Evaluation** \n   Following the suggestion of Reviewer hz7A, we have conducted experiments on erasing additional concepts in **Table D.2**.\n   > See **R3** to Reviewer hz7A.\n  \n4. **Experiments with More SD Version**\n  Following the suggestion of Reviewer hz7A, we have added experiments on SDXL in **Table D.3**.\n    > See **RQ2** to Reviewer hz7A. \n    \n---\n### **To Reviewer XpvQ**\n\n1. **Related Work** \n   To clarify any confusion regarding Related Work, we explain the reason and provide more details in the main text. \n   > See **R1** to Reviewer XpvQ.\n\n2. **Detailed Computation** \n   Following the suggestion of Reviewer XpvQ, we present detailed experimental settings, and information of time and memory usage in **Table E.1**. \n   > See **R2** regarding computation information and **R3** involving GPU usage to Reviewer XpvQ.\n\n3. **Typographical Error** \n   In line with the suggestion, we revise the paper and check it again to avoid typographical errors. \n   > See **R4** to Reviewer XpvQ."}}, "id": "zbB1eO4bp4", "forum": "3y3hnL7KhS", "replyto": "3y3hnL7KhS", "signatures": ["ICLR.cc/2026/Conference/Submission943/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission943/Authors"], "number": 15, "invitations": ["ICLR.cc/2026/Conference/Submission943/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763693774013, "cdate": 1763693774013, "tmdate": 1763693774013, "mdate": 1763693774013, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}