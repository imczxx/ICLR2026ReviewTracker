{"id": "cEXEmyW77N", "number": 8729, "cdate": 1758096295801, "mdate": 1759897767401, "content": {"title": "Structurally Human, Semantically Biased: Detecting LLM-Generated References with Embeddings and GNNs", "abstract": "Large language models are increasingly used to curate bibliographies, raising the question: are their reference lists distinguishable from human ones? We build paired citation graphs, ground-truth and GPT-4o-generated (from parametric knowledge), for 10,000 focal papers ($\\approx$ 275k references) from SciSciNet, and added a field-matched random baseline that preserves out-degree and field distributions while breaking latent structure. We compare (i) structure-only node features (degree/closeness/eigenvector centrality, clustering, edge count) with (ii) 3072-D title/abstract embeddings, using an RF on graph-level aggregates and Graph Neural Networks with node features. Structure alone barely separates GPT from ground truth (RF accuracy $\\approx$0.60) despite cleanly rejecting the random baseline ($\\approx$ 0.89--0.92). By contrast, embeddings sharply increase separability: RF on aggregated embeddings reaches $\\approx$ 0.83, and GNNs with embedding node features achieve 93\\% test accuracy on GPT vs.\\ ground truth. Thus, LLM bibliographies, generated purely from parametric knowledge, closely mimic human citation topology, but leave detectable semantic fingerprints; detection and debiasing should target content signals rather than global graph structure.", "tldr": "", "keywords": ["Large Language Models (LLMs)", "Citation Networks", "Graph Neural Networks (GNNs)"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/988e045431b122f676981652e7732a30bf9be6d0.pdf", "supplementary_material": "/attachment/a107021082bd0984be28cb9096edfaaf0a110f36.zip"}, "replies": [{"content": {"summary": {"value": "The paper investigates whether citation graphs can distinguish between reference generated by LLM and those by humans. The author uses SciSciNet constructs 3 sets of paired graphs for each paper: the original graph, a graph generated by GPT-4o and a random graph. The research finds that only using structural features is difficult to distinguish GPT from humans, but the semantic information can increase the accuracy of distinguishing. Both human and GPT graphs are easily distinguished from random.."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The story is interesting and timely, the work empirically investigates whether LLM-generated bibliographies hold detectable signals distinct from human ones.\n2. The paper has clear experimental design. For each paper, the authors build three paired graphs (human / GPT / random) and control reference count, field, and year. This makes it easy to see what structure explains and how much semantics adds."}, "weaknesses": {"value": "Although the limitations are discussed fairly comprehensively, several issues should be addressed to make the work more well-rounded:\n1. Since the paper is about LLM capability, evaluating only GPT-4o is insufficient. Cross-model experiments are needed (e.g., generate with other LLMs; keep the embedding backbone fixed). Conversely, keep the generator fixed and vary the embedding backbone.\n2. No detailed analysis about the LLM bias. A literature field analysis would reveal performance differences across different disciplines, and a temporal analysis could test for newer vs. older references.\n3. Only a small subset of basic structural features is used in this paper. Will it omit distinguishable structural signals, and what motivate the selection of these features?\n4. Missing metadata normalization policy. The paper does not specify how reference fields are standardized/canonicalized before matching and analysis"}, "questions": {"value": "See my weaknesses above. In addition, lines 132–137: why replace each directed edge with an undirected one? This removes information about “who came first” and “who cited whom,” which I think is the essential structural signal."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1izwNa7B24", "forum": "cEXEmyW77N", "replyto": "cEXEmyW77N", "signatures": ["ICLR.cc/2026/Conference/Submission8729/Reviewer_XBHR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8729/Reviewer_XBHR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8729/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962612118, "cdate": 1761962612118, "tmdate": 1762920524993, "mdate": 1762920524993, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "### Summary\n\nThis study presents an approach to assess whether reference lists generated by large language models (LLMs) can be distinguished from those created by humans. The authors construct paired citation graphs using 10,000 papers from SciSciNet.  \n\nTo generate synthetic reference lists, they use GPT-4o, providing paper metadata such as title, abstract, authors, year, and venue. Three citation graphs are created:\n\n- (A) Human ground-truth references (extracted from each paper)  \n- (B) GPT-generated references  \n- (C) Field-matched random baseline (references randomly sampled from papers in the same field and year)\n\n---\n\n### Methodology\n\nUsing these three citation graphs, the authors introduce three classification models to determine whether a reference list was generated by GPT-4o or by humans. These are applied as pairwise binary classification tasks (A vs B, A vs C, B vs C):\n\n1. **Graph Topology:**  \n   A Random Forest (RF) classifier trained on hand-crafted graph-level statistics to distinguish citation networks by their structural topology.\n\n2. **Semantic Embeddings:**  \n   An RF classifier using aggregated text-embedding vectors of paper titles to classify graphs based on the semantic coherence of their reference papers.\n\n3. **Graph Neural Networks (GNNs):**  \n   Four GNN classifiers that jointly learn from citation structure and node embeddings through message passing, capturing both topological and semantic features.\n\n---\n\n### Key Findings\n\n1. The models achieved an accuracy of 0.6 when distinguishing between (A) and (B), showing that GPT mimics the structural patterns of human references.  \n2. Adding semantic features improved discrimination between (A) and (B), suggesting that main differences lie in semantics.  \n3. Structure-only GNNs could not effectively distinguish GPT-generated from human references, while embedding-based GNNs performed well when distinguishing (B) from (C)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "### Strengths\n\n- **Originality:**  \n  This paper addresses the novel problem of distinguishing LLM-generated reference lists from human ones by constructing citation graphs and developing three classification approaches. While citation graphs and Random Forests are established methods, their application to this specific problem represents a new use case.\n\n- **Quality:**  \n  The study demonstrates a solid experimental setup by evaluating three distinct classification approaches across multiple models. The authors leverage a large-scale dataset of 10,000 papers and 275,000 references, enabling comprehensive and meaningful analysis.\n\n- **Clarity:**  \n  The paper is well-written and logically structured. Each approach is supported with clear explanations and informative figures.\n\n- **Significance:**  \n  The paper tackles a timely research question with little prior work. While earlier studies have examined the detection of LLM-generated content in general, the detection of LLM-generated references remains largely unexplored. This study thus provides a valuable foundation for future research."}, "weaknesses": {"value": "### Weaknesses\n\n- **Related Work:**  \n  The paper lacks a dedicated related work section and does not fully contextualize its contribution. The authors briefly mention prior studies by Algaba et al. (2024), Mobini et al. (2025), and Algaba et al. (2025), but do not clarify the distinct contributions of each. A more thorough discussion is needed, especially regarding connections to related areas such as LLM-generated content detection, citation network analysis, citation generation, citation recommendation, and citation-related biases.\n\n- **Discussion:**  \n  Although the results of the three classification approaches are presented clearly within individual sections, the paper lacks a consolidated discussion that synthesizes the findings and compares the approaches. A dedicated discussion section would enhance interpretability and depth.\n\n**Overall:**  \nThe paper could be significantly improved by adding comprehensive related work and discussion sections."}, "questions": {"value": "**Major suggestions**\n1. Include a comprehensive related work section.  \n2. Add a discussion section summarizing and comparing the key findings.\n\n**Minor suggestions**\n1. **Figure 2:** Simplify the figure to reduce textual complexity and improve readability; this could also free up space for expanded related work and discussion sections.  \n2. **Table 3:** Adjust the table to fit within the page margins specified by the template.  \n3. **References:** Add DOIs or URLs to allow readers to verify sources more easily.  \n4. **Grammar:** Correct the minor typo in line 465 (“have have”)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5cr7yGRZgH", "forum": "cEXEmyW77N", "replyto": "cEXEmyW77N", "signatures": ["ICLR.cc/2026/Conference/Submission8729/Reviewer_cRu8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8729/Reviewer_cRu8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8729/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762052714915, "cdate": 1762052714915, "tmdate": 1762920524298, "mdate": 1762920524298, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates whether large language models like GPT-4o produce bibliographies that can be distinguished from real, human-authored bibliographies when viewed through the lens of citation graph analysis.  The authors construct a large paired dataset of 9,218 citation graphs from SciSciNet, each with a ground-truth set of references, an equal-sized GPT-generated list, and a random baseline. The experiments show that using structural information alone cannot separate GPT-generated citations from the ground truth using either Random Forests or GNNs. However, when using semantic embeddings (from the title and sometimes the abstract), both RF and GNNs can distinguish the GPT-generated citations from the ground truth."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The findings of the paper are timely, as LLM-generated scientific bibliographies are emerging. Knowing the bias in the generated citations would be helpful to all researchers (and reviewers).\n2. The paper provides firm empirical grounding. Not only does the paper present the accuracy results, but it also includes descriptive statistics and visualization to confirm/motivate the results (Figures 2 and 3).\n3. The paper presents a carefully controlled dataset of ~9k citation graphs across three conditions. The results from two distinct machine learning methods (tree-based models and many GNN architectures) align closely."}, "weaknesses": {"value": "1. The paper focuses on \"parametric knowledge\" and GPT-4o. This setting might not reflect all LLMs' behaviors nor citation recommendation systems that increasingly perform \"deep research\". \n2. While the paper argues that semantic embeddings reveal the key differences between human and GPT-generated citation graphs, this claim is potentially confounded by the extreme disparity in feature dimensionality (3072 vs 5). The observed accuracy gain in the Random Forest might partly reflect model capacity rather than genuine informational superiority. A dimensionality-controlled ablation or matched-feature comparison would strengthen this conclusion.\n3. There was some ambiguity in the text.\n    - The baseline citations are constructed based on the field of the papers. However, it is unclear whether the constructions follow the citations' chronological order.\n    - The paper states that the citation graphs of the three datasets have the same degree. However, summing over vectors is still an unusual option.\n    - Figure 3 shows that the projected embedding of the GPT and ground truth citations overlap, but the classification model can distinguish between them. This means that 2D PCA lost most of the variance.  Thus, it might be helpful to see the plot."}, "questions": {"value": "1. Was temporal order preserved in the random baseline graphs?\n2. What percentage of variance is captured by the PCA projection in Figure 3? Perhaps t-SNE would be a better choice?\n3. Is the embedding (semantic of structure) learnable under the GNN models?\n4. If we append a random vector of size 3,067 to the structural node embedding, would it improve the performance of the GNNs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "WJxEpxLK6O", "forum": "cEXEmyW77N", "replyto": "cEXEmyW77N", "signatures": ["ICLR.cc/2026/Conference/Submission8729/Reviewer_13Z6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8729/Reviewer_13Z6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8729/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762080451000, "cdate": 1762080451000, "tmdate": 1762920523682, "mdate": 1762920523682, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates whether LLMs when tasked with generating bibliographic references for scientific papers using only parametric knowledge, reproduce human-like citation patterns. Using 10,000 focal papers and around 275,000 references from SciSciNet, the authors construct paired citation graphs: ground-truth reference networks, GPT-generated reference networks, and a field-matched random baseline. Then they evaluate structural graph properties (centrality, clustering, density, etc. ), semantic embedding signals (OpenAI text-embedding-3-large), and multiple Graph Neural Networks (GCN, GAT, GIN, GraphSAGE). Their key results demonstrate that structural topology alone cannot reliably distinguish GPT-generated from human citation graphs, semantic embeddings do reliably distinguish them.\nOverall it is a well written paper."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The following are 3 key strong points of this paper:\n1. Authors carried out rigorous experimental design by using paired graphs per focal paper and apply field-matched randomization to break subtle citation structure, making conclusions robust. This is one of the strongest points of this paper. \n\n2. Authors have done a good job of clearly decomposing Structural vs. Semantic signals. This leads to better interpretability and diagnostic insights.\n\n3. Their experiments provide strong empirical evidence at scale by considering 10,000 focal papers and 9,218 valid paired graphs; this is large for bibliometric graph learning and this adds confidence."}, "weaknesses": {"value": "1. The analysis carried out in this paper is limited to only GPT-4o. Concept drift/divergence between models is noted but not tested. This is a serious limitation of this paper. \n\n2. While semantic embeddings separate classes, the authors do not identify what semantic dimensions differ (recency, methodology, prestige, jargon)?\n\n3. For GNNs, only titles and simple metrics are used. Full-text content or citation contexts might yield deeper insights.. Is there any reason for this?"}, "questions": {"value": "Below are a few comments to the authors:\n\n(a) Please answer the above 3 weak points.\n\n(b) The conclusion states differences lie in semantics, but the dimensions are not unpacked. Attention weights, probing tasks, or PCA factors would help interpretability. What are your thoughts on this? How do you go about addressing this issue?\n\n(c) Generate references with multiple models (Claude, LLaMA, DeepSeek), then train detectors on one and test on others. How the results would look in this case?\n\n(d) Considering temporal bias metrics would be nice. In other words, LLMs are known to over-cite recent literature. Is this really happening in your experiments? If yes, please quantify this directly.\n\n(d) Authors mention isolated nodes but does not explore their semantic role.. It would be nice to understand what such isolated nodes mean?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "43hYL1X9Gu", "forum": "cEXEmyW77N", "replyto": "cEXEmyW77N", "signatures": ["ICLR.cc/2026/Conference/Submission8729/Reviewer_owXj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8729/Reviewer_owXj"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8729/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762621408777, "cdate": 1762621408777, "tmdate": 1762920523370, "mdate": 1762920523370, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}