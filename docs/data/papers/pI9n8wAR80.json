{"id": "pI9n8wAR80", "number": 1417, "cdate": 1756880988111, "mdate": 1763694953403, "content": {"title": "CoLA: Co-Calibrated Logit Adjustment for Long-Tailed Semi-Supervised Learning", "abstract": "Long-tailed semi-supervised learning is hampered by a vicious cycle of confirmation bias, where skewed pseudo-labeling progressively marginalizes tail classes. This challenge is compounded in real-world scenarios by a class distribution mismatch between labeled and unlabeled data, rendering the bias unpredictable and difficult to mitigate. While existing methods adapt Logit Adjustment (LA) using dynamic estimates of the unlabeled distribution, we argue their effectiveness is undermined by two critical limitations stemming from LA's core design, i.e., its class-wise and overall adjustment mechanisms. First, their reliance on simple frequency counting overestimates the prevalence of head classes due to sample redundancy, leading to harmful over-suppression. Second, and more critically, they overlook the interplay between the above two types of adjustment, treating the overall adjustment strength as a fixed hyperparameter. This is a significant oversight, as we empirically find that the optimal strength is highly sensitive to the estimated distribution. To address these limitations, we propose Co-Calibrated Logit Adjustment (CoLA), a framework that co-designs the class-wise and overall LA components. Specifically, CoLA refines the class-wise adjustment by estimating each class's effective sample size via the effective rank of its representations. Subsequently, it formulates the overall adjustment strength as a learnable parameter, which is optimized through a meta-learning procedure on a proxy validation set constructed to mirror the refined distribution. Supported by a theoretical generalization bound, our extensive experiments show that CoLA establishes a new state-of-the-art on $4$ public benchmarks across $6$ challenging distributions.", "tldr": "Improve the original logit adjustment for realistic long-tailed semi-supervised learning.", "keywords": ["Semi-supervised learning", "long-tailed learning", "logit adjustment"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a640056815739c33db4c065b472412f4e7c6d03a.pdf", "supplementary_material": "/attachment/b8ce7fc1bc775d03141ef99295dea4a2b28733fc.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses the issue of pseudo‑label bias in long‑tailed semi‑supervised learning, and identifies two core limitations in existing Logit Adjustment (LA)–based approaches: distribution estimation distortion caused by sample redundancy, and the use of a fixed overall adjustment strength. To overcome these limitations, the authors propose the CoLA framework, whose main components include: estimating the effective number of samples via the effective rank of the representation matrix to obtain a de‑duplicated class distribution; and, based on the estimated distribution, constructing a proxy validation set and optimizing the overall adjustment strength through meta‑learning so that it adapts to the characteristics of the current distribution. Furthermore, the paper provides a theoretical generalization error bound for the proposed LMC and validates the method through experiments on benchmark datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The problems identified in the paper are reasonable and important, and the authors provide a detailed analysis supported by both theoretical justification and experimental evidence.\n2. The paper presents a generalization bound and a convexity analysis for the meta‑learning process, which enhances the theoretical soundness of the proposed method.\n3. The visualization in the ablation study is presented in a clear and comprehensive manner."}, "weaknesses": {"value": "1. The computation of effective rank and the meta‑learning procedure may introduce substantial computational overhead. It would be beneficial to include an analysis of the time complexity and computational complexity, particularly with respect to runtime performance on large‑scale datasets.\n2. In the downstream experimental evaluation, I notice that the SIN‑127 dataset is a down‑sampled version of ImageNet‑127. Why not perform testing directly on ImageNet‑127? I am curious about the potential results on the full ImageNet‑127 dataset.\n3. The paper lacks a primary diagram illustrating the proposed method. Introducing a main figure would make the methodology clearer and facilitate reader understanding."}, "questions": {"value": "See the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "iHfiTtpflB", "forum": "pI9n8wAR80", "replyto": "pI9n8wAR80", "signatures": ["ICLR.cc/2026/Conference/Submission1417/Reviewer_DkFy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1417/Reviewer_DkFy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1417/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761645010040, "cdate": 1761645010040, "tmdate": 1762915764314, "mdate": 1762915764314, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper attempts to tackle an problem in Long-Tailed Semi-Supervised Learning (LTSSL): the confirmation bias driven by biased pseudo-labels. The authors claim that existing methods based on LA suffer from two critical limitations: 1) they rely on naive frequency counting to estimate the unlabeled data distribution, and 2) they treat the overall adjustment strength as a fixed hyperparameter. The authors propose CoLA, which consists of two main components: first, a De-Duplicated Distribution Estimation (DDDE) module that attempts to estimate a more accurate class distribution by calculating the effective rank of class representations to account for sample redundancy. Second, a Logit Meta-Calibration (LMC) procedure that constructs a proxy validation set and uses meta-learning to automatically optimize the overall adjustment strength. The experiment results show that their method establishes a new state-of-the-art on four public benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors do identify a potentially interesting aspect of the LA mechanism, namely the interplay between the class-wise adjustment and the overall adjustment strength. This is a reasonable observation.\n2. The authors evaluate their method across multiple datasets and distribution mismatch scenarios."}, "weaknesses": {"value": "1. The first of my concern is novelty. The core idea of this paper is little more than a combination of existing techniques, such as effective number, dual-branch, and meta-learning for hyperparams.\n2. The description of the DDDE module is overly simplistic. The authors propose computing the effective rank for the representation matrix Zy of each class y. They fail to discuss the computational cost of this procedure.\n3. In Figure2 (b,d,e), after applying LMC, the slope of the pseudo-label accuracy improvement barely changes. So I think its contribution is questionable.\n4. The proxy validation set Dv is resampled from the small and imbalanced labeled set Dl. For tail classes, Dl may contain only a few samples. How do you justify that such a severely constrained proxy set can effectively guide the learning of $\\tau$ for a massive and differently distributed unlabeled set Du?"}, "questions": {"value": "See in Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JhYxZ526sg", "forum": "pI9n8wAR80", "replyto": "pI9n8wAR80", "signatures": ["ICLR.cc/2026/Conference/Submission1417/Reviewer_peuh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1417/Reviewer_peuh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1417/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761727608798, "cdate": 1761727608798, "tmdate": 1762915764148, "mdate": 1762915764148, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors address in their manuscript the problem of long-tailed semi-supervised learning. They analyze the weaknesses of several methods based on logit adjustment and propose an approach CoLA that is claimed to suffer less from over-suppression. They further propose DDDE to estimate the unlabeled distribution and LMC as a meta-learning strategy. They validate their method on 4 different datasets (CIFAR-10/100-LT, STL-10-LT, and SIN-127)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-written (with exception line 090 \"each class's representations\") and structured (DDDE=4.1, LMC=4.2, CoLA=4.3).\n2. The main hypothesis is clearly stated and the approach is presented in a plausible way.\n3. Technical parts are accurately and detailed described.\n4. A good set of datasets has been selected for the experiments.\n5. The results are good (even if not always beating the state of the art)"}, "weaknesses": {"value": "1. The related work is covering a subset of the field, important references (such as [1]) are only used in the appendix, other are completely missing e.g. [2-5].\n2. The premise for the main hypothesis, i.e., the negative effect of overlooking the interplay between the two types of adjustment, has not been clearly supported by experimental results. If the premise is not properly established, all subsequent claims are affected. Figure 1b) only shows that monotonicity is not fulfilled.\n3. Some statements lack evidence or reference, e.g. line 085. \"current work\" embraces all works, see also 1. (this is not saying that any of [2-5] does).\n4. The protocol (for CIFAR) chosen according to Du et al. ICML 2024 (Simpro) deviates from other, previously published protocols, e.g. from the cited paper [6], and makes comparisons difficult, in particular to state-of-the-art methods that remained un-cited and that use those previous protocols.\n5. For experiments that use compatible protocols, e.g. STL-10-LT, the proposed method is inferior to e.g. [4} and rather en par with [3]. \n6. The description of erank is not sufficiently self-contained. In particular, it is not clear why the EN is estimated by erank. Line 197 just says \"we quantify EN ... using ... erank\" and references point to EN and erank, but not why the quantification is possible.  Also, it is not obvious why line 205 $p(i)$ is a probability and not just a point in the $m_y$-simplex.\n7. 4.2 is partly written in a procedural way and the overall approach that leads to the algorithm needs to be stated more clearly.\n\n[1] Zhang et al. Mixup: Beyond empirical risk minimization. ICLR 2018.\n\n[2] Lazarow et al. Unifying distribution alignment as a loss for imbalanced semi-supervised learning. CVPR 2023.\n\n[3] Chen et al. Softmatch: Addressing the quantity-quality tradeoff in semi-supervised learning. ICLR 2023.\n\n[4] Aimar et al. Flexible distribution alignment: Towards long-tailed semi-supervised learning with proper calibration. ECCV 2024.\n\n[5] Kim et al. Separated and Independent Contrastive Semi-Supervised Learning for Imbalanced Datasets. IEEE Access 2025.\n\n[6] Kim et al. Distribution aligning refinery of pseudo-label for imbalanced semi-supervised learning. NeurIPS 2020."}, "questions": {"value": "1. (related to weakness 2.): which are the experimental results that clearly show that the _interplay_ of the two types of LA cause the issue? \n2. (related to weakness 4.): what results are obtained with the protocol from Kim et al. 2020 or is there some other way to make the results comparable?\n3. (related to weakness 5./1.): as the statement about state-of-the-art results need to be revised: in which situation does the proposed method shows its main strengths and weaknesses?\n4. (related to weakness 6.): why is the quantification possible and why is $p(i)$ a proper probability?\n5. (related to weakness 7.): what is the overall approach in 4.2?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tqtZMkrPFO", "forum": "pI9n8wAR80", "replyto": "pI9n8wAR80", "signatures": ["ICLR.cc/2026/Conference/Submission1417/Reviewer_bnRy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1417/Reviewer_bnRy"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1417/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761856497681, "cdate": 1761856497681, "tmdate": 1762915764018, "mdate": 1762915764018, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on improving Long-Tailed Semi-Supervised Learning (LTSSL) by employing logit-adjustment methods. The paper identifies two key issues with the logit-adjustment approaches: 1) An over-estimation of popular class probabilities can lead to over-suppression of model predictions for the popular classes; and 2) The overall adjustment factor in the logit-adjustment approach is sensitive to particular dataset and needs to selected carefully. The paper then proposes two solutions to address these two issues, namely *de-duplicated distribution estimation* (DDDE) and *logit meta-calibration* (LMC). The paper provides a generalization analysis for LMC. The paper then provides a comprehensive empirical evidence of the value of the proposed approach while comparing it with existing logit-adjustment-based approaches and other methods beyond logit-adjustment for LTSSL in the literature."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper studies a well motivated problem by identifying key limitations of a widely popular approach in the literature.\n- The empirical results in the paper clearly showcase the improvements compared to competitive baselines from the literature. \n- The paper presents ablation results to establish the value of both DDDE and LMC."}, "weaknesses": {"value": "- The generalization analysis in Section 5 does not significantly enhance the overall contributions of the paper. Does the theory inspire/motivate the method proposed in the paper? If not, does the theory provide useful guarantees towards the final performance of the proposed solution? \n- The presentation of the theoretical part of the paper can be greatly improved.\n   -  Could the authors expand on the Line 298 (``If our estimation is accurate,...justifying our methodology``) and make it mathematically precise. \n   - If the reviewer understand it correctly, the only optimizing parameter in Section 5 is $\\tau$ and the function class $h_{\\tau}$ is linear with respect to $\\tau$ (since $\\tau$ is the overall logit-adjustment factor). Could the author attempt to provide a more explicit characterization of the Rademarcher complexity in this case?"}, "questions": {"value": "- Could you please provide a description/pseudocode of your overall method in the form of an algorithmic block or a figure?\n- In Line 275, the assumption is that $P\\_{X\\_{u} \\mid Y\\_{u}}(\\mathbf{x}|y) =  P\\_{X\\_{l} \\mid Y\\_{l}}(\\mathbf{x}|y)$ (between $u$ and $l$). However, the importance weight in 277 deals with $P\\_{X\\_{u}, Y\\_{u}}$ and  $P\\_{X\\_{v}, Y\\_{v}}$. Are the authors relying on the fact that since $\\mathcal{D}\\_{v}$ is sub-sampled from $\\mathcal{D}\\_{l}$ and thus share the same class conditionals? If yes, please consider making this clearer.\n- Please consider making the notations consistent. E.g., Line 286 uses $R_{P\\_u}$ (with lowercase $u$) while Line 294 uses $R_{P\\_U}$ (with uppercase $U$).\n- Did you use the logit-adjustment form in Line 234 (as opposed to the one in Eq. (1)) for your experiments?\n- Why have you used the form in Line 226 for sampling? Why can one not simply use $\\hat{P}\\_{Y\\_u}(y\\_i)$ as the probability to select $(\\mathbf{x}^l\\_i, y\\_i)$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fupnLUGxSn", "forum": "pI9n8wAR80", "replyto": "pI9n8wAR80", "signatures": ["ICLR.cc/2026/Conference/Submission1417/Reviewer_nQAr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1417/Reviewer_nQAr"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1417/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762148615723, "cdate": 1762148615723, "tmdate": 1762915763894, "mdate": 1762915763894, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}