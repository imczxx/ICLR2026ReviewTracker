{"id": "4sDszSYKP6", "number": 12599, "cdate": 1758208880886, "mdate": 1759897499533, "content": {"title": "Strongly Convex Sets in Riemannian Manifolds", "abstract": "Strong convexity plays a key role in designing and analyzing convex optimization algorithms and is well-understood in Hilbert spaces. However, the notion of strongly convex sets beyond Hilbert spaces remains unclear. In this paper, we propose various definitions of strong convexity for uniquely geodesic sets in a Riemannian manifold, examine their relationships, introduce tools to identify geodesically strongly convex sets, and analyze the convergence of optimization algorithms over these sets. In particular, we show that the Riemannian Frank-Wolfe algorithm converges linearly when the Riemannian scaling inequalities hold.", "tldr": "We propose various definitions of strong convexity for uniquely geodesic sets in a Riemannian manifold, examine their relationships, introduce tools to identify strong convexity, and analyze the convergence of optimization algorithms over these sets", "keywords": ["Strong convexity", "Riemannian", "Manifold", "Frank-Wolfe", "optimization", "nonconvex"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5e4c9a96f970ef5f6169c33e0b3f3601a69ff607.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a Riemannian Frank–Wolfe (RFW) algorithm with linear convergence guarantees under a novel set of strong convexity assumptions for constraint sets on manifolds. It extends the classical Euclidean FW framework and introduces several definitions of strong convex sets tailored to geodesic settings. The theoretical development is comprehensive and the main results are sound."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper generalizes linear convergence guarantees of the FW method from Euclidean to Riemannian settings under appropriately defined curvature-aware convexity.\n\n2. The paper provides formal geometric characterizations and includes theoretical examples of sets satisfying the RSI condition."}, "weaknesses": {"value": "1. Although the paper motivates the RFW method via machine learning applications (e.g., Example 5.3), there are no real ML experiments. In particular, the neural network loss mentioned in Example 5.3 is not geodesically strongly convex, and the main convergence theorems do not apply to such cases. This weakens the practical relevance of the proposed method.\n\n2. The three definitions of strongly convex sets—geodesic, Riemannian, and double-geodesic—are introduced in sequence, but are somewhat hard to digest. A clearer summary (e.g., a comparison table showing hierarchy, assumptions, and known examples) would greatly help readability.\n\n3. The proposed notion of strong convexity (and RSI) is in contrast with proximal smoothness (prox-regularity) in Euclidean space, where the corresponding inequalities (see Davis, Drusvyatskiy, and Shi, SIAM J. Optim. 2025) take the opposite form (i.e., bounding curvature from above instead of below). The paper should clarify that this is due to fundamentally different settings: the current work focuses on Riemannian geometry, while prox-regularity is established in embedded space.\n\nreferences:\nDavis, D., Drusvyatskiy, D., and Shi, Z. (2025). Stochastic Optimization Over Proximally Smooth Sets. SIAM Journal on Optimization, 35(1), 157–179."}, "questions": {"value": "Which practical ML objectives/constraints on common manifolds (e.g., sphere, SPD, Grassmann) actually satisfy your assumptions (geodesic convexity + RSI, or approximate RSI + gradient lower bound)? Please provide at least one end-to-end experiment and a concrete example to check/estimate the RSI constant and strong-convexity modulus on real data."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "36L134Ojoy", "forum": "4sDszSYKP6", "replyto": "4sDszSYKP6", "signatures": ["ICLR.cc/2026/Conference/Submission12599/Reviewer_ArMd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12599/Reviewer_ArMd"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12599/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761832307944, "cdate": 1761832307944, "tmdate": 1762923449474, "mdate": 1762923449474, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the notion of strong convexity in the setting of reimannian manifolds (and geodesic spaces). Though strong convexity is a well studied and natural notion in Euclidean space, generalization of this concept to manifolds is non trivial. The present paper studies various versions of such a definition and presents fast convergence of natural algorithms under these definitions. In particular, they show that a version of Frank-Wolfe converges linearly for strongly convex optimization"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Generalization of the toolkit of optimization to the setting of manifolds has considered an interesting and important problem for the past several years, due to both theoretical and practical motivation. Systemizing Euclidean definition to the manifold setting is an important step and understanding what assumptions lead to fast algorithms is an important step"}, "weaknesses": {"value": "Though the problem is interesting, I personally think that the definitions presented in the paper are not particularly insightful and it is not clear how generally applicable and useful the defnition would be. As presented, the definition come off as a \"syntactic\" generalization of the Euclidean case and thus fail to convey insight into the RM optimization problem"}, "questions": {"value": "-> Further discussion of the assumptions are very important. For example, assumption 1.3 seems very strong to me. In particular, it is seems like a strong quantitative local Euclidean property that could potential make the difficultly of the RM setting a bit moot (I understand that there is still variation in the metric and this leads to technical difficulties; but it would be good discuss the \"conceptual\" hurdles. \n-> Getting log(1/eps) rates for Geodesic optimization actually happens to be an important problem in subfields of theoretical computer science (eg https://arxiv.org/pdf/1910.12375) and has garnered interest in the field. Unfortunately most proposed algorithms work under assumptions that are hard to check or make assumptions the algorithm work only is \"near Euclidean\" settings. It would be interesting to see a discussion of the present paper in this context (or related applications)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HApH40yRtg", "forum": "4sDszSYKP6", "replyto": "4sDszSYKP6", "signatures": ["ICLR.cc/2026/Conference/Submission12599/Reviewer_51us"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12599/Reviewer_51us"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12599/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762150379388, "cdate": 1762150379388, "tmdate": 1762923448873, "mdate": 1762923448873, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper considers strongly convex sets in Riemannian manifolds and proposes several definitions, which generalize the Euclidean counterparts. In addition, the linear convergence rate of Riemannian FW algorithm can be derived via the proposed Riemannian scaling inequality condition."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Studying strongly convex sets in Riemannian manifolds is interesting, which requires a good understanding of both convex analysis and Riemannian optimization/geometry."}, "weaknesses": {"value": "1. I did not see the practical improvement/implication of this paper's results on optimization over manifolds (e.g., SPD, SO(3), Stiefel manifolds, Grassmann manifolds). It would be great if the authors can explicitly provide some new results for concerte examples.\n2. The numerical experiments are limited and only for sphere constraints. In this case, this paper is quite related to (https://arxiv.org/abs/1911.11955). In addition, there are several papers of optimization over SPD and Stiefel manifolds with linear convergence rate, e.g., (https://arxiv.org/abs/2001.01700, https://arxiv.org/abs/2112.06556). It would be better to compare with these papers."}, "questions": {"value": "1. the scaling inequality is quite similar to the uniform normal inequality in https://www.heldermann-verlag.de/jca/jca02/jca02008.pdf and https://arxiv.org/pdf/2002.06309. It would be better to mention them in your paper.\n2. Could you provide some concrete examples of $C$ that satisfy Assumption 1.2?\n3. In lines 243-245, the authors mention \"This theorem applies to most practical cases ...\". Could the authors explain more about this part? I am curious about the implication of results in this paper on specific optimization over manifolds (e.g., SPD, SO(3), Stiefel manifolds)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "oDYPdXTfx0", "forum": "4sDszSYKP6", "replyto": "4sDszSYKP6", "signatures": ["ICLR.cc/2026/Conference/Submission12599/Reviewer_QN9G"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12599/Reviewer_QN9G"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12599/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762202759541, "cdate": 1762202759541, "tmdate": 1762923448400, "mdate": 1762923448400, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a critical gap in Riemannian optimization by providing the first systematic definition and analysis of strongly convex sets on Riemannian manifolds. Unlike prior work that focused on strong convexity of functions (Zhang & Sra, 2016; 2018) or limited notions of set convexity in metric spaces, this work introduces three rigorous definitions of strongly convex sets (i.e., geodesic, Riemannian, double geodesic) that naturally extend Euclidean strong convexity."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Propositions 2.5–2.7 establish a hierarchy of strong convexity notions, clarifying when each definition is applicable (e.g., double geodesic strong convexity is equivalent to geodesic strong convexity under mild distance equivalence assumptions).\n\n2. Theorem 4.2 extends a classic Euclidean result (Journée et al., 2010) to Riemannian manifolds, showing that sublevel sets of geodesically smooth, strongly convex functions are themselves strongly convex.\n\n3. The paper leverages the Riemannian Scaling Inequality to prove linear convergence of the Riemannian Frank-Wolfe (RFW) algorithm (Theorems 5.1–5.2)."}, "weaknesses": {"value": "1. While this paper provides theoretical conditions for strong convexity (e.g., Theorem 4.2, Theorem D.4), it offers limited guidance on how to verify these conditions for a given manifold and set in practice.\n\n2. The results in this paper heavily depend on manifold curvature (e.g., Theorem D.4’s radius bound, Proposition D.2’s smoothness/strong convexity constants), but it does not fully explore how curvature impacts algorithmic performance or the practicality of strong convexity.\n\n3. The related work section mentions prior notions of set convexity in metric spaces (e.g., Aleksandrov, 1957; Paris, 2020) but fails to provide a systematic comparison of the proposed definitions to these alternatives.\n\n4. This paper mainly focuses on convex objectives (geodesically convex f), but many practical Riemannian optimization problems are non-convex (e.g., training manifold-valued neural networks, Katsman et al., 2023). Can the framework be extended to non-convex objectives with strongly convex feasible sets?"}, "questions": {"value": "1. While this paper provides theoretical conditions for strong convexity (e.g., Theorem 4.2, Theorem D.4), it offers limited guidance on how to verify these conditions for a given manifold and set in practice.\n\n2. The results in this paper heavily depend on manifold curvature (e.g., Theorem D.4’s radius bound, Proposition D.2’s smoothness/strong convexity constants), but it does not fully explore how curvature impacts algorithmic performance or the practicality of strong convexity.\n\n3. The related work section mentions prior notions of set convexity in metric spaces (e.g., Aleksandrov, 1957; Paris, 2020) but fails to provide a systematic comparison of the proposed definitions to these alternatives.\n\n4. This paper mainly focuses on convex objectives (geodesically convex f), but many practical Riemannian optimization problems are non-convex (e.g., training manifold-valued neural networks, Katsman et al., 2023). Can the framework be extended to non-convex objectives with strongly convex feasible sets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DVRARWcUiX", "forum": "4sDszSYKP6", "replyto": "4sDszSYKP6", "signatures": ["ICLR.cc/2026/Conference/Submission12599/Reviewer_6e96"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12599/Reviewer_6e96"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12599/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762248252664, "cdate": 1762248252664, "tmdate": 1762923447262, "mdate": 1762923447262, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper provides the first systematic study of strong convexity of sets in Riemannian manifolds, bridging geometric structure and algorithmic benefits. Authors introduce novel properties of sets defined in Riemannian manifolds, provide examples, and demonstrate improved convergence rates when minimizing functions over such sets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Authors introduce various definitions of strongly convex sets in Riemannian manifolds and establishes relationships between them.\n2. This paper introduces the notion of approximate scaling inequality and its link with what they call double geodesic strong convexity.\n3. Authors prove that sublevel sets of geodesically smooth, strongly convex functions are strongly convex in Riemannian manifolds under mild conditions, providing a constructive perspective for identifying such sets.\n4. Authors derive a linear convergence bound for the Riemannian Frank–Wolfe algorithm when the constraint set satisfies the (Approximate) Riemannian Scaling Inequality.\n5. This paper also provides examples of strong convex sets in Riemannian manifolds. More precisely, Appendix D shows that Riemannian balls (with restricted radius) satisfy the strongest of the notions of Riemannian strong geodesic convexity. Appendix E details a simple linear minimization oracle for the sphere manifold."}, "weaknesses": {"value": "This article has theoretical significance and is well written, however， this paper lacks practical experiments. Can some practical application scenarios of the proposed algorithm be added."}, "questions": {"value": "1. This article has theoretical significance and is well written, however， this paper lacks practical experiments. Can some practical application scenarios of the proposed algorithm be added.\n2. If it is possible to discuss the application of the proposed theory in practical scenarios in the main text."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "yfLUHrKtRR", "forum": "4sDszSYKP6", "replyto": "4sDszSYKP6", "signatures": ["ICLR.cc/2026/Conference/Submission12599/Reviewer_66fh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12599/Reviewer_66fh"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission12599/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762783279410, "cdate": 1762783279410, "tmdate": 1762923446314, "mdate": 1762923446314, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}