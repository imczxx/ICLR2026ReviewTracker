{"id": "RuP0GDhjWb", "number": 8299, "cdate": 1758077911256, "mdate": 1759897793581, "content": {"title": "When Do Multi-Agent Systems Outperform? Analysing the Learning Efficiency of Agentic Systems", "abstract": "Reinforcement Learning (RL) has emerged as a crucial method for training or fine-tuning large language models (LLMs), enabling adaptive, task-specific optimizations through interactive feedback. Multi-Agent Reinforcement Learning (MARL), in particular, offers a promising avenue by decomposing complex tasks into specialized subtasks managed by distinct interacting agents, potentially enhancing the ability and efficiency of LLM systems. However, theoretical insights regarding when and why MARL outperforms Single-Agent RL (SARL) remain limited, creating uncertainty in selecting the appropriate RL framework. In this paper, we address this critical gap by rigorously analyzing the comparative sample efficiency of MARL and SARL within the context of LLM.\n% \\cwu{training/fine-tuning? js: applicable to both}. \nLeveraging the Probably Approximately Correct (PAC) framework, we formally define SARL and MARL setups for LLMs, derive explicit sample complexity bounds, and systematically characterize how task decomposition and alignment influence learning efficiency. Our results demonstrate that MARL improves sample complexity when tasks naturally decompose into independent subtasks, whereas dependent subtasks diminish MARL's comparative advantage. Additionally, we introduce and analyze the concept of task alignment, quantifying the trade-offs when enforcing independent task decomposition despite potential misalignments. These theoretical insights clarify empirical inconsistencies and provide practical criteria for deploying MARL strategies effectively in complex LLM scenarios.", "tldr": "This paper compares the efficiency of llm-based multi-agent system and single agent system", "keywords": ["learning efficiency", "llm-based agentic system"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9a3df8ea82ba5df80f50c1ae2619dc45cacff60b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates a fundamental theoretical question: under what conditions does Multi-Agent Reinforcement Learning (MARL) outperform Single-Agent Reinforcement Learning (SARL) in the context of large language model (LLM) training? The authors employ the Probably Approximately Correct (PAC) learning framework to derive sample complexity bounds for both SARL and MARL under different task decomposition scenarios. The main theoretical contributions include: (1) explicit sample complexity characterizations for SARL (Theorem 4.1) and MARL under dependent (Theorem 4.2) and independent (Theorem 4.3) subtask decompositions; (2) formal analysis showing that MARL achieves superior sample efficiency when tasks decompose into independent subtasks, with efficiency gains up to 1/K for K homogeneous agents (Proposition 4.4); and (3) quantification of task misalignment effects through an alignment factor α (Theorem 4.6, Proposition 4.7).\n\nThe theoretical analysis is conducted within a well-defined framework with standard regularity assumptions (bounded rewards, compact parameter spaces, Lipschitz parameterization, finite horizon). However, the empirical validation is limited to synthetic noisy arithmetic regression tasks, which raises significant concerns about the practical applicability and real-world relevance of the theoretical insights, particularly given the paper's explicit motivation of LLM agentic systems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "### 1. **Addresses an Important and Timely Question**\nThe paper tackles a fundamental theoretical gap in understanding when and why MARL outperforms SARL in LLM training scenarios. This question is highly relevant given the growing adoption of multi-agent LLM systems in practice (retrieval-augmented generation, tool-augmented generation, multi-step reasoning), yet the lack of theoretical understanding. The motivation is well-articulated and the research question is clearly formulated.\n\n### 2. **Rigorous Theoretical Framework**\nThe PAC-based analysis is technically sound and provides explicit, non-asymptotic sample complexity bounds. The use of covering numbers and uniform convergence arguments is appropriate and correctly applied. The proofs appear rigorous (based on the appendix), and the assumptions (bounded rewards, compact parameters, Lipschitz continuity, finite horizon) are reasonable and well-justified in Appendix B as aligned with practical LLM training regimes (weight decay, KL penalties, gradient clipping, sequence length limits).\n\n### 3. **Clear Characterization of Task Structure Effects**\nThe distinction between independent (Equation 3.2) and dependent (Equation 3.1) subtask decompositions is insightful. The theoretical results cleanly show that:\n- For independent subtasks, MARL complexity is dominated by the hardest agent: O(d̃ log(γ/ε)/ε²)\n- For dependent subtasks, MARL complexity scales with cumulative difficulty: O(Σᵢ dᵢ log(·)/(ε/K)²)\nThis provides a principled way to reason about task decomposition strategies.\n\n### 4. **Novel Alignment Analysis**\nThe introduction of the task alignment factor α (Section 4.3) and the characterization of conditions under which MARL remains advantageous despite misalignment (Proposition 4.7) is a valuable theoretical contribution. The condition κ_d κ_ℓ ≤ (1 - 2α/ε)² provides actionable guidance for practitioners.\n\n### 5. **Well-Written and Well-Organized**\nThe paper is clearly written with good structure. The technical presentation is accessible, with intuitions provided alongside formal statements. The progression from problem setup to main results to alignment analysis is logical."}, "weaknesses": {"value": "This is the paper's most significant weakness and the primary reason for my recommendation to reject. The empirical study (Section 4.4) consists solely of synthetic noisy arithmetic regression tasks:\n\n```\ny_i = w_i^T x_i + ξ_i  (independent)\ny_i = w_i^T x_i + average(y_(<i)) + ξ_i  (dependent)\n```\n\n**Why this is problematic:**\n\na) **Misalignment with Motivation**: The paper is explicitly motivated by LLM agentic systems, citing applications like retrieval-augmented generation, tool-augmented generation, and multi-step reasoning. Yet there is zero validation on any actual LLM task. The gap between toy linear regression and real LLM training is enormous.\n\nb) **Questionable Relevance**: The assumptions underlying the theory (autoregressive text generation, sequence-level rewards, policy gradient methods like PPO/GRPO mentioned in Appendix A) are completely absent from the experiments. The synthetic tasks do not involve:\n   - Language models or text generation\n   - Sequential decision-making with discrete actions\n   - Reward signals typical of RLHF scenarios\n   - Any of the complexity inherent in LLM training\n\nc) **Trivial Task Structure**: The arithmetic tasks are so simplified that they fail to stress-test the theoretical predictions. For instance:\n   - The \"independent\" case is literally independent linear regressions\n   - The \"dependent\" case uses a simple averaging operation\n   - There's no exploration, no credit assignment challenges, no compositional complexity\n   \nd) **Missing Key Experimental Questions**: The experiments don't address questions critical to the theory's practical utility:\n   - How do real LLM tasks align with the independent/dependent decomposition spectrum?\n   - Can task decomposition structure be identified in practice?\n   - Do the theoretical sample complexity ratios hold in realistic settings?\n   - What about partial dependencies or more complex task structures?\n\n**What would be needed**: At minimum, the paper should include experiments on 1-2 real LLM tasks demonstrating:\n- A task that naturally decomposes independently (e.g., retrieval + generation)\n- Sample efficiency comparisons matching theoretical predictions\n- Connection to actual RLHF or policy gradient training\n\nWithout this, the paper reads as a theoretical exercise disconnected from its stated application domain."}, "questions": {"value": "1. **Why no real LLM experiments?** This is the elephant in the room. The paper is motivated by LLM agentic systems and cites extensive LLM applications. Why not validate the theory on even a single real LLM task? For example:\n   - Code generation with retrieval (MARL: retrieval agent + generation agent vs. SARL: end-to-end)\n   - Multi-step reasoning on GSM8K (MARL: decomposed steps vs. SARL: direct)\n   - Tool-augmented QA (MARL: tool-use agent + QA agent vs. SARL: integrated)\n\n2. **What is the theory-practice gap?** Given that the bounds are based on covering numbers (which are known to be loose), what is the expected gap between theoretical predictions and practical sample requirements? Can you provide any empirical evidence from the synthetic experiments that the theoretical bounds are not vacuous?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wKm6iRosmK", "forum": "RuP0GDhjWb", "replyto": "RuP0GDhjWb", "signatures": ["ICLR.cc/2026/Conference/Submission8299/Reviewer_osy4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8299/Reviewer_osy4"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761554633265, "cdate": 1761554633265, "tmdate": 1762920228652, "mdate": 1762920228652, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on comparing the sample efficiency advantages of MARL and SARL approaches in LLM agentic systems. Based on the PAC framework, it formally defines the LLM sequential decision problem and presents a comparison of the efficiency of MARL and SARL under different subtask conditions, along with quantitative analysis and verification. The conclusions are validated using synthetic tasks."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "LLM agentic systems have recently been frequently explored for complex task processing based on MARL. While many empirical algorithms have emerged for MARL-based approaches, theoretical guidance is currently lacking. \n\nThis paper presents a rigorous theoretical derivation and, in the LLM agentic setting, provides a systematic PAC comparison and testable thresholds for SARL vs. MARL. In particular, the introduced \"task alignment\" factor, $\\alpha$, quantifies the sample cost of MARL strategies in complex real-world situations, providing strong theoretical guidance."}, "weaknesses": {"value": "1.\tExperimental Verification: First, I think there is a gap between the experimental verification and and motivation & background, which are based on a complex LLM agentic system. Section 4.4 only uses a lightweight synthetic linear task. The \"dependence\" in the synthetic experiment (i.e., the current output depends on the mean of the previous output) is completely different from the complex semantics, logic, and state dependencies in the LLM agentic system. Therefore, while this experiment mathematically verifies the theory, it does not prove that the theory can be transferred to the LLM problem it claims to solve. Second, the experiment lacks some key theoretical verifications. For example, in Section 4.3, the paper proposes a task misalignment and defines a \"misalignment factor\" α, deriving new sample bounds. However, the experimental section does not verify α and its PAC bounds at all. Furthermore, the paper itself mentions in its limitations that the experiment only tests the two extreme cases of \"complete independence\" and \"complete dependence,\" lacking exploration of intermediate scenarios and coverage of \"partial dependence.\"\n\n2.\tLimitations of Theoretical Assumptions: Based on strong assumptions, the paper models MARL as segmented turn-based, sequence-level single scalar rewards, and text concatenation. This is significantly different from real-world complex agent interactions, such as parallel collaboration and multi-round debate."}, "questions": {"value": "1.\tThe theoretical bounds depend on hyperparameters such as $d,d_i,B,B_i,L_{\\rm step},T_{\\rm max}$. How do these quantities relate to the actual number of parameters in a high-dimensional LLM? Can you provide a theoretical and practical connection?\n\n2.\tCan you add supplementary experiments to bridge the gap between the paper's background and experiments, and provide additional experimental support for the relevant theory?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AlDQTV9qQ7", "forum": "RuP0GDhjWb", "replyto": "RuP0GDhjWb", "signatures": ["ICLR.cc/2026/Conference/Submission8299/Reviewer_oXhZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8299/Reviewer_oXhZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761659561567, "cdate": 1761659561567, "tmdate": 1762920228326, "mdate": 1762920228326, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper provides a theoretical analysis of when multi-agent systems outperform single-agent ones in learning efficiency. Using the PAC framework, it derives sample complexity bounds for both settings and shows that multi-agent systems gain advantages when tasks can be decomposed into independent subtasks but lose efficiency when interdependencies increase. A small synthetic experiment supports the theory, illustrating how task alignment determines when multi-agent learning is beneficial."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper addresses a valuable and timely problem: providing a theoretical understanding of when multi-agent systems outperform single-agent systems. Such an analysis is needed to ground current LLM-based multi-agent research in solid theory.\n\n- The theoretical foundation is solid. The authors derive PAC-based sample complexity bounds for both MARL and SARL, offering a rigorous comparison of their learning efficiencies.\n\n- The inclusion of a small empirical study adds some empirical support to the theoretical conclusions and helps illustrate the conditions under which multi-agent setups are beneficial."}, "weaknesses": {"value": "- While the theoretical analysis is sound, the setting is overly simplified. The “multi-agent” formulation effectively reduces to a fixed workflow where each agent corresponds to a submodel handling a static subtask. This abstraction misses the richer dynamics of real LLM-based multi-agent systems, where benefits and failures often stem from high-level task decomposition and coordination rather than low-level execution efficiency.\n\n- The conclusions that multi-agent systems help when subtasks are independent and hurt when they are interdependent, though well-derived, are quite intuitive. It offers limited new insight beyond established intuition.\n\n- The empirical study is minimal, involving only a single toy task without details on model training or architecture. Also, despite frequent references to “LLMs,” the experimental setup and simplifications in the theoretical deduction make the work largely disconnected from realistic LLM-based multi-agent scenarios."}, "questions": {"value": "Sea above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "t7kEt9PIxM", "forum": "RuP0GDhjWb", "replyto": "RuP0GDhjWb", "signatures": ["ICLR.cc/2026/Conference/Submission8299/Reviewer_geeW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8299/Reviewer_geeW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761724262148, "cdate": 1761724262148, "tmdate": 1762920227959, "mdate": 1762920227959, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a clear theoretical framework for comparing the sample efficiency of MARL and SARL under different task decomposition structures. The topic is important and timely in the context of LLM-based RL. The theoretical analysis is mathematically sound and extends to non-ideal task alignment scenarios, offering practical insights. However, several theoretical assumptions are not clearly stated or sufficiently justified, including the independence among agents, the definition of some symbols, the derivation of certain theorems, and the reliance on specific assumptions. In addition, the empirical study is relatively simplified and does not fully examine the effects of key parameters."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses an important and timely problem in the context of LLM-based RL by clarifying the theoretical boundary between MARL and SARL applicability. It provides valuable insights into how task decomposition structure influences sample efficiency and extends the discussion to imperfect alignment cases, offering practical relevance beyond ideal theoretical settings."}, "weaknesses": {"value": "1. The paper does not specify whether agents share the same input or have partial observations. Would this assumption affect the validity of the theoretical derivations?\n2. Several symbols, such as $r_i$ in Eq.~(3.1), are introduced without clear definitions. Please provide precise definitions to ensure the rigor and clarity of the theoretical reasoning.\n3. The paper does not clearly explain why the $K^2$ term in Theorem~4.2 represents a tight bound. The dependence among rewards $r_i$ is not formally defined, so the derivation of this scaling factor lacks a clear justification.\n4. Does the analysis assume i.i.d. samples under a fixed distribution? If so, it would be helpful to mention this in the limitations section, since real RL/MARL trajectories are often temporally correlated, which may affect the practical validity of the theoretical bounds.\n5. The analysis assumes that agent dimensions $d_i$ can be directly summed. Does this imply independent and non-overlapping parameters? In practice, shared or heterogeneous architectures may violate this assumption and lead to an overestimation of model complexity.\n6. The alignment factor $\\alpha$ is defined in Eq.~(4.1) but not specified or computed. More explanation is needed on how $\\alpha$ could be interpreted or estimated in LLM-based RL settings.\n7. The empirical study is too simplified and does not capture the effects of key parameters such as $K$ and $d$, or other factors identified as influential in the theoretical analysis."}, "questions": {"value": "1. Can the above weaknesses be addressed?\n2. Releasing the code or benchmark used in the empirical study would improve the paper’s transparency and reproducibility."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "sWJgNT8o98", "forum": "RuP0GDhjWb", "replyto": "RuP0GDhjWb", "signatures": ["ICLR.cc/2026/Conference/Submission8299/Reviewer_aE3u"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8299/Reviewer_aE3u"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761794148768, "cdate": 1761794148768, "tmdate": 1762920227633, "mdate": 1762920227633, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}