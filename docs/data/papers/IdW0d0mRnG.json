{"id": "IdW0d0mRnG", "number": 7768, "cdate": 1758035445219, "mdate": 1759897833663, "content": {"title": "Asymptotic analysis of shallow and deep forgetting in replay with neural collapse", "abstract": "Neural networks exhibits two forms of forgetting: deep (loss of feature separability) and shallow (classifier misalignment). We analyze the effect of replay buffers on these phenomena through an asymptotic study of feature geometry under Neural Collapse. Our results show that replay reliably mitigates deep forgetting but fails to prevent shallow forgetting, as classifier weights converge to buffer-based rather than true class statistics. We extend the NC framework to continual learning, including the multi-head setting, and characterize how buffer size, weight decay, and feature-norm growth determine feature–head alignment. The analysis further reveals that multi-head models induce structurally lower-rank feature spaces and that weight decay has divergent effects on separability across learning regimes. Finally, we establish a formal connection between continual learning and out-of-distribution detection. Empirical evaluations on standard benchmarks support the theoretical predictions and quantify the persistence of shallow forgetting across buffer sizes.", "tldr": "We analyze continual learning in the long-training limit, showing via Neural Collapse that replay preserves feature separability but causes head–feature misalignment, explaining why deep forgetting is mitigated while shallow forgetting persists.", "keywords": ["continual larning", "neural collapse", "deep learning"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/eaea177e78311feefcae710f7167aeca07ad8302.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The author developed an asymptotic framework to analyze feature geometry with and without replay buffers. They demonstrate that replay can reliably alleviate deep forgetting (loss of feature separability), but does not alleviate shallow forgetting (misalignment between classifier weights and features). This work extends NC theory to multi head CL settings, characterizes the effects of buffer size and weight decay, and establishes a theoretical connection between CL and OOD. The empirical results of CIFAR100, Tiny ImageNet, and CUB-200 validate the theoretical findings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Extends Neural Collapse analysis to continual learning and multi-head architectures—an unexplored direction. Uses asymptotic analysis and connects NC with OOD theory in a rigorous manner. Establishes a bridge between NC, CL, and OOD detection, enriching all three research domains."}, "weaknesses": {"value": "While conceptually strong, it provides limited actionable guidance for improving CL performance."}, "questions": {"value": "Why do we focus on discussing Multi Head Models? Is this model commonly used in modern continuous learning and multi task learning? Do you analyze whether the purpose of this model is to increase workload or has practical significance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "UuQqJb7DAj", "forum": "IdW0d0mRnG", "replyto": "IdW0d0mRnG", "signatures": ["ICLR.cc/2026/Conference/Submission7768/Reviewer_hg1i"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7768/Reviewer_hg1i"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7768/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761893550057, "cdate": 1761893550057, "tmdate": 1762919809759, "mdate": 1762919809759, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents an asymptotic analysis of replay-based continual learning under the neural collapse phenomenon. The authors study how replay buffers affect shallow and deep forgetting. Empirically, they find that replay-based continual learning effectively mitigates deep forgetting but still suffers from shallow forgetting even when the replay buffers are large. They then use Neural Collapse theory to analyze the limiting geometry of features and heads in three continual learning setups. They also identify a connection between continual learning and OOD detection, showing that under weight decay, the distribution of OOD inputs converges to a degenerate null distribution. They also show the effect of replay in their framework, demonstrating that deep forgetting is not mitigated by the model with small replay buffer because of the approximation error when using the buffer distribution to approximate the true class distribution."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This work proposes a novel framework for replay-based continual learning. The results and implications are meaningful and helpful to the community. \n2. The authors provide a sufficient and comprehensive theoretical analysis for replay-based continual learning, considering three different setups and showing the effect of replay.\n3. The empirical study is consistent with the theoretical findings, across both real-world and simulated datasets.\n4. The work is well structured and easy to follow for the readers."}, "weaknesses": {"value": "1. In Theorems 1, 2, and 3, it seems that $\\nu = 1 - \\eta \\lambda$ is required to be non-negative or greater than $-1$, but I do not find any explicit condition on $\\nu$.\n\n2. The explanation of why replay cannot strongly mitigate shallow forgetting is not convincing to me. The authors argue that the approximation error is the key reason, but there is no formal result to support this claim, which limits the contribution of this paper.\n \n3. In the experimental results, the authors only vary the buffer size from $0\\\\%$ to $10\\\\%$. This seems insufficient to support their theoretical findings.\n\n4. There are some typos and inconsistencies:\n   1. Lines 139, 141. Two citations are missing.\n   2. Line 315, \"Theorem 6\" should be \"Theorem 2.\"\n   3. Line 987, \"class-il\", \"domain-il\", and \"task-il\" should be written as \"CIL,\" \"DIL,\" and \"TIL,\" consistent with other figures. Moreover, the task indices in Figure 12 should be positive integers.\n\n5. The term “balanced replay” is unclear. I think “balanced replay” refers to the replay buffer being sampled in a balanced manner from the training set, rather than the buffer size being equal to the size of the training data."}, "questions": {"value": "1. How to understand the theoretical results when $\\eta \\lambda \\geq 2$?\n2. Why are experiments conducted only for buffer sizes varying from $0\\\\%$ to $10\\\\%$?\n3. What is the precise meaning of \"balanced replay\"?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fy5cZsyJo4", "forum": "IdW0d0mRnG", "replyto": "IdW0d0mRnG", "signatures": ["ICLR.cc/2026/Conference/Submission7768/Reviewer_wGRs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7768/Reviewer_wGRs"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7768/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920857812, "cdate": 1761920857812, "tmdate": 1762919809377, "mdate": 1762919809377, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper analyzes how the replay buffer in continual learning scenarios influences model forgetting, distinguishing between shallow and deep forgetting. It further investigates these phenomena within the Neural Collapse framework, examining the geometric structure of the feature space and supporting the analysis with empirical results."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper is well written and clearly organized, with a pleasant and coherent flow of discussion. The topic addressed is novel and engaging. Moreover, the theoretical analysis is insightful and clearly explained."}, "weaknesses": {"value": "While the theoretical discussion is sound and convincing, I have some concerns regarding the empirical analysis. First, it is unclear why the authors chose ResNet and ViT as reference models. It seems that the selected architectures could significantly influence the observed behaviors and results. If this is the case, the authors should explicitly discuss this aspect. Otherwise, a justification of why the chosen architectures do not affect the outcomes should be provided.  Along the same lines, the rationale behind considering both pretrained and from-scratch models is not entirely clear. In the case of pretrained models, it would be important to explain how the initialization was adapted to the continual learning setting, as mentioned in Section 1.1. Additionally, the discussion in Section 3.3.2 highlights the effect of weight decay, but the influence of other hyperparameters and architectural choices remains unexplored. Given their potential impact, especially in the context of deep forgetting, this omission seems non-negligible. The authors should include a discussion addressing this point to provide a more comprehensive understanding of the empirical results. Another aspect that would benefit from clarification is the adoption of the Neural Collapse (NC) framework. The authors should briefly discuss possible alternative frameworks and justify the choice of NC in this context.\nFinally, the discussion on the distinction between multi-head and single-head settings could be improved by adding a short introductory explanation earlier in the paper to help readers unfamiliar with these concepts. In addition, Section 3 contains some citation issues, where “?” symbols appear instead of proper references, and these should be corrected."}, "questions": {"value": "- Could the authors clarify the rationale behind choosing ResNet and ViT as reference architectures, and discuss how this choice might influence the observed behaviors and results?\n\n- How were pretrained models adapted to the continual learning setting, and what motivated the comparison between pretrained and from-scratch training approaches?\n\n- Beyond weight decay, have the authors examined the influence of other hyperparameters or architectural choices on the empirical results, particularly in relation to deep forgetting?\n\n- What motivated the adoption of the Neural Collapse framework, and could the authors discuss potential alternative frameworks or justify why NC is particularly suitable for this analysis?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "fHPE64IK8v", "forum": "IdW0d0mRnG", "replyto": "IdW0d0mRnG", "signatures": ["ICLR.cc/2026/Conference/Submission7768/Reviewer_5K6E"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7768/Reviewer_5K6E"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7768/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761941230558, "cdate": 1761941230558, "tmdate": 1762919808652, "mdate": 1762919808652, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}