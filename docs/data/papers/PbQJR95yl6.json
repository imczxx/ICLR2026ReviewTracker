{"id": "PbQJR95yl6", "number": 18231, "cdate": 1758285434049, "mdate": 1759897117795, "content": {"title": "A Modular Multi-task Reasoning Framework Integrating Spatio-temporal Models and LLMs", "abstract": "Spatio-temporal data mining plays a pivotal role in informed decision making across diverse domains. However, existing models are often restricted to narrow tasks, lacking the capacity for multi-task inference and complex long-form reasoning that require generation of in-depth, explanatory outputs. These limitations restrict their applicability to real-world, multi-faceted decision scenarios. In this work, we introduce STReason, a novel framework that integrates the reasoning strengths of large language models (LLMs) with the analytical capabilities of spatio-temporal models for multi-task inference and execution. Without requiring task-specific finetuning, STReason leverages in-context learning to decompose complex natural language queries into modular, interpretable programs, which are then systematically executed to generate both solutions and detailed rationales. To facilitate rigorous evaluation, we construct a new benchmark dataset and propose a unified evaluation framework with metrics specifically designed for long-form spatio-temporal reasoning. Experimental results show that STReason significantly outperforms advanced LLM baselines across all metrics, particularly excelling in complex, reasoning-intensive spatio-temporal scenarios. Human evaluations further validate STReason’s credibility and practical utility, demonstrating its potential to reduce expert workload and broaden the applicability to real-world spatio-temporal tasks. We believe STReason provides a promising direction for developing more capable and generalizable spatio-temporal reasoning systems. Our code is available at: https://anonymous.4open.science/r/STReason-B0B2/", "tldr": "This paper presents STReason, a modular framework combining LLMs and spatio-temporal models for multi-task inference. It generates interpretable outputs without fine-tuning and achieves SOTA on a new reasoning dataset with strong human evaluations.", "keywords": ["Spatio-temporal Reasoning", "Complex Query Decomposition", "Modular LLM", "Function Pool"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f208a7c17a4ef541e7f4f73eb6a664ed0330017c.pdf", "supplementary_material": "/attachment/8f2c5f3b68bf92500582d61c31da7a29221b34b0.zip"}, "replies": [{"content": {"summary": {"value": "This paper focuses on long-contextual question answering, which requires spatio-temporal cross-task reasoning.\n\nThis paper proposes STReason, which utilizes LLM as a high-level planner and incorporates spatio-temporal models as tools/functions to deliver subtask decomposition and tool calling to handle multi-task, long-form inference and execution.\n\nThe authors introduce a new benchmark specifically for spatio-temporal tasks; both automated and human evaluations demonstrate that STReason has significant advantages over robust LLM baseline algorithms."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper proposes a new framework for spatio-temporal reasoning. Combining LLMs’ general knowledge with domain-specific small models is effective: the small models complement LLMs with specialized expertise while LLMs provide a unified framework for high-level scheduling, integrating, and analyzing information gathered by small models.\n\nThe experimental results show their superior performance, especially in the metric of Factuality score and human evaluation."}, "weaknesses": {"value": "1. It would significantly strengthen the evaluation to include domain-specific baselines in spatio-temporal reasoning. Such comparisons would better contextualize the gains and clarify where the proposed approach provides unique value.\n\n2. It’s unclear whether the function pool actually helps. Intuitively, it should, but the results in Table 3 don’t clearly demonstrate a benefit. Additionally, how to choose domain-specific functions or models for LLMs.\n\n3. While the framework is tailored to spatio-temporal settings and has some novel elements, the overall paradigm—LLMs as tool callers invoking domain-specific small models—feels familiar. As a result, the contribution may fall a bit short of the typical acceptance bar.\n\n4. Additionally, it is not clear how the proposed benchmark can contribute to the research field. The author states that they address long-form reasoning, but I did not see a lot of description or comparison about this."}, "questions": {"value": "It appears that answers to the reasoning tasks are free-form. Could the authors provide more details about the evaluation protocol? If an additional LLM is used as the evaluator, how is the consistency and accuracy of its judgments ensured?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "H5nwnmo12k", "forum": "PbQJR95yl6", "replyto": "PbQJR95yl6", "signatures": ["ICLR.cc/2026/Conference/Submission18231/Reviewer_69yp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18231/Reviewer_69yp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18231/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761924781530, "cdate": 1761924781530, "tmdate": 1762927968525, "mdate": 1762927968525, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents STReason, a two stage modular spatio temporal reasoning framework where an LLM emits executable ST Programs and an interpreter runs specialized modules to produce verifiable execution rationales. Experiments on a new benchmark show improvements over pure LLM baselines in constraint adherence, factuality, and forecasting accuracy; contributions include the architecture, an extensible function pool, and evaluation suite, with limitations in manual example/function curation and rare anomaly detection."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper proposes a new benchmark covering spatio-temporal analysis, anomaly detection, and forecasting reasoning, with unified evaluation metrics that better reflect practical task and engineering constraints.\n2. It provides extensive empirical results on automatic metrics and human evaluation, and ablation studies that reveal how key design choices (e.g., in‑context examples and the Function Pool) concretely affect performance."}, "weaknesses": {"value": "The baseline setup is somewhat simplistic; it lacks direct comparisons with stronger time‑series/spatio‑temporal specialized methods or advanced hybrid baselines that invoke external tools, which may lead to an overestimation of the method’s relative advantage.\n\nThe approach depends on a manually designed and maintained Function Pool (and in‑context examples), reducing automation and deployability; when handling tasks with strict constraints, repeated Function calls can cause loss of contextual information. From the second demo in the video, when asked to query weekend data, the RefineOutput function appears to forget this requirement."}, "questions": {"value": "See the weakness above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UeSp74JwnQ", "forum": "PbQJR95yl6", "replyto": "PbQJR95yl6", "signatures": ["ICLR.cc/2026/Conference/Submission18231/Reviewer_PRfp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18231/Reviewer_PRfp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18231/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966713729, "cdate": 1761966713729, "tmdate": 1762927968136, "mdate": 1762927968136, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces STReason, a new framework that fuses LLMs with specialized spatio-temporal models to perform multi-task reasoning and execution without task-specific fine-tuning. STReason operates in the command generation stage and command execution stage. In the first stage, it generates a ST-Program based on examples, and on the second stage it executes the ST-Program sequentially using 12 modular components. The authors built a new benchmark of 150 instances from real-world datasets and evaluated the STReason on the proposed benchmark, along with baselines LLMs. Results show that the proposed STReason can improve the performance on the proposed benchmark."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The transparency and reproducibility is great. There's an open source repo and a video demo in the paper, verifying that the method is working and also ensuring it's easy to reproduce / apply the paper. \n2. The STReason proposal is novel. It combines LLM reasoning with domain-specific spatio-temporal models for multi-task inference and explanatory reasoning. \n3. The system design is simple and extensible. \n4. There are human annotators validating the accuracy of the proposed dataset."}, "weaknesses": {"value": "1. The performance of the proposed approach largely depend on manually curated in-context examples. As a result, the generalization is greatly limited. \n2. The evaluation dataset is small (150 queries) and spans only among traffic and air quality, which limits the evaluation on generalization.\n3. The baselines used are all general-purpose LLMs, but no comparison is made with specialized spatio-temporal neural networks. The comparison with specialized spatio-temporal neural networks will help to establish a context for the performance that LLM achieved."}, "questions": {"value": "1. How are Command Interpreter Modules determined? Why do we include one module instead of another? Are those just selected by authors or there are some rational behind the selection."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "YPckTPnU9W", "forum": "PbQJR95yl6", "replyto": "PbQJR95yl6", "signatures": ["ICLR.cc/2026/Conference/Submission18231/Reviewer_2E98"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18231/Reviewer_2E98"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18231/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761975602085, "cdate": 1761975602085, "tmdate": 1762927967775, "mdate": 1762927967775, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Traditional spatiotemporal models are specialized for narrow tasks (such as forecasting) and cannot handle complex reasoning, whereas general LLMs struggle to analyze ST data directly, often losing critical info when the data is converted to text. This paper presents a framework (STReason) to make LLMs into generalizable spatio-temporal reasoning systems. It uses in-context learning to decompose natural language queries into executable programs and executes these programs. A new benchmark dataset of 150 instances across three tasks (Analysis, Anomaly Detection, and Prediction & Reasoning) and an evaluation metric for long-form spatio-temporal reasoning are also proposed in the work."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Long-form reasoning for spatio-temporal data is an important and underexplored problem. \n2. ST Reason's training-free approach makes it practically advantageous."}, "weaknesses": {"value": "1. Only 150 examples across three tasks. This small scale makes it difficult to believe the STBench's robustness and generalizability. And Human evaluation is conducted only on 18 questions. \n2. Only 12 pre-defined modules in the Function Pool limit generalizability, even though the paper claims \"task and domain-agnostic\". Function Pool requires manual intervention to add new modules.\n3. Task-specific in-context examples require manual curation, which also limits generalizability.\n4. The framework is benchmarked only against vanilla LLMs like (GPT-4, Deepseek-V3), they don't compare STReason with any other Spatio-temporalness aware LLMs. The experiment, as designed, demonstrates that \"LLMs with ST tools\" are more effective at ST tasks than \"LLMs without ST tools,\" which is an expected outcome."}, "questions": {"value": "1. How does it perform on completely new task types not seen in the three categories?\n2. What is the performance if LLMs are given the ST models as tools? (No function pool or in-context examples)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "70XQkiQuUQ", "forum": "PbQJR95yl6", "replyto": "PbQJR95yl6", "signatures": ["ICLR.cc/2026/Conference/Submission18231/Reviewer_pm73"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18231/Reviewer_pm73"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18231/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984459462, "cdate": 1761984459462, "tmdate": 1762927967330, "mdate": 1762927967330, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}