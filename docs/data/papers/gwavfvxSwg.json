{"id": "gwavfvxSwg", "number": 13471, "cdate": 1758218302700, "mdate": 1759897435072, "content": {"title": "Can Large Language Models Assess and Reframe Psychological Attribution: A Benchmark and Analysis", "abstract": "According to the reformulated version of the Learned Helplessness theory, an individual who experiences uncontrollable negative events may subsequently develop a negative attributional style, thereby exhibiting greater susceptibility to depressive symptoms. This depressogenic attributional style not only contributes to depressive symptoms but also represents a malleable target for cognitive therapy. \nDespite its theoretical and practical significance, computational research on attributional cognition remains underexplored due to the lack of large-scale, high-quality datasets and robust evaluation protocols. In this work, we introduce the Attributional Style Transfer Dataset (ASTD) along with dedicated evaluation metrics, the first benchmark designed to model, assess, and reframe attributional explanations at scale. \nConstructed via a Prevent–Filter–Validate pipeline that integrates LLM-based generation with specialist validation, ASTD contains 42,000 real-world events paired with psychologically grounded attributions spanning seven styles. Using this dataset, we address two key challenges: (1) scalable assessment of attributional style via both supervised classifiers and zero/few-shot LLMs; and (2)attributional reframing and evaluation, where we propose automatic evaluation metrics to quantify psychological validity. Furthermore, we leverage our proposed metrics to construct a preference dataset, fine-tuning LLMs with Direct Preference Optimization (DPO) and achieving substantial gains in reframing quality. Together, our dataset, metrics, and methodology offer a new paradigm for understanding and modeling attributional style, with direct implications for scalable and adaptive mental health interventions.", "tldr": "This paper introduces the Attributional Style Transfer Dataset (ASTD) and evaluation framework to assess and reframe psychological attributional styles using large language models for scalable mental health interventions.", "keywords": ["Attributional reframing; Attributional Style; ASTD Benchmark"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0b733da240aebcb639a2050dc6adf87f5fae78f5.pdf", "supplementary_material": "/attachment/3948d148cca94e3449f8926f52aae05a3d94b2b5.zip"}, "replies": [{"content": {"summary": {"value": "The paper makes a valuable contribution to the growing field of AI-assisted mental health by addressing the challenging and socially important topic of depressive symptoms. Building on the well-established foundation of cognitive therapy, the authors introduce the Attributional Style Transfer Dataset (ASTD) as a novel resource designed to transform negative attributional explanations into positive ones. This dataset provides a meaningful benchmark for evaluating the capabilities of large language models (LLMs) in generating supportive and cognitively reframed text. Overall, the paper contributes both a new dataset and an insightful application domain that could advance AI-driven approaches to mental health support."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "-\tThe ASTD dataset development is systematic and transparent, with well-defined stages for data collection, annotation, and validation.\n-\tThe language is clear and professional, with a solid structure and strong organization.\n-\tThe literature review is comprehensive and positions the work well within both cognitive therapy and AI-assisted mental health research.\n-\tThe benchmarking of multiple LLMs provides useful insights and a foundation for future research."}, "weaknesses": {"value": "-\tThe attributional explanations were generated by a Llama model trained on datasets of uneven quality. Given the clinical sensitivity of depressive symptoms, dataset creation should involve domain experts (e.g., cognitive therapists) rather than relying mainly on LLM outputs.\n-\tThe paper does not clearly describe how attributional dimensions (locus, stability, generality, and shift) are represented or incorporated into model fine-tuning.\n-\tWhile the domain contribution is strong, the paper offers limited methodological novelty in machine learning; it is more a dataset and domain-focused study than an ML innovation.\n-\tOver-reliance on LLMs for both data generation and benchmarking raises concerns about circular validation and data authenticity.\n-\tThe evaluation lacks detail: information about the three expert raters and their qualifications is missing; 500 samples may be insufficient for robust validation.\n-\tThe argumentation sometimes feels underdeveloped — particularly regarding how reframing quality is assessed and how results generalize to real-world therapeutic contexts."}, "questions": {"value": "-\tGive more information about reframing and how this is fine-tuned into LLMs?"}, "flag_for_ethics_review": {"value": ["Yes, Potentially harmful insights, methodologies and applications", "Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "details_of_ethics_concerns": {"value": "authors only that human experts are used for data evaluation. This does not seem to be enough for a sensitive topic such as depression."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Xx0Gu5MePG", "forum": "gwavfvxSwg", "replyto": "gwavfvxSwg", "signatures": ["ICLR.cc/2026/Conference/Submission13471/Reviewer_Njcu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13471/Reviewer_Njcu"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13471/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761737153359, "cdate": 1761737153359, "tmdate": 1762924088117, "mdate": 1762924088117, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ASTD (Attributional Style Transfer Dataset), a 42,000-sample benchmark for assessing and reframing attributional styles based on the reformulated learned helplessness theory. The work addresses two key research questions: (1) efficient assessment of attributional style, and (2) automated generation and evaluation of attributional reframing. The authors employ a Prevent-Filter-Validate (PFV) pipeline combining LLM generation with expert validation to create the dataset. They benchmark both supervised classifiers and LLMs for attributional style classification, propose four automatic evaluation metrics for reframing quality, and use Direct Preference Optimization (DPO) to improve LLM performance. Results show supervised models achieve the highest classification accuracy (~97%), while DPO fine-tuning yields substantial improvements in reframing quality across four dimensions: attributional shift, catastrophizing reduction, coherence, and constructive coping."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "(a) This is the first large-scale dataset specifically targeting attributional style assessment and reframing based on the reformulated learned helplessness theory. \n\n(b) The PFV pipeline is well-designed, combining retrieval-grounded generation (reducing hallucination), heterogeneous LLM-based filtering, and expert validation (30% of uncertain cases reviewed by three trained raters with 94.3% LLM-human agreement, κ=0.91).\n\n(c) The use of DPO with LLM-generated preference labels (derived from the proposed metrics) to improve reframing quality is practically valuable."}, "weaknesses": {"value": "(a) The dataset is constructed from English-language sources and validated by raters in a specific cultural context, but attributional styles can vary significantly across cultures. The paper does not discuss potential cultural biases in the source data or how attributional patterns might differ in non-Western contexts. Given that LLMs risk generating inaccurate, biased, stigmatizing, and harmful information about mental health when trained on unrestricted text more explicit discussion of cultural limitations and validation plans for diverse populations would strengthen the work.\n\n(b) While the paper compares supervised models and LLMs, it lacks comparisons with recent cognitive reframing approaches. Notable omissions include comparisons with structured prompting techniques like \"Diagnosis of Thought\" (DoT) that guide models to separate facts from subjective interpretations and therapeutic frameworks like RESORT or HealMe (https://aclanthology.org/2024.acl-long.93.pdf) that integrate CBT techniques into prompt structures. Additionally, the paper would benefit from ablation studies examining: (a) the contribution of each PFV component, (b) the impact of different weighting schemes in the composite evaluation metric (Equation 2), and (c) sensitivity to the confidence margin threshold (0.2) used for expert validation."}, "questions": {"value": "(a) Given that mental health LLMs carry risks of generating inaccurate or harmful information despite fine-tuning strategies, what specific safety mechanisms have you considered for clinical deployment? How would your system handle cases where attributional reframing might be contraindicated (e.g., situations involving genuine external threats where internal attribution could be harmful)? Have you consulted with clinical psychologists about potential misuse scenarios or unintended consequences?\n\n(b) Recent work has explored reasoning-augmented approaches for cognitive restructuring, finding that models explicitly augmented with reasoning strategies provide strong performance gains. How does your DPO-based approach compare with these reasoning-enhanced methods? Additionally, CBT-Bench evaluates LLMs on cognitive model construction for patients. Could your attributional style assessment component be integrated with or compared against such cognitive modeling approaches?\n\n(c) Your PFV pipeline uses Llama 3.3-70B for generation and GPT-4o + Llama 3.3-70B for validation. Could you discuss potential biases inherited from these models and how they might affect the dataset's representativeness? Have you analyzed whether certain demographic groups, life situations, or event types are over/under-represented? Given that cognitive distortion datasets often vary in annotation quality and domain specificity, what steps ensure ASTD maintains consistent quality across its 42,000 samples and diverse event categories?\n\n(d) Your evaluation focuses on immediate reframing quality, but therapeutic effectiveness requires sustained behavior change. Have you considered or planned studies examining whether LLM-generated reframes lead to internalization of adaptive attributional styles over time? How might your system integrate with existing self-guided mental health interventions or stepped-care models that use multiple intervention intensity levels?"}, "flag_for_ethics_review": {"value": ["Yes, Discrimination / bias / fairness concerns", "Yes, Privacy, security and safety", "Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "details_of_ethics_concerns": {"value": "Since the paper concerns using AI for cognitive reframing based on users' attributional styles, the data used or created in the study needs to be examined for ethical and legal compliance."}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YZmWnu6YVL", "forum": "gwavfvxSwg", "replyto": "gwavfvxSwg", "signatures": ["ICLR.cc/2026/Conference/Submission13471/Reviewer_h5Up"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13471/Reviewer_h5Up"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13471/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761887313260, "cdate": 1761887313260, "tmdate": 1762924087113, "mdate": 1762924087113, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the author proposed a psychological benchmark dataset and also a pipeline for scalable data generation."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The author presents what is claimed to be the first large-scale benchmark dataset for attributional explanation, which represents a valuable contribution to the field.\n\n2. The paper is well-written and organized."}, "weaknesses": {"value": "1. From the LLM perspective, the novelty of this work appears limited. The dataset generation process relies more on engineering efforts rather than introducing conceptual or methodological innovations in generation or hallucination mitigation. Overall, the paper feels more like an application of existing techniques to the field of psychology rather than a fundamentally new contribution.\n\n\n2. In addition, the author mentions that attributional reframing is applied in a language-guided therapeutic context. This use case demands greater caution regarding the quality and reliability of both the model and the dataset, particularly when dealing with out-of-distribution (OOD) data."}, "questions": {"value": "1. One aspect that confuses me is the scalability of the dataset validation process. As this is a psychological dataset, data quality is of critical importance. In the proposed pipeline, involving real human experts for validation seems essential, but how can this be achieved at scale while maintaining reliability and consistency? Or is this pipeline not designed for scalable data generation purpose?\n\n2. The author mentions the design of reframing metrics. Could you clarify how these proposed metrics differ from existing ones and what specific advantages they offer?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "6bkdocm1Pg", "forum": "gwavfvxSwg", "replyto": "gwavfvxSwg", "signatures": ["ICLR.cc/2026/Conference/Submission13471/Reviewer_AQ8U"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13471/Reviewer_AQ8U"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13471/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761963506952, "cdate": 1761963506952, "tmdate": 1762924086710, "mdate": 1762924086710, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes the Attributional Style Transfer Dataset (ASTD) and a set of related evaluation metrics.   ASTD stems from a combination of LLM generations and expert validation, encompassing a wide range of events annotated with psychologically grounded attributions,  Authors also builds a preference dataset for finetuning via  Direct Preference Optimization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The contributions are clearly articulated and the designed pipelines are supported by clear and informative visuals. \nThe social relevance and potential impact of the work make it both valuable and timely. Moreover, the interdisciplinary nature of the study allows it to engage multiple research communities, broadening its relevance and potential influence.\nThe experimental design is extensive, and the implementation choices are well-motivated and justified, contributing to the overall robustness of the work."}, "weaknesses": {"value": "The generalizability of the proposed approach remains somewhat unclear. It would strengthen the paper to include a discussion of how the methods and findings might extend to other tasks or domains.\nThe paper would benefit from the inclusion of data examples to help readers better understand the nature and diversity of the dataset.\nThe Ethics Statement could be expanded to include a more nuanced discussion of potential limitations and risks. In particular, consider addressing how the proposed resources might be misused or applied in unintended ways, e.g., by clarifying the intended use cases.\nIncluding a paragraph on future work would help outline possible extensions and highlight open research directions stemming from this study."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "lLpZij7OQR", "forum": "gwavfvxSwg", "replyto": "gwavfvxSwg", "signatures": ["ICLR.cc/2026/Conference/Submission13471/Reviewer_ctxW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13471/Reviewer_ctxW"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13471/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762164731692, "cdate": 1762164731692, "tmdate": 1762924086392, "mdate": 1762924086392, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}