{"id": "oljjAkgZN4", "number": 18478, "cdate": 1758288124672, "mdate": 1759897101079, "content": {"title": "MIAM: Modality Imbalance-Aware Masking for Multimodal Ecological Applications", "abstract": "Multimodal learning is crucial for ecological applications, which rely on heterogeneous data sources (e.g., satellite imagery, environmental time series, tabular predictors, bioacoustics) but often suffer from incomplete data across and within modalities (e.g., missing records in a time series, unavailable satellite image due to cloud cover). While data masking strategies have been used to improve robustness to missing data by exposing models to varying input subsets during training, existing approaches typically rely on static masking and inadequately explore the space of input combinations. As a result, they fail to address modality imbalance, a critical challenge in multimodal learning where dominant modalities hinder the optimization of others. To fill this gap, we introduce Modality Imbalance-Aware Masking (MIAM), a dynamic masking strategy that: (i) explores the full space of input combinations; (ii) prioritizes informative or challenging subsets; and (iii) adaptively increases the masking probability of dominant modalities based on their relative performance and learning dynamics. We evaluate MIAM on two key ecological datasets, GeoPlant and TaxaBench, with diverse modality configurations, and show that MIAM significantly improves robustness and predictive performance over previous masking strategies. In addition, MIAM supports fine-grained contribution analysis across and within modalities, revealing which variables, time segments, or image regions most strongly drive performance.", "tldr": "MIAM: a masking strategy to address modality imbalance in the context of multimodal ecological applications", "keywords": ["multimodality", "masking", "modality imbalance", "ecology"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/17d8a9e9cd6d5f60f99239414885ee03de0a7a83.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces a masking strategy called MIAM. The objective is to improve the robustness of transformers to missing modalities at test time. The topic is important because there is a trend towards fusing more and more modalities, while it is crucial to maintain performance on any subset of modalities seen during training for practical utility. MIAM increases the probability of a modality being masked (not given as input) if its unimodal validation performance is high and not changing; conversely, modalities with low and increasing accuracy are masked less often (given as input). MIAM improves over other masking strategies for two multi-modal datasets."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "- Multi-modal masked modelling is increasingly used, so the topic is important\n- I learned from the paper and it may inform my research\n- The idea of MIAM is intuitive, fairly simple, and seems to work — at least when the number of modalities > 2\n- The paper is well written and has nice figures that aid understanding"}, "weaknesses": {"value": "Moderate weakness:\n- I believe that according to the appendix, all transformers have 3 layers and embedding dimension 192, which is very very small. For reference, a ViT-Base has 12 layers and dimension 768. I understand that larger models are costlier but I suspect model size will interact with masking strategies. For example, larger models may be able to fit all modalities easier, and thus uniform masking may be fine. \n\nMinor weakness:\n- The method seems to rely on computing validation accuracy after each epoch. Thus it cannot be directly used in self-supervised learning, e.g., masked autoencoding (MAE), since we aim to learn task-agnostic representations without using labelled data. Since multi-modal MAE is quite popular, having MIAM directly support MAE would be nice."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JBVz2ry2by", "forum": "oljjAkgZN4", "replyto": "oljjAkgZN4", "signatures": ["ICLR.cc/2026/Conference/Submission18478/Reviewer_Hfi3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18478/Reviewer_Hfi3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18478/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761504074930, "cdate": 1761504074930, "tmdate": 1762928167618, "mdate": 1762928167618, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces MIAM (Modality Imbalance-Aware Masking), a dynamic masking strategy for multimodal learning. MIAM formalizes masking as probability distributions over unit hypercubes and addresses three key principles often missing in prior methods: Full support for all input combinations, Corner prioritization to emphasize critical configurations, and Imbalance awareness by adapting masking probabilities based on modality dominance. To achieve this, MIAM constructs a mixture of product beta distributions and dynamically adjusts masking during training using modality-specific performance and learning speed. This design enables handling arbitrary missing inputs, mitigating modality imbalance, and supporting fine-grained contribution analysis across and within modalities."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "-\tInteresting approach to improve performance and robustness when modalities are missing. \n-\tStrong average performance across different subsets of modalities compared to other sampling strategies. \n-\tMethodology is clearly described and well-structured. \n-\tProvides insightful analysis of how modality-specific values evolve during training."}, "weaknesses": {"value": "-\tOnly tested on two classification downstream tasks. Broader applicability (e.g., segmentation tasks like flood mapping where optical data is often missing) is not demonstrated. Also includes frequent references to pre-training masking strategies in related work, while not compared for pre-training.\n-\tDownstream performance is sensitive to new hyperparameters. With ablation shown only on one dataset (Figure 10), it is difficult for readers to tune parameters effectively. \n-\tEvaluated with only one architecture, which is not well explained, even though MIAM is likely applicable to many others. \n-\tTraining details and architecture description are insufficient. Before presenting results, it should be made explicit that one model per masking strategy was trained and then evaluated on different subsets."}, "questions": {"value": "-\tCould MIAM be adapted for other model architectures? If so, what could be challenges? \n-\tHow should practitioners choose λ and κ in practice for new datasets without extensive tuning?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CmyOfPw3tI", "forum": "oljjAkgZN4", "replyto": "oljjAkgZN4", "signatures": ["ICLR.cc/2026/Conference/Submission18478/Reviewer_CJxa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18478/Reviewer_CJxa"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18478/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761679090581, "cdate": 1761679090581, "tmdate": 1762928167236, "mdate": 1762928167236, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MIAM (Modality Imbalance-Aware Masking), a dynamic masking strategy for multimodal learning that addresses the challenge of modality imbalance in ecological applications. The key insight is to formalize masking strategies as probability distributions over unit hypercubes and design a principled approach with three properties: (i) full support over all input combinations, (ii) corner prioritization to favor complete/minimal modality combinations, and (iii) imbalance-awareness that adaptively masks dominant modalities based on their performance and learning dynamics. MIAM uses a mixture of product beta distributions whose parameters are dynamically adjusted during training based on per-modality performance scores and their temporal derivatives. The method is evaluated on two ecological benchmarks (GeoPlant and TaxaBench) and demonstrates consistent improvements over existing masking strategies while providing fine-grained contribution analysis."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Testing on two diverse ecological datasets (GeoPlant with 3 modalities, TaxaBench with 5 modalities) with multiple modality combinations demonstrates robustness.\n2. The fine-grained contribution analysis (Fig. 5) demonstrates how the method can provide ecological insights (e.g., importance of NDVI bands, impact of extreme events), bridging ML and domain science.\n3. The progressive ablation showing the contribution of each design principle (uniform hypercube → beta hypercube → MIAM) is convincing."}, "weaknesses": {"value": "1. Only ecological datasets are thoroughly evaluated; broader applicability claims need support from other domains. The SatBird result (Appendix A.4.3) showing similar performance across strategies raises questions about when MIAM is beneficial. No comparison on standard multimodal benchmarks (e.g., vision-language tasks)\n2. The choice of ε=3 and φ=10 appears arbitrary. THere is limited discussion of how to set these in practice. The corner weights (Eq. 3) use specific fractions (1/4, 1/2) without justification\n3. OPM (Wei et al. 2024) is the main dynamic masking baseline, but other recent modality balancing methods are mentioned but not compared. Missing comparison with recent self-supervised multimodal methods."}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "H6AX1ok2u0", "forum": "oljjAkgZN4", "replyto": "oljjAkgZN4", "signatures": ["ICLR.cc/2026/Conference/Submission18478/Reviewer_5e4q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18478/Reviewer_5e4q"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18478/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762078822682, "cdate": 1762078822682, "tmdate": 1762928166847, "mdate": 1762928166847, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new masking algorithm that addresses the problem of modality competition, wherein one modality dominates the learned features. The algorithm uses a mixture of product beta distributions that concentrations probability mass in the corners (especially the all-on or all-off corners) of a unit hypercube representing the probability that tokens within each modality are masked. The weights are adjusted dynamically to adjust the masking probability depending on the performance and learning speed of each modality. Experiments are performed on two multimodal ecology datasets, GeoPlant and TaxaBench, using a transformer architecture. MIAM overall improves performance on these benchmarks compared to baselines including On-the-fly Prediction Modulation (OPM), which adjusts per-modality probabilities based on relative performance scores but applies the probability to the entire modality, not each token within each modality as in MIAM. The paper also shows how MIAM indicates which inputs drive performance, providing a measure of the contribution/importance of each modality."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "- This paper addresses an understudied problem in multimodal learning of modality imbalance/competition. Despite being understudied, it is a common challenge in multimodal learning for remote sensing (and other domains).\n- The paper is well written and easy to read. Technical details are clearly explained. Figures and tables are high quality and are helpful for understanding the paper’s results and ideas.\n- The contribution analysis enabled by MIAM is a nice bonus and would be appreciated by domain experts in ecology and other domains (e.g. across remote sensing applications).\n- The ablation experiment is well designed and effectively shows the contribution of each component of the proposed algorithm.\n- The proposed algorithm is well-motivated, and the paper gives nice explanations and figures to support the motivation and intuition behind the algorithm’s design."}, "weaknesses": {"value": "- The MIAM masking algorithm could be applied to any model architecture that implements masked multimodal learning. I think there was a missed opportunity to show the value of MIAM on existing multimodal remote sensing foundation models. If it worked, MIAM could significantly improve the utility of these models. (To me, this is the difference between a score of 8 and 10.)\n- It seems that a natural extension (or even baseline?) of MIAM is to assign a masking probability to each token, rather than applying the same probability to all tokens within each modality. Did the authors consider or test this?\n- I think the motivation for prioritizing the all-on/all-off corners (or corners in general) could be better explained in terms of the ecological application context. It doesn’t seem obvious to me why it would be beneficial to prioritize combinations with almost all tokens or almost no tokens from each modality."}, "questions": {"value": "- Why is it beneficial to prioritize combinations with almost all tokens or almost no tokens from each modality?\n- How does MIAM affect the performance of multimodal remote sensing foundation models?\n- How does applying the same probability to all tokens in a modality compare to applying a different probability to each token regardless of modality?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "mFFHs3sb6e", "forum": "oljjAkgZN4", "replyto": "oljjAkgZN4", "signatures": ["ICLR.cc/2026/Conference/Submission18478/Reviewer_Cimh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18478/Reviewer_Cimh"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18478/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762135455973, "cdate": 1762135455973, "tmdate": 1762928166419, "mdate": 1762928166419, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}