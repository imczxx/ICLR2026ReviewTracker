{"id": "BGT5csoTtw", "number": 12863, "cdate": 1758211023865, "mdate": 1759897480828, "content": {"title": "Domain-Specific Text-to-Image Generation: Planning, Merging, and Replacing with Training-free LLMs", "abstract": "Diffusion-based techniques, such as Stable Diffusion, exhibit remarkable capabilities in text-to-image synthesis and editing. However, general text-to-image diffusion methods frequently fail to accurately generate domain-specific components, such as particular electrical elements in schematic circuit diagram. Lacking domain-specific knowledge, rules, and sufficient data,  existing methods may struggle with resource-consumption model training. To address these limitations, we propose a novel, training-free framework for mastering domain-specific text-to-image generation, namely Planning, Merging, and Replacing (PMR).  Specifically, PMR precisely generates domain-specific elements and their configurations, enabling schematic circuit diagram generation without requiring model fine-tuning. \nBased on the establishment of a knowledge base, PMR employs large language models (LLMs) to plan inter-component connectivity according to the requirements provided by users. \nPMR further utilizes LLMs to spatially arrange symbolic blocks (representing components) and their connecting wires. Subsequently, PMR has a fine-grained positional control and generates symbolic blocks and wires at designated locations.  Extensive experiments demonstrate that PMR outperforms existing methods in domain-specific generation.\nOur work opens a potentially new avenue of automated domain-specific text-to-image generation.", "tldr": "", "keywords": ["Diffusion Models", "Domain-Specific Generation", "Circuit Diagram Synthesis", "Large Language Models (LLMs)"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ad3c72fe398562112f16e913ae464f3be13c2b1e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper tackles the failure of text-to-image models in generating circuit diagrams. It proposes PMR, a novel training-free framework. PMR uses LLMs to plan component connectivity and layout, then guides a diffusion model for fine-grained, spatially-controlled generation, avoiding the need for resource-intensive fine-tuning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Targeting electrical circuit generation, the authors' proposed method of Planning, Merging, and Replacing advances beyond several existing T2I baselines."}, "weaknesses": {"value": "1.  The title of the paper claims the contribution is \"Domain-Specific\", yet the methodology and experiments focus exclusively on a single domain (e.g., electrical circuit generation). This is confusing and potentially misleading. If the method's generality has not been substantiated, the title and claims should be narrowed to specifically reflect its application to electrical circuit generation.\n\n2.  Section 3.4 is confusing to me; can you explain the complete denoising process? Please also clarify the role of the softmax operation and the meaning of the function \\(\\phi\\) in Equations 9 and 10. Furthermore, have you compared your method with layout-to-image diffusion models (e.g., LayoutDiffusion [1], LayoutDM [2])? Such a comparison would help strengthen the persuasiveness of your work.\n\n3.  It seems the experimental dataset used for evaluation is not clearly specified. Please clarify whether a publicly available benchmark or a private dataset was used.\n\n**References**\n\n[1] Zheng, G., et al.: LayoutDiffusion: Controllable diffusion model for layout-to-image generation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2023)\n\n[2] Inoue, N., et al.: LayoutDM: Discrete diffusion model for controllable layout generation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2023)"}, "questions": {"value": "Please see Weaknesses section"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nSpOUZ9xs1", "forum": "BGT5csoTtw", "replyto": "BGT5csoTtw", "signatures": ["ICLR.cc/2026/Conference/Submission12863/Reviewer_xMiG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12863/Reviewer_xMiG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12863/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760781664385, "cdate": 1760781664385, "tmdate": 1762923654223, "mdate": 1762923654223, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the problem of text-based circuit diagram generation.\n\nThe main contribution is to propose a training-free solution to the problem, which utilizes domain-specific knowledge derived from historical circuit diagram examples and the reasoning abilities of pretrained large language models (LLM) to guide the image generation of pretrained diffusion models."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Domain-specific text-to-image generation is an important problem to study.\n\n2. The proposed merge regional diffusion is shown to be effective."}, "weaknesses": {"value": "1. The paper is claimed to focus on domain-specific text-to-image generation, as indicated by many places in the paper, such as the title, the last sentence of the abstract, the second last sentence of the second paragraph in the introduction. However, the components of the proposed method are highly specialized for circuit diagram design. It is not clear how the method can be adapted to solve text-to-image generation in other domains. To provide strong evidence for the paper’s claim, it would be necessary to provide several examples of how the proposed method can be applied to other domains. \n\n2. The effectiveness of the proposed method is not adequately validated. In particular, the evaluation of the full generation method (introduced in Section 3) is missing in the experiments, and only a single component (i.e., the merge regional diffusion) is tested."}, "questions": {"value": "1. How are the contextual examples used in the second step (Section 3.3) created?\n\n2. How many input text prompts are used in the experiments (Section 4)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0dsO6eRRI1", "forum": "BGT5csoTtw", "replyto": "BGT5csoTtw", "signatures": ["ICLR.cc/2026/Conference/Submission12863/Reviewer_3dLJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12863/Reviewer_3dLJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12863/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761671321949, "cdate": 1761671321949, "tmdate": 1762923653883, "mdate": 1762923653883, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes PMR (Planning, Merging, Replacing), a training-free framework for domain-specific text-to-image generation, exemplified by circuit diagrams. It builds a knowledge base and uses LLMs to plan connectivity, arrange component layouts, and enforce fine-grained positional control, enabling accurate rendering without finetuning. Experiments report superior component and topology fidelity vs. baselines with lower training cost."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The work effectively leverages chain-of-thought (CoT) ideas to operationalize LLMs for domain-specific generation of circuit diagrams. Compared with large models without domain-specific finetuning, the proposed approach shows clear advantages in this task. The paper is well written and technically complete, with clear organization and presentation."}, "weaknesses": {"value": "The paper does not clearly define domain-specific text-to-image generation. Although the framework is described as training-free with respect to LLMs, the training workload is shifted to an object recognition module, which diminishes the core contribution. Moreover, the work lacks comparisons with this year’s state-of-the-art methods, making the claimed effectiveness insufficiently substantiated."}, "questions": {"value": "1.\tIn Related Work, the subsection “Specialized Diffusion Models” should cover Domain-Specific Diffusion Models; currently it does not. The comparisons also lack domain-specific diffusion baselines.\n2.\tThe paper lacks experiments validating the method’s effectiveness on other domains.\n3.\tCaptions for Figs. 2, 3, and 6 should briefly explain the method, rather than only providing a title.\n4.\tThe paper lacks ablation experiments."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ayxZRTk2pn", "forum": "BGT5csoTtw", "replyto": "BGT5csoTtw", "signatures": ["ICLR.cc/2026/Conference/Submission12863/Reviewer_E6Ns"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12863/Reviewer_E6Ns"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12863/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761909206271, "cdate": 1761909206271, "tmdate": 1762923653662, "mdate": 1762923653662, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work introduces a method to solve the detailed schematic circuit diagram generation by leveraging the LLM for planning and Diffusion model for the diagram generation. Specifically, this work’s pipeline is constructed with three stages: Planning, Merging, and Replacing.\n\nIn the Planning stage, this work first plans the component relationship through the CoT process of LLM with knowledge base of schematic circuit diagram preprocessed from diagram images. Then it leverages LLM to plan the regions (positions and sizes) and lines. This pipeline then merges and replaces the latents of each planned region to form the final generation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. It successfully uses PMR (Planning, Merging, and Replacing) to achieve training-free generation of schematic circuit diagrams.\n 2. It successfully utilizes pretrained models for practical applications.\n 3. It proposed a stable and reliable method to generate circuit diagrams."}, "weaknesses": {"value": "1. This paper should either consider using this pipeline as a syntactical data pipeline and fine-tuned (lora) the Flow Matching model (Flux) with syntactical data for an end-to-end model or test this method for more other domains than the circuit schematic as stated in the title.\n2. It does not have qualitative results shown, for example, some sample generated circuit diagram, although it has some generated black blocks.\n3. The method this work uses highly correlated to the major backbone of this paper (Yang et al.)\n\n[1] Ling Yang, Zhaochen Yu, Chenlin Meng, Minkai Xu, Stefano Ermon, and Bin Cui. Mastering textto-image diffusion: Recaptioning, planning, and generating with multimodal llms. In Forty-first International Conference on Machine Learning, 2024."}, "questions": {"value": "1. Could the authors please show the actual generated circuit figure instead of just black boxes?\n2. It is highly recommended that the authors do more types of domain specific text-to-image generation other than circuit one?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "NhnxU4uqLp", "forum": "BGT5csoTtw", "replyto": "BGT5csoTtw", "signatures": ["ICLR.cc/2026/Conference/Submission12863/Reviewer_Yc5Y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12863/Reviewer_Yc5Y"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12863/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977254717, "cdate": 1761977254717, "tmdate": 1762923653315, "mdate": 1762923653315, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}