{"id": "RInCbleaY3", "number": 24390, "cdate": 1758356382419, "mdate": 1759896768591, "content": {"title": "Cortical-SSM: A Deep State Space Model for EEG and ECoG Motor Imagery Decoding", "abstract": "Classification of  electroencephalogram (EEG) and electrocorticogram (ECoG) signals obtained during motor-imagery (MI) has substantial application potential, including for communication assistance and rehabilitation support for patients with motor impairments. These signals remain inherently susceptible to physiological artifacts (e.g., eye blinking, swallowing), which pose persistent challenges. Although Transformer-based approaches for classifying EEG and ECoG signals have been widely adopted, they often struggle to capture fine-grained dependencies within them. To overcome these limitations, we propose Cortical-SSM, a novel architecture that extends deep state space models to capture integrated dependencies of EEG and ECoG signals across temporal, spatial, and frequency domains. We validated our method across three benchmarks: 1) two large-scale public MI EEG datasets containing more than 50 subjects, 2) and a clinical MI ECoG dataset recorded from a patient with amyotrophic lateral sclerosis. Our method outperformed baseline methods on the three benchmarks. Furthermore, visual explanations derived from our model indicate that it effectively captures neurophysiologically relevant regions of both EEG and ECoG signals. Our project page is available at https://cortical-ssm-u90sg.kinsta.page/", "tldr": "We propose Cortical-SSM, a novel architecture that extends deep state space models to capture integrated dependencies of EEG and ECoG signals across temporal, spatial, and frequency domains.", "keywords": ["Brain Computer Interface (BCI)", "Electroencephalography (EEG)", "Electrocorticography (ECoG)", "Motor Imagery", "Deep State Space Model"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f088211be9c2e1493d2962f8148b1c72e64e4096.pdf", "supplementary_material": "/attachment/22a06efdad997a58fef0d986153773a15cf83b63.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose Cortical-SSM, extending deep state space models to capture integrated dependencies of EEG and ECoG signals across temporal, spatial, and frequency domains. The manuscript is well-written and presents extensive content. However, the concern is the relatively limited technical contribution of the work."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "[1] Apply deep state space models to EEG MI\\\n[2] Two tasks: EEG MI and ECoG MI"}, "weaknesses": {"value": "[1] Wavelet-Convolution – The wavelet transformation with convolution/CNN has been applied in the current literature, such as:\\\nHou et al., A novel approach of decoding EEG four-class motor imagery tasks via scout ESI and CNN, In Journal of Neural Engineering.\\\nThe authors are encouraged to compare the performance under different convolution settings, e.g., pure convolution, convolution in the frequency domain, etc.\\\n[2] Equation (1) – For convolution, batch normalization is usually used, instead of layer normalization. Why did the authors apply a layer normalization after the wavelet transform?\\\n[3] Experimental datasets – The authors are encouraged to employ the largest benchmark in the EEG MI field: \\\nEEG Motor Movement/Imagery Dataset\\\nLink: https://archive.physionet.org/pn4/eegmmidb/ \\\nHigh Gamma Dataset\\\nLink: https://github.com/robintibor/high-gamma-dataset"}, "questions": {"value": "[1] How was the visual explanation in Figure 3 related to the human neuron activations with the EEG signals?\\\n[2] How was the performance of Wavelet-Convolution, compared with the convolution (the second term in Equation (1))? And why didn’t the authors conduct convolution after the Wavelet transform?\\\n[3] What are the specific technical contributions on the SSM, e.g., any architecture innovations or new algorithm design? Or, did the authors just simply apply the SSM to EEG MI?\\\n[4] Where and what is the interpretation of the interpretability/visual maps?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CULe0pKfnQ", "forum": "RInCbleaY3", "replyto": "RInCbleaY3", "signatures": ["ICLR.cc/2026/Conference/Submission24390/Reviewer_DVQH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24390/Reviewer_DVQH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24390/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761417467078, "cdate": 1761417467078, "tmdate": 1762943069777, "mdate": 1762943069777, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Cortical-SSM, a state-space model for EEG and ECoG motor-imagery decoding. It combines a wavelet-based spectral extraction module with dual SSMs (frequency- and channel-wise) to model temporal, spatial, and spectral dependencies, and reports improved performance on three datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The integration of a wavelet–convolution frequency module with state-space models applied along the frequency and channel domains offers a unified treatment of temporal, spatial, and spectral dependencies in EEG/ECoG, representing a transfer of recent SSM advances to neural signal modeling. Empirically, the paper reports consistent improvements across both EEG and ECoG benchmarks.  \nThis cross-domain application is interesting and demonstrates that SSMs can be effective for modeling long-term temporal dependencies in neural signals."}, "weaknesses": {"value": "The approach largely follows the conventional EEG pipeline (temporal–spatial–spectral features) and appears to recombine existing components; the core modules (CWT, SSM) are adopted without modification or a clear theoretical contribution. \n \nThe interpretability claim rests on a straightforward use of Grad-CAM, which by itself may not constitute a methodological advance. \n\nThe Wavelet-Convolution combines handcrafted and learnable filters with a simple weighted-sum fusion, but this conventional design is not well justified nor clearly shown to improve spectral representation or interpretability. \n\nFor ECoG, the evidence is limited to a single-subject ALS dataset, which constrains the strength and generalizability of the conclusions. \n \nThe comparative evaluation would benefit from broader baselines, including recent general time-series models and state-of-the-art EEG/ECoG approaches [1-3]. \n \n[1] Rusch, T. Konstantin, and Daniela Rus. \"Oscillatory State-Space Models.\" In Proceedings of the Thirteenth International Conference on Learning Representations (ICLR), 2025. \n[2] Wang, Jiquan, Sha Zhao, Zhiling Luo, Yangxuan Zhou, Haiteng Jiang, Shijian Li, Tao Li, and Gang Pan. “CBraMod: A Criss-Cross Brain Foundation Model for EEG Decoding.” In Proceedings of the Thirteenth International Conference on Learning Representations (ICLR), 2025. \n[3] Chen, Xupeng, et al. \"A neural speech decoding framework leveraging deep learning and speech synthesis.\" Nature Machine Intelligence 6.4 (2024): 467-480. \n \nThe manuscript asserts lower computational cost and improved preservation of fine-grained temporal dependencies. However, the manuscript includes no relevant comparisons or analyses to substantiate these claims."}, "questions": {"value": "Do Figures 3–4 present only averaged success cases, and if so, how do the authors address possible selection bias? Have they examined failure cases or conducted quantitative evaluation? \n \nCould the authors clarify why frequency extraction relies solely on the Morlet wavelet, and whether they considered comparisons with other wavelets (e.g., Gabor [1], Morse [2]) or with learnable filters (e.g., SincNet [3])? Such comparisons would help determine whether the reported gains stem from the overall design or from the specific frequency filter used [1-3]. \n[1] Luan, Shangzhen, et al. \"Gabor convolutional networks.\" IEEE Transactions on Image Processing 27.9 (2018): 4357-4366. \n[2] Olhede, Sofia C., and Andrew T. Walden. \"Generalized morse wavelets.\" IEEE Transactions on Signal Processing 50.11 (2002): 2661-2670. \n[3] Ravanelli, Mirco, and Yoshua Bengio. \"Speaker recognition from raw waveform with sincnet.\" 2018 IEEE spoken language technology workshop (SLT). IEEE, 2018. \n\nThe introduction jumps directly from the limitations of Transformer-based approaches to your proposed SSM, without explaining why SSM is a natural or necessary alternative. Could you elaborate on the specific properties of SSMs (e.g., linear recurrence, stability, computational scaling) that make them particularly suitable for EEG/ECoG signals? \n\nStieger2021 dataset appears only in the Appendix, even though it could provide an important validation point. Is there a reason this dataset was not emphasized in the main text? \n\nFigure 2 is hard to interpret. Could you clarify the flow of information across modules and specify what input each SSM receives?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OPvKKMIOOx", "forum": "RInCbleaY3", "replyto": "RInCbleaY3", "signatures": ["ICLR.cc/2026/Conference/Submission24390/Reviewer_5YxK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24390/Reviewer_5YxK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24390/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962270385, "cdate": 1761962270385, "tmdate": 1762943068763, "mdate": 1762943068763, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Cortical-SSM model, which is a deep state-space architecture for motor-imagery (MI) decoding from EEG and ECoG. The model has three components: Wavelet-Convolution that fuses the deterministic continuous wavelet transform (CWT) features (E-branch) with learnable Conv1D features (A-branch), Frequency-SSM that models spatio-temporal dynamics per frequency band, and Channel-SSM that models temporal-frequency dynamics per electrode. Both SSM stacks build on S5 (time-invariant, MIMO). The method is evaluated on OpenBMI, Stieger2021, and a single-subject ECoG-ALS dataset with cross-subject or cross-session protocols. The authors report SOTA results on all three datasets with statistically significant gains via Wilcoxon tests, and provide Grad-CAM–style visualizations highlighting mu-band, C3/C4 in EEG, and the hand-knob area in ECoG."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe proposed Vortical model can capture dependencies of EEG and ECoG across temporal, spatial, and frequency modals.\n2.\tThis paper is presented with solid cross-dataset evidence. On OpenBMI, and on ECoG-ALS it reaches obviously better performance than previous baselines. Stieger2021 (LR/UD/2D) also shows consistent improvements. \n3.\tThe authors make ablation study, they test STFT vs CWT, and different temporal backbones, and use Wilcoxon with Shapiro–Wilk to justify non-parametric testing under session/subject shift. \n4.\tThe method can also capture the neurophysiological relevant regions of EEG and ECoG signals, providing better explanation ability than other methods."}, "weaknesses": {"value": "1. The novelty is incremental. The method primarily recombines known ingredients of S5-style SSMs for long sequences, wavelet features for EEG, and Grad-CAM for explanations, into a two-branch temporal pipeline. The core technical advance is largely architectural refactoring rather than a new modeling principle or learning objective.\n\n2. The ECoG generalization is unclear. ECoG evidence is based on a single ALS subject across eight sessions. Cross-session gains are strong but between-subject generalization and electrode-layout variability central for clinical translation are not evaluated. \n\n3. The task of classification of EEG and ECoG signals for motor imagery is an extensively researched one, why the authors did not consider to use the model for intermediate representation of EEG and ECoG, so that the learned representation can be used to more downstream tasks."}, "questions": {"value": "Please refer to the weaknesses part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "cloWOhHELQ", "forum": "RInCbleaY3", "replyto": "RInCbleaY3", "signatures": ["ICLR.cc/2026/Conference/Submission24390/Reviewer_WUtg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24390/Reviewer_WUtg"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24390/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990821137, "cdate": 1761990821137, "tmdate": 1762943067561, "mdate": 1762943067561, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed a method based on state-space models to capture EEG and ECoG features for motor imagery classification tasks. Representations were extracted from temporal, spatial, and frequency domains to achieve good classification performance and interpretability, while the Wavelet-convolution was emphasized for frequency features. Two datasets, containing non-invasive EEG and invasive ECoG, were used for comparison."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Introduce a new state-space model for EEG and ECoG feature extraction.\n2. Clear performance on different datasets and model ablation studies was reported to demonstrate the superior ability of the proposed model.\n3. The authors paid attention to brain feature analysis, which gave evidence of the usability of the Cortical-SSM model.\n4. The writing is easy to follow.\n5. The appendix gave many details which is useful to know the model and reproduction."}, "weaknesses": {"value": "1. The summary of the contributions claimed at the end of the introduction has not been well-proven. Although the work achieved good performance on various datasets, it's still not easy to figure out which part of the model really contributes to the final results, and what the improvement is compared to related works, such as DeepSSM mentioned in the paper.\n2. There have been some analyses to show the spatial and temporal patterns obtained by the classification models. However, up to the novelty mentioned in the introduction, the current visualization of one subject or one session (Fig. 3 and Fig. 4) is not enough to prove the claim. \n3. There are uncertain points of the pattern analysis: 1) the motor imagery of left and right in Fig. 3 showed similar patterns, but there should be some synchronization and desynchronization. 2) The frequency band of Column 3 in Fig. 4(a) spanned across all the frequency bands. Would that be some artifacts? 3) It is not clear what the content is shown in Fig. 4(b). Maybe further visualization of different subjects or the average one would show rich patterns.\n4. The modules of the model did not seem to have a significant improvement for EEG data in Tables 3 and 4. Why did they have a large impact on the ECoG data? Some explanation would be beneficial for understanding."}, "questions": {"value": "1. Have you evaluated the performance under domain shift conditions, such as cross-subject, cross-session?\n2. Would the parameters of the Cortical-SSM have an impact on the overall performance?\n3. Please see the Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "azmUrE46V2", "forum": "RInCbleaY3", "replyto": "RInCbleaY3", "signatures": ["ICLR.cc/2026/Conference/Submission24390/Reviewer_8g7z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24390/Reviewer_8g7z"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24390/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762174979626, "cdate": 1762174979626, "tmdate": 1762943067133, "mdate": 1762943067133, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}