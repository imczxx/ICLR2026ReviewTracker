{"id": "F5bDWU4M0J", "number": 5045, "cdate": 1757838632627, "mdate": 1759897998315, "content": {"title": "SpRePE: A Spherical Geometry-Aware Position Embedding for Vision Transformers", "abstract": "Position embedding (PE) is a key mechanism that breaks the permutation symmetry of tokens in Transformer, introducing a spatial inductive bias that enables attention to model locality, distances, and directional relations. \nSpherical data arise in many scientific domains, most notably in astronomy and meteorology, where Vision Transformers is increasingly adopted for the ability to capture long-range dependencies. However, conventional PEs are designed for linear sequences and cannot faithfully capture the sphere’s non-Euclidean geometry. \nFurthermore, existing designs for encoding spherical positional information rely on additional network modules or specialized network architectures, which introduce extra parameters and computational overhead.\nThese limitations motivate a geometry-aware and efficient embedding scheme that fully exploits spherical structure to advance Transformer-based modeling on the sphere.\nWe introduce \\textbf{Spherical Reflection Position Embedding (SpRePE)}, a lightweight method efficiently leveraging spherical positional information for Vision Transformer.\nSpRePE encodes the absolute position on the sphere using a Householder matrix and incorporates the explicit relative position dependency into the attention formulation, achieving both high computational efficiency and high accuracy without requiring substantial additional parameters and modifications to the overall model architecture.\nWe evaluate SpRePE on representative tasks, including spherical image classification and global weather forecasting. SpRePE consistently outperforms well-known baselines including APE, RPE, ALiBi and RoPE.\nThese results indicate that SpRePE offers an efficient and broadly applicable position embedding scheme for Transformer models on the sphere.", "tldr": "We propose SpRePE, a spherical position embedding scheme for Transformers. It encodes absolute positions on the sphere via a Householder matrix and incorporates an explicit spherical relative-position term into the attention formulation.", "keywords": ["Vision Transformer", "Position Embedding", "Geometry-Aware Modeling", "Spherical Data Processing"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3869ec2a70ab064cf9c61e20b3f98226a82db0d5.pdf", "supplementary_material": "/attachment/dc89f8eeef450d5a811cdc861691488b6b5eb0dd.pdf"}, "replies": [{"content": {"summary": {"value": "SpRePE introduces a spherical position embedding for Vision Transformers using Householder reflection matrices to encode positions on a sphere, applied directly to query/key vectors with RoPE-like computational efficiency. The method shows improvements over older standard position embeddings (APE, RPE, ALiBi, RoPE) on Spherical MNIST classification and ERA5 weather forecasting tasks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Principled geometric foundation, using Householder reflections to respect spherical topology while maintaining the computational efficiency and drop-in simplicity of methods like RoPE."}, "weaknesses": {"value": "- Experiments use relatively small-scale tasks (Spherical MNIST, downsampled ERA5 at 128×256 resolution) and lack comparison to specialized spherical architectures or more recent baselines designed for spherical data.\n- The improvements over simpler baselines like RoPE are often marginal (e.g., 0.88pp on MNIST), making it unclear whether the added geometric complexity translates to meaningful real-world benefits that justify adoption.\n- The paper lacks ablation studies on key design choices (auxiliary point selection, masking strategies), theoretical analysis of when spherical geometry matters most, and evaluation on diverse spherical tasks beyond weather forecasting and toy image classification."}, "questions": {"value": "- When does spherical geometry actually matter?\n- How should auxiliary points be selected, and how much do results depend on masking strategies, the number of 3D subspaces, or other hyperparameters that lack principled guidance?\n- How does SpRePE perform at production-scale resolutions, on other spherical domains (astronomy, geology), with different architectures (Swin, hierarchical transformers), and does the computational overhead remain negligible at scale?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "KXqLIMwmH2", "forum": "F5bDWU4M0J", "replyto": "F5bDWU4M0J", "signatures": ["ICLR.cc/2026/Conference/Submission5045/Reviewer_G8kz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5045/Reviewer_G8kz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5045/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761680632755, "cdate": 1761680632755, "tmdate": 1762917840719, "mdate": 1762917840719, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a positional encoding method for data defined on a sphere. The core concept builds on the RoPe scheme, where positions are encoded using complex exponentials, which are then multiplied (rather than added) to the vectors. This approach is further adapted for datapoints on a 3D-sphere. From what I gathered, the key innovation lies in using Householder reflection matrices (relative to a predefined grid of points, denoted as $n$) to encode the positional data."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The manuscript is well-written, presenting a novel positional encoding scheme by adapting RoPe for spherical data.\n\n2. The approach is evaluated through benchmarking against several existing methods from the literature."}, "weaknesses": {"value": "1. The manuscript does not provide a more formal statement for the proof in Appendix C. Although Section 3.1 discusses the result, its current form makes it unclear what the formal statement is and what its implications are (see also Question 3).\n\n2. It would be helpful to include one or two additional experimental settings. For instance, the Spherical CNN approach by Cohet et al. (2018) offers experimental settings that could be considered for comparison."}, "questions": {"value": "1. Can you explain how you are choosing the grid of $n$. There is a discussion in section 3.1 about this saying \"... for every pair of $(p_1, p_2)$, any two auxiliary points $n_1$ and $n_2$ must define distinct sections.\", but how is this condition enforced both for uniform and non-uniform grid?\n\n2. It is not very clear to me the details of \"Density-adaptive Mask\". Can you elaborate on that?\n\n3. In the derivation provided in Appendix C, what is is the main result and the consequence?\n\n(I have kept my score on the lower end and will change it based on the answers of the above questions.)\n\n4. The RoPe scheme uses complex exponetials, which can be thought of as spherical harmonics in 2D. Have you thought of extending this idea and designing something using spherical harmonics in 3D?\n\nTypo in line 255: \"Noticed\" -> \"Notice\"."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7UqHfgLPx3", "forum": "F5bDWU4M0J", "replyto": "F5bDWU4M0J", "signatures": ["ICLR.cc/2026/Conference/Submission5045/Reviewer_1Wsb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5045/Reviewer_1Wsb"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5045/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761690118092, "cdate": 1761690118092, "tmdate": 1762917840279, "mdate": 1762917840279, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Spherical Reflection Position Embedding (SpRePE), a geometry-aware and lightweight position embedding method for Transformers operating on spherical data. The approach leverages the Householder matrix to encode absolute positions on the sphere and incorporates explicit relative position dependencies directly into the attention formulation. Unlike previous spherical embedding methods that rely on additional modules or complex architectures, SpRePE maintains high computational efficiency with minimal parameter overhead. Experiments are conducted on spherical image classification and global weather forecasting tasks, showing improvements over existing baselines such as APE, RPE, ALiBi, and RoPE."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper targets an important and under-explored area — transformer modeling on spherical domains, which has strong relevance to scientific applications like meteorology and astronomy.\n\nThe formulation is elegant, providing a theoretically grounded yet efficient way to encode positional information on non-Euclidean manifolds.\n\nThe method is lightweight, requiring minimal architectural changes and extra parameters.\n\nThe paper is well written, and the idea is clearly explained with sound mathematical motivation."}, "weaknesses": {"value": "The performance gain is quite small compared to APE — for example, in Table 3, accuracy only improves from 96.29 to 96.74, and in Table 4, from 0.9954 to 0.9965. Such marginal improvements raise concerns about the practical significance of the proposed method.\n\nThe evaluation is limited to a few specific datasets (spherical image and weather data). To better demonstrate generalization and robustness, it would be valuable to test on more widely used image or language datasets (e.g., ImageNet, COCO, or text benchmarks).\n\nIt is unclear whether SpRePE provides benefits beyond specialized spherical data — this limits its broader impact and may restrict its applicability."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MWjAGMEEht", "forum": "F5bDWU4M0J", "replyto": "F5bDWU4M0J", "signatures": ["ICLR.cc/2026/Conference/Submission5045/Reviewer_NJ9S"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5045/Reviewer_NJ9S"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5045/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761894899804, "cdate": 1761894899804, "tmdate": 1762917839846, "mdate": 1762917839846, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SpRePE (Spherical Reflection Position Embedding), a geometry-aware and efficient positional encoding for ViTs on spherical data. It uses Householder reflections to encode absolute positions on the sphere and lets relative information emerge via attention inner products. No extra trainable parameters, and it’s drop-in to standard Transformers. Validated on Spherical MNIST and ERA5."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tNovel geometric formulation: Reflection-based, sphere-aware encoding; handles poles & longitudinal wrap-around better than planar PE.\n2.\tMinimal overhead: No architecture change; same complexity class as RoPE; avoids quadratic RPE.\n3.\tEmpirical gains: Better accuracy/robustness (especially at high latitudes & long horizons).\n4.\tComprehensive eval: Comparisons + ablations (masking, robustness).\n5.\tClarity & reproducibility: Derivations are clean; code & settings well documented."}, "weaknesses": {"value": "1.\tDataset breadth: Only Spherical MNIST & ERA5; lacks panoramic CV / point-cloud / remote-sensing detection tasks.\n2.\tQualitative insight: Could add attention maps / distance heatmaps to visualize geometric effects.\n3.\tAblation depth: Need to isolate the contribution of the geometric term vs. reflection itself; clarify sensitivity to auxiliary points {n_i}.\n4.\tTheory rigor: Proof that reflections yield correct relative encoding could be strengthened.\n5.\tBaselines: Missing comparisons with newer geometry-aware methods (e.g., Sphere2Vec, Heal-Swin) on same backbones."}, "questions": {"value": "1.\tAuxiliary points: How are {n_i} chosen (fixed grid / learned / random)? Sensitivity & stability?\n2.\tMasking: Tried learned or entropy-gated masks instead of cosine-latitude heuristics?\n3.\tGenerality: Extendable to other manifolds (hyperbolic / cylindrical)? What changes?\n4.\tScale: Results on larger backbones / higher-res ERP (e.g., ViT-L/16 @ 1024×2048)? Memory trade-offs?\n5.\tInterpretability: Any visualization of reflection effects in latent space or attention geometry?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vtkXtRc7Ja", "forum": "F5bDWU4M0J", "replyto": "F5bDWU4M0J", "signatures": ["ICLR.cc/2026/Conference/Submission5045/Reviewer_W8Az"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5045/Reviewer_W8Az"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5045/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761895513688, "cdate": 1761895513688, "tmdate": 1762917839559, "mdate": 1762917839559, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}