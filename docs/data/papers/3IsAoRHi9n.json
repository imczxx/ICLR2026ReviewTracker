{"id": "3IsAoRHi9n", "number": 15839, "cdate": 1758255945387, "mdate": 1759897278595, "content": {"title": "Beyond Consensus: Mitigating the Agreeableness Bias in LLM Judge Evaluations", "abstract": "New Large Language Models (LLMs) become available every few weeks, and modern application developers confronted with the unenviable task of having to decide if they should switch to a new model. While human evaluation remains the gold standard, it is costly and unscalable. The state-of-the-art approach is to use LLMs as evaluators (LLM-as-a-judge), but this suffers from a critical flaw: LLMs exhibit a strong positive bias. We provide {\\em empirical} evidence showing that while LLMs can identify valid outputs with high accuracy (i.e., True Positive Rate >96%), they are remarkably poor at identifying invalid ones (i.e., True Negative Rate <25%). This systematic bias, coupled with class imbalance, often leads to inflated reliability scores. \n\nWhile ensemble-based methods like majority voting can help, we show that they are not good enough. We introduce an optimal minority-veto strategy that is resilient to missing data and mitigates this bias to a large extent. For scenarios requiring even higher precision, we propose a novel regression-based framework that directly models the validator bias using a small set of human-annotated ground truth data. On a challenging code feedback task over 366 high-school Python programs, our regression approach reduces the maximum absolute error to just 1.4%, achieving a 2x improvement over the best-performing ensemble of 14 state-of-the-art LLMs.", "tldr": "", "keywords": ["Large Language Models (LLMs)", "Feedback Generation", "LLM-as-a-Judge", "Benchmarking", "Ensemble", "Calibration", "Regression Analysis"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2d9dce8675d1c347e1b2e8016b8b69010db7c9ad.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper identifies the positive bias problem in LLM-as-a-judge, i.e., LLM verifiers have high TPR while low TNR. The paper first proposes minority-veto strategy, an improvement upon the majority-voting method that marks the response as invalid when the number of individual verifiers that output \"invalid\" reaches a certain threshold. This threshold strikes a balance between TPR and TNR. In addition, minority-veto strategy is robust to missing data, a problem for majority-voting. Then the paper proposes the regression-base approach, another bias correction strategy that assumes access to a small proportion of human annotated data. Based on the assumptions that verifiers' TPR/TNR are independent of the generator, this strategy learns the verifiers' TPR and TNR with the accessible human data, which can be used to predict the precision of a new generator. Finally, the paper creates a new dataset to test the two approaches."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper formalizes the positive bias problem as the gap between TPR and TNR, and provides empirical evidence for it. The paper provides two novel solutions, one as a fix for the popular majority-voting strategy, the other based on regression."}, "weaknesses": {"value": "1. Weakness in quality: All experiments in the paper are conducted on a self-created dataset, without any experiment results on public datasets. In addition, the dataset contains only 366 problems, so the evaluation result suffers from high variance.\n2. Weakness in clarity: \n    - The term \"precision\" in the paper is confusing, especially when appearing together with TPR and TNR. In line 142, \"precision\" is defined as \"the proportion of valid feedback among all successfully generated items\". This violates the [usual definition](https://developers.google.com/machine-learning/crash-course/classification/accuracy-precision-recall) of \"precision\" (TP/(TP+FP)). In fact, \"precision\" should be renamed as \"accuracy\" according to common conventions.\n    - The regression-based approach is based on the strong assumption that the TPR and TNR of the verifiers does not change with generators. In practice, this assumption does not hold, as Eq. (2) and (3) cannot be minimized simultaneously. \n3. Weakness in significance: The two strategies proposed in the paper are completely independent, and they cannot be combined together. Therefore, the paper can be viewed as the combination of two separate works.\n4. Weakness in novelty: The minority-veto approach is essentially choosing the decision threshold in the classical precision-recall trade-off , which is widely discussed in ML research."}, "questions": {"value": "1. How do the proposed methods perform in publicly accessible datasets? \n2. As a sanity check, how do the methods perform on tasks with verifiable answers? Benchmarks including GSM8K, MATH-500, etc. These benchmarks add reliability to the proposed methods, as the answers are objective and the benchmarks have more data."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "K5QKVNYi0w", "forum": "3IsAoRHi9n", "replyto": "3IsAoRHi9n", "signatures": ["ICLR.cc/2026/Conference/Submission15839/Reviewer_cH21"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15839/Reviewer_cH21"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15839/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761630013170, "cdate": 1761630013170, "tmdate": 1762926064317, "mdate": 1762926064317, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies a practical and timely problem: the reliability of LLMs used as validators (LLM-as-a-judge) for open-ended tasks where correctness is non-binary (here: automated feedback for incorrect high-school Python programs). The authors introduce and analyse the “agreeableness bias”, validators show very high True Positive Rate (TPR ≳ 96%) but very low True Negative Rate (TNR ≲ 25%), causing systematic over-estimation of a generator’s precision. Using a dataset of 366 buggy programs, feedback generated by 14 LLMs, and human annotations for 6 generators, the paper (i) quantifies the bias (Figures 1, 3–4, Table 1), (ii) shows limits of simple majority voting (sensitivity to missing outputs and a floor imposed by validator TNR), (iii) proposes a Minority-Veto ensemble that improves robustness to missing values, and (iv) presents a regression-based calibration that models each validator’s TPR/TNR and each generator’s precision, using a small calibration set of human-annotated generators. The regression approach, when calibrated with up to 5 annotated generators, reduces maximum absolute error to ~1.4% (Figure 6), outperforming ensembles."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "* Simple, effective ensemble method. The Minority-Veto rule is conceptually simple, robust to missing values, and empirically outperforms plain majority voting after minimal calibration.\n\n* Reproducibility intent & dataset release. The authors commit to releasing code and the dataset (14 LLM outputs × 366 tasks), which will be useful for follow-up work."}, "weaknesses": {"value": "* Single domain study; limited evidence of generality. All experiments are on code-feedback generation (366 programs). The authors acknowledge this; however, it remains unclear how agreeableness and the regression correction behave on other open-ended domains (summaries, creative writing, dialogue, medical advice) where human agreement patterns differ.\n\n*The paper compares the proposed methods mainly against simple majority voting and a random baseline, but omits other relevant approaches from related domains such as advanced aggregation schemes (e.g., weighted or probabilistic voting), existing calibration or de-biasing techniques used in LLM judgment tasks, or classical ensemble reliability models. Without broader comparisons, it is difficult to gauge the relative contribution and novelty of the proposed ensemble and regression methods beyond these straightforward baselines."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3wTfTPaBWC", "forum": "3IsAoRHi9n", "replyto": "3IsAoRHi9n", "signatures": ["ICLR.cc/2026/Conference/Submission15839/Reviewer_Ri2p"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15839/Reviewer_Ri2p"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15839/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761708916166, "cdate": 1761708916166, "tmdate": 1762926063665, "mdate": 1762926063665, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents the \"agreeableness bias” of LLM-as-a-judge on the task of programming feedback, described as having high TPR and low TNR. The authors show that strong models also exhibit this bias. But an ensemble method like majority vote and a proposed variant of it can mitigate it. Moreover, the paper presents a regression-based method that uses the full judgment data and human-annotated calibration data to further reduce this bias."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Good motivation, utilizing previous work findings on positive bias, and the need for improved open-ended task evaluation.\n2. A good number of models in the experiments.\n3."}, "weaknesses": {"value": "1. The motivation and experimental setup are not aligned: a. The task of \"programming feedback\" is different then LLMaaJ. b. The experiment data is very narrow and not general enough to frame the paper as a general LLMaaJ results. The authors recognize this in a few places, but their response is not sufficient. This is a core problem of the paper.\n2. Some parts are not clear enough. The predicted and estimated precision, and if it's just the LLM precision, why and how the close agreement between Validator Mean and ground truth aligns with the positive bias.\n3.  “invalid” responses can exist, but using established methods and best practices like structured output, etc., can reduce them. Moreover, it can stem from choosing relatively old models.\n4. Minority Veto strategy seems very specific to your setup, and ignores the quality of each judge. It can just be the MV of the top-4.\n5. The regression-based method is not feasible, requires many judges, and human-annotated data.\n6. Going back to the motivation, the paper doesn't address the motivation it raises or provide a solution that is better or more accurate than the current method."}, "questions": {"value": "The paper needs to be framed in the context of the target domain or adapted to general data suited for the assessment of LLMaaJ. The writing needs to be improved and clearer to make the paper's point about \"agreeableness bias” and its mitigation really come across."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YCkGGVYKtp", "forum": "3IsAoRHi9n", "replyto": "3IsAoRHi9n", "signatures": ["ICLR.cc/2026/Conference/Submission15839/Reviewer_u2Jz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15839/Reviewer_u2Jz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15839/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761842855717, "cdate": 1761842855717, "tmdate": 1762926063030, "mdate": 1762926063030, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}