{"id": "43YE7hqSQJ", "number": 2541, "cdate": 1757140991253, "mdate": 1759898142280, "content": {"title": "GraphTorque: Torque-Driven Rewiring Graph Neural Network", "abstract": "Graph Neural Networks (GNNs) have emerged as powerful tools for learning from graph-structured data, leveraging message passing to diffuse information and update node representations. However, most efforts have suggested that native interactions encoded in the graph may not be friendly for this process, motivating the development of graph rewiring methods. In this work, we propose a torque-driven hierarchical rewiring strategy, inspired by the notion of torque in classical mechanics, dynamically modulating message passing to enhance representation learning in heterophilous and homophilous graphs. Specifically, we define the torque by treating the feature distance as a lever arm vector and the neighbor feature as a  force vector weighted by the homophily ratio disparity between node pairs. We use the metric to hierarchically reconfigure each layer’s receptive field by automatically pruning high-torque edges and adding low-torque links based on a Bernoulli-guided learnable sampling process, suppressing the impact of irrelevant information and boosting pertinent signals during message passing. Extensive evaluations on benchmark datasets show that the proposed approach surpasses state-of-the-art rewiring methods on both heterophilous and homophilous graphs.", "tldr": "We propose a torque-driven hierarchical rewiring strategy to enhance message passing in heterophilous and homophilous graphs.", "keywords": ["Graph Neural Network", "Graph Rewiring", "Heterophily and Homophily", "Message Passing"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/df0b4300b4f06edf375fdcae81b9e4705044fca5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors propose a graph rewiring strategy, inspired by mechanical torque, to improve message passing in GNNs under both homophily and heterophily. During training, each edge is assigned a score that guides rewiring, with Gumbel–Softmax parameterizing the selection, yielding a dynamic graph-rewiring method."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The rewiring method combines (i) the distance between node representations and (ii) the neighbor’s feature strength, weighted by the local homophily gap a principled and interesting criterion. \n\n* Unlike curvature or spectral based rewiring, the scoring is directly dependent on the task and the data, leveraging node features together with homophily information.\n\n\n* The model’s computational complexity appears operational on large graphs, making it practical beyond small benchmarks."}, "weaknesses": {"value": "- **Ambiguity in the introduction on the heterophily definition.**  \n  The introduction conflates label heterophily  with feature dissimilarity. Phrases such as “addressing heterophily, where nodes with dissimilar labels or features  tend to be connected” and “heterophilous graphs typically connect node pairs with low similarity” assume that heterophilous edges usually join feature dissimilar nodes, whereas one can have similar features but different labels. This ambiguity harms the motivation of the work.\n\n- **Reliance on pseudo-labels for local homophily.**  \n  The gap \\(|h_i^{+} - h_j^{+}|\\) is computed with pseudo-labels beyond annotated nodes. This can create a kind of self-reinforcing error : early mistakes in pseudo-labels may be treated as correct, shaping subsequent estimates and making those errors more likely to persist. The risk could be higher with imbalance class. Additionally the paper notes progressive refinement, but it does not quantify how sensitive the method is to pseudo-label.\n\n- **Limited theory behind the “torque” intuition.**  \n  The torque  analogy remains empirical. There is no formal guarantee linking the torque score to reduced over-squashing, or proxy analyses (e.g., Jacobian/sensitivity bounds, changes in effective resistance, or diagnostics of topological bottlenecks). The paper should clarify : \n  - (i) How torque values flag edges that exacerbate over-squashing ?\n  - (ii) How you can analyse the final rewired structure ?\n  - (iii) Why these structural rewiring should mitigate over-squashing ? \n\nIn my view, this is the paper’s most significant weakness\n\n- **Missing discussion of feature-aware rewiring baselines.**  \n  While the method leverages node features, the authors omit recent approaches that also use features for rewiring [1–4].  \n  To clarify the paper’s evaluation and highlight the method’s performance, a focused discussion and comparison (not with all baselines, of course) is in my view necessary. Note that [4] also uses the Gumbel–Softmax to perform dynamic rewiring based on triangle substructures.\n\n  - [1] Hugo Attali, Buscaldi, D., & Pernelle, N. Delaunay Graph: Addressing over-squashing and over-smoothing using Delaunay triangulation, ICML 2024.\n  - [2] Jonas Linkerhägner, Cheng Shi, Ivan Dokmanić : Joint Graph Rewiring and Feature Denoising via Spectral Resonance, ICLR 2025.\n  - [3] Celia Rubio-Madrigal, Adarsh Jamadandi, Rebekka Burkholz : GNNs Getting ComFy: Community and Feature Similarity Guided Rewiring, ICLR 2025\n  - [4] Hugo Attali, Thomas Papastergiou, Nathalie Pernelle, Fragkiskos D. Malliaros : Dynamic Triangulation-Based Graph Rewiring for Graph Neural Networks, CIKM 2025.\n\n- **Notation issues.**  \n  The symbol \\(D\\) is overloaded (node degree vs. displacement vector). Use distinct symbols to avoid confusion and improve the clarity."}, "questions": {"value": "-  See Weakness please. \n\nI would welcome the opportunity to continue this discussion and engage with these points during the rebuttal phase."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IUzgqqJTdb", "forum": "43YE7hqSQJ", "replyto": "43YE7hqSQJ", "signatures": ["ICLR.cc/2026/Conference/Submission2541/Reviewer_5f9Z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2541/Reviewer_5f9Z"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2541/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761322034441, "cdate": 1761322034441, "tmdate": 1762916273602, "mdate": 1762916273602, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a method that that rewires the graph structure of GNNs during training to improve node classification, especially on heterophilous graphs where neighbors mostly have different labels. It defines a \"torque score\" for each edge using the (learned) node embedding similarity, and how different their local \"label distributions\" are (with pseudo-labels during training). High \"torque\" edges are considered harmful and get pruned, while low \"torque\" edges can be added; they only consider a candidate subset given by cosine similarity for computational reasons. The rewiring is done separately at every layer."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper presents an integrated, train-time rewiring mechanism instead of doing static preprocessing.\n- The method performs rewiring separately at each layer, which is an important design choice albeit not novel.\n- It includes ablations that justify each component of the method."}, "weaknesses": {"value": "1. The motivation for this rewiring method is lacking. In parts of the paper, \"bad\" edges are described as spurious or missing, but in the experiments the method is compared against approaches targeting over-squashing, which is a different problem.\n2. The paper relies almost entirely on the outdated assumption that \"heterophily = bad\" and does not present any alternative conceptual motivation or new theoretical insight beyond that.\n3. The claim that adversarial edges tend to connect low-similarity nodes does not imply the converse, that low-similarity edges are adversarial or spurious. Moreover, there are no ablations or experiments on robustness or resistance to adversarial edges, even though that is presented as a core motivation for the method.\n4. Importing a concept from physics is not a contribution by itself, unless that concept enables new insight, which is not the case here.\n5. It looks like many of the experimental gains fall within the standard deviations.\n6. The paper does not discuss or compare to prior work on similarity-based rewiring methods (1), layer-wise rewiring methods (2) or noisy edge rewiring methods (3).\n7. Minor: Fig.4 caption seems to be wrong, as it is the same one than Fig.5.\n\n(1) GNNs Getting ComFy: Community and Feature Similarity Guided Rewiring. Celia Rubio-Madrigal et al. ICLR 2025.\n\n(2) DRew: Dynamically Rewired Message Passing with Delay. Benjamin Gutteridge et al. ICML 2023.\n\n(3) Towards Understanding and Reducing Graph Structural Noise for GNNs. Mingze Dong et al. ICML 2023."}, "questions": {"value": "1. What problem is this method actually solving: over-squashing or noisy / spurious edges? If it is over-squashing, there is no theoretical link to their methodological proposal. If it is noisy edges, there is no experimental evidence in terms of robustness, and no comparison against prior methods with that stated goal.\n2. How does the method affect model overconfidence, given that it reinforces pseudo-labels produced by the model itself?\n3. Why are higher torque values assumed to indicate less reliable edges? This looks like a fallacy given by the \"adversarial edge\" story, which does not necessarily follow. Also, \"reliability\" is never formally defined, and there is no theory that explains this connection to the method.\n4. How does this criterion compare to just maximizing pairwise similarity, which already exists, e.g. (1)? And how about comparing on equal footing to a layer-wise similarity-based rewiring strategy using the learned embeddings during training? Why is the torque view necessary?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WfeiZEIjAh", "forum": "43YE7hqSQJ", "replyto": "43YE7hqSQJ", "signatures": ["ICLR.cc/2026/Conference/Submission2541/Reviewer_Xk2o"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2541/Reviewer_Xk2o"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2541/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761574694504, "cdate": 1761574694504, "tmdate": 1762916273367, "mdate": 1762916273367, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work introduces Torque-driven Hierarchical Rewiring as a novel rewiring strategy to overcome the over-squashing problem in GNNs. THR assigns a torque value, a physics-inspired concept, to each edge. This metric measures the potential of each edge to interfere with message passing based on node feature differences and local label homophily. Using these torque values, the method hierarchically rewires the graph by pruning unreliable edges and sampling important connections in an end-to-end manner."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- This is the first work that uses a physics-inspired torque idea as a graph rewiring technique; this is novel and well motivated by the successful application of torque in other fields.\n- Experiments show strong performance across different evaluation setups.\n- Design choices are thoroughly ablated."}, "weaknesses": {"value": "- The method’s main limitation lies in its relatively higher computational complexity, primarily due to the need to sort edges after torque computation in order to identify the torque gap for edge removal. Of course, this could not be a limiting factor in practice, but the authors do not provide a runtime comparison. I would highly recommend a runtime comparison be included in the Supplementary.\n- The authors have mainly performed experiments on node-level dataset. However, a lot of the works on graph rewiring, over-smoothing, over-squashing, and long-range dependencies are also evaluating on graph-level datasets (such as the LRGB [[2], [3]]) or other synthetic tasks (such as Trees-NeighborsMatch [[4]]). Does the proposed method support these datasets? Could the authors provide a comparison on these datasets? I would also recommend that the authors use all of the datasets from [[5]] for heterophilic tasks.\n- Did you conduct an ablation study comparing the torque-based edge removal to a simpler strategy that removes a fixed number of edges with the lowest torque values? It would be interesting to observe the performance trade-off in such a setting. If the performance degrades substantially, the higher computational complexity of the proposed approach would be justified.\n- Have you evaluated the method’s behavior when excluding initial input graph features? Understanding how this affects training stability would help clarify the model’s dependence on early representations.\n- Could the proposed approach be extended to dynamic graphs, where edges appear/disappear over time, as in DGraph [[1]]? The concept of an adaptive receptive field seems promising for this.\n- (Minor) The method’s performance may appear to depend on reliable early-stage guidance, as noisy or unstable initial representations may negatively affect the rewiring process.\n- (Minor) The font on Figure 2 is very small. Please consider increasing the font.\n- (Very minor) Please consider using \\citep{} when referencing a paper, but not directly referring to the authors.\n\n[1]: https://arxiv.org/abs/2207.03579\n[2]: https://arxiv.org/abs/2206.08164\n[3]: https://arxiv.org/abs/2309.00367\n[4]: https://arxiv.org/abs/2006.05205\n[5]: https://arxiv.org/pdf/2302.11640"}, "questions": {"value": "Please see weaknesses above.\n\nOverall, I believe that the work is interesting and that the paper could be accepted. However, I suggest that the authors add a runtime analysis, such that it would be easier to understand the performance tradeoffs. Moreover, a clarification regarding graph-level tasks and other empirical results on synthetic datasets would be needed --- I recommend that the authors add results on the LRGB [[2], [3]] and some synthetic setups (such as Trees-NeighborsMatch [[4]] for over-squashing). I would also highly recommend that the authors provide results on all of the datasets from [[5]].\n\n\n[1]: https://arxiv.org/abs/2207.03579\n[2]: https://arxiv.org/abs/2206.08164\n[3]: https://arxiv.org/abs/2309.00367\n[4]: https://arxiv.org/abs/2006.05205\n[5]: https://arxiv.org/pdf/2302.11640"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "T9WslOInWR", "forum": "43YE7hqSQJ", "replyto": "43YE7hqSQJ", "signatures": ["ICLR.cc/2026/Conference/Submission2541/Reviewer_moV6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2541/Reviewer_moV6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2541/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761668514702, "cdate": 1761668514702, "tmdate": 1762916273080, "mdate": 1762916273080, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an edge rewiring strategy that considers both the similarity of node features and the consistency of labels (or pseudo-labels). The authors evaluate the proposed rewiring method on both homophilic and heterophilic datasets, demonstrating its effectiveness compared with other rewiring approaches."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The overall writing of the paper is relatively clear. However, it is worth noting that the citation format is used incorrectly throughout the entire paper, which significantly affects readability.\n- Determining the optimal graph connectivity based on the given node features is inherently a very challenging problem.\n- The authors provide experimental results on datasets with large-scale edges."}, "weaknesses": {"value": "- Modeling node feature similarity and label consistency as a concept of “torque” lacks strong justification. In fact, the authors merely intend to express the combined influence of these two metrics on edge probabilities. There are, in practice, many ways to model such combined effects. The choice of using torque for this purpose is not well justified and is therefore unconvincing.\n- In line 274, the authors mention selecting the top‑t most similar nodes as candidate nodes. Theoretically, this requires computing the similarity for all $n^2$ pairs of nodes, which results in a computational complexity of $O(n^2)$. Why is this part not considered in the complexity analysis? Additionally, under such complexity, how did the authors conduct experiments on large graphs such as Penn94 and Flickr? Does this involve a mini-batch strategy?\n- The authors propose using pseudo-labels to mark unlabeled nodes in order to compute label consistency. This makes the model heavily dependent on the proportion of labeled nodes in the dataset. In their experiments, they use training splits of 48%/32%/20%, but results under lower training proportions should also be provided (e.g., the semi-supervised settings on Cora/CiteSeer/PubMed), especially since most baseline methods do not rely on label information for edge rewiring.\n- The Cornell, Texas, and Wisconsin datasets used in the experiments are too small, making the results unreliable. The authors should replace them with larger-scale heterophilic datasets, such as other datasets from the Tolokers and Penn94 series used in the paper.\n- Based on the experimental results, THR is actually very close to the baselines, and the performance gains are not significant."}, "questions": {"value": "- Does the experiment on larger-scale datasets involve a mini-batch strategy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6sqABIzioP", "forum": "43YE7hqSQJ", "replyto": "43YE7hqSQJ", "signatures": ["ICLR.cc/2026/Conference/Submission2541/Reviewer_VcxD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2541/Reviewer_VcxD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2541/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761802376496, "cdate": 1761802376496, "tmdate": 1762916272680, "mdate": 1762916272680, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}