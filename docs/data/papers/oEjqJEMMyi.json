{"id": "oEjqJEMMyi", "number": 14041, "cdate": 1758227500953, "mdate": 1760980359574, "content": {"title": "Eidolon: Unleashing Stealthy Backdoor Pandemic by Infecting a Single Diffusion Model", "abstract": "The remarkable success of modern Deep Neural Networks (DNNs) can be primarily attributed to having access to compute resources and high-quality labeled data, which is often costly and challenging to acquire. Recently, text-to-image Diffusion Models (DMs) have emerged as powerful data generators to augment training datasets. Machine learning practitioners often utilize off-the-shelf third-party DMs for generating synthetic data without domain-specific expertise or adaptation. Such a practice leads to a novel and insidious threat: diffusion-model infected with a backdoor can effectively spread into a large number of downstream models, causing a backdoor pandemic. To achieve this for the first time, we propose Eidolon, designed and optimized to stealthily transfer the backdoor injected into a single diffusion model into virtually an infinite number of downstream models without any active attacker role in the downstream training tasks. Proposed Eidolon not only makes the attack stealthier and effective, it also enforces a strict threat model for injecting backdoor into the downstream model compared to conventional backdoor attacks. We propose four necessary tests that a successful backdoor attack on the diffusion model should pass to cause a backdoor pandemic. Our evaluation across a wide range of benchmark datasets and model architectures exhibits that only our attack successfully passes these tests, causing widespread pandemic across many downstream classifiers.", "tldr": "We introduce Eidolon, the first backdoor attack on diffusion model that stealthily causes a widespread backdoor pandemic by passively transferring the attack to downstream models through synthetic data generation", "keywords": ["Diffusion Model", "Backdoor Attack"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/c9f67ec7706706da8f2828738bbceb660f67e975.pdf", "supplementary_material": ""}, "replies": [{"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "We would like to withdraw the paper as we have some additional experiments and the paper would be strong with those experiments.  Additionally, all the authors agree that with these additions the paper might be more suited for a vision conference."}}, "id": "y6ZWcne8BN", "forum": "oEjqJEMMyi", "replyto": "oEjqJEMMyi", "signatures": ["ICLR.cc/2026/Conference/Submission14041/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14041/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760980358524, "cdate": 1760980358524, "tmdate": 1760980358524, "mdate": 1760980358524, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}