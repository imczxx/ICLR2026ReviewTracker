{"id": "pq6rx9r6Aj", "number": 6419, "cdate": 1757982229474, "mdate": 1759897915822, "content": {"title": "Jailbreaking Jailbreaks: A Proactive Defense for LLMs", "abstract": "The proliferation of powerful large language models (LLMs) has necessitated robust safety alignment, yet these models remain vulnerable to evolving adversarial attacks, including multi-turn jailbreaks that iteratively search for successful queries. Current defenses, primarily reactive and static, often fail to counter these search-based attacks. In this paper, we introduce ProAct, a novel proactive defense framework designed to disrupt and mislead autonomous jailbreaking processes. Our core idea is to intentionally provide adversaries with \"spurious responses\" that appear to be results of successful jailbreak attacks but contain no actual harmful content. These misleading responses provide false signals to the attacker's internal optimization loop, causing the adversarial search to terminate prematurely and effectively jailbreaking the jailbreak.\nBy conducting extensive experiments across state-of-the-art LLMs, jailbreaking frameworks, and safety benchmarks, our method consistently and significantly reduces attack success rates by up to 92\\%. When combined with other defense frameworks, it further reduces the success rate of the latest attack strategies to 0\\%. ProAct represents an orthogonal defense strategy that can serve as an additional guardrail to enhance LLM safety against the most effective jailbreaking attacks.", "tldr": "We introduce a novel and effective proactive defence framework designed to mislead and disrupt autonomous jailbreaking attacks against LLMs, demonstrating a significant reduction in attack success rates across SOTA models, strategies, and benchmarks.", "keywords": ["AI Safety", "Jailbreak Defense", "Multi-agent"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/da2b1c8d86a52f6a2cd2b42f1a1c754c77ddbeca.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes PROACT, a proactive defense that “jailbreaks the jailbreak” by returning spurious, non-harmful responses that look like successful jailbreak outputs to an attacker’s evaluator, thereby misleading and prematurely terminating the adversarial search. PROACT is instantiated as a three-agent pipeline: a User Intent Analyzer routes only malicious queries into the defense, a Proactive Defender generates topic-consistent but benign “encoded” outputs that appear harmful, and a Surrogate Evaluator iteratively critiques and refines these spurious responses until they pass a jailbreak evaluator. Across different target LLMs and attack frameworks, PROACT significantly lowers while preserving instruction-following utility."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The idea of \"Jailbreaking jailbreaks\" is very interesting and novel. \n\n2, The paper is well-written and easy to follow\n\n3. The empirical result of the PROACT method seems very good, and it can work with other defense methods together."}, "weaknesses": {"value": "1, \nThe Achilles heel of the PROACT system might be its User Intent Analyser, as it is basically acting as an LLM judge that detects the harmful content in the user input. One ICML 2025 paper (https://icml.cc/virtual/2025/poster/45356) specifically talks about how the LLM detection can be bypassed with their attack. The paper might need to address the usage of the LLM as a User Intent Analyser further. \n\n2. \nSome work, such as the persuasion attack (https://doi.org/10.18653/v1/2024.acl-long.773), also use a LLM judge to score the response's harmfulness and I am curious if that will work against the surrogate evaluator. \n\n3, \nSome jailbreak attacks do not involve iterative optimizations. For example, long-context jailbreaks (https://arxiv.org/pdf/2402.16717) or many-shot jailbreaking (https://proceedings.neurips.cc/paper_files/paper/2024/hash/ea456e232efb72d261715e33ce25f208-Abstract-Conference.html). Is PROACT defenseless against these types of attacks?\n\n4. \nIt seems like there are many back and forth between LLMs within the PROACT system. It raises the concern of increasing latency and resources of computing."}, "questions": {"value": "1, How will the PROACT work against the jailbreak attack that was designed to bypass LLM detection (https://icml.cc/virtual/2025/poster/45356), or does not need iterative optimization (https://proceedings.neurips.cc/paper_files/paper/2024/hash/ea456e232efb72d261715e33ce25f208-Abstract-Conference.html)?\n\n\n2, What is the extra latency of inferencing with PROACT?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sXTfOK88X9", "forum": "pq6rx9r6Aj", "replyto": "pq6rx9r6Aj", "signatures": ["ICLR.cc/2026/Conference/Submission6419/Reviewer_kWYP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6419/Reviewer_kWYP"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6419/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761552643123, "cdate": 1761552643123, "tmdate": 1762918815028, "mdate": 1762918815028, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a jailbreak defense method called ProAct against multi-turn seach-based attacks. The defense method first identifies jailbreak attempts and returns perturbed responses when spotting mallious inputs."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. ProAct seems to be effective against PAIR and TAP, reducing ASR to nearly zero. On average, it reduces attack sucess rate for more than 50%, which is notable.\n2. The authors conducted several ablations and experiments across different models to validate the method's effectiveness."}, "weaknesses": {"value": "1. My major concern is about the User Intent Analyzer. Why is it necessary to return nonsense strings to the attackers when we can actually spot them? Would be much more easier and safer to just terminate the conversation or connection as it is done in most commercial chat websites like ChatGPT or Claude. In summary, I simply do not understand why such defense is needed when we can actually identify the attackers. For me, identifying the attackers is the most vital part of the defense.\n\n2. The perturbation algorithms used by ProAct are trivial string operations, which is not adaptive to specific attackers. This might explain why the ASR is still above 50% for X-teaming."}, "questions": {"value": "Is ProAct effective when we cannot identify the attackers?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pKoiuE1mA5", "forum": "pq6rx9r6Aj", "replyto": "pq6rx9r6Aj", "signatures": ["ICLR.cc/2026/Conference/Submission6419/Reviewer_3D3V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6419/Reviewer_3D3V"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6419/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761833272001, "cdate": 1761833272001, "tmdate": 1762918814579, "mdate": 1762918814579, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces ProAct, a proactive defense framework that thwarts adversarial jailbreaks by generating deceptive responses that mislead attackers without producing harmful content. Extensive experiments show that ProAct reduces attack success rates by up to 92%, and to 0% when combined with other defenses, offering a powerful complement to existing LLM safety measures."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Innovative idea of generating spurious responses to actively mislead jailbreak attackers.\n\nGood writting structure and easy to follow."}, "weaknesses": {"value": "The defense's effectiveness relies on the attacker's evaluation mechanism `User Intent Analyzer`, which could be imperfect."}, "questions": {"value": "null"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "QZkvpgcAyx", "forum": "pq6rx9r6Aj", "replyto": "pq6rx9r6Aj", "signatures": ["ICLR.cc/2026/Conference/Submission6419/Reviewer_XNVM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6419/Reviewer_XNVM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6419/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968922992, "cdate": 1761968922992, "tmdate": 1762918814139, "mdate": 1762918814139, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a jailbreak defense method called ProAct. The proposed method use a three-agent system that first identifies the users' intention, and then craft a spurious response (which serves as the proactive defender). This response is refined iteratively in order to deceive the  surrogate evaluator. The experimental results in Table 1 shows significant improvement on the models' robustness against jailbreaking attacks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. (Clarity) This paper raises 5 RQs and provide detailed discussion regarding each of them, which improves the readability of this paper.\n2. (Significance) The experimental results in Table 1 shows significant improvement on the models' robustness against jailbreaking attacks."}, "weaknesses": {"value": "See the quetions part."}, "questions": {"value": "To what extent does the method presented in this study affect the efficiency of LLM serving? Is it possible to provide a quantitative assessment of the extra token consumption introduced by this method, and how does it perform in comparison with alternative methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "ybL8vkNW5o", "forum": "pq6rx9r6Aj", "replyto": "pq6rx9r6Aj", "signatures": ["ICLR.cc/2026/Conference/Submission6419/Reviewer_1EQm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6419/Reviewer_1EQm"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6419/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761970204168, "cdate": 1761970204168, "tmdate": 1762918813679, "mdate": 1762918813679, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}