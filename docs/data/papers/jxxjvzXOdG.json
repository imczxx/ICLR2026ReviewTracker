{"id": "jxxjvzXOdG", "number": 3355, "cdate": 1757407669135, "mdate": 1763743144740, "content": {"title": "Can Reasoning Language Models Think More Creatively? A Study of Reasoning Ability and Overconfidence", "abstract": "Recent advances in Large Language Models (LLMs) have been largely attributed to improvements in reasoning abilities. Reasoning models trained with Supervised Fine-Tuning (SFT) and Reinforcemenet Learning (RL), such as Policy Optimization (PO), demonstrate significantly superior performance compared to base models.  However, recent studies raise questions about the ability of these reasoning models to achieve creative thinking beyond that of the base model. In this study, we compare the creative problem-solving abilities in mathematics of two types of models: reasoning models and math models that have been further trained on simple mathematical corpora. Our comparison spans two representative open-source LLM families, DeepSeek and Qwen. The results indicate that reasoning models are less effective in generating creative solutions. We attribute the reasoning models’ limited ability to generate creative responses to Overconfidence (OC)—the tendency of models to exhibit excessive confidence in their own outputs. For example, within the DeepSeek family, reasoning models exhibit 15% higher OC compared to the math model, and within the Qwen family, the gap rises to 80%. Notwithstanding their heightened OC, they fail to generate creative responses as intended. We hypothesize that the high OC may stem from overly aggressive probability adjustments for certain tokens during SFT and PO. To examine this hypothesis, we introduce the notion of a High Entropy Segment (HES), defined as a region in which entropy varies sharply. Within these segments, reasoning models tend to exhibit greater heterogeneity compared to other models. Lastly, we measure the proportion of time steps where the model does not generate the most probable token, and observe that reasoning models show a substantially lower rate than math models. This is largely because their distributions contain a substantially greater share of tokens whose probabilities exceed 80% at each step. Our findings will be of great help in understanding and improving reasoning models.", "tldr": "base language models show more creative thinking than reasoning language models. This is due to overconfidence caused by excessive tuning during SFT and PO.", "keywords": ["LLM", "Reasoning model", "mathematics", "hallucination", "overconfidence"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d4f722ea441ac4df13dccb5960e1df0258c4f062.pdf", "supplementary_material": "/attachment/cee08e489b71fa904ddea514e87d99bcb92de591.zip"}, "replies": [{"content": {"summary": {"value": "In this analysis paper, the authors analyze the creativity of Qwen and Deepseek after different training stages using a model-based evaluation approach. They find that further post-training can harm their creativity. The authors also quantify token entropy and finds that models exhibit lower entropy after post-training."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The investigation into the diversity of language model outputs is important, as it is closely related to the generalization of language models.\n2. Overall, the analysis is comprehensive and multi-faceted."}, "weaknesses": {"value": "1. The fact that entropy can be lower after post-training has been investigated and is a well-known fact in the field [1-3], which makes the analysis less novel.\n2. The creativity evaluation is a bit subjective as it is model-based and reference-based. The authors do not clarify why the reference solution is less creative. Also, the lack of qualitative studies makes it hard for the reader to understand.\n3. Besides the analysis, guidance on how to help design better language model training methodologies is also lacking\n4. The use of the terms \"reasoning model\" and \"math model\" is a bit strange, as a reasoning model can also perform well on math tasks. I understand the naming habit of open-source models before o1 was released in 2024/09, but it would be better not to treat them as parallel categories.\n\nReferences\n\n[1] The Entropy Mechanism of Reinforcement Learning for Reasoning Language Models, in arxiv 2025\n\n[2] One-shot Entropy Minimization, in arxiv 2025\n\n[3] Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning, in arxiv 2025"}, "questions": {"value": "See the weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TBSAjH1p7s", "forum": "jxxjvzXOdG", "replyto": "jxxjvzXOdG", "signatures": ["ICLR.cc/2026/Conference/Submission3355/Reviewer_Abau"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3355/Reviewer_Abau"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3355/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761466151034, "cdate": 1761466151034, "tmdate": 1762916685132, "mdate": 1762916685132, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the trade-off between reasoning ability and creative problem-solving in Large Language Models, comparing two types of models: reasoning models (trained via SFT/RL, including DeepSeek-RL, Qwen-Inst) and math models (only pre-trained on mathematical corpora, including DeepSeek-Math, Qwen-Math). The core findings suggest that reasoning models exhibit higher accuracy in typical mathematical tasks but significantly lower creativity than math models."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The study addresses a critical yet underexplored gap in LLM research—whether the pursuit of advanced reasoning ability (via SFT/RL) compromises creative thinking. This is highly relevant given the widespread application of reasoning models in fields like mathematics and coding, where both accuracy and novel problem-solving are valuable. \n- The cross-model family design (DeepSeek + Qwen) enhances the generalizability of findings, while the introduction of HES and OAR adds mechanistic depth beyond simple OC ratio measurements. Comparing entropy, token length, and OC across model types (reasoning vs. math) and evaluation scenarios (self-evaluation vs. external evaluation) provides a comprehensive view of the relationship between model training paradigms and creative output.\n- The identification of OC as a barrier to creativity, along with the potential of distillation models (e.g., Qwen-Distill) to balance reasoning and creativity, offers actionable insights for improving LLM design"}, "weaknesses": {"value": "- Severe Writing and Table Clarity Issues. e.g.,\n1. Inconsistent Model Naming: Section 3.1 clearly defines model aliases, but Table 1 uses inconsistent full names. This forces readers to repeatedly check Section 3.1 to map model types (reasoning vs. math), creating unnecessary confusion.​\n2. Unreadable Table Structures: Table 2 is hard to read and we can't have a straightforward comparison between different models in Table 3.\n- Insufficient Control and Baseline Design: The inclusion of InternLM2-Math-20B in Table 1 lacks justification (no explanation of its training paradigm in the main text) and creates a baseline mismatch. Unlike the DeepSeek/Qwen models, which have clear \"math vs. reasoning\" pairs, InternLM2-Math-20B’s classification as a \"reasoning model\" is unsubstantiated, weakening the paper’s core comparison between model types.​\n- Incomplete Explanations: While the paper attributes low creativity to OC, it does not fully address why OC arises during SFT/RL. For example, it mentions \"overly aggressive probability adjustments for certain tokens\" but provides no analysis of which tokens (e.g., fork tokens vs. common tokens) are affected or how RL loss functions (e.g., GRPO) drive this bias.​"}, "questions": {"value": "- Confusion in Section 5.1: Why is InternLM2-Math-20B classified as a reasoning model? What is the purpose of including InternLM2-Math-20B? \n- Confusion in Section 5.2: Why is 28.9% considered a \"high\" OC ratio? How to explain OC ratio drops in non-self-evaluation? \n- Confusion in Section 5.3: Why link token length to creativity? \n- Priority of Creativity vs. Accuracy: Why is overconfidence criticized if it boosts accuracy?\n- Consequences of Overconfidence: What harms does OC cause beyond low creativity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JpzJY0B74y", "forum": "jxxjvzXOdG", "replyto": "jxxjvzXOdG", "signatures": ["ICLR.cc/2026/Conference/Submission3355/Reviewer_LKxK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3355/Reviewer_LKxK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3355/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761601588955, "cdate": 1761601588955, "tmdate": 1762916684950, "mdate": 1762916684950, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the internal behavioral patterns of reasoning-oriented large language models (LLMs) by introducing two quantitative metrics: token-level entropy and overconfidence (OC). Through comparative experiments between math-pretrained models (e.g., Qwen-Math, DeepSeek-Math) and reasoning-enhanced models (e.g., Qwen-Inst, DeepSeek-RL), the authors find that reasoning models exhibit lower overall entropy and higher OC, indicating excessive certainty and reduced creative variability. The study further introduces High Entropy Segments (HES) to analyze local uncertainty spikes, suggesting that these segments may correspond to superficial or unstable creative attempts rather than genuine reasoning diversity."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper provides well-defined and interpretable quantitative metrics (entropy and OC) to assess model uncertainty and reasoning confidence, addressing a relatively underexplored aspect of LLM interpretability.\n\n- The experimental analysis is systematic and statistically grounded, using proper correlation metrics and consistent evaluations across two model families (DeepSeek and Qwen)."}, "weaknesses": {"value": "- While the results are internally coherent, the implications for training methodologies (SFT and RL) are not fully articulated. It remains unclear what practical insight the findings offer for improving reasoning model design beyond observational diagnosis.\n\n- The definition and evaluation of “creativity” rely entirely on LLM-based judges. The paper does not convincingly justify that current LLMs possess the reliability or semantic sensitivity to distinguish truly creative reasoning from surface-level diversity.\n\n-  Model selection is somewhat confusing. The DeepSeek “RL” and Qwen “Inst” variants are presented as reasoning models, but they lack clear long-chain-of-thought (LongCoT) abilities typically associated with advanced reasoning architectures. The experimental lineup therefore might not represent the reasoning paradigm in its full sense.\n\n- There is limited discussion of causality: are high OC and low entropy truly caused by RL fine-tuning, or simply correlated with model style and decoding parameters?"}, "questions": {"value": "Minor stylistic issue: line 141 refers to DeepSeek-Coder with a typo."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wjTiXmdEkA", "forum": "jxxjvzXOdG", "replyto": "jxxjvzXOdG", "signatures": ["ICLR.cc/2026/Conference/Submission3355/Reviewer_zFCN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3355/Reviewer_zFCN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3355/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761655217549, "cdate": 1761655217549, "tmdate": 1762916684751, "mdate": 1762916684751, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focus on the diversity loss or homogeneity of reasoning models compared to pre-trained models in terms of math problem solving.\nThe author introduced a concept of **High Entropy Segment** to measure the ratio of the mean TE (token-level entropy) of a window compared to  the mean of the entire generation.  The take-away is that, although reasoning models often exhibited (over-)confidence in\nthe creativity of their generations, the actual proportion of creative solutions was relatively low."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The theme to investigate diversity loss or homogeneity of reasoning models is imo very pertinent and deserves more attention to the LLM community.\n2. The author introduced a concept of **High Entropy Segment** to measure the ratio of the mean TE (token-level entropy) of a window compared to  the mean of the entire generation. I can envision future works report the time-sensitive heterogeneity of their model using this metric"}, "weaknesses": {"value": "Two major weaknesses:\n1. The overall observation is that reasoning models is less creative in math problem solving than a base model pre-trained on math corpus.\nA very important hypothesis of the paper is that this is because of **overly aggressive probability adjustments for certain tokens -- referred to as fork tokens**. The authors introduced High Entropy Segment (HES) only to corroborate such observation, yet, no quantitative or qualitative analysis is conducted on these certain tokens to showcase or support the hypothesis. \nThe claim *This is largely because their distributions contain a substantially greater share of tokens whose probabilities exceed 80% at each step.* needs more support either by quantitative or qualitative analysis.\nI am afraid the take-away message is `reasoning models tend to mysteriously exhibit greater heterogeneity` with an `unverified hypothesis`. This make the contribution less convincing to me.\n\n2. Paper presentation is largely unclear. I found the following confusing:\n* Experimental models mentioned in Section 3.1 does match the results shown in Table 1, Section 5. No results for qwen-distill. Where does InternLM2-Math-20B come from\n\n* The results of jaccard, HESR are presented in Table 3 without definition of these terms. (later they were explained in section 6 but the authors need to provide definitions the first time these terms appear. otherwise it is surprising and confusing to the readers when the first time encountering these terms are in the results table. \n\n* The paper seem to not emphasize its effort in LLM as a judge, but a decent proportion of the results, analysis, and discussions are pertinent to the variance of math&reasoning models as a judge. \n\n* Same as previous point, def of math model is presented in Figure 1, but abstract and intro did not provide a crystal clear definition"}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "110T1G2LiA", "forum": "jxxjvzXOdG", "replyto": "jxxjvzXOdG", "signatures": ["ICLR.cc/2026/Conference/Submission3355/Reviewer_hhFo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3355/Reviewer_hhFo"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3355/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761961642707, "cdate": 1761961642707, "tmdate": 1762916684540, "mdate": 1762916684540, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Summary of Revisions in the Updated Manuscript"}, "comment": {"value": "First, we would like to express our sincere gratitude to all reviewers and the AC for their hard work in reviewing our paper. We have uploaded the revised version, which incorporates all reviewer feedback. We understand that you have busy schedules, but we kindly ask that you review the updated manuscript.\n\nHere is a summary of the revisions:\n1. We added quantitative and qualitative analyses of token probability adjustments in Figures 10 and 11 and Table 7 in Appendix E.\n2. We no longer use the previously introduced terms “math model” and “reasoning model” in the Abstract or Introduction. Beginning in Section 3, we instead define the terms “math model” and “RL model” clearly and use them throughout the rest of the paper to prevent confusion.\n3. The experimental results for InternLM in Table 1 were removed, as they were unnecessary.\n4. Table 2 has been revised to improve readability.\n5. The definition of HESR has been moved from Section 6 to Section 4 so that it appears before the abbreviation is used in the text.\n6. We clearly articulated the basis for our research assumptions by accurately citing findings from prior studies, such as token-probability adjustments during the SFT/RL process. We also clarified our novel contributions and the specific aspects on which our analysis focuses.\n\nWe were able to improve the presentation and clarity of our paper thanks to the many thoughtful comments from the reviewers. We sincerely appreciate everyone who provided us with this valuable opportunity to strengthen our work, and we are fully prepared for any further discussion.\n\nThank you sincerely.\n\nAuthors"}}, "id": "ZWxRtXbcut", "forum": "jxxjvzXOdG", "replyto": "jxxjvzXOdG", "signatures": ["ICLR.cc/2026/Conference/Submission3355/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3355/Authors"], "number": 12, "invitations": ["ICLR.cc/2026/Conference/Submission3355/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763743356944, "cdate": 1763743356944, "tmdate": 1763743356944, "mdate": 1763743356944, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}