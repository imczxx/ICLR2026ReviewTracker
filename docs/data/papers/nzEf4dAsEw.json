{"id": "nzEf4dAsEw", "number": 9268, "cdate": 1758116823180, "mdate": 1759897734340, "content": {"title": "DICT: Uncertainty-Constrained Trustworthiness for Graph Learning", "abstract": "Graph Neural Networks (GNNs) face growing demands for trustworthiness, encompassing robustness, fairness, etc. However, these dimensions are often undermined by various perturbations, which induce distributional uncertainty and compromise the trustworthiness of GNNs. To address this, we propose DICT, a novel framework that models distributional uncertainty to achieve trustworthy graph learning. Specifically, DICT formulates a unified optimization objective that captures perturbation-induced distributional shifts in graph topology, node features, and labels, and minimizes the worst-case risk over the uncertainty set. To make the primal infinite-dimensional problem tractable, we integrate strong duality and local Lipschitz continuity of the loss to reformulate the objective as a finite-dimensional min-max problem. We focus on robustness and fairness as primary instantiations of DICT because they are not only critical in real-world applications, but also provide transferable modeling principles for broader trustworthiness objectives. By formulating fairness in the form of an uncertainty set, DICT pioneers unified robustness and fairness within a single optimization framework. Extensive experiments across diverse benchmarks and GNN backbones demonstrate that DICT consistently improves both robustness and fairness, validating the effectiveness and adaptability of the DICT framework. We envision uncertainty constraints as a foundational principle for trustworthy graph learning and a step toward broader advancements in trustworthy AI.", "tldr": "A unified distributionally robust framework that enhances the trustworthiness of graph neural networks by jointly modeling robustness and fairness under data distributional uncertainty.", "keywords": ["Trustworthy Graph Learning;Distributionally Robust Optimization;Robustness;Fairness"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e513530b57596f890b6d8f94c91ad8de469d13f4.pdf", "supplementary_material": "/attachment/d707774b9c1c2a8b50c245e02b8e66f5cc9ed706.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces DICT, a unified framework for trustworthy graph learning that models distributional uncertainty via Wasserstein distributionally robust optimization (DRO). The authors address the challenge of ensuring robustness and fairness in graph neural networks (GNNs) . DICT formulates a unified optimization objective that captures perturbation-induced distributional shifts in graph topology, node\nfeatures, and labels, and minimizes the worst-case risk over the uncertainty set. The framework is instantiated for both robustness and fairness, with theoretical guarantees and extensive experiments demonstrating consistent improvements across multiple benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Strengths:\n\n1.The proposed method and framework are highly novel and appealing.\n\n2.The experimental results demonstrate that the proposed method achieves excellent performance.\n\n3.The paper provides a very clear derivation of the experiments."}, "weaknesses": {"value": "Suggestions:\n\n1.The experimental results would be more convincing if the raw accuracy values for the Cora, Citeseer, and PubMed datasets were provided, rather than only the $ \\bigtriangleup acc$\n\n2. The impact of hyperparameters on the experimental results is significant, particularly for $K_s$.\n\n3. The influence of this work could be substantially broadenedif the method could be extended to more recent GNN research, such as Transformer-based GNNs."}, "questions": {"value": "Please refer to the weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ho1w4hNKed", "forum": "nzEf4dAsEw", "replyto": "nzEf4dAsEw", "signatures": ["ICLR.cc/2026/Conference/Submission9268/Reviewer_aGWN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9268/Reviewer_aGWN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9268/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761622527688, "cdate": 1761622527688, "tmdate": 1762920916286, "mdate": 1762920916286, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DICT, a distributionally robust optimization (DRO) framework for trustworthy graph learning. By constructing a Wasserstein uncertainty set over graph structure, features, labels, and sensitive attributes, DICT aims to jointly improve robustness and fairness in graph neural networks (GNNs). The authors transform the infinite-dimensional primal optimization problem into a tractable min-max formulation by leveraging strong duality and local Lipschitz continuity. Empirical evaluations on several fairness and robustness benchmarks demonstrate DICT’s effectiveness across multiple datasets and GNN architectures."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The framework is built upon a well-established distributionally robust optimization principle, extended to handle graph-structured data with non-i.i.d. dependencies. By introducing a unified objective that jointly models robustness and fairness via Wasserstein uncertainty sets, DICT provides a principled foundation for trustworthy GNNs. The dual formulation using Lipschitz regularization offers a computationally feasible approximation of the intractable primal problem. The experimental design is thorough, showing consistent improvements across architectures (GCN, GIN, GraphSAGE) and datasets. The use of gradient-based and Hessian-based approximations for perturbation sensitivity is reasonable and practically effective."}, "weaknesses": {"value": "The distinction between label space and node set is unclear.\nOn page 2, lines 53–55, the label space is defined as Y=[0,1]^N, which suggests it has the same dimension as the node set. This may lead to confusion about whether each node has a binary label or if labels are assigned to all nodes regardless of supervision. Clarification of this formulation is necessary to avoid misunderstanding.\n\nThe assumption of i.i.d. perturbed graphs is problematic.\nIn line 114, the paper suggests that the set of perturbed graphs can be treated as approximately i.i.d. However, since all perturbed graphs are generated from the same base graph, they retain strong structural dependencies. The justification for this approximation is insufficient and should be clarified in relation to the theoretical guarantees provided later.\n\nThe meaning of the Dirac measure formulation is not explained clearly.\nIn line 116, the paper introduces the Dirac measure δ(A,X,y ̂), but does not provide adequate explanation of its role or implications in modeling graph distributions. This hinders the reader’s understanding of the empirical distribution used in the uncertainty set.\n\nThe label definitions in lines 119–120 are vague.\nThe relation between the observed labels y ̂,y ̂_kand the true labels y,y_kis not clearly explained. It remains ambiguous how these perturbed labels are generated, and whether they are considered noisy estimates or adversarial modifications.\n\nThe research problem and design goals are not clearly presented.\nThe introduction lacks a clear articulation of the core research problem and motivation. While the need for trustworthy graph learning is introduced, the specific challenge addressed by DICT is not sufficiently distinguished from existing methods. A concise formulation of the problem and the intended contributions would improve clarity.\n\nFairness and robustness are not formally defined.\nAlthough the paper discusses robustness and fairness throughout, formal definitions for these concepts are missing. For instance, fairness metrics such as statistical parity or equalized odds are used in experiments but not rigorously defined in the main text. This affects the reproducibility and interpretability of the results.\n\nClaims and Evidence\nThe empirical claims are supported by quantitative evaluations across datasets and backbones, and the use of ∆Acc, ∆SP, and ∆EO is appropriate. However, theoretical claims such as the validity of duality and Lipschitz approximations depend on assumptions (e.g., approximate i.i.d., local smoothness) that are not always adequately discussed or validated.\n\nRelation to Broader Scientific Literature\nThe paper is well-referenced but could better situate itself in relation to closely related work. For instance, the ROAD method (Grari et al., 2024), which also uses robust optimization for fairness in GNNs, is cited but not discussed in depth. A clearer comparison with other DRO-based GNN approaches would strengthen the literature positioning.\n\nEssential References Not Discussed\nSome recent work in robust and fair graph learning, such as those applying kernel-based DRO or information-theoretic fairness constraints, could be included to broaden the context. Moreover, extensions to privacy or interpretability via similar uncertainty modeling are briefly mentioned but not adequately linked to existing studies. Authors are suggested to discuss them in related work and evaluations."}, "questions": {"value": "refer to the weakness part"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "i6rkTfQNHE", "forum": "nzEf4dAsEw", "replyto": "nzEf4dAsEw", "signatures": ["ICLR.cc/2026/Conference/Submission9268/Reviewer_8w2e"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9268/Reviewer_8w2e"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9268/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761895640913, "cdate": 1761895640913, "tmdate": 1762920915900, "mdate": 1762920915900, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DICT, a unified framework for trustworthy graph learning that explicitly models distributional uncertainty in graph topology, features, labels, and sensitive attributes using a Wasserstein distributionally robust optimization formulation. DICT derives a dual  reformulation of the infinite-dimensional DRO problem using strong duality and local Lipschitz continuity, resulting in a tractable empirical loss regularized by a Lipschitz penalty that quantifies sensitivity to perturbations. The framework is demonstrated via specialization to both robustness and fairness objectives, and experiments on standard GNN backbones and multiple datasets show improvements in both robustness and fairness compared to strong baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. DICT presents a mathematically grounded and general framework that encompasses multiple trustworthiness objectives (robustness, fairness, privacy, etc.) within a single optimization structure.\n2. The paper covers tractable algorithms for estimating node-level Lipschitz constants (via first- and second-order Taylor approximations), and describes all perturbation models (Appendix D) for empirical reproducibility.\n3. The paper is well-written with clear figures."}, "weaknesses": {"value": "1. While the theoretical min-max and duality reformulations are elegant, computing the entire Lipschitz penalty at scale may not be feasible for very large graphs or in real-world GNN deployments. \n2. More GNNs should be included in the experiments.\n3. The claim that DICT can be seamlessly extended to other trustworthiness goals (e.g., privacy) is reasonable in theory, but only sketched in passing and not demonstrated in a experiments. The framework's claims to extensibility are not substantiated outside robustness and fairness."}, "questions": {"value": "1. Why didn't you add more classic GNNs, such as GAT, to Table 1 for experimentation?\n2. Can the authors provide empirical or theoretical guarantees on the runtime/memory overhead incurred by approximating $L(\\theta)$, especially for large graphs? Is the efficiency sufficient for scalable real-world deployment?\n3. Beyond theoretical pointers, can the authors demonstrate (even via toy examples) how DICT can be instantiated for privacy or interpretability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "goPE6qVUSB", "forum": "nzEf4dAsEw", "replyto": "nzEf4dAsEw", "signatures": ["ICLR.cc/2026/Conference/Submission9268/Reviewer_dD69"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9268/Reviewer_dD69"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9268/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923268444, "cdate": 1761923268444, "tmdate": 1762920915578, "mdate": 1762920915578, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}