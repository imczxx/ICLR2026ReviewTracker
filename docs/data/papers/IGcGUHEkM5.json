{"id": "IGcGUHEkM5", "number": 21918, "cdate": 1758323557565, "mdate": 1759896896159, "content": {"title": "BARE: Leveraging Base Language Models for Few-Shot Synthetic Data Generation", "abstract": "As the demand for high-quality data in model training grows, researchers and developers are increasingly generating synthetic data to tune and train LLMs. However, current data generation methods rely on seed sets containing tens of thousands of examples to prompt instruction-tuned models. This reliance can be especially problematic when the large-scale collection of high-quality seed examples is expensive or difficult. In this paper we explore the novel few-shot synthetic data generation setting -- generating a high-quality dataset from only a few seed examples. We show that in this low-seed setting, instruction-tuned models used in current synthetic data methods produce insufficient diversity for downstream tasks. In contrast, we show that base models without post-training, largely untapped for synthetic data generation, offer substantially greater output diversity, albeit with lower instruction following abilities. Leveraging this insight, we propose Base-Refine (BARE), a novel two-stage method that combines the diversity of base models with the quality assurance of instruction-tuned models. BARE excels in few-shot synthetic data generation: using only 3 seed examples it generates diverse, high-quality datasets that significantly improve downstream task performance. We show that fine-tuning Llama 3.1 8B with 1,000 BARE-generated samples achieves performance comparable to state-of-the-art similarly sized models on LiveCodeBench tasks. Furthermore, data generated with BARE enables a 101% improvement for a fine-tuned Llama 3.2 1B on GSM8K over data generated by only instruction-models, and an 18.4% improvement for a fine-tuned Llama 3.1 8B over the state-of-the-art RAFT method for RAG data generation.", "tldr": "Leveraging Base Language Models for Few-Shot Synthetic Data Generation", "keywords": ["synthetic data", "diversity", "large language models", "base models"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f6a6fe36584aca0b52b00bb3a7ff6a375fd2d5fd.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces Base-Refine (BARE), a novel two-stage method that tackles the quality-diversity trade-off in few-shot synthetic data generation. BARE first leverages a base model for diverse data generation from minimal seed examples, then uses a capable instruction-tuned model to individually refine these outputs for high quality, correcting errors while preserving diversity. The authors substantiate the framework's efficacy with experiments across a wide range of domains."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe manuscript is well-written, the proposed BARE pipeline is well-presented and can be easily understood.\n\n2.\tThe authors validate their BARE framework across a wide range of domains, from natural language classification to complex reasoning in math and code."}, "weaknesses": {"value": "1.\tLimited Novelty: The conceptual novelty of the proposed BARE framework appears incremental. The \"refine\" stage, a core component, seems to be a direct application of existing self-correction techniques [1] to the domain of LLM training data. The authors should more clearly articulate the fundamental innovation of this stage beyond a simple application of prior work.\n\n2.\tInsufficient Motivation: The paper's central motivation, tackling the quality-diversity trade-off in few-shot synthetic data generation, is not well-supported. This premise is challenged by recent works like Magpie [2], which can generate high-quality and diverse data from scratch (i.e., in a zero-shot setting) without requiring seed examples. The authors must provide a clearer justification for why such methods are insufficient and why the few-shot problem setting remains a critical, unsolved challenge.\n\n3.\tInsufficient Experimental Evaluation: The empirical evaluation is lacking crucial comparisons to state-of-the-art baselines. To properly contextualize the performance of BARE, the experiments should include more methods from the post-training data synthesis literature, such as [2-6]. Without these comparisons, the claimed advantages of the BARE framework are not adequately substantiated.\n\n\n\n[1] Kamoi, Ryo, et al. \"When can llms actually correct their own mistakes? a critical survey of self-correction of llms.\" Transactions of the Association for Computational Linguistics 12 (2024): 1417-1440.\n\n[2] Xu, Zhangchen, et al. \"Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing.\" The Thirteenth International Conference on Learning Representations, 2025.\n\n[3] Xu, Can, et al. \"WizardLM: Empowering large pre-trained language models to follow complex instructions.\" The Twelfth International Conference on Learning Representations. 2024.\n\n[4] Ding, Ning, et al. \"Enhancing Chat Language Models by Scaling High-quality Instructional Conversations.\" Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. 2023.\n\n[5] Lambert, Nathan, et al. \"T\" ulu 3: Pushing frontiers in open language model post-training.\" arXiv preprint arXiv:2411.15124 (2024).\n\n[6] Kaur, Simran, et al. \"Instruct-skillmix: A powerful pipeline for llm instruction tuning.\" arXiv preprint arXiv:2408.14774 (2024)."}, "questions": {"value": "1.\tHow does the \"refine\" stage differ conceptually from a direct application of the self-correction techniques outlined in [1]? \n\n2.\tGiven that methods like Magpie [2] can generate high-quality, diverse data from scratch, why is the quality-diversity trade-off in few-shot generation still a key motivation?\n\n3.\tCan the authors provide theoretical discussion and empirical results to show that the proposed method can outperform the previous data synthesis methods like [2-6]?\n\n[1] Kamoi, Ryo, et al. \"When can llms actually correct their own mistakes? a critical survey of self-correction of llms.\" Transactions of the Association for Computational Linguistics 12 (2024): 1417-1440.\n\n[2] Xu, Zhangchen, et al. \"Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing.\" The Thirteenth International Conference on Learning Representations, 2025.\n\n[3] Xu, Can, et al. \"WizardLM: Empowering large pre-trained language models to follow complex instructions.\" The Twelfth International Conference on Learning Representations. 2024.\n\n[4] Ding, Ning, et al. \"Enhancing Chat Language Models by Scaling High-quality Instructional Conversations.\" Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. 2023.\n\n[5] Lambert, Nathan, et al. \"T\" ulu 3: Pushing frontiers in open language model post-training.\" arXiv preprint arXiv:2411.15124 (2024).\n\n[6] Kaur, Simran, et al. \"Instruct-skillmix: A powerful pipeline for llm instruction tuning.\" arXiv preprint arXiv:2408.14774 (2024)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FtNHbTwsic", "forum": "IGcGUHEkM5", "replyto": "IGcGUHEkM5", "signatures": ["ICLR.cc/2026/Conference/Submission21918/Reviewer_gmgL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21918/Reviewer_gmgL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21918/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761797732029, "cdate": 1761797732029, "tmdate": 1762941982355, "mdate": 1762941982355, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces BARE (Base-Refine), a two-stage framework for few-shot synthetic data generation. The authors observe that instruction-tuned LLMs produce high-quality but low-diversity data, while base LLMs generate diverse but lower-quality samples. BARE leverages this complementarity:\n(i) A base model first generates a diverse pool of synthetic data from only a few seed examples (e.g., 3).\n(ii) An instruction-tuned model then refines each generated example for correctness and clarity.\n\nThe paper demonstrates that BARE produces diverse and realistic datasets that significantly improve downstream fine-tuning performance, even with minimal seed data. For instance, fine-tuning Llama-3.2-1B on 1,000 BARE-generated GSM8K samples improves accuracy by 101% over instruction-only baselines, and surpasses strong methods such as RAFT on RAG tasks by 18.4%."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The observation that base models retain diversity while instruct models lose it due to post-training is well-motivated and empirically verified.\n2. BARE is a simple yet effective way to combine strengths of base and instruct models, addressing the overlooked potential of base models in data generation."}, "weaknesses": {"value": "1. While combining base and instruct models is insightful, the method itself (generate + refine) is conceptually simple and resembles earlier “draft–refine” pipelines. The main novelty lies in the empirical insight rather than algorithmic design.\n2. The success of BARE heavily depends on the choice and strength of the refiner model (e.g., GPT-4o vs. Llama-Instruct), which limits reproducibility for weaker setups."}, "questions": {"value": "1. How sensitive is BARE’s performance to the choice of refiner model? For example, if a weaker instruction-tuned model (e.g., Llama-3-Instruct-8B) is used instead of GPT-4o, how much does performance degrade?\n2. During refinement, how does the refiner avoid “mode collapse” and preserve diversity? Would it make more sense to impose some mechanism (e.g., randomness, sampling temperature) to prevent homogenization during refinement?\n3. It would also be great to place larger / more recent LLMs as baselines and validate the proposed method."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FcqAWwkbMS", "forum": "IGcGUHEkM5", "replyto": "IGcGUHEkM5", "signatures": ["ICLR.cc/2026/Conference/Submission21918/Reviewer_mjgC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21918/Reviewer_mjgC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21918/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761928219591, "cdate": 1761928219591, "tmdate": 1762941982088, "mdate": 1762941982088, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes BARE, which is a new method for few-shot training data generation with base LLMs. Specifically, instead of synthesizing data with instruct model or base model only, BARE first generates training data with base model and then uses instruct model to further improve these data. In this way, the diversity of the synthetic data generated by the base model is maintained while the quality is improved by the instruct model. Evaluation shows that BARE-generated data performs the best for LoRA fine-tuning."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- This paper explores an important and interesting research direction.\n- The evaluation has included lots of in-depth study and discussion on the quality of synthetic data."}, "weaknesses": {"value": "- One major concern is the scalability of the method. While the evaluation has included different model series (i.e., Llama-3.1 and Qwen3) and benchmarks, the models used for training is limited to 8B-level and the training set only includes 1000 samples. More experiments on larger models with much larger training sets are needed to study whether the performance gain BARE brings can scale up consistently. \n- The relationship between downstream accuracy and indistinguishability rate is unclear. Specifically, while the indistinguishability rate of BARE data is similar to that of instruct data, the training performance using BARE data is clearly better than that using instruct data. More study is needed here to show whether indistinguishability rate is a good metric to evaluate the quality of synthetic data."}, "questions": {"value": "- Why does the evaluation focus on LoRA fine-tuning instead of full-weight fine-tuning?\n- Results in Table 8 seem to show that “BARE LLAMA 3.1 70B” performs worse than “BARE LLAMA 3.1 8B” on downstream accuracy. What’s the explanation for this abnormal phenomenon?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ajbIEfeZBx", "forum": "IGcGUHEkM5", "replyto": "IGcGUHEkM5", "signatures": ["ICLR.cc/2026/Conference/Submission21918/Reviewer_Qc13"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21918/Reviewer_Qc13"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21918/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972607239, "cdate": 1761972607239, "tmdate": 1762941981859, "mdate": 1762941981859, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Synthetic datasets are used to train LLMs, but they rely on a large number of curated seed tasks to introduce diversity into the synthetic data. This paper proposes BARE, a two-step approach that uses a base LM to generate highly diverse synthetic data and then an instruction-tuned model to improve generation quality. Furthermore, the base model uses only three seed examples, making it particularly useful for few-shot synthetic data generation. The downstream evaluations show that BARE-generated instructions improve LLM performance by a significant margin compared to baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper is well motivated and well written. \n\nThe proposed approach is quite simple and easy to implement. \n\nThe downstream evaluation with synthetic data shows positive results compared to the baselines. In particular, the results on the LCB leaderboard with BARE instructions are quite promising."}, "weaknesses": {"value": "**Missing key related work.**  \nMany of the findings and techniques in this paper have been introduced in prior work [a, b]. However, the paper does not discuss any of these works, either in the related work or the experiments. URIAL [a] uses three prompts to enable instruction-following abilities in base models. BARE also uses a similar three-prompt strategy to generate synthetic data with the base model. The authors should highlight the differences between the two methods. Furthermore, ALMA [b] uses only a base model for synthetic data generation, rather than the two-step approach with an instruction-tuned model in BARE. The paper should discuss and compare these works in the related work and experiments. Finally, the authors should also discuss related work that highlights the limitations of relying solely on the base model with in-context learning for following and generating instructions [c].\n\n**Method.**  \nThe method does not rely solely on the base model; BARE uses the base model to generate low-quality synthetic data and then an instruction-tuned model to refine it. While this is a reasonable approach, it still relies heavily on the instruction-tuned model to refine instructions. Furthermore, using the base model to produce more diverse synthetic data and then using an instruction-tuned model to improve the quality seems like a workaround rather than a principled approach to the problem. This could limit the impact of the work.\n\n**Factual inaccuracies.**  \nIn lines 89–90, the authors claim that this is the first work to show the value of base models for data generation. This is not accurate because [b] has already shown the benefits of using a base model for synthetic data generation. It would be great if the authors could refine or qualify this claim.\n\nIn line 42, the authors suggest that Li et al., 2024c [d] uses 500,000 text segments as seed sets. This is not accurate and is potentially misleading. Table 1 in [d] says they use 3,200 samples. Please consider rephrasing the sentence.\n\n**Miscellaneous**  \nFigure 8: Missing Instruct result for GSM8K. The caption says “generations derailed.” What does this mean?\n\nEntry-wise quality: It is unclear if this is a reliable metric. This appears to be an LLM-as-a-judge heuristic to indicate whether an example is synthetic or not. I’m not sure whether LLMs—even powerful ones like GPT-4o—can reliably judge whether an example is synthetic.\n\n**References**  \n\n[a] *The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context Learning.* ICLR 2024.  \n\n[b] *ALMA: Alignment with Minimal Annotation.* arXiv 2024.  \n\n[c] *Is In-Context Learning Sufficient for Instruction Following in LLMs?* ICLR 2025. \n \n[d] *Self-Alignment with Instruction Backtranslation.* ICLR 2024."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YcWK4zEkah", "forum": "IGcGUHEkM5", "replyto": "IGcGUHEkM5", "signatures": ["ICLR.cc/2026/Conference/Submission21918/Reviewer_C12M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21918/Reviewer_C12M"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21918/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762010978906, "cdate": 1762010978906, "tmdate": 1762941981523, "mdate": 1762941981523, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}