{"id": "EltjRajCVI", "number": 18763, "cdate": 1758290707623, "mdate": 1759897082579, "content": {"title": "Emergent Chess Skill Acquisition in Large Language Models", "abstract": "We investigate the emergent behaviors of rule comprehension, tactical execution, and strategic competence in transformer-based models trained on algebraic chess notation. To support structured reasoning, we introduce a disambiguation-aware tokenization scheme that explicitly encodes promotions, castling, checks, and mates, enabling fine-grained modeling of chess rules and dynamics.\n\nOur analysis reveals phase transitions in capabilities: shallow models fewer than 15 layers exhibit high illegality rates, while deeper models 20 layers or more increasingly demonstrate reliable tactical and positional behaviors. Training dynamics show while rule comprehension emerges early, higher-order abilities follow a hierarchical developmental path that mirrors curriculum learning. These trends remain consistent across decoding strategies and training distributions. \n\nOur findings suggest that transformer models can acquire human-aligned planning abilities in symbolic domains. Chess provides a tractable benchmark for evaluating the staged emergence of hierarchical competence in language models. Our methodology, including vocabulary design, architectural scaling, and behavioral evaluation, has the potential to generalize to other structured domains such as programming, formal logic, and mathematical proof systems.", "tldr": "", "keywords": ["training dynamics; large language models; chess; model pre-training; vocabulary design; domain specific languages; symbolic domains"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fbcdcf0ae2d9a88a24765b5f83fc29c0a9cd2ac4.pdf", "supplementary_material": "/attachment/f0c46c0d2082ac5ada58dcfc084ca9f36f0cf783.zip"}, "replies": [{"content": {"summary": {"value": "This paper investigates chess skills in decoder-only transformer models trained from scratch on algebraic chess notation. The authors focus on the training dynamics and developmental trajectory of these skills, rather than final performance. They systematically vary model depth (5 to 25 layers) and the training data distribution (a balanced dataset vs. a white-win-only dataset). Using a custom, disambiguation-aware tokenization scheme, they analyze the emergence of three hierarchical levels of competence: rule comprehension, tactical execution, and strategic planning. The paper concludes that chess provides a valuable, interpretable benchmark for studying how structured, hierarchical reasoning emerges in language models."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The dynamics of skill acquisition rather than just end-state performance is interesting.\n\nThe study is well-designed varying variables: architectural depth and data distribution.\n\nThe evaluation is good, moving beyond simple win rates or Elo."}, "weaknesses": {"value": "The current evaluation protocol appears to test the models as the White player. It would be beneficial to clarify if any experiments were conducted with the model playing as Black.\n\nThere seems to be a slight inconsistency in the evaluation methodology that I would appreciate clarification on. Rule comprehension is measured based on unconstrained generation, whereas the strategic evaluation uses prefix-constrained decoding to enforce legality. Could the authors explain the rationale for this dual approach? I wonder if this might decouple the model's strategic choices from its internal rule knowledge, potentially affecting the interpretation of the strategic metrics for shallower models that have not yet mastered legality.\n\nThe paper mentions that the training data was filtered to include games between 80 and 200 plies. Could the authors elaborate on the justification for this specific range?\n\nThe custom disambiguation-aware tokenization scheme is an interesting feature of the methodology. Could the authors explain why this hand-engineered approach was chosen over standard, data-driven subword tokenization methods like BPE?"}, "questions": {"value": "Please refer to the weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3J5uGRc5Nb", "forum": "EltjRajCVI", "replyto": "EltjRajCVI", "signatures": ["ICLR.cc/2026/Conference/Submission18763/Reviewer_35oD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18763/Reviewer_35oD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761613787036, "cdate": 1761613787036, "tmdate": 1762928492227, "mdate": 1762928492227, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Using chess as the research domain, the study examines how models acquire various chess skills from scratch. Lower-level skills, such as making legal moves, are learned early in training, whereas higher-level strategies, such as sacrificing pieces, are only acquired in the later stages."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Provides a detailed characterization of skill acquisition during the model’s training process."}, "weaknesses": {"value": "1. **I am not an expert in explainable AI!**\n2. I find the **article’s conclusion quite obvious: higher-level skills are learned later in training**. This is predictable and does not provide the reader with additional insights. I suggest the authors focus on discussing how the existing findings in the paper can inform better strategies for training models."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Q1z6fW3pP4", "forum": "EltjRajCVI", "replyto": "EltjRajCVI", "signatures": ["ICLR.cc/2026/Conference/Submission18763/Reviewer_nJCJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18763/Reviewer_nJCJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761981968328, "cdate": 1761981968328, "tmdate": 1762928491025, "mdate": 1762928491025, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies how language models acquire chess skills when trained on algebraic chess notation. By introducing a disambiguation-aware tokenization scheme and train models of varying depths (5-25 layers) on different datasets to study the emergence of capabilities. They observe clear developmental patterns: shallow models struggle with move legality, while deeper models develop tactical and positional understanding. Models trained on balanced game outcomes consistently outperform those trained only on white-win games."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well-organized and clearly written. \n- The intuition of this paper is great."}, "weaknesses": {"value": "- The largest model studied (25 layers, ~100M parameters) is relatively small by current standards. It's unclear if the observed patterns would hold at scales of billions of parameters. \n- The paper doesn't compare performance against purpose-built chess engines. This makes it difficult to assess overall performance compared to other methods.\n- The paper lacks information about the computing resources needed for training.\n- The paper lacks cast studies."}, "questions": {"value": "Please refer to the \"Weaknesses\" section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "F5o6ueXM6I", "forum": "EltjRajCVI", "replyto": "EltjRajCVI", "signatures": ["ICLR.cc/2026/Conference/Submission18763/Reviewer_8rpj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18763/Reviewer_8rpj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762035364317, "cdate": 1762035364317, "tmdate": 1762928488829, "mdate": 1762928488829, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies how language models acquire chess-playing abilities when trained on algebraic chess notation. The authors introduce a custom disambiguation-aware tokenization scheme and train models of varying depths on datasets. The paper reveals an approach similar to curriculum learning, with rule comprehension emerging early and higher-order abilities following later."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The motivation of the paper is sound. \n- The paper is well-structured with clear method descriptions and results presentation."}, "weaknesses": {"value": "- The paper is titled with \"Large Language Models.\" However, the maximum size of the models trained in the paper is 100M parameters, which is relatively small.\n- As mentioned in Section 5.3, evaluations used only 10 games per configuration, which may limit the robustness of the proposed method, especially for cases like sacrifices or complex tactics.\n- There's no analysis of how the custom tokenization scheme impacts learning compared to other alternatives."}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "mmBeaSCAae", "forum": "EltjRajCVI", "replyto": "EltjRajCVI", "signatures": ["ICLR.cc/2026/Conference/Submission18763/Reviewer_UMvn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18763/Reviewer_UMvn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762044234586, "cdate": 1762044234586, "tmdate": 1762928487852, "mdate": 1762928487852, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}