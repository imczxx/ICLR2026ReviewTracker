{"id": "BDEJA4KVNW", "number": 24606, "cdate": 1758358430883, "mdate": 1759896758576, "content": {"title": "Weighted Deep Ensemble Under Misspecification", "abstract": "Deep neural networks are supported by the universal approximation theorem, which guarantees that sufficiently large architectures can approximate smooth functions. In practice, however, this guarantee holds only under restrictive conditions, and violations of these conditions give rise to model misspecification. We categorize such misspecification into three sources: variable misspecification, arising from insufficiently informative features; structural misspecification, stemming from the limited width and depth of networks that cannot fully capture the underlying complexity; and inherent misspecification, occurring when the true model possesses properties such as discontinuities that cannot be faithfully represented. To mitigate the impact of these forms of misspecification, ensemble methods have become a common strategy for enhancing predictive performance. However, standard ensembles composed of identically architected and equally weighted models may suffer from \"collective blindness\", where shared errors are amplified and lead to systematically biased predictions with high confidence. To mitigate this issue, we introduce weighted deep ensemble method that  learns the optimal weights. We prove that our method provably attains the convergence rate of the best single model in the ensemble and asymptotically achieves oracle-level predictive risk. To the best of our knowledge, this is the first work to provide rigorous theoretical guarantees for weighted deep ensemble under both well-specified and misspecified settings.", "tldr": "We provide rigorous theoretical guarantees for weighted deep ensembles under both well-specified and misspecified settings.", "keywords": ["Deep Ensembles;  Weighted Averaging", "Misspecification; Asymptotic optimality;"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c281e3464c7c0cfa63a62a99d5bd438559c94b35.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The submission is concerned with weighted ensembles of neural networks."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Weighted ensembles of neural networks are a relevant topic."}, "weaknesses": {"value": "## A review and comparison with the state of the art is missing.\n\nA review and comparison with the state of the art is missing.\n\nFirst, weighed ensembles are in no way new. The basic idea goes back to stacking\n\nDavid H. Wolpert. Stacked generalization. Neural Networks, 5(2):241–259, 1992\n\nFor a more neural network focussed paper see for example:\n\nAnders Krogh and Peter Sollich. Statistical mechanics of ensemble learning. Physical Review E, 55(1) 1997.\n\nSecond, there are a lot of papers dealing with — theoretically well motivated — weighting of deep neural networks.\nFor example:\n\nAndrés R. Masegosa. Learning under model misspecification: Applications to variational and ensemble methods.\nIn Advances in Neural Processing Systems (NeurIPS), volume 33, 2020  \n\nLuis A. Ortega, Rafael Cabañas, and Andres Masegosa. Diversity and generalization in neural network ensembles.\nIn International Conference on Artificial Intelligence and Statistics (AISTATS),  2022\n\nThird, there are also generalisation bounds for weighted ensembles, which are applicable to neural network ensembles:\n\nAndrés R. Masegosa, Stephan S. Lorenzen, Christian Igel, and Yevgeny Seldin. Second order PAC-Bayesian\nbounds for the weighted majority vote. In Advances in Neural Processing Systems (NeurIPS), 2020\n\nYi-Shan Wu, Andrés R. Masegosa, Stephan S. Lorenzen, Christian Igel, and Yevgeny Seldin. Chebyshev-Cantelli\nPAC-Bayes-Bennett inequality for the weighted majority vote. In Advances in Neural Processing Systems529\n(NeurIPS), 2021\n\nHauptvogel, Igel. On Uniform, Bayesian, and PAC-Bayesian Deep Ensembles. arXiv:2406.05469 [cs.LG], 2024\n\nIn addition, I was missing a reference to \n\nLars Kai Hansen and Peter Salamon. Neural network ensembles. IEEE Transactions on Pattern Analysis and\nMachine Intelligence, 12(10):993–1001, 1990.\n\n\n## The paper lack mathematical rigour.\n\nThe paper lack mathematical rigour. Examples:\n\nLine 165: incomplete, meaningless statement. Seems like a part of the equation is missing.\n\nLines 180-190: Statement lack rigour: Example makes no sense without stating something about h.\nIn expectation over all hypothesises? \n\nLine 229: Should this be $\\hat{f}$ on the RHS?\n\nCondition 1: $\\epsilon$ is not defined\n\n## There are several misleading statements.\n\nTheorem 1: The theorem only talks about n. Should there not be specific assumptions about n_train and n_val. \nE.g., does this hold for small constant n_val?\n\nJust consider the first three sentences:\n\n„Model misspecification in statistics arises  […]  inclusion of\nirrelevant variables […]. In such cases, the best possible approximation […] still maintains a significant approximation error from the true\nfunction“:  Could you please cite a rigorous  theoretical result that states that adding irrelevant variables must cause a significant approximation error \n\n„In deep learning, the neural networks are always assumed to be well-specified.“: In  general not true. I do not assume that - and I do not know anybody who does.\n\n„To the best of our knowledge, this is the first study to offer a theoretical guarantee for weighted deep ensemble.“: Clearly wrong, see the many reference given above and references therein as starting points.\n\n## General comments\n\nInherent misspecification: How much does this matter on digital computers (aka  „in practice“)?\nThis should be discussed.\n\nWhile I think it is interesting to study weighted neural network ensembles, I have to say that I could not identify exciting novel insights in the manuscript.\nTheorem 1 does not come as a surprise and is not put into relation to other (e.g., PAC-Bayesian) bounds.\n\n\n## Minor comments\n\n* „Ensemble methods is“ -> „Ensemble methods are“\n\n* l 79: Strange references for deep ensembles. Why not not \n\nLars Kai Hansen and Peter Salamon. Neural network ensembles. IEEE Transactions on Pattern Analysis and\nMachine Intelligence, 12(10):993–1001, 1990.\n\nand the later cited \n\nBalaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty\nestimation using deep ensembles. In Advances in Neural Processing Systems (NeurIPS), volume 30, 2017.\n\n* I think the discussion of mode misspecification should go along with a brief discussion of parametric vs non-parametric models.\n* Line 282: Why „without loss of generality“?"}, "questions": {"value": "see \"Weaknesses\" above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "l8jOREFur0", "forum": "BDEJA4KVNW", "replyto": "BDEJA4KVNW", "signatures": ["ICLR.cc/2026/Conference/Submission24606/Reviewer_Afi7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24606/Reviewer_Afi7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24606/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761400061348, "cdate": 1761400061348, "tmdate": 1762943135702, "mdate": 1762943135702, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses a challenge in deep ensemble learning with model misspecification, where the universal approximation does not hold, and proposes an optimal weighted ensemble approach. Typical deep ensemble suffers from collective blindness as they reinforce shared biases, while the proposed weighted deep ensemble strategy can achieve oracle-level optimality. Comprehensive theoretical analysis shows asymptotic bounds for the estimator for regression and classification compared to the best candidate model and convergence under misspecifications. Experiments on synthetic tasks show improvement under various misspecification scenarios."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Interesting problem formulation: Systematic categorization of misspecification in deep learning with rigorous definitions.\n2. Rigorous theoretical guarantees: Provides a formal analysis of the weighted deep ensembles with an asymptotic error bound matching the best candidate, and oracle optimality $R(\\hat{w})/\\inf_w R(w) \\rightarrow 1$. Proofs are technically sound and leverage modern empirical process theory.\n3. Comprehensive numerical validation: Experiments span all three misspecification types with nicely designed ablations."}, "weaknesses": {"value": "1. The proposed algorithm is not new. The idea of of weighted ensemble with learned simplex weights by validation risk minimization has been explored with similar theoretical guarantees, just not on neural networks.\n2. The theory only proves a \"no-regret\" sense of guarantee--the weighted ensemble performs at least as good as the best expert asymptotically. But the author did not investigate the ensemble gain under the weighted ensemble. This is especially important in the misspecification scenarios defined in the paper, where all models suffer from one or more sources of misspecification and are imperfect. The paper did not discuss how the weighted scheme affects the diversity or variance reduction that brings the ensemble gain under equal weight averaging. Even under misspecifications, candidate models may still have uncorrelated errors, which also explains the observed improvement in the numerical experiments.\n3. Experiments are only done on synthetic datasets with shallow networks, which is good for demonstrating how different ensemble strategies perform under various misspecifications. It would be great to see how the algorithm works on standard small-scale vision benchmarks like CIFAR-10 or 100, or Tiny-ImageNet."}, "questions": {"value": "1. This paper is primarily motivated by this notion of collective blindness, but it was not discussed later in the analysis. Can we somehow formalize the collective blindness of equal-weight ensembles through some sort of error decomposition and get a quantitative improvement bound for WDE compared with equal-weight ensembles?\n2. In the proof of Theorem 1, the author leverages a Rademacher complexity term for the simplex with respect to both $M$ and $n$, $r\\sqrt{\\frac{2\\log M}{n}}$. $M$ is omitted in the big-O as the number of ensemble members is finite, and the resulting bound becomes $\\frac{r}{\\sqrt{n}}$. But in practice, the number of ensemble members should somehow scale as a function of $n$, and you can only safely omit it if $M$ grows sub-polynomially with $n$. The author should clarify this somewhere in the paper, as you are deriving asymptotic bounds with $n$ while treating $M$ fixed.\n3. The paper asserted the convexity of the VRM objective in classification because the ensemble is an affine mapping of logs. But this is only true for post-softmax probabilities. If the ensemble averages the logits instead (common practice in ensemble learning), would this break the convexity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YOLSnomNAZ", "forum": "BDEJA4KVNW", "replyto": "BDEJA4KVNW", "signatures": ["ICLR.cc/2026/Conference/Submission24606/Reviewer_uRvF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24606/Reviewer_uRvF"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24606/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761700331403, "cdate": 1761700331403, "tmdate": 1762943135442, "mdate": 1762943135442, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work conducts a theoretical study on Weighted Deep Ensembles, which assume unequal weighting coefficients across ensemble members. In this framework, the ensemble weights are learned through empirical risk minimization on a pre-held validation dataset."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- It appears to be well grounded in existing theoretical results for deep neural networks. In particular, Corollaries 1–3, which provide asymptotic error bounds for practical architectures such as MLPs, CNNs, and RNNs, are quite compelling. Of course, the practical usefulness of such theoretical results remains somewhat unclear, but that’s often the nature of theoretical work.\n\n- From a quick look, the derivations seem sound, and the experimental design appears reasonably solid. I particularly like that Table 4 highlights an important comparison with In-sample and Greedy Ensembles, and Figure 2 nicely shows convergence toward the oracle weights."}, "weaknesses": {"value": "- The method used in this work to determine the weighting coefficients for combining ensemble members’ predictions is a form of stacking (also known as stacked generalization, functional aggregation, and perhaps other related terms, as it has been referred to under various names in the literature). This approach has been extensively studied since the seminal works of Wolpert (1992) and Breiman (1996), with further theoretical developments by Van der Laan et al. (2007), Arsov et al. (2019), Chen et al. (2024), and others. However, this line of research is not discussed at all in the paper. The proposed weighted deep ensemble should explicitly position itself within the stacked generalization framework and clarify both the established findings in this area and its specific contributions in the context of deep neural networks.\n\n- Corollaries 1–3 are presented in a somewhat simplified form in the main text, and although Appendix B.4 offers a slightly more detailed version, it still appears insufficient. It would be beneficial to include a fully formalized version in the appendix that explicitly incorporates the necessary conditions outlined in works such as Jiao et al. (2023). While those formulations, as far as I know, involve a number of intricate and cumbersome assumptions, this work, as a theoretical contribution building upon them, should nonetheless aim to achieve a comparable level of rigor and completeness.\n\n- At present, there is neither empirical nor theoretical validation of the claimed “collective blindness.” The only supporting evidence is the conceptual illustration in Figure 1, which does not pertain to “deep” ensembles. While the authors claim that traditional deep ensembles may suffer from “collective blindness,” this assertion seems questionable given the experimental scale considered here, which can hardly be described as involving truly “deep” ensembles. In my experience, in synthetic setups with small MLPs, ensembles trained from different random initializations through stochastic optimization (i.e., standard recipe for constructing deep ensembles) often exhibit limited diversity, which aligns with the notion of “collective blindness.” However, as the network depth and complexity increase, the highly non-convex nature of the loss landscape tends to induce substantial diversity among ensemble members, and even simple deep ensembles can perform remarkably well, as demonstrated by Fort et al. (2019). Hence, it becomes difficult to argue that “collective blindness” remains a meaningful concern in deep ensemble settings.\n\n- The experimental results seem rather limited to be considered a proper evaluation of a weighted “deep” ensemble. Given the computational constraints, it might be a good idea to extend the results of Wortsman et al. (2022) as a way to demonstrate larger-scale experiments. Their official codebase already provides checkpoints that can be directly used as ensemble components, so there is no need for additional training. Since they have already considered Uniform and Greedy Ensembles, it would suffice to simply add the Weighted Ensemble for comparison.\n\n---\n- Wolpert (1992), Stacked generalization.\n- Breiman (1996), Stacked regressions.\n- Van der Laan et al. (2007), Super learner.\n- Arsov et al. (2019), Stacking and stability.\n- Chen et al. (2024), Error reduction from stacked regressions.\n- Fort et al. (2019), Deep ensembles: a loss landscape perspective.\n- Wortsman et al. (2022), Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time."}, "questions": {"value": "- Incomplete statement on line 164?\n- How were the oracle weights in Figure 2 obtained?\n- If the validation split (2 out of the 6:2:2 split) is used to “train” the weighting coefficients in WDE, then it is effectively being used as part of the ensemble “training” process. What if a standard deep ensemble is trained using the combined training and validation splits, since that data could alternatively be used to train the ensemble members rather than the ensemble weights?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lpRw69mXKP", "forum": "BDEJA4KVNW", "replyto": "BDEJA4KVNW", "signatures": ["ICLR.cc/2026/Conference/Submission24606/Reviewer_iDai"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24606/Reviewer_iDai"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24606/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979554346, "cdate": 1761979554346, "tmdate": 1762943134166, "mdate": 1762943134166, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper first defines three different kinds of model misspecifications, which if they occur in particular lead to traditional guarantees like universal approximation theorems for deep neural networks not holding. They furthermore argue that traditional ensembles, made up of models with identical architectures and each weighted equally, are also impacted by this issue since if every submodel is biased, this will usually lead to highly confident, systematically biased predictions of the ensemble. To address this issue, they propose and analyze the weighted deep ensemble method, which trains ensembles consisting of different models and optimizes the weights of the different ensemble members to optimize the error on the validation set. They prove that the ensemble achieves the convergence rate of the best model in the ensemble and empirically demonstrate the effectiveness of the method on synthetic datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The story of the paper was relatively clear and the paper was well-organized.\n- By investigating the question when the assumptions of traditional machine learning approximation results fail to hold, the paper is making progress and bringing more attention to a very relevant question.\n- Furthermore, by providing the weighted ensemble method, they also provide a new way of addressing the issues they point out. The analyses of the theoretical properties (i.e., showing both asymptotic error bounds and asymptotic optimality in certain cases) of the weighted ensemble method is original and insightful."}, "weaknesses": {"value": "The paper claims that they are 'introduc[ing] [the] weighted deep ensemble method that learns the optimal weights'. At the same time, in the related work section, they state that 'recent studies have delved into weighted deep ensemble', but do not provide much more detail about these methods although this would be relevant to judge what exactly is novel in the paper. \nFurthermore, it would be relevant and interesting to also see the performance of their method on non-synthetic datasets (and with models trained on these tasks) to investigate whether they can also provide significant advantages in real-world settings and potentially on more not misspecified settings."}, "questions": {"value": "1. Could you clarify what kind of work has been done on weighted ensembles before? What are the key differences of your work from previous work on this topic? \n2. In line 165, is $f_0(x)-g(\\pi(\\boldsymbol{X}))$ supposed to be $0$ almost surely? \n3. Could you make the following statement more formal or illustrate it a bit more clearly: \n> As stated before, traditional deep ensembles may suffer from \"collective blindness\" in the presence of variable, structural, or inherent misspecification. \n4. We use our validation data to fit the weights of the ensemble, correct? Would this in the case of many different ensemble members lead to overfitting on the validation data? Could we then still use the same validation data for hyperparameter tuning, etc.? \n5. Why do we need Conditions 1 and 2 for Theorem 3? What would lead to the Theorem not holding anymore if we relax these conditions? \n6. Why did you decide not to additionally test your methods on real-world datasets or mode widely on non-misspecified settings?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wuwKRnjnhg", "forum": "BDEJA4KVNW", "replyto": "BDEJA4KVNW", "signatures": ["ICLR.cc/2026/Conference/Submission24606/Reviewer_DdZD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24606/Reviewer_DdZD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24606/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995285617, "cdate": 1761995285617, "tmdate": 1762943133776, "mdate": 1762943133776, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}