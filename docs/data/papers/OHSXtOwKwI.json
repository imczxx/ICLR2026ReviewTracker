{"id": "OHSXtOwKwI", "number": 19098, "cdate": 1758293566810, "mdate": 1759897059557, "content": {"title": "Load Balancing Neurons: Controlling Firing Rates Improves Plasticity in Continual Learning", "abstract": "Neural networks in continual learning often lose plasticity: some neurons become inactive, while others fire almost constantly. This limits adaptation to shifting data and wastes capacity. Prior work mitigates this by periodically reinitializing low-utility units, but such resets can destroy previously learned features and do not proactively prevent low utility. We study a simple diagnostic measure: the firing rate of ReLU units, defined as the fraction of positive pre-activations. Low rates identify dead units, while very high rates indicate linearized, always-on units. Based on this view, we introduce a lightweight load-balancing mechanism that adjusts per-neuron thresholds to keep firing rates within a target range. Across Continual ImageNet and Class-incremental CIFAR-100, improvements in firing-rate distributions help explain differences in plasticity across approaches, including our load-balancing mechanism and well-known techniques, notably L2 regularization and non-affine normalization.", "tldr": "", "keywords": ["Continual learning", "Plasticity", "Firing rate"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/24d1671ae86cea7a15757ca7e3a0ffbad0967bd0.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "In this paper the authors argue that neuron firing rates (fraction of positive pre-activations for ReLU-like units) provide a simple, interpretable lens on plasticity loss in continual learning. They document how standard training drives many units to dead (≈0%) or always-on (≈100%) states, and they correlate with balanced activation with improved adaptation. \n\nBuilding on this, the authors propose a lightweight load-balancing (LB) layer that adds a per-neuron, stop-gradient offset β before ReLU and updates it with a tiny controller to keep each neuron’s exponentially averaged firing rate ρˉ within target bounds (e.g., 40–60% or exactly 50%). \n\nAcross Continual ImageNet (binary class stream) and class-incremental CIFAR-100, LB improves accuracy over strong baselines (BatchNorm+L2, resets, and CBP), and the paper further shows that non-affine normalization and normalized skip connections naturally steer firing rates toward balanced regimes and also help. There are small studies with LeakyReLU/GELU and an RL demo on DemonAttack (DQN) suggesting similar trends. Code snippets and detailed training protocols are provided in the appendix."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- Clear and interpretable diagnostic. Firing-rate distributions over tasks/layers reveal dead/linearized regimes and track plasticity dynamics better than scalar “dormancy” alone. The layer-wise heatmaps are especially informative. \n\n- Simple, low-overhead mechanism. The LB layer (stop-gradient offset with EMA-based controller) is easy to drop-in, architecture-agnostic, and empirically effective with tiny step sizes and bounds.\n\n- Consistent gains across setups. On Continual ImageNet and CIFAR-100 CIL, LB (40–60% or 50%) improves over BN+L2, resets, and often CBP. The tables summarize statistically stable gains.\n\n- Architectural guidance. The authors infer that under non-affine normalization and normalized skip connections push firing rates toward balanced regimes and can match or exceed CBP, offering alternative routes when LB is undesirable.\n\n- Transparency & scope. Training details, implementation notes, sensitivity to activations, and an RL probe broaden credibility. The LLM usage is explicitly disclosed."}, "weaknesses": {"value": "- The theoretical justification remains local. The 50% target is motivated by per-neuron entropy; the paper acknowledges that joint entropy/correlation matters but does not measure it. Some empirical cases (non-affine LayerNorm) suggest layer-dependent optima instead of a universal 50%. A small study of inter-neuron correlations / total correlation would strengthen the story. \n\n- Bound & sensitivity of the controller. The LB controller uses fixed α,τ,[ρmin⁡,ρmax⁡]. There is limited analysis of stability/sensitivity to these hyperparameters across tasks/architectures, class imbalance, or nonstationarity patterns.\n\n- Broader CL baselines. The comparisons focus on CBP, resets, BN/LN(+L2). Missing are rehearsal-based and regularization-based class-incremental baselines (e.g., ER-ACE/DER++, EWC/SI, LwF/distillation, prompt/adapters), which might help to contextualize practical competitiveness.\n\n- Potential interaction with biases/norms. Figures suggest weight/bias magnitudes shift under LB (BN bias competition). A brief calibration/regularization analysis (e.g., weight decay placement) might be the way that can help practitioners."}, "questions": {"value": "- Controller robustness. How sensitive are gains to α, τ, and the band [ρmin⁡,ρmax⁡]? Would be nice if the authors provide a grid on CIFAR-100 CIL and Continual ImageNet, including tighter/looser bands and varied EMA half-lives. \n\n- When not to use 50%? Non-affine LN appears to benefit from broader, layer-varying firing-rate distributions, and enforcing 50% might lead to reduced accuracy. Would a layer-adaptive target (e.g., via percentiles or learned priors) be valuable, can the authors elaborate/explain on the benefits (or report results)? \n\n- Correlations across units. Would be nice to see total correlation / redundancy among activation states to complement the marginal-entropy view and test whether LB reduces harmful correlations.\n\n- Compatibility with rehearsal / adapters. How does LB interact with experience replay (balanced buffers) or adapter/prompt methods? \n\n- Conv vs. FC placement. The authors show 1D/conv variants. Any cases where inserting LB after vs. before normalization helps/hurts? The work might benefit from clarifying the recommended placement when norms are absent or affine."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A."}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PnttcP01ow", "forum": "OHSXtOwKwI", "replyto": "OHSXtOwKwI", "signatures": ["ICLR.cc/2026/Conference/Submission19098/Reviewer_EQ9A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19098/Reviewer_EQ9A"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19098/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761913633848, "cdate": 1761913633848, "tmdate": 1762931122073, "mdate": 1762931122073, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper analyses plasticity loss from the perspective of neuron firing rates. The authors posit that a neuron carries maximum information when the entropy of the indicator of firing is maximized; which is precisely at a firing rate of 50%. The authors introduce the load balancing mechanism that biases each neuron towards a range of target firing rates. Training a ResNet-18 on the Continual ImageNet and Class Incremental CIFAR 100 continual learning benchmark problems, the authors show that firing rates that deviate away from 50% are a correlate of plasticity loss and that their proposed load balancing method maintains the target firing rate while improving plasticity over competitor continual learning interventions. Additionally, the authors briefly analyze normalization schemes, remarking that the success of these methods can be tied to their ability to perform “load balancing”."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well written and clear.\n- The manner in which the authors analyze plasticity loss through firing rates is simple and avoids unnecessary abstractions. Motivating the optimal firing rate of 50% through the lens of maximizing the information of a neuron is intuitive and simple. Connecting firing rates to neuron death in conjunction with teh analysis of normalization schemes under this framework is a positive unification of existing work. \n- The presentation of the experimental results is relatively clear and supports the claims of the paper."}, "weaknesses": {"value": "- The paper claims to introduce neuron firing rates to the analysis of plasticity loss. However, there is existing work [2] that casts the problem of identifying dead neurons as that of identifying neurons whose firing rates have effectively halted. It would be useful to cite this work and juxtapose its analysis and the Self Normalized Resets (SNR) algorithm with that of the authors’ analysis and the load balancing method.\n- While the lens of firing rates is interesting, it is not entirely novel (see the point above). For instance, it is not clear if a decline in the firing rate is not simply another way of describing neuron death. It would be useful in the main body to showcase when deviations from the optimal firing rate are synonymous with neuron death and when they are not. In fact, almost all of the plots with side-by-side firing rates and loss/accuracy, show that plasticity loss is associated with a collapse in the firing rate, which is essentially neuron death. However, the authors make the point that a suboptimal firing rate could be above 50%, but none of the empirical evidence demonstrates that this occurs.\n- Crucially, the claims of the paper would be strengthened if additional competitor algorithms were evaluated against load balancing. For instance, only a single continual reset scheme, CBP, is evaluated, but ReDO [1] and SNR [2] have not been evaluated. Given how tangential SNR is to load balancing and its robust performance, it would be useful to consider this method. Additionally, L2 Init [3] would also be critical to evaluate as this is a simple, robust, and effective regularization based approach for mitigating plasticity loss. It would be worthwhile to investigate neuron firing rates under L2 Init.\n- The paper considers a limited number of benchmark problems: only Continual ImageNet and Class Incremental CIFAR 100. Evaluating load balancing on more benchmarks would strengthen the results.\n- The paper considers only a CNN and a ResNet-18 architecture. Additional architectures in the experiments would be useful, such as a ViT. \n- It would be useful to have a section (say in the appendix) listing the hyperparameters used in the experiments and how they were selected. Were competitor algorithms tuned fairly against load balancing, beyond simply using the same hyperparameters from prior literature?\n- The empirical results show a minor improvement in loss/accuracy with load balancing over competitor methods. Given how minor the improvement is, along with limited set of competitor methods, architectures, and benchmark problems evaluated along with a lack of details of hyperparameter tuning, the efficacy of load balancing is in question.\n\n\n[1] Sokar, Ghada, et al. \"The dormant neuron phenomenon in deep reinforcement learning.\" International Conference on Machine Learning. PMLR, 2023.\n[2] Farias, Vivek F., and Adam D. Jozefiak. \"Self-normalized resets for plasticity in continual learning.\" arXiv preprint arXiv:2410.20098 (2024).\n[3] Kumar, Saurabh, Henrik Marklund, and Benjamin Van Roy. \"Maintaining plasticity in continual learning via regenerative regularization.\" arXiv preprint arXiv:2308.11958 (2023)."}, "questions": {"value": "Related to the issue of hyperparameters, do the experiments use SGD or Adam and with what learning rate?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VaHEPb6IJJ", "forum": "OHSXtOwKwI", "replyto": "OHSXtOwKwI", "signatures": ["ICLR.cc/2026/Conference/Submission19098/Reviewer_UUtk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19098/Reviewer_UUtk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19098/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761938611260, "cdate": 1761938611260, "tmdate": 1762931121721, "mdate": 1762931121721, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "## Summary \n* The paper proposes a firing-rate analysis based on neuron activation probabilities and demonstrates that it can serve as a lightweight tool to diagnose plasticity loss.\n* It further introduces a load-balancing method that mitigates plasticity loss by explicitly controlling firing rates.\n* Through continual learning and reinforcement learning experiments, the paper shows the effectiveness of the proposed approach.\n\n## Pros \n* Proposes a simple and intuitive new diagnostic tool for plasticity loss.\n* Conducts experiments and analyses on established benchmarks for assessing plasticity loss, including continual ImageNet, class-incremental CIFAR-100, and a reinforcement learning setting.\n\n## Cons \n* Insufficient analysis of the proposed load-balancing method itself.\n* Experimental scope is limited and focuses on a specific architecture.\n* Some details are missing from the main text."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- (originality) Proposes firing rate as a new metric for measuring plasticity. This metric unifies two known phenomena arising from plasticity loss—dormant neurons and linearized neurons—and is highly intuitive.\n- (quality) The paper uses appropriate baselines in experiments. In addition to methods proposed by prior work, it also considers common training variants such as BN+L2, clarifying the interpretation of results.\n- (clarity) Both the proposed metric and methodology are clearly described; the experimental settings and results are easy to understand.\n- (significance) Beyond the specific method, the paper explores architectural design choices that can naturally induce balanced firing rates, suggesting broad applicability."}, "weaknesses": {"value": "- The proposed methodology relies on adding a normalization layer, which is a limitation; the paper does not discuss the additional computational cost.\n- [Sec 3.1] The claim that the optimal firing rate is 50% lacks theoretical justification. Is there evidence that maximizing mutual information leads to improved plasticity? If we interpret the firing rate as an activation probability, doesn’t enforcing it risk constraining model expressivity?\n- [Sec 5] The experimental scope is too limited. In particular, the RL study uses only a single task and does not include comparisons with methods such as CBP.\n- [Sec 5.2] The reinforcement learning experiment lacks results and analysis in the main text; at minimum, a brief discussion is needed.\n- The paper omits analyses of several recently discussed plasticity-related metrics. Including additional indicators such as spectral norm and gradient covariance would strengthen the study [R1].\n[R1] Alex Lewandowski et al., Learning Continually by Spectral Regularization, ICLR 2025."}, "questions": {"value": "- [L296] What is the rationale for choosing $\\alpha = 0.001$, and how does the actual $\\rho$ value change after the shift?\n- [L302] After applying Load Balancing and BatchNorm, isn’t the resulting functional change too large? Although CBP is described as a reset-based method, it induces little functional change in practice.\n- [L302] What is the reason for applying L2?\n- [Figure 3–4] What happens if BatchNorm and L2 are also applied to CBP? Do we obtain essentially the same performance as simply applying L2 to CBP?\n- The defined neuron activity appears to reflect each neuron’s contribution to learning, but a neuron with low activity may still encode important information. Have you examined weight utility or related measures?\n- [Sec 4] Could the optimal firing rate be neuron-specific? Farias and Jozefiak [R2] highlight that activation probabilities can vary across neurons.\n\n[R2] Vivek Farias and Adam Daniel Jozefiak, Self-Normalized Resets for Plasticity in Continual Learning, ICLR 2025."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "j3VuH4F3E5", "forum": "OHSXtOwKwI", "replyto": "OHSXtOwKwI", "signatures": ["ICLR.cc/2026/Conference/Submission19098/Reviewer_nCj4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19098/Reviewer_nCj4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19098/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982548065, "cdate": 1761982548065, "tmdate": 1762931121390, "mdate": 1762931121390, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper reframes plasticity loss as an imbalance in neuron activity, units either drift toward dead or always-on regimes. The authors argue that the firing rate (fraction of positive pre-activations) is a simple, layer-agnostic diagnostic to track and prevent this collapse. It motivates an information-theoretic target of 50% firing, maximizing the entropy of the binary activation of each ReLU. Building on this lens, the authors propose a lightweight load-balancing layer that adds a per-neuron, stop-gradient offset before the ReLU and updates it up/down after each batch so the long-term firing rate stays within chosen bounds (e.g., 40–60% or exactly 50%). On Continual and class-incremental CIFAR-100, constraining firing rates to intermediate ranges improves accuracy over baseline methods. The analysis further connects architectural choices to the same principle: non-affine normalization and normalized skip connections implicitly center or stabilize pre-activations, producing more balanced firing distributions."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Identifying neuron firing rates as being a correlate of plasticity is somewhat novel, albeit, tightly correlated with the well documented phenomenon of neuron death. \n- The connection between neuron death and normalization schemes through the lens of neuron firing rates is a strength this paper, as this unifies two strategies for mitigating plasticity loss: neuron resets and normalization.\n- The main body is clear and avoids unnecessary jargon and abstractions. For instance, the intuition regarding targeting an optimal firing rate of 50% is very approachable."}, "weaknesses": {"value": "- It would be nice if some theory could be derived regarding the choice of targeting a firing rate of 50%. While the information theoretic argument provides good intuition, it is not clear that this is optimal for all architectures, model sizes, and environments. \n- To strengthen the claims of the paper, the authors should consider expanding their experiments: more continual learning benchmark problems, more architectures, such as a transformer architecture, and comparing against more competitor algorithms, such as additional reset schemes and regularization schemes.\n- There is a recent work on Self Normalized Resets that similarly analyzes the firing rates of neurons and derives a reset scheme based on such information. It would be useful if the authors could contrast their analysis and approach against this method.\n- One critique of the overall message: it is not clear that deviating from an optimal firing rate is distinct from neuron death. In addition, most of the experiments seem to illustrate a decline in neuron firing rates when plasticity loss is present."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jp28Nwmg08", "forum": "OHSXtOwKwI", "replyto": "OHSXtOwKwI", "signatures": ["ICLR.cc/2026/Conference/Submission19098/Reviewer_vFaN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19098/Reviewer_vFaN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19098/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762053528492, "cdate": 1762053528492, "tmdate": 1762931121049, "mdate": 1762931121049, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}