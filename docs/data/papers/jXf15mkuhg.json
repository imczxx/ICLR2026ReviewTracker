{"id": "jXf15mkuhg", "number": 18427, "cdate": 1758287692966, "mdate": 1759897104351, "content": {"title": "EMERGE: A Benchmark for Updating Knowledge Graphs with Emerging Textual Knowledge", "abstract": "Knowledge Graphs (KGs) are structured knowledge repositories containing entities and relations between them. In this paper, we investigate the problem of automatically updating KGs over time with respect to the evolution of knowledge in unstructured textual sources. This problem requires identifying a wide range of update operations based on the state of an existing KG at a specific point in time. This contrasts with traditional information extraction pipelines, which extract knowledge from text independently of the current state of a KG. To address this challenge, we propose a method for construction of a dataset consisting of Wikidata KG snapshots over time and Wikipedia passages paired with the corresponding edit operations that they induce in a particular KG snapshot. The resulting dataset comprises 233K Wikipedia passages aligned with a total of 1.45 million KG edits over 7 different yearly snapshots of Wikidata from 2019 to 2025. Our experimental results highlight challenges in updating KG snapshots based on emerging textual knowledge, particularly the integration of knowledge between text and KGs, positioning the dataset as a valuable benchmark for future research. We will publicly release our dataset and model implementations.", "tldr": "A new dataset aligning KG updates with emerging textual knowledge, introducing operations for updating KGs from evolving textual sources.", "keywords": ["knowledge base construction", "named entity recognition and relation extraction", "entity linking/disambiguation"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/170e9e95e760feeddd0f690b8146d2754a7569f9.pdf", "supplementary_material": "/attachment/204e53a207da60371930e22f5f1b27bda1246813.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces EMERGE, a large-scale benchmark designed for studying how knowledge graphs can be automatically updated with new information from unstructured text sources such as Wikipedia. Unlike most static datasets, EMERGE aligns evolving Wikipedia passages with temporal Wikidata snapshots, producing over 233K passages and 1.45 million text-driven KG update operations. These operations include adding, modifying, and deprecating triples to reflect newly emerging knowledge."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1.\tComprehensive related works are mentioned to position it within the broader research landscape including knowledge graph completion, refinement, and information extraction.\n\n2.\tThe experimental settings and evaluation details are provided, allowing for clearly understanding of the resource.\n\n3.\tThe paper is generally clearly-written and easy to follow."}, "weaknesses": {"value": "1.\tThe practical utility of the resource remains unclear. More concrete use cases, applications, or empirical demonstrations are needed to justify its real-world usefulness.\n\n2.\tThe work focuses solely on factual updates (new or deprecated triples) while not considering schema-level or structural modifications, such as ontology changes, entity merges, or property reorganizations.\n\n3.\tThe dataset is limited to entities presented in Wikidata while omitting literal values (e.g., numerical or date attributes), constraining its applicability to many factual domains.\n\n4.\tThe benchmark evaluation only reports recall/completeness without precision or F1, which reduces the comprehensiveness of performance assessment under open-world assumptions.\n\n5.\tThe dataset assumes synchronized temporal windows between textual and KG updates, however in practice, Wikipedia and Wikidata could diverge significantly in update timing."}, "questions": {"value": "1.\tHow can this resource be effectively leveraged by other research communities or real-world applications? In what ways does it offer measurable advantages over existing datasets?\n\n2.\tWhat is the unique benefit of EMERGE compared to directly utilizing sequential Wikidata snapshots for temporal KG analysis?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "QEaQaC3z14", "forum": "jXf15mkuhg", "replyto": "jXf15mkuhg", "signatures": ["ICLR.cc/2026/Conference/Submission18427/Reviewer_pLRm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18427/Reviewer_pLRm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18427/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760532423587, "cdate": 1760532423587, "tmdate": 1762928124120, "mdate": 1762928124120, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of how to correctly map newly emerging textual facts to the required updates of a knowledge graph (KG) at a specific point in time. The authors formalize the Text-driven Knowledge Graph Updating (TKGU) task and define five update operation types: X-Triples, E-Triples, EE-Triples, EE-KG-Triples, and D-Triples. They further construct EMERGE, a large-scale and incrementally extensible benchmark aligned between Wikipedia text and weekly deltas of Wikidata, spanning 2019–2025 with 233K instances and ~1.45M KG update operations. Using two families of advanced information extraction baselines, they conduct systematic evaluation across multiple snapshots and temporal deltas, showing that existing IE/LLM methods struggle with connecting emerging entities back to the KG and with fact revocation operations. In addition, performance degradation increases with larger deltas, indicating that EMERGE reveals realistic capability gaps in dynamic KG maintenance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "S1: The paper not only proposes the direction of “text-driven KG updating” but also formalizes the task into five concrete TKGU operations (Section 3). With clear examples (Figure 1), the classification criteria are explicit and allow direct validation and quantification, going beyond generic triple extraction.\n\nS2: EMERGE covers seven yearly snapshots (2019–2025) and up to five-week cumulative deltas per snapshot, totaling 233K instances and ~1.45M updates, with significant growth in KG entities and relations over time. This provides a solid foundation for studying robustness to temporal evolution and schema drift.\n\nS3: The benchmark construction leverages Wikipedia/Wikidata historical dumps and includes weekly snapshot/delta generation, text–KG alignment, and data curation pipelines. Cleaning rules and rollback filtering strategies are documented, supporting extensibility and reproducibility.\n\nS4: The evaluation is detailed across different models, snapshots, and deltas using completeness/recall metrics (Table 2, Figure 3, Appendix). Qualitative failure examples (Appendix E) help identify future research directions (e.g., the need for models to exploit KG structure rather than text alone)."}, "weaknesses": {"value": "W1: Although Meta-Llama-3.1 is used to filter alignment pairs efficiently, details of the LLM filtering process—thresholds, prompt designs, and rules for marking updates as “unsupported”—are insufficiently provided, affecting interpretability and reproducibility of the dataset.\n\nW2: D-Triples constitute only 0.6% of the full dataset (3.3% in the subsampled test set), and their correctness often relies on KG-level reasoning. The imbalance and uncertainty make the evaluation unstable, and the paper does not demonstrate mitigation strategies for potential misjudgment or skewed metrics.\n\nW3: EE-KG-Triples rely on external KG knowledge or schema assumptions (e.g., typing a new entity as Human). Many such links are not textually supported, yet the paper does not provide a clear evaluation protocol or manual validation rate to confirm their accuracy.\n\nW4: Closed-IE ReLiK models and open-generation EDC+ differ significantly in the amount of KG information provided (entity/relation dictionaries vs. prompt-based access). The comparison risks conflating model capabilities with differences in provided prior knowledge.\n\nW5: The definitions of EE-KG and D-Triples are introduced without intuitive examples in the main paper, leaving readers dependent on the Appendix for clarity.\n\nW6: Section 4 (dataset construction) is disproportionately long, while Section 5 (analysis) offers limited error type exploration and insufficient discussion of challenge sources."}, "questions": {"value": "Q1: How are the non-textually supported EE-KG links retained (fully Wikidata-driven?), and can the authors provide manual evaluation results (accuracy, common error types) for a small EE-KG sample?\n\nQ2: The authors state that code/data will be released after acceptance, but even in the anonymized version, please provide: data format specification (JSON schema), alignment output examples.\n\nQ3: Could the authors clarify whether D-Triples rely strictly on explicit deletion operations or also semantic overrides? Please also provide Cohen’s κ / F1 from human annotation if available."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9u8wo7iuhK", "forum": "jXf15mkuhg", "replyto": "jXf15mkuhg", "signatures": ["ICLR.cc/2026/Conference/Submission18427/Reviewer_V2ha"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18427/Reviewer_V2ha"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18427/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969392798, "cdate": 1761969392798, "tmdate": 1762928123752, "mdate": 1762928123752, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a pipeline as well as a benchmark dataset for the updates in the knowledge graphs."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "--> The pipeline for automated updates from text could be a useful tool to integrate for the live updates of the major general purpose knowledge graphs such as Wikidata or DBpedia."}, "weaknesses": {"value": "- In the abstract the authors could give a bit of the introduction of how is the framework implemented.\n- The interchangeable use of the terms knowledge graphs and knowledge bases is quite well known, it does not need to be explicitly said in footnote 2.\n- There are many other datasets available for KG completion such as LiterallyWikidata [1] or Codex [2], etc.\n- The authors are discussing the SoTA on KG Completion but this task is not discussed later on or the framework is not evaluated on that task. Why are the authors relating this task to that family of algorithms?\n- Why is the SoTA on information extraction is discussed since this is also not the main focus, the main focus is on how to handle updates in the knowledge graph.\n- the authors should also discuss the methods for ontology versioning, etc. in the SoTA and make a clear distinction [3].\n- The authors should keep in mind that Wikidata is also crowdsourced on top of containing the information from Wikipedia.\n- The part on \"Emerging entities to KG triples...\" discusses about \"instanceOf\" relation which is a different problem, i.e., entity typing and adding new instances to an entity.\n- The example of deprecated triple seems misleading. If a person stops being a member of a club then there should be added an end date because the fact doesn't change it just expires overtime.\n\n[1] https://link.springer.com/chapter/10.1007/978-3-030-88361-4_30 \n[2] https://arxiv.org/pdf/2009.07810 \n[3] https://arxiv.org/pdf/2409.04572"}, "questions": {"value": "- The authors are discussing the SoTA on KG Completion but this task is not discussed later on or the framework is not evaluated on that task. Why are the authors relating this task to that family of algorithms?\n- Why is the SoTA on information extraction is discussed since this is also not the main focus, the main focus is on how to handle updates in the knowledge graph? It should talk about Entity Linking algorithms and the existing dataset which suffer from the updates in the KG.\n- Overall, the problem statement of the paper is a bit confusing. The pipeline is for updates in the knowledge graph with a dataset which enriches the Knowledge Graph with updated information but the evaluation seems to be on entity linking which is another problem linked with updated knowledge graphs and the text on which the entity linking is performed.\n- the paper might be a better fit for the evaluations on dynamic knowledge graph completion."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Rdp63pBq7D", "forum": "jXf15mkuhg", "replyto": "jXf15mkuhg", "signatures": ["ICLR.cc/2026/Conference/Submission18427/Reviewer_wRHi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18427/Reviewer_wRHi"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18427/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762091299745, "cdate": 1762091299745, "tmdate": 1762928123393, "mdate": 1762928123393, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}