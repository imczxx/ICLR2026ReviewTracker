{"id": "zvHqmW4NkP", "number": 21201, "cdate": 1758314841705, "mdate": 1763617456039, "content": {"title": "Deep Reflection Hinting: Leveraging Offline Knowledge for Improving LLM Agents Adaptation", "abstract": "Large language model (LLM) agents perform well in sequential decision-making tasks, but improving them on unfamiliar domains often requires costly online interactions or fine-tuning on large expert datasets. These strategies are impractical for closed-source models and expensive for open-source ones, with risks of catastrophic forgetting. Offline trajectories offer reusable knowledge, yet demonstration-based methods struggle because raw traces are long, noisy, and tied to specific tasks. We present \\emph{Deep Reflection Hinter (DR.Hinter)}, an agentic system that distills offline traces into compact, context-aware hints. A zooming mechanism highlights decisive steps in long trajectories, capturing both strategies and pitfalls. Unlike prior methods, DR.Hinter leverages both successful and failed trajectories, extracting guidance even when only failure data is available, while supporting parallelized hint generation and benchmark-independent prompting. At inference, a retriever selects relevant hints for the current state, providing targeted guidance with transparency and traceability. Experiments on MiniWoB++, WorkArena, and WebArena Lite show that DR.Hinter consistently outperforms strong baselines, including human- and document-based hints.", "tldr": "Deep Reflection Hinting (DRH) improves LLM agents by distilling offline trajectories, documents, and instructions into transparent, reusable hints that enhance adaptation and generalization without fine-tuning.", "keywords": ["LLM agents", "Web agents", "Retrieval-Augmented Generation"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b26fbee0ca882a0d99d66f0b517d4c5f6e142bfc.pdf", "supplementary_material": "/attachment/b85c0ee7ffb6c9f8770ffbc70a2e757cb4923ed3.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces DR. HINTER, an agentic framework that turns offline trajectories—both successful and failed—into compact, reusable natural-language hints to improve LLM agents without fine-tuning. A zooming module identifies critical decision points within long traces, and a reflection step distills these segments into strategy and pitfall hints, each indexed by a semantic key for retrieval. Hints can be generated from single traces, contrastive pairs, or multi-trace aggregates, enabling coverage even when only failures exist, and are retrieved at inference either step-by-step (contextual) or once per episode (goal-conditioned). This approach is benchmark-independent, scalable, and transparent, and it supports closed-source models by shifting computation offline to a more capable “hinter” model. Across MiniWoB++, WorkArena-L1, and WebArena-Lite, DR. HINTER consistently outperforms ReAct and an AutoGuide reimplementation, sustains competitive out-of-task generalization, and proves more practical than documentation or human-authored hints. Ablations show that zooming improves hint quality and larger hinter models yield further gains, especially on long-horizon tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The general idea to distill off-line traces into compact hints looks promising.\n2. Some designs like zooming and extracting hints from both successful and failure trajectories sound practical\n3. The writing is clear in general."}, "weaknesses": {"value": "1. I think the experimental setting is not very good. Based on the descriptions from line 252-275, the authors seems to collect trajectories from benchmark data. Even in out-of-task generalization, the hints from other tasks on the same datasets are used, which means they use hints of similar tasks in the same distribution in the evaluation. In WebArena, the benchmark uses task templates to construct tasks, where multiple tasks only differ in a few values, while the trajectories to complete them are very similar. I think this gives the question about whether the results are overfitting and how the proposed methods can be applied in general tasks.\n2. The experiments remain the GPT5--nano and GPT5-mini, but the effectiveness on more powerful models like GPT-5 or Claude-4.1 remain unclear.\n3. From example in Appendix E.2, I feel that the generated hints are specific to certain tasks. It would be better to further abstract hints or scale the number of hints to make this mechanism generalizable."}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7TSZgoIs6n", "forum": "zvHqmW4NkP", "replyto": "zvHqmW4NkP", "signatures": ["ICLR.cc/2026/Conference/Submission21201/Reviewer_iAEN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21201/Reviewer_iAEN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21201/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761595500157, "cdate": 1761595500157, "tmdate": 1762941608848, "mdate": 1762941608848, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Deep Reflection Hinter (DR.HINTER), an agentic system that distills offline trajectories into explicit, context-aware hints. DR.HINTER is capable of extracting hints from both successful and failed trajectories simultaneously. Experiments on MiniWoB++, WorkArena-L1, and WebArena-Lite show that DR.HINTER's method outperforms ReAct and AutoGuide, demonstrating the high efficiency of the proposed approach."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The proposed method has strong generality. The author consider the scenario in practical applications where only failed trajectories might be available.\n\n* The proposed method has strong interpretability. The Case Study in Section 5.4 makes it easy to understand the reasons for the method's effectiveness.\n\n* The paper provides a detailed description of the method's design and prompt design, which facilitates reproducibility."}, "weaknesses": {"value": "* A key innovation of this work is the ability to utilize both successful and failed trajectories. However, some existing works also emphasize the ability to extract experience from failed trajectories to guide subsequent inference, such as Automanual [1]. This paper lacks a comparison and experimental contrast with these works.\n\n* Another innovation of this work is the design of the zooming mechanism. However, the paper only proves the importance of this step through ablation experiments and lacks an interpretability analysis or qualitative analysis of this step. For example, it is unclear whether the zooming mechanism would still provide benefits if using large models that support long contexts, such as GPT-5, as the complete trajectory could also provide richer information.\n\n* The paper only verifies that the method achieves performance improvements on GPT-5-Nano and GPT-5-Mini. It lacks experimental analysis on larger models like GPT-5, Gemini 2.5 Pro, and state-of-the-art open-source models like Qwen3-8B.\n\n* A significant advantage of improving model performance through context is strong generalization. However, this paper conducts limited generalization experiments. For instance, the paper should experiment with whether hints obtained on MiniWob++ can be applied to other benchmarks of the same type.\n\n[1] Minghao Chen, Yihang Li, et.al. \"AutoManual: Constructing Instruction Manuals by LLM Agents via Interactive Environmental Learning\""}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "sMi8UxP0bx", "forum": "zvHqmW4NkP", "replyto": "zvHqmW4NkP", "signatures": ["ICLR.cc/2026/Conference/Submission21201/Reviewer_YdbX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21201/Reviewer_YdbX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21201/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761867375219, "cdate": 1761867375219, "tmdate": 1762941608221, "mdate": 1762941608221, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Deep Reflection Hinting (DR. HINTER), an offline pipeline that distills agent trajectories—successful and unsuccessful—into natural-language hints keyed by semantic summaries for retrieval at inference time. The pipeline has three main stages: (i) Zoom & Reflect, which identifies critical steps within long traces and prompts an LLM (“hinter”) to produce step-focused guidance; (ii) Hint indexing via semantic keys; and (iii) Retrieve & Act, which injects hints either once per episode (goal-conditioned) or per step (context-conditioned). Experiments on MiniWoB++, WorkArena-L1, and WebArena-Lite report gains over ReAct and AutoGuide; ablations assess out-of-task generalization, the effect of larger hinters, and documentation/human-hint baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The paper provides a clear, modular pipeline with ablations to justify some choices (e.g., LLM “zooming”), and the episode- vs. step-level retrieval modes are well-motivated.  \n* The method leverages failed trajectories to mine “what not to do,” enabling hint creation even when no success trace exists—useful in low-success regimes.  \n* Broad evaluation across three web-agent benchmarks, including documentation and human-hint comparisons; out-of-task results and hinter-scaling ablations further add empirical soundness.  \n* Qualitative case studies in the appendix support interpretability claims."}, "weaknesses": {"value": "My main concern is the novelty aspect, but I am open to revising my assessment during the discussion period.\n* Conceptual novelty feels incremental relative to prior works. DR. HINTER’s main advances— zooming, single/failed/multi-trace, etc.—read as engineering refinements. Additionally, there are relevant prior works that are not discussed (e.g. \\[1\\]).  \n* **Most components rely on prompts to an LLM.** The paper should be more explicit about exactly which roles are handled by LLM prompting (e.g., the step selection) and which are not.  \n* **Domain scope.** All experiments are browser-based; it’s unclear how the hint format transfers to other settings. Such empirical specificity should be explicit in the title or be accompanied by an additional domain.\n\n\\[1\\] Holt, S., Luyten, M. R., & Pouplin, T. (2025). Improving LLM Agent Planning with In-Context Learning via Atomic Fact Augmentation and Lookahead Search. *ArXiv*. https://arxiv.org/abs/2506.09171"}, "questions": {"value": "1. How do you address duplicate, contradictory, or incorrect hints?   \n2. Will you release the AutoGuide reimplementation so others can reproduce results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pmlS8adwk7", "forum": "zvHqmW4NkP", "replyto": "zvHqmW4NkP", "signatures": ["ICLR.cc/2026/Conference/Submission21201/Reviewer_bPLF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21201/Reviewer_bPLF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21201/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993011739, "cdate": 1761993011739, "tmdate": 1762941607725, "mdate": 1762941607725, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General response"}, "comment": {"value": "We thank the reviewers for their constructive feedback. Reviewers highlighted several strengths of our work, including **comprehensive evaluation (bPLF), leveraging both success and failures (bPLF),  interpretability (bPLF, YdbX), generality (YdbX), reproducibility (YdbX), practical design (iAEN)**, and **clarity of writing (iAEN)**. Below, we summarize the common concerns raised across the reviews and describe the major additions made to the revised manuscript. We also provide detailed, point-by-point responses to each reviewer. The main additions are:\n\n**1. Zooming: qualitative + quantitative analysis.**\n\nAs requested by **YdbX**, we added a detailed case study showing how zooming isolates the decisive AXTree snapshots that define a task’s causal backbone, enabling high-quality hint synthesis (e.g., 0.1→0.7 improvement on workarena.servicenow.sort-hardware-list). We also include new quantitative comparisons demonstrating that providing the **full trace** to the hinter yields only marginal gains (MiniWoB++: 0.715→0.718; WorkArena-L1: 0.661→0.715), whereas **zooming with two traces yields much larger improvements** (MiniWoB++: 0.739; WorkArena-L1: 0.770). This confirms that the hinter benefits from selecting critical steps, not simply from adding more tokens.\n\n\n**2. Stronger base and hinter models.**\n\n To address concerns about generality to stronger base models (**YdbX, iAEN**), we added results using **GPT-5** both as the base ReAct agent and as the hinter. We also tested a vision-based CUA agent with **Claude-4.5-Sonnet** serving as both the base and the Hinter model. In all cases across MiniWoB++, WorkArena-L1, and WebArena-Lite, DR. Hinter continues to provide consistent and often substantial gains (e.g., on WorkArena-L1: GPT-5 0.661 → 0.770; on WebArena-Lite: CUA-Claude-4.5-Sonnet 0.206 → 0.40).\n\n**3. Curator module for hint abstraction.**\n\nWe tested adding a curator module that merges semantically similar hints (**bPLF, iAEN**), and generalizes overlapping hints into a cleaner instruction set. While the curator has a modest impact on final performance, largely because our agent already performs step-level hint filtering, it improves consistency, avoids redundant or contradictory hints.\n\n---\n\nWe also added clarifications and explanations for our experimental setup and generalization scope (**bPLF, YdbX, iAEN**), comparison to existing works (**bPLF, YdbX**), and framework details (**bPLF**).\nAll of these additions, including new analyses, ablations, experiments, and discussions, are now incorporated into the revised manuscript to improve clarity and completeness, further strengthening the quality and contribution of the work."}}, "id": "icUVIZz7RE", "forum": "zvHqmW4NkP", "replyto": "zvHqmW4NkP", "signatures": ["ICLR.cc/2026/Conference/Submission21201/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21201/Authors"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission21201/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763600175364, "cdate": 1763600175364, "tmdate": 1763600175364, "mdate": 1763600175364, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}