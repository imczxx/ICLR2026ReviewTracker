{"id": "mMK9pvQJxf", "number": 21473, "cdate": 1758317972417, "mdate": 1759896920107, "content": {"title": "Improving Classifier-Free Guidance in Masked Diffusion: Low-Dim Theoretical Insights with High-Dim Impact", "abstract": "Classifier-Free Guidance (CFG) is a widely used technique for conditional generation and improving sample quality in continuous diffusion models, and its extensions to discrete diffusion has recently started to be investigated. In order to improve the algorithms in a principled way, this paper starts by analyzing the exact effect of CFG in the context of a low-dimensional masked diffusion model, with a special emphasis on the guidance schedule. Our analysis shows that high guidance early in sampling (when inputs are heavily masked) harms generation quality, while late-stage guidance has a larger effect. These findings provide a theoretical explanation for empirical observations in recent studies on guidance schedules. The analysis also reveals an imperfection of the current CFG implementations. These implementations can unintentionally cause imbalanced transitions, such as unmasking too rapidly during the early stages of generation, which degrades the quality of the resulting samples. To address this, we draw insight from the analysis and propose a novel classifier-free guidance mechanism. Intuitively, our method smoothens the transport between the data distribution and the initial (masked) distribution, which results in improved sample quality. Remarkably, our method is achievable via a simple one-line code change. Experiments on conditional image and text generation empirically confirm the efficacy of our method.", "tldr": "We introduce an improved mechanism for applying classifier-free guidance in discrete diffusion", "keywords": ["discrete diffusion", "conditional generation", "guidance"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4a62e2b127e0df16da144692d1ce5da005ec530c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates Classifier-Free Guidance (CFG) in the context of masked discrete diffusion models. The authors claim to have identified a key flaw in existing CFG implementations, where high guidance strength can lead to imbalanced transitions and unmasking too rapidly, which degrades sample quality.\n\nTo address this issue, the authors propose a novel CFG mechanism based on a column normalization of the rate matrix, achievable via a one-line code change. The authors provide a low-dimensional (1D and 2D) theoretical analysis to motivate this change and to characterize the properties of effective guidance schedules.  Experimental results are also provided to validate the technique."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper's primary contribution is a fix for a problem in discrete CFG that can be implemented with a one-line code change. I always like seeing examples of this kind of simple and effective solution, especially when they are theoretically motivated.\n2. The methodology of using low-dimensional (1D and 2D) theoretical analysis to derive insights that are relevant to the high-dimensional setting is a strong and interesting approach.\n3. Based on the experimental results, the proposed normalization fix appears to be effective."}, "weaknesses": {"value": "My current impression of the paper is that the authors have indeed likely identified a flaw in CFG for masked discrete diffusion models and found a simple fix for it. However, the more serious weaknesses I outline below prevented me from more deeply appreciating the authors' contributions, which has me currently sitting on the negative side of the fence. That said, I admit to being a good deal less familiar with the discrete diffusion literature than I am with the continuous diffusion literature, hence the low confidence in my score. I will keep an open mind during the discussion period, and I look forward to seeing the authors' responses and the feedback from the other reviewers.\n\nI'll list my concerns in decreasing order of seriousness:\n1. There seems to be a major contradiction in the paper's claims regarding effective guidance schedules. In Section 3.4 (lines 368-370), the 2D theoretical analysis concludes: \"Therefore, effective schedules have higher guidance in the beginning and middle phases of the generation, and their effect towards the end is negligible.\" This directly contradicts empirical results from numerous other works as well as statements in this paper's abstract and the discussion in Section 4.2: \"[S]chedules that apply stronger guidance during the middle and later stages of the sampling process, while keeping early guidance small, tend to perform better.\" Unless there is a serious misreading on my part, the results of Section 3.4 are never reconciled with these statements and the empirical record.\n2. Considering the weight given to the paper's theoretical results, I found them very hard to follow in their current form. Notation is occasionally not defined, and it was sometimes challenging to match the theorems or lemmas with their counterparts and proofs in the appendix.\n3. On the topic of notation, in most of the CFG literature, in both continuous and discrete diffusion, $x$ is a state and $y$ is a condition. But in this paper $y$ (never explicitly defined) is apparently a member of the state space (judging by the formula for the partition function) as well as a condition. I found this quite confusing.\n4. There are some minor typos and other errors in the paper (e.g. *diffusion* is misspelled in the header for Section 2.1, the regionalism *smoothen* is used in the abstract instead of the standard *smooth*).\n5. In the literature, the probability ratio the authors refer to as the *score* is referred to as the *concrete score*. I recommend sticking to this terminology to avoid confusion with the score as it's understood in the continuous diffusion literature."}, "questions": {"value": "1. Can the authors resolve the central contradiction (Weakness #1)? Which finding is correct: the 2D theory suggesting high early guidance, or the empirical results suggesting high late guidance? Why does the theory not seem to match the practice here?\n\n2. In the abstract, what is meant by \"late-stage guidance has a larger effect\"? Is this a positive or negative effect on generation quality? (This also relates to Weakness/Question #1.)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No concerns."}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "XZOCSqQWgY", "forum": "mMK9pvQJxf", "replyto": "mMK9pvQJxf", "signatures": ["ICLR.cc/2026/Conference/Submission21473/Reviewer_Yvo9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21473/Reviewer_Yvo9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21473/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761753329430, "cdate": 1761753329430, "tmdate": 1762941796333, "mdate": 1762941796333, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper analyzes the effect of using guidance schedules in discrete diffusion models and how such schedules can improve performance compared to constant guidance. Drawing inspiration from continuous diffusion models, the authors note that high guidance scales are necessary to enhance sample quality and condition alignment; however, using a constant high guidance scale results in suboptimal performance due to large changes during the early sampling stages. They first demonstrate that transition matrices should be normalized (via SoftMax) in the presence of guidance. Then, using a low-dimensional setup, they show that a constant guidance scale leads to poor performance, reducing diversity and increasing bias in the final generation. To address this, the authors propose an increasing weight schedule to balance the effect of guidance across sampling steps, leading to improved performance across various diffusion models for both image and text generation."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Since guidance in discrete diffusion models is underexplored, this paper bridges an important gap between CFG in continuous diffusion models and discrete diffusion models. The results have potential implications for all systems that rely on discrete diffusion.\n\n- The proposed method is simple and can be easily integrated into existing sampling pipelines.\n\n- The theoretical results provide intuition and reasoning behind the method, although their presentation could be significantly improved.\n\n- Experiments are conducted on both image and text generation benchmarks."}, "weaknesses": {"value": "- In my opinion, the main weakness of the paper is its presentation. Several parameters are either misused in notation or not defined prior to their introduction in the text. This makes the paper difficult to follow and obscures the intuition and analysis behind the proposed method.\n\n- Section 3.4 appears to contradict the main message of the paper. It states that “effective schedules have higher guidance in the beginning and middle phases of generation,” whereas the best performance is reported for “schedules that apply stronger guidance during the middle and later stages of the sampling process, while keeping early guidance small.”\n\n**Minor**:\n- There might be a typo in Equation 6.\n- Table 1 indicates that the increasing schedule has one parameter, while Table 2 shows it has two parameters ($w$ and $r$).\n- The theoretical analysis could also consider the effect of guidance on condition alignment, in addition to its impact on diversity and stability."}, "questions": {"value": "1. Do normalization and time-dependent schedules also improve the performance of Simple Guidance?\n\n2. Could you provide additional metrics, such as Precision and Recall, to separately evaluate diversity and quality, rather than relying solely on FID?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZoqNPGoeak", "forum": "mMK9pvQJxf", "replyto": "mMK9pvQJxf", "signatures": ["ICLR.cc/2026/Conference/Submission21473/Reviewer_DWkQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21473/Reviewer_DWkQ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21473/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761828008932, "cdate": 1761828008932, "tmdate": 1762941796016, "mdate": 1762941796016, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper analyzes CFG for masked diffusion, showing (in a low-dimensional setting) that strong early guidance hurts quality while late guidance helps. It also identifies an implementation flaw that causes over-eager early unmasking and proposes a one-line fix to smooth the transition from the masked prior to the data distribution."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. CFG is a well researched topic in continuous diffusion. But in masked/discrete diffusion is under active exploration. Clarifying scheduling effects is valuable for both image inpainting/masked modeling and text infilling models\n2. Section 3.4 provides exhaustive analysis across factors such as time parameters and guidance strength.\n3. The experiment in Section 2.3 is intuitive, improving explainability.\n4. The method can be performed in inferencing time."}, "weaknesses": {"value": "1. **Novelty:** The importance of guidance scheduling and rescaling by conditional/unconditional norms has been reported by Kynkäänniemi et al. (2024). Can you clarify how your approach differs?\n2. **Metrics/Benchmarks:** For text-to-image evaluation, you only report ImageReward. Could you also evaluate with **HPSv2** to check for aesthetic trade-offs? Additionally, please test on T2I benchmarks like **GenEval** and **T2I-CompBench**.\n\n[1] Kynkäänniemi, T., Aittala, M., Karras, T., Laine, S., Aila, T., & Lehtinen, J. (2024). *Applying guidance in a limited interval improves sample and distribution quality in diffusion models.* NeurIPS 37, 122458–122483."}, "questions": {"value": "1. Prior work reports that higher guidance weights can distort images and reduce fidelity, yet in your Figure 8 larger guidance weights yield better performance. Can you justify this discrepancy?\n2. The appendix includes many generated images—could you also include the text prompts used to produce them?\n3. Unified reward models are surging. Could you evaluate your method with Show-o [1] and Dual Diffusion [2] to assess its effectiveness in that setting?\n\n[1] Xie, J., Mao, W., Bai, Z., Zhang, D. J., Wang, W., Lin, K. Q., ... & Shou, M. Z. (2024). Show-o: One single transformer to unify multimodal understanding and generation. arXiv preprint arXiv:2408.12528.\n[2] Li, Z., Li, H., Shi, Y., Farimani, A. B., Kluger, Y., Yang, L., & Wang, P. (2025). Dual diffusion for unified image generation and understanding. In Proceedings of the Computer Vision and Pattern Recognition Conference (pp. 2779-2790)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Gfq25PkieP", "forum": "mMK9pvQJxf", "replyto": "mMK9pvQJxf", "signatures": ["ICLR.cc/2026/Conference/Submission21473/Reviewer_xrKo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21473/Reviewer_xrKo"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21473/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762129151757, "cdate": 1762129151757, "tmdate": 1762941795745, "mdate": 1762941795745, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper analyzes classifier-free guidance (CFG) in masked discrete diffusion and shows—theoretically (in low dimensions)—that strong early guidance harms quality, whereas late guidance has a larger positive impact. It identifies a flaw in common CFG implementations, where imbalanced transitions unmask tokens too quickly. To remedy this, the paper proposes a simple one-line column/softmax normalization that smooths transport. Empirically, this normalization improves ImageNet-256 FID, ImageReward text-to-image alignment, and MATH-500 text generation accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper presents a principled low-dimensional analysis of CFG for masked discrete diffusion, showing that strong early guidance is harmful while late guidance is beneficial.\nBuilding on this insight, it introduces an elegant, theory-grounded tweak—a one-line column/softmax normalization—that corrects imbalanced early unmasking.\nImportantly, by linking this tractable normalization to improved robustness and better FID/ImageReward/MATH-500 results, the paper offers a practical change likely to be widely adopted in discrete diffusion implementations."}, "weaknesses": {"value": "1. The paper develops analysis and closed-form expressions only in 1–2 dimensions for masked discrete diffusion. As a result, guarantees for realistic high-dimensional CTMCs remain implicit, leaving the theoretical treatment somewhat loose.\n\n2. Some results isolate the mechanism using a simple sampler without remasking and with fixed step counts (e.g., 50 steps on ImageNet-256), which may limit generality. Moreover, sampling schedules and samplers are crucial to implementing the guidance mechanism, yet the paper provides neither theoretical analysis nor empirical evaluation of their effects.\n\n3. Although the evidence spans ImageNet-256 FID, ImageReward, and MATH-500 with a single LLM backbone, broader discrete domains (e.g., ASR, text, protein) and larger vocabularies are not explored. Because the approach is closely related to Unlocking Guidance and Simple Guidance, running additional experiments on the datasets used in those works is crucial.\n\n4. Quality gains are reported, but diversity metrics are missing. Because guidance mechanisms can reduce sampling diversity, it is important to report diversity measures and quantify the proposed method’s impact.\n\n5. It is recommended to ensure the citation style is applied uniformly across the manuscript."}, "questions": {"value": "1. Since the theory is developed in 1–2D masked diffusion, could you provide bounds or a proof sketch that extends to realistic high-d CTMCs?\n\n2. With results limited to ImageNet-256 FID and MATH-500 on a single LLM backbone, is there evidence that the approach generalizes to other discrete diffusion tasks?\n\n3. Although normalization is cheap, schedule changes can alter unmasking rates and step counts. Therefore, reporting the resulting overhead (wall-clock, GPU-hours, memory) is important to demonstrate the strength of the proposed method.\n\n4. The proposed framework mainly targets masked diffusion, what changes are needed for uniform or other discrete diffusions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "s3jF7mwO4E", "forum": "mMK9pvQJxf", "replyto": "mMK9pvQJxf", "signatures": ["ICLR.cc/2026/Conference/Submission21473/Reviewer_sPcA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21473/Reviewer_sPcA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21473/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762780662076, "cdate": 1762780662076, "tmdate": 1762941795478, "mdate": 1762941795478, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}