{"id": "FZ65g1It7i", "number": 19089, "cdate": 1758293523170, "mdate": 1759897061347, "content": {"title": "Unifying Perspectives: Plausible Counterfactual Explanations on Global, Group-wise, and Local Levels", "abstract": "The growing complexity of AI systems has intensified the need for transparency through Explainable AI (XAI). Counterfactual explanations (CFs) offer actionable \"what-if\" scenarios on three levels: Local CFs providing instance-specific insights, Global CFs addressing broader trends, and Group-wise CFs (GWCFs) striking a balance and revealing patterns within cohesive groups. Despite the availability of methods for each granularity level, the field lacks a unified method that integrates these complementary approaches. We address this limitation by proposing a gradient-based optimization method for differentiable models that generates Local, Global, and Group-wise Counterfactual Explanations in a unified manner. We especially enhance GWCF generation by combining instance grouping and counterfactual generation into a single efficient process, replacing traditional two-step methods. Moreover, to ensure trustworthiness, we pioneer the integration of plausibility criteria into the GWCF domain, making explanations both valid and realistic. Our results demonstrate the method's effectiveness in balancing validity, proximity, and plausibility while optimizing group granularity.", "tldr": "This paper introduces a unified method for generating local global, and group-wise counterfactual explanations for differentiable classification models, using gradient-based optimization and a probabilistic plausibility criterion.", "keywords": ["Explainable AI", "Counterfactual Explanations"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4eb3cbd0840f00104f2dd8f1d2213fbd2d2aec3d.pdf", "supplementary_material": "/attachment/b06c861be9864c6f242dbdde49c912b8dbc0b669.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents a unified framework for generating counterfactual explanations at three different granularity levels: local (instance-specific), global (dataset-wide), and group-wise (for cohesive subgroups). Counterfactual explanations are a key tool in Explainable AI (XAI) that provide actionable \"what-if\" scenarios, showing how changes to input features can alter a model's predictions. The paper makes two  contributions to the field of counterfactual explanations. First, it introduces a unified approach that can generate counterfactual explanations at any desired granularity level through a single gradient-based optimization framework. Second, the paper attempts to develop group-wise counterfactual generation by developing an end-to-end optimization process that simultaneously performs instance grouping and counterfactual generation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Despite the incremental nature of the novelty, the paper makes contributions that advance the practical state of the art in an important problem area. The combination of addressing real limitations in existing methods, providing comprehensive experimental validation, and demonstrating practical utility creates a package that is greater than the sum of its parts. For practitioners working with counterfactual explanations, this method would likely represent a genuine improvement over existing approaches, particularly for group-wise explanations where current methods are limited. The work is well-suited for practical advances built on engineering and thorough evaluation are valued, even when the fundamental algorithmic innovations are modest.\n\nThe paper's claim centers on joint optimization for group-wise counterfactuals, replacing the two-step clustering-then-generation approach. However, this contribution should be contextualized carefully. The idea of jointly optimizing clustering and another objective is not new in machine learning—it appears in various forms across deep clustering, mixture models, and representation learning literature. The specific application here involves learning a soft assignment matrix P through Sparsemax while simultaneously optimizing counterfactual directions in matrix D_GW. While this integration is sensible and addresses real limitations of prior two-step methods, it represents engineering ingenuity rather than algorithmic innovation. The optimization itself uses standard gradient descent on a carefully weighted multi-objective loss function—a common pattern in machine learning."}, "weaknesses": {"value": "The paper's contributions, while practically useful, exhibit limited fundamental novelty when examined critically. The core claim of a \"unified framework\" is somewhat overstated—the unification is primarily achieved through parameterization of a standard gradient-based optimization formulation rather than introducing new theoretical insights. Setting K=N recovers local counterfactuals, K=1 recovers global counterfactuals, and intermediate values yield group-wise explanations. This is more of an observation about special cases of a general formulation than a novel algorithmic contribution. The mathematical framework itself relies entirely on well-established techniques: gradient-based optimization for differentiable models has been the standard approach in counterfactual explanation literature since Wachter et al. (2017).\n\nThe paper's weakness is its lack of fundamental algorithmic or theoretical innovation. As detailed in the novelty evaluation, the core technical components are borrowed from very recent work (2024) with straightforward extensions. The \"unified framework\" reduces to parameter selection in a standard gradient-based optimization formulation rather than introducing new theoretical insights. The plausibility integration using normalizing flows comes directly from Wielopolski et al. (2024), the validity loss from the same source, and the global counterfactual formulation extends GLOBE-CE (Ley et al., 2023). The joint optimization for group-wise counterfactuals, while addressing real limitations, applies well-known techniques (Sparsemax, entropy regularization, gradient descent) without innovation. \n\nThe paper provides no theoretical grounding or guarantees for its proposed method. There is no analysis of convergence properties, optimization landscape characteristics, sample complexity, approximation guarantees, or theoretical justification for why joint optimization should outperform two-step approaches beyond intuitive arguments. The choice of specific regularization terms (log-determinant for diversity, entropy for sparsity) lacks theoretical motivation for why these particular forms are optimal. \n\nThe paper makes several overstated claims that weaken its credibility. The abstract claims a \"novel unified approach\" when the unification is primarily through parameterization. The introduction states the method \"eliminates the inefficient two-step process\" as if unprecedented, but joint optimization is common in machine learning. The claim of \"innovatively introducing\" plausibility to group-wise settings understates how straightforward this extension is. The paper claims to generate explanations at \"any desired granularity,\" but users must still manually set K (number of groups) or rely on automatic selection via regularization that may not match their needs. The \"unified\" framework still requires different hyperparameter configurations for different granularities, limiting true unification. More precise, measured language would better serve the paper's contributions."}, "questions": {"value": "The paper claims joint optimization eliminates inefficiencies of two-step methods, but provides no theoretical analysis. Specific sub-questions include: (a) Does the non-convex optimization landscape with coupled variables (B, D_GW, K) have local minima that trap the method in poor solutions? (b) What convergence guarantees exist for the alternating gradient descent on these coupled parameters? (c) Under what data distributions or model characteristics does joint optimization provably improve upon sequential clustering-then-generation?\n\nHow should practitioners set the five loss weights (λ, λ_p, λ_s, λ_k, λ_d) spanning five orders of magnitude for new datasets and domains without exhaustive grid search?\n\n(a) Do human users (domain experts, affected individuals) actually find these groups more interpretable, coherent, and actionable than alternatives? (b) What metrics beyond group count quantify interpretability—within-group homogeneity, between-group separation, semantic coherence, alignment with known subpopulations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics concerns have been identified."}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ScZohBQjlz", "forum": "FZ65g1It7i", "replyto": "FZ65g1It7i", "signatures": ["ICLR.cc/2026/Conference/Submission19089/Reviewer_K9zo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19089/Reviewer_K9zo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19089/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761405431724, "cdate": 1761405431724, "tmdate": 1762931111939, "mdate": 1762931111939, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper provides a single formulation for the problem of finding counterfactual explanations on local, group-wise, and global scales. The authors formulate it using an objective composed of a linear combination of multiple penalty functions, including a penalty for plausibility, which is modeled using a conditional normalizing flow model. They then use gradient descent to find the set of counterfactuals."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper reformulates the somewhat distinct tasks of finding global, local, and group counterfactuals by posing them as instances of a more general task. I consider this perspective valuable to the community. The paper reads well, and the substantial appendix contains a lot of extra information about experimental evaluation, suggesting that substantial effort has been made in hyperparameter optimization and in comparing the proposed method to other CE methods."}, "weaknesses": {"value": "The paper contains a few unsupported claims\n - The authors claim to achieve \"superior plausibility compared to state-of-the-art methods\". However:\n   - In plausible local counterfactual explanations, fair comparison on plausibility is relevant only with respect to C-CHVAE, as neither Wachter nor DiCE considers plausibility. Furthermore, the state-of-the-art for local counterfactuals is not properly discussed, mainly pointing to a survey (Karimi et al. 2022) with a cut-off date at the end of 2020. Since then, there have been many other models, including the recent PPCEF by Wielopolski et al. (2024) as cited in the paper, to which the proposed method seems to be most similar (utilizing flow models), or LiCE (https://openreview.net/pdf?id=rGyi8NNqB0) from ICLR 2025, which reported outperforming C-CHVAE. \n   - Statistical significance of the results is not discussed, and the reported standard deviations suggest a lot of uncertainty.\n - A claim that eq. 14 \"guarantees that p(y^\\prime) will be higher than any other class y\"\n   - My understanding is that it is just a loss term. How is this outcome guaranteed?\n   - There are cases where the validity of generated counterfactuals is not 100% (e.g., HELOC in Table 11). Why is that, if not due to this loss term being nonzero in the obtained minimum?\n -  Claims of the method \"consistently outperforming baseline approaches\" is also quite strong, since on proximity, Figure 2 suggests rather underperformance.\n\nDespite flow models being quite scalable, experimental evaluation was done mostly on low-dimensional data (<200 samples or <= 3 attributes in 4 out of 6 datasets). This influences the rank evaluation, as on the higher-dimensional datasets (HELOC, Digits), TCREx seems to outperform the proposed model in proximity and plausibility (as per Table 11).\n\nSome results left for the appendix, e.g., the ones about group sizes and number of groups, would fit better into the main body, rather than having three seemingly arbitrary examples without comparison to other methods. Those are used to support a claim of interpretability, which would be better supported by a user study or some proxy attribute of the groups. \nMore details on the comparison to other approaches would be appreciated. Compared methods are not well-described when introduced, and little interpretation of the results is provided. Especially comparison to Wielopolski et al. (2024) that also uses normalized flow models might increase the value of the paper.\n\nBecause of these issues, my initial score is reject, though I am open to being swayed if my concerns are addressed. In this form, I find the contribution limited and the conclusions drawn from computational results overstated.\n\nEthics statement mentions the perspective of fairness though this is not discussed in the paper. It is unclear how would the method be used to audit fairness when the sample groups are optimized, rather than being given prior.\n\nMinor comments:\n- L161: The indexing suggests N+1 examples, rather than N.\n- L174: X_0 is already included in eq. 5. Did you mean to write X_K^\\prime?\n- L260: a typo: eq. equation \n- L748: missing S in \"constraint\""}, "questions": {"value": "From the weaknesses, a couple of main questions that could influence my decision arise:\n - Are the results statistically significant?\n - How does the model differ from Wielopolski et al. (2024) when considering the local counterfactual scenario?\n - What train-test splitting was done to prevent optimizing the hyperparameter values on the data used to report results?\n - Why were these datasets selected? The trained models often achieve perfect accuracy on the simpler datasets, suggesting they might be too simple. Why was not some benchmark of tabular data (e.g., https://proceedings.neurips.cc/paper_files/paper/2022/file/0378c7692da36807bdec87ab043cdadc-Paper-Datasets_and_Benchmarks.pdf) used? Does the method scale beyond 10,000 samples?\n\nMinor questions:\n - What K is selected and why? How different is it from the optimized number of groups, usually? \n - Why was $\\delta$ chosen equal to the first quartile on the training set and not the median, as was the case in Artelt & Hammer (2020)?\n - Why does the proposed method achieve less than 100% coverage in some cases?\n - Why were the actionability constraints applied? Why is it not actionable to decrease one's Number of Satisfactory trades, for example?\n - When applying the group counterfactuals shown in Figure 3, is there something preventing an individual with a NetFractionInstallBurden of 30 from being assigned to group 3 and suggesting (non actionably) that they should have the fraction negative?\n - In group evaluation, is an individual given a counterfactual from the \"most probable\" group or is the counterfactual computed as a convex combination using the p vector?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "EzAno21koD", "forum": "FZ65g1It7i", "replyto": "FZ65g1It7i", "signatures": ["ICLR.cc/2026/Conference/Submission19089/Reviewer_rEYX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19089/Reviewer_rEYX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19089/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761588721601, "cdate": 1761588721601, "tmdate": 1762950132927, "mdate": 1762950132927, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a new approach that unifies the concepts of local, global, and group-wise counterfactual explanations. Their method allows for simultaneously generating group and group-wise counterfactuals, where this is normally done sequentially. The authors compare their method on different datasets to several baselines based on proximity, validity, and plausibility."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "-\tThe authors introduce a novel way to unify different types of counterfactual explanations that exist in the current literature and allow the user of the method to easily switch between and compare counterfactuals on different granularities\n-\tFor group-wise explanations, the optimization method allows for simultaneous generation of the groups and the counterfactuals, which was not done before.\n-\tThe experiment section is extensive and includes multiple datasets and state-of-the-art benchmarks\n-\tThe methodology is clearly written"}, "weaknesses": {"value": "-\tIn their method, the authors use regularization to enforce desired characteristics. However, this does not create any guarantees for these characteristics. Guaranteeing validity would, in certain contexts, be crucial for a good explanation and can be enforced using hard constraints. There is literature on counterfactual explanations that enforce characteristics as actionability, validity, and many more by means of hard constraints using mathematical optimization; see e.g. [1],[2],[3]. This is not discussed by the authors, nor is there a comparison in the experiment section.\n-\tWhen comparing to benchmarks, the authors use rankings and claim their method outperformed baseline approaches across all granularity levels. However, their method seems to be consistently outperformed in terms of proximity. When the authors claim competitive proximity scores, this does not evidently follow from the rankings. Yes, the proposed method often comes second, but the rankings do not tell the relative (%) or absolute gap to the benchmark methods. Showing rankings only does not show how far off all methods are from the best model for each characteristic.\n-\tThere experimental results shown in the main paper are very limited. Nearly all results are in the Appendix.\n\n[1] Maragno, D., Röber, T. E., & Birbil, I. (2022). Counterfactual explanations using optimization with constraint learning\n[2] Maragno et al. - Finding Regions of Counterfactual Explanations via Robust Optimization\n[3] Carrizosa, E., Ramírez-Ayerbe, J., & Morales, D. R. (2024). Mathematical optimization modelling for group counterfactual explanations"}, "questions": {"value": "-\tThe lambda hyperparameters are chosen to set priority between the various desired characteristics for the counterfactual. Does this mean the metrics are normalized before determining the hyperparameters? This is implied but not discussed.\n-\tWhat is the reason that the proposed method is always outperformed by another method in terms of proximity?\n-\tWhy did the authors not discuss robustness of counterfactual explanations; see e.g. [2]. It seems that robust counterfactuals improve validity which is one of the key metrics in this paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jXDSMSdS1h", "forum": "FZ65g1It7i", "replyto": "FZ65g1It7i", "signatures": ["ICLR.cc/2026/Conference/Submission19089/Reviewer_tRov"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19089/Reviewer_tRov"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19089/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761735858471, "cdate": 1761735858471, "tmdate": 1762931110942, "mdate": 1762931110942, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper consolidates the existing Counterfactual (CF) methods, including local CF, Global CF, and Group-wise CF."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**Clear and well-motivated unification.**\nThe paper proposes a neat idea: generating local, group-wise, and global counterfactuals within one optimization framework. This unifies previous methods and avoids redundancy.\n\n**Thorough experimentation.**\nExperiments cover diverse datasets, models, and baselines. Comparisons across validity, proximity, and plausibility metrics show careful validation and strong results.\n\n**Readable and well-structured writing.**\nThe paper is clear and organized, with consistent notation, clean math, and helpful figures. The ideas are presented logically and concisely."}, "weaknesses": {"value": "**Hyperparameter Sensitivity.**\nThe method uses several regularization weights ($\\lambda$, $\\lambda_p$, $\\lambda_s$, $\\lambda_k$, $\\lambda_d$). Defaults are given, but sensitivity to these choices isn’t analyzed. A short study or tuning guide would make the method easier to reproduce.\n\n**Plausibility.**\nPlausibility is measured with the Isolation Forest metric, but not with *causal plausibility*—whether counterfactuals follow real cause-and-effect relations between features. Adding a causal metric would make the evaluation more realistic. If some knowledge about the causal graph is available, it could be added to the optimization. Using causal constraints or structure-based regularization would help generate counterfactuals that are both statistically and causally sound, making them more meaningful and trustworthy in practice."}, "questions": {"value": "Please consider the points in the weaknesses part. Further, how does this paper compare with causal counterfactual explanations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8gRij9wW3X", "forum": "FZ65g1It7i", "replyto": "FZ65g1It7i", "signatures": ["ICLR.cc/2026/Conference/Submission19089/Reviewer_TJfs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19089/Reviewer_TJfs"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19089/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978786015, "cdate": 1761978786015, "tmdate": 1762931109981, "mdate": 1762931109981, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}