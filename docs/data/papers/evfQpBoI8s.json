{"id": "evfQpBoI8s", "number": 15523, "cdate": 1758252297939, "mdate": 1759897301445, "content": {"title": "Random Scaling of Emergent Capabilities", "abstract": "Language models famously improve under a smooth scaling law, but some specific capabilities exhibit sudden breakthroughs in performance.\nWhile advocates of ``emergence\" view breakthroughs as unlocked capabilities, others attribute them to thresholding effects on noncontinuous metrics. We propose that breakthroughs are instead driven by continuous changes in the \\textit{probability distribution} of training outcomes when performance is bimodally distributed across random seeds. In synthetic length generalization tasks, we show that different random seeds can produce either highly linear or emergent scaling trends. We reveal that sharp breakthroughs in metrics are produced by underlying continuous changes in their distribution across seeds. In a case study of inverse scaling, we  show that even as the probability of a successful run declines, the average performance of a successful run increases monotonically.\nWe validate our distributional scaling framework on realistic settings by measuring MMLU performance in LM populations. Our observations hold true even under continuous loss metrics, confirming that random variation must be considered when predicting a model's performance from its scale.", "tldr": "", "keywords": ["random variation", "emergence", "length generalization", "scaling"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/db687e0434eac852eff35aa93d905435d9de12a2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents the observation of the bimodal distribution of performance of models trained under different random seeds. Some seeds show emergent abilities, while some seeds display smooth improvement. The bimodal distribution can be used to explain some training dynamics. For example, the emergent abilities of LLM might be a manifestation where a smaller model falls into the left side of the distribution (bad performance) and a larger model falls into the right side (good performance). Also, the minimum capability can be identified when the performance distribution goes from unimodal (all on the left side) to bimodal. Experiments are conducted on two synthetic algorithmic tasks, MMLU, and CSQA."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed observation of bimodal distribution is interesting and makes sense as a potential explanation for emergent abilities.\n2. The emergence from unimodal to bimodal distribution as a sign of possessing minimum capability is an interesting and well-explained observation.\n3. The paper is clear and easy to follow."}, "weaknesses": {"value": "1. I would suggest changing the title of Section 2 from \"Experiment\" to \"Experimental Setup.\" You only introduce the setup there.\n2. Typos in lines 246-247: \"we see that the probability (Figure 3.2 (bottom left) and mean (bottom right) of such “successful”.\" Throughout the paper, you seem to regard Figures 3 and 6, which have 4 subfigures, as being displayed as a 2*2 layout.\n3. In lines 359 & 368, Figure 3.5 is mislinked to Figure 6.\n4. In line 414, incorrect citation format. (\"...process the multiple-choice format Hu and Frank (2024).\")\n5. Results of the synthetic task in Section 3 may not transfer well to benchmark datasets. Specifically, the experiments of MMLU and CSQA do not convince me:\n    (1) The emergent abilities of MMLU happen at the emergence threshold, where model performance rapidly increases from 25% acc to 40% or so, as displayed in Figure 1 of [a]. In contrast, your experiments are on small models that are before the emergence threshold.\n    (2) Figures 8 and 15 do not show a clear bi- or multi-modal distribution.\n\nMy understanding is that a slight perturbation on model weights (through different randomizations) affects its performance, leading to a steeper/flatter performance gap between two adjacent models. However, the effect of perturbation is eliminated as the model size grows (trained on more samples).\n\n6. I would suggest that authors discuss this work's limitations in an independent paragraph or section.\n\na. [U-shaped and Inverted-U Scaling behind Emergent Abilities of Large Language Models](https://openreview.net/forum?id=jjfve2gIXe)\n\nMy main concern is 5.; MMLU and CSQA do not exhibit clear bimodal distribution in my opinion."}, "questions": {"value": "1. [a] seems relevant to some of your arguments, such as the observation in Section 3.5 (\"Competing solutions can lead to either monotonic or U-shaped trends in emergence likelihood.\"). They found that emergent abilities can be decomposed into a U-shaped trend and a double descent trend, which cancel out each other before the emergence threshold.\n\n2. Can you explicitly state the formulas of overall mode, overall mean, success probability, and mean of successful runs in Figures 3 and 6?\n\n3. Do you have any hypotheses for the cause of bimodal distribution?\n\n4. Some works [a, b] argue the predictability of emergent abilities. Does this observation provide any new insights to help answer this long-lasting debate?\n\na. [U-shaped and Inverted-U Scaling behind Emergent Abilities of Large Language Models](https://openreview.net/forum?id=jjfve2gIXe)\n\nb. [Predicting Emergent Capabilities by Finetuning](https://arxiv.org/abs/2411.16035)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vEjqFL0HID", "forum": "evfQpBoI8s", "replyto": "evfQpBoI8s", "signatures": ["ICLR.cc/2026/Conference/Submission15523/Reviewer_Fq9j"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15523/Reviewer_Fq9j"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15523/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761209704429, "cdate": 1761209704429, "tmdate": 1762925806225, "mdate": 1762925806225, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Instead of studying emergent capabilities using a single training run or average of a few runs, this paper studies emergent capabilities using ~200 training runs of different random seeds. The authors attributed that \"breakthroughs are instead driven by continuous changes in the probability distribution of training outcomes when performance is bimodally distributed across random seeds\"."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper studies emergent capabilities from a novel perspective, from a distributional perspective of many training runs instead of a single training run. This is important and helpful because neural network learning is inherently stochastic."}, "weaknesses": {"value": "1. I could not agree with the paper's explanation that emergent capabilities are driven by the binomial distribution in capabilities, that \"This variability is precisely what causes some model runs to appear as breakthroughs while others follow a more linear progression.\" I believe the causality should be the other way around. Some training runs show breakthrough, so that the capability performance improves abruptly from one mode to another. And other training runs show linear improvement. When these two kinds of training combine, they give the multi-modal distribution shown in Figure 2.\n\nFor example, thresholding is a mechanism that gives rise to discontinuity and that might cause emergent capability. I understand this as a valid cause driving emergent capability. But I believe how the distribution of capability performance changes during learning is more of a result/consequence of linear/emergent learning, rather than as cause/driving factor.\n\nI acknowledge that the distribution of different training runs, rather than one single training run, is worth study regarding emergent capability. My concerns are regarding the causality.\n\n2. The authors conduct experiments using reinitializations rather than training from scratch for computational cost constraints. Reintializations involves reinitialize the final attention layer and the subsequent LM head, while keeping most other layers as trained. I believe this experimental setup differs significantly from a from-scratch training, and might change the learning behaviour. Could the authors provide evidence that support the eligibility of such approach for studying emergent capabilities? for example, are there other works on studying emergent capabilities that use similar reinitialisation instead of training from scratch?\n\n3. The Section 4.3 explains Figure 8 as roughly bi-modal. I think it is ambiguous from reading the figure alone. It also looks reasonable to me that the MMLU ratio = 7.5% figure and the MMLU ratio = 20% figure are unimodal. Could the authors more rigorously use a standard to test whether they are bimodal, for example statistical tests?\n\n4. Finally, I feel the paper is quite dense in terms of experiments and explanations and I feel personally challenging to grasp the main take-away. The authors are encouraged to improve the ease of reading."}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PJL5XNXqhP", "forum": "evfQpBoI8s", "replyto": "evfQpBoI8s", "signatures": ["ICLR.cc/2026/Conference/Submission15523/Reviewer_Tnbg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15523/Reviewer_Tnbg"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15523/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761840383424, "cdate": 1761840383424, "tmdate": 1762925805901, "mdate": 1762925805901, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies \"emergent\" capabilities--sharp breakthroughs/increases in model performance at a sufficiently large model size--and provides empirical support for the view that model performance across scales is bimodally distributed across random seeds. Through experiments on both synthetic and natural language tasks (MMLU), they show that some seeds exhibit linear trends, while others show emergent trends; they argue that when reporting results on individual seeds, results are likely skewed to the modes of the underlying distributions of model performances at scales. They find that these results hold for both discrete and continuous metrics (loss)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper provides a careful conceptual lens through which to view the well-studied phenomenon of emergent capabilities. This viewpoint is empirically well-supported.\n- Experiments are extensive, showing the robustness of results for a wide range of metrics (continuous vs discrete, mode vs mean) across seeds and datasets (synthetic and real-world)."}, "weaknesses": {"value": "- Potential for impact: Although the finding that not all individual seeds themselves exhibit non-linearity in emergent capabilities is interesting, it is not clear what the impact of the empirical findings in the work are. If what appears as emergence is that the mode of the performance distributions sharply increases, is this not a form of emergence? What are the implications of this work for how we study and evaluate models?\n- Some analysis decisions are arbitrary: For example, why is 20% exact match accuracy used as the threshold for success in Section 3.2?\n- Limited models: All analyses on real-world tasks are with Qwen models, not models from other families."}, "questions": {"value": "Minor Notes:\n- Figure 3 is referred to as Figure 3.2 in the paper, but there is only a single figure. Line 247: It is also unclear to me what \"bottom left\" and \"bottom right\" mean here.\n- Line 247: What do depths 2 and 3 correspond to in the figure?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "gChOM5x7ft", "forum": "evfQpBoI8s", "replyto": "evfQpBoI8s", "signatures": ["ICLR.cc/2026/Conference/Submission15523/Reviewer_JeTL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15523/Reviewer_JeTL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15523/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761882261507, "cdate": 1761882261507, "tmdate": 1762925805525, "mdate": 1762925805525, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}