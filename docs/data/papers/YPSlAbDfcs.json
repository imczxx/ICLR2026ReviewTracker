{"id": "YPSlAbDfcs", "number": 18246, "cdate": 1758285571623, "mdate": 1763288407573, "content": {"title": "A Dual-Protection Framework for Copyright Protection and Image Editing Using Multi-Label Conformal Prediction", "abstract": "Recent advances in diffusion models have significantly enhanced image editing capabilities, raising serious concerns about copyright protection. Traditional watermarks often fail to withstand diffusion-based edits, making image protection challenging. To address this, we propose a method that embeds an imperceptible perturbation in images, serving as a watermark while simultaneously disrupting the output of latent diffusion models.  Our method employs a Score Estimator trained on select latent embeddings to embed the watermark by minimizing the score function. We then apply conformal inference to compute p-values for watermark detection. To distort the output of latent diffusion models, we shift watermarked image embeddings away from the distribution mean, distorting unauthorized generations. Experiments demonstrate our framework's superior performance in watermark detection, imperceptibility, and distortion efficacy, offering a comprehensive approach to protect images against latent diffusion models.", "tldr": "", "keywords": ["Diffusion Models", "Copyright Protection", "Conformal Inference", "Invisible Watermarking"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/301b85c576a6f8518e3c7b2eb3f59620eed583b2.pdf", "supplementary_material": ""}, "replies": [{"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "TN89DLoGXv", "forum": "YPSlAbDfcs", "replyto": "YPSlAbDfcs", "signatures": ["ICLR.cc/2026/Conference/Submission18246/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18246/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763288406767, "cdate": 1763288406767, "tmdate": 1763288406767, "mdate": 1763288406767, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces an image watermarking method that simultaneously addresses copyright protection and re-generation prevention. An image protected by this method carries a verifiable watermark, whose presence could be detected statistically based on multi-label conformal prediction. When the image is used for re-generation, the results would be visibly distorted. The authors evaluated this framework on multiple aspects and also justified certain design choices."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "-\tThe paper proposes a unified framework to solve two critical problems: adding a watermark for ownership verification and preventing unauthorized re-generation of that image. This dual-functionality has practical significance. \n-\tThe experimental evaluations are comprehensive, demonstrating the method’s performance across both tasks, its imperceptibility, generalization capabilities, robustness, and security, followed by ablation studies on key design choices."}, "weaknesses": {"value": "-\tRegarding watermark detection, the claim of achieving “comparable” detection rates to baseline methods (line 292) is not directly supported by experiment results. \n-\tRegarding protection against re-generation, the method shows superior performance over adapted watermarking techniques but is not compared against methods specifically designed for this purpose (e.g., Glaze, AdvDM). Involving comparisons against these methods could make the evaluation more fair and convincing.\n-\tAs acknowledged by the authors, when protecting against unauthorized generation, the method has limited cross-model generalizability.\n-\tAs a 0-bit design, the watermark’s robustness lacks behind state-of-the-art, especially under geometric transformations. Cropping with parameter 0.9 or a 10-degree rotation could cause the accuracy rate drop below 40%.\n\nBy addressing these issues (mainly the first two), the paper’s main claims could be better supported."}, "questions": {"value": "-\tCompared to baseline methods selected in the paper, would the proposed per-image optimization process require more time to watermark an image? \n-\tThe Score Estimator is a separate network trained on labels derived from the LDM's VAE encoder. Could this be considered a form of knowledge distillation? If so, what was the motivation for training a new model rather than more directly using the VAE encoder itself to derive the conformity score?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XmSKCBTd2Q", "forum": "YPSlAbDfcs", "replyto": "YPSlAbDfcs", "signatures": ["ICLR.cc/2026/Conference/Submission18246/Reviewer_NLZm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18246/Reviewer_NLZm"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18246/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761372841912, "cdate": 1761372841912, "tmdate": 1762927977015, "mdate": 1762927977015, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a dual protection framework which embed imperceptible adversarial perturbations into images that functions both as a digital watermark and as a defense mechanism against LDMs. The method trains a score estimator on LDM latent embeddings and applies conformal inference to compute statistically valid p-values for watermark detection, while shifting image embeddings toward low-density latent regions to distort unauthorized generations. Experiments demonstrate the effectiveness of this approach in achieving good watermark detectability, visual imperceptibility, and resilience to diffusion-based editing."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper focuses on an important and interesting topic: traditional watermarks can be easily removed or degraded through diffusion-based image-to-image editing. It solves the problem by introducing a dual protection framework that embeds imperceptible perturbations into images, serving both as a verifiable watermark and as a mechanism to disrupt diffusion-based editing.\n2. The proposed method is intuitively reasonable and demonstrated to be effective in disrupting editing."}, "weaknesses": {"value": "1. The motivation for the dual-protection framework needs stronger justification as there have been multiple works which focuses on proposing watermarking method robust to image editing techniques such as [1][2].\n\n[1] Robust Watermarking Using Generative Priors Against Image Editing: From Benchmarking to Advances\n\n[2] Robust-Wide: Robust Watermarking against Instruction-driven Image Editing\n\n2. The evaluation is not comprehensive enough. The main experiments are conducted with only one dataset and only one prompt for image-to-image editing, which is insufficient to demonstrate the effectiveness of the method across different settings. In addition, it is suggested that the authors should also demonstrate the performance of performance of baselines in Table 1 to show that whether the proposed method is able to achieve watermark detector accuracy similar to other methods.\n3. The method fails to demonstrate good transferability when the score estimator is trained with one model and the watermarked images are input into another diffusion model. This raise a concern of the applicability of the method. In real practice, the owner of the images will not have the knowledge about what kind of diffusion model will be used for the attack.\n4. While the proposed method demonstrates strong robustness against common attacks such as cropping and Gaussian noise, there exist more specialized and targeted watermark removal techniques, such as [3][4][5]. It is therefore suggested that the authors evaluate their method against these advanced removal attacks to provide a more comprehensive assessment of its robustness and practical reliability. \n\n[2] Invisible Image Watermarks Are Provably Removable Using Generative AI \n\n[3] Generative autoencoders as watermark attackers: Analyses of vulnerabilities and threats \n\n[4] Evading watermark based detection of AI-generated content\n\n5. In Section 5.5, the author demonstrate that the entire watermark pipeline can be transferred to another diffusion model, but only one model is considered in the experiments and no visualization are shown, which is not sufficient."}, "questions": {"value": "1. Section 5.6 demonstrate that the proposed method is robust to several image corruption by showing the watermark detection rate after the corruption. Can the effect of the resilience to image editing also be retained after the attacking?\n2. Is the proposed method able to achieve a comparable performance in defending malicious image editing with some adversarial method against image editing such as [1][2]?\n\n[1] DiffusionGuard: A Robust Defense Against Malicious Diffusion-based Image Editing\n\n[2] DCT-Shield: A Robust Frequency Domain Defense against Malicious Image Editing\n\n3. If the watermark detector for the proposed method is applied to images watermarked by other watermarking methods such as HiDDeN, what will be the false negative rate?\n\n4. Is there a trade-off between the watermark detection accuracy and the effect of defending malicious image editing?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Tsb86f0wya", "forum": "YPSlAbDfcs", "replyto": "YPSlAbDfcs", "signatures": ["ICLR.cc/2026/Conference/Submission18246/Reviewer_qxif"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18246/Reviewer_qxif"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18246/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761786945075, "cdate": 1761786945075, "tmdate": 1762927976588, "mdate": 1762927976588, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a dual approach for watermark protection. It embeds an imperceptible perturbation in images, serving as a watermark while simultaneously disrupting the output of latent diffusion models. Experiments demonstrate the effectiveness of the proposed method."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "[1] The paper is clear and easy to understand, clearly stating the motivation and the intuition.\n\n[2] Experiments are performed to demonstrate the effectiveness of the method.\n\n[3] Copyright protection is an important topic."}, "weaknesses": {"value": "[1] My major concern is the lack of justification of the novelty of the proposed work. The major issue is that the authors only includes two papers in 2024 and there is no paper in 2025. The missing of the references could prevent authors from understanding the novelty and the importance of the paper. While there may be not many papers when considering the specific techniques, many papers are published in this field and should be acknowledged. The following list a few literature:\n\nBui, Tu, Shruti Agarwal, and John Collomosse. \"TrustMark: Robust Watermarking and Watermark Removal for Arbitrary Resolution Images.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2025.\n\nLiu, Gaozhi, et al. \"Watermarking One for All: A Robust Watermarking Scheme Against Partial Image Theft.\" Proceedings of the Computer Vision and Pattern Recognition Conference. 2025.\n\nWu, Shaowu, Wei Lu, and Xiangyang Luo. \"Robust Watermarking Based on Multi-layer Watermark Feature Fusion.\" IEEE Transactions on Multimedia (2025).\n\nDzhanashia, Kristina, and Oleg Evsutin. \"Robust image watermarking for diverse channels with template-forming neural network.\" Applied Soft Computing (2025): 114125.\n\nXu, Rui, et al. \"InvisMark: Invisible and Robust Watermarking for AI-generated Image Provenance.\" 2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV). IEEE, 2025.\n\nThe authors are suggested to revise the introduction and related works section about this. And experiments should also compare with more recent methods as well.\n\n[2] The robustness evaluation only considers \"Gaussian noise, Gaussian blur, cropping, rotation, and JPEG compression\", but not those more adversarial edits. The authors are suggested to add experiments for other techniques, e.g. Bui et al. (2025).\n\n[3] In \"Case 1: Can watermarked images trained on one diffusion model withstand attacks from another?\", the limitation on the transferability could be a concern of the proposed approach. I'm wondering if the authors could provide a mitigation strategy for it (intuition is enough). The transferability is important when applying watermark techniques in real practice."}, "questions": {"value": "Please address my concerns in the above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Psq1KSWYX5", "forum": "YPSlAbDfcs", "replyto": "YPSlAbDfcs", "signatures": ["ICLR.cc/2026/Conference/Submission18246/Reviewer_PsPo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18246/Reviewer_PsPo"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18246/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923850326, "cdate": 1761923850326, "tmdate": 1762927976273, "mdate": 1762927976273, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a dual-protection scheme that adds an imperceptible, adversarial perturbation to images which (i) acts as a watermark detectable via multi-label conformal prediction on a learned \"score estimator\" and (ii) shifts latent embeddings away from the data distribution so that latent diffusion models produce distorted edits. In the evaluation part, this paper contrasts this design with prior key-based watermarks and reports results covering detection, imperceptibility, distortion on edits, robustness to common transforms, and several security scenarios."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper addresses a timely and important problem of protecting image copyrights amid diffusion-based editing and regeneration.\n- The dual-protection scheme is novel.\n- The reported results suggest the method achieves watermark detectability and editing deterrence while maintaining imperceptibility across evaluated scenarios."}, "weaknesses": {"value": "- The \"distortion\" evaluation relies primarily on FID computed between edited outputs and reference art-style images, which is known to conflate fidelity/diversity and to be sensitive to the feature backbone. Alternative metrics (e.g., precision/recall decompositions) and/or human studies would strengthen the claims [1].\n- The security section focuses on three fixed scenarios (fake watermarking, direct claims, and removal/replacement), but there's no experiment where an attacker adapts to this specific detector or uses detector feedback to tune an attack. This matters because defenses that look fine under fixed tests often fail once attacks are tailored to them, and even simple, query-efficient black-box methods can succeed with limited feedback [2,3,4]. The method also relies on the owner’s secret choice of latent dimensions staying hidden (Section 3.1.1), but there is no analysis of how much a probing attacker could infer from scores or p-values. \n- The claim that a moderate-accuracy VGG backbone \"provides better uncertainty calibration\" for conformal prediction (Section 5.1) is asserted without calibration evidence.\n- The paper itself shows that watermarks trained with one diffusion model do not reliably distort edits from different models (Section 5.5, Case 1), and only report success after retraining the pipeline for each target model (Case 2), which increases deployment cost and narrows protection unless such retraining is feasible at scale.\n\n### References\n- [1] G. Stein et al. Exposing Flaws of Generative Model Evaluation Metrics and Their Unfair Treatment of Diffusion Models. NeurIPS 2023.\n- [2] A. Athalye et al. Obfuscated Gradients Give a False Sense of Security. ICML 2018. \n- [3] F. Tramèr et al. On Adaptive Attacks to Adversarial Example Defenses. NeurIPS 2020. \n- [4] A. Ilyas et al. Black-box Adversarial Attacks with Limited Queries and Information. ICML 2018."}, "questions": {"value": "- The security model hinges on secret selection of m latent dimensions (Section 3.1.1); can an adaptive adversary with query access infer these dimensions, and how does this compare formally with SKS-style secret keys?\n- Section 5.1.1 states VGG yields “better uncertainty calibration” for conformal embedding. Can you elaborate more on this with theoretical or empirical results?\n- Section 5.5 shows limited cross-model transfer; what practical deployment path do you envision: per-encoder retraining or a mechanism to improve transfer?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cjaRcZJSTo", "forum": "YPSlAbDfcs", "replyto": "YPSlAbDfcs", "signatures": ["ICLR.cc/2026/Conference/Submission18246/Reviewer_JgXK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18246/Reviewer_JgXK"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission18246/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980396248, "cdate": 1761980396248, "tmdate": 1762927975969, "mdate": 1762927975969, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}