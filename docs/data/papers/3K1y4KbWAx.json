{"id": "3K1y4KbWAx", "number": 19979, "cdate": 1758301188992, "mdate": 1763730665622, "content": {"title": "TraPO: A Semi-Supervised Reinforcement Learning Framework for Boosting LLM Reasoning", "abstract": "Reinforcement learning with verifiable rewards (RLVR) has proven effective in training large reasoning models (LRMs) by leveraging answer-verifiable signals to guide policy optimization, which, however, suffers from high annotation costs. To alleviate this problem, recent work has explored unsupervised RLVR methods that derive rewards solely from the model’s internal consistency, such as through entropy and majority voting. While seemingly promising, these methods often suffer from model collapse in the later stages of training, which may arise from the reinforcement of incorrect reasoning patterns in the absence of external supervision. In this work, we investigate a novel semi-supervised RLVR paradigm that utilizes a small labeled set to **guide** RLVR training on unlabeled samples. Our key insight is that supervised rewards are essential for stabilizing consistency-based training on unlabeled samples, ensuring that only reasoning patterns verified on labeled instances are incorporated into RL training. Technically, we propose an effective policy optimization algorithm TraPO that filters out reliable unlabeled samples by matching their learning trajectory similarity to labeled ones. Building on this, TraPO achieves remarkable data efficiency and strong generalization on nine advanced benchmarks. With only 1K labeled and 3K unlabeled samples, TraPO reaches 42.6% average accuracy, surpassing the best unsupervised method trained on 45K unlabeled samples (38.3%). Notably, when using 4K labeled and 12K unlabeled samples, TraPO even **outperforms the fully supervised model** trained on the full 45K labeled samples on all benchmarks, while using only **10%** of the labeled data.", "tldr": "", "keywords": ["Reinforcement Learning with Verifiable Rewards", "Semi-supervised Learning", "Large Language Model"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5384951c5b51ad5525766f9dc9e5402535eb876b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "TRAPO tackles semi-supervised RL with verifiable rewards (RLVR) for LLM reasoning. Core idea: use a small labeled set to **anchor** training while selecting reliable unlabeled items via **trajectory similarity**—match each unlabeled sample’s pass-rate curve to the averaged labeled trajectory, then include only top-p/above-threshold items in GRPO updates. Experiments on math ID (AIME/AMC/Minerva/MATH-500/Olympiad) and OOD (ARC-c/GPQA*/MMLU-Pro) show notable label-efficiency gains (e.g., 1k L + 3k U outperforming stronger unsupervised methods; 4k L + 12k U rivaling/ surpassing fully supervised on 45k L). Includes an informal generalization bound tying trajectory consistency to target risk."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. **Clean, intuitive mechanism:** “learn from how learning evolves,” not from point estimates. The trajectory-matching mask is simple to implement atop GRPO and robust to domain shift. \n2. **Label efficiency & breadth:** Strong results with tiny labeled sets; both ID and OOD improvements; ablations with OOD unlabeled data are convincing. \n. **Theoretical framing:** A readable (if high-level) bound linking trajectory similarity and confidence to generalization; clarifies the role of labeled anchors."}, "weaknesses": {"value": "1. **Novelty positioning:** Semi-supervised filtering by “learning dynamics” echoes curriculum/confidence-based selection; paper could contrast more sharply vs. entropy/self-certainty and preference-based filtering beyond empirical gains. \n2. **Proxy fidelity:** Unlabeled “pseudo-pass rates” depend on majority voting; risk of reinforcing easy/short answers remains. Need stress tests where voting is systematically biased. \n3. **Sensitivity & cost:** Top-p/Γ thresholds, warm-up length, rollouts (G=8), batch sizes, β=0, entropy coef=0.01 with no thorough sweep or compute-normalized comparison; H200×8 requirements make label-efficiency claims less practical if compute rises. \n4. **Theory scope:** Bound is informative but rests on simplifying assumptions (e.g., confidence terms, domain discrepancy decomposition); no empirical diagnostics linking bound terms to measured quantities. \n5. **Generalization breadth:** Mostly math-centric; limited non-math/OOD beyond three benchmarks; no noisy-label or adversarial-feedback scenarios."}, "questions": {"value": "Please address the weakness above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "94rXRuGReV", "forum": "3K1y4KbWAx", "replyto": "3K1y4KbWAx", "signatures": ["ICLR.cc/2026/Conference/Submission19979/Reviewer_NfpB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19979/Reviewer_NfpB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19979/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761329021063, "cdate": 1761329021063, "tmdate": 1762932879263, "mdate": 1762932879263, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents TRAPO, a semi-supervised RLVR paradigm. TRAPO measures the similarity between trajectories from unlabeled and labeled data across training epochs and updates the model using only reliable samples. Experiments on the Qwen2.5-7B model demonstrate that TRAPO achieves higher accuracy across several math reasoning benchmarks under limited labeled data settings, and in some cases even surpasses models trained with fully labeled data."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Tackles an important and practical problem in semi-supervised RLVR.\n- The proposed approach is overall reasonable and well-motivated.\n- The paper is clearly written and well-organized.\n- Experimental results show promising improvements."}, "weaknesses": {"value": "- Some design choices require stronger justification (see below).\n- Missing key ablation studies to verify and better understand design components."}, "questions": {"value": "Thank you for submitting this interesting and well-written paper. The problem is timely and relevant, and the proposed direction is promising. Below are my specific questions and suggestions for improvement:\n\n- Q1: Would not the ordering of samples within each epoch affect the results? Because the trajectories of each sample highly depends on the model's current capability.  \n\n- Q2: Why is the average trajectory used as a proxy for similarity a good choice? Have the authors considered clustering the unlabeled data first and then computing per-cluster averages for more robust similarity estimation?\n\n- Q3: Since TRAPO evaluates all data each epoch but only updates with part of it, what is the training overhead, and how does it scale with dataset size?\n\n- Q4: Could the authors clarify the expected-answer criteria used in evaluation (e.g., is $a_i = y$ for all $q \\in D_u$)?\n\n- Q5: The evaluation should include more models. While the Llama-3.1 experiments are appreciated, they lack fair baselines comparable to those in Qwen.\n\n- Q6: It would be informative to report results under different labeled data sizes (e.g., 10K, 20K).\n\n- Q7: Please include a sensitivity analysis for hyperparameters $p$ and threshold $T$ to better understand their influence on performance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "27KwXtd9ML", "forum": "3K1y4KbWAx", "replyto": "3K1y4KbWAx", "signatures": ["ICLR.cc/2026/Conference/Submission19979/Reviewer_aiJH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19979/Reviewer_aiJH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19979/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761339335603, "cdate": 1761339335603, "tmdate": 1762932878475, "mdate": 1762932878475, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes TRAPO, a semi-supervised variant of reinforcement learning with verifiable rewards (RLVR) designed to improve reasoning in large language models (LLMs) with minimal labeled data. The key idea is to use a small labeled dataset to guide policy optimization on much larger unlabeled corpora. TRAPO aligns unlabeled samples with labeled ones by comparing their pass rate trajectories—the evolution of correct-response rates during training—thereby selecting only reliable unlabeled examples for reward-based updates. This stabilizes learning and prevents the collapse common in unsupervised RLVR. Empirically, TRAPO achieves notable data efficiency: with only 1K labeled and 3K unlabeled examples, it outperforms fully unsupervised methods trained on 45K samples; with 4K labeled and 12K unlabeled, it surpasses even fully supervised models trained on all 45K labeled samples. The framework generalizes across domains and model architectures, offering a principled, efficient path for semi-supervised reasoning enhancement in LLMs"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "(1) My biggest takeaway is that carefully curated mixture of labeled and unlabeled data could improve the performance and solve the unstability issue raised in the unsupervised training.\n\n(2) The paper provides rigorous theoretical analysis, including generalization and convergence proofs linking trajectory consistency with domain adaptation theory.\n\n(3) The paper presentation is good and easy to follow, also comes with comprehensive baselines and benchmarks."}, "weaknesses": {"value": "(1) My main concern is the practical usage of the method, to my understanding, the method works as a preprocessing data selection step before launching the training on mixture data, what would be the cost and running time for this step? if it needs a long trajectory to determine good samples, is this process even more costly than the rl training itself? Correct me if I am wrong\n\n(2) I am not sure if the roll out pass rate is a 'stable' indicator of this problem, as everytime the roll out could be different, while the model weights keep updating and the selection mask is applied to question.\n\n(3) I guess one baseline, where selecting samples using your methods vs random selection with the same amount, is missing, because increasing the number of unlabeled data could natuarally worsen the training"}, "questions": {"value": "(1) Is there a threshold that can adjust the total number of selected questions, i.e, sum of M (SigmaM), it could be better if there are trend curve and ablation that when SigmaM =  0, it shows the full grpo result with increment 0%, when it is 1, it gives marginal improvement like 0.6%, and when using your method, the increment is the optimal like 4.3%, and the performance at other possible values in between."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "R4grus9vo0", "forum": "3K1y4KbWAx", "replyto": "3K1y4KbWAx", "signatures": ["ICLR.cc/2026/Conference/Submission19979/Reviewer_UVjM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19979/Reviewer_UVjM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19979/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762133538398, "cdate": 1762133538398, "tmdate": 1762932877714, "mdate": 1762932877714, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}