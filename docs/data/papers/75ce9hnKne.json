{"id": "75ce9hnKne", "number": 20499, "cdate": 1758306842116, "mdate": 1763653679454, "content": {"title": "When Bias Helps Learning: Bridging Initial Prejudice and Trainability", "abstract": "Understanding the statistical properties of deep neural networks (DNNs) at initialization is crucial for elucidating both their trainability and the intrinsic architectural biases they encode prior to data exposure. Mean-field (MF) analyses have demonstrated that the parameter distribution in randomly initialized networks dictates whether gradients vanish or explode. Recent work has shown that untrained DNNs exhibit an initial-guessing bias (IGB), in which large regions of the input space are assigned to a single class. \nIn this work, we provide a theoretical proof linking IGB to MF analyses, establishing that a network’s predisposition toward specific classes is intrinsically tied to the conditions for efficient learning. This connection leads to a counterintuitive conclusion: the initialization that optimizes trainability is systematically biased rather than neutral. We validate our theory through experiments across multiple architectures and datasets.", "tldr": "We prove theoretically that the optimal trainable state is necessarily biased in a wide range of models.", "keywords": ["Trainability", "initial guessing bias", "mean field regime", "phase diagrams"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2bb0525829a8fc7614601620a6e05788a637af89.pdf", "supplementary_material": "/attachment/75626e09e978ea4e6b4d10d504e83e848e58bb6b.zip"}, "replies": [{"content": {"summary": {"value": "Develops a theoretical link between mean-field (MF) trainability and initial guessing bias (IGB) at random initialization. Shows an equivalence between MF quantities and IGB statistics, argues that the edge of chaos corresponds to a state of transient deep prejudice that enables fast learning, and provides supporting experiments on MLPs, a simplified ViT, and a large ImageNet-pretrained ViT fine-tuned on CIFAR-100."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Clear statement of the MF-IGB connection, including a formal mapping between MF covariances and IGB drift ratio, and phase-diagram reinterpretations for bounded and unbounded activations.\n- Reproducibility note and code availability claim.\n- Empirical plus theoretical curves illustrating $c^{(l)}\\rightarrow$1 for ReLU, with different rates in ordered vs. chaotic regimes."}, "weaknesses": {"value": "- Empirical scope is limited relative to broad claims. Experiments focus on binarized Fashion-MNIST, binarized CIFAR-10, CIFAR-10 with simplified MLP/ViT, and a single large ImageNet-pretrained ViT on CIFAR-100.\n\n- Assumptions narrow external validity. Core analysis relies on the infinite-width mean-field regime and an i.i.d. Gaussian input model in the IGB framework.\n\n- Fairness framing without fairness evaluation. The introduction and contributions connect learnability and fairness from initialization onward, but the experiments report only accuracy and maximum class fractions, with no group-attribute metrics.\n\n- Pretraining-bias angle is underdeveloped. For the large ViT, weights are uniformly rescaled to traverse phases, but there is no analysis disentangling ImageNet pretraining priors from weight-scaling dynamics.\n\n- Clarity/calibration: extrapolating MF to practice. Theoretical mapping claims that “best trainability” corresponds to a state of transient deep prejudice (Proposition 4.1), yet validation remains on toy or simplified settings."}, "questions": {"value": "- Representativeness of experiments. Can the empirical section include standard ImageNet-scale or at least non-binarized, multi-class tasks with production architectures (with normalization and residuals) to assess whether the MF–IGB link and the “transient deep prejudice” claim persist beyond toy settings?\n\n- Input-distribution assumptions. How sensitive are the theoretical conclusions to deviating from i.i.d. Gaussian inputs, for example, to real image statistics or correlated features? Any finite-width theory or experiments targeted at non-Gaussian inputs?\n\n- Fairness measurements. Since the paper motivates fairness, could group metrics on a dataset with sensitive attributes be provided to test whether initial “transient deep prejudice” impacts disparities during early training and at convergence?\n\n- Pretraining biases. For the large ViT, is it possible to disentangle the role of ImageNet pretraining from the weight-scaling operation, and measure whether class-prior skew or spurious correlations from pretraining amplify or dampen IGB on the target data?"}, "flag_for_ethics_review": {"value": ["Yes, Other reasons (please specify below)"]}, "details_of_ethics_concerns": {"value": "The paper states that they are finding related work with LLMs, but is that allowed?\nAlso, the entire paper appears to be LLM-written. Now I am not certain if they simply rephrased every human-written paragraph using LLMs or made LLMs generate the entire paper."}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "EgG1DX3WbM", "forum": "75ce9hnKne", "replyto": "75ce9hnKne", "signatures": ["ICLR.cc/2026/Conference/Submission20499/Reviewer_YDAS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20499/Reviewer_YDAS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20499/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761949601365, "cdate": 1761949601365, "tmdate": 1762933930065, "mdate": 1762933930065, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the relationship between initialization bias and trainability of DNNs, reconciling two theoretical perspectives:\n- Mean-Field (MF) theory — which studies gradient propagation and identifies the “edge of chaos” (EOC) as the optimal initialization boundary for stable training;\n- Initial Guessing Bias (IGB) framework — which describes how untrained networks can exhibit predictive bias (favoring one class) even before training.\n\nThe authors establish a formal equivalence between the MF and IGB frameworks, showing that the trainability boundary in MF corresponds to a biased initialization state in IGB. Contrary to the intuitive belief that the most trainable initializations should be neutral, they demonstrate theoretically and empirically that the optimal initialization is systematically biased rather than unbiased — a state they call transient deep prejudice."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Theoretical contribution: The paper establishes a clean mathematical connection between two previously distinct frameworks (MF and IGB), enriching both perspectives.\n2. Insight: It introduces a novel idea: bias at initialization can improve trainability; The new “prejudice-neutrality” phase view offers an intuitive explanation for initialization effects, linking bias to the dynamical stability of gradient flow."}, "weaknesses": {"value": "1. The theory is derived in the infinite-width limit and validated on small- to mid-scale settings. Its applicability to practical, large-scale deep networks (e.g., transformers with normalization and attention) is not demonstrated. Additionally, empirical evaluation focuses on synthetic and small vision datasets. It is of readers' interest to learn results on simple language tasks. \n2. Ambiguous practical relevance: While the “transient bias” insight is conceptually interesting, there is no clear recipe for practitioners (e.g., how to initialize weights to achieve the right level of prejudice). It would be helpful to add some executable takeaways.\n3. It would be helpful to introduce and compare with alternative trainability-enhancing initializations (e.g., orthogonal, LSUV, scaled ReLU, or NTK-based initializations)."}, "questions": {"value": "There can be some terminological confusion: It would be helpful to clarify that “bias,” “prejudice,” and “neutrality” refer to statistical asymmetry / symmetry in prediction space. Otherwise, readers may think about fairness or ethical bias."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "jFJHcHLkRD", "forum": "75ce9hnKne", "replyto": "75ce9hnKne", "signatures": ["ICLR.cc/2026/Conference/Submission20499/Reviewer_h1rA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20499/Reviewer_h1rA"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20499/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761964566424, "cdate": 1761964566424, "tmdate": 1762933929674, "mdate": 1762933929674, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper links two views of randomly initialized networks: initial guessing bias, which is when untrained models over-predict one class, with the mean field theory describing trainability at initialisation. The core result is that there is a mapping between both views, such that the same initialisation that can yield a good gradient flow also produces the most biases starting predictions. The paper extends this across architectural choices, including an experiment to perturb a pre-trained ViT to demonstrate these effects."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. Clean conceptual claim that ties IGB statistics with network trainability\n2. Clear testable claim forhow models which start with maximal bias learn fastest\n3. Robust checks beyond toy MLPs to ViTs, both training and perturbing them"}, "weaknesses": {"value": "1. The infinite width setting is somewhat limiting on the theory side\n2. It's unclear how much the choice of norms matters or whether this result is idiosyncratic\n3. The pooling for the 2-dimensional case is similarly limited"}, "questions": {"value": "1. Is it possible to link the theory to regimes beyond the infinite width setup? \n2. How does this theory work under harder settings e.g. the vanilla MLPs are not the strongest baselines for performance?\n3. Is it possible to measure bias level in practice and across training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "V3gwS9pncf", "forum": "75ce9hnKne", "replyto": "75ce9hnKne", "signatures": ["ICLR.cc/2026/Conference/Submission20499/Reviewer_cZgs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20499/Reviewer_cZgs"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20499/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761985501113, "cdate": 1761985501113, "tmdate": 1762933929311, "mdate": 1762933929311, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies initial guessing bias (IGB)—when a network exhibits a bias towards certain classes. It mathematically links IGB to mean-field theory of wide networks, thus connecting learnability properties to IGB. Using this, the authors show that initializing networks to be optimized for trainability and have stable gradients also yields class bias at initialization."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Understanding how and why neural networks are biased is an important topic for fairness in AI systems. This paper considers the impact of weight initialization, independent of data, which could help us understand how learning dynamics affect bias. By connecting IGB to established mean-field theory of wide networks, it helps build a framework for this. The authors support their theoretical claims with experiments in several architectures and datasets."}, "weaknesses": {"value": "I found the paper difficult to follow and understand. I think it could have more strongly motivated why the link to MF theory is an important one to make and why the contribution made is important. It was also unclear to me at times what was background on previous work versus a novel contribution of the paper.\n\n“Prejudice” is a more loaded term than “bias” and I find the use of it here somewhat inappropriate for what is being referred to. Bias is used to refer to behavior a network might be more prone to do (e.g., inductive bias) and I think would be more apt.\n\nThe paper briefly mentions it, but by assuming the infinite-width limit, the paper focuses on the so-called lazy learning regime. While the lazy learning regime may be valuable to study, it seems like a limitation for a study motivated by fairness to not focus on the rich feature learning regime optimized for in practice. Furthermore, there is substantial literature on feature learning that discusses how different initializations impact learning and representations, which should probably be reviewed and discussed more in this paper.\n\nI think the contribution of the paper is limited. In particular, the main finding concerns how different initializations associated with trainability also reflect different bias. However, although they show that stable initializations are initially biased, this effect goes away with training. It’s unclear whether this specific initialization effect would persist in other settings and actually affect fairness. For example, this result would be strengthened by showing that it persists or is amplified by certain properties of the data."}, "questions": {"value": "What is the difference between “chaotic-deep prejudice” and “(chaotic) prejudice”? Why is it called “deep”?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "ote2fWfXns", "forum": "75ce9hnKne", "replyto": "75ce9hnKne", "signatures": ["ICLR.cc/2026/Conference/Submission20499/Reviewer_2DTJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20499/Reviewer_2DTJ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20499/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762129073478, "cdate": 1762129073478, "tmdate": 1762933928737, "mdate": 1762933928737, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}