{"id": "TiR04Pv0hY", "number": 2509, "cdate": 1757128731997, "mdate": 1759898143923, "content": {"title": "Abductive Reasoning over Temporal Knowledge Graphs via Logical Hypothesis Generation", "abstract": "Abductive reasoning (ABR) aims to infer plausible hypotheses that explain observed facts. Existing studies have mainly focused on abductive reasoning over static knowledge graphs, while the temporal setting remains underexplored. In this paper, we investigate \\textbf{abductive reasoning on temporal knowledge graphs (ABTKG)} and propose a dedicated framework for this task. We first generate logical hypotheses that explain an observation at a given time, and then train a temporal hypothesis generator through supervised learning. However, supervision alone is insufficient to handle unfamiliar observations at specific time points. To address this limitation, we introduce a reinforcement learning objective defined on the TKG, which reduces the gap between the observation and the conclusion produced by the generated hypothesis. Experiments on four public TKG datasets demonstrate consistent improvements in both explanatory power and reasoning accuracy, with gains observed across all datasets.", "tldr": "", "keywords": ["Temporal knowledge graph", "Abductive reasoning", "Temporal knowledge graph reasoning", "Reinforcement learning"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d4b3916f153b69ff237715a9f976d5f65c08f451.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a novel framework for abductive reasoning on temporal knowledge graphs (ABTKG) that combines supervised learning for temporal hypothesis generation with reinforcement learning to enhance generalization to unfamiliar observations, achieving consistent improvements in explanatory power and reasoning accuracy across four benchmark datasets.\n\nNevertheless, the submitted paper exhibits substantial similarity to the referenced work [1], introducing only minor modifications. Consequently, I do not consider this submission suitable for the ICLR community.\n\nReference: [1] Controllable logical hypothesis generation for abductive reasoning in knowledge graphs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper introduces the concept of abductive reasoning within the context of temporal knowledge graphs."}, "weaknesses": {"value": "1. The logical hypotheses presented in Figure 1 closely resemble the structural form of logical rules found in temporal knowledge graphs. Nevertheless, the introduction section lacks a comparative discussion between these two concepts.\n\n2. The Related Work section does not sufficiently review recent developments in temporal knowledge graph reasoning, particularly with respect to logical inference and reinforcement learning approaches. Moreover, the discussion on abductive reasoning is nearly identical to that of Reference [1]; however, an explicit introduction and discussion of [1] is absent.\n\n3. The proposed methodology demonstrates a significant lack of originality, as its core framework is nearly identical to that of Reference [1]. The only modifications involve the introduction of a temporal hypothesis generator and the replacement of the original GRPO algorithm with PPO.\n\n4. Section 5.7 does not specify the size of the T5 model utilized in the experiments, which may compromise the validity and fairness of the experimental conclusions."}, "questions": {"value": "See Weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "m5qNLuRj55", "forum": "TiR04Pv0hY", "replyto": "TiR04Pv0hY", "signatures": ["ICLR.cc/2026/Conference/Submission2509/Reviewer_TA8e"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2509/Reviewer_TA8e"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2509/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761473653437, "cdate": 1761473653437, "tmdate": 1762916260277, "mdate": 1762916260277, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates abductive reasoning over temporal knowledge graphs (TKGs) and proposes ABRTKG, a two-stage generative framework: (i) supervised logical-hypothesis generation conditioned on observations and time, and (ii) PPO-based reinforcement learning with multi-signal rewards (Jaccard, Dice, Overlap) computed against the observed temporal graph. The task is formalized under the open-world assumption; hypotheses are first-order logical queries whose conclusions are compared to the observation via set similarity. The pipeline first constructs temporal observation–hypothesis pairs from predefined logical patterns, trains a GPT-2 decoder that merges relation and time embeddings, and then applies RL with a KL penalty to keep the policy near the supervised reference. Experiments on ICEWS14, ICEWS18, YAGO, and WIKI include per-pattern analyses, ablations on reward combinations, explicit-vs-implicit temporal encodings, and GPT-2 vs T5 backbones. Results show strong gains from RL on complex patterns, while simple patterns and certain datasets see mixed effects; explicit timestamp concatenation consistently hurts. Structural faithfulness is reported with a Smatch-style graph metric after an AMR compatibility conversion."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.Notation and dataset inconsistencies that hinder clarity. The paper alternates between ABTKG and ABRTKG; similarly, the intro text says “three datasets,” while elsewhere four datasets and Table 1 are used. Please unify the name throughout and fix the dataset count. \n\t2.Limited theoretical grounding for temporal gains. The work’s conceptual story is strong, but the paper lacks formal insight into why temporal constraints and the merged (r, t) tokenization improve abductive inference under OWA. For example, conditions under which maximizing Jaccard on J_H (K_G ) approximates abductive optimality, or when KL-regularized PPO improves generalization, are not analyzed beyond empirical evidence. Adding propositions around the objective in Eq. (3) and the PPO objective (Eq. (6)) would strengthen the contribution. \n\t3.Negation under OWA needs clearer semantics. Since OWA treats unobserved facts as unknown, the meaning of negative literals (¬r) in training and evaluation must be clarified. Ambiguity here affects both pattern construction and reward evaluation. \n\t4.Reward design rationale is mostly empirical. Although the multi-signal reward shows benefits, the choice and weighting of Jaccard/Dice/Overlap are justified empirically rather than via properties tied to temporal reasoning. A principled analysis would improve credibility. \n\t5.Structural faithfulness vs. semantic accuracy trade-off. Table 2 shows that RL improves Jaccard averages yet lowers Smatch averages on multiple datasets—suggesting that optimization may favor set-level matches at the expense of structural alignment. Please discuss and, if possible, regularize for structure. \n\t6.Baselines for temporal reasoning are not directly compared. The related-work section mentions TeMP, xERTE, and TiRGN, but the experiments do not contrast ABRTKG against these temporal baselines on shared patterns, leaving open how much gain stems from the abductive formulation vs. improved temporal modeling."}, "weaknesses": {"value": "1.Notation and dataset inconsistencies that hinder clarity. The paper alternates between ABTKG and ABRTKG; similarly, the intro text says “three datasets,” while elsewhere four datasets and Table 1 are used. Please unify the name throughout and fix the dataset count. \n\t2.Limited theoretical grounding for temporal gains. The work’s conceptual story is strong, but the paper lacks formal insight into why temporal constraints and the merged (r, t) tokenization improve abductive inference under OWA. For example, conditions under which maximizing Jaccard on J_H (K_G ) approximates abductive optimality, or when KL-regularized PPO improves generalization, are not analyzed beyond empirical evidence. Adding propositions around the objective in Eq. (3) and the PPO objective (Eq. (6)) would strengthen the contribution. \n\t3.Negation under OWA needs clearer semantics. Since OWA treats unobserved facts as unknown, the meaning of negative literals (¬r) in training and evaluation must be clarified. Ambiguity here affects both pattern construction and reward evaluation. \n\t4.Reward design rationale is mostly empirical. Although the multi-signal reward shows benefits, the choice and weighting of Jaccard/Dice/Overlap are justified empirically rather than via properties tied to temporal reasoning. A principled analysis would improve credibility. \n\t5.Structural faithfulness vs. semantic accuracy trade-off. Table 2 shows that RL improves Jaccard averages yet lowers Smatch averages on multiple datasets—suggesting that optimization may favor set-level matches at the expense of structural alignment. Please discuss and, if possible, regularize for structure. \n\t6.Baselines for temporal reasoning are not directly compared. The related-work section mentions TeMP, xERTE, and TiRGN, but the experiments do not contrast ABRTKG against these temporal baselines on shared patterns, leaving open how much gain stems from the abductive formulation vs. improved temporal modeling."}, "questions": {"value": "1.\tConsistency in naming and dataset count.Please confirm the official method name and the dataset count used in the final version to avoid confusion created by the current mixture of three and four dataset references and two method names.\n2.\tNegation and open-world formalization\nHow are negative literals handled during training signal construction and reward computation. Please clarify whether negatives are evaluated against the observed training graph or an estimate of the hidden graph and how this choice affects patterns that include negation. \n3.\tObjective-level guarantees\nUnder what conditions does maximizing the Jaccard objective on the hidden graph lead to abductively correct hypotheses with temporal constraints. Any sufficient conditions or counter-examples would help scope the guarantees around Equation three. \n4.\tRole of KL-regularized PPO\nCan you articulate when the KL-penalized policy improves generalization rather than overfitting to set-level signals. A brief discussion tied to the dynamic penalty schedule would make the reinforcement stage more principled. \n5.\tReward sensitivity and stability\nHow sensitive are results to the lambda weights and the beta schedule. Do you see signs of instability during PPO updates. Training-curve snapshots for rewards and KL terms would clarify optimization behavior. \n6.\tPattern complexity coverage\nSince samples are allocated equally across thirteen patterns, could you report statistics of variable counts, recursion depth, and answer set sizes in the constructed training pairs, and relate them to per-pattern results."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "n8De6yfCTc", "forum": "TiR04Pv0hY", "replyto": "TiR04Pv0hY", "signatures": ["ICLR.cc/2026/Conference/Submission2509/Reviewer_6vPf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2509/Reviewer_6vPf"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2509/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761833469230, "cdate": 1761833469230, "tmdate": 1762916259999, "mdate": 1762916259999, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the task of abductive reasoning on temporal knowledge graphs (ABTKG), identifying this as an underexplored area compared to existing work on static KGs. The authors propose a framework that begins by training a temporal hypothesis generator through standard supervised learning. To address the limitations of this initial approach, the framework is then augmented with a reinforcement learning objective designed to handle unfamiliar observations at specific time points. Experiments conducted on four public TKG datasets reportedly demonstrate consistent improvements in both explanatory power and reasoning accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The manuscript is well-written and easy to follow. The related work section is comprehensive and well-contextualized.\n2. The split of the train, validation, and test datasets is fair. Furthermore, the progressive inclusion of unseen snapshots effectively examines the proposed approach's performance.\n3.  The reward function defined by the authors can be viewed as multi-objective, as its components represent distinct goals. The authors rigorously conducted an ablation study, with the results reported in Table 4."}, "weaknesses": {"value": "1. The authors mention abductive reasoning on static KGs (Bai et al., 2024; Gao et al., 2025) in the Introduction, but these works are not discussed in the Related Work section.\n2. The notations in Section 3 are somewhat unclear. For example, what is the exact relationship between $r_{im,t}$ and $r(u,v,t)$? Moreover, it would be helpful if the authors included the formal definitions of the Dice similarity coefficient and overlap volume in the manuscript to help readers who are not familiar with these concepts.\n3. The only baseline used in this work is GPT-2, which is quite outdated. More recent and knowledge-enhanced language models are known to perform better on KG-involved tasks, but the authors do not include any such models in their comparison. This weak baseline comparison (combined with the issue raised in Q1) calls into question the robustness and significance of the experimental results, making it difficult to assess the true effectiveness of the proposed method.\n4. While the authors state that the key contribution of this work is abductive reasoning on TKGs, the proposed methods and experiments are not sufficient to support this novelty claim. The authors modify TKG data for abductive reasoning in the problem definition section, but none of the proposed methods in Section 4 appears to be specifically targeted to handle abductive reasoning on TKGs."}, "questions": {"value": "1. It is unclear why the authors did not include static KG-based methods as baselines. If these methods are not directly applicable to TKGs, the authors should either adapt them for comparison or elaborate in the manuscript (e.g., in the related work or experimental setup) on why this is not feasible.\n2. The citation for Smatch appears to be missing. The authors should also specify which version of the Smatch metric was used. Moreover, I recommend that the authors include a brief definition of Smatch in the paper to make the manuscript more self-contained."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "aztXBLAMwo", "forum": "TiR04Pv0hY", "replyto": "TiR04Pv0hY", "signatures": ["ICLR.cc/2026/Conference/Submission2509/Reviewer_WYQJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2509/Reviewer_WYQJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2509/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762045284706, "cdate": 1762045284706, "tmdate": 1762916259640, "mdate": 1762916259640, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}