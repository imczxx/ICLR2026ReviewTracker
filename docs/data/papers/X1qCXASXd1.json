{"id": "X1qCXASXd1", "number": 5734, "cdate": 1757930360541, "mdate": 1759897957564, "content": {"title": "MiCoTA: Bridging the Learnability Gap with Intermediate CoT and Teacher Assistants", "abstract": "Large language models (LLMs) excel at reasoning tasks requiring long thought sequences for planning, reflection, and refinement. However, their substantial model size and high computational demands are impractical for widespread deployment. Yet, small language models (SLMs) often struggle to learn long-form CoT reasoning due to their limited capacity, a phenomenon we refer to as the \"SLMs Learnability Gap\". To address this, we introduce \\textbf{Mi}d-\\textbf{Co}T \\textbf{T}eacher \\textbf{A}ssistant Distillation (MiCoTAl), a framework for improving long CoT distillation for SLMs. MiCoTA employs intermediate-sized models as teacher assistants and utilizes intermediate-length CoT sequences to bridge both the capacity and reasoning length gaps. Our experiments on downstream tasks demonstrate that although SLMs distilled from large teachers can perform poorly, by applying MiCoTA, they achieve significant improvements in reasoning performance. Specifically, Qwen2.5-7B-Instruct and Qwen2.5-3B-Instruct achieve an improvement of 3.47 and 3.93 respectively on average score on AIME2024, AMC, Olympiad, MATH-500 and GSM8K benchmarks. To better understand the mechanism behind MiCoTA, we perform a quantitative experiment demonstrating that our method produces data more closely aligned with base SLM distributions. Our insights pave the way for future research into long-CoT data distillation for SLMs.", "tldr": "We propose MiCoTA, a distillation method that improve the long reasoning ability in small language models.", "keywords": ["Math Reasoning", "Knowledge Distillation", "LLM"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/789f235b31b4281842bc4195316cc1adf321e756.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses the reasoning ability gap between large and small language models in Chain-of-Thought (CoT) reasoning distillation. The authors observe that small models often fail to learn effectively from long reasoning traces generated by powerful teachers. To tackle this, they propose MICOTA (Mid-CoT Teacher Assistant Distillation), a framework that introduces an intermediate-sized “Teacher Assistant” (TA) model and leverages intermediate-length CoT sequences to bridge both the capacity gap and the reasoning-length gap between teacher and student models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear problem definition. This paper clearly identifies the SLM learnability gap as a crucial issue in long-CoT distillation, framing it along both capacity and reasoning-length dimensions.\n2. Intuitive idea. The “half-size, half-length” strategy is intuitive and well-grounded. Combining teacher-assistant distillation with model-merging (DARE + TIES) to generate mid-length CoTs is novel in the CoT context.\n3. Thorough experimental validation.  The experimental results are across multiple model scales and benchmarks. Ablations confirm the method contributes to the performance."}, "weaknesses": {"value": "1. Lack of theoretical grounding. The key novelty is their combination for “half-size, half-length” CoTs. The paper does not provide a principled criterion for how much to shorten CoTs or why the proposed merge yields half length beyond an anecdotal trend and a qualitative claim about “approximately half” tokens.\n2. Evaluation is narrow on math.  All five core benchmarks are mathematical or math-heavy. This makes it unclear whether MICOTA generalizes to non-mathematical reasoning. The current evidence may only reflect math-specific artifacts rather than a general CoT length–capacity phenomenon.\n3. Evaluation protocol is limited and may mask errors. The paper uses greedy decoding, a single maximum length, and exact-match via rule-based answer extraction only. Many math benchmarks require robust extraction guards to avoid format drift. The absence of calibration curves or solution-consistency checks weakens claims about genuine reasoning improvement."}, "questions": {"value": "1. I wonder whether “half-size, half-length” CoTs really play a role. I hope more evidence shows that this method is better than usual distillation.\n2. The failure analysis is not enough. Figure 1 can not prove this situation.\n3. The efficiency of investing compute between MICOTA and other models?\n4. As the paper only uses Qwen, what about other models? This is important for generalizability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ah0bMKvGIn", "forum": "X1qCXASXd1", "replyto": "X1qCXASXd1", "signatures": ["ICLR.cc/2026/Conference/Submission5734/Reviewer_KAks"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5734/Reviewer_KAks"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5734/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761829235378, "cdate": 1761829235378, "tmdate": 1762918226349, "mdate": 1762918226349, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the \"SLMs Learnability Gap\", where small language models (SLMs) struggle to learn long-form Chain-of-Thought (CoT) reasoning from large language models (LLMs) due to limited capacity. It introduces the MiCOTA framework, which uses intermediate-sized teacher assistants to generate intermediate-length CoT sequences, significantly improving SLMs' long CoT distillation performance, as demonstrated by notable gains on multiple mathematical reasoning benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The framework design is reasonable and has a certain novelty: The paper addresses a practical issue in Large Language Model (LLM) knowledge distillation and proposes a clear solution with sufficient motivation. The concept of \"learning capability gap\" relatively accurately summarizes the problem, and the proposed \"teacher-assistant-student\" pipeline is a reasonable and logically consistent approach to bridge this gap.\n2. The experimental results are convincing and show good performance: The main experimental validation process is detailed and has strong argumentative power. The authors demonstrate obvious performance improvements across multiple student models and a series of challenging reasoning benchmarks; moreover, the comparison with the \"strong teacher CoT\" baseline directly provides support for the core hypothesis."}, "weaknesses": {"value": "1. Domain Generalization：All evaluations are conducted on mathematical reasoning tasks. It remains unclear whether MiCOTA generalizes to other reasoning-heavy domains (e.g., code reasoning, legal text analysis, multi-hop QA).\n2. Faithfulness and Error Propagation in Mid-CoT：This methodology relies on a Teacher Assistant that is not perfect, leading to the risk of error propagation that has not been fully addressed. If the intermediate CoT generated by the TA has flaws, omissions, or misunderstandings, it may be systematically learned by the student model. The paper does not explore the potential quality degradation in the knowledge transfer process, which raises concerns about the reliability and robustness of the final student model.\n3. Analysis of practical application feasibility is missing: The paper fails to address a key practical issue of the proposed scheme, namely, it does not resolve the significant computational overhead introduced by the MiCOTA framework. Given that efficiency is one of the main motivations for using SLMs, it is difficult to evaluate the practical application value of this method without discussing the trade-off between performance gain and additional costs.\n4. Ablation on TA Size and CoT Length：The “half-size, half-length” heuristic is intuitive but untested."}, "questions": {"value": "1. Add more intuitive examples in the appendix: For the same complex problem, present the CoT outputs of the teacher, assistant, and student models to intuitively demonstrate the step-by-step simplification of reasoning complexity. Meanwhile, provide the prompt for LLM-as-Judge to facilitate readers in reproducing the relevant evaluations.\n2. The current experimental scenarios have limitations: Experiments are mainly focused on the field of mathematical reasoning. If they can further cover a wider range of tasks such as commonsense reasoning, multi-hop question answering, and scientific problem-solving, it will more fully prove the generality and practical value of the method.\n3. It is suggested to supplement the analysis of boundary cases: The effectiveness of MiCOTA may be affected by the capability gap between the student and assistant models. It is recommended to systematically explore two types of boundary cases. First, when the student model is extremely small, whether the learning capability gap is too large to be bridged even with the introduction of an assistant. Second, when the capabilities of the student and assistant models are close, whether the performance improvement is close to negligible. Such analysis will help clarify the optimal application scenarios of the method."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Do6gm6LK2G", "forum": "X1qCXASXd1", "replyto": "X1qCXASXd1", "signatures": ["ICLR.cc/2026/Conference/Submission5734/Reviewer_YsLS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5734/Reviewer_YsLS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5734/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761892096247, "cdate": 1761892096247, "tmdate": 1762918226050, "mdate": 1762918226050, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of small language models (SLMs) struggling to learn long-form Chain-of-Thought (CoT) reasoning when distilled from large teacher models—a phenomenon termed the \"SLMs Learnability Gap.\" The authors propose MICOTA (Mid-CoT Teacher Assistant Distillation), a framework that employs intermediate-sized models as teacher assistants and utilizes intermediate-length CoT sequences to bridge both the capacity gap and reasoning length gap. The method involves training an intermediate-sized model (14B) on long CoT data from a strong teacher (32B), then using model merging (DARE algorithm) to create a \"Mid-CoT Teacher Assistant\" that generates medium-length CoT sequences. Small student models (1.5B, 3B, 7B) are then trained on this intermediate data."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Clear problem motivation with concrete experimental evidence\n- Well-structured paper with logical flow from problem identification to solution\n- Addresses a practical problem in deploying reasoning-capable SLMs"}, "weaknesses": {"value": "- No rigorous theoretical explanation for why intermediate-length CoT should help beyond the intuitive capacity/length gap argument\n- Only evaluated on math reasoning tasks (AIME, AMC, Olympiad, MATH-500, GSM8K)\n- Missing analysis of what happens with different TA sizes"}, "questions": {"value": "- Can you provide theoretical or empirical evidence for why half-length CoT is optimal? Why not 1/3 or 2/3 length?\n- How do you select the optimal TA size?\n- Can you test MICOTA on other model families (LLaMA, Mistral) to show generalization?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "xP0V5FIMhO", "forum": "X1qCXASXd1", "replyto": "X1qCXASXd1", "signatures": ["ICLR.cc/2026/Conference/Submission5734/Reviewer_kFWh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5734/Reviewer_kFWh"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5734/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762167288153, "cdate": 1762167288153, "tmdate": 1762918225671, "mdate": 1762918225671, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}