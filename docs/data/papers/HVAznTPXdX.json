{"id": "HVAznTPXdX", "number": 7424, "cdate": 1758021172259, "mdate": 1759897853541, "content": {"title": "Controllable Adversarial Makeup for Privacy via Text-Guided Diffusion", "abstract": "As face recognition becomes more widespread in government and commercial services, its potential misuse raises serious concerns about privacy and civil rights. To counteract this threat, various anti-facial recognition techniques have been proposed, which protect privacy by adversarially perturbing face images. Among these, generative makeup-based approaches are the most widely studied. However, these methods, designed primarily to impersonate specific target identities, can only achieve weak dodging success rates while increasing the risk of targeted abuse. In addition, they often introduce global visual artifacts or a lack of adaptability to accommodate diverse makeup prompts, compromising user satisfaction. To address the above limitations, we develop MASQUE, a novel diffusion-based framework that generates localized adversarial makeups guided by user-defined text prompts. Built upon precise null-text inversion, customized cross-attention fusion with masking, and a pairwise adversarial guidance mechanism using images of the same individual, MASQUE achieves robust dodging performance without requiring any external identity. Comprehensive evaluations on open-source facial recognition models and commercial APIs demonstrate that MASQUE significantly improves dodging success rates over all baselines, along with higher perceptual fidelity preservation, stronger adaptability to various makeup prompts, and robustness to image transformations.", "tldr": "", "keywords": ["Adversarial Makeup", "Diffusion Model", "Anti-Facial Recognition"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6b4f0813dfd70e48976c4a0a6c5c3d06857fcafc.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents MASQUE, a diffusion-based framework that generates localized adversarial makeup guided by text prompts to protect facial privacy. While the motivation is meaningful and the implementation is solid, the method mainly combines existing ideas with limited novelty and questionable contributions. Therefore, I recommend rejection for the reasons discussed above.\n\nNote that **it is also published as an ICLR Workshop**; I'm not sure if this is compliant. MASQUE: A Text-Guided Diffusion-Based Framework for Localized and Customized Adversarial Makeup."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed method enables local modifications and text control.\n- The writing is very clear.\n- Research questions are highly meaningful."}, "weaknesses": {"value": "## 1、Weak and combinational technical novelty\nThe proposed approach combines existing techniques such as makeup transfer [1], diffusion-based editing [2], and face masking [3] to achieve facial privacy protection. All of these components have already been explored in prior work, resulting in limited technical innovation.\n\n[1] Diffam: Diffusion-based Adversarial Makeup Transfer for Facial Privacy Protection  \n[2] DiffPrivate: Facial Privacy Protection with Diffusion Models  \n[3] NullFace: Training-Free Localized Face Anonymization\n\n## 2、Questionable contributions\n- The authors claim that their method performs target-free protection, i.e., it does not require any external or reference identity beyond the victim. However, this should not be considered an advantage. A target-free attack produces anonymized faces that correspond to uncontrolled, random identities, which could cause confusion or ethical concerns in real-world scenarios. In contrast, targeted anonymization allows assigning a virtual identity to avoid such issues. Therefore, the claimed “Inoffensive Identity Protection” cannot be regarded as a valid contribution.\n- Moreover, the paper does not introduce any technical innovations specific to the target-free setting; it merely employs a standard adversarial identity loss, which makes the claimed effectiveness unconvincing.\n\n## 3、Doubtful transferability\n- The authors do not present any concrete mechanisms to enhance the transferability of their protection method, yet the paper claims that it can generalize to unseen models. This is puzzling and raises questions about the reliability of the results.\n- **More importantly, I cropped and tested several protected faces generated by MASQUE (Fig. 1)  using the Face++ recognition API, and the verification similarity still reached around 90%**, suggesting that the proposed method fails to achieve effective protection."}, "questions": {"value": "1. Could the authors clarify which components or mechanisms constitute the novel technical contribution of this work? Does the framework introduce any new learning objectives, optimization strategies, or architectural innovations beyond combining existing modules?\n\n2. The authors highlight the target-free protection setting as a main contribution. Could the authors elaborate on why this should be considered an advantage compared to targeted anonymization, which can assign consistent virtual identities to avoid ambiguity?\n\n3. The paper claims that the proposed method generalizes to unseen models. Could the authors clarify what mechanisms or training strategies enable this transferability?\n\n4. In independent testing (e.g., using the Face++ recognition API), some protected faces still yielded similarity scores around 90%. How do the authors explain this high similarity, and what does it imply about the practical robustness of the protection mechanism?\n\nGiven its current weaknesses, I find it difficult to accept this work for publication at the top-tier conference ICLR unless the authors provide strong supporting evidence."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "AknegDUIC0", "forum": "HVAznTPXdX", "replyto": "HVAznTPXdX", "signatures": ["ICLR.cc/2026/Conference/Submission7424/Reviewer_mg7j"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7424/Reviewer_mg7j"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7424/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760467950197, "cdate": 1760467950197, "tmdate": 1762919544853, "mdate": 1762919544853, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents MASQUE, a text-guided adversarial makeup generation method for defending against malicious face recognition. The manuscript provides a thorough introduction to the anti–facial recognition (AFR) task, reviews related work, and details the necessary preliminaries and problem formulation. After outlining the limitations of existing AFR approaches, the authors propose MASQUE, a diffusion-based adversarial technique driven by user-supplied text prompts. Experiments demonstrate the effectiveness of MASQUE on the AFR task."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "Following the four evaluation aspects outlined in the instructions, the strengths of the proposed method are summarized below.\n\n**Originality**: The method’s novelty is rather limited. Although the authors give a thorough overview of the task, background, motivation, and technical details, the work contributes little genuinely new knowledge.\n\n**Quality and Clarity**: The paper is well written, clearly structured, and easy to follow; even readers unfamiliar with the field should have no difficulty understanding it.\n\n**Significance**: While the study may interest researchers in AI or biometric forensics and safety, its technical contributions are not sufficiently novel to be considered significant for the broader AI community."}, "weaknesses": {"value": "The principal weakness of this work is its limited methodological novelty. While MASQUE does mitigate shortcomings of existing AFR approaches in AI-safety applications, it is essentially a pipeline assembled from established techniques, such as cross-attention-based target grounding and DDIM inversion. Although effective, the incremental knowledge it provides appears, in my view, insufficient to meet the ICLR novelty threshold."}, "questions": {"value": "The authors are encouraged to highlight the methodological innovations of their work, ideally in an application-agnostic manner that would engage the broader AI community. If such novelty is clearly demonstrated, I am prepared to raise my rating; otherwise, if the contribution remains merely a new AFR pipeline, the recommendation will not be changed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "t5MCfMpIJl", "forum": "HVAznTPXdX", "replyto": "HVAznTPXdX", "signatures": ["ICLR.cc/2026/Conference/Submission7424/Reviewer_WCjs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7424/Reviewer_WCjs"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7424/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761386230421, "cdate": 1761386230421, "tmdate": 1762919544276, "mdate": 1762919544276, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel diffusion-based framework to protect user privacy from facial recognition by generating localized, text-guided adversarial makeup. The authors address key limitations of prior methods, namely their risky focus on impersonation and their resulting weak dodging performance and visual artifacts. The proposed framework employs a pairwise adversarial guidance mechanism, which uniquely uses another image of the same individual rather than an external target to achieve robust dodging success. Furthermore, it utilizes customized cross-attention fusion with masking and null-text inversion to ensure precise, high-fidelity modifications that strongly adhere to user prompts. The method achieves state-of-the-art dodging performance and higher visual quality."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe method ensures high dodging success by only requiring the user's own images, not an external person's image. This design choice inherently reduces the risks of targeted misuse and ethical concerns.\n2.\tThe framework employs a facial mask generation module to strictly constrain adversarial perturbations to designated areas. This localization ensures the original image itself is not globally altered, preserving its fine-grained details and vastly enhancing the visual quality of the final protected image.\n3.\tExtensive experiments justify the selection of each parameter, making the results more credible."}, "weaknesses": {"value": "1.\tThe framework's core \"pairwise adversarial guidance\" mechanism performs best when provided with one or more additional images of the user. Its performance is notably weaker when no separate guide image is available, and the tested self-augmentation techniques (like flipping) provide minimal benefits. This dependency limits its effectiveness in common scenarios where a user may only have a single photo.\n2.\tThe current framework suffers from limited efficiency, with the overall process being relatively time-consuming."}, "questions": {"value": "1.\tHow does the L_edit loss (in Eq. 5) handle global prompts like \"tanned skin\"? For such a prompt, the mask must cover the entire face, creating a spatial conflict where the new token (\"tanned skin\") and the shared structural token (\"face\") occupy the same region. \n2.\tDoes the paper analyze the nature of this dodging? Specifically, is the protected image consistently misclassified by the FR system as a single, specific incorrect identity (which would be akin to an untargeted impersonation), or is it pushed into a non-man in the feature space, making it dissimilar to all identities in the database?\n3.\tHow sensitive is this method to differences between the guidance image and the input image? Would it still be effective if the guidance image has a completely different angle or pose?\n4.\tIs the framework's capability limited to only a predefined set of large facial regions (like 'lips', 'eyes', 'skin')? If so, would expanding this module to support a much wider and more granular set of regions (e.g., 'cheeks', 'nose-bridge', 'chin') allow the model to generate a more diverse range of makeup styles to improve the framework's overall robustness against FR systems?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "kjv1HvbgNI", "forum": "HVAznTPXdX", "replyto": "HVAznTPXdX", "signatures": ["ICLR.cc/2026/Conference/Submission7424/Reviewer_JWTj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7424/Reviewer_JWTj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7424/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761818962898, "cdate": 1761818962898, "tmdate": 1762919543170, "mdate": 1762919543170, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces MASQUE, a diffusion-based framework for generating localized adversarial makeup through text guidance to protect facial privacy from recognition systems. Unlike prior approaches that rely on target identities or produce visible artifacts, MASQUE combines null-text inversion, cross-attention fusion with masking, and pairwise adversarial guidance using images of the same person to achieve identity dodging without external references. Experiments on CelebA-HQ, VGG-Face2-HQ, and commercial APIs show that MASQUE achieves higher dodging success rates, better visual quality, and stronger prompt adherence than existing AFR methods. The method also offers fine-grained user control, robustness to image transformations, and avoids ethical concerns linked to impersonation-based attacks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Originality: Proposes a novel diffusion-based approach for adversarial makeup generation using text guidance, eliminating the need for external identity references and addressing ethical concerns of impersonation-based methods.\n\nTechnical Quality: introduces well-motivated and effective components such as null-text inversion, cross-attention masking, and pairwise adversarial guidance that together yield strong privacy protection with high visual fidelity.\n\nClarity: The paper is clearly structured with detailed explanations, visual examples, and ablation studies that make the method and results easy to understand.\n\nSignificance: Addresses an important and timely issue of facial privacy, achieving state-of-the-art dodging success while maintaining natural appearance and user controllability, making it both practically and socially impactful."}, "weaknesses": {"value": "1 - The method’s applicability across gender and makeup preferences is unclear. Since makeup-based protection may inherently favor female faces, it would be important to test whether the approach remains effective and unbiased for male faces or faces without visible makeup cues.\n\n2 - The paper depends on a face parsing network for region localization, but there are no details about this model, its training data, or accuracy. The process for generating masks or mapping text prompts to facial regions is not clearly explained, despite being central to the method’s design.\n\n3 - The reported runtime of around 90 seconds per image is notably slower than prior works such as Clip2Protect (18 s) and DiffAM (30 s), which limits practical deployment and suggests a need for optimization.\n\n4 - The evaluation lacks human perceptual studies to assess the visual realism and subjective quality of generated makeup, which would complement the quantitative metrics used.\n\n5 - The authors note that prior work (e.g., C2P) produces artifacts beyond facial regions, but do not discuss whether similar masking techniques could have been integrated into those baselines or experimentally justify why MASQUE performs better in this respect.\n\n6 - Ablation depth: Although the paper includes some ablations, it doesn’t isolate the contribution of each major component (e.g., null-text inversion vs. pairwise adversarial guidance) in improving dodging success and image quality. A more granular breakdown would help understand which parts are most critical."}, "questions": {"value": "Please see the weaknesses section"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Vg0Q3kFtNx", "forum": "HVAznTPXdX", "replyto": "HVAznTPXdX", "signatures": ["ICLR.cc/2026/Conference/Submission7424/Reviewer_N3Wv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7424/Reviewer_N3Wv"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7424/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762594380022, "cdate": 1762594380022, "tmdate": 1762919542625, "mdate": 1762919542625, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}