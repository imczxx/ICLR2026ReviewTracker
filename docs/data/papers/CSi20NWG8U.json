{"id": "CSi20NWG8U", "number": 23324, "cdate": 1758342153633, "mdate": 1758807201510, "content": {"title": "CulturAdaptEval: Do Language Models Get You? A Dual-Axis Benchmark for Cultural Empathy in Multicultural Dialogue", "abstract": "Large Language Models (LLMs) are no longer just text generators—they are\ncompanions, advisors, and interlocutors embedded in daily life. But do they truly\nget the people they serve? Prior work has studied empathy and cultural adaptation\nseparately, but never in tandem. We introduce EXACT (Empathy × Culture\nAssessment of Conversational Tasks), the first framework for evaluating cultural\nempathy in dialogue. EXACT combines (i) a dual-axis benchmark of 504 culturally\nsituated scenarios—spanning 12 globally grounded personas (e.g., a South Indian\nstudent ashamed of disappointing her family) and 6 core emotional states (e.g.,\ngrief, shame, guilt, spiritual doubt)—with (ii) a robustness-first evaluation protocol\nthat integrates multi-family ensemble judges, order randomization with flip-check\nfiltering, verbosity controls, and Bradley–Terry–Luce modeling with bootstrap\nconfidence intervals.\nWe evaluated 14 state-of-the-art LLMs across multiple providers and anchor\nautomated scores with a targeted human validation study using Best–Worst Scaling,\nstrategically oversampling ambiguous cases, and key model rivalries. Our findings\nreveal stark cultural blind spots, emotion-dependent empathy failures, and rank\ninversions between pooled and macro-averaged scores, challenging the notion of a\nsingle “best” model. All prompts, generations, and evaluation code are released to\ncatalyze the development of culturally aligned AI.", "tldr": "", "keywords": ["Cultural Empathy", "Dialogue Evaluation", "Benchmarking LLMs", "Cross-Cultural Adaptation", "Emotionally Aware AI", "Responsible AI"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/1734d742e83a250047ebbc6648b0b157c499d320.pdf", "supplementary_material": ""}, "replies": [], "withdrawn": true}