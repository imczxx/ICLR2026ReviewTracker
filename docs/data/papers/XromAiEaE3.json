{"id": "XromAiEaE3", "number": 16193, "cdate": 1758261345562, "mdate": 1759897255276, "content": {"title": "GraphMind: LLMs as Dynamic Knowledge Builders for Sequential Decision-Making", "abstract": "While the reasoning capabilities of large language models (LLMs) have advanced considerably due to their extensive internal knowledge, efficiently internalizing and leveraging new information in dynamic environments remains challenging. This limitation is particularly pronounced in partially observable environments, which require agents to manage long-term memory and perform effective exploration under incomplete information. To address this, we propose an LLM agent architecture that integrates a knowledge graph as a graph-based memory module to facilitate high-level action planning. The agent incrementally constructs the knowledge graph through environmental interactions and retrieves relevant information to formulate efficient plans. We evaluate our approach in complex navigating environments specifically designed to present long-horizon and partially observable challenges. Experimental results demonstrate that employing a knowledge graph as an external memory significantly enhances the success rate and efficiency of the LLM’s planning capabilities.", "tldr": "", "keywords": ["Large Language Models", "Sequential Decision Making"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c1ec4a6f867946385bf3612a01ec61abfd0023c0.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "\"GraphMind: LLMs as Dynamic Knowledge Builders for Sequential Decision-Making\" proposes an LLM agent that constructs and uses a dynamic knowledge graph (KG) as an external memory for planning in partially observable BabyAI environments. The agent alternates between graph construction (building nodes/edges from observations) and structured planning via a domain-specific language (DSL). Experiments on small BabyAI gridworlds (maps with 2×2 and 3×3 rooms) with tasks like OpenDoor and PutNextTo suggest that the graph-based memory improves task success rates over a “stacked memory” baseline and a no-memory setup."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "* The framework is well-engineered, with detailed modular prompts and clear visualization of how the knowledge graph evolves.\n* The combination of structured memory and DSL-based planning is conceptually clean and helps connect symbolic reasoning with embodied action.\n * The experiments, though small-scale, are thorough within the limited setting, including GED-based analysis of graph accuracy and qualitative visualizations."}, "weaknesses": {"value": "* **Novelty**: The idea of dynamically constructing and exploiting a knowledge graph as an LLM memory in partially observable settings is not new. Prior work like AriGraph explored very similar designs: LLMs building and querying graph-structured memory for decision-making in POMDP. The paper’s core claim of being the “first” dynamic KG-based planner is overstated.\n * **Evaluation scope**: The empirical validation is extremely limited—only two BabyAI missions (OpenDoor, PutNextTo) in 2×2 and 3×3 grids, with about 20 layouts and three trials each. There is no testing on larger, more complex environments, distractors, or longer object-interaction chains. Claims of generality to “real-world” or “long-horizon” reasoning are unsubstantiated.\n* **Baselines**: Comparisons are weak—only a simple “stacked memory” and a no-memory version. Missing comparisons with prior KG/RAG-based or agentic-memory frameworks makes it unclear how much progress is achieved.\n* **Practicality and efficiency**: The paper omits any discussion of runtime, compute, or token costs, which are crucial for assessing the feasibility of maintaining dynamic KGs with LLMs."}, "questions": {"value": "Please address the weaknesses mentioned in the previous section.\n\n1. Could you clarify how your approach fundamentally differs from prior work such as AriGraph or other KG-based memory frameworks for LLM-driven agents?\n\n2. Could you elaborate on why experiments are limited to small BabyAI environments (2×2, 3×3) and discuss how you expect the method to scale to larger or more complex tasks?\n\n3. Please provide quantitative data on computational and token-level costs (e.g., inference time per step, prompt length, graph update overhead) to assess the scalability and practicality of maintaining dynamic KGs in your setup"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics concerns with respect to this work."}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7qp9viBMS4", "forum": "XromAiEaE3", "replyto": "XromAiEaE3", "signatures": ["ICLR.cc/2026/Conference/Submission16193/Reviewer_us7X"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16193/Reviewer_us7X"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16193/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761945741124, "cdate": 1761945741124, "tmdate": 1762926355963, "mdate": 1762926355963, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present an approach to us a knowledge graph as a memory for reasoning with an LLM in tasks that have longer range dependencies."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "* I like the setup of the task, which is such that the agent must have a long-range memory in order to find a good solution. It remains a bit unclear how hard the actual tasks are because of the generation and filtering approach. \n* The overall results show that the method results in an overall better performance.\n* The method is rather intuitive"}, "weaknesses": {"value": "* I think the opening premise of the abstract is a bit strange: \"the reasoning capabilities of large language models (LLMs) have advanced considerably due to their extensive internal knowledge\". This is actually not really a proven thing. The reasoning capabilities seem to stem from analogies with knowledge, but it is, despite anecdotal evidence, not formally proven.\n\n* This work might suffer from a confirmation bias. It is not really possible to say that an LLM could in no way solve these problems; it might just be that we have not yet found the right way to prompt it. A theoretical proof of such a limitation would be a much stronger contribution. In this context it is important that the paper adds computational tools, specifically BFS to the LLMs capabilities. It would be great if one can proof that the LLM cannot perform a BFS of such depth with its context window; but I think it could. It would also be useful to get statistics on how often these tools are called, and how deep the BFS needs to go. As a sub-comment, I am not sure why the details on the tool calls are hidden in the appendix, while they are actually pretty essential."}, "questions": {"value": "* Is it possible for your agent to not store information in the knowledge graph and instead use the context window? \n* Do you have a way to measure the accuracy of the content in the knowledge graph compared to what really is in the environment? \n* In some places, you call your environment dynamic, but I don't understand what is dynamic in your environment, can you elaborate?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Q6eszbxiWW", "forum": "XromAiEaE3", "replyto": "XromAiEaE3", "signatures": ["ICLR.cc/2026/Conference/Submission16193/Reviewer_1GUm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16193/Reviewer_1GUm"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16193/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762020193217, "cdate": 1762020193217, "tmdate": 1762926355481, "mdate": 1762926355481, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes GraphMind, an LLM-based agent architecture for sequential decision-making in partially observable environments. It integrates a knowledge graph (KG) as dynamic memory, incrementally built from object interactions to support long-horizon planning. The LLM retrieves relevant KG subgraphs to generate high-level actions, refined into low-level steps. Evaluations focus on custom grid-world navigation tasks (e.g., object collection with partial observability), claiming superior success rates and efficiency over baselines like ReAct and naive LLM planners, especially in exploration-heavy scenarios."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The work addresses a pertinent challenge in LLM agents: managing long-term memory, where naive prompting fails due to context limits. The KG as structured memory is a reasonable extension, enabling interpretable retrieval (e.g., via subgraph queries) and reducing hallucination risks. Experiments show intuitive visualizations and quantitative gains, with ablations on memory types providing some insight."}, "weaknesses": {"value": "Despite its aims, GraphMind lacks substantial novelty, largely recombining existing ideas: LLM prompting for planning, KG for memory augmentation, and rule-based updates in grid worlds. KG construction is simplistic (e.g., object-centric heuristics), without learned mechanisms or handling of noisy perceptions, limiting generalization beyond toys. \n\nExperiments are severely constrained: custom, low-dimensional grid tasks ignore standard benchmarks (e.g., MiniGrid, BabyAI), and baselines are weak—missing SOTA like Voyager. \n\nClaims of \"dynamic knowledge builders\" are vague without ablation on LLM sensitivity (e.g., GPT-4 vs. open models) or scaling to larger graphs (potential explosion). \n\nRobustness tests are contrived (e.g., fixed obstacles), overlooking real shifts like dynamics changes or multi-agent interactions. Overall, the method feels incremental and underexplored, with no theoretical analysis of efficiency or failure modes.\n\nWhile LLM+KG integration is promising for memory in agents, GraphMind offers no groundbreaking advances. The narrow, toy-like evaluations fail to demonstrate broad impact, and overstated claims undermine credibility."}, "questions": {"value": "In the end of Section 3, authors mentioned \"This cyclical structure ensures that planning remains adaptive, resilient to execution errors, and\nrobust under partial observability.\" Regarding the partial observability, are there any specific techniques leveraged to tackle the challenge, or just rely on LLMs to provide additional information?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fO8zxd42xb", "forum": "XromAiEaE3", "replyto": "XromAiEaE3", "signatures": ["ICLR.cc/2026/Conference/Submission16193/Reviewer_dc4W"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16193/Reviewer_dc4W"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16193/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762148859151, "cdate": 1762148859151, "tmdate": 1762926355027, "mdate": 1762926355027, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes GraphMind, a framework that builds knowledge graph for LLMs to provide memory and help sequential decision making especially in BabyAI tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is clearly written and well structured. The use of a graph-based memory and DSL makes the system interpretable. Ablation studies (no memory, stacked memory) are clean and support the main claim. Graph-edit distance as a proxy for memory accuracy is intuitive."}, "weaknesses": {"value": "I’m concerned about the generalization and scalability of the proposed framework. The experiments are confined to the BabyAI environment with only a few predefined layouts, which are relatively simple and small-scale. There’s no evaluation in more challenging or diverse settings, such as larger or irregular maze environments, tasks with richer object interactions, or real-world scenarios. So it’s unclear whether the approach would maintain its effectiveness beyond this narrow domain."}, "questions": {"value": "Is the knowledge graph truly necessary? Couldn’t we achieve similar results by simply giving the LLM access to a global map of the environment or by providing prior trajectories and observations in plain text? Given the current strength of modern LLMs, such structured graph representations may not be essential for this relatively simple task."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4yYvyydZc1", "forum": "XromAiEaE3", "replyto": "XromAiEaE3", "signatures": ["ICLR.cc/2026/Conference/Submission16193/Reviewer_yhK8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16193/Reviewer_yhK8"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16193/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762904162314, "cdate": 1762904162314, "tmdate": 1762926354555, "mdate": 1762926354555, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}