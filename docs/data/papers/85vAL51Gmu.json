{"id": "85vAL51Gmu", "number": 11133, "cdate": 1758190177478, "mdate": 1759897606016, "content": {"title": "Design Linear Constrained Neural Layers with Implicit Convex Optimization", "abstract": "One essential limitation of neural networks is how to enforce (hard) constraints on prediction. We propose a plug-in, differentiable layer, which involves a fast implicit (convex) optimization procedure to enforce the general linear constraint. It aims to minimize a divergence between unconstrained and constrained outputs. Connecting to and beyond existing handcrafted layers, we show that our layer degrades to classic layers like Softmax, Sinkhorn and tanh etc. when the corresponding constraint is enforced by KL-divergence minimization. We further show that by replacing the KL-div with a Euclidean distance, a closed-form solution can be derived for highly-efficient constraint enforcing. We evaluate the above two variants of layers, termed as BLCLayer and GLCLayer, with their corresponding neural solver BLCNet and GLCNet with simple MLP/GNN-like backbone. Experiments on liner programming, as well as two real-world problems: partial graph matching and portfolio allocation which involve other discrete constraints.", "tldr": "", "keywords": ["Linear Programming", "Convex Optimization", "Constrained Neural Layer"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a58735d35fc2d9ac65b659146a82dbfa0b3c15f2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors propose a neural architecture designed to enforce constraints directly on the outputs of neural networks. They begin by observing that standard layers—such as softmax—can be interpreted as implicit layers, where the layer output is implicitly defined as the solution of an optimization problem conditioned on the layer input. Building on this perspective, the authors introduce two implicit layers tailored to enforce linear constraints, along with corresponding training procedures and differentiation rules to ensure compatibility with end-to-end backpropagation.\n\nThe first layer, BLCLayer, is formulated as a Bregman iteration, for which the authors provide a convergence guarantee. It is applicable to binary positive linear constraints. The second layer, GLCLayer, admits a closed-form solution and can be applied to arbitrary linear equality constraints. To handle inequalities, the authors further develop an ADMM-based variant of the GLCLayer.\n\nExtensive experiments demonstrate that the proposed layers successfully enforce constraints while remaining computationally efficient. This includes outperforming recent baselines like LinSATNet and, on large-scale linear programs, achieving up to a 20x speedup over Gurobi for finding high-quality approximate solutions (90-95% of the optimal value)."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "**Originality**. The paper’s originality stems from its novel framework that unifies classic layers like Softmax under the lens of implicit optimization minimizing the KL-divergence. This creative perspective is then used to derive new, principled layers for enforcing linear constraints.\n\n**Quality**. The quality of the work is high, with strong empirical results across multiple tasks. The proposed methods are principled and effective—consistently outperforming recent baselines and showing impressive competitiveness against a commercial solver like Gurobi on large-scale problems.\n\n**Clarity**. The paper is well-written. The narrative builds intuition by connecting the new formulation to familiar concepts such as Softmax layers, and the main contributions arise as direct consequences of enforcing the output constraints within this framework. \n\n**Significance**. The work makes a significant practical contribution to constrained deep learning. The method performs well and is efficient, making the proposed method relevant for real-world applications."}, "weaknesses": {"value": "While the paper has a solid idea and strong empirical results, its contribution is significantly undermined by two major weaknesses.\n\nThe first and most significant weakness is **the failure to cite and compare against highly relevant prior work, specifically HardNet [1]**. HardNet is a closely related framework that also uses a projection-based layer to enforce output constraints, and a direct comparison is crucial because it:\n\n- Presents a closed-form solution for general affine constraints (including inequalities) that is more versatile than the GLCLayer.\n- Directly handles input-dependent (per-sample) constraints, a more general and practical setting that this paper does not address.\n- Avoids iterative methods for inequalities, a key limitation of this paper's layers which require either Bregman iterations or an ADMM-based solver.\n- Extends to general convex constraints, albeit by requiring differentiable solvers.\n\nThis omission significantly overstates the novelty of the proposed methods and presents an incomplete picture of the state-of-the-art. Therefore, **I am unable to recommend acceptance unless the authors thoroughly discuss HardNet in their submission, including an empirical comparison.**\n\nThe second major weakness is the **lack of a universal approximation guarantee**. By adding a fixed projection layer, the authors fundamentally change the network's architecture. Without a formal guarantee, it is unclear if this fixed projection is too restrictive and prevents the model from representing the optimal feasible solution. While I would still recomend a borderline accept if only the HardNet comparison is added, providing this theoretical guarantee would strongly enhance the paper and elevate my recommendation.\n\n- [1] Y, Min and N. Azizan. HardNet: Hard-Constrained Neural Networks with Universal Approximation Guarantees. arXiv preprint at arXiv:2410.10807 (2024).\n\n---\n\nI have additional comments which, while not central to my overall recommendation, should still be addressed:\n\n1. **Motivation clarity**. The claim that constraints enforced during training may not hold at deployment is imprecise. The authors should acknowledge that theoretical generalization guarantees for constrained learning do exist (e.g., PAC-style results [2]), even if they come with limitations.\n\n\n2. **Experimental rigor**. The experiments have two major issues. First, for iterative methods (BCL and GCL-ADMM), the feasibility gap must be reported, as convergence is only guaranteed asymptotically. Without this, it is unclear whether the reported performance is achieved at the cost of (potentially severely) infeasible solutions. Second, while seeds are fixed, the authors should still quantify uncertainty across random seeds to convince the reader that the results are not due to a lucky run.\n\n\n3. **Missing discussion of future work**. The framework appears naturally extensible by exploring alternative implicit layer formulations. A brief discussion of promising directions—or even scenarios where the current approach might fail (e.g., when the Bregman subproblems lack closed-form solutions)—would strengthen the paper and better situate its broader impact.\n\n- [2] L. Chamon and A. Ribeiro. Probably Approximately Correct Constrained Learning. In NeurIPS, 2020."}, "questions": {"value": "Can the authors provide a convergence rate for the BLCLayer's Bregman iterations to complement the existing asymptotic convergence guarantee?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "W7XHe3mHI5", "forum": "85vAL51Gmu", "replyto": "85vAL51Gmu", "signatures": ["ICLR.cc/2026/Conference/Submission11133/Reviewer_5jVk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11133/Reviewer_5jVk"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11133/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760730342764, "cdate": 1760730342764, "tmdate": 1762922303655, "mdate": 1762922303655, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the problem of enforcing hard linear constraints on neural network outputs by introducing a plug-in differentiable layer based on implicit convex optimization. The proposed LinConLayer framework ensures a network’s output $x$ satisfies general linear constraints ($Wx=b$) by finding the closest feasible $x$ to the unconstrained output $y$ in terms of a divergence. Two variants are presented: (i) BLCLayer, which uses a KL-divergence (Bregman) iterative projection to handle binary coefficient linear constraints with $x \\ge 0$, generalizing classic layers like Softmax and Sinkhorn as special cases; and (ii) GLCLayer, which uses a Euclidean (least-squares) objective to enforce general linear equality constraints and yields a closed-form solution $x = y - W^\\top(WW^\\top)^{-1}(Wy - b)$ without requiring inner-loop gradient descent. The paper’s contributions span theory – formalizing classic normalization and activation layers as constrained optimization outcomes and deriving an analytic projection for arbitrary linear constraints – and practice, by integrating these layers into neural architectures (termed BLCNet and GLCNet) that solve tasks like linear programming, partial graph matching, and portfolio optimization while strictly satisfying constraints. Empirically, the approach demonstrates improved efficiency and competitive accuracy, e.g., being more stable and faster than prior constrained-layer methods on graph matching and portfolio tasks, and scaling to large linear programs with speed-ups over traditional solvers."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper’s key strengths lie in its originality and technical insights. It provides a unifying view that generalizes prior constraint-specific layers. For instance, showing that Softmax, Sinkhorn, and Tanh can be derived from this framework under appropriate KL-based constraints. The methodology is well-founded theoretically: the use of KL-divergence vs. Euclidean distance is explored to design two-layer types, and notably, the Euclidean case yields an analytical solution, eliminating the need for iterative solvers or tuned hyperparameters (unlike earlier methods such as GLinSAT, which required careful step-size tuning). The results are compelling: networks using BLCLayer and GLCLayer achieve equal or better performance than strong baselines while maintaining hard constraint satisfaction. For example, adding BLCLayer improves stability and speed over LinSATNet on graph matching and finance benchmarks, and a GLCNet model for linear programming attains near-optimal solutions (within ~90–95% of Gurobi’s objective) while running an order of magnitude faster on large-scale problems. Additionally, the approach is practical and well-presented: the layers are modular and differentiable (easy to plug into existing models), and the paper is clear in its explanations, it includes a comparison table and proofs, helping readers understand the implementation and convergence properties."}, "weaknesses": {"value": "The approach has certain limitations. BLCLayer is restricted to cases where outputs are non-negative and the constraint matrix $W$ has binary entries, which limits its direct applicability to problems with more general (non-binary) coefficients or where negative values are needed. The GLCLayer lifts some of these restrictions by handling general linear equalities, but it still cannot natively enforce inequality constraints or bounds without additional mechanisms. The authors address $x\\ge0$ constraints via a separate ADMM routine, introducing extra complexity and iterations (thus losing the elegance of the closed-form solution in those cases). Another concern is the reliance on the invertibility of $WW^\\top$ for the GLCLayer’s formula. This assumes $W$ is full rank and well-conditioned; if the constraint matrix is ill-conditioned or large, computing $(WW^\\top)^{-1}$ could be a numerical stability issue or a computational bottleneck (the paper mitigates this by precomputing the inverse, but that may not scale well if $W$ grows or changes). In terms of novelty, the idea of integrating constrained optimization into neural networks is not entirely new – prior works like LinSAT/GLinSAT and differentiable optimization layers (e.g. cvxpylayers) have pursued related goals. Thus, the contribution here is somewhat incremental, focusing on improved efficiency and specialized formulations rather than a fundamentally new paradigm. Finally, the empirical evaluation, while positive, is confined to three domains (a synthetic LP solver and two application tasks), so it remains to be seen how the method performs on a broader range of constraints or in other settings not explored in the paper."}, "questions": {"value": "Several questions arise that could help clarify the work. \n\n- Generality: Can the authors extend their framework beyond linear constraints? For example, how might one design a similar “implicit” layer for enforcing nonlinear or more complex constraints (e.g. quadratic or logical constraints), and what challenges would that entail? \n\n- Numerical stability: How does the GLCLayer handle cases where $W W^\\top$ is ill-conditioned or nearly singular? Would small eigenvalues or numerical inversion errors affect training stability, and are there any regularization or iterative solver strategies to address this scenario? \n\n\n- Scalability: Are there potential GPU bottlenecks when scaling up these layers? In particular, for very large constraint matrices or high-dimensional outputs, does the cost of precomputing a matrix inverse or performing many Bregman/ADMM iterations become problematic, and how could the approach be optimized or made more efficient in such cases (e.g. using sparse structure, batching strategies, or approximate methods)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zEkQJnWq4G", "forum": "85vAL51Gmu", "replyto": "85vAL51Gmu", "signatures": ["ICLR.cc/2026/Conference/Submission11133/Reviewer_WyVt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11133/Reviewer_WyVt"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11133/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760744179434, "cdate": 1760744179434, "tmdate": 1762922303149, "mdate": 1762922303149, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "They propose networks that satisfy linear constraints on the individual outputs that add a layer to an unconstrained network.  They propose modifying given constraints to binary positive linear constraints and imposing those via Bregman projections (without gradient descent), or using a (closed-form, if small enough to invert) Euclidean projection."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "I found the paper mostly readable."}, "weaknesses": {"value": "MOTIVATION: Too weak. Please add a simple motivating example. The best motivation I can imagine is if the outputs represent probabilities of different events and I want those output probabilities to always sum to 1? Can you give a quick real-world example where W and b are more interesting in a sentence in the intro? \n\nSIGNIFICANCE: I'm struggling to see this as a really hard important problem that we really need new methods to solve. The couple times I’ve had this problem in real life (and in both cases it was the simple case of wanting your outputs to live in [0,1] and sum to 1). I think the obvious thing to do is take a pseudoinverse, which seems to be what they propose in (12) and call a GLC net.  I don't think that's publishable... and I didn't see the Bregman variant as interesting enough to publish either. A key challenge for GLC is the matrices might be too big to do it closed form, but one can still train a layer that approximates (12). \n\nMINOR:\n- Just fyi that I found it non-standard to have your output be called $x$, when $x$ is traditionally reserved for inputs in ML, so that caused me a little confusion until I saw Fig. 1 as at first when you said you wanted Wx=b I thought it was a constraint on inputs $x$, but sure, whatever. If it were me I'd have used $x$ as inputs, $y$ as the unconstrained outputs, then $z$ as the final outputs. \n\n- Formula running into margin after (17).\n\n- A few typos, e.g. descent vs decent"}, "questions": {"value": "Why is the GLCNet in Table 4 faster at Inference than Untrained?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6F08R40gGH", "forum": "85vAL51Gmu", "replyto": "85vAL51Gmu", "signatures": ["ICLR.cc/2026/Conference/Submission11133/Reviewer_GXkN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11133/Reviewer_GXkN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11133/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968498044, "cdate": 1761968498044, "tmdate": 1762922302603, "mdate": 1762922302603, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces LinConLayer, a general framework for designing neural network layers that explicitly satisfy linear constraints through implicit convex optimization. By interpreting classic layers like Softmax and Sinkhorn as solutions to divergence-minimization problems, the authors generalize this idea into two efficient variants: BLCLayer, which enforces binary linear constraints via KL-divergence minimization and Bregman projections, and GLCLayer, which enforces general linear equality constraints via Euclidean projection with a closed-form solution. Integrated into neural architectures (BLCNet and GLCNet), these layers enable fast, differentiable constraint satisfaction, achieving strong empirical results across different applications, including graph matching, portfolio optimization, and linear programming tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper proposes a clear and intuitive solution that connects classic neural network layers to simple optimization principles, then extends this view to build layers that can naturally handle linear constraints. This makes the method both easy to understand and practical to use in different settings. It’s also quite flexible and can be applied to multiple tasks, including graph matching, portfolio design, and linear programming, which shows that the idea isn’t just theoretical but useful in many real problems. I am not an expert in this field so I am not the best to judge the novelty of this work."}, "weaknesses": {"value": "1. The assumption that $W$ is binary may restrict the method’s applicability in continuous domains; a discussion on potential extensions to non-binary or continuous constraints would strengthen the work.\n\n2. The approach relies on inverting $WW^T$, which could become computationally expensive for large-scale problems; the paper does not address possible strategies for handling sparse or low-rank matrices.\n\n\nMinor:\n\n1. Line 90: it should be \"we first introduce the _Optimal_ Transport\"\n2. Line 216, there are additional \" around the first sentence.\n3. Line 251, missing reference []\n4. Line 153 missing a space in between \"solution\" and \"x\""}, "questions": {"value": "It would be helpful if the authors could comment on the points raised in the weakness section to clarify the method’s limitations and possible extensions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "vHui1sHMsJ", "forum": "85vAL51Gmu", "replyto": "85vAL51Gmu", "signatures": ["ICLR.cc/2026/Conference/Submission11133/Reviewer_quiU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11133/Reviewer_quiU"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11133/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762019437389, "cdate": 1762019437389, "tmdate": 1762922302266, "mdate": 1762922302266, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}