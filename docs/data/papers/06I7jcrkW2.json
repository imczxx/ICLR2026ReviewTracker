{"id": "06I7jcrkW2", "number": 18854, "cdate": 1758291547393, "mdate": 1759897077611, "content": {"title": "Orbital Transformers for Predicting Wavefunctions in Time-Dependent Density Functional Theory", "abstract": "We aim to learn wavefunctions simulated by time-dependent density functional theory (TDDFT), which can be efficiently represented as linear combination coefficients of atomic orbitals. In real-time TDDFT, the electronic wavefunctions of a molecule evolve over time in response to an external excitation, enabling first-principles predictions of physical properties such as optical absorption, electron dynamics, and high-order response. However, conventional real-time TDDFT relies on time-consuming propagation of all occupied states with fine time steps. In this work, we propose OrbEvo, which is based on an equivariant graph transformer architecture and learns to evolve the full electronic wavefunction coefficients across time steps. First, to account for external field, we design an equivariant conditioning to encode both strength and direction of external electric field and break the symmetry from SO(3) to SO(2). Furthermore, we design two OrbEvo models, OrbEvo-FullWF and OrbEvo-DM, using wavefunction pooling and density matrix as interaction method, respectively. Motivated by the central role of the density functional in TDDFT, OrbEvo-DM encodes the density matrix aggregated from all occupied electronic states into feature vectors via tensor contraction, providing a more intuitive approach to learn the time evolution operator. We adopt a training strategy specifically tailored to limit the error accumulation of time-dependent wavefunctions over autoregressive rollout. To evaluate our approach, we generate TDDFT datasets consisting of 5,000 different molecules in the QM9 dataset and 1,500 molecular configurations of the malonaldehyde molecule in the MD17 dataset. Results show that our OrbEvo model accurately captures quantum dynamics of excited states under external field, including time-dependent wavefunctions, time-dependent dipole moment, and optical absorption spectra characterized by dipole oscillator strength. It also shows strong generalization capability on the diverse molecules in the QM9 dataset.", "tldr": "", "keywords": ["Machine learning density functional theory", "Time dependent neural PDE solver"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b9b9470edaaf38e546adf996fb79f0e4341c771e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper tackles the important and challenging problem of accelerating Real-Time TDDFT (RT-TDDFT) computations using deep learning.  \nSpecifically, it adopts an autoregressive framework to accelerate the propagations of RT-TDDFT, where the wavefunctions of previous steps are input into the network for the prediction of the next steps' wavefunctions. The paper proposes two model architectures (OrbEvo-FullWF and OrbEvo-DM) with different electronic state interacting strategies and compares their performance on their self-generated TDDFT dataset.\n\nI think the paper is in a good shape, with nontrivial contributions for a novel application (RT-TDDFT) and specifically designed models (OrbEvo-FullWF and OrbEvo-DM). Nonetheless, there exist several concerns, which should be addressed before acceptance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "* Machine learning TDDFT is an important and relatively under-explored research field. This paper approaches the problem with a novel setting (directly learning the wavefunctions), representing a pioneering attempt in this direction. The handling of the high-dimensional orbital coefficient object (the time, the electronic state and the atomic orbital dimensions are all different from the number of atoms) is especially interesting.\n* The design choices of the prediction target and the model architectures seem to be thoroughly considered and physics-grounded.\n* The practices of improving model performance, such as the delta transformation of wavefunctions, the time bundling setting and the push-forward training, are detailed and provide a good impression of adopting state-of-the-art techniques in related fields.\n* The paper is written in a clear and easy-to-understand language, with moderate background knowledge included."}, "weaknesses": {"value": "* Although the paper has provided some background information for RT-TDDFT, I find myself unclear about the big picture and lost in the implementation details. It is not clear how the learned model is used in the RT-TDDFT framework.\n* The units are missing from all the performance numbers in the paper.\n* Neither the source code nor the dataset are provided. This renders the paper hard to follow."}, "questions": {"value": "* About motivation: Could you provide a clearer picture of the framework? For example, how is the learned model used in RT-TDDFT to accelerate the computation?\n* About performance: How much acceleration is achieved? How should one interpret the metrics in Table 1 and Table 2?\n* How does the model compare to direct property prediction methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nfuK4RDRJ7", "forum": "06I7jcrkW2", "replyto": "06I7jcrkW2", "signatures": ["ICLR.cc/2026/Conference/Submission18854/Reviewer_ce9Z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18854/Reviewer_ce9Z"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18854/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761660275641, "cdate": 1761660275641, "tmdate": 1762930821290, "mdate": 1762930821290, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes *Orbital Transformers*, an equivariant graph Transformer designed to directly predict the *time evolution of Kohn–Sham wavefunctions* in real-time time-dependent density functional theory (RT-TDDFT). Unlike prior approaches that predict energies, Hamiltonians, or spectral observables, this model learns the mapping $C(t) \\to C(t+\\Delta t)$ (or $\\Delta C_t$) directly, effectively learning the quantum propagation operator. The authors introduce an SO(2)-equivariant attention mechanism that takes the external electric field direction as the reference axis, and use FiLM-style conditioning to inject both the field’s direction and time-dependent amplitude. A local autoregressive temporal modeling scheme, along with pushforward training, enables the model to track the dynamic evolution of the system stably over several femtoseconds. Experiments on RT-TDDFT trajectories of QM9 and MD17 molecules under external fields show that the model accurately reproduces dipole dynamics and orbital evolution."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This is the first work to *directly predict the time evolution of wavefunctions* in RT-TDDFT rather than energies or Hamiltonians. The idea of learning an implicit propagation operator $f_\\theta: C(t)\\mapsto C(t+\\Delta t)$ is conceptually novel and impactful.  \n2. Modeling system evolution under an external field is *physically meaningful* and directly corresponds to realistic nonequilibrium dynamics.  \n3. The paper presents an *innovative autoregressive temporal modeling* strategy that allows the neural network to continuously track and predict the system’s electronic evolution, combining local ΔC prediction with pushforward training to reduce error accumulation.  \n4. The *integration of field information into the atomic graph network* is well designed: the electric-field direction defines the SO(2) equivariant reference axis, and the field information enters through FiLM-style modulation. This construction is both physically grounded and computationally efficient."}, "weaknesses": {"value": "1. The network predicts the next-step evolution solely from the current state, **and although the authors adopt certain stabilization strategies** — such as local autoregressive temporal modeling, pushforward training, and ΔC prediction — these mechanisms only address short-term error accumulation. **There remains no explicit architectural component (e.g., temporal attention or recurrent memory) to model long-range temporal dependencies**, which consequently limits robustness and stability during long-horizon propagation beyond several femtoseconds.\n\n2. The SO(2)-equivariant design relies on the external-field direction as the rotational reference axis. Once the external field vanishes, this reference loses physical meaning, and the network no longer has a well-defined axis for the equivariant operations. Moreover, if the external-field direction varies over time or differs across samples, the reference frame for the SO(2) operations also changes with time. It is unclear how well the model would perform under such cases.\n\n3. The paper appears to **lack systematic efficiency evaluation experiments**, for example, comparisons on runtime and computational resource usage, which would be important to assess the practical utility of the proposed model."}, "questions": {"value": "The authors generate and RT-TDDFT trajectories with external fields for standard datasets like QM9 and MD17, which may enrich the data resources for time-dependent electronic-structure ML. Will the generated trajectories and other data be publicly released, providing valuable data for future time-dependent quantum ML research?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bgy26jEHMo", "forum": "06I7jcrkW2", "replyto": "06I7jcrkW2", "signatures": ["ICLR.cc/2026/Conference/Submission18854/Reviewer_6czi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18854/Reviewer_6czi"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18854/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761911925522, "cdate": 1761911925522, "tmdate": 1762930820535, "mdate": 1762930820535, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposed a new model and method that learns the time-dependent DFT's properties, and has shown that the new proposed method, combined with a serious method improvement, can predict nicely the properties from TDDFT."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The network is well designed with very good respect for the physics.\n2. The increase in accuracy is very impressive."}, "weaknesses": {"value": "1. The writing needs more clarification, for example, the model design, more words in the caption and the method part can be helpful to understand it clearly.\n2. The experimental work is comparably weak. More comparison with other models, and specific studies on in-distribution, out-of-distribution systems can make this study more solid."}, "questions": {"value": "1. In real applications, we often focus on a specific kind of system, where we often do not have that much data. In terms of this, how is this method transferable to similar structures but with limited training data? How is the data efficiency in that?\n\n2. How to transfer the model to different external field conditions?\n\n3. How is the SO3-SO2 mapping achieved in layer norm? I haven't found it in the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "0HKETKMwSW", "forum": "06I7jcrkW2", "replyto": "06I7jcrkW2", "signatures": ["ICLR.cc/2026/Conference/Submission18854/Reviewer_F1P1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18854/Reviewer_F1P1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18854/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761967486125, "cdate": 1761967486125, "tmdate": 1762930820080, "mdate": 1762930820080, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces OrbEvo, an equivariant graph transformer framework for learning the time evolution of Kohn–Sham wavefunctions in real-time time-dependent density functional theory (RT-TDDFT). Unlike prior works such as OrbFormer, which focus on static ground-state properties, OrbEvo aims to learn the dynamics of electronic states under external electric fields.\nThe authors propose two model variants: OrbEvo-FullWF, which aggregates wavefunction features through pooling across occupied states, and OrbEvo-DM, which computes density-matrix-based interactions between states via tensor contraction. The model employs SO(2)-equivariant conditioning to represent field-induced symmetry breaking and a pushforward training scheme to stabilize long-horizon rollout. Experiments on QM9 and MD17 demonstrate that OrbEvo-DM outperforms the pooling-based variant, capturing physically consistent time-dependent dipole moments and absorption spectra."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "**Easy to follow and clear motivation**: The paper provides an intuitive and well-structured explanation of the challenge in modeling time-dependent DFT, with smooth transitions from motivation to formulation.\n\n**Tackling an impactful and general problem**: The work addresses a scientifically meaningful and practically impactful challenge: learning the time evolution of Kohn–Sham wavefunctions to accelerate quantum dynamics simulations. Importantly, the model is trained across thousands of diverse molecules (QM9) and demonstrates generalization to unseen molecular systems, showing potential as a shared, cross-molecular surrogate model for electronic dynamics. This highlights the scalability and versatility of the approach beyond single-molecule modeling.\n\n**Sound model design**: The use of SO(2)-equivariant conditioning, density-matrix features, and push forward training demonstrates strong physical insight and solid engineering."}, "weaknesses": {"value": "Dataset scale is limited, making it difficult to assess generalization to larger molecules or different field conditions."}, "questions": {"value": "1. **Applicability to static DFT**: Can the OrbEvo architecture be used for static ground-state DFT tasks, such as predicting stationary wavefunction coefficients or density matrices? Or is it strictly limited to time-dependent TDDFT propagation?\n\n2. **Ablation on time bundling**: How much does the time bundling technique contribute to the model’s performance and stability? It would be helpful to see results comparing models with and without time bundling."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BXaxWyNQ81", "forum": "06I7jcrkW2", "replyto": "06I7jcrkW2", "signatures": ["ICLR.cc/2026/Conference/Submission18854/Reviewer_GR5K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18854/Reviewer_GR5K"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18854/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994886019, "cdate": 1761994886019, "tmdate": 1762930819421, "mdate": 1762930819421, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}