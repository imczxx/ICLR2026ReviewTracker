{"id": "Dud8FtScW7", "number": 13389, "cdate": 1758217297704, "mdate": 1759897440925, "content": {"title": "The Quest for Efficient Reasoning: A Data-Centric Benchmark to CoT Distillation", "abstract": "Data-centric distillation, including data augmentation, selection, and mixing, offers a promising path to creating smaller, more efficient student Large Language Models (LLMs) that retain strong reasoning abilities. However, there still lacks a comprehensive benchmark to systematically assess the effect of each distillation approach. This paper introduces DC-CoT, the first data-centric benchmark that investigates data manipulation in chain-of-thought (CoT) distillation from method, model and data perspectives. Utilizing various teacher models (e.g., o4-mini, Gemini-Pro, Claude-3.5) and student architectures (e.g., 3B, 7B parameters), we rigorously evaluate the impact of these data manipulations on student model performance across multiple reasoning datasets, with a focus on in-distribution (IID) and out-of-distribution (OOD) generalization, and cross-domain transfer. Our findings aim to provide actionable insights and establish best practices for optimizing CoT distillation through data-centric techniques, ultimately facilitating the development of more accessible and capable reasoning models. The nonymous codebase can be accessed https://anonymous.4open.science/r/DC-COT-FF4C/", "tldr": "DC-CoT is the first benchmark for data-centric CoT distillation, testing how augmentation, selection, and mixing impact student LLMs. It evaluates multiple teachers and students  across multimodel reasoning tasks, focusing on IID, OOD, and transfer.", "keywords": ["Chain-of-Thought", "Knowledge Distillation", "Large Language Models", "Benchmarking", "Data Augmentation", "Data Selection", "Data Mixing"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9ab70c63162968ca9d89602cd6db62ee16619df3.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces **DC-CoT**, a comprehensive benchmark for evaluating **data-centric approaches to Chain-of-Thought (CoT) distillation**, spanning three axes: (1) data augmentation (e.g., reverse thinking, answer rephrasing), (2) data selection (e.g., teacher-correct filtering, LLM-as-judge), and (3) data mixing (e.g., by length or teacher source). The authors conduct extensive experiments across diverse reasoning tasks (textual, mathematical, agentic, visual), multiple teacher models (e.g., GPT-4, Claude 3.5, Gemini-1.5-Pro), and student architectures (e.g., Llama-3.1-8B, Mistral-7B). Key findings include: augmentation (especially reverse thinking) generally outperforms selection or mixing; the existence of a “learnability gap” where smaller students may not benefit from the strongest teachers; and strong out-of-distribution (OOD) generalization after CoT distillation. The benchmark is well-documented and accompanied by a public codebase."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. **High practical relevance**: Efficient reasoning via CoT distillation is a critical direction for deploying capable yet lightweight LLMs. The focus on *data-centric* methods—rather than architectural or training tricks—is timely and underexplored.\n2. **Systematic design**: DC-CoT offers a unified framework to compare augmentation, selection, and mixing strategies across modalities, tasks, and model pairs—something missing in prior work.\n3. **Empirical rigor**: The paper includes large-scale experiments, ablations, statistical significance tests (Appendix H), and cross-dataset generalization analysis (Table 5).\n4. **Actionable insights**: Findings like “reverse thinking boosts math reasoning” or “small students may learn better from moderately strong teachers” provide concrete guidance for practitioners."}, "weaknesses": {"value": "1. **Significance of Research Question**\n\nThe core problem—improving CoT distillation via data manipulation—is undeniably important for efficient reasoning. However, the paper does not clearly demarcate what constitutes a *data-centric* CoT distillation method versus general data synthesis or instruction tuning. For instance, “question augmentation” blurs the line with self-instruct-style data generation. This conceptual fuzziness slightly weakens the benchmark’s focus.\n\n2. **Problematic construction of benchmark**\n\n- All CoT traces are generated by **closed-source API models** (GPT-4, Claude, etc.), with limited transparency on prompt templates, temperature settings, or consistency checks. This raises reproducibility concerns.\n- The **LLM-as-a-Judge** filtering method, while common, is not validated against human judgments. Given known issues with LLM evaluators (e.g., length bias, preference leakage), this may introduce hidden noise.\n- **Visual and agentic tasks are underrepresented**: only one visual (Visual-CoT) and one agentic (WebArena) benchmark are used, limiting generalizability in these domains.\n- The OOD transfer pairs (e.g., SQA → BoolQ) are reasonable but **not systematically justified** (e.g., no measure of task similarity), making it hard to interpret generalization patterns.\n\n3. **Potential of benchmark**\n\nThe paper offers valuable heuristics (e.g., prefer reverse thinking for math, avoid over-strong teachers for small students). However:\n- Many conclusions are **tied to specific teacher–student pairs** (e.g., Gemini → Llama-3.1-8B). It’s unclear how well they generalize to new architectures (e.g., MoE, multimodal-native models).\n- No comparison to **non-data-centric distillation** (e.g., logits distillation, representation matching), making it hard to assess whether data manipulation is truly the most promising path."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "oe9UAqL57h", "forum": "Dud8FtScW7", "replyto": "Dud8FtScW7", "signatures": ["ICLR.cc/2026/Conference/Submission13389/Reviewer_tyeG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13389/Reviewer_tyeG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13389/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761294685814, "cdate": 1761294685814, "tmdate": 1762924027673, "mdate": 1762924027673, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces DC-CoT, a novel benchmark aimed at systematically evaluating data-centric distillation approaches (augmentation, selection, mixing) for chain-of-thought (CoT) reasoning. This work conducts a large empirical study across various teacher–student model pairings including teacher models like GPT-4, Gemini, Claude-3.5, and student sizes of ~3B to ~7B, and multiple reasoning datasets, measuring IID, OOD, and cross‐domain generalization. Their findings show that augmentation (such as question or answer rephrasing, reverse thinking) typically provides the strongest gains, selection (filtering by teacher correctness or student error) and mixing (blending data from different domains/lengths) offer more nuanced benefits depending on teacher/student compatibility and data regime."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. In general, this contributes to the community by having such a controllable and comprehensive benchmark. I feel this work, in the long term, will support the data-centric distillation in reasoning.\n2. Figures explaining different components of data-centric distillation are very clear.\n3. The experiments are designed in a fine-grained and comprehensive manner."}, "weaknesses": {"value": "1. The improvement of the teacher models is very fast, the observations found in this paper might not hold.\n2. Following the previous, it would be great if the authors could consider expanding the diversity of teacher models. For example, clustering teacher models by architectural differences such as MoE/full activation, linear/full/sparse attention, etc. The observations might be more generalizable if we analyze from a perspective of architectural differences, instead of picking the strongest teacher models.\n3. One more sentence needed explaining $\\mathcal{M}$ in section 3.1 would be appreciated. Currently, I was confused about whether $\\mathcal{M}$ is a framework or a network.\n4. Though the figures 1-4 are great, there are no explicit references to them over the main text.\n5. Line 112-113, typo: should be $D^{\\text{target}}$"}, "questions": {"value": "1. What does the “IID OOD” contribute to in Figure 1? Training/test data, or domain-specific data distribution?\n2. Maybe it’s better to explain what $L$ is from the start of section 3? I only see that in the third part (Answer Augmentation) in the data augmentation subsection. However, $L$ is also used before that.\n3. Can you explain one or two sentences more on how Consistency Filtering works for Reverse Thinking Augmentation? I was wondering this when I read this paragraph\n4. I have a naive question about “Answer Augmentation”. How do methods avoid the model from generating arbitrary reasoning traces and then the correct answer? The assumption behind this question is that if the teacher model ‘memorizes’ the answer, and is asked to generate diverse reasoning traces, then it will try to follow the prompt by generating true and false reasoning traces. This question is not in the scoop of this work itself, but it would be great if the authors could answer this."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KURa7KiwDy", "forum": "Dud8FtScW7", "replyto": "Dud8FtScW7", "signatures": ["ICLR.cc/2026/Conference/Submission13389/Reviewer_wMDH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13389/Reviewer_wMDH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13389/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993186475, "cdate": 1761993186475, "tmdate": 1762924027326, "mdate": 1762924027326, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces DC-CoT, the first benchmark and framework specifically designed for systematically evaluating Data-Centric approaches in Chain-of-Thought (CoT) Distillation. The authors address the lack of standardized evaluation methods by investigating how data manipulations (e.g., augmentation, selection, and mixing) influence the reasoning capabilities of smaller, efficient student Large Language Models (LLMs). The DC-CoT benchmark comprehensively assesses the performance of various teacher models (e.g., GPT-4-mini, Gemini-Pro, Claude-3.5) and student architectures (e.g., 3B, 7B) across In-Distribution (IID), Out-of-Distribution (OOD), and Transfer Learning tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. DC-CoT addresses a timely research gap by focusing on data-centric strategies in CoT distillation. \n\n2. The evaluation structure is comprehensive, spanning different teacher models, various student model scales, and multiple evaluation settings (IID, OOD, Transfer).\n\n3. The study directly confronts the challenge of making robust reasoning accessible to smaller models, which is paramount for reducing inference costs in real-world applications."}, "weaknesses": {"value": "1. The exploration of specific data-centric strategies (augmentation, selection, mixing) appears superficial. The current implementation is limited to basic methods, failing to incorporate or evaluate more advanced, state-of-the-art (SOTA) data selection or augmentation techniques (e.g., based on model uncertainty or influence). \n\n2. The study fails to clearly articulate the generalizability of the optimal data strategies. The results seem highly task-dependent, yet the authors do not provide a rigorous, nuanced discussion on when a strategy offers a universal benefit versus when it is specific to a task domain (e.g., math vs. commonsense). \n3. While the paper's core objective is to achieve \"efficient reasoning\" during the inference phase, the evaluation relies primarily on coarse metrics like model size (3B, 7B). The benchmark critically lacks explicit, quantitative analysis of the achieved inference efficiency. Crucial metrics such as throughput (tokens/second), actual latency, or GPU memory consumption for the final distilled models are absent."}, "questions": {"value": "1. Given the concerns about SOTA methods, did the authors experiment with or consider advanced data selection techniques, such as methods based on student model uncertainty or influence estimation, rather than just simple teacher correctness filtering? If not, why were these omitted?\n\n2.  Among the data-centric strategies (augmentation, selection, mixing), which one provided the most reliable and significant performance uplift for OOD and transfer tasks? A deeper theoretical explanation is requested as to why the CoT rationales generated by a specific teacher model generalize better to unseen or out-of-domain data.\n3. To fully validate the paper's core claim of efficient reasoning, a quantitative comparison of inference efficiency is essential. Please provide explicit performance metrics for the final distilled 3B and 7B student models—specifically tokens per second throughput, actual latency (e.g., time to first token and time to completion), and peak GPU memory utilization—compared against the original teacher models (or a similarly sized, non-distilled baseline model)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "WmFu4o0amT", "forum": "Dud8FtScW7", "replyto": "Dud8FtScW7", "signatures": ["ICLR.cc/2026/Conference/Submission13389/Reviewer_qqBm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13389/Reviewer_qqBm"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13389/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996895792, "cdate": 1761996895792, "tmdate": 1762924026970, "mdate": 1762924026970, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}