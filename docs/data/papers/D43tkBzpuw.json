{"id": "D43tkBzpuw", "number": 24225, "cdate": 1758354392649, "mdate": 1762955494299, "content": {"title": "LLM-CoT Enhanced Graph Neural Recommendation with Harmonized Group Policy Optimization", "abstract": "Graph neural networks (GNNs) have advanced recommender systems by modeling interaction relationships. However, existing graph-based recommenders rely on sparse ID features and do not fully exploit textual information, resulting in low information density within representations. Furthermore, graph contrastive learning faces challenges. Random negative sampling can introduce false negative samples, while fixed temperature coefficients cannot adapt to the heterogeneity of different nodes. In addition, current efforts to enhance recommendations with large language models (LLMs) have not fully utilized their Chain-of-Thought (CoT) reasoning capabilities to guide representation learning. To address these limitations, we introduces LGHRec (LLM-CoT Enhanced Graph Neural Recommendation with Harmonized Group Policy Optimization). This framework leverages the CoT reasoning ability of LLMs to generate semantic IDs, enriching reasoning processes and improving information density and semantic quality of representations. Moreover, we design a reinforcement learning algorithm, Harmonized Group Policy Optimization (HGPO), to optimize negative sampling strategies and temperature coefficients in contrastive learning. This approach enhances long-tail recommendation performance and ensures optimization consistency across different groups. Experimental results on three datasets demonstrate that LGHRec improves representation quality through semantic IDs generated by LLM's CoT reasoning and effectively boosts contrastive learning with HGPO. Our method outperforms several baseline models. The code is available at: \\url{https://anonymous.4open.science/r/LLM-Rec}.", "tldr": "", "keywords": ["Recommender System", "Large Language Model", "Graph Neural Networks", "Reinforcement Learning"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/6eb832c14e03d59071424e664fbc44cbb8aeef2a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes LGHRec, a framework that enhances graph neural network-based recommender systems through two main components: (1) Deep Semantic Embedding Generator (DSEG), which uses LLM Chain-of-Thought reasoning to generate semantic IDs for items offline, and (2) Harmonized Group Policy Optimization (HGPO), a reinforcement learning algorithm that optimizes graph contrastive learning via adaptive negative sampling and temperature coefficient adjustment. The method aims to address low information density in ID-based features, false negative sampling issues, and performance imbalances in long-tail recommendations. Experiments on three datasets show 3-7% improvements over baseline methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**Originality:**\n- Combining LLM CoT reasoning with GNN-based recommendations is a reasonable idea\n- The cross-group coordination mechanism in HGPO addresses a gap in GRPO\n- Offline preprocessing strategy avoids online LLM inference latency\n\n**Quality:**\n- Extensive experiments across 9 baseline models and 3 datasets\n- Detailed ablation studies examining different components\n- Analysis of performance across different user/item activity levels (Figure 5)\n- Convergence proof provided in appendix (though standard)\n\n**Clarity:**\n- Clear motivation illustrated in Figure 1\n- Architecture diagram (Figure 2) shows overall framework\n- Comprehensive appendix with implementation details\n\n**Significance:**\n- Addresses practical problems in recommender systems (long-tail items, contrastive learning optimization)\n- Shows consistent but modest improvements (3-7%) across datasets\n- Offline approach may be deployable in industrial settings"}, "weaknesses": {"value": "### 1. **Limited Technical Novelty **\n\nThe paper combines existing techniques without significant innovation:\n\n**DSEG Component:**\n- Using LLMs to generate text descriptions is standard practice\n- CoT prompting (Figure 4) is straightforward application of existing techniques (Wei et al., 2022)\n- Encoding with BERT is standard - **why not use the LLM's own embeddings?** This adds complexity\n- Mixed fine-tuning to prevent catastrophic forgetting is well-known\n- Simply concatenating semantic IDs with ID embeddings is the most basic fusion method\n\n**HGPO Component:**\n- Essentially GRPO + variance minimization term (Eq. 19)\n- The reward function (Eqs. 1-6) is entirely hand-crafted with **9 hyperparameters** (θFN, θeasy, θFP, θeasy_low, w1-w5)\n- No learning of reward structure - just manual threshold tuning\n- Adaptive temperature via reinforcement learning has been explored in other contrastive learning contexts\n\n### 2. **Weak Theoretical Contributions (Major)**\n\n**Convergence Proof (Appendix C):**\n- The proof is standard gradient descent convergence for smooth functions\n- **Critical admission** (line 1010-1011): Authors acknowledge L-smoothness doesn't actually hold due to min/clipping operations in the loss\n- Provides no novel theoretical insights specific to the problem\n- Convergence to local minimum is expected and not a contribution\n\n**Missing Theory:**\n- Why does CoT reasoning improve recommendations? No formal analysis\n- What properties of the reward structure guarantee good negative sample selection?\n- Under what conditions does HGPO outperform GRPO?\n- No generalization bounds or sample complexity analysis\n\n### 3. **Experimental Weaknesses **\n\n**Modest Improvements:**\n- 3-7% improvements are marginal given the added complexity\n- On MIND dataset (densest), improvements are smallest (2-7.49%), suggesting the method works best where it's needed least\n- Standard deviations not reported for many results in Table 1 - are improvements statistically significant?\n\n**Unfair Baseline Comparisons:**\n- TALLRec and SPRec are \"LLM-as-RS\" methods solving a different problem (end-to-end generation)\n- **Missing critical baselines**: Other LLM-enhanced methods that use semantic features (e.g., recent works using LLM embeddings for cold-start, knowledge-enhanced recommendations)\n- No comparison with simpler alternatives: What if you just use pre-trained LLM embeddings without CoT? What about using GPT-style embeddings instead of BERT?\n\n**Hyperparameter Sensitivity:**\n- The reward function has 9 hyperparameters that require careful tuning (Table 6)\n- Figure 8 shows performance is sensitive to λharm, c1, w5\n- How do you set these in practice? Cross-validation on every new dataset?\n- This makes the method impractical for real deployment\n\n**Computational Cost:**\n- Table 4 shows **15.2 hours** for LLM inference on Amazon-Book (903.7 min)\n- Training time increases significantly (11.8s → 16.1s per epoch on Yelp)\n- How often must items be re-processed? Items in recommender systems change frequently\n- For industrial systems with millions of items, this is prohibitive\n\n### 4. **Questionable Design Choices**\n\n**Why BERT encoding?**\n- The LLM (Qwen-2.5-32B) already produces embeddings\n- Adding BERT encoding adds complexity and another model to maintain\n- No justification for this design choice\n\n**Concatenation fusion:**\n- Simple concatenation + linear layer is the most basic fusion method\n- Have you tried: attention-based fusion, gating mechanisms, learned weighted combination?\n- Ablation (Table 2) shows weighted summation is worse, but many other options exist\n\n**Mixed fine-tuning trade-off:**\n- Figure 3 shows mixed fine-tuning prevents catastrophic forgetting\n- But this means the LLM isn't really learning recommendation-specific CoT reasoning\n- It's just maintaining general capabilities while adding domain examples\n- Does this contradict the claim about leveraging deep CoT reasoning?\n\n**CoT necessity:**\n- The prompt (Figure 4) asks for 5 characteristics and sources\n- Is this actually \"reasoning\" or just structured extraction?\n- Ablation shows improvement over raw text (Table 2), but the gain is modest (2-4%)\n\n### 5. **Long-tail Claims Not Well Supported **\n\nThe paper claims to improve long-tail recommendations:\n- Figure 5 shows improvements across activity levels, but differences between LGHRec and baselines are often within error bars\n- On MIND (right panel), improvements for low-activity users [5,10) appear minimal\n- **No specific long-tail metrics**: Precision/Recall for cold-start items, coverage metrics, Gini coefficient\n- Figure 7(c) shows variance reduction, but absolute performance for long-tail items is not directly evaluated\n\n### 6. **Scalability and Practical Concerns **\n\n**Item cold-start:**\n- New items require LLM processing (15+ hours for 700K items)\n- How do you handle new items in real-time?\n- Periodic batch updates introduce staleness\n\n**Hyperparameter tuning cost:**\n- With 9 reward hyperparameters + 3 HGPO coefficients, tuning is expensive\n- Table 6 shows sensitivity - requires careful tuning per dataset\n- Industrial systems need methods that work out-of-the-box\n\n**Memory requirements:**\n- Table 4 shows modest memory increases\n- But storing semantic IDs for millions of items adds overhead"}, "questions": {"value": "1. **Why BERT encoding instead of LLM embeddings?** The LLM already produces embeddings. Adding BERT seems to add complexity without clear justification. Can you show that BERT encoding outperforms using the LLM's own embeddings?\n\n2. **Is CoT actually reasoning or structured extraction?** Your prompt (Figure 4) asks for 5 characteristics. This seems more like structured information extraction than deep reasoning. Can you demonstrate that the LLM is actually performing logical inference rather than just reformatting the input?\n\n3. **How do you set 9+ hyperparameters in practice?** The reward function has θFN, θeasy, θFP, θeasy_low, w1-w5, plus λharm, c1, w5 for HGPO. How should practitioners set these? Grid search would be prohibitively expensive.\n\n4. **Statistical significance?** Many improvements in Table 1 are 3-5% with no error bars. Are these statistically significant? Please provide significance tests.\n\n5. **Comparison with simpler LLM-enhanced methods?** Why not compare with: (a) using pre-trained LLM embeddings without CoT, (b) using simpler text descriptions, (c) other recent LLM-enhanced recommendation works?\n\n6. **Mixed fine-tuning contradiction?** Figure 3 shows mixed fine-tuning is best, but this prevents the LLM from specializing in recommendation CoT. Doesn't this undermine the claim about leveraging deep reasoning capabilities?\n\n7. **Computational cost trade-offs?** 15 hours for preprocessing Amazon-Book is substantial. Can you provide cost-benefit analysis? At what scale does this become impractical?\n\n8. **Long-tail specific evaluation?** Figure 5 shows activity-level breakdown, but can you provide dedicated cold-start metrics? Coverage? Gini coefficient? Evaluation specifically on tail items?\n\n9. **Why does HGPO outperform GRPO?** The only difference is the variance minimization term (Eq. 19). Can you provide deeper analysis of why this helps? Is it just preventing over-optimization of popular items?\n\n10. **Generalization across domains?** All three datasets are user-item interactions. Does this work for other types of recommendations (e.g., session-based, sequential with short sessions)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "2Q6fu9W1vb", "forum": "D43tkBzpuw", "replyto": "D43tkBzpuw", "signatures": ["ICLR.cc/2026/Conference/Submission24225/Reviewer_TkSg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24225/Reviewer_TkSg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24225/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761570827110, "cdate": 1761570827110, "tmdate": 1762943003517, "mdate": 1762943003517, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "4a9PXCnmEc", "forum": "D43tkBzpuw", "replyto": "D43tkBzpuw", "signatures": ["ICLR.cc/2026/Conference/Submission24225/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24225/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762955493203, "cdate": 1762955493203, "tmdate": 1762955493203, "mdate": 1762955493203, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a plug-and-play module for GNN-based recommender systems that enables the incorporation of CoT reasoning from LLMs and also applies HGPO, Harmonized Group Policy Optimization, to optimize negative sampling in recommender systems. Outperformed experimental results on three widely used datasets validates the efficacy of the proposed method."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper effectively leverages LLM-based high-quality representations through the generation of semantic IDs, which contributes to the observed performance gains.\n- The experiment that groups users by interaction count and demonstrates robustness under long-tailed user distributions aligns well with the claimed contributions in the introduction, reinforcing the practical relevance of the proposed approach.\n- The paper presents an effective ablation study, which thoroughly evaluates the contribution of each component in the proposed framework."}, "weaknesses": {"value": "- While the authors conduct a sensitivity analysis, the method still involves a large number of hyperparameters that require careful tuning, which may limit the practical applicability and ease of deployment of the approach.\n- Since Entropy Regularization loss is related to long-tail items, showing an ablation study on long-tailed items with this loss may enhance the novelty of the proposed method.\n- Although random negative sampling is acknowledged as a limitation, many graph-based contrastive learning methods also face similar challenges. Demonstrating that even the latest contrastive learning approaches struggle with this issue could further highlight the significance and contribution of incorporating LLM-based representations in the proposed method.\n- The visualization in Figure 6 is difficult to differentiate among the three methods."}, "questions": {"value": "1. Could the authors justify more why the NDCG increases when applying mixed data compared to using only domain data?\n2. During optimization, could the authors provide the reward trend to demonstrate that the reward consistently increases as intended by the model?\n3. How are the positive sample embedding and the candidate negative sample pool defined?\n4. Are the user and item embedding dimensions of the base model the same when incorporating LGHRec? Setting them to identical values would provide a fairer comparison, as some methods’ performance may depend on the embedding dimensionality."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "KcRUpHsVTW", "forum": "D43tkBzpuw", "replyto": "D43tkBzpuw", "signatures": ["ICLR.cc/2026/Conference/Submission24225/Reviewer_4s6f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24225/Reviewer_4s6f"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24225/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761876589913, "cdate": 1761876589913, "tmdate": 1762943003361, "mdate": 1762943003361, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes LGHRec, which fuses LLM step-by-step reasoning with reinforcement-learning-driven contrastive calibration to jointly upgrade semantic richness and training fairness for all user & item groups."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This work integrates LLMs and graph learning for recommendation, which is a novel topic that captures current trends and interests in the field.\n\n2. The paper is well-written and easy to follow, with a clear articulation of the motivation behind the research.\n\n3. The conducted experiments demonstrate the strengths of the proposed method, providing solid evidence of its effectiveness."}, "weaknesses": {"value": "1. In terms of overall comparison, it appears that the authors only compare their proposed method against the base model. To further validate the effectiveness of their approach, they should consider including comparisons with other LLM-enhanced recommendation systems.\n\n2. The authors should incorporate both significance analysis and case studies to provide a more comprehensive demonstration of the effectiveness of their work.\n\n3. What is the efficiency of the proposed method? The authors should consider adding efficiency experiments in the draft."}, "questions": {"value": "See Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Pm7RXA6LMb", "forum": "D43tkBzpuw", "replyto": "D43tkBzpuw", "signatures": ["ICLR.cc/2026/Conference/Submission24225/Reviewer_mkMn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24225/Reviewer_mkMn"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24225/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762263051306, "cdate": 1762263051306, "tmdate": 1762943002956, "mdate": 1762943002956, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents LGHRec, a framework that integrates the Chain-of-Thought (CoT) reasoning capabilities of Large Language Models (LLMs) with Graph Neural Network (GNN)-based recommender systems to enhance both semantic representation and contrastive learning. Specifically, the authors employ LLM-generated CoT reasoning to create high-density semantic ID embedding for items, which are encoded and fused with traditional ID embeddings, thereby enriching the representation space without incurring additional online costs. To address limitations in existing graph contrastive learning—particularly issues around fixed temperature coefficients and random negative sampling—the paper proposes Harmonized Group Policy Optimization (HGPO), a reinforcement learning strategy that adaptively selects negative samples and adjusts temperature values based on node characteristics, while ensuring cross-group consistency to mitigate performance disparities across long-tail and high-activity nodes. Extensive experiments across multiple datasets and models demonstrate consistent improvements, with NDCG@20 gains between 3% and 7%, especially in sparse data settings."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper proposes a new RecSys training paradigm that aims to solve the disadvantages of previous efforts.\n\n2. Paper proposes deep semantic embedding generator that generate much richer information through fine-tuned LLM.\n\n3. The paper designs a new reinforcement training algorithm based on grouped user/items."}, "weaknesses": {"value": "See Questions."}, "questions": {"value": "1. The paper is poorly written. For example, (1) authors spend too much words on describing the weakness of current methods in Abstract and Introduction. It is unnecessary and will shift away reader's attention to your main contribution. (2) Figure 1 is totally unnecessary for your paper. Authors do not need to explain the basic concept of LLM enhanced RecSys. (3) Most of figures in your paper are to vague to see, like Figure 3, 6, 7, 8.  The fonts on the figures are too small to observe.\n\n2. Authors discussed all the disadvantages of previous methods from graph contrastive learning, LLM-based RecSys and negative sampling. Can your method solve all the mentioned disadvantages at the same time? If those are not the problems authors try to solve, why bother mention them?\n\n3. Prompt grammatical error in Figure 4. \"Each keyword must be should focus on the item's attributes.\" \n\n4. There are so many thresholds in your method. How did authors decide them?\n\n5. The method design seems really combinational with several seeming unrelated modules. In my point of view, find the root cause and solution for each one of them is more worth to investigate than just combine them together."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LkKUky8xQG", "forum": "D43tkBzpuw", "replyto": "D43tkBzpuw", "signatures": ["ICLR.cc/2026/Conference/Submission24225/Reviewer_UuYJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24225/Reviewer_UuYJ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24225/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762297889211, "cdate": 1762297889211, "tmdate": 1762943002793, "mdate": 1762943002793, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}