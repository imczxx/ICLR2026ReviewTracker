{"id": "tVe3qmrH2h", "number": 5006, "cdate": 1757832137031, "mdate": 1759898000724, "content": {"title": "Rethinking LLM Human Simulation: When a Graph is What You Need", "abstract": "Large language models (LLMs) are increasingly used to simulate humans, with applications ranging from survey prediction to decision-making. However, are LLMs strictly necessary, or can smaller, domain-grounded models suffice? We identify a large class of simulation problems in which individuals make choices among discrete options, where a graph neural network (GNN) can match or surpass strong LLM baselines despite being three orders of magnitude smaller. We introduce Graph-basEd Models for Human Simulation (GEMS), which casts discrete choice simulation tasks as a link prediction problem on graphs, leveraging relational knowledge while incorporating language representations only when needed. Evaluations across three key settings on two simulation datasets show that GEMS achieves comparable or better accuracy than LLMs, with far greater efficiency, interpretability, and transparency, highlighting the promise of graph-based modeling as a lightweight alternative to LLMs for human simulation.", "tldr": "We present a graph-based link-prediction method for discrete-choice human simulation that matches or surpasses LLM-centric human simulation approaches while offering additional advantages.", "keywords": ["social and human simulation", "graphs", "large language models", "representation learning"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/aeba0edf764a0dff378544db611e700e372c0a75.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper reframes a classic recommender-style GNN as an alternative to LLMs for discrete choice prediction. While competently executed, it lacks conceptual novelty, overstates its claims about “human simulation,” and provides limited scientific insight."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors clearly reframe discrete-choice human simulation (e.g., predicting survey answers or behavioral decisions) as a link prediction task on a graph, where nodes represent individuals and choices.\n2. GEMS achieves comparable or even superior performance to strong LLM baselines (e.g., zero-shot, few-shot, chain-of-thought, fine-tuning) on three human-simulation subtasks."}, "weaknesses": {"value": "1. The presented results are not surprising. It is already well known that large language models perform well on some tasks but not on others. Beating them on structured, discrete-choice problems is expected rather than a breakthrough. The only contribution here appears to be modeling a discrete prediction problem as a network-based one, as graph neural networks for link prediction have already been widely studied in prior work.\n\n2. The use of the term “human simulation” exaggerates the scope of the paper and may mislead readers into thinking that it deals with cognitive modeling, psychology, or game theory, which it does not.\n\n3. The paper’s central empirical claim that graph neural networks can match or surpass large language models is not particularly impressive once it is clear that the evaluated tasks are simple classification problems with small and discrete output spaces.\n\n4. Overall, the work reads more like an engineering benchmark than a piece of scientific research that offers new insights or advances our understanding of the problem."}, "questions": {"value": "1. How can your model be generalized to other tasks related to human simulation?\n\n2. What are the contributions, except for modeling the discrete choice problem as link prediction?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0AAqbXPLoo", "forum": "tVe3qmrH2h", "replyto": "tVe3qmrH2h", "signatures": ["ICLR.cc/2026/Conference/Submission5006/Reviewer_U1BN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5006/Reviewer_U1BN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5006/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761199618682, "cdate": 1761199618682, "tmdate": 1762917818198, "mdate": 1762917818198, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces GEMS, a graph-based framework that reframes human simulation tasks where individuals choose among discrete options, as a link prediction problem on a heterogeneous graph of individuals, subgroups, and choices. Using relational structure and a GNN (plus an LLM-to-GNN projection when new questions appear), the authors conduct a comprehensive comparison of GEMS against multiple LLM-based baselines, achieving comparable or superior performance in most cases."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper provides a comprehensive comparison between the proposed GEMS framework and multiple LLM-based baselines, covering diverse settings and evaluation dimensions.\n\n- It addresses a highly relevant and practical problem and offering an efficient alternative to LLM-heavy approaches.\n\n- The study provides valuable and insightful findings, demonstrating that relational structure and graph-based reasoning can rival or surpass LLMs while being more efficient and interpretable."}, "weaknesses": {"value": "- The related work section is incomplete; it omits relevant studies exploring GNN-based approaches for multi-choice question answering, such as [1]. Including these works would clarify the connection to prior research and more accurately position the paper’s novelty.\n\n- The paper lacks simpler and stronger baselines. Comparing GEMS against a more basic neural network or MLP classifier could better isolate the contribution of the graph structure, while incorporating newer or larger LLMs would help establish upper performance bounds.\n\n- The paper lacks sufficient ablation studies to clarify the specific advantages of the proposed approach. For instance, conducting a user study to assess the claimed interpretability benefits would provide stronger empirical support for those claims.\n\n[1] QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question Answering."}, "questions": {"value": "- The datasets examined in the paper mostly contain a small number of choices (4–6). In real-world scenarios, the number of options can be much larger. How do the authors expect GEMS to perform compared to LLMs in such settings?\n\n- It would be interesting to explore the impact of demonstration selection in the few-shot setting, not only based on question similarity but also by incorporating attributes or other contextual features.\n\n- The paper mentions that LoRA was applied only to the attention query and value matrices. Could the authors clarify the motivation for restricting LoRA adaptation to only these parameters?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Bw12Xw6Ra7", "forum": "tVe3qmrH2h", "replyto": "tVe3qmrH2h", "signatures": ["ICLR.cc/2026/Conference/Submission5006/Reviewer_FxyC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5006/Reviewer_FxyC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5006/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761416585525, "cdate": 1761416585525, "tmdate": 1762917817864, "mdate": 1762917817864, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents GEMS, a framework for modeling human choices using GNNs, as an alternative to the use of LLMs. The case is made that GNNs can be at least as good as LLMs for such modeling with better efficiency and interpretability. GEMS uses relational knowledge between humans and tasks and uses link prediction for predicting the human choices on missing responses, new questions, and new individuals. There is a mechanism to transfer representation from LLMs to GNNs for the case of predicting responses on new questions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper develops a nice model for predicting choices using link prediction.\n\nThe transfer of information from LLMs to GNNs is done well.\n\nThe performance and interpretability of the approach is good."}, "weaknesses": {"value": "It is not unexpected that for many domains LLMs' performance can be surpassed through the use of GNNs or some other machine learning method. Thus, I find that the novelty low.\n\nThe setup and solutions are sound and along expected lines."}, "questions": {"value": "Why is the approach novel?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "BQ6spcBi11", "forum": "tVe3qmrH2h", "replyto": "tVe3qmrH2h", "signatures": ["ICLR.cc/2026/Conference/Submission5006/Reviewer_zh8M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5006/Reviewer_zh8M"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5006/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761799211770, "cdate": 1761799211770, "tmdate": 1762917817634, "mdate": 1762917817634, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose using GNN approaches to model discrete choice human simulation tasks, by formulating the problem as a link prediction problem on a graph of individuals, choices and subgroups. They show that their methods achieve comparable performance to LLM-based approaches."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "The paper is very well-motivated; The authors demonstrate a very good knowledge of the social simulation literature by covering all the main research progresses in the area. The three evaluation settings make sense. The writing is very clear and easy to follow. It’s also very nice that the authors included test-retest baselines."}, "weaknesses": {"value": "The authors do not adequately address the fundamental reasons why LLM-based social simulator are so popular. \n\n1)\tThe end-users for these models are often researchers with limited computational resources or expertise. LLMs, accessible via APIs and natural language prompting, offer a near-zero barrier to entry. In contrast, the GEMS framework requires data preprocessing, graph construction, model training, and fine-tuning, all posing a significant technical hurdle.\n\n2)\tA key advantage of LLMs is their ability to generate natural language outputs. Even though the chain-of-thought is not a genuine cognitive process, these textual explanations are invaluable for social scientists seeking qualitative insights. GEMS is a purely predictive model and thus simply does not have this capability.\n\n3)\tWhile many papers focus on single-step discrete choice settings, this is certainly not the entire LLM-for-social simulation field, as there are many applications that requires natural language output, or multi-turn interactions. \n\n4)\tThe paper's \"new questions\" setting is a form of in-domain generalization. The true challenge, which LLMs are better poised to handle, is cross-domain or cross-dataset generalization (e.g., applying a model trained on political surveys to a new dataset on consumer preferences). The GNN's rigid structure and learned embeddings are unlikely to transfer, a critical limitation that is not discussed with sufficient honesty. The GEMS approach is not a general-purpose \"human simulator\" but a specialized prediction model.\n\n5) The paper's empirical results are compelling, but their strength is contingent on the choice of baselines. The comparison is made against relatively small (7-8B parameters) and now somewhat dated LLMs (LLaMA-2, Mistral-7B-v0.1). To make a truly convincing case, it is essential to compare against a stronger \"upper bound,\" such as a state-of-the-art proprietary model (e.g., via the GPT-5 or Claude 4.5 APIs) or a strong open model. These models exhibit far superior reasoning and in-context learning capabilities, and practitioners would most likely use them as their first choice. Without this comparison, it is unclear if GEMS's performance advantage holds against the models that are actually being deployed for the social simulation tasks.\n\n6) Several claims need revision\n\na.\tPrompt formulations for LLM (Section 5.1) capture at most 1-hop structure and do not naturally express higher-order dependencies… I would like to see some references on this; In general, as universal function approximators, sufficiently large LLMs can theoretically learn complex, higher-order dependencies from data, even if they lack a specific graph-based inductive bias. This claim should be rephrased as a hypothesis about the differing inductive biases rather than a statement of fact about LLM capabilities.\n\nb.\tGEMS makes predictions in a computationally simple and interpretable way -> While the dot-product mechanism and embedding space are more inspectable than an LLM's internal states, GEMS is still a deep neural network, which is fundamentally uninterpretable, compared to, say, a decision tree. \n\n\n7) Clarification questions:\n\n(a) How does GEMS handle scenarios where the number of available options for a question changes between the training and test sets? This is a common practical issue that LLMs handle seamlessly but would likely require architectural changes or retraining for the GNN.\n\n(b) While the appendices contain details, the main paper would benefit from a more explicit description of the train/validation/test splits, particularly for the more complex imputation setting (Setting 1), to ensure the comparison between methods is clearly understood as fair."}, "questions": {"value": "see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7w0evTM4tR", "forum": "tVe3qmrH2h", "replyto": "tVe3qmrH2h", "signatures": ["ICLR.cc/2026/Conference/Submission5006/Reviewer_6bXm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5006/Reviewer_6bXm"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5006/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996316532, "cdate": 1761996316532, "tmdate": 1762917817321, "mdate": 1762917817321, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}