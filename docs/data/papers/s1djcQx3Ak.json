{"id": "s1djcQx3Ak", "number": 1419, "cdate": 1756881195752, "mdate": 1759898210127, "content": {"title": "ToProVAR: Efficient Visual Autoregressive Modeling via Tri-Dimensional Entropy-Aware Semantic Analysis and Sparsity Optimization", "abstract": "Visual Autoregressive (VAR) models enhance generation speed but face a critical efficiency bottleneck in later stages. In this paper, we present a novel optimization framework for VAR models that fundamentally differs from prior approaches such as FastVAR and SkipVAR. Instead of relying on heuristic skipping strategies, our method leverages attention entropy to characterize the semantic projections across different dimensions of the model architecture. This enables precise identification of parameter dynamics under varying token granularity levels, semantic scopes, and generation scales. Building on this analysis, we further uncover sparsity patterns along three critical dimensions—token, layer, and scale—and propose a set of fine-grained optimization strategies tailored to these patterns. Extensive evaluation demonstrates that our approach achieves aggressive acceleration of the generation process while significantly preserving semantic fidelity and fine details, outperforming traditional methods in both efficiency and quality. Experiments on Infinity-2B and Infinity-8B models demonstrate that ToProVAR achieves nearly 3.5× average acceleration with minimal quality loss, effectively mitigating the issues found in prior work. Our code will be made publicly available.", "tldr": "", "keywords": ["Image Generation", "Autoregressive Models", "Efficient Visual Generation;"], "primary_area": "infrastructure, software libraries, hardware, systems, etc.", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/370e05af9abd63cc145d0ccae5e3a9afd82af8a2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes ToProVAR for visual autoregressive models' acceleration. ToProVAR can identify parameter dynamics and redundancy at different granularities, semantic scopes, and generation scales, enabling fine-grained acceleration and pruning. In the experiments, the authors conduct comprehensive quantitative and qualitative evaluations on mainstream VAR models (Infinity-2B and Infinity-8B). Results show that ToProVAR achieves an average 3.5× inference speedup with almost no loss in generation quality, significantly outperforming existing SOTA methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- To obtain the entropy of the attention map while remaining compatible with FlashAttention, the authors propose FlashAttn-Entropy, which is noteworthy.\n\n- The proposed method achieves faster speed against previous methods like FastVAR.\n\n- The paper is well-written and easy to follow."}, "weaknesses": {"value": "- The proposed method is only evaluated on the Infinity model families. How does it perform on other model families such as HART?\n\n- The proposed method requires searching for the best hyperparameter combinations on different datasets. What is the computational cost of this process?\n\n- In Figure 3, the meaning of the lines with different colors is unclear. It is recommended to add a legend in this figure. Moreover, in Table 1, the bolded performance on the DPG dataset seems to be incorrect (FastVAR’s 83.39 should be better)."}, "questions": {"value": "- It seems that the proposed method requires performing online SVD for different samples. What is the time cost of this step?\n \n- What is the computational overhead of the proposed FlashAttn-Entropy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "AcqGOuHDPN", "forum": "s1djcQx3Ak", "replyto": "s1djcQx3Ak", "signatures": ["ICLR.cc/2026/Conference/Submission1419/Reviewer_FVpx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1419/Reviewer_FVpx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1419/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761615844917, "cdate": 1761615844917, "tmdate": 1762915765278, "mdate": 1762915765278, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ToProVAR, a novel acceleration framework for Visual Autoregressive (VAR) models that leverages attention entropy to perform fine-grained sparsity analysis across three dimensions—token, layer, and scale. By dynamically identifying and pruning semantically redundant computations, ToProVAR achieves up to 3.5× inference speedup on Infinity-2B and Infinity-8B models with minimal degradation in generation quality, effectively addressing issues like semantic loss, structural distortion, and detail collapse observed in prior methods such as FastVAR and SkipVAR."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The idea of employing attention entropy is interesting and the motivation is strong.  \n2. Solid experiments and promising performance."}, "weaknesses": {"value": "1. It would be beneficial to include results on additional backbones beyond Infinity, such as HART [1] and STAR [2], to demonstrate the generalizability of ToProVAR across different VAR architectures.\n2. The paper does not provide a detailed analysis of the computational overhead of SVD. Is there an analysis of the layer representation score? What are the patterns in the emergence of Global Layers and Detail Layers? Figure 10 shows an alternating pattern, is this behavior general? \n3. According to Table 4, Layer Representation Identification contributes most significantly to preserving generation quality (GenEval ↑ from 0.477 to 0.679), suggesting its critical role. Thus, more analysis such as qualitative cases would strengthen the paper’s claims."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qyF9UcZxF7", "forum": "s1djcQx3Ak", "replyto": "s1djcQx3Ak", "signatures": ["ICLR.cc/2026/Conference/Submission1419/Reviewer_2xuz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1419/Reviewer_2xuz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1419/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761816583297, "cdate": 1761816583297, "tmdate": 1762915765075, "mdate": 1762915765075, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ToProVAR, which is a training free acceleration framework for VAR that uses attention-entropy to drive sparsity decisions jointly across tokens, layers, and scales. The method authors proposed can generalize entropy beyond local tokens to cross-layer and cross-scale scopes. ToProVAR has shown good performance, where on infinity-2b/8b, it reports 3.4x and 2.7-3.0x speedups respectively with little quality loss on GenEval/DPG/HPSv2/ImageReward and MJHQ30K."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "$\\bullet$ New sparsity signal: moves from frequency heuristics to entropy based semantic salience, and the results with illustrations are convincing. \n\n$\\bullet$ three dimension design is well structured: starting with low entropy ratio, layer classification via principal component ratio from SVD, then unified token retention probability. \n\n$\\bullet$ Nontrivial novelty in the engineering design: FAE integrates entropy into flash attention to avoid $N \\times N$ instantiation and keep the linear-time behavior at the same time. \n\n$\\bullet$ Solid Empirical performance"}, "weaknesses": {"value": "$\\bullet$ The paper takes low attention-entropy as salient, but there is no proof it correlates with task loss or semantics, nor normalization across heads and layers with different logit temperatures. \n\n$\\bullet$ Deriving the error bounds or optimality for the tri-stage greedy pruning: Scale -> layer -> tokens decisions are locally heuristic with no suboptimality gap, stability, or compounding-error control. \n\nI understand this work focuses on empirical contributions, but it is often necessary to justify the empirical findings with explanations. I am not asking the authors to develop a full theoretical framework to address these weaknesses; I will be satisfied if the authors can answer these questions in text."}, "questions": {"value": "$\\bullet$ Can authors clarify the intended scope of attention-entropy as a salience proxy? How is it calibrated across heads/layers?\n\n$\\bullet$ Can authors discuss interactions across the scale -> layer -> token stages, provide the fallbacks, stop conditions, and outline a safe operating range where compounding errors are unlikely?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "hWyDZDEizW", "forum": "s1djcQx3Ak", "replyto": "s1djcQx3Ak", "signatures": ["ICLR.cc/2026/Conference/Submission1419/Reviewer_TaTd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1419/Reviewer_TaTd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1419/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761961399435, "cdate": 1761961399435, "tmdate": 1762915764949, "mdate": 1762915764949, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors show that attention entropy can be generalized across three dimensions (token, layer, and scale) to guide semantic-aware acceleration in visual autoregressive (VAR) models based on next-scale prediction. They first quantify semantic fineness across scales via the low-entropy ratio, determining the depth at which generation can safely begin pruning. Next, the authors classify layers into Global vs. Detail using the principal-component dominance (SVD-based ratio) of attention entropy, pruning only the Detail layers. Finally, the authors apply token-level salience pruning within prunable layers via a unified gating function that combines normalized entropy, layer scope, and scale depth. Empirically, the paper shows that compressing Global layers harms structure, whereas up to 90% compression on Detail layers preserves fidelity. Images with complex local detail show lower entropy and thus require deeper scales."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Integrated semantic perspective. The tri‑dimensional entropy viewpoint connects token salience, layer scope, and multi‑scale semantics, which motivates where to prune.\n\n* Layer taxonomy with a quantitative analysis. SVD‑based gives a reproducible criterion to distinguish Global/Detail layers before pruning.\n\n* Scale‑aware depth selection. The low‑entropy ratio offers a principled way to adapt depth to content complexity rather than using a fixed scale budget.\n\n* Empirical validation. The layer-specific compression curves (Fig. 3b) and ablations (Table 4) quantitatively support the semantic analysis, showing that pruning Detail layers up to 90% yields minimal quality degradation."}, "weaknesses": {"value": "I'm not an actual expert in this area, but I have some concerns about the paper (including some appendix) based on my understanding.\n\n* In terms of overhead and practicality, computing entropy per token, SVD per layer × scale, and tri‑dimensional gating online can be expensive. What is the actual (e.g., net) wall‑clock speedup vs. simpler frequency‑based methods once analysis overhead is included?\n\n* Calibration burden: Depth threshold $\\tau$ is selected by pre‑sampling (in Appendix). How robust is $\\tau$ across prompts, resolutions, and models? Is there an online estimator to avoid pre‑runs?\n\n* I think that the ablation studies should be done across dimensions. Could the authors isolate the incremental contributions of scale‑level, layer‑level, and token‑level pruning (three‑way ablation)? Current evidence is mostly qualitative.\n\n* Generalization beyond Infinity‑series: Do the layer‑scope statistics and ρs behavior hold for other VAR families and codebooks? Please include failure cases where Global/Detail separation is ambiguous."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "8ZjZOFL8co", "forum": "s1djcQx3Ak", "replyto": "s1djcQx3Ak", "signatures": ["ICLR.cc/2026/Conference/Submission1419/Reviewer_myfg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1419/Reviewer_myfg"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1419/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995259080, "cdate": 1761995259080, "tmdate": 1762915764823, "mdate": 1762915764823, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}