{"id": "7a95PGL0Up", "number": 3615, "cdate": 1757487040474, "mdate": 1763727859272, "content": {"title": "MC-SJD : Maximal Coupling Speculative Jacobi Decoding for Autoregressive Visual Generation Acceleration", "abstract": "While autoregressive (AR) modeling has recently emerged as a new paradigm in visual generation, its practical adoption is severely constrained by the slow inference speed of per-token generation, which often requires thousands of steps to produce a single sample. To address this challenge, we propose MC-SJD, a training-free, lossless parallel decoding framework designed to accelerate AR visual generation by extending the recently introduced Speculative Jacobi Decoding (SJD). Although SJD shows strong potential for accelerating AR generation, we demonstrate that token instability across iterations significantly reduces the acceptance rate, a limitation that primarily arises from the independent sampling process used during draft token generation. To overcome this, we introduce MC-SJD, an information-theoretic approach based on coupling, which substantially accelerates standard SJD by maximizing the probability of sampling identical draft tokens across consecutive iterations, all while preserving its lossless property. Remarkably, this method requires only a single-line modification to the existing algorithm, yet achieves substantial performance gains, delivering up to a ~3.8x speedup in image generation and ~10x speedup in video generation compared to standard AR decoding, without any degradation in output quality.", "tldr": "", "keywords": ["speculative decoding", "jacobi decoding", "autoregressive visual generation"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cffd52624ad1d01cc33b6a31e6f188f3ae53ccbb.pdf", "supplementary_material": "/attachment/f31b71a90b6ce0ff4216ac09a7a23206c597973f.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses the slow inference of autoregressive (AR) visual models by improving Speculative Jacobi Decoding (SJD). The authors identify that SJD's performance is bottlenecked by token instability, where independent sampling creates dissimilar draft tokens even when underlying probability distributions are close. The proposed solution, MC-SJD, is a lossless and training-free framework that uses \"Coupling\" to maximize the token similarity between iterations, thereby stabilizing convergence. The method demonstrates impressive speedups, achieving up to ~$3.8\\times$ in image and ~$10\\times$ in video generation without any degradation in output quality."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* Well-written and easy to follow.\n* Provides a novel problem and method in SJD based on the theoretically sound principle of coupling.\n* Demonstrates significant empirical speedups over baselines. The inclusion of experiments on both image and video generation tasks is a positive aspect of the evaluation."}, "weaknesses": {"value": "1. **Limited Empirical Support for Motivation**\n\t* The correlation in Fig. 2, which is used to empirically validate Observation 1, is not fully convincing. The Y-axis is restricted to an extremely narrow range (59.0–61.0), which makes the \"strong correlation\" difficult to confirm. The argument would be far more compelling if SJD, GS-SJD, and MC-SJD were all plotted on the same graph. This direct comparison would clearly visualize whether the proposed methods truly shift performance toward lower token difference and lower NFE, which is central to the paper's hypothesis.\n\t\n2. **Apparent Discrepancy Between Theory and Results**\n\t* An interesting discrepancy arises in Table 1 ($L=32$), where the theoretically suboptimal $\\pi_{GS}$ (Gumbel Coupling) achieves a better NFE than the \"optimal\" $\\pi_{MC}$. The paper fails to provide any analysis for this critical discrepancy, undermining its own central argument.\n\t\n3. **Incomplete Experimental Reporting**\n\t* Tables 2 and 3 report results for an ambiguous \"Ours\" metric, failing to specify whether $\\pi_{MC}$ or $\\pi_{GS}$ was used. As established in Weakness 2 (and Table 1), the performance trade-off between $\\pi_{MC}$ and $\\pi_{GS}$ seems inconsistent and setup-dependent. Therefore, it would be necessary to report results for both methods to provide a complete and transparent comparison.\n\t* Table 3 (Janus-Pro) omits wall-clock latency. This is a critical metric for evaluating the method's practical benefit, especially given the computational overhead of $\\pi_{MC}$ and $\\pi_{GS}$ observed in Table 1.\n\t* The validation for each task is confined to a single dataset (MSCOCO2017 for images, real-state-10k for video), which limits the assessment of the method's generalizability.\n\n4. **Lack of Limitation**\n\t* The paper does not provide any discussions regarding limitations."}, "questions": {"value": "1. The paper speculates that Gumbel Coupling ($\\pi_{GS}$) promotes \"long-range stabilization\". Could the authors elaborate on this concept? Specifically, what is the mechanism of this stabilization (e.g., how does sharing the same Gumbel noise across all iterations achieve this effect), and what is its concrete role in the decoding process? Does it, for example, help the entire sequence trajectory converge to a stable state more quickly?\n\n2. Following the first question and weakness 2, Table 1 shows that at $L=32$, $\\pi_{GS}$ achieves a better NFE than the theoretically optimal $\\pi_{MC}$. Does this finding suggest that the \"greedy\" optimization of $\\pi_{MC}$ (maximizing immediate $t$ vs. $t-1$ collision) is not always the globally optimal strategy for minimizing total NFE? Does it imply that, depending on the setup (like window size L, model, or task, etc), the \"long-range\" approach of $\\pi_{GS}$ can actually be the superior strategy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VyawTGJI84", "forum": "7a95PGL0Up", "replyto": "7a95PGL0Up", "signatures": ["ICLR.cc/2026/Conference/Submission3615/Reviewer_cQ2e"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3615/Reviewer_cQ2e"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3615/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982096123, "cdate": 1761982096123, "tmdate": 1762916873278, "mdate": 1762916873278, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors show that the bottleneck in Speculative Jacobi Decoding (SJD), low acceptance due to independent draft sampling, can be removed by coupling the draft distributions across iterations. They propose two couplers: Maximal Coupling (with acceptance equal to 1−TV(p,q)) and a cheaper Gumbel-Coupling (shared Gumbel noise) with a provable lower bound on collision probability; both plug into SJD with a one-line change in the drafting step. Theoretical analysis connects acceptance to total-variation distance and shows that independent sampling yields low collision probability bounded by Rényi-2 entropy, especially flat in visual AR; coupled sampling markedly raises acceptance trajectories βₜ (Fig. 3–4)."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "* Theoretical observation is very interesting. The paper replaces independent drafting by a principled coupling with formal guarantees (Theorem 2/3). The relationship between the acceptance and the total-variation is clear.\n\n* Drop‑in practicality. The “single‑line” modification to SJD is attractive for practitioners and retains lossless correctness of speculative decoding. \n\n* Strong speedups across both image and video domains, scaling favorably with larger SJD windows where vanilla SJD saturates."}, "weaknesses": {"value": "I'm not an expert in this area, but I have some concerns about the paper based on my understanding.\n\n1. I have some doubt on compute/memory cost of coupling. What is the runtime and memory overhead for maximal vs. Gumbel coupling (per step, per window L)? Any GPU kernel implications vs. independent sampling?\n\n2. Is there any failure modes observed empirically? For example, when p and q are both flat (I think it would be common in AR images), TV is small but entropy is high. Does coupling still help, or do we hit the Rényi‑2 bound and stagnate? Please show acceptance curves for extreme‑flat logits.\n\n3. CFG interaction: you note speed dips at higher guidance (sharper logits). Can you quantify the acceptance–guidance trade‑off and provide an adaptive lambda schedule for maximum throughput?"}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "TD3j6ITm3T", "forum": "7a95PGL0Up", "replyto": "7a95PGL0Up", "signatures": ["ICLR.cc/2026/Conference/Submission3615/Reviewer_znnZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3615/Reviewer_znnZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3615/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992856150, "cdate": 1761992856150, "tmdate": 1762916872908, "mdate": 1762916872908, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Global Response : Coupling Overhead"}, "comment": {"value": "# Overhead of Coupling  \n  \n\n\nWe thank the reviewers for the constructive feedback. In fact, our coupler introduces **almost no overhead** compared to standard SJD in the real implementation, and this property is actually one of the **key strengths** of our method. This is because of the following:\n\n* **For $\\pi_{MC}$:** Algorithm 2 in the paper is pseudo-code for a conceptually clear comparison with SJD, and there are actually no cached probabilities in the real implementation. In an actual efficient implementation, the for-loop in Line'5(in Alg.2) does not exist, and **we simply execute the verification loop in Line'9 without a break, storing the index of the first $k=0$ signal**. This can be easily validated by the fact that Line'5 and Line'9 are strictly identical operations because $p^{(t+1)}, p^{(t)}$ in Line'9 becomes $p^{(t)}, p^{(t-1)}$ in the next loop's Line'5. Thus, there is no additional memory used compared to standard SJD. Moreover, because we do not have to break Line'8 loop sequentially, we can **vectorize** this loop; thus, the computational overhead of MRS relative to the window Length is also negligible. We also show real latency breakdown of vectorized MRS in below.\n\n* **For $\\pi_{GS}$:** In an actual efficient implementation, we do not need to pre-sample and store Gumbel noise in memory. We can just sample Gumbel noise **online** by hashing the global index(which is only 4Bytes) of the current token to generate the Uniform RNG, eliminating memory overhead; the computational overhead of this online RNG sampling is negligible. Moreover, because the 'token sampling' part with Gumbel noise is computationally identical to the standard multinomial sampling used in independent sampling, GS also has negligible overhead in reality.\n\n# Latency Breakdown\n\nTo also validate that our coupler has negligible overhead in practice, we implemented the efficient version of our coupler and present the wall-clock latency breakdown of each component in a single NFE step.\n\n| Operation  | $L=16$ | $L=32$ | $L=64$ | \n| :--- | :---: | :---: | :---: |\n| Input Preprocessing | 1.52 | 1.53 | 1.58 |\n| **Transformer Forward** | **26.49** | **27.73** | **36.41** |\n| Logit Processing (CFG, Top-K) | 0.16 | 0.23 | 0.25 |\n| **Token Sampling (GS-Coupling)** | 0.13 | 0.13 | 0.14 |\n| **Vectorized MRS (MC-Coupling)** | 1.56 | 1.58 | 1.66 |\n| Post Process | 0.81 | 0.82 | 0.84 |\n(milliseconds, Janus-Pro, RTX 3090)\n\n\nAs shown, the Transformer forward pass dominates the total latency, and the overhead introduced by our coupling (Vectorized MRS or Token Sampling) is under $\\sim$5\\%, and even decreases when the window size increases.\n\n---\n\nWe will add difference between the logical representation of the algorithm in the paper and the actual implementation. Also, we will clarify that there is almost no overhead with our coupling with breakdown results. Besides, we also note that our use of Gumbel Coupling is driven not just by efficiency, but by its implementation simplicity (friendly for limited hardware like NPUs) and its positive impact on NFE at some cases."}}, "id": "yTTVIhDEXJ", "forum": "7a95PGL0Up", "replyto": "7a95PGL0Up", "signatures": ["ICLR.cc/2026/Conference/Submission3615/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3615/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3615/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763725932236, "cdate": 1763725932236, "tmdate": 1763725932236, "mdate": 1763725932236, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The manuscript proposes MC-SJD, a training-free modification of Speculative Jacobi Decoding (SJD) for autoregressive (AR) visual generation. The manuscript analyzes that the acceptance rate is negatively proportional to the total variation of the drafter and verifier distributions, and argues that independent drafting in SJD yields very low collision under flat vision logits. Aware of this, they propose a key idea to couple the draft sampling across consecutive Jacobi iterations via maximal coupling (using the same MRS routine as SD verification) or a cheaper Gumbel noise–sharing variant to increase token collisions between drafts, thereby boosting acceptance rates while remaining lossless. Empirically, they report up to ~3.8× image speedup and ~10× video speedup without quality degradation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Clean and intuitive problem statement - points out an overlooked but crucial detriment of SJD.\n2. MC-SJD can be employed with minimal implementation change."}, "weaknesses": {"value": "1. Baseline coverage is a bit limited. While SJD and one baseline (GSD) are included, there’s no comparison with other accepted speculative decoding baselines, such as EAGLE-3.\n2. Latency analyses w.r.t. the batch size are absent.\n3. Memory overhead analysis of the cached probabilities is needed, especially w.r.t. the batch size and window length.\n4. Latency breakdown or microbenchmark for the sampling process would benefit the paper."}, "questions": {"value": "1. When using top-k sampling (as in the experiments section) or using CFG, how is the lossless-ness guaranteed? How does the sampling process go?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RpySvWoS3n", "forum": "7a95PGL0Up", "replyto": "7a95PGL0Up", "signatures": ["ICLR.cc/2026/Conference/Submission3615/Reviewer_FLTy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3615/Reviewer_FLTy"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3615/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762076683491, "cdate": 1762076683491, "tmdate": 1762916872374, "mdate": 1762916872374, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}