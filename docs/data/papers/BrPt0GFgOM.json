{"id": "BrPt0GFgOM", "number": 20953, "cdate": 1758311980624, "mdate": 1759896950055, "content": {"title": "Dual Language Models: Balancing sample-efficiency and overfitting resilience", "abstract": "This paper combines autoregressive and masked-diffusion training objectives without any architectural modifications, resulting in flexible models that outperform single-objective baselines in both settings. Autoregressive language modeling has been a popular training approach, partly because of its sample efficiency; however, this comes at the cost of susceptibility to overfitting. On the other hand, masked-diffusion language models are less sample-efficient while being more resilient to overfitting. In this work, we demonstrate that dual-objective training achieves the best of both worlds. To derive the optimal ratio of the masked-diffusion and autoregressive objectives, we train and evaluate 50 language models under varying levels of data repetition. We show that it is optimal to combine both objectives under all evaluated settings and that the optimal ratio is similar whether targeting autoregressive or masked-diffusion downstream performance.", "tldr": "We simultaneously train language models on autoregressive and masked-diffusion objectives, resulting in flexible models that outperform the single-objective models in both settings.", "keywords": ["language model", "pretraining", "training objective", "mixed training objective", "masked diffusion"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/04089950d0e4860c5bc68739e3bce217bb90d66e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Dual Language Models (Dual-LMs), which jointly train a single transformer with both autoregressive (AR) and masked-diffusion (MD) objectives. The key motivation is to balance sample efficiency (of AR training) and overfitting resilience (of MD training) without changing the model architecture. The authors conduct a large-scale empirical study on 50 language models to support the method's effectiveness."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Clear motivation and timely problem.\nThe work addresses a relevant issue as large-scale language model training increasingly encounters limited high-quality data and potential overfitting under repeated exposure.\n2. Practical recommendations\nThe derived empirical guidelines (e.g., small MD component under regular regimes, stronger MD ratio under high repetition) are actionable for practitioners designing large-scale LLM training recipes."}, "weaknesses": {"value": "1. Limited contribution in standard settings.\nWhen trained with only 1× data repetition, Dual-LMs provide no significant improvement over pure autoregressive baselines. This weakens the overall claim of universal benefit; the method is primarily helpful under extreme data-reuse scenarios\n2. Practical rarity of extreme repetition.\nThe key advantage appears only under 128× repetition, which is rarely used in modern large-scale LLM training. In realistic compute-optimal regimes (1–8× repetition), the dual-objective gains are negligible.\n3. Learning rate confound.\nFor very high repetition, a smaller learning rate is typically required to maintain stability. Since the experiments maintain a fixed LR schedule, it is unclear whether the observed benefits of Dual-LMs come from the objective mixing itself or from suboptimal tuning in baselines.\n4. Method scope and positioning.\nOverall, the approach seems more suitable as a regularization mechanism for repeated training rather than a fundamentally new paradigm for LLM optimization. The contribution is empirical rather than conceptual, and its practical importance outside data-scarce settings is limited."}, "questions": {"value": "1. The paper’s results suggest that the dual-objective helps mainly under extreme data repetition. What prevents it from providing gains in standard (1–8×) training regimes? Is it fundamentally tied to overfitting mitigation rather than general sample efficiency improvement?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "x1yybzo43y", "forum": "BrPt0GFgOM", "replyto": "BrPt0GFgOM", "signatures": ["ICLR.cc/2026/Conference/Submission20953/Reviewer_Z29n"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20953/Reviewer_Z29n"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20953/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760695799903, "cdate": 1760695799903, "tmdate": 1762939051091, "mdate": 1762939051091, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the trade-off between sample efficiency and overfitting resilience in language modeling by combining autoregressive and masked-diffusion objectives in a single transformer architecture, without architectural modifications. The authors conduct an extensive empirical study, training 50 models across varying data repetition regimes, to uncover the optimal balance between the two objectives. They show that the dual-objective approach consistently outperforms single-objective baselines in both autoregressive and masked-diffusion downstream tasks, providing practical guidance on loss balancing and implications for prefix language modeling."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The authors train and evaluate 50 language model configurations under a wide range of data repetition regimes, allowing for robust conclusions on objective balancing.\n- The dual-objective method is introduced without architectural changes, maximizing practical usability.\n- The paper distills its complex results into two practical, easy-to-understand guidelines for training models in regular and data-constrained regimes."}, "weaknesses": {"value": "- The core idea of combining AR and masked objectives in a single decoder-only model is not entirely new and builds heavily on previous work, particularly GPT-BERT, which the authors acknowledge. The primary contribution is more of an extensive empirical investigation rather than a fundamentally new training paradigm.\n- While Section 6 discusses prior methods such as GPT-BERT and AntLM, the paper does not include empirical comparisons with these or other recent approaches (e.g. Block Diffusion [1], AR-Diffusion [2]) that address the same AR–diffusion trade-off. Including recent works as baselines under the same training setup would provide a clearer and fairer assessment of the proposed method’s advantages.\n- The paper assumes that the findings generalize to larger models, but this remains speculative, as all experiments are limited to the 470M scale. Given the unpredictability of scaling behavior, it is unclear whether the observed trends would hold for models beyond 1B parameters.\n- While Equations (2) and (4) define the individual objectives, the paper offers little theoretical explanation of how their joint optimization works. The rationale for specific weighting choices is empirical, and potential gradient interference or complementarity between the two losses is not analyzed.\n\n[1] Arriola, Marianne et al. “Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models.” 2025\n[2] Wu, Tong et al. “AR-Diffusion: Auto-Regressive Diffusion Model for Text Generation.” 2023"}, "questions": {"value": "- The paper builds on established ideas such as GPT-BERT and CM3, with the main contribution appearing to be the systematic analysis of data repetition effects. Could the authors clarify the specific technical or algorithmic innovations introduced by the proposed dual-objective framework beyond these prior methods?\n- Would the authors consider adding or discussing comparisons with related works (e.g. Block Diffusion and AR-Diffusion), which also address the AR–diffusion trade-off?\n- Can the authors provide evidence—empirical or analytical—that the optimal AR–MD ratios and the 16-repetition guideline (Remark 2) remain valid for larger models (≥ 1B parameters)?\n- Can the authors provide a more rigorous theoretical basis or empirical ablation for their objective weighting strategy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6OqkP7QexV", "forum": "BrPt0GFgOM", "replyto": "BrPt0GFgOM", "signatures": ["ICLR.cc/2026/Conference/Submission20953/Reviewer_apc1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20953/Reviewer_apc1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20953/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761726856726, "cdate": 1761726856726, "tmdate": 1762939050231, "mdate": 1762939050231, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work studies Dual LM, which combines the auto aggressive next token prediction and masked language modeling into a single model. To be specific, authors are investigating the potential to train one single LLM with two different training objectives. And the finding is we can achieve a better trade off between compute efficiency and data efficiency by adjusting the ratio of two training objectives."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1) Very clear presentation. The lessons and insights are very presented so that readers can understand the problem well.\n2) Studying the data efficiency is a very important problem, for both large and small models, especially considering we are overtraining models for better quality and cheaper serving cost.\n3) The sweep on training objective ratio is informative. This can help to design better training schedule targeting on a specific data/compute efficiency."}, "weaknesses": {"value": "1) The definition of sample-efficiency is confusing. I think it would be better to rephrase it as \"compute-efficiency\". The sample efficiency makes people confused whether the sample here means \"unique token efficiency\". \n2) Minor: I understand the research is usually for long term purpose, but to be very honest, the conclusion we achieved in this work is we only need dual LM for very aggressive repeats. This is anyway informative but not something we have to use now."}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "y9Al1dViO8", "forum": "BrPt0GFgOM", "replyto": "BrPt0GFgOM", "signatures": ["ICLR.cc/2026/Conference/Submission20953/Reviewer_59vc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20953/Reviewer_59vc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20953/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761753055467, "cdate": 1761753055467, "tmdate": 1762939048767, "mdate": 1762939048767, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to introduce a unified training objective for language modeling that jointly optimizes autoregressive (AR) and masked-diffusion losses within a single transformer, while requiring no architectural modification. \nBy co-training a single transformer model on both losses, DLM leverages AR’s rapid convergence while regularizing with the diffusion objective to prevent overfitting. Extensive experiments across diverse benchmarks demonstrate that this hybrid objective consistently enhances performance over single-objective baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This paper is well written and easy to follow. The narrative is coherent, and the topic is both timely and important for the current stage of large language model development.\n\nThe proposed DLM objective is conceptually simple and practically appealing. It requires no architectural changes and includes GPU-efficient adaptations, making the method easy to implement and broadly applicable. This design choice enhances the practical relevance of the work.\n\nThe empirical evaluation appears systematic and comprehensive. The experiments are carefully structured, covering a wide range of data regimes and objective ratios, which strengthens the credibility of the results and the generality of the conclusions.\n\nAlthough the work is primarily empirical, it offers new insights that meaningfully advance understanding in the community."}, "weaknesses": {"value": "### The link to diffusion language model is a bit weak \n\nIt is unclear to me whether the “diffusion mode” in the proposed objective truly corresponds to a standard masked diffusion language model, as to my knowledge, no published work implements diffusion language model using a decoder. \nConceptually, the proposed objective appears closer to introducing stochastic regularization into standard autoregressive training—adding noise to the input sequence to improve generalization and reduce overfitting. \nMoreover, it remains ambiguous whether the resulting model supports parallel decoding, a defining property of diffusion-based LMs. \nWhile the paper claims that the model “can generalize to prefix LM,” it does not explicitly demonstrate diffusion-style generation. A clearer explanation of how the diffusion time-conditioning interacts with the next-token prediction objective would strengthen the technical grounding.\n\n\n### Lack of analytical justificaiton. \n\nThe paper’s conclusions are derived almost entirely from empirical evidence. While the experiments are thorough and convincing, additional theoretical or analytical insights would improve the work’s depth. For example, identifying sufficient conditions (some toy cases) under which the dual-objective training is guaranteed to outperform either individual objective would help explain why the method works beyond observation. \n\n\n### Incomplete discussion of training dynamics.\nThe paper focuses primarily on zero-shot, multiple-choice benchmarks but provides limited discussion of training behavior. Analyses of the loss curves (for both AR and diffusion modes), convergence patterns, and stability would give a more complete understanding of how the dual objective influences optimization and generative quality."}, "questions": {"value": "* Could you elaborate more on how closely does the proposed “diffusion mode” correspond to a standard masked-diffusion language model? For instance, how is the diffusion time variable integrated into the next-token prediction objective, is it sampled per token or globally for the sequence, and how does this choice affect model behavior? How does the new objective support parallel decoding or multi-token prediction? \n\n* How stable is the training process under the dual objective? I am wondering what would the loss curves look like and whether there are any significant tradeoffs between the two modes during training?\n\n* How does this work relate to a recent work [1] that proposed a modified decoder architecture to do any-order next-token prediction? \n\n[1] Any-Order GPT as Masked Diffusion Model: Decoupling Formulation and Architecture, arxiv preprint 2506.19935"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "0k94nPNopR", "forum": "BrPt0GFgOM", "replyto": "BrPt0GFgOM", "signatures": ["ICLR.cc/2026/Conference/Submission20953/Reviewer_cMFP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20953/Reviewer_cMFP"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20953/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762436903605, "cdate": 1762436903605, "tmdate": 1762939047018, "mdate": 1762939047018, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}