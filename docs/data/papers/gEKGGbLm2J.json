{"id": "gEKGGbLm2J", "number": 12871, "cdate": 1758211062837, "mdate": 1759897480273, "content": {"title": "GraGR: Gradient-Guided Graph Reasoner for Aligned and Interpretable GNNs", "abstract": "We propose the GraGR framework, which leverages gradients as reasoning signals to address two intertwined challenges in GNNs: (1) node-level gradient inconsistency across neighbors, and (2) interpretability misalignment between model training and explanations. GraGR’s core modules detect and smooth conflicting per-node gradients via a conflict loss and Laplacian-based smoothing, and convert pairwise gradient inner-products into attention weights for message passing. We further introduce a meta-gradient scaling scheme (learnable task weights updated by hypergradients) to balance heterogeneous objectives when multiple tasks are present. Together, these components reduce local gradient misalignment and yield more stable, faithful explanations. We extend GraGR to GraGR++ by adding multi-pathway routing (parallel routing pathways) and an adaptive training scheduler that gates gradient reasoning until base convergence. Importantly, we define six gradient-derived node features that quantitatively characterize a node’s learning dynamics and offer interpretable insights. Experiments on benchmark datasets (Cora, Citeseer, PubMed, OGB-MolHIV) show that GraGR/GraGR++ improve predictive performance and explanation coherence compared to baselines, while significantly reducing the proposed conflict energy. This work unifies optimization and interpretability in GNNs under a gradient-as-reasoning paradigm, making node-level dynamics both correctable and explainable.", "tldr": "We introduce GraGR, a gradient-guided reasoning framework for GNNs that reduces gradient conflicts and enhances interpretability through gradient-derived features and dynamic reasoning pathways.", "keywords": ["Graph Neural Networks", "Gradient", "Topological Features", "Interpretable", "Reasoning", "Explainable AI", "Natural Language Processing"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9d439858b17124ee74157b7dc66c0ddc768b7eeb.pdf", "supplementary_material": "/attachment/36c323a15b2f4a9f86109da46689b3a0932ffabd.zip"}, "replies": [{"content": {"summary": {"value": "This paper argues that reducing gradient conflicts within GNNs can improve the performance and bring interpretability.\nTo this end, this work presents a GraGR framework, which integrates many techniques for processing gradient conflicts, and generates more node features for downstream tasks. Experiments on benchmark datasets show that GraGR/GraGR++ improves predictive performance compared to baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- This article integrates many interesting gradient processing techniques to improve the training of GNN.\n- The Figures in this article are exquisite, and the typesetting is beautiful."}, "weaknesses": {"value": "1. In Section 4.2, Equation (4) appears abruptly. Do $g'_v$ in Equation (3) and $g'_v$ in Equation (4) refer to the same variable?  \n\n2. Under what circumstances does $cos(g'_v, g_{ctx})$ in Lemma 1 become greater than 0? It seems to be always equal to 0, which is confusing.  \n\n3. During training, does g'_v replace the original gradients of nodes? If so, $L_{conf}$ should be always equal to 0 so is it meaningful?  \n\n4. When $L_{val}$ is first introduced, its specific form is not explained. If $L_{val}$ simply refers to $L_{conf}$, what is the point of introducing $L_{val}$?  \n\n5. This work integrates many gradient-processing techniques to handle conflicting gradients and generate diverse node features for downstream tasks. However, the \"Reasoner for Aligned and Interpretable GNNs\" claimed in the title is not as intuitively demonstrated as CoT. The interpretability claimed in the title is also generated by LLMs; in fact, LLMs can generate plausible explanations for other explanatory components through prompt engineering, making the relevant experiments less convincing. For how to evaluate standard GNN interpretability, the authors may refer to the experiments in the PGExplainer cited in their paper and compare with baselines. \n\n6. The experimental results lack rigor. First, no statistical tests are conducted, so it is unclear whether the improvements brought by GraGR are significant. Second, tuning the seed and scheduler in GraGR++ is unfair to baseline methods. Third, Section 5.2 states that using GraGR in every epoch may even be harmful, yet Section 4 only presents the advantages of GraGR without providing sufficient analysis on why GraGR may be harmful.  \n\n7. The paper states that e_v in Eq. (16) serves as both (i) an auxiliary signal for the GNN classifier and (ii) structured input for a large LLM, but e_v does not directly appear in the input of the LLM in Eq. (17), and it is not explained where prediction $\\hat{y}$ in Eq. (17) comes from.\n\nIn summary, the method section of this paper introduces many gradient-processing techniques. However, the connections between these techniques and the motivations/necessity for introducing them are not organized concisely and clearly. This makes it difficult for me to judge whether these techniques actually work, and also hard to identify the contributions of this work."}, "questions": {"value": "Please refer to the above weakness section for suggestions and questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "4vqbhv6cxJ", "forum": "gEKGGbLm2J", "replyto": "gEKGGbLm2J", "signatures": ["ICLR.cc/2026/Conference/Submission12871/Reviewer_VvJd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12871/Reviewer_VvJd"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12871/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760861541087, "cdate": 1760861541087, "tmdate": 1762923661780, "mdate": 1762923661780, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes GraGR, a framework that leverages gradients as reasoning signals to jointly address gradient inconsistency across neighboring nodes and the misalignment between training and interpretability in GNNs. The method introduces conflict loss, Laplacian-based smoothing, and meta-gradient scaling to balance multiple objectives and enhance explanation faithfulness. An extended version, GraGR++, incorporates multi-pathway routing and adaptive training scheduling. Experiments on several benchmark datasets demonstrate improved predictive performance, stability, and interpretability compared to existing methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "S1: The proposed method provides a meaningful contribution to improving the optimization process of GNNs.\n\nS2: Experimental results across four baseline GNN architectures demonstrate the effectiveness of the proposed optimization method."}, "weaknesses": {"value": "W1: In the experimental section, the proposed method appears to show inconsistent behavior across different GNN backbones, and some results are not fully convincing. For example, in Table 7, the reported training times of various models raise questions. It is unclear why the GAT model requires less training time than other classical GNNs, or why GraGR++ takes less time than GraGR, which seems counterintuitive.\n\nW2: The description of using large language models (LLMs) for generating explanations in Section 7.1 lacks sufficient detail. The process and implementation are not clearly explained, and the reliability of the generated explanations may depend on several factors—most importantly, the quality of the LLM itself. However, the authors do not specify which LLM was used or provide any justification for its choice.\n\nW3: The paper’s central claim regarding node-level gradient inconsistency lacks sufficient empirical and literature support. While the authors argue that gradient conflicts are widespread and significantly impact GNN optimization and interpretability, the reported experimental evidence (e.g., only 21 conflicting nodes out of 2708 on Cora) suggests that the phenomenon may be limited. This raises concerns about the generality and practical significance of the proposed motivation.\n\nW4: The proposed method primarily focuses on smoothing the GNN optimization process, while its claimed interpretability benefits appear less convincing. The paper lacks illustrative, strong interpretability examples, and the embedding visualizations show limited improvement, making it difficult to substantiate the claimed enhancement in explanation quality."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PTdf3Ad8NE", "forum": "gEKGGbLm2J", "replyto": "gEKGGbLm2J", "signatures": ["ICLR.cc/2026/Conference/Submission12871/Reviewer_9hVV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12871/Reviewer_9hVV"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12871/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761633458919, "cdate": 1761633458919, "tmdate": 1762923661415, "mdate": 1762923661415, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper propose the GraGR framework that integrates gradient-based reasoning into Graph Neural Networks (GNNs) to tackle the challenges of gradient inconsistency and misalignment between model training and interpretability. The core idea of GraGR is to treat gradients as explicit reasoning signals, enabling more stable optimization and interpretable explanations. The framework introduces several techniques, including gradient conflict detection, Laplacian-based gradient smoothing, gradient-based attention for message passing, and meta-gradient modulation for multi-task learning. Additionally, the authors extend GraGR to GraGR++ by adding multi-pathway routing and an adaptive scheduling mechanism, improving robustness and stability during training."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe paper introduces a way of using gradients as reasoning signals to improve both the stability and interpretability of GNNs."}, "weaknesses": {"value": "1.\tThe overall paper is somewhat confusing to read. For example, in the introduction, the authors emphasize node-level gradient inconsistency, but the introduction does not focus on the multi-task learning setup. This makes it unclear where the node-level gradient inconsistency originates. It is not until the Problem Statement section that the issue is revealed to be related to multi-task learning in GCNs. As a result, there is a noticeable disconnection between the introduction and the Problem Statement section, which creates confusion for the reader.\n2.\tI am not entirely sure what the authors are focusing on. The overall impression from reading the paper is that the authors aim to improve multi-task learning accuracy by designing gradient-related loss terms. However, if the focus is on improving the accuracy of multi-task learning, the experimental results show that on the PROTEINS dataset, the performance is not better than the baseline. Moreover, there are no multi-task learning-related baselines in the experiments; instead, the baselines are based on gradient methods for the original GCN, which are not related to multi-task learning. This comparison seems unfair.\n3.\tIn the Methodology section, what is the relationship between each subsection (4.1, 4.2, 4.3, 4.4)? In Section 4.3, the attention weight based on the smoothed gradients is introduced. How is this applied in Section 4.4? If the training process is related to this gradient, then the authors' research problem seems to shift to how to improve accuracy in multi-task learning. Therefore, the baseline section should include more related baselines for multi-task learning.\n4.\tWhat is the relationship between Section 5 and Section 4? In Section 5, what exactly is the 'reasoning pathway'? Why is it necessary to test different random seeds? These aspects are quite confusing. Is each pathway referring to the information propagation path in GCN?\n5.\tIn Section 7, the paper uses an LLM model to directly generate explanations for the GCN model. However, the LLM itself is a complex black-box model, and so is GCN. The explanations generated by the LLM cannot be directly evaluated, which raises concerns about their reliability"}, "questions": {"value": "See the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "V82ZT5O2ST", "forum": "gEKGGbLm2J", "replyto": "gEKGGbLm2J", "signatures": ["ICLR.cc/2026/Conference/Submission12871/Reviewer_nrZf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12871/Reviewer_nrZf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12871/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761812616562, "cdate": 1761812616562, "tmdate": 1762923661123, "mdate": 1762923661123, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the issue of inconsistent gradient directions and magnitudes across neighboring nodes in graph neural networks (GNNs), particularly on irregular graphs. It introduces a Gradient Smoothing (GS) module that aligns node gradients locally to stabilize training and reduce conflicting updates. The method is model-agnostic and is evaluated across multiple node and graph classification benchmarks, showing improved convergence and accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The GS module is lightweight, model-agnostic, and can be integrated into existing GNNs without modifying architecture or message-passing schemes.\n\n- Experimental results across standard benchmarks on node classification and graph classification task demonstrates consistent performance and convergence improvements."}, "weaknesses": {"value": "- Unclear and underdeveloped motivation: The paper claims that inconsistent gradients across neighboring nodes cause optimization instability (e.g., overshooting or oscillation), but this is not directly demonstrated. No empirical evidence is shown that training without smoothing leads to such instability. The proposed method is introduced immediately after this claim, without establishing whether existing optimization techniques (e.g., normalization, adaptive learning rates) are insufficient.\n\n- Unjustified suppression of conflicting nodes: The method includes masking nodes whose gradients deviate from a smoothed global direction, but offers no justification for why this is appropriate. It remains unclear whether such nodes are noisy or informative, and no empirical analysis supports the impact of this masking.\n\n- No connection to interpretability, despite gradient-based framing: The paper begins by analyzing gradient inconsistency, a topic relevant to GNN explainability, but does not evaluate whether smoothing improves attribution, saliency, or stability. The method is not compared to any existing GNN explainability methods quantitatively and qualitatively. Its benefit on interpretability is over-claimed without sufficient empricial justification.\n\n- No evaluation on link prediction tasks: The method is only evaluated on node and graph classification. It is unclear whether gradient smoothing benefits more general GNN tasks like link prediction, limiting the scope of the evidence presented.\n\n- Writing and presentation reduce clarity: Key concepts are presented with minimal intuition and heavy reliance on math. Several typos and grammar issues are present (e.g., “mult-pathways optimization” in Line 136, broken line in “node- and graph- level prediction” in Line 39). Tables 4 and 5 are rotated in a way that makes them difficult to read, further affecting clarity."}, "questions": {"value": "- Can the authors provide concrete evidence that inconsistent gradients directly cause optimization instability in vanilla GNNs?\n\n- Why are potentially informative or hard examples suppressed during training if their gradients differ from the smoothed direction?\n\n- Could this approach really help interpretability? Why were no comparisons to GNN explanation methods included?\n\n- Does the method generalize well to link prediction tasks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "K3nbPU1uix", "forum": "gEKGGbLm2J", "replyto": "gEKGGbLm2J", "signatures": ["ICLR.cc/2026/Conference/Submission12871/Reviewer_5QgX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12871/Reviewer_5QgX"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12871/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761987831441, "cdate": 1761987831441, "tmdate": 1762923660532, "mdate": 1762923660532, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}