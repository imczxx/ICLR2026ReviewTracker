{"id": "foWHXC8MeT", "number": 21094, "cdate": 1758313698591, "mdate": 1763747377366, "content": {"title": "One-step Optimal Transport via Regularized Distribution Matching Distillation", "abstract": "Unpaired domain translation remains a challenging task due to the need of finding a balance between faithfulness and realism. Diffusion-based methods for unpaired translation typically excel at realism, but require numerous inference steps and tend to offer suboptimal input-output alignment. Many of the optimal transport (OT) based methods, on the other hand, offer efficient few-step inference and reach superior input-output alignment, but heavily rely on adversarial training and inherit its shortcomings. In this paper, we propose a method called Regularized Distribution Matching Distillation (RDMD), which combines the best of both worlds. It replaces the adversarial training with diffusion-based distribution matching, addressing the typical shortcomings of OT methods and providing a strong initialization for the trained models. RDMD maintains the advantages of the OT methods by providing one-step inference and explicitly controlling the input-output faithfulness via regularization of the transport cost. We prove that in theory RDMD approximates the OT map and demonstrate its empirical performance on several tasks, including unpaired image-to-image translation in pixel and latent space and unpaired text detoxification. Empirical results show that RDMD achieves a comparable or better faithfulness-realism trade-off compared to the diffusion and OT-based baselines.", "tldr": "We propose RDMD: one-step optimal transport method that combines transport cost minimization with distribution matching and achieves comparable/superior faithfulness-realism trade-off compared to the baselines", "keywords": ["optimal transport", "unpaired translation", "image-to-image translation", "diffusion distillation"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/db2168d61925d10956d25a80101b66a6956de415.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Regularized Distribution Matching Distillation (RDMD) for unpaired image-to-image translation, adding a quadratic transport-cost regularizer to DMD to preserve input–output structural correspondence. RDMD enables one-step generation with a faithfulness–realism trade-off, showing competitive performance on multiple benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "-  The writing of the paper is clear and fluent.\n\n-  Applying DMD to efficiently tackle unpaired I2I translation is an interesting approach."}, "weaknesses": {"value": "- Limited resolution benchmarks. Experiments are restricted to low resolutions (64×64/128×128). It is unclear whether the approach scales to ≥ 256×256, where input–output alignment typically become more challenging.\n\n- Overly simple regularization. The transport-cost regularizer is instantiated as plain L2, which is often insufficient to enforce semantic correspondence between input and output. This choice may limit the method’s expressiveness under complex cross-domain shifts.\n\n- Have the authors considered using feature-level perceptual regularization[1] instead of pixel-space L2, for example by leveraging pretrained critics or reward models to better enforce semantic or structural details between the source and the one-step outputs?\n\n[1] Li M, Yang T, Kuang H, et al. Controlnet++: Improving conditional controls with efficient consistency feedback"}, "questions": {"value": "see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qk42Ut9NQW", "forum": "foWHXC8MeT", "replyto": "foWHXC8MeT", "signatures": ["ICLR.cc/2026/Conference/Submission21094/Reviewer_cLN3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21094/Reviewer_cLN3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21094/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761634069345, "cdate": 1761634069345, "tmdate": 1762941250105, "mdate": 1762941250105, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This manuscript proposes a novel unpaired translation method called RDMD. The method aims to address the limitations of existing approaches: diffusion models, while offering strong realism, are slow and have low faithfulness; Optimal Transport (OT) methods, while fast and faithful, rely heavily on unstable adversarial training. The core innovation of RDMD is replacing the adversarial loss with a stable, DMD, while explicitly adding a transport cost as a regularization term to ensure faithfulness. This design allows RDMD to leverage the strong prior of pre-trained diffusion models, achieve efficient one-step inference, and strike a better balance between realism and faithfulness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This manuscript proposes an unpaired translation method named RDMD, which is validated on both image and text tasks. The writing is relatively clear, the theoretical part is complete, and it provides some inspiration for the community in solving unpaired translation tasks."}, "weaknesses": {"value": "1. Figure 1 is shown, but it is neither mentioned nor described in the manuscript.\n\n2. The proposed method (Equation 9) introduces a \"fake\" diffusion model, $D_t^{\\phi}$, which reframes the training as a coordinate descent process involving both the generator $G_{\\theta}$ and this \"fake\" model $D_t^{\\phi}$. My concern is that this approach seemingly exchanges one form of complexity (the instability of adversarial training) for another (the complexity of jointly training two networks).\n\n3. There is a key contradiction between the paper's theoretical claims and its practical results. Theorem 3.1 states that the RDMD solution $G^{\\lambda}$ converges to the true Optimal Transport (OT) map $G^*$ only as $\\lambda \\to 0$. However, the empirical results (e.g., Figure 6) clearly show that the model performs poorly at $\\lambda = 0.0$ and achieves its best results at a non-zero $\\lambda$ (e.g., 0.2). This implies that the empirically optimal model is *not* the true OT map the theory focuses on. Could the authors please address this gap and clarify whether the asymptotic convergence (Theorem 3.1) is the true justification, or if the method is better understood as an empirically-tuned \"regularized DMD\" where the transport cost is simply a helpful, non-asymptotic, constraint?\n\n4. The authors selected the quadratic cost function $||x-y||^2$. They claim that in practice, any cost function of interest can be chosen. However, in the image translation experiments, only this single cost function was used. Are there any experiments with other cost functions? To my knowledge, pixel-level losses often lead to image blurriness. How would a perceptual cost (e.g., LPIPS) perform?\n\n5. Given the clear trade-off between FID (realism) and LPIPS (faithfulness) in the experiments (where one improves, the other often degrades), it is difficult to assert which method is \"better\" based solely on these two automatic metrics. Have the authors considered conducting a human evaluation? For example, presenting human evaluators with paired results from RDMD and the strongest baseline (e.g., DDIB) and asking them to score the outputs along the two dimensions of \"image realism\" and \"similarity to the original image.\""}, "questions": {"value": "See details in the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Ht5s2ZBdx6", "forum": "foWHXC8MeT", "replyto": "foWHXC8MeT", "signatures": ["ICLR.cc/2026/Conference/Submission21094/Reviewer_dJn6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21094/Reviewer_dJn6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21094/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761799408648, "cdate": 1761799408648, "tmdate": 1762941249475, "mdate": 1762941249475, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Regularized Distribution Matching Distillation (RDMD) for one-step unpaired image-to-image translation. The method builds on Distribution Matching Distillation (DMD) by introducing an optimal transport (OT)-motivated regularization that enforces source faithfulness during translation. Specifically, the generator is trained so that its outputs match the target distribution via DMD, while adding a source–target transport cost regularizer (implemented as a simple pixel-level L2 loss). The paper further provides a theoretical argument showing that the trained generator approximates a Monge OT map. Extensive experiments across a wide range of domains—multiple datasets, resolutions, pixel vs latent spaces, text conditions, and synthetic toy setups—demonstrate strong one-step translation performance and consistent generalization."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The manuscript is well written, with clear explanations and a well-designed experiment section. The range of datasets and conditions evaluated is notably broad, and the ablations are thoughtful. The appendix contains detailed implementation information, including training setups and dataset details, which makes the work meaningfully reproducible.\n2. Unpaired image translation is still a meaningful and relevant task, and the paper’s focus on improving one-step approaches within this setting is justified, and the comparisons against other one-step baselines are appropriate.\n3. At first glance, the modification relative to DMD—changing the regularization term from teacher–student to source–generator—could appear incremental. However, the authors provide a clear OT-based justification and a formal argument that the model approximates a Monge OT map. This theoretical framing substantially elevates the contribution beyond a simple loss engineering tweak.\n4. Achieving competitive translation quality in a single step, across multiple datasets and resolutions, and demonstrating Pareto-optimal trade-offs between fidelity and style, is compelling."}, "weaknesses": {"value": "1. Even with the introduction of latent space, the experiments are limited to 256 resolution, despite 512 being a commonly expected baseline in modern latent diffusion pipelines. I would like clarification on whether the method was unable to scale to higher resolutions in practice, and whether pixel-space training at 256 resolution was feasible or intentionally not pursued.\n2. Similar to DMD, three diffusion models (target, fake, and generator) must be loaded simultaneously during training, which imposes a heavy memory requirement.\n3. Training time appears nontrivial. For example, on AFHQ-64 the generator training alone takes approximately three additional days, which suggests that although inference is one-step, the overall training burden remains high."}, "questions": {"value": "1. Is the L2 loss applied in latent space (on the latent experiment)? If so, does this impact source fidelity due to mismatch between perceptual structure and latent geometry? Have you evaluated applying the regularization after decoding back into pixel space, and if so, did it improve or worsen perceptual source consistency?\n2. In Table 3, were the diffusion models also trained only on the same limited datasets, or were any pretrained on larger datasets? Clarification is necessary for fair comparison."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aaCBQWiqM7", "forum": "foWHXC8MeT", "replyto": "foWHXC8MeT", "signatures": ["ICLR.cc/2026/Conference/Submission21094/Reviewer_wb1N"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21094/Reviewer_wb1N"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21094/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761809246221, "cdate": 1761809246221, "tmdate": 1762941248852, "mdate": 1762941248852, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Regularized Distribution matching distillation for one-step image translation."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "It proposes simple and intuitive approach to include OT-based regularization into DMD in order to make one-step diffusion model for I2I."}, "weaknesses": {"value": "1. Although the paper proposes that GAN-based models are mostly superior to EGSDE, I am a bit suspicious on these statements. There are so many GAN-based Image translation methods such as StarGAN, StarGANv2, CUT, CycleGAN, etc. These methods show great FID score when it comes to AFHQ and CelebA-HQ. To clearly show the advantage of proposed one-step model, please include the GAN-based methods. Also, please show comparison output between recent zero-shot editing based methods (prompt-to-prompt, Nano Banana.. etc) for thorough evaluation.  \n\n2. Since the methods rely on DMD, the performance of I2I is limited on the teacher diffusion backbone. Also the DMD-based method requires additional network (fake teacher), the computation complexity and training time increases. Please show proper comaprison on this."}, "questions": {"value": "No"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lqXRJsEkMZ", "forum": "foWHXC8MeT", "replyto": "foWHXC8MeT", "signatures": ["ICLR.cc/2026/Conference/Submission21094/Reviewer_93vz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21094/Reviewer_93vz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21094/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761922523569, "cdate": 1761922523569, "tmdate": 1762941248219, "mdate": 1762941248219, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}