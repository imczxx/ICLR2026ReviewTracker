{"id": "eyC4tGF8mQ", "number": 22300, "cdate": 1758329323923, "mdate": 1759896873911, "content": {"title": "MISLEADER: Defending against Model Extraction with Ensembles of Distilled Models", "abstract": "Model extraction attacks aim to replicate the functionality of a black-box model through query access, threatening the intellectual property (IP) of machine-learning-as-a-service (MLaaS) providers. Defending against such attacks is challenging, as it must balance efficiency, robustness, and utility preservation in real-world scenarios. Despite recent advances, most existing defenses presume that attacker queries are out-of-distribution (OOD), enabling detection or disruption of suspicious inputs. However, this assumption is increasingly unreliable: modern models are trained on diverse datasets, and attackers often operate under limited query budgets. As a result, the effectiveness of these defenses is significantly compromised in realistic deployment settings. To address this gap, we propose MISLEADER (enseMbles of dIStiLled modEls Against moDel ExtRaction), a novel defense strategy that does not rely on OOD assumptions. MISLEADER formulates model protection as a bilevel optimization problem that simultaneously preserves predictive fidelity on benign inputs and reduces extractability by potential clone models. Our framework integrates data augmentation to simulate attacker queries and ensembles heterogeneous distilled models to enhance robustness and diversity. We further develop a tractable approximation algorithm and provide theoretical error bounds to characterize defense effectiveness. Extensive experiments across various settings validate the utility-preserving and extraction-resistant properties of our proposed defense strategy. Our code is available at https://anonymous.4open.science/r/misleader-B54B.", "tldr": "", "keywords": ["Model extraction defense", "ensemble methods", "machine-learning-as-a-service"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/450e0708baf9cb01653bb254500c82750357835a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces a defense against model extraction that employs an ensemble of defense models to replace the target model. These defense models are optimized using a bilevel objective that balances fidelity to the target with resistance to cloning. Theoretical analyses show when the proposed method is effective and where it may fall short. Experiments on MNIST and CIFAR-10/100 demonstrate lower clone accuracies and higher clean accuracy for the defended ensemble compared to several existing defenses."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Defending against model extraction without relying on OOD-query detection is practical in real-world scenarios.\n2. The optimization process is simple and intuitive to implement."}, "weaknesses": {"value": "1. Limited novelty: The core component, as the title suggests, to use an ensemble of models to defend against model extraction is similar to EDM [1]. While the authors claim to use data augmentation to approximate attacker queries, there is no analysis demonstrating that such augmentation truly approximates attacker queries. Moreover, the augmentation techniques used are standard practices in machine learning.\n2. Incorrect highlight: In Table 1, under the DFMS-HL attack on CIFAR-100 with the clone model ResNet18_8x, their method is not the best but is incorrectly highlighted as such. The table caption, “Overall, MISLEADER exhibits the best performance”, is therefore misleading.\n3. Inconsistent baselines: The authors compare their method with EDM [1] in the appendix, but EDM is not included in the main paper’s comparisons, making the evaluation incomplete.\n4. Lack of computational resource analysis: Training multiple attacker and defense models requires significantly more computational resources than other methods. A quantitative comparison of computational cost is necessary to assess practical feasibility, especially for larger images or datasets such as PASCAL.\n5. Minor typos: The paper uses the ICLR 2025 LaTeX template instead of the 2026 version. Additionally, in line 051, one reference is incorrectly marked with a “?” placeholder.\n\n[1] Sanjay Kariyappa, Atul Prakash, and Moinuddin K Qureshi. Protecting dnns from theft using an ensemble of diverse models. In International Conference on Learning Representations, 2021b."}, "questions": {"value": "Please refer to my concerns in the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AI6f1ahwiR", "forum": "eyC4tGF8mQ", "replyto": "eyC4tGF8mQ", "signatures": ["ICLR.cc/2026/Conference/Submission22300/Reviewer_mDAU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22300/Reviewer_mDAU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22300/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761489359268, "cdate": 1761489359268, "tmdate": 1762942159452, "mdate": 1762942159452, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MISLEADER, a novel framework for defending against model extraction attacks without assuming that attacker queries are out-of-distribution (OOD). The defense is formulated as a bilevel optimization problem that balances utility preservation (for benign users) and robustness against extraction. MISLEADER introduces three core ideas:\n\n1. Data augmentation-based proxy queries to simulate attacker behavior;\n2. Ensemble of heterogeneous distilled models to enhance robustness and prediction stability;\n3. Theoretical justification through generalization bounds (via Rademacher complexity) and Wasserstein-based analysis for data-free settings.\n\nExtensive experiments on MNIST, CIFAR-10, and CIFAR-100 show that MISLEADER achieves superior defense performance while maintaining high prediction utility compared to state-of-the-art baselines such as GRAD, MeCo, ACT, and DNF."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The bilevel/trilevel optimization framework is mathematically coherent and provides a principled way to handle both data-based and data-free extraction.\n2. The authors provide non-trivial theoretical analyses in Theorem 1 and Theorem 2 that connect defense performance with model capacity and distributional divergence.\n3. The experiments are extensive and well-controlled, with multiple datasets, attacker/defender architectures, and clear ablation studies. The proposed method consistently outperforms SOTA baselines by large margins in both DFME and DBME settings.\n4. Implementation details, hyperparameter ranges, and open-source code are well documented in the appendix, supporting transparency."}, "weaknesses": {"value": "1. While the integration of data augmentation, ensemble distillation, and bilevel optimization is elegant, each element individually is well-established. The conceptual leap feels incremental rather than groundbreaking. \n2. The authors are encouraged to further clarify how their proposed formulation aligns with or extends beyond the traditional OOD-based defense assumption.\n3. All experiments use image classification benchmarks; no exploration is done on NLP or tabular domains, which limits generalizability.\n4. Figures and algorithm boxes are dense, with limited explanation of intuition behind each step."}, "questions": {"value": "Overall, while the paper presents a comprehensive framework with comparably solid theoretical and empirical support, the level of innovation may be more suitable for a journal extension rather than a conference contribution, given its emphasis on system integration rather than a novel conceptual breakthrough."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "daOxOOxqEV", "forum": "eyC4tGF8mQ", "replyto": "eyC4tGF8mQ", "signatures": ["ICLR.cc/2026/Conference/Submission22300/Reviewer_GMs9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22300/Reviewer_GMs9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22300/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761532849500, "cdate": 1761532849500, "tmdate": 1762942159233, "mdate": 1762942159233, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper propose MISLEADER (enseMbles of dIStiLled modEls Against moDel ExtRaction), a unified and theoretically grounded defense framework for model extraction. MISLEADER uses a bilevel optimization problem to train a defense model that preserves accuracy for legitimate users while hindering an attacker’s ability to clone it. The framework employs data augmentation to simulate attacks and an ensemble of distilled models to increase robustness. Experiments show MISLEADER significantly reduces clone model accuracy across various datasets and attack types, outperforming state-of-the-art defenses while maintaining high utility."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.Focusing on a defense that is agnostic to the query distribution is a significant and timely contribution that aligns better with real-world MLaaS deployment scenarios.\n\n2.This paper evaluates against diverse baselines (RandP, P-poison, GRAD, MeCo, ACT, DNF) under both data-based (DBME) and data-free (DFME) attack settings, using both soft and hard labels.\n\n3.The paper is well written and clearly structured."}, "weaknesses": {"value": "1.This paper mentions the range and tuning of hyperparameters, but does not analyze the impact of hyperparameters on attack performance in detail.\n\n2.Training an ensemble of models via a bilevel optimization process is significantly more expensive than training a single model or applying a lightweight output perturbation. While the paper mentions parallel deployment, a more detailed discussion on the inference-time cost would be beneficial.\n\n3.While data augmentation is a key part of simulating attacker queries, this paper does not present a detailed ablation study on the specific choice of augmentations."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "h7Bz0kSKFD", "forum": "eyC4tGF8mQ", "replyto": "eyC4tGF8mQ", "signatures": ["ICLR.cc/2026/Conference/Submission22300/Reviewer_Lahy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22300/Reviewer_Lahy"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22300/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761807641921, "cdate": 1761807641921, "tmdate": 1762942159006, "mdate": 1762942159006, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MISLEADER, a defense mechanism against model extraction attacks. The authors target a key limitation of prior work: the reliance on an assumption that attacker queries originate from out-of-distribution (OOD) data. To address this, MISLEADER formulates the defense as a bilevel optimization problem, aiming to preserve utility on benign inputs while degrading extractability. The core of the proposed method involves using data augmentation to simulate attacker queries and deploying an ensemble of heterogeneous distilled models (e.g., ResNet, MobileNet) to increase the difficulty of cloning. The authors provide theoretical analysis for generalization and demonstrate strong empirical results, showing their method reduces clone model accuracy while maintaining or even improving utility on benchmarks like CIFAR-10/100."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Addresses a Valid Limitation: The paper clearly identifies a practical weakness in many existing model extraction defenses—their dependency on OOD detection. The goal of creating a defense that is robust to in-distribution queries is well-motivated from a security perspective.\n\n\n\nStrong Empirical Validation: The experimental evaluation is thorough within its defined scope. The authors compare MISLEADER against a wide array of SOTA baselines across multiple datasets (MNIST, CIFAR-10, CIFAR-100) and attack scenarios (DFME, DBME). The results consistently show that MISLEADER provides a stronger defense (lower clone accuracy) while preserving high utility.\n\n\n\n\n\nClarity: The paper is well-written and clearly structured. The proposed method, including the optimization algorithm and ensemble strategy, is explained well ."}, "weaknesses": {"value": "Significant Practicality Concerns (Overhead): The primary weakness of this paper is the practicality of the proposed solution. MISLEADER relies on an ensemble of heterogeneous models (e.g., ResNet18_8x, MobileNetV2, DenseNet121). While this architectural diversity is key to the defense, it introduces a massive computational overhead. Both training and—more critically—inference require running multiple distinct models for every single query . For a real-world MLaaS provider, where inference latency and cost are paramount, this solution is likely non-viable. The paper fails to adequately discuss or quantify this significant trade-off.\n\n\n\nDebatable Significance and Relevance: The paper's motivation rests on the assumption that model extraction of classic vision classifiers (like ResNets on CIFAR) is a high-priority threat for the ICLR community. This premise is questionable. The field's focus has largely shifted to large-scale generative models (LLMs, diffusion models), where the \"IP\" is more complex than just a set of weights for a classifier. The paper does not provide any discussion or evidence that its approach (bilevel optimization, heterogeneous ensembles) would scale to or is even relevant for these modern, high-value models. As such, the problem itself, while a classic security topic, may feel \"old-fashioned\" and of limited significance to the ICLR audience.\n\n\nLimited Novelty: The core components of the method—model ensembling for robustness, knowledge distillation , and data augmentation —are all very well-established techniques. While their combination to solve this specific OOD-agnostic defense problem is new, the work is more of an incremental, albeit effective, engineering combination rather than a fundamental conceptual breakthrough."}, "questions": {"value": "Overhead Analysis: Could the authors provide a concrete analysis of the inference-time overhead? Specifically, what is the increase in latency and computational cost (e.g., FLOPs) for a single prediction using MISLEADER compared to the \"undefended\" model and the other single-model defense baselines (like DNF or MeCo)? How can this significant cost be justified in a practical MLaaS deployment?\n\nScalability to Modern Architectures: The experiments are confined to small-scale vision classifiers. How is this approach expected to scale to models with billions of parameters, such as the LLMs that dominate today's MLaaS offerings? Is it feasible to train and run an ensemble of heterogeneous large-scale models, and is model extraction (as defined here) even the correct threat model for those generative systems?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "li54QYHPYO", "forum": "eyC4tGF8mQ", "replyto": "eyC4tGF8mQ", "signatures": ["ICLR.cc/2026/Conference/Submission22300/Reviewer_ddVX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22300/Reviewer_ddVX"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22300/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969141018, "cdate": 1761969141018, "tmdate": 1762942158706, "mdate": 1762942158706, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}