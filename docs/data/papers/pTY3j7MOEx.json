{"id": "pTY3j7MOEx", "number": 19361, "cdate": 1758295693112, "mdate": 1759897043201, "content": {"title": "Interpretable Classification via a Rule Network with Selective Logical Operators", "abstract": "We introduce the Rule Network with Selective Logical Operators (RNS), a novel neural architecture that employs \\textbf{selective logical operators} to adaptively choose between AND and OR operations at each neuron during training. Unlike existing approaches that rely on fixed architectural designs with predetermined logical operations, our selective logical operators treat weight parameters as hard selectors, enabling the network to automatically discover optimal logical structures while learning rules. The core innovation lies in our \\textbf{selective logical operators} implemented through specialized  Logic Selection Layers (LSLs) with adaptable AND/OR neurons, a Negation Layer for input negations, and a Normal Form Constraint (NFC) to streamline neuron connections. We demonstrate that this selective logical operator framework can be effectively optimized using adaptive gradient updates with the Straight-Through Estimator to overcome gradient vanishing challenges. Through extensive experiments on 13 datasets, RNS demonstrates superior classification performance, rule quality, and efficiency compared to 23 state-of-the-art baselines, showcasing the power of RNS in rule learning. Code and data are available at \\url{https://anonymous.4open.science/r/RNS_-4A67/}.", "tldr": "", "keywords": ["Interpretable", "Rule Network", "Classification", "Learnable Logical Operator Selection"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d1bbfaff466f5b8738b9855f385f69596b18db16.pdf", "supplementary_material": "/attachment/9e91b5fc06da236168530069796ee9785dc22559.zip"}, "replies": [{"content": {"summary": {"value": "RNS learns interpretable CNF/DNF rules via neurons selecting AND/OR, a Negation Layer, and a Normal Form Constraint. Using ±1 encoding with min/max and STE avoids vanishing gradients. Across 13 datasets vs 23 baselines, RNS improves accuracy, rule quality, and efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper’s motivation and writing are clear, and the methodology is well-reasoned.\n\n2. The results are competitive, and I believe this work is valuable to the differentiable rule learning community."}, "weaknesses": {"value": "1. Lack of discussion of [1]. I believe the paper may overstate the novelty of automatically selecting logic gates. The absence of discussion of this work is unacceptable.\n\n2. The baseline results are all taken directly from prior work, which is fine; however, I would like to see two additional baselines [2,3].\n\n[1] Petersen, Felix, et al. \"Deep differentiable logic gate networks.\" Advances in Neural Information Processing Systems 35 (2022): 2006-2018.\n\n[2] Yang, Lincen, and Matthijs van Leeuwen. \"Probabilistic Truly Unordered Rule Sets.\" arXiv preprint arXiv:2401.09918 (2024).\n\n[3] Qiao, Litao, Weijia Wang, and Bill Lin. \"Learning accurate and interpretable decision rule sets from neural networks.\" Proceedings of the AAAI conference on artificial intelligence. Vol. 35. No. 5. 2021."}, "questions": {"value": "On line 51 you list “non-learnable structural design” as a weakness, but doesn’t weight sparsification itself also change the final network structure? Don’t many differentiable rule-learning methods already support this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9x5D1HIkQ2", "forum": "pTY3j7MOEx", "replyto": "pTY3j7MOEx", "signatures": ["ICLR.cc/2026/Conference/Submission19361/Reviewer_Xjk9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19361/Reviewer_Xjk9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19361/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761139484687, "cdate": 1761139484687, "tmdate": 1762931296682, "mdate": 1762931296682, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work introduces **Rule Network with Selective Logical Operators (RNS)**, which is a novel architecture that can selectively learn whether an AND (/\\\\) or (OR) (\\\\/) should be placed between two feature variables when fitting a set of rules on a given data. This is achieved through 4 critical components: 1. two logical selection layers, 2. a negation layer, 3. Straight-Through Estimator for optimization, 4. normal form constraint to filter connections between neurons. Experiments show that RNS achieves competitive performance on various datasets when compared to SOTA methods. A few example learned rules were shown to support interpretability."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "S1: the architectural design proposed in this work is novel, aiming to allow flexible learning of logical rules by allowing each neuron to be either AND or OR gates.\n\nS2: the architectural itself is clear, interpretable, and simple enough that the responsibility of each component is very intuitive to the reader. It is surprising how lightweight this architecture is given the variety of tasks it can perform.\n\nS3: The proposed network was tested across many datasets (small and large), all showing comparative results to the interpretable and non-interpretable counterparts."}, "weaknesses": {"value": "W1: ambiguity -- in the writing, there are many confusing descriptions (which i will include detailed examples in the questions section)\n\nW2: over-claimed results -- it is claimed that RNS outperforms the selected baselines, however, from Table 1 and sec 4.3 it seems that the improvements are incremental: in Table 1, if we look at each column, we can find that (among the ones that RNS performs the best) the second-best method was only <1% below what RNS achieves, not mentioning that there are 2 datasets where RNS was not leading. In the comparison in sec 4.3 the highlighted differences also seem to be small (~2%). Given these results, I don't think it is supportive enough to claim that RNS **outperforms** SOTA methods. It is at most **comparative** to SOTA methods. The lowest average rank could only support that cross-dataset wise, RNS has the best overall performance.\n\nW3: poor presentation. There are multiple writing style/clarity issues which will be outlined in the Questions section. \n\nW4: In conclusion, it was not explained at all why and how future directions include recommendations and text applications. Why would RNS be beneficial to these applications? How can RNS be adapted to these domains?\n\nW5: scalability concerns -- Table 2 shows examples of learned rules, which are almost the same as the ground truth rules in the simulation. How scalable does this claim hold? If given hundreds/thousands of variables, will the quality still be that high?\n\nW6: if the architecture constraints on the output learned rules to be CNF or DNF anyways, why would we want to allow a free learning of AND/OR gates initially? This seems to contradicts the motivation of allowing flexible rules to be learned, which is a major contribution to distinguish this work from prior works."}, "questions": {"value": "It will be really helpful if the authors can give some more explanations on the following questions: \n\nQ1: The normal form constraints are claimed to guarantee that the learned rules are in either CNF or DNF. However, it is not very clear how it works: it was mentioned that only when the two operators are opposite would the connection weight $W^{ij}_{conn}$ be updated, but how was W initialized? In addition, in Figure 2 it was shown that some rules were cut out in \"Model interpretation\", does that mean the normal form guarantee will only happen at inference time (so another filtering after the rule is extracted from the network)? A minor note is that Figure 2 does not have any descriptive caption other than \"overall structure\". This is a style issue but it confuses the reader.\n\nQ2: a general question is that how were the input features obtained? some of the evaluated datasets are pictorial (e.g. fashion mnist), how were these data pre-processed before inputing to RNS? Did all baseline models use the same preprocessing? These should be discussed clearly in order to show the significance of the results (please kindly remind me if they were already discussed).\n\nQ3: Why was F1 scores computed on 13 datasets but rule quality metrics were only evaluated on 10 datasets? Which three datasets were dropped and why? Also, Figure 3 (d) only shows 9 datasets instead of 10.\n\nQ4: In Table 2, what does the \",\" stands for? Does RNS output a set of rules? or just one CNF/DNF? If the \",\" stands for \\\\/, why does the 4th row shows $x_1 \\vee \\neg x_2 \\vee \\neg x_3$ not $x_1 , \\neg x_2 ,  \\neg x_3$? \n\nQ5: seems like Figure 6 was not mentioned in the main text. Is the purpose of Figure 6 showing the learned rules for the real dataset?\n\nAlso it would be nice if the authors can clarify W6 above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "l6vCbBSL5v", "forum": "pTY3j7MOEx", "replyto": "pTY3j7MOEx", "signatures": ["ICLR.cc/2026/Conference/Submission19361/Reviewer_J98E"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19361/Reviewer_J98E"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19361/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761603888974, "cdate": 1761603888974, "tmdate": 1762931296291, "mdate": 1762931296291, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the Rule Network with Selective Logical Operators (RNS), a novel neural architecture designed for interpretable classification. The core innovation is the use of \"selective logical operators,\" which allow each neuron in two Logic Selection Layers (LSLs) to adaptively learn to be an AND or an OR gate during training. This is complemented by a Negation Layer for functional completeness and a Normal Form Constraint (NFC) to enforce a CNF/DNF structure and reduce the search space. The model is optimized using a Straight-Through Estimator (STE) and min/max activation functions, which the authors argue effectively mitigates the gradient vanishing problem prevalent in prior work like RRL. The paper presents extensive experiments on 13 datasets, demonstrating that RNS achieves state-of-the-art performance in classification accuracy, rule quality (diversity, coverage, accuracy), and training efficiency compared to 23 interpretable and non-interpretable baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. **Novel and Well-Motivated Contribution:** The idea of making the logical operator (AND/OR) at each neuron a learnable parameter is a significant and compelling advancement over existing rule-based neural networks that rely on fixed, pre-defined logical layers.\n\n2. **Comprehensive Technical Design:** The architecture addresses key challenges through:\n   - Selective Logical Operators using sign-based weights\n   - Negation Layer for functional completeness\n   - Effective gradient handling via ±1 encoding and min/max activations\n\n3. **Thorough Empirical Evaluation:** Extensive experiments evaluating both classification performance and rule quality metrics, including a simulation study showing ground-truth rule recovery."}, "weaknesses": {"value": "1. **Scalability and Computational Cost:** More detailed analysis needed comparing training/inference time and memory usage against simpler interpretable baselines.\n\n2. **Depth of the Architecture:** Discussion needed on potential and challenges of extending beyond two LSLs for more complex logical expressions.\n\n3. **Baseline Comparison for Rule Quality:** Rule quality analysis should include non-neural interpretable baselines beyond RRL.\n\n4. **Clarity on \"Naive Negation\":** The implementation of \"naive negation\" in RRL comparisons should be better explained."}, "questions": {"value": "1. For different seeds, are the extracted rules similar?\n2.If I read it correctly, the rule is single side which is if not class A then it is class B. Althought it is fully correct for tested dataset as binary classification, what if we apply your method to multi-class classification?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "WOuYYUs0T2", "forum": "pTY3j7MOEx", "replyto": "pTY3j7MOEx", "signatures": ["ICLR.cc/2026/Conference/Submission19361/Reviewer_MvR6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19361/Reviewer_MvR6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19361/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969542858, "cdate": 1761969542858, "tmdate": 1762931295865, "mdate": 1762931295865, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the Rule Network with Selective Logical Operators (RNS) for interpretable classification. Unlike previous neuro-symbolic approaches that rely on fixed logical operators (e.g., all neurons in a layer are AND operators), RNS features \"Logic Selection Layers\" (LSLs) where each neuron adaptively and dynamically chooses to function as either an AND or an OR operator.\nThe architecture is designed to be fully differentiable and trainable end-to-end, cleverly employing the Straight-Through Estimator (STE) to handle the discrete choices of operators and connections. Further, the model incorporates a Negation Layer for NOT operations and a Normal Form Constraint (NFC) to maintain the learned rules in CNF and DNF while reducing the computational complexity.\n\nThe extensive evaluation on 13 datasets (including both small and large scale ones) against 23 interpretable/non-interpretable baselines demonstrate that RNS not only achieves superior classification performance but also generates higher-quality, more concise, and more diverse rules."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Novelty in the neuro-symbolic research area: making the logical function of a neuron (AND vs. OR) a learnable parameter is a significant and elegant. This allows the model to discover more optimal and flexible logical structures. The combination of LSLs for operator selection, a Negation Layer for logical completeness, and the NFC for structural integrity is a coherent and complete design. \n\n2. The experiment results are strong and clear with both small and large datasets on enough baselines. Specifically, the learned rules are measured by diversity, coverage, and accuracy together, which is the good evidence to support the rules quality.\n\n3. The discussion on mitigating vanishing gradients for min/max functions is also a nice technical contribution."}, "weaknesses": {"value": "1. Only the rules from one dataset (bank-marketing dataset) in Figure 6 was reported. More results from other domain datasets could be added. Meanwhile, the justification of the rules are limited where only heuristic explanations are in Appendix I. For example, such rules could be verified by domain experts, or some common guidelines.\n\n2. The learned rules comparison with baselines in Table 2 is simple. Could the model generalized to more complex rules? For example, rules with larger chains/more clauses (e.g., $(x_1 AND x_2) OR (NOT x_1 AND x_3) OR (x_2 AND x_3) OR ...$).\n\n3. Lack of formal convergence on STE/min-max. Authors mentioned that \"using ±1 encoding and min/max logic, RNS preserves discrete interpretability while ensuring that gradient signals remain strong and informative\", and they give intuitive arguments and empirical results to support it. However, a convergence analysis would strengthen the paper.\n\n4. The implementation of the Normal Form Constraint (NFC) part in Section 3.5 is not clear. I am curious if this is a hard architectural constraint, a soft regularization penalty in the loss function, or something else."}, "questions": {"value": "1. If we use softmin/softmax compared with min/max, what is the difference? Meanwhile, can we add fuzzy logic to deal with noisy data?\n\n2. During training process, is there a convergence conflict between the learning of w_op (which determines the neuron's AND/OR) and the connection weights W_conn? Have you observed oscillations (nodes frequently switching between AND/OR in the later stages of training)? If so, how to stabilize it?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "NxjhG7qWJF", "forum": "pTY3j7MOEx", "replyto": "pTY3j7MOEx", "signatures": ["ICLR.cc/2026/Conference/Submission19361/Reviewer_mKDJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19361/Reviewer_mKDJ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19361/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988729092, "cdate": 1761988729092, "tmdate": 1762931295332, "mdate": 1762931295332, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}