{"id": "sJCs8mqPsY", "number": 8460, "cdate": 1758084830856, "mdate": 1759897782646, "content": {"title": "AFMCC: Asynchronous Federated Multi-modal Constrained Clustering", "abstract": "Federated multi-modality clustering (FedMMC) aims to cluster distributed multi-modal data without compromising privacy. Existing approaches often rely on contrastive learning (CL), but suffer from representation degeneration, arbitrary modality missing, and computational imbalance. We propose Asynchronous Federated Multi-modal Constrained Clustering (AFMCC), which tackles these challenges through three key designs: (i) a Class-Correlation Matrix (CCM) regularization to prevent CL degeneration and enhance cluster separability, (ii) client-specific weighted aggregation to handle modality heterogeneity, and (iii) a weighted asynchronous aggregation strategy to mitigate computational imbalance and accelerate convergence. We further provide a theoretical analysis of AFMCC through a particle dynamics lens. Extensive experiments on diverse benchmarks demonstrate that AFMCC consistently outperforms state-of-the-art FedMMC methods in clustering accuracy and efficiency, while preserving privacy. We have released the source code and the dataset as supplementary material.", "tldr": "This paper introduces AMCFC, an Asynchronous Multi-modal Constrained Federated Clustering framework designed to address challenges in multimodal clustering, including data heterogeneity, modality missingness.", "keywords": ["Federated clustering", "multimodal learning", "data heterogeneity", "modality missingness", "asynchronous"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7f32d992707890c78fd27c86aa490bb307b2df43.pdf", "supplementary_material": "/attachment/9ce7039fec553431b76c9e3b311a0c74a0966fe3.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses the issues of representation degradation, modality absence, and imbalance in federated multimodal clustering by proposing an asynchronous federated multimodal constrained clustering method, referred to as AFMCC. This method prevents representation degradation and enhances the separability of multimodal data clustering by calculating the Class-Correlation Matrix $Q$ between different categories and integrating it with the loss function of the target matrix $Q_{tgt}$. Additionally, the article designs a client-specific weighted aggregation approach to effectively handle the problem of modality absence. Experimental results from various benchmark tests demonstrate that AFMCC outperforms other methods in terms of performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper addresses the issues of modality absence and representation degradation in multimodal clustering, which holds significant research value.\n2. ﻿It also provides open-source code and datasets, offering strong support for community development."}, "weaknesses": {"value": "The innovation of this method is relatively limited. While the design of the Class-Correlation Matrix (CCM) is interesting, the calculation details of the target matrix are unclear. What is the specific process for calculating $Q_{tgt}$? What is the difference between $P_{ai}$ and $P$? Does the calculation of $Q$ require that all categories of data be present in each client or batch? Additionally, the design of the weighted aggregation has a high computational complexity, as it requires all other clients' models to compute features locally. Assigning higher weights to clients with poor cross-modal feature alignment appears unreasonable and requires further explanation. Furthermore, the design addressing asynchronous improvements appears lacking, making it difficult to effectively resolve issues related to client communication being asynchronous or clients going offline."}, "questions": {"value": "1. The details of the formulas in the article need further modification to improve readability. For example, the matrix $A$ in line 207, the calculation logic of $Q$ in line 248, and the definitions of $Q_{ab}$ and $I_K$ in line 253 are not sufficiently clear. These formulas require further explanation.\n2. This paper requires further clarification on how it addresses asynchronous aggregation and alleviates computational imbalance issues."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "o9e6Umgvzg", "forum": "sJCs8mqPsY", "replyto": "sJCs8mqPsY", "signatures": ["ICLR.cc/2026/Conference/Submission8460/Reviewer_ra9y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8460/Reviewer_ra9y"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8460/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761831061801, "cdate": 1761831061801, "tmdate": 1762920343777, "mdate": 1762920343777, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Misleading title"}, "comment": {"value": "The combination of contrastive learning with the class correlation constraint, client-specific weighted aggregation and the asynchronous update scheme feels well thought through, experiments on popular multi-view benchmarks look convincing on the standard clustering metrics. My main issue is that the author repeatedly frames the approach as federated multi modal clustering and motivates challenges like genuine modality heterogeneity and arbitrary modality missingness, but all of the experiments are actually on standard multi-view style benchmarks where the different channels are alternative feature views of the same underlying data rather than truly different modalities such as image plus text or image plus audio features etc. Because of that, the empirical results do not really validate the broader multimodal story that the title and introduction lean on. I think the work would be much stronger if the authors either explicitly stated that they use modality in the sense of view and toned down the multimodal claims, or added at least one experiment on genuinely heterogeneous modalities to back up the broader motivation."}}, "id": "EHXRll6PyU", "forum": "sJCs8mqPsY", "replyto": "sJCs8mqPsY", "signatures": ["~Oseremen_Iyamah1"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "~Oseremen_Iyamah1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8460/-/Public_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763081848670, "cdate": 1763081848670, "tmdate": 1763081848670, "mdate": 1763081848670, "parentInvitations": "ICLR.cc/2026/Conference/-/Public_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper explores a new insight about the reasons why contrastive learning fails in federated clustering, especially when different clients observe different modality subsets. To address this challenge, the authors introduce a new constraint mechanism to avoid clustering degeneration over time, as well as a new client-specific aggregation method."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "* Explaining contrastive learning in both probabilistic and particle view is interesting\n* Extensive baselines and benchmark datasets."}, "weaknesses": {"value": "* Confusing writing. Introduction and related work fail to clarify the motivation and the problem. It is unclear between federated multimodal learning and federated clustering from the authors’ writing.\n* Lack of motivation. It is unclear why we need to solve this problem. What is the difference between multimodal clustering in centralized and federated settings? What are the benefits of federated clustering?\n* Unclear problem formulation. What is $K$ in line 160, how to determine this number. Why do we enforce these clusters to be balanced, while in the standard settings, clusters can be various in size based on the data distribution.\n* Lack of literature review. Contrastive learning - based regularization is used commonly in multimodal learning with different variants[1,2], which are theoretically guaranteed. Why these regularizations can not handle the clustering tasks, since these regularizations are designed for clustering modalities implicitly to perform downstream tasks. The authors should expand their literature reviews to highlight their contributions.\n* Lack of contributions. The proposed method, while adding explanation and new insights about federated clustering, seems to be an improvement of FMCSC[3]. Empirically, Figure 3b shows that the constraint loss – one of main contributions – does not affect the performance significantly.\n\n[1] Nguyen et al., Learning Reconfigurable Representations for Multimodal Federated Learning with Missing Data, NeurIPS’25\n\n[2]  Nguyen et al., Fedmac: Tackling partial-modality missing in federated learning with cross modal aggregation and contrastive regularization. NCA’24\n\n[3] Chen et al., Bridging Gaps: Federated Multi-View Clustering in Heterogeneous Hybrid Views, NeurIPS’24"}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hw6EIuSz8M", "forum": "sJCs8mqPsY", "replyto": "sJCs8mqPsY", "signatures": ["ICLR.cc/2026/Conference/Submission8460/Reviewer_WJyL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8460/Reviewer_WJyL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8460/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761864956400, "cdate": 1761864956400, "tmdate": 1762920342873, "mdate": 1762920342873, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes AFMCC for federated multimodal unsupervised clustering with (i) a Class-Correlation Matrix (CCM) constraint that projects features into a pseudo-probability space and penalizes deviations from a relaxed target;(ii)a client-specific weighted aggregation, and (iii) asynchronous training to tolerate heterogeneous compute. Experiments on several benchmarks report ACC/NMI/ARI gains."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.Broad problem surface: the method tries to address degeneration in contrastive clustering, missing modalities, and client asynchrony in one framework.\n2.The experimental results are of excellent performance, leading in multiple indicators across various datasets."}, "weaknesses": {"value": "1.Limited novelty; heavy rebranding. The “particle-dynamics three-force” story largely repackages standard contrastive attraction/repulsion plus a global regularizer, and relies on strong approximations.\n2.Unrealistic core assumptions. The CCM derivation assumes equal class sizes and a known K (see the definition of Q and text around Eq. 4), with no robustness analysis under heavy class imbalance or unknown K—both common in FL.\n3.There is no reporting of wall-clock time, communication rounds, bandwidth, or staleness-vs-accuracy curves—so the claimed training-time reduction remains unsubstantiated."}, "questions": {"value": "1.What are the mathematical properties of aggregated weights? How are the weights of Equation (6) constructed from the deviation quantities?\n2. How does the CCM behave under long-tail and cross-client imbalance? Can you couple AFMCC with non-parametric clustering when K is unknown?\n3.Why is this algorithm effective and can it provide a more convincing theoretical proof."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "As mentioned above."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zledN1SBts", "forum": "sJCs8mqPsY", "replyto": "sJCs8mqPsY", "signatures": ["ICLR.cc/2026/Conference/Submission8460/Reviewer_vPCD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8460/Reviewer_vPCD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8460/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761922319186, "cdate": 1761922319186, "tmdate": 1762920342254, "mdate": 1762920342254, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents an asynchronous federated multi-modal constrained clustering, which adapts to scenarios with arbitrary missing modalities. This method directly fuses multimodal embeddings into a shared embedding by weighted aggregation. By introducing a class-correlation matrix, it alleviates the degradation of contrastive learning in multimodal clustering. Extensive experiments are performed and detailed theoretical analyses are provied."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-written, and the motivations of the work are clear;\n2. Theoretical analyses are solid;\n3. The overall design is reasonable."}, "weaknesses": {"value": "1. The introduction of the class-correlation matrix seems to be adopted by several works, which limits the novelty.;\n2. The main solution to the arbitrary modality missing problem is to aggregate view-specific embeddings with a calculated weight, which seems somewhat trivial.\n3. Experiments seem insufficient.\n4. Some texts in the figures are small."}, "questions": {"value": "1. Do the experiments consider the Non-iid distribution of data?\n2. Does the method (Section 3.2 in Page 5) require the equal distribution of samples in each cluster? In practice, the data distribution of each client might be highly different (i.e., the Non-IID issue). As a result, even with a loose constraint based on the class-correlation matrix, whether the equal distribution is reasonable in practice should be discussed.\n3. The problem statament sets the sample number of each client is $N$, which might not be proper and should be corrected."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "pLPbrcISW9", "forum": "sJCs8mqPsY", "replyto": "sJCs8mqPsY", "signatures": ["ICLR.cc/2026/Conference/Submission8460/Reviewer_G3Dk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8460/Reviewer_G3Dk"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8460/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990292764, "cdate": 1761990292764, "tmdate": 1762920341962, "mdate": 1762920341962, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}