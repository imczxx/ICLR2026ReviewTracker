{"id": "k2CKteHKZO", "number": 16972, "cdate": 1758270767411, "mdate": 1759897207004, "content": {"title": "Unified, Practical, and White-box Seismic Tomography with Automatic Differentiation", "abstract": "Seismic tomography methods are complex, diverse, and incompatible with each other.\nTraditional adjoint approaches are case-specific, requiring challenging analytical derivations for each set of parameters, waves, and loss functions.\nApproximating wave equation propagation with neural networks (NNs) remains impractical, since finite training datasets cannot cover all seismic parameters for the infinite number of possible geologic models.\nIn this paper, we propose a unified seismic tomography framework with automatic differentiation (AD) for gradient computation, avoiding analytical derivations and NN training.\nOur framework is designed for generalized misfit functionals and wave equations, supporting broader applications than previous AD-based studies.\nOur method is fully white-box, and AD gradients are proven to be equivalent to adjoint gradients theoretically and numerically.\nTo show its generality, we performed ten cross-scenario tests across domains (time/frequency), waves (acoustic/SH/P-SV/visco-acoustic/visco-elastic), and losses (waveform/travel time/amplitude).\nWe also evaluated our method on the OpenFWI benchmark dataset to compare with NN methods. \nPracticality was further demonstrated by a checkerboard test in the Nankai subduction zone, which is challenging for NN methods due to the lack of suitable training datasets.\nOur method avoids laborious derivation and implementation of adjoint methods, with only modest computational overhead (1.3–1.8 $\\times$ slower and 1.3–2.0 $\\times$ more memory without mini-batching or checkpointing in our tests), which can be further reduced with these standard optimizations.\nWe open-sourced a PyTorch-based platform with various extensible wave simulations and imaging methods, facilitating further developments.\nOur work illustrates AD's unifying capability in inverse problems, suggesting broader applications in allied scientific computing fields.", "tldr": "We present a unified, practical, white-box seismic imaging framework based on automatic differentiation, requiring no gradient derivations or neural network training.", "keywords": ["seismology", "automatic differentiation", "inverse problem", "seismic tomography"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d706c218d07c765c0ee4eeca1d78438fe265eb03.pdf", "supplementary_material": "/attachment/6531cade1bbfccc3dc438edc83f044c80541f8aa.zip"}, "replies": [{"content": {"summary": {"value": "Theoretically proves the equivalence of gradients between AD methods and \nadjoint methods under frequency domain and any misfit functions. Numerically, defends its argument by experiments on different PDEs and wave types."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. Extends AD methods to frequency domain with theoretical \njustifications and numerical results. Previous AD methods are mostly restricted\nto time domain for complexity reasons, while this work has a mathematical \nproof and has achived unified results between time and frequency domain over\ndifferent problems.\n\n2. Proofs and experiments are strong with clear explanations and straightforward\n diagrams.\n\n3.  Inversion problems are notoriously hard, but this work has demonstrated the\n potential of AD methods with strong evidences."}, "weaknesses": {"value": "Fails to demonstrate why diverse misfit functions are a difficulty. \n The challenges are neither discussed in mathematical deductions, nor further\n explained in experiments."}, "questions": {"value": "1. In the context of AD, is implementing diverse misfit functions too trivial to be a significant contribution of this paper? AD-based methods were invented at least 4 years ago (ADSeismic) and people may have already been well aware of its flexibility compared to adjoint methods. Hence implementing diverse misfit functions may not be a significant contribution. (Or there do exist some particularly difficult misfit functions, but this paper does not discuss them in detail.)\n\n2. Time domain methods are iteration based, and thus errors get maginified and divergence may happen. What is the time sample-rate  of the involved datasets? How do you address this problem?\nA pure time domain method, especially over hundreds of steps, may be extremely unstable. Your frequency-based method may be a possible and robust solution.\n\n3. How is the forward process of PDEs in frequency domain implemented? This might be worth mentioning since its not a trivial task."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Ebq1Dlurrt", "forum": "k2CKteHKZO", "replyto": "k2CKteHKZO", "signatures": ["ICLR.cc/2026/Conference/Submission16972/Reviewer_YP9p"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16972/Reviewer_YP9p"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16972/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760683790204, "cdate": 1760683790204, "tmdate": 1762926988751, "mdate": 1762926988751, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a framework for performing Full Waveform Inversion (FWI) through automatic differentiation (AD), implemented in PyTorch. Instead of deriving gradients via the traditional adjoint state method, the authors construct differentiable forward wavefield solvers and use PyTorch's AD mechanism to compute gradients of the loss. They theoretically and numerically demonstrate AD's effectiveness by proving that the gradients from AD are equivalent to those from the adjoint method. Then they demonstrate a few proof-of-concept inversions on synthetic and field examples."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. They theoretically and numerically demonstrate AD's effectiveness by proving that the gradients\nfrom AD are equivalent to those from the analytical adjoint method\n2. Potential engineering contribution for an open-source package for various differentiable forward operators."}, "weaknesses": {"value": "1. Unclear novelty and contribution. The paper does not propose a new FWI algorithm or learning method; it merely replaces the adjoint state gradient computation with PyTorch's automatic differentiation. Once the forward modeling is implemented in PyTorch, gradient computation follows directly from built-in autodiff; thus, the contribution is quite limited.\n\n2. Writing and presentation need improvement: 1) The target problem and motivation are not clearly expressed. 2) Jargon terms and mathematical notation are used without adequate definition. 3) The underlying physical concepts are not explained. 4) The optimization objective of FWI is never formally stated, i.e., only gradient computation is discussed, which makes the end goal ambiguous.\n\n3. Baseline results are not shown in the paper.\n\n4. As shown in Figure 4, the inversion starts from a relatively strong initial, which reduces the challenge and overstates the effectiveness of the approach."}, "questions": {"value": "Please refer to the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XhY7KtNKZ2", "forum": "k2CKteHKZO", "replyto": "k2CKteHKZO", "signatures": ["ICLR.cc/2026/Conference/Submission16972/Reviewer_4MRU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16972/Reviewer_4MRU"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16972/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761803254071, "cdate": 1761803254071, "tmdate": 1762926988215, "mdate": 1762926988215, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a unified framework for seismic tomography using automatic differentiation (AD) for gradient computation, aiming to avoid the manual derivation required by traditional adjoint methods. The authors claim their AD-based approach is theoretically and numerically equivalent to the adjoint method, supports a wide range of wave equations and misfit functions, and is practical for real-world scenarios. They provide a PyTorch-based open-source platform and validate their method across synthetic, benchmark, and field datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Unified Framework: The paper presents a generalizable approach that can handle various wave types, domains (time/frequency), and misfit functions, which is broader than previous AD-based works.\n2. Theoretical and Numerical Equivalence: The authors provide detailed proofs and numerical experiments showing that AD gradients match those from the adjoint method.\n3. Open-Source Implementation: The release of a PyTorch-based platform may benefit the community and facilitate further research.\nPractical Validation: The method is tested on synthetic models, the OpenFWI benchmark, and a field experiment, demonstrating applicability."}, "weaknesses": {"value": "1. Lack of Deep Insight or Novelty: The main contribution is the application of AD to seismic tomography, but this is not fundamentally new. The equivalence between AD and adjoint gradients is well-understood in the scientific computing community, and the paper itself cites prior works that have already used AD for integrating physics into inverse problems .\nThe theoretical proof of equivalence is a straightforward application of chain rule, which is standard in optimization and inverse problems.\nThe practical advantage (avoiding manual derivation) is incremental rather than transformative, as modern frameworks (e.g., PyTorch, JAX) already make AD accessible.\n2. Comparison to Conventional Gradient Computation:\nThe paper claims AD gradients are equivalent to adjoint gradients, which is correct. If AD does not match the conventional adjoint method, either implementation is wrong. This is a well-established fact in computational physics and inverse problems."}, "questions": {"value": "Beside the implementation and showing the equivalence of AD and conventional method, what else the main contribution of this paper? AD can handle different misfit functions, and practically we also observed the success of using misfit function beyond l2 loss, e.g., Unsupervised learning of full-waveform inversion: Connecting cnn and partial differential equation in citation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ehxXfLDme3", "forum": "k2CKteHKZO", "replyto": "k2CKteHKZO", "signatures": ["ICLR.cc/2026/Conference/Submission16972/Reviewer_7KA1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16972/Reviewer_7KA1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16972/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761928464458, "cdate": 1761928464458, "tmdate": 1762926987791, "mdate": 1762926987791, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed a unified framework for seismic tomography that leverages automatic differential (AD) to compute gradients. This framework works on a case-by-case basis and can be applied across both time and frequency domains with various wave types and diverse misfit functions. A theoretical proof is provided by the authors to demonstrate the equivalence of the gradients of their framework and adjoint methods. Experiments show the effectiveness of the framework across various scenarios. Furthermore, the authors performed a cost analysis and highlighted the advantages of their method."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-organized and easy to follow.\n2. The authors provided detailed proof to theoretically demonstrate the equivalence of the gradients of the proposed framework and adjoint methods.\n3. The experiments  covers 10 scenarios with different domains, wave types and misfit functions, offering a comprehensive evaluation that shows the effectiveness of the proposed framework.\n4. The authors evaluated their proposed framework on the public benchmark dataset OpenFWI, which makes the experiments more convincing. Besides, a field experiment is conducted to further illustrate its potential for real-world applications."}, "weaknesses": {"value": "1. The authors compared their proposed framework with adjoint method to show the advantages of AD. However, there also exist other methods that leverage AD such as Physics-Informed Neural Network (PINN), which also avoids analytical derivation. I think it is crucial to provide a comparison of the proposed framework and such methods. Otherwise, the novelty may be limited.\n2. In the experiment section, the author stated that there are two baselines (ADFWI and a Matlab-based visco-acoustic wave equation solver). However, the performance of these baselines are missing in the quantitative results.\n3. (MS-)SSIM is used as the only evaluation metric throughout the paper. The experiments would be more comprehensive if other metrics such as mean absolute error (MAE) and mean squired error (MSE) are reported. \n\nI would be willing to raise my rating if these issues are properly addressed."}, "questions": {"value": "1. The experiments of equivalence numerical validation in Section 4.1 are a little bit confusing. Could the authors further clarify the specific tasks being evaluated? \n2. According to the field experiment, noise is added to the observed data. What about the other scenarios? Did the authors also add noise to the measurements? Such experiments and others with missing traces can further demonstrate the robustness of the proposed method. \n3. For the experiments on OpenFWI, some follow-up studies reported better performance (e.g., [1]). The authors may also consider including a few of them as additional baselines. \n4. [Minor] The first three paragraphs in Section 3 discussed the advantages of AD and some related works. I think it might be more appropriate to move them to the introduction section or the related work section.\n5. [Minor] In Figure 2, there are too many equations with limited context, which may make it difficult for readers to understand the high-level idea. \n6. [Minor] The authors mentioned Gaussian filters had been used to generate the initial model. It would be clearer to specify the parameters of the filters rather than using terms such as “heavy” or “slightly”, \n\n[1] Jin, P., Feng, Y., Feng, S., Wang, H., Chen, Y., Consolvo, B., ... & Lin, Y. (2024). An empirical study of large-scale data-driven full waveform inversion. Scientific Reports, 14(1), 20034."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BdmOaj49T0", "forum": "k2CKteHKZO", "replyto": "k2CKteHKZO", "signatures": ["ICLR.cc/2026/Conference/Submission16972/Reviewer_13jS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16972/Reviewer_13jS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16972/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969974967, "cdate": 1761969974967, "tmdate": 1762926987441, "mdate": 1762926987441, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}