{"id": "60Vj3aBnjw", "number": 25482, "cdate": 1758368504335, "mdate": 1759896719359, "content": {"title": "Position-Aware Modeling for Next-Token Prediction", "abstract": "Next-token prediction (NTP) serves as the dominant training paradigm for large language models (LLMs), enabling strong autoregressive (AR) generation capabilities. Despite its success, models trained with vanilla NTP often exhibit counterintuitive failure patterns, such as the reversal curse, factorization curse, and sensitivity to knowledge position. These failures stem from the fixed left-to-right token order during teacher-forcing supervision, which entangle content and token order in ways that compromise permutation invariance. To address these failures, we introduce a position-aware training framework that enables AR models to predict the next token not just based on seen content, but also to account for predicted token position. This disentanglement of what to predict and where to predict improves the robustness of LLMs to different token orderings. We instantiate this framework via two complementary approaches: (1) Content-Position Coupling (CPC), which injects a lightweight position-aware embedding into the input sequence without modifying the model architecture; and (2) Content-Position Decoupling (CPD), which introduces the modular position-aware blocks for the pre-training AR model to provide explicit supervision over target positions. Experiments across three representative tasks demonstrate that our framework consistently improves performance over strong baselines, while maintaining architectural simplicity and convergence efficiency. Codes are available at {\\url{https://anonymous.4open.science/r/CPC-CPD}}.", "tldr": "", "keywords": ["Next-Token Prediction", "Large language models", "Position-aware"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/668dbccaa4698ef7d2734ce006f857e0db5b4d45.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper identifies the inherent sensitivity to token ordering in standard Next-Token Prediction (NTP) training as a root cause for several failure modes in LLMs, such as impaired planning and reasoning. The authors argue this sensitivity leads to issues like the reversal curse and knowledge position sensitivity. To address this, they propose a \"position-aware enhancement framework.\" This framework is designed to improve standard training by enabling the model to distinguish prediction targets based on both their content and their intended output position. The authors claim that this method significantly improves the model's robustness to variations in token order and allows smaller models to outperform larger-scale LMs on certain tasks."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "* The authors correctly identify that the strict left-to-right, autoregressive objective is linked to several well-documented failure modes in LLMs, including the reversal curse, the factorization curse, and sensitivity to the position of knowledge in the context. \n* Addressing this fundamental issue is a valuable research direction, and a successful solution would represent an important contribution to the field."}, "weaknesses": {"value": "The paper's central premise is to overcome the limitations of fixed left-to-right generation. However, it fails to cite or compare against a large and directly relevant body of work on any-order autoregressive models [1, 2, 3]. These methods are explicitly designed to break the left-to-right dependency structure in LLMs.\n\nIn general, the paper is poorly written and difficult to understand. The description of the method is vague and imprecise.\n\n- The paper claims \"teacher-forcing... is a problem in NTP\" (lines 68-69) and defines a standard MLE objective in Eq. 2, but it never clearly explains why teacher-forcing is the problem it aims to solve, nor how its method (which also appears to be a supervised objective) avoids this supposed problem.\n\n- The authors use highly informal language, such as the \"downside of potentially messing with the original token embedding\" (line 109), which is inappropriate for a scientific paper.\n\n- The paper introduces concepts like \"semantic representations learned during pre-training to drift\" (lines 269-271) without providing a clear definition of what this \"drift\" is, why it's a problem, or how the proposed 'CPD' mechanism resolves it.\n\n- Equation 3 is referred to as an \"objective\" (line 172), but it does not appear to be an objective function to be optimized.\n\nThese examples are not exhaustive; the entire method section is difficult to parse, and reading it carefully does not resolve the ambiguity.\n\n[1] Hoogeboom, Emiel, et al. \"Autoregressive diffusion models.\" arXiv preprint arXiv:2110.02037 (2021).\n\n[2] Shih, Andy, Dorsa Sadigh, and Stefano Ermon. \"Training and inference on any-order autoregressive models the right way.\" Advances in Neural Information Processing Systems 35 (2022): 2762-2775.\n\n[3] Pannatier, Arnaud, Evann Courdier, and François Fleuret. \"σ-gpts: A new approach to autoregressive models.\" Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Cham: Springer Nature Switzerland, 2024."}, "questions": {"value": "1. The paper states (lines 313-315) that the attention mask \"retains [the] left-to-right generation constraint in vanilla NTP.\" If generation at inference time is still strictly left-to-right, what is the effect of your position-aware training? How does the model's behavior at inference time differ from a standard autoregressive model?\n\n2. The proposed method appears to add extra parameters to the model. Is it possible that any observed performance gains are simply due to an increase in model capacity? Please provide a precise breakdown of the parameter overhead introduced by your method and include comparisons to baselines with a similar total parameter count.\n\n3. The authors use the term \"permutation-invariant language modeling\" (line 485). Language is inherently sequential and not permutation-invariant (e.g., \"dog bites man\" vs. \"man bites dog\"). What is meant by \"permutation-invariance\" in this context?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1tfJZTAUrX", "forum": "60Vj3aBnjw", "replyto": "60Vj3aBnjw", "signatures": ["ICLR.cc/2026/Conference/Submission25482/Reviewer_nPtM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25482/Reviewer_nPtM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25482/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761612548560, "cdate": 1761612548560, "tmdate": 1762943450243, "mdate": 1762943450243, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "LLM's are mainly trained in a teacher forced next token prediction setting. As a result the model mainly captures the entangled training distribution, and will not appropriately handle scenarios like token permutation, as they'd be required to be added to training datasets.\nThe authors therefore propose training some additional parameters to the attention mechanics, in order to disentangle token order."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- it is in principle a relevant field of research, e.g. making LLM's more reusable in different scenarios like those permutation settings"}, "weaknesses": {"value": "W1 the paper is unfortunately in its current form poorly written which already is not keeping the bar for this conference. there are plenty grammar issues and weird phrases in abstract and introduction. the figure 1 does not help at all (CPC looks like plain transformer) and the pseudo code is also not really presentable.\n\nW2 the permutation curse is only partially covered. yes, we have token permutation now, but this almost never exist in the language case, except for permutation of whole sentences, for which other approaches seem more plausible. (E.g. a reversed written word will end up in completely different sequence of tokens. if it was discussed i missed it, but it should be there!)  The TPM experiments , e.g. what kind of permutation was used in main text, are hard to follow, i.e. if they are comparable at all to what you do in CPC. Yes on graph or number shuffling it makes more sense, here it's unclear to me however, if its 'just your embedding technique' or if you trained the algorithm into that added attention mechanics.\n\nW3 you want 'minor modifications' - yet you afterall train positional embeddings and another crossattention which most likely renders the model useless on plain language when 'running in this mode'. if quick reusability/ exchangeability of deployed models is your goal i'd require an ablation against adapters etc."}, "questions": {"value": "none"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Rx1HpBxaIu", "forum": "60Vj3aBnjw", "replyto": "60Vj3aBnjw", "signatures": ["ICLR.cc/2026/Conference/Submission25482/Reviewer_Qq6w"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25482/Reviewer_Qq6w"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25482/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761831139410, "cdate": 1761831139410, "tmdate": 1762943449831, "mdate": 1762943449831, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper argues that current next-token prediction training paradigm could be improved to the proposed content-position coupling and content-position decoupling to improve modeling for positional informations. The key is to incorporate a ROPE embedding (as in equation (1)) into the next-token prediction training. Content-position coupling directly injects the rope embedding into the input IDs, while content-position decoupling uses an attention module to incorporate that. Through experiments on the reversal curse, factorization curse, and positional bias, this paper demonstrates the improvement of their methods over standard NTP."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The research question is intuitive on current failure modes of NTP training. The formulation is rigorous and the experiment results looks good to me. The code is provided for reproducibility."}, "weaknesses": {"value": "1. To be honest I still don't quite get why the core idea is working. Why is incorporating z_{τ_t} from equation (1) improving the current transformer architecture that is already considering positional embeddings such as RoPE? Is this work trying to make the RoPE positional embedding more explicit for NTP?\n\n2. Following 1, why does the proposed method improve performance on the reversal curse and factorization curse, which seems far from positional embeddings to me? In summary, I don't quite get the intuition why the proposed CPC and CPD work.\n\n3. I was looking for experiments on natural language modeling, but maybe I missed it. The experiment on Wiki2023+ is only about movie domain according to line 428. It is uncertain to me if CPD would harm NLP/reasoning performance and experiments are needed here. Optionally, the authors could explicitly note in this paper that though CPC/CPD gives SOTA performance on path planning, alg reasoning, etc., it is not tested yet if this method could actually be used to pretrain language models.\n\n4. When reading CPD, I was thinking about the additional attention cost (approximately double?) when letting CPD to run additional attention with the same length of sample. The cost for CPC should be minimal as it directly incorporate the RoPE embedding. Then, I found Table E1 in appendix, which is actually important and should be extended and move to the main pages (the main pages emphasize improvement but not cost).\n\nOn Table E1, first of all, I want to ask why CPC is not a minimal improvement over NTP but TPM? Is it because we need to generate many permuted samples? In that case, the novelty of CPC is weakened by the existence of TPM. Second, there should be some study comparing marginal cost & marginal performance gain of CPD for future reference whether CPD should be implemented or not in practice. (when performance of NTP is acceptable, there is no need to implement CPD for double cost).\n\n5. The evaluations are all on LLaMA models, which implements RoPE already to the best of my knowledge. It is uncertain if CPC/CPD are compatible with other positional encodings and other groups of LLMs.\n\nThis paper is a clear rejection at its current stage, as I was unable to grasp the core intuition behind why the proposed method works (which may partly be due to my own limitations). Given this uncertainty, it would be risky for me, a cautious reviewer, to recommend acceptance at this point. That said, the overall quality of the work appears promising, and several missing experiments could substantially strengthen the paper. I would be glad to revisit my evaluation and potentially raise my rating accordingly, even to acceptance during the rebuttal phase."}, "questions": {"value": "1. Could the authors illustrate more about how z_τt is different from Pos_Embed(τj) in equation (6)?\n\n2. In what scenarios do you think we should use CPC/CPD rather than NTP? (given that NTP is working pretty well now for training production LLMs)\n\n3. Is CPD using 1-layer attention or stacked layers of attention?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rqls2OSD5r", "forum": "60Vj3aBnjw", "replyto": "60Vj3aBnjw", "signatures": ["ICLR.cc/2026/Conference/Submission25482/Reviewer_trsa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25482/Reviewer_trsa"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25482/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761935013627, "cdate": 1761935013627, "tmdate": 1762943449613, "mdate": 1762943449613, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper identifies a single root cause for several well-known failure modes in Large Language Models (LLMs), such as the reversal curse, factorization curse, and knowledge position sensitivity. The authors argue that these issues stem from the standard Next-Token Prediction (NTP) training paradigm, where the fixed left-to-right token order entangles a token's content with its position. To solve this, they propose a position-aware training framework that explicitly disentangles these two aspects. By making the model aware of the intended position of the token it is predicting, it can learn more robust, permutation-invariant representations.\nThe core solution is to augment the training process by providing the model with explicit information about the target position of the token to be predicted. This is done through two complementary approaches:\n\n1. Content-Position Coupling (CPC): This is a simple, data-centric approach. A lightweight, learnable position-aware embedding is created for the target token's position. This embedding is then directly added to the input token embeddings before they are fed into the transformer. It requires no changes to the base model's architecture. The model implicitly learns to use this fused information to distinguish between different target positions.\n\n2. Content-Position Decoupling (CPD): This is a more modular, model-level approach. It adds auxiliary position-aware blocks on top of a pre-trained AR model. These blocks use a cross-attention mechanism where the Query is the target position embedding. The Key and Value are the hidden states from the base model. This design explicitly separates the positional query from the content, allowing for more flexible and explicit supervision."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Novelty: The paper provides a clear and unified explanation for several seemingly disparate LLM failures, tracing them back to the entanglement of content and position in NTP. Both proposed methods, CPC and CPD, are shown to be highly effective at mitigating these failures across a range of tasks, from synthetic benchmarks to real-world knowledge retrieval.\nSimplicity: CPC is extremely simple, requiring no changes to the model architecture, making it easy to implement. CPD is designed as a modular add-on, allowing it to be integrated with existing pre-trained models without requiring full retraining. This is a major practical advantage."}, "weaknesses": {"value": "Scope of Evaluation: The framework has not been tested on more complex symbolic reasoning tasks, where hierarchical structure is as important as sequential position."}, "questions": {"value": "How does this model compare on reasoning benchmarks where causality matters?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "iBT6XAeYkB", "forum": "60Vj3aBnjw", "replyto": "60Vj3aBnjw", "signatures": ["ICLR.cc/2026/Conference/Submission25482/Reviewer_pECw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25482/Reviewer_pECw"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25482/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977905966, "cdate": 1761977905966, "tmdate": 1762943449434, "mdate": 1762943449434, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}