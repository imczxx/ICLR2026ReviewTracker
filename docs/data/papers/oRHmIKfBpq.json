{"id": "oRHmIKfBpq", "number": 9134, "cdate": 1758112392457, "mdate": 1759897741590, "content": {"title": "Self-Improving Medical Visual Question Answering through Reasoning Trajectory Clustering", "abstract": "While large language models have shown promise in medical applications, their performance in medical visual question answering (VQA) remains limited by insufficient vision-language reasoning capabilities. We address this challenge through two complementary approaches. First, we generate high-quality reasoning annotations for existing medical VQA datasets using COMCTS algorithm. Second, we introduce a self-improvement framework that bootstraps model performance by learning from its own outputs, guided by a small set of high-quality reasoning samples. To optimize this self-improvement process, we propose a novel filtering mechanism based on reasoning trajectory K-medoids clustering, which employs Dynamic Time Warping (DTW) distances to select the most effective generated reasoning paths. Our comprehensive approach demonstrates significant improvements in medical VQA tasks. We release both the COMCTS-generated reasoning datasets and our code to support future research. Our code is available at https://anonymous.4open.science/r/SelfImproving-MedicalVQA-5507", "tldr": "We enhance medical VQA through COMCTS-generated reasoning annotations and a self-improvement framework that filters generated reasoning paths via DTW-based trajectory clustering.", "keywords": ["Medical visual question answering", "Reasoning trajectory clustering", "Self-improvement learning"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/59a01a5ccf3ab5d398241dffbf59306b60fee7d0.pdf", "supplementary_material": "/attachment/5627e689403f511596ef1baf8474d87eb9081fb8.zip"}, "replies": [{"content": {"summary": {"value": "The paper targets vision–language reasoning in medical VQA. It first augments existing medical VQA datasets with chain-of-thought rationales generated via COMCTS using Qwen2-VL-7B and Gemma-3-27B, with DeepSeek-R1 for rationale scoring. It then proposes a self-improvement framework: train on rationale-augmented data, infer on answer-only samples, and keep generations that match ground truth; further, it filters by comparing generated reasoning traces to original ones using K-medoids with DTW distance. The authors report gains and release code and rationale data."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The code is open-sourced.\n- The reasoning data over medical datasets might be valuable to the community."}, "weaknesses": {"value": "From my perspective, the current manuscript is more like an engineering report that composes existing methods: COMCTS + open-source LLMs (Qwen2-VL/Gemma-3/Deepseek-R1) + DTW-based K-medoids. The novelty might be limited and largely in the specific domain rather than a new learning principle. Additionally, it is unclear the improvement comes from more reasoning data or just more data."}, "questions": {"value": "## Baselines and more ablation studies\n1. There are several methods for bootstrapping reasoning in general LLMs: STaR, V-STaR. The authors should consider to compare with previous approaches. Additionally, I recommend the authors to clearly articulate the conceptual advance beyong combining COMCTS + DTW-based K-medoids.\n\n> L219-221: For image features, we use the facebook/dino-vits16 model (Caron et al., 2021), and for sentence representations, we use the all-MiniLM-L6-v2 model from Sentence Transformers\n\n2. Why DTW + K-medoids? Why dino-vits and MiniLM are chosen? Is there any ablation study? It might be better if the authors could justify these choices with sensitivity analyses (different hyper-parameters, alternative distances, alternative clustering). \n\n2.1 Does self-consistency majority vote work here?\n\n3. Do DTW distances actually correlate with human-rated rationale quality in medical research?\n\n## Reliance on LLM\n4. It seems that the construction of reasoning datasets relys on LLMs generally. Is there any hallucination? Are the reasoning traces verified by medical experts?\n\n5. The authors should report prompts, calibration, and exact rules; quantify false accepts/rejects. Additionally, is there any leakage risk if the judge saw the same datasets during pretraining?\n\n## Experiments\n\n6. Mean accuracy moves from 39.57 -> 40.59 . \n\n    6.1 Is this (less than 3% improvement) signifcant?\n\n    6.2 How to distinguish the performance improvement from more data / more reasoning traces? The authors should provide more explanations. Additionally, the authors should provide more details about confidence intervals, multiple seeds, and standardized compute.\n\n> Table 2: We report sentence-level BLEU-1 scores\n\n7. Is BLEU-1 suitable for short or medical VQA answers? The authors should include per-type breakdowns (yes/no vs open-ended), and clinical-error criticality analysis.\n\n8. Report training/inference budgets for COMCTS, judge calls, and clustering; provide full prompts and code to reproduce DTW pipelines and clustering seeds; quantify cost vs. accuracy trade-offs. It might be better if the authors could model how performance scales with the amount of COMCTS data.\n\n## Typos\n\nTypos: Figure 3, \"the reasining dataset\" -> Should be reasoning\n\nIt seems that there is not any figure caption for Figure L141 - L158."}, "flag_for_ethics_review": {"value": ["Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "details_of_ethics_concerns": {"value": "Medical reasoning data"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "b8xK8wOhW0", "forum": "oRHmIKfBpq", "replyto": "oRHmIKfBpq", "signatures": ["ICLR.cc/2026/Conference/Submission9134/Reviewer_Cb2n"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9134/Reviewer_Cb2n"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9134/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761193026447, "cdate": 1761193026447, "tmdate": 1762920825383, "mdate": 1762920825383, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles the limited reasoning capabilities of medical visual question answering (VQA) models by combining rationale generation via COMCTS with a self-improvement pipeline.\n\nIt first builds a rationale-augmented dataset using strong external VLMs (Gemma-3-27B, Qwen2-VL-7B) and an LLM judge (DeepSeek-R1), then bootstraps a smaller model by learning from its own generated rationales.\n\nA key novelty is filtering self-generated samples using K-medoids clustering over reasoning trajectories, with DTW distances computed from image and sentence embeddings to retain high-quality, on-distribution chains of thought.\n\nExperiments across VQA-RAD, SLAKE, PathVQA, PMC-VQA, and OmniMed-VQA show consistent average gains over baselines, with the CA+CL filter outperforming correctness-only filtering in both accuracy and BLEU-1."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Originality: Introducing trajectory-level filtering with K-medoids + DTW for rationale selection in medical VQA is novel and complementary to correctness-based filtering. Leveraging COMCTS to seed high-quality rationales in a low-rationale domain is a creative adaptation of recent reasoning-generation methods.\n\nQuality: The pipeline is clearly modular (dataset construction, self-improvement, filtering, SFT), with ablations across Mbase, Mreas, MSI-ca, and MSI-ca+cl demonstrating incremental benefits. Use of both accuracy and BLEU-1 offers a more nuanced view for short-form answers typical in medical VQA.\n\nClarity and significance: The method and algorithms are described with sufficient detail (feature extraction, DTW definition, clustering procedure), and figures illustrate the workflow. Given the scarcity of rationale-rich medical data, releasing COMCTS-generated rationales and code could materially benefit the community."}, "weaknesses": {"value": "Limited scale and generality: Due to computational constraints, the study uses restricted subsets of datasets and a fixed K=10 with p=0.2 pruning, which may limit external validity and sensitivity analysis. More thorough scaling experiments and hyperparameter sweeps (K, p, embedding backbones) would strengthen claims.\n\nDependency on external LLMs/VLMs: The approach relies on stronger proprietary/open models (DeepSeek-R1, Gemma-3-27B, Qwen2-VL-7B) for both generation and judging, raising cost and reproducibility concerns. A discussion of budget, latency, and access constraints, plus open-source alternatives or lighter judges, would be helpful.\n\nEvaluation breadth: While average gains are reported, some per-dataset/model combinations regress (e.g., PathVQA, PMC-VQA in accuracy for certain backbones), and clinical robustness is not assessed. More granular analysis of error types, reasoning faithfulness, and safety/clinical relevance would improve the evaluation."}, "questions": {"value": "How sensitive are the results to the choice of sentence/image encoders and to K and pruning fraction p in K-medoids, and could adaptive clustering (e.g., silhouette- or density-based) yield better filtering?\n\nCan you quantify the end-to-end compute and API cost of COMCTS generation, answer verification, and clustering, and provide guidance for practitioners with constrained budgets?\n\nDo DTW-cluster outliers ever correspond to valid but novel reasoning paths, and if so, could you add a controlled experiment that preserves a subset of outliers to test for creativity vs. noise?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "v4QcQE0faA", "forum": "oRHmIKfBpq", "replyto": "oRHmIKfBpq", "signatures": ["ICLR.cc/2026/Conference/Submission9134/Reviewer_oKTs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9134/Reviewer_oKTs"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9134/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761437267257, "cdate": 1761437267257, "tmdate": 1762920824632, "mdate": 1762920824632, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of limited reasoning capabilities in medical Visual Question Answering (VQA) by proposing a self-improvement framework. The core of the method involves two stages: first, generating reasoning trajectories for existing medical VQA datasets using the off-the-shelf COMCTS algorithm; second, using a model trained on this data to generate more reasoning samples on unlabeled data, which are then filtered based on answer correctness and a novel clustering of reasoning trajectories using K-medoids and Dynamic Time Warping (DTW). The filtered data is used to further train the model. Experiments on five medical VQA datasets show that the proposed filtering strategy can lead to performance improvements over baselines in terms of accuracy and BLEU-1 scores."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. Practical Problem Focus: The work tackles a genuine and important problem in medical VQA: the scarcity of high-quality, rationale-augmented datasets. The effort to generate and release such a dataset is a positive contribution to the community.\n2. Comprehensive Evaluation: The evaluation is conducted across multiple established medical VQA datasets (VQA-RAD, Slake, etc.), which adds credibility to the claimed improvements. The use of both exact-match accuracy and BLEU-1 provides a more nuanced view of model performance."}, "weaknesses": {"value": "1. Significant Issues with Motivation and Narrative:\n\nThe introduction and related work sections fail to build a compelling narrative. They do not sufficiently clarify the specific limitations of existing medical VQA models and datasets to motivate the need for this particular self-improvement approach. The transition from the general problem to the proposed solution feels abrupt.\n\nThe motivation for using reasoning trajectory clustering is particularly weak. The paper lacks a clear, intuitive explanation or preliminary analysis showing that \"high-quality\" reasoning paths naturally form clusters in the trajectory space, and that noisy paths are outliers. This makes the core filtering mechanism seem like an ad-hoc choice rather than a well-motivated design.\n\n2. Limited Methodological Novelty:\n\nThe foundational step of generating reasoning data relies entirely on the COMCTS algorithm, which is not an original contribution of this work. While its application to medical VQA is valid, it sets the baseline for the paper's novelty.\nThe clustering-based filtering, while novel in this specific context, is presented without strong justification. The idea of filtering data based on feature similarity is well-established. The specific use of DTW on reasoning sequences is interesting but feels incremental without a deeper analysis of why this is the right metric for reasoning quality in medical VQA, or a comparison to simpler semantic similarity measures.\n\n3. Incomplete and Potentially Unreliable Experimental Setup:\n\nAs correctly pointed out, the experiments are conducted on random subsets of the original datasets due to computational constraints. This raises serious concerns about the statistical significance and generalizability of the results. The performance on such small subsets may not reflect the true performance on the full datasets.\n\nThe results are reported from a single run. Given the randomness in subset selection, model initialization, and the stochastic nature of training, the reported improvements could be due to chance. The community standard for claiming a meaningful improvement is to report the mean and standard deviation across multiple random seeds. The absence of this undermines the credibility of the conclusions.\n\nThe performance gains, while positive on average, are inconsistent across datasets and models (e.g., performance drops in several cases for Path-VQA and PMC-VQA). This inconsistency is not adequately discussed or analyzed, leaving the reader uncertain about the method's robustness."}, "questions": {"value": "The reasoning trajectory sequence is defined as $S=(r_0,r_1,…,r_m)$, where $r_0$ is solely the image feature. However, the entire reasoning process is driven and constrained by the \"question\". Could the authors clarify how the textual information of the question is incorporated into the similarity calculation of these trajectories? If the question features are indeed absent, please justify this design choice, as different questions for the same image should lead to distinct reasoning paths. Neglecting the question may fundamentally undermine the DTW-based clustering approach"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "plPaNjxKV7", "forum": "oRHmIKfBpq", "replyto": "oRHmIKfBpq", "signatures": ["ICLR.cc/2026/Conference/Submission9134/Reviewer_NuXQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9134/Reviewer_NuXQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9134/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761808315064, "cdate": 1761808315064, "tmdate": 1762920824164, "mdate": 1762920824164, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper fails to adhere to the ICLR author guidelines, most notably by not providing references for the cited literature.\n\nThe paper lacks sufficient details regarding the experimental procedures conducted on the VQA-RAD, Slake-VQA, Path-VQA, and PMC-VQA datasets.\n\nThe reported accuracy is significantly lower than that in other studies; however, the reviewer cannot fairly compare these metrics because insufficient information is provided."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Same as summary"}, "weaknesses": {"value": "Same as summary"}, "questions": {"value": "Same as summary"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "acVnM5bfwG", "forum": "oRHmIKfBpq", "replyto": "oRHmIKfBpq", "signatures": ["ICLR.cc/2026/Conference/Submission9134/Reviewer_RKb5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9134/Reviewer_RKb5"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9134/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761847040516, "cdate": 1761847040516, "tmdate": 1762920823766, "mdate": 1762920823766, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}