{"id": "UMZqvCvnnX", "number": 5374, "cdate": 1757905166987, "mdate": 1759897979236, "content": {"title": "Exploring System-1 and System-2 Communication for Latent Reasoning in LLMs", "abstract": "Should LLM reasoning live in a separate coprocessor, or within a single model that uses the same forward pass and representational space? We study dual-architecture latent reasoning, where a fluent Base exchanges latent messages with a Coprocessor, and test two hypotheses aimed at improving latent communication over Liu et al. (2024b): (H1) increase channel capacity; (H2) learn communication via joint finetuning. Under matched latent-token budgets on GPT-2 and Qwen-3, H2 is consistently strongest while H1 yields modest gains. A unified soft-embedding baseline—a single model with the same forward pass and shared representations, using the same latent-token budget—nearly matches H2 and surpasses H1, suggesting current dual designs mostly add compute rather than qualitatively improving reasoning. Across GSM8K, ProsQA, and a Countdown stress test with increasing branching factor, scaling the latent-token budget beyond small values fails to improve robustness. Latent analyses show overlapping subspaces with limited specialization, consistent with weak reasoning gains. We conclude dual-model latent reasoning remains promising in principle, but likely requires objectives and communication mechanisms that explicitly shape latent spaces for algorithmic planning.", "tldr": "We explore dual-architecture latent reasoning—separating a Base from a Coprocessor (Liu et al. + two communication variants)—to see if it yields genuine reasoning; in our tests, current designs mostly buy extra compute, not robust reasoning", "keywords": ["LLMs", "Latent reasoning", "Cache augmentation", "Latent communication"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2fd5400c30d6afb342ab0aa5cf4446f0c2940ad0.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper revisits dual-architecture latent reasoning for large language models (LLMs), where a “Base” model exchanges latent messages with a “Coprocessor.” It proposes two hypotheses to improve cross-module communication: (H1) augmenting KV-cache communication in a frozen Base and (H2) co-finetuning both models jointly."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* **Clear motivation and structure**: The paper clearly frames the problem as evaluating and improving communication between “System-1” (Base) and “System-2” (Coprocessor) reasoning modules.\n\n* **Rigorous experimental baselines and fair token budgeting**: The authors control for latent-token and data budgets and include both continued pretraining and soft-embedding baselines, which exposes when dual architectures add redundant capacity.\n\n* **Comprehensive interpretability analysis**: The cross-capture and silhouette diagnostics offer rare quantitative insight into latent redundancy."}, "weaknesses": {"value": "* **Limited empirical scope and scale**: Experiments are restricted to GPT-2 (124 M) and Qwen-3 (0.6 B) models with modest token budgets. The findings might not generalize to larger LLMs (≥ 7 B parameters) where representational capacity and KV-cache dynamics differ significantly.\n\n* **Unclear evidence for emergent reasoning**: The paper’s conclusions rest on negative results (flat scaling on GSM8K/Countdown), but it lacks task diversity to confirm that the observed redundancy is a general property rather than a dataset artifact.\n\n* **Theoretical contribution remains descriptive**: While the dual-system framing is conceptually appealing, the paper contributes little formal theory or training objectives to explain why latent specialization fails to emerge.\n\n* **Potential training mismatch**: The authors note that pretraining and curriculum finetuning conflict, but do not analyze how or why this mismatch arises, leaving uncertainty about whether the issue is architectural or procedural.\n\n* **Limited methodological advancement**: This paper primarily builds upon an existing dual-module paradigm and explores a few minor variants of it, using empirical experiments to compare their relative strengths and distinctive properties. While such exploration can offer useful insights for future research, the methodological innovation presented here remains limited."}, "questions": {"value": "* **Alternative latent objectives**: Have you tried explicit decorrelation or orthogonality regularizers to encourage latent specialization, or contrastive losses to diversify Coprocessor representations?\n\n* **Ablation of communication depth**: For Hypothesis 1, have you examined partial-layer cache concatenation (e.g., top-k layers only) to see if selective coupling can balance compute and communication efficiency?\n\n* **Cross-task generalization**: Could you include additional reasoning benchmarks (e.g., MATH, SVAMP) to test whether the “redundant latents” phenomenon persists across reasoning domains?\n\n* Can you further elaborate on how the findings presented in this work concretely support or inspire the two promising directions mentioned at the end of the paper?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xgHcG2MyU0", "forum": "UMZqvCvnnX", "replyto": "UMZqvCvnnX", "signatures": ["ICLR.cc/2026/Conference/Submission5374/Reviewer_Pkeg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5374/Reviewer_Pkeg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5374/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760716562055, "cdate": 1760716562055, "tmdate": 1762918029052, "mdate": 1762918029052, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tests dual-model latent reasoning where a Base LLM exchanges “thought” tokens with a Coprocessor. Of two upgrades over Liu et al. (2024), H2 (joint finetuning) beats H1 (KV-cache concat with frozen Base)—but a single-model soft-embedding baseline with the same latent budget nearly matches H2 and surpasses H1, suggesting the dual setup mostly adds compute, not better reasoning."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper poses clear, falsifiable hypotheses about cross-module communication in dual-model latent reasoning.\n\n2. The evaluation in the paper matches latent budgets across methods and adds a strong single-model soft-embedding baseline for fair comparison.\n\n3. The proposed three-pass training protocol reduces shortcutting and clarifies where gains originate."}, "weaknesses": {"value": "1. The paper’s motivation feels underdeveloped. The work is framed as improving the KV-Coprocessor within its own paradigm, but the generality and adoption of KV-Coprocessor remain unsettled, making this study read more like a targeted extension of that framework than a standalone contribution.\n\n2. The dual-model setups introduce additional trainable components relative to the soft-embedding baseline, leaving open whether observed gains stem from architectural choices or simply extra capacity/compute.\n\n3. The ablation of the each component of the proposed structure is missing in the current work.\n\n4. The KV-concat pathway (H1) may be sensitive to sequence length or attention scaling, yet length-generalization tests are absent, leaving robustness claims underexplored."}, "questions": {"value": "See the weaknesses part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VxHt9mMvwC", "forum": "UMZqvCvnnX", "replyto": "UMZqvCvnnX", "signatures": ["ICLR.cc/2026/Conference/Submission5374/Reviewer_2Jz5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5374/Reviewer_2Jz5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5374/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761699546163, "cdate": 1761699546163, "tmdate": 1762918028798, "mdate": 1762918028798, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies dual-architecture latent reasoning, which contains a base model and a coprocessor. The authors tested two hypotheses aimed at improving latent communication compared to a previous work [1]. The evaluation of the two hypotheses suggests that the current dual designs mostly add computation rather than improving reasoning, which is supported by the marginal gain on GSM8k, ProsQA, and the countdown stress test dataset by scaling the latent-token budget beyond small values, and overlapping spaces in latent analysis. \n\n**References:**\n\n[1] Liu, Luyang, Jonas Pfeiffer, Jiaxing Wu, Jun Xie, and Arthur Szlam. \"Deliberation in latent space via differentiable cache augmentation.\" arXiv preprint arXiv:2412.17747 (2024)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper studies an important and interesting question: whether the dual model really benefits reasoning by effective communication, or whether it merely adds computation (even in an inefficient way)?\n\n2. The paper conducts a more careful analysis of a previous work, which uncovers interesting results, such as using a single model can achieve similar performance gain as the dual system."}, "weaknesses": {"value": "1. The major concern is that the scope of this paper might be a bit narrow. The conclusion that the current dual system for latent reasoning is not efficient is based on the analysis of one previous work, which makes the conclusion not fully convincing or solid. The contribution is also limited, since the paper did not propose effective methods to mitigate it.\n\n2. The definition of the whole process can be more precise. Many refer to Liu et al. (2024b), but it would be more helpful for readers unfamiliar with the work to provide the mathematical formulations in greater detail.\n\n3. The flow of the paper could be improved for reading. Some sentences are not very coherent within the context, and some seem broken.\n\n4. “A single forward pass could allow the Base model to shortcut … defeating the purpose of the technique.” Although this might make sense, I think there should be some evidence, even if it is indirect."}, "questions": {"value": "1. What does the ahead token N_A mean? Is it defined anywhere in the paper? For the latent augmentation, what does M refer to (i.e., what is the difference between multiple augmentations for the same sequence)\n\n2. On page 6, the authors mentioned, “A single LLM with the same aggregate parameter count would almost certainly do better.” But the result for Qwen3 benchmarks shows “Dual models fare better: Hyp. 1 +6.5 pp (47.2 vs. 40.7%); Hyp. 2 +8.7 pp (49.4%).”. Am I missing anything?\n\n3. In diagnostic 1 (line 397), what does $n\\_i$ mean?\n\n4. For diagnostic 1, I wonder what the typical dimension of $P\\_i$ is. If $P\\_i$ is close to the identity matrix, then $H\\_{ij}$ should always be very high."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "a9C7lGOwXF", "forum": "UMZqvCvnnX", "replyto": "UMZqvCvnnX", "signatures": ["ICLR.cc/2026/Conference/Submission5374/Reviewer_pnWg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5374/Reviewer_pnWg"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5374/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761878670969, "cdate": 1761878670969, "tmdate": 1762918028539, "mdate": 1762918028539, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper examines dual-architecture latent reasoning where a Base model exchanges latent messages with a Coprocessor to improve reasoning capabilities. The authors test two hypotheses to strengthen communication over existing work - increasing channel capacity via cache augmentation and learning communication through joint finetuning - but find that a simpler soft-embedding baseline nearly matches the best dual-model variant, suggesting the approach mostly adds compute rather than enabling qualitatively better reasoning."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The paper provides a thorough empirical evaluation across multiple model sizes (GPT-2, Qwen-3) and tasks with proper baselines, which is refreshing. The interpretability analysis using cross-capture heatmaps and silhouette scores to examine latent specialization is insightful and reveals that latents tend to occupy overlapping subspaces rather than specializing. The three-pass training implementation cleanly separates latent computation from next-token prediction, avoiding potential shortcuts."}, "weaknesses": {"value": "The wrting is bad. \nThe negative results, while honestly reported, limit the impact .. the dual-model architecture doesn't deliver on its promise of System-2 reasoning. The soft-embedding baseline performs nearly as well with half the parameters, which undermines the main architectural contribution. The experiments are limited to smaller models due to compute constraints, and it's unclear if findings generalize to larger scales where the original work showed stronger results."}, "questions": {"value": "Have you tried other communication mechanisms beyond cache augmentation, like attention-based message passing between modules?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "n/a"}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "P8a9hCy7uf", "forum": "UMZqvCvnnX", "replyto": "UMZqvCvnnX", "signatures": ["ICLR.cc/2026/Conference/Submission5374/Reviewer_x3BX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5374/Reviewer_x3BX"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5374/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762034919275, "cdate": 1762034919275, "tmdate": 1762918028253, "mdate": 1762918028253, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}