{"id": "QNcrdCKNa5", "number": 16194, "cdate": 1758261347981, "mdate": 1759897255263, "content": {"title": "TopoScorer: a light, interpretable predictor for protein-protein binding affinity", "abstract": "Protein-protein binding affinity underlies complex stability, selectivity, and therapeutic action, yet experimental measurement is low-throughput and existing deep learning based approaches lack interpretability and a differentiable path from affinity back to the interface. We present TopoScorer, a lightweight, interpretable, end-to-end–trainable affinity scorer that can act as a loss or reward to steer generative and discriminative protein models; across protein and mutation affinity benchmarks, it delivers performance comparable to state-of-the-art methods and, when integrated into a modern antibody-design workflow, improves affinity-related metrics of generated candidates. The core component of TopoScorer is Specter(Spectral Topology Encoder), a topology-driven, multi-channel, multi-scale differentiable feature extractor for protein–protein interfaces that converts full-atom coordinates into topo-spectral representations via Persistent Topological Hyperdigraph Laplacians (PTHLs) and differentiable spectral descriptors, preserving physicochemical-role–aware cues alongside 3D topological structure to yield compact, interpretable features suitable for learning.", "tldr": "", "keywords": ["Topological Deep Learning; Protein Design; Binding Affinity;"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8dd46f951ca7831314106a781f3201be9f64314f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces TopoScorer, a model designed to predict the binding affinity of protein-protein interactions. The method is evaluated using standard data, and it also includes a case study demonstrating how an antibody generative model can be guided to produce designs with higher affinity. While the method is presented as being lightweight, interpretable, and end-to-end trainable, each of these aspects currently exhibits significant weaknesses."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The featurization and model architecture are described with great detail.\n- The concept of fine-tuning a generative antibody model to enhance affinity is both practically interesting and innovative."}, "weaknesses": {"value": "**Major**\n\n- Although the featurization and model architecture are well-explained, there is a lack of clarity regarding the training details, loss function, and data. Section 3.3, \"BINDING AFFINITY PREDICTION MODEL,\" only covers the \"Model Architecture\" paragraph, leaving the training objective and data unclear.\n- The proposed method appears to underperform existing approaches. For scoring mutations, Table 1 shows only a slight improvement in Spearman correlation over RDE-Net, while its Pearson correlation is substantially lower. A similar trend is observed for affinity prediction in Table 1 when compared against DSMBind, a fully unsupervised method.\n- The evaluation seems to be affected by data leakage, and further analysis is needed. The affinity prediction section (Section 4.1) does not specify how the complexes were split (e.g., sequence or structure similarity). The data for antibody design is split by release time (Section 4.2), which is known to cause data leakage when used as the sole criterion [1].\n- The method's key novelties, being \"lightweight, interpretable, and end-to-end trainable\", have considerable issues:\n  - The claim that the model is \"lightweight\" is not supported. Running time is not analyzed. Section 4.1 only states that TopoScore has  approximately four times fewer parameters than RDE-Network, but it remains unconfirmed whether this translates into substantially lower memory or time consumption.\n  - The \"interpretability\" of the method is only demonstrated through a single example (Figure 2b). It is unclear whether similar interpretability could be achieved by simply calculating the number of bonds rather than relying on topological features (please refer to Question 1).\n  - While the Abstract states that \"existing deep learning based approaches lack interpretability and a differentiable path from affinity back to the interface,\" multiple prior methods are indeed end-to-end differentiable, including for example [2], and DDGPred, which is mentioned in Related Work as end-to-end differentiable (line 94).\n\n**Minor**\n- The paper does not cite or discuss TopNetTree, a previous method that also uses topological features of protein-protein interfaces to predict affinity [3].\n- Some sentences are missing references:\n  - [Line 39]. The sentence \"Deep learning has become the dominant paradigm for protein–protein binding affinity prediction, delivering state-of-the-art accuracy and throughput\" lacks a reference.\n  - [Line 45]. The \"High training cost\" of prior methods is not supported by any reference.\n  - [Line 106]. \"Reviews\" are mentioned, but only one is cited.\n\nReferences\n\n- [1] Bushuiev et al, 2024, “Revealing data leakage in protein interaction benchmarks”, https://arxiv.org/abs/2404.10457\n- [2] Shuai et al, 2025, “Sidechain conditioning and modeling for full-atom protein sequence design with FAMPNN”, https://www.biorxiv.org/content/10.1101/2025.02.13.637498v1.full.pdf\n- [3] Want et al, 2020, “A topology-based network tree for the prediction of protein–protein binding affinity changes following mutation”, https://www.nature.com/articles/s42256-020-0149-6"}, "questions": {"value": "1. What would be the outcome if Figures 2e, f, and g were replaced with simple bar plots showing the counts of respective bonds? For instance, instead of Figure 2e, if there were simply three numbers representing carboxylate O - carboxylate O bonds for each of the three structures, would the same trend still be observable?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9ZJvF90NZj", "forum": "QNcrdCKNa5", "replyto": "QNcrdCKNa5", "signatures": ["ICLR.cc/2026/Conference/Submission16194/Reviewer_sgQZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16194/Reviewer_sgQZ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16194/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760620823031, "cdate": 1760620823031, "tmdate": 1762926357882, "mdate": 1762926357882, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose TopoScorer a binding affinity prediction with a focus on interpretability. They designed Specter which is a differentiable feature extractor for encoding protein protein interface encoding for both structural and chemical information.  They showcase an differentiable deep learning based model that can steer a generative antibody design model.\n\nThe model architecture is formed based on hyper graph induced cross protein distances to encode the heavy atoms into physicochemical role aware classes within the binding interface. They also use soft filtration to persistent topological hyperdigraph laplacians and then summarize the topology with a six tuple of differentiable spectral statistics of eigen values. They differentiate the eigen values with a fallback schedule to handle ill conditioned classes. Multi channel encoding is used to encode the the interface as a multi channel graph from role aware atom types. They map Atom37 names to 11 chemical role aware classes to differentiate between backbone donors/acceptors, aromatic carbon, sulfur atoms etc. They employ transformer with multi head self attention to mix information across channels, scales and interface regions. The different heads are expected to understand hydrophobic, polar, long range scales etc."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "For the sequence and structure co design model the fine tuning helps as shown in table 2. Addition of the proposed method helps steer optimization towards more plausible interface specially at the H3 region. It is great that the authors do a lot of ablation on the single channel vs multi channel to explain the interpretability."}, "weaknesses": {"value": "From the results (table 1) in the affinity prediction task top scorer outperforms other baselines on spearman. For multiple mutations it is the same pattern. It is hard to evaluate and compare the model performances if the pearson and spearman results are not consistent although authors claim that ranking based metrics are better for the task. \n\nIn addition the authors do not compare their model to other models notably GearBind which is also an all atom based graph model. For predicting affinity it is important to compare to the surface and structure based models such as AtomSurf as well. \nOn PDBBind data (Figure 2h) the correlation is 0.298. It is hard to say how good is the score when the proposed method is the only one and the other correlation values (Figure 2i) shows the ablation of the TopoScorer method. \n\nInterpretability analysis is an important area of research and often most methods do not focus on it but on the benchmark tasks itself the model seems to underperform compared to the other methods (Table 1 PearsonR shows DSMBind is best, DDGPred is best on single mutation task as shown in PearsonR)."}, "questions": {"value": "Have the authors considered other methods such as SurfPro https://arxiv.org/pdf/2405.06693 which is a surface based models on the protein design tasks and compared the results? It will make the approach more robust if other SOTA surface aware methods are compared."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "tBrTdHdVaL", "forum": "QNcrdCKNa5", "replyto": "QNcrdCKNa5", "signatures": ["ICLR.cc/2026/Conference/Submission16194/Reviewer_wGNS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16194/Reviewer_wGNS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16194/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761450726365, "cdate": 1761450726365, "tmdate": 1762926357530, "mdate": 1762926357530, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces TopoScorer, a lightweight, differentiable scorer for protein–protein binding affinity. It builds Specter, a topo-spectral feature extractor that computes soft, differentiable spectral statistics of PTHL spectra across radii, and pairs this with a small ttransformer to predict affinity from multi-channel, physicochemical role–aware interface graphs. On PPB-Affinity and SKEMPI-2.0, the method achieves strong Spearman correlations, and when used as a frozen reward it improves an antibody co-design model on DockQ in a held-out set."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Clean, coherent idea in a multi-scale, multi-channel topo-spectral features with a compact Transformer. Also it should be easy to plug into design loops.\n- Differentiable topology done carefully and in a specialized knowgledge domain.Soft zero-counts, log-sum-exp min/max, Huberized std. Also, eigenvalue-only backprop with stability guarantees.\n- Competitive ranking performance: best or near-best Spearman on PPB-Affinity and SKEMPI subsets. Clear reporting against physics and learned baselines.\n- As a frozen reward, improves DockQ and SR in IgGM finetuning on a post-2013 SAbDab split."}, "weaknesses": {"value": "- Generalization controls: time-based PPB-Affinity test is good, but no explicit homology/interface-similarity controls are reported (e.g., sequence-identity thresholds at contacting residues, SCOPe/CATH or interface clustering). This weakens cold-family claims.\n- Robustness to structural noise: mutants come from FoldX; there’s no stress-test for AF vs crystal, side-chain repacking choices, or coordinate jitter/protonation.\n- Channel/radius attributions are plausible, but there’s no deletion/counterfactual test showing predicted changes track"}, "questions": {"value": "- How do you prevent train–test leakage at the interface level (e.g., sequence identity on contacting residues, SCOPe/CATH families, interface RMSD clustering)?\n- How sensitive are results to structure sources (AF vs crystal), side-chain packers, coordinate jitter, and protonation?\n- In IgGM finetuning, how is the TopoScorer reward normalized across targets/sizes to avoid scale bias? Did you test reward-weight sweeps or label-shuffle controls?\n- What radii set do you use by default, and how often do eigenvalue fallback/stability tricks trigger in practice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "itJDFhqqz4", "forum": "QNcrdCKNa5", "replyto": "QNcrdCKNa5", "signatures": ["ICLR.cc/2026/Conference/Submission16194/Reviewer_XQ4x"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16194/Reviewer_XQ4x"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16194/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761902469217, "cdate": 1761902469217, "tmdate": 1762926356545, "mdate": 1762926356545, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work proposes a parameter-efficient protein-protein interaction (PPI) affinity prediction model, TopoScorer, based on a topological features of PPI complex structures. Specifically, the structure is represented by a multi-channel graph with role-aware atom types and physiochemical properties. The core component is a feature extractor named Specter, which employs a differentiable distance filter to obtain the multi-scale Hodge Laplacians which are then used to compute spectral features from the eigenvalues. The binding affinity predictor is then trained on the spectral features. Experiments on affinity and mutation impact prediction shows comparable performance with state-of-the-art methods.\n\nMoreover, the predictor is used in the fine-tuning of a language model for antibody design, achieving improved performance than the larger RDE-Network. Interpretation analysis show the importance of interface connectivity features and side chain structures."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The formulation and rationale of the proposed methods are clearly and soundly presented. The use of spectral features offer a rather novel insight into the\n\n- The application of the predictor as fine-tuning for generative models proves good generalizability and meaningful representations.\n\n- The biological relevance of the learned model patterns is demonstrated through interpretability analysis."}, "weaknesses": {"value": "- The predictive performance is not significantly improved compared to the baselines, \n\n- Because of this, the major advantage of the proposed model may lie in its parameter efficiency and adaptability as guidance methods. However, this part needs some additional demonstration. See Questions."}, "questions": {"value": "The work overall looks promising, but some important application aspects need to be addressed and I'm willing to raise the scoring with sufficient evidences:\n\n- How does the predictive performance compare to other PTHL-based models such as topoformer?\n\n- A more detailed comparison of the parameter and time efficiency between models would be appreciated.\n\n-  Besides comparing with a totally different generative framework, how does classifier guidance with TopoScorer compare to other prediction or scoring models (eg compared in Table 1) as classifier guidance on the same generative model, in terms of performance, parameter size and running time?\n\n- What is the side chain packing method used in the fine-tuning? Also, as side chain packing algorithms can take long to run, how does affect the running time of the fine-tuning loop?\n\n- 4.3 and Fig 2: some additional justifications of the analysis are needed: how does the pattern of $\\lambda_{sum}$ indicate the physiochemical properties of the amino acids and atoms *a priori*?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5L9Y6zUsNZ", "forum": "QNcrdCKNa5", "replyto": "QNcrdCKNa5", "signatures": ["ICLR.cc/2026/Conference/Submission16194/Reviewer_dETA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16194/Reviewer_dETA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16194/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761939720600, "cdate": 1761939720600, "tmdate": 1762926356100, "mdate": 1762926356100, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}