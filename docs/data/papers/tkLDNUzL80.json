{"id": "tkLDNUzL80", "number": 1361, "cdate": 1756875628132, "mdate": 1763030447438, "content": {"title": "Physically Ground Commonsense Knowledge for Articulated Object Manipulation with Analytic Concepts", "abstract": "We human rely on a wide range of commonsense knowledge to interact with an extensive number and categories of objects in the physical world. Likewise, such commonsense knowledge is also crucial for robots to successfully develop generalized object manipulation skills. While recent advancements in Multi-modal Large Language Models (MLLMs) have showcased their impressive capabilities in acquiring commonsense knowledge and conducting commonsense reasoning, effectively grounding this semantic-level knowledge produced by MLLMs to the physical world to thoroughly guide robots in generalized articulated object manipulation remains a challenge that has not been sufficiently addressed. To this end, we introduce analytic concepts, procedurally defined upon mathematical symbolism that can be directly computed and simulated by machines. By leveraging the analytic concepts as a bridge between the semantic-level knowledge inferred by LLMs and the physical world where real robots operate, we are able to figure out the knowledge of object structure and functionality with physics-informed representations, and then use the physically grounded knowledge to instruct robot control policies for generalized, interpretable and accurate articulated object manipulation. Extensive experiments in both simulation and real-world environments demonstrate the superiority of our approach. Please refer to the appendix for more details, and our codes will be made publicly available.", "tldr": "We propose analytic concepts as knowledge representation in physical form and a pipeline to ground semantic-level knowledge inferred by LLMs in the physical world through concepts, providing concrete guidance for articulated object manipulation.", "keywords": ["Articulated Object Manipulation", "Robotics", "Neural Symbolic", "Physical Concepts"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/a3acd4e9c01c7d344d18f55a4aaa640ed84e5cc8.pdf", "supplementary_material": "/attachment/e2eef3d39da6b8e45a34fbe902f654d3d3fde1f9.zip"}, "replies": [{"content": {"summary": {"value": "The paper presents an approach that aims to bridge semantic knowledge and the physical world through analytic concepts, leveraging MLLMs for articulated object manipulation. While the topic is relevant and potentially valuable, the current manuscript suffers from serious issues in writing clarity, conceptual organization, and experimental rigor."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The general idea of connecting MLLM reasoning with robotic control through analytic concepts is interesting.\n2. The motivation to achieve generalized manipulation is aligned with current trends in embodied AI."}, "weaknesses": {"value": "1. The overall writing is weak and difficult to follow. Many sentences are unclear, and logical connections between sections are missing. The readability issues significantly hinder understanding of the main contributions.\n2. Analytic Concepts Section is especially problematic. It is unclear why a “DISCUSSIONS” subsection appears here, this part should only provide definitions and conceptual clarifications. \n3. Figures 1 and 2 are difficult to understand. They fail to clearly illustrate the framework or the flow of reasoning. Figure 3, which appears to represent the main method, is overly simplified and does not sufficiently explain the proposed approach.\n4. The methodology section feels incomplete and fragmented, possibly due to space constraints. However, as it stands, the description is too brief to allow readers to follow the method. \n5. The experimental setup is simple. From the limited results in Table 2 and Table 3, I cannot form a comprehensive judgment of the method’s performance. The experiments lack comparison and analysis with more meaningful baselines."}, "questions": {"value": "1. How many data samples were used for training and evaluation in total?\n2. Was your model trained from scratch or fine-tuned from an existing pretrained MLLM?\n3. You mentioned using a single NVIDIA A100 GPU. What was your total training time?\n4. Did you re-implement or reproduce the experimental results of other compared methods for fair comparison?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8zkaY7ehBq", "forum": "tkLDNUzL80", "replyto": "tkLDNUzL80", "signatures": ["ICLR.cc/2026/Conference/Submission1361/Reviewer_oPjT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1361/Reviewer_oPjT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1361/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761549849132, "cdate": 1761549849132, "tmdate": 1762915747761, "mdate": 1762915747761, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "u3ddYWn2wJ", "forum": "tkLDNUzL80", "replyto": "tkLDNUzL80", "signatures": ["ICLR.cc/2026/Conference/Submission1361/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1361/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763030446761, "cdate": 1763030446761, "tmdate": 1763030446761, "mdate": 1763030446761, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes using analytic concepts to represent commonsense knowledge via MLLMs, and then grounding them in physical form so that robots can complete manipulation tasks more easily."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The idea of introducing analytic concepts and connecting them to physical actions seems interesting."}, "weaknesses": {"value": "1. The writing needs significant improvement. The current version is very hard to read and follow. Too much information is pushed to the appendix, while the main paper lacks concrete examples. The authors try to present too many things, but the content is not well organized. For acceptance at a top AI venue, the paper should be made clearer and more structured.\n\n2. Figures: there is no main figure that clearly shows the overall workflow. Fig. 1(b) at the bottom explains it briefly, but this is insufficient (and it is not even clearly indicated that it is from the authors). In addition, the fonts are too small in most figures (it is hard to read the text in a printed version)\n\n3. It is difficult to understand what differentiates the proposed method from the baselines. Even though related works are mentioned, the contribution is not clear. Much of Section 4 (Methodology) simply presents components of the method without motivation or clear comparison to prior work\n\n4. The explanation of analytic concepts is unclear. Similar structure-based representations have been used for many robotics tasks [1]. What makes the proposed concepts novel? Why are they called “analytic”? The authors mention that detailed examples are provided in the appendix, but a simple and concrete example should be included in the main paper for clarity.\n\n[1] Samuel Li et al.,\"ShapeGrasp: Zero-Shot Task-Oriented Grasping with Large Language Models through Geometric Decomposition,\" IROS 2024"}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8DXfvuHBSQ", "forum": "tkLDNUzL80", "replyto": "tkLDNUzL80", "signatures": ["ICLR.cc/2026/Conference/Submission1361/Reviewer_zCrC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1361/Reviewer_zCrC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1361/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761772408461, "cdate": 1761772408461, "tmdate": 1762915747603, "mdate": 1762915747603, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a framework for robotic manipulation that combines multi-modal large language models (MLLMs) with analytically defined manipulation concepts—symbolic templates that encode structural and interaction priors for articulated objects. These concepts are manually crafted to reflect physically grounded properties of common object parts (e.g., handles, lids) and their associated manipulation strategies. The MLLM selects the appropriate concept and strategy, while learned perceptual modules extract relevant physical parameters from point-cloud observations. Experiments in both simulation and real-world scenarios demonstrate improved performance over prior MLLM-based approaches (e.g., A3VLM, ManipLLM)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- **Strong balance between LLM reasoning and grounded control.**  \n  The paper effectively bridges high-level LLM-based affordance reasoning with physically grounded manipulation strategies, offering a compelling middle ground between symbolic priors and data-driven policy learning.\n\n- **Solid generalization performance.**  \n  The reported 27.1% gain on unseen object categories, along with consistent performance across both suction-based and parallel-jaw gripper setups, demonstrates strong generalization and robustness.\n\n- **Transparent and interpretable pipeline.**  \n  The system's modular structure allows clear diagnosis of failure modes (e.g., pose estimation vs. analytic concept selection), making it easier to analyze and improve individual components.\n\n- **Practical and accessible analytic concept design.**  \n  The authors convincingly argue that analytic concepts are simple to author—even for non-experts—and that a relatively small library (153 total, with only a subset needed per environment) can cover a wide range of real-world tasks."}, "weaknesses": {"value": "- **Dependence on analytic concept library.**  \n  While the analytic concepts are elegant, the approach fundamentally relies on the completeness and correctness of the concept library. The paper argues that these concepts are easy for humans to author, but it remains unclear how scalable and generalizable this process is in practice. For instance, how does the system handle objects or interaction modes that do not align cleanly with any existing concept? The method implicitly assumes that the library is sufficiently comprehensive, which may not always hold in real‐world deployments.\n\n- **Assumptions about perception reliability.**  \n  The pipeline assumes that the MLLM and Grounded-SAM can consistently identify the correct part and category from a single RGB image. In realistic scenarios, occlusions, ambiguous language cues, or objects with multiple plausible interaction points may challenge this assumption. Additional analysis or experiments examining such failure cases would strengthen the paper.\n\n- **Limited evaluation scope for task complexity.**  \n  Experiments are primarily conducted on single-step tasks with a single type of gripper. It remains unclear how analytic concepts extend to more complex settings, such as multi-stage manipulation (e.g., opening a door before pulling a drawer), deformable objects, or tool‐use scenarios. Although the proposed method appears conceptually compatible with long-horizon tasks, demonstrating results beyond single-step manipulation would provide a more complete understanding of the method’s practical capabilities."}, "questions": {"value": "- **Coverage and fallback mechanisms.**  \n  Although the paper argues that analytic concepts are straightforward to author, the method assumes that the concept library is sufficiently comprehensive. How does the system behave when encountering objects that only partially align with existing concepts or fall entirely outside the library? Is there a fallback mechanism—such as compositional reasoning, interpolation between concepts, or automatic discovery of new concepts—or does performance degrade sharply in these out-of-distribution scenarios?\n\n- **Extension to long-horizon and sequential manipulation.**  \n  The experiments mainly evaluate single-step tasks with a single gripper modality. Can analytic concepts be composed to support multi-stage, long-horizon manipulation with sequential dependencies (e.g., open lid → insert spoon → stir)? Do the authors envision the framework performing hierarchical reasoning and re-grounding at each step, or is it currently limited to feed-forward, single-stage execution?\n\n- **Generalization beyond rigid articulated objects.**  \n  The framework is currently tailored to rigid, articulated objects. Do the authors view analytic concepts as a general representation for physical commonsense that could extend to deformable objects, tool-use, or non-rigid manipulation? If so, what modifications would be required to accommodate more complex material properties and dynamic interactions?\n\n- **Failure mode analysis and comparative insights.**  \n  The paper would benefit from a more detailed failure-mode analysis. What are the most common sources of error observed in practice? Additionally, highlighting scenarios where the proposed analytic-concept approach succeeds compared to prior methods would help clarify its practical strengths and limitations for real-world deployment."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qcYQdPRVu8", "forum": "tkLDNUzL80", "replyto": "tkLDNUzL80", "signatures": ["ICLR.cc/2026/Conference/Submission1361/Reviewer_RY1Z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1361/Reviewer_RY1Z"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1361/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761860509613, "cdate": 1761860509613, "tmdate": 1762915747442, "mdate": 1762915747442, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}