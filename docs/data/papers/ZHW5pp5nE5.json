{"id": "ZHW5pp5nE5", "number": 13011, "cdate": 1758212684900, "mdate": 1759897471026, "content": {"title": "Delta-XAI: A Unified Framework for Explaining Prediction Changes in Online Time Series Monitoring", "abstract": "Explaining online time series monitoring models is crucial across sensitive domains such as healthcare and finance, where temporal and contextual prediction dynamics underpin critical decisions. While recent XAI methods have improved the explainability of time series models, they mostly analyze each time step independently, overlooking temporal dependencies. This results in further challenges: explaining prediction changes is non-trivial, methods fail to leverage online dynamics, and evaluation remains difficult. To address these challenges, we propose Delta-XAI, which adapts 14 existing XAI methods through a wrapper function and introduces a principled evaluation suite for the online setting, assessing diverse aspects, such as faithfulness, sufficiency, and coherence. Experiments reveal that classical gradient-based methods, such as Integrated Gradients (IG), can outperform recent approaches when adapted for temporal analysis. Building on this, we propose Shifted Window Integrated Gradients (SWING), which incorporates past observations in the integration path to systematically capture temporal dependencies and mitigate out-of-distribution effects. Extensive experiments consistently demonstrate the effectiveness of SWING across diverse settings with respect to diverse metrics. Our code is publicly available at https://anonymous.4open.science/r/Delta-XAI.", "tldr": "", "keywords": ["Time Series", "Online Time Series Monitoring", "Explainable Artificial Intelligence", "XAI"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5185a28e5aa155cf1485968e6be3a0b3dc1e929b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces SWING, an integrated gradients methods designed for time series for time series explainability. This explainability method mainly focus on why the prediction changes between 2 time points, instead of only explaining prediction at 1 time point. The paper also includes new evaluation metrics to suit more specifically to time series."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- The paper addresses many different issues of in the time series explainability paradigm and proposes a new method SWING to for time series explanations. This includes explaining \"prediction changes\" rather than a single \"prediction\".\n- The paper also include newer evaluation metrics in which I think they make sense. \n- The logic and flow of the paper is quite coherent in general.\n- Extensive results are included and the the results seem to show that SWING achieve the best performance."}, "weaknesses": {"value": "- Several notations and presentations can be better in Section 4.\n- The \"Unified Framework\" introduced in the contributions in the introduction is almost nowhere to be found. It could be implied in the Appendix.\n- While the method (SWING) is to explain the prediction changes from $T_1$ to $T_2$, the other baseline methods aimed to explain the prediction for $T$. This can imply that the experiments are not completely fair (both to SWING and to the other baseline methods)."}, "questions": {"value": "- The equations should be numbered.\n\n- When I was reading the paper, I did not find any hint about Delta-XAI being a \"unified framework\" for the 14 existing XAI methods. To me, as a reader, the main idea of the paper is to introduce the explanation of prediction change from $T_1$ to $T_2$, rather than a single time points. Then for each time point, the paper tackles the problem of OOD for IG and specifically tackle the problem of having 2 time points $T_1$ and $T_2$. The notation for this \"framework\", $\\varphi(f, X_{t,c}|T_1\\rightarrow T_2 )$, is just to explain the model $f$ on data $X$ from time $T_1$ to $T_2$. This is a generic time series explainability statement. Thus I think saying that there is a unified framework introduced is misleading. Also, there is no discussion on why this is a unified framework anywhere in the main text of the paper. Thus I think the idea of it being a unified framework can be removed from the main contributions. There could be a small paragraph on the adaption of this notations to other method after the experiment section, if the authors really want this to be a framework.\n\n- The \"generic wrapper function\" $g$ is not really generic as in line 178, $g$ is defined to be the difference of the predictions (with a moving window).\n\n- I think the main idea of this paper is very neat. We tend to explain a prediction at a specific time point $T$ instead of the prediction change from $T_1$ to $T_2$. As the authors discussed this in section 4 about how merely subtracting the difference of the other methods (Dynamask) can produce misleading explanations, the authors did not do the same in the experiments in Figure 1. I think comparing columns (c) to columns (d) may not be the most fair comparison as the explanations in (c) is to explain a single time point. The author can tackle this by either do the \"difference\" comparison, or make the point of the usefulness of explaining the prediction changes is more useful than explaining a single-timepoint prediction.\n\n- The author should include the notation $\\varphi (f, X_{t, d} | T_1\\rightarrow T_2)$ and $\\varphi (f, X_{t, d} | T)$ in the first paragraph in section 2. This is to highlight the main notation being used throughout the paper.\n\n- (Minor) I believe the $\\gamma_{2, 1}$ is wrong in Figure 2. Shouldn't it be from $T_2 - 1$ to $T_1$?\n\n- For the RBS and DPI, I think there is one main concern about the rationale of this choice (both notations and also the formulae). From an IG perspective, when we want to use IG on an input X w.r.t. the baseline X', the IG explanations is to explain the *difference* between X' and X. Thus, in Line 235, if the baseline X' is set to be $X_{T-W: T-1}$ then this explanation should \"really\" be $\\varphi(f, X_{t,d} | T - 1 \\rightarrow T)$, instead of $\\varphi(f, X_{t,d} | T)$. So in line 245, the RBS explanations are actually the difference of explanations between the \"changes\" in $T_2$ (from $T_2 - 1$) and the \"changes\" in $T_1$ (from $T_1 - 1$). It is thus the \"change\" of \"changes\". For DPI, it makes more sense because the \"changes\" and calculated between 2 pairs of points. But the rationale of this selection is not explained. (This is shown in Figure 2)\n\n- Equations in line 261 are not the friendliest to the readers. The idea is quite simple. Maybe do this. Let $\\gamma_{T}^\\pm(\\alpha) = (1-\\alpha)X_{T-W+1:T} + \\alpha X_{T-W+1\\pm 1: T\\pm 1}$ be the line segment between two neighbouring sliding windows. Let $\\gamma_{i, j}(\\alpha)$ be the concatenation of the line segments $\\gamma_{T_m}^\\pm$ for $m=i, \\ldots j$ (or $m=j \\ldots i$).\n\n- Line 323, aggregating attributions with a sliding window - does this apply to everything? i.e. Top K features, correlations, other attribution methods?\n\n- In 6.3 Ablation study, there are descriptions of \"SWING components\" (RBS, DPI, PHI). The SWING attributions are described in line 267, which seems to include \"concepts\" of RBS, DPI and PHI. But it is unclear that we can remove each of them. So what does the formula look like for SWING without RBS, PHI, without RBS and without DPI separately?\n\n- In 6.3 Ablation, what is that baseline distance $d$? $d$ was used as the feature index in the above text (section 4) and it is not really defined here. If I am guessing, SWING corresponds to d=1 which corresponds to the description in the RBS (baseline set to the time point right before T). So I suppose that all the \"1\" will be replaced by \"d\" in equations 251 and 267? If this is the case, either removing these ablations from the table, or introduce this design in Section 4. (and resolving the notations for feature index and this baseline distance)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "na"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "L9swiqw3iC", "forum": "ZHW5pp5nE5", "replyto": "ZHW5pp5nE5", "signatures": ["ICLR.cc/2026/Conference/Submission13011/Reviewer_QpEH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13011/Reviewer_QpEH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13011/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761593110663, "cdate": 1761593110663, "tmdate": 1762923754227, "mdate": 1762923754227, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces SWING, a time-series explainability method that extends Integrated Gradients to a temporal setting. The novelty of this work is in providing explanations for changes in the model’s prediction rather than the prediction at a single time point, which is a realistic scenario in many applications. The authors compare SWING to existing time-series explainability methods by adapting those methods to this change-in-time setup using a wrapper function."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1) The proposed explanation setup that focusing on changes in model prediction over time rather than the absolute prediction is compelling and well aligned with application domains, especially healthcare, where decisions often hinge on changes.\n\n2) The evaluation presented in the paper is very thorough: many baselines, multiple backbones, and more importantly analyses from several angles, including performance and computational cost."}, "weaknesses": {"value": "1) The paper focuses on attributing prediction changes when the argmax class does not change from time $T_1$ to $T_2$. But scenarios where the class does change seem highly relevant. Does the method extend to class-change cases, and if so, how?\n\n2) The choice of retrospective baseline (using previous time steps) is intuitive for isolating the single transition’s contribution, but it can fail depending on the granularity of change. It may be better to allow path selection based on the specific output change to explain. For example, if a clinician observes a heart-rate increase from a few hours earlier, the baseline should be the window producing the prediction for the prior hour.\n\n3) Some metrics (CPP, CPD, AUPD, and Correlation) may not align with the paper’s setup. They measure sensitivity of the prediction to removing observations, not which observations most influence the change in prediction over time. These metrics seem appropriate for all earlier baselines that measure importance of features for prediction at a certain point in time, however, they don't necessary guarantee improved performance in the proposed dynamic setup.\n\n4) Please clarify the motivation for the dual path integration (DPI). I'm not convinced why this component is a necessary part especially given that In the ablation (top-k removal), DPI shows no benefit. Also, it appears to be a notation issue in the equation for this section: for $i=1$, the text integrates over $\\gamma_{1,2}$ for $T_2$ and $\\gamma_{1,1}$ for $T_1$. Did the authors mean $\\gamma_{2,1}$ instead of  $\\gamma_{1,1}$ ?"}, "questions": {"value": "1) In the feature-attribution case study, you state that SWING yields sharper, localized attributions emphasizing recent time steps most responsible for prediction changes. Why is this desirable?\n\n2) How does the wrapper handle positive vs. negative attributions? Do the scores need to be normalized to produce realistic explanations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "f5nMYiKMxd", "forum": "ZHW5pp5nE5", "replyto": "ZHW5pp5nE5", "signatures": ["ICLR.cc/2026/Conference/Submission13011/Reviewer_y8Zs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13011/Reviewer_y8Zs"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13011/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761702293790, "cdate": 1761702293790, "tmdate": 1762923753785, "mdate": 1762923753785, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Delta-XAI, a wrapper that reframes explaining prediction change between two times as a single-prediction explanation, enabling adaptation of 14 XAI methods for online time series. It also introduces a tailored evaluation suite and presents SWING, an IG-based method that uses retrospective baselines, dual path symmetry, and piecewise historical integration to reduce path OOD and capture temporal dependence, achieving stronger faithfulness and preservation than IG at comparable cost, with code released."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe wrapper reduces the new task (change explanations) to standard single-step explanations, enabling broad reuse of existing methods.\n2.\tThe evaluation suite addresses multiple metrics (faithfulness, sufficiency, completeness, coherence, efficiency) tailored to evolving predictions.\n3.\tSWING is well-motivated for online streams and retains IG’s desirable axioms."}, "weaknesses": {"value": "1.\tThe method is defined for prediction change, but experiments do not clearly stratify or stress-test stable segments where the delta is small. In online monitoring, long stable stretches are common.\n2.\tIn the problem setting, it is mentioned that it can solve multiclass classification, but it is doubtful since the target class is assigned with the one with the largest probability increase.\n3.\tThe current setup seems focused on overlapping windows (short gaps). The applicability to non-overlapping/larger gaps is not demonstrated. \n4.\tIt mentioned that this method can be applied to 14 existing XAI methods, but only show the IG version."}, "questions": {"value": "As mentioned in the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6wKH94eYFM", "forum": "ZHW5pp5nE5", "replyto": "ZHW5pp5nE5", "signatures": ["ICLR.cc/2026/Conference/Submission13011/Reviewer_hFWL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13011/Reviewer_hFWL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13011/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761831869517, "cdate": 1761831869517, "tmdate": 1762923753447, "mdate": 1762923753447, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on explainable AI (XAI) for improving the interpretability of model predictions in online time series monitoring. It reformulates the explainability problem into a new XAI setting that is more practically relevant for deployed online time series models. In addition to introducing a new perspective on explainability for online time series monitoring, the paper also provides a new set of metrics designed to better evaluate the performance of different XAI methods. Beyond proposing this new problem definition and evaluation framework, the authors adapt existing XAI methods using a wrapper under the new setup. Through extensive benchmarking and comparisons, the authors further propose a new XAI method called SWING, adapted from the Integrated Gradients (IG) approach, which achieves state-of-the-art performance compared to prior methods."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The writing of this paper is clear and succinct. Figure 1 clearly motivates why time series monitoring requires a new framework for explaining feature attributions.  \n2. Instead of following complex or recent prior works, the authors modify existing classical IG methods to achieve state-of-the-art performance, demonstrating a strong understanding of the relevant literature.  \n3. This paper presents a comprehensive study that includes a new problem framing, a new set of evaluation metrics, a new method that performs well, and extensive experiments demonstrating the applicability of the proposed method and framework."}, "weaknesses": {"value": "1. The SWING framework is an extension of the IG baseline. The choice of using IG as the base method for SWING is motivated by its strong empirical performance in prior XAI metrics. While this is a reasonable motivation, there should be a more qualitative or theoretical explanation of why IG performs so well compared to more recent methods.  \n2. It would be valuable to conduct a user study to assess whether practitioners who regularly interact with time series dashboards prefer this new type of explanation.  \n3. Since this work defines a new problem framework for XAI in time series, along with the data, data processing, and evaluation implementation, it should be released as a benchmark for future methods to build upon and test against.  \n4. The reviewer disagrees with how the data features are used for MIMIC-III. Splitting GCS scores into different features would likely increase rather than reduce noise in an already highly incomplete dataset."}, "questions": {"value": "1. Could the authors provide a more detailed explanation on why IG works better than others instead of just claiming it does empirically?\n2. The paper introduces a new evaluation suite (faithfulness, sufficiency, completeness, coherence, efficiency). However, these are still indirect proxies for human interpretability. Could the authors provide evidence or discussion on how well these quantitative metrics align with human-perceived explanation quality in real-world decision-making, especially in clinical contexts?\n3. For SWING, is there a systematic trade-off between the length of the temporal window, computational efficiency, and the interpretability of the resulting explanations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yAa6LSeIZk", "forum": "ZHW5pp5nE5", "replyto": "ZHW5pp5nE5", "signatures": ["ICLR.cc/2026/Conference/Submission13011/Reviewer_z3oK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13011/Reviewer_z3oK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13011/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761884965557, "cdate": 1761884965557, "tmdate": 1762923753083, "mdate": 1762923753083, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}