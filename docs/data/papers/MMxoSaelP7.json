{"id": "MMxoSaelP7", "number": 5684, "cdate": 1757927190208, "mdate": 1759897960784, "content": {"title": "EvoProto: Evolving Prototypes with Class Similarity for Weakly Incremental Segmentation", "abstract": "Weakly Supervised Incremental Learning for Semantic Segmentation (WILSS) seeks to segment new classes using only image-level labels, without access to old class data, which challenges the stability-plasticity balance. The absence of pixel-level annotations for new classes and historical data for old classes often leads to class overwriting, where predictions for new classes misclassify or override regions belonging to semantically similar previously learned classes. We observe that such overwriting frequently arises from class confusion, where visually similar classes are entangled due to weak supervision and limited feature discrimination. To address this, we propose EvoProto, a framework that explicitly models and mitigates class confusion through the dynamic evolution of trainable class prototypes. We begin by introducing a confusion score that quantifies semantic similarity between new and old classes. Computed from CAM-derived predictions after a warm-up phase, this score is transformed into adaptive weights that guide both contrastive prototype learning and prototype-level knowledge distillation, thereby reinforcing inter-class separability during continual updates. Besides, each class in EvoProto is associated with a learnable prototype vector, which is continuously updated during training to better capture class-specific semantics and improve discriminability under weak supervision. Additionally, to counter the degradation in classification capability and the resulting pseudo-label noise during incremental steps in weak supervision, we propose a CAM Channel Selection mechanism that emphasizes confident and consistent activations as more reliable supervision. Extensive experiments on Pascal VOC and COCO benchmarks demonstrate that EvoProto effectively alleviates class overwriting and achieves state-of-the-art performance under various incremental scenarios. The code will be made publicly available.", "tldr": "", "keywords": ["weakly supervised learning", "class overwriting", "class similarity", "incremental semantic segmentation", "prototype learning"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bbd874120da890972bb85a703505e52d3edf4ba0.pdf", "supplementary_material": "/attachment/ab6c7f03cec7d816f9577319ec3c0e1fc4364890.pdf"}, "replies": [{"content": {"summary": {"value": "This paper addresses the problem of Weakly Supervised Incremental Learning for Semantic Segmentation (WILSS), where models must learn to segment new classes with only image-level labels, without accessing previous class data. The authors identify class overwriting， the misclassification of old classes as new ones due to class confusion, as a key failure mode in WILSS. This paper provide a framework that explicitly models and mitigates class confusion through dynamic prototype evolution guided by inter-class similarity. Experiments on Pascal VOC  and COCO-to-VOC under multiple incremental protocols (10-10, 15-5, 10-5, 10-2) show state-of-the-art results."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "After reading this paper carefully, I think this paper has the following strengths:\n\n- The idea of quantifying inter-class confusion and evolving prototypes accordingly is novel and well-motivated for the WILSS setting. Integrating contrastive learning and prototype-level distillation under confusion-aware reweighting is a creative and non-trivial combination.\n\n- The paper is generally well-written and structured, with logical flow from motivation to implementation.\n\n- The method is rigorously formulated, with mathematical clarity on confusion scoring, reweighting, and objective functions.\n\n- The paper targets an emerging and challenging area (WILSS) with practical importance: learning segmentation models from limited supervision under continual updates."}, "weaknesses": {"value": "The following weaknesses should be solved to improve the quality of this paper:\n\n- While the confusion-aware weighting is new, the prototype evolution concept shares similarities with prior prototype refinement works such as RePRIand PLOP. The contribution could be perceived as incremental rather than fundamentally novel.\n\n- The paper defines a symmetric confusion score from pseudo-labels but does not analyze its robustness to CAM noise or how it behaves across steps. It’s unclear whether confusion scores remain stable or amplify errors over time; this could undermine reliability.\n\n- The framework introduces multiple prototype-level losses and dynamic confusion estimation per epoch. Runtime or memory overhead is not discussed.\n\n- The ALD module uses activation thresholds but the rationale for the averaging bias “+1” and its hyperparameter sensitivity is underexplained. The section could be clearer on its interaction with confusion-aware objectives."}, "questions": {"value": "I have some questions fior this paper:\n\nQ1: How does the model prevent confusion scores from being corrupted by noisy pseudo-labels, especially early in incremental steps? Have the authors tried smoothing or memory-based averaging?\n\nQ2: Would EvoProto generalize to instance segmentation or open-vocabulary segmentation tasks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "zaKJ4ExIcs", "forum": "MMxoSaelP7", "replyto": "MMxoSaelP7", "signatures": ["ICLR.cc/2026/Conference/Submission5684/Reviewer_og6J"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5684/Reviewer_og6J"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5684/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761839675549, "cdate": 1761839675549, "tmdate": 1762918192768, "mdate": 1762918192768, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces EvoPrototype to address the problem of class overwriting in weakly supervised incremental learning for semantic supervision. Class overwriting stems from the confusion between semantically similar old and new classes. EvoPrototype addresses this by learning the prototypes with contrastive learning to maximize the discrimnation and distillation to preserve old class performance. EvoProtoype constructs a confusion matrix M to indicate the bidirectional confusion measurement between classes. M is then (1) uses to reweight the prototype contrastive loss with the most confusing class (CO_i); and (2) determines how much to distill from the previous step, where it assigns low weight to confusing classes. Furthermore, the authors introduce Activation-based label denoising to refines the image-level labels of old classes in new steps, using the average of the maximal activation across different activation maps as the threshold to binarize. EvoPrototype demonstrates state of the art on multiple datasets in different settings on both ViT and ResNet backbone."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Although the use of confusion matrix has been explored to reweight class-wise loss in [1], this paper utilize the matrix in a clever way for the task of WILSS.\n2. The method demonstrates consistently strong results accross benchmarks.\n3. The writing is easy to follow.\n4. Extensive experiments are conducted.\n\n[1] https://proceedings.mlr.press/v238/zhang24e/zhang24e.pdf"}, "weaknesses": {"value": "1. Although being introduced and cleverly used, the contribution of the confusion matrix should be ablated (results when all indicies is 1) to quantify its effect.\n2. The reviewer is not convinced on using the average across class activation as the threshold for all classes because the classes should be independent.\n3. Currently, there are many strong general natural open-vocal segmentation/grounding models, which makes this task less relevant. unless it is applied in specific domain that those foundation models underperform (e.g., medical imaging). It could be more relevant to see how this adapts in these special domain rather on natural images."}, "questions": {"value": "1. Is there any results to quantify the effectiveness of the confusion matrix?\n2. In figure 1, the reviewer finds the bottom plots ambiguous. Why is the y-axis cuttof, and what is the value of sheeps and trains?\n3. In Equation 4, w_{ij} = 0 for classes that are not the most confused counter part, why do we need this and can we set it to the original value because it naturally lower than the CO class?\n4. Could the author elaborate how equation 5 ensure that i and CO_i are always selected at the old-new boundary?\n5. The threshold thre is obtained as the average of maximum activation of each class i in equation (8). Reviewer finds that the activation of each class should be indepdent, could the author justify how the average across classes is a good value for threshold?\n6. The paper claims that class overwriting is caused by class confusion, is there any quantitative analysis on this cause and effect? (e.g., the correlation between pair-wise class semantic similarity and their mIoU, where low mIoU indicates class overwriting)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mOsVdUXuog", "forum": "MMxoSaelP7", "replyto": "MMxoSaelP7", "signatures": ["ICLR.cc/2026/Conference/Submission5684/Reviewer_EREY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5684/Reviewer_EREY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5684/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761892577799, "cdate": 1761892577799, "tmdate": 1762918192505, "mdate": 1762918192505, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the challenging problem of Weakly Supervised Incremental Learning for Semantic Segmentation (WILSS), where new categories must be segmented using only image-level labels, and old data are unavailable. The authors identify class overwriting—the misclassification of old regions as new ones—as a key obstacle caused by class confusion under weak supervision. To address this, the paper proposes EvoProto, a framework that dynamically evolves learnable class prototypes guided by a confusion score quantifying semantic similarity between classes. The confusion-aware adaptive weights regulate both contrastive prototype learning and prototype-level distillation, enabling better inter-class separation. Additionally, an Activation-based Label Denoising (ALD) module enhances pseudo-label reliability. Experiments on Pascal VOC and COCO show consistent improvements over prior WILSS baselines, confirming the framework’s effectiveness."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Clearly identifies class confusion as the root cause of class overwriting in WILSS, providing a strong conceptual motivation.\n\nThe EvoProto framework is well-designed and technically sound, integrating prototype evolution, adaptive reweighting, and knowledge distillation in a coherent manner.\n\nThe confusion score is intuitive and bridges semantic similarity and optimization dynamics, offering interpretability.\n\nThe ALD module effectively complements the prototype evolution mechanism, improving pseudo-label quality under weak supervision.\n\nExtensive experiments on Pascal VOC and COCO, along with ablation and visualization, convincingly demonstrate the model’s advantages over state-of-the-art methods.\n\nWriting is clear, and figures (especially confusion visualization) help convey the intuition."}, "weaknesses": {"value": "While the proposed EvoProto framework is well-structured, several concerns limit its novelty and practicality. First, the mechanism by which the adaptive weights evolve across incremental stages remains insufficiently explained, and it is unclear whether such adaptive reweighting may introduce error accumulation over time. Second, the overall innovation appears moderate, as the paper lacks an in-depth discussion of related works in fine-grained recognition and continual incremental learning. Third, the framework involves numerous hyperparameters (e.g., k, γ, τ), yet their sensitivity is not analyzed, making the method complex and potentially difficult to reproduce. In addition, without any released implementation, the computational overhead introduced by prototype evolution and the activation-based label denoising (ALD) module may be nontrivial; a complexity or runtime comparison would substantially strengthen the contribution. Finally, the paper does not clarify how the model behaves when the ratio between new and old classes varies, which is important for assessing its robustness under different incremental settings."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zSJG89rY9e", "forum": "MMxoSaelP7", "replyto": "MMxoSaelP7", "signatures": ["ICLR.cc/2026/Conference/Submission5684/Reviewer_kavz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5684/Reviewer_kavz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5684/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991615331, "cdate": 1761991615331, "tmdate": 1762918192187, "mdate": 1762918192187, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work focuses on weakly supervised incremental learning for semantic segmentation, where pixel-level annotations for new classes and historical data for old classes are unavailable. To address this, it employs CAM to generate pseudo labels for training. However, due to the lack of precise annotations, the model tends to suffer from overwriting and class confusion. To mitigate this issue, a confusion matrix is introduced to model inter-class relationships. The proposed method is evaluated on the Pascal VOC and COCO benchmarks and compared with multiple baselines, achieving state-of-the-art performance and even surpassing some methods that rely on pixel-level annotations."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1、This paper achieves state-of-the-art performance on short-task, long-task, and cross-dataset incremental learning settings, demonstrating further improvements over existing methods.\n\n2、The proposed approach is not limited to a specific model architecture and has been validated on both ResNet and ViT backbones."}, "weaknesses": {"value": "1、The changes in the “Train” mIoU curves in Figure 1 are not clearly presented.\n\n2、In Eq. 1, the meanings of u and v are not clearly defined.\n\n3、The framework diagram in Figure 2 lacks clarity and appears somewhat confusing. For example, the “class prototype pool” in the upper-right corner seems unnecessary, and among the two BCE losses, the one shown at the bottom of the figure is not clearly explained."}, "questions": {"value": "1、Weakly Incremental Learning for Semantic Segmentation (WILSS) incrementally learns new classes using only image-level supervision. However, in Figure 2, it is unclear where the GT (ground truth) labels come from.\n\n2、Eq. 3 implies M_{i, j} = M_{j, i}. However, the confusion matrix M in Figure 2 appears asymmetric, which might be due to certain normalization or visualization processing. Could you please clarify this?\n\n3、Because the class activation map A ∈ [0, 1]^p obtained from CAM cannot be directly used as pseudo labels for semantic segmentation, the authors introduce a thresholding scheme in Eq. 8 to generate binary masks. However, the effectiveness of this threshold selection of concerning, as it remains unclear whether the chosen threshold is accurate or optimal.\n\n4、In the overall objective shown in Eq. 11, multiple loss terms are included, but the BCE loss mentioned in Figure 2 and Section 4.1.2 is missing, which appears to be inconsistent.\n\n5、The overall objective involves multiple hyperparameters, which makes parameter selection challenging.  It is unclear how the optimal parameters were determined, and corresponding ablation studies on these hyperparameters are needed to support the choice.\n\n6、The proposed method relies on CAM to generate pseudo labels, which are then used for training. As the quality of these pseudo labels intuitively determines the overall performance of the method, would adopting more advanced class activation mapping techniques, such as Grad-CAM or Grad-CAM++, help improve the pseudo-label quality and consequently enhance model performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sHadpmyjhS", "forum": "MMxoSaelP7", "replyto": "MMxoSaelP7", "signatures": ["ICLR.cc/2026/Conference/Submission5684/Reviewer_CRsn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5684/Reviewer_CRsn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5684/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762006590666, "cdate": 1762006590666, "tmdate": 1762918191872, "mdate": 1762918191872, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}