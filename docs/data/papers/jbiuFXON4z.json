{"id": "jbiuFXON4z", "number": 8063, "cdate": 1758056716388, "mdate": 1763104587068, "content": {"title": "Enhancing Taxonomic Classification Consistency with Hierarchical Reasoning", "abstract": "While Vision-Language Models (VLMs) excel at visual understanding, they often fail to grasp hierarchical knowledge. This leads to common errors where VLMs misclassify coarser taxonomic levels even when correctly identifying the most specific level (leaf level). Existing approaches largely overlook this issue by failing to model hierarchical reasoning. To address this gap, we propose VL-Taxon, a two-stage, hierarchy-based reasoning framework designed to improve both leaf-level accuracy and hierarchical consistency in taxonomic classification. The first stage employs a top-down process to enhance leaf-level classification accuracy. The second stage then leverages this accurate leaf-level output to ensure consistency throughout the entire taxonomic hierarchy. Each stage is initially trained with SFT to instill taxonomy knowledge, followed by RL to refine the model's reasoning and generalization capabilities. Extensive experiments reveal a remarkable result: our VL-Taxon framework, implemented on the Qwen2.5-VL-7B model, outperforms its original 72B counterpart by over 10% in both leaf-level and hierarchical consistency accuracy on average on the iNaturalist-2021 dataset. Notably, this significant gain was achieved by fine-tuning on just a small subset of data, without relying on any examples generated by other VLMs.", "tldr": "", "keywords": ["Vision Language Model", "Taxonomic Classification", "Hierarchical Reasoning"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/97b688d8ec969473fcfeec46d20b23499ac790b9.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper discusses that while VLMs perform well in visual understanding, they have a problem in grasping hierarchical relations and classifying coarser classes, which can result in bad hierarchical reasoning. The paper proposes VL-Taxon, a two-stage hierarchy-based reasoning framework, to improve leaf-level and higher-level classification accuracy. In the first stage, the model generates classes from the finest level to the coarsest level. In the second stage, the reasoning is performed conditioning on the first stage prediction."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well-motivated. The paper points out a valid question and challenge: lack of hierarchical consistency in VLMs. \n\nThe writing is without problems and well-structured. \n\nThe idea is intuitive and simple. The experiments show that the idea works well. \n\nThe paper compares the results with the Qwen2.5-VL and shows improvements over the model. The paper provides comparisons on three datasets and shows improvements."}, "weaknesses": {"value": "The paper uses reinforcement learning; however, in the writing, it is not clear what the pipeline is. Also, the paper discusses SFT and hierarchical SFT.\n\nThe experimental setup for Table 1 is not clear. How is the default SFT and hierarchical performed? \nIn Table 2, comparing leaf condition and direct listing, what if the model is memorizing the hierarchy and overfitting?\nTan et al 2025 includes results using LoRA, where the results improve (Tables 4 and 5). I wonder why these results are not included.\nWhy is the paper not including GPT as Tan et al 2025 does?\nI wonder if the paper can compare the idea with protect paper and compare the performance and show how the ideas are different.\n\nEquation 2 is wrong. \nThe abstract mentions SFT when the paper has not introduced what SFT means yet. \nLines 421 and 423, acc leaf is written wrong."}, "questions": {"value": "Please check the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5ZD6Ob4zkt", "forum": "jbiuFXON4z", "replyto": "jbiuFXON4z", "signatures": ["ICLR.cc/2026/Conference/Submission8063/Reviewer_KRzm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8063/Reviewer_KRzm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8063/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761762917879, "cdate": 1761762917879, "tmdate": 1762920053783, "mdate": 1762920053783, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "YDhccIif6r", "forum": "jbiuFXON4z", "replyto": "jbiuFXON4z", "signatures": ["ICLR.cc/2026/Conference/Submission8063/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8063/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763104586239, "cdate": 1763104586239, "tmdate": 1763104586239, "mdate": 1763104586239, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles the important problem of hierarchical inconsistency in large vision-language models (VLMs), proposing a two-stage reasoning framework (VL-Taxon) that first predicts fine-grained (leaf-level) categories and then refines the full taxonomy tree for consistency. The model is trained with supervised fine-tuning and GRPO-based reinforcement optimization. Experiments on iNaturalist and CUB show notable improvements over existing large-scale VLMs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**1. Timely and meaningful problem.** The paper addresses a real and underexplored weakness of current large-scale VLMs—hierarchical inconsistency. This direction is important and worth continued attention.\n\n\n**2. Empirical effectiveness**. The proposed method achieves superior performance compared to other VLM baselines on fine-grained taxonomic datasets, suggesting that hierarchical reasoning can indeed improve structured understanding."}, "weaknesses": {"value": "**1. Questionable use of the VQA setting.**\n While the paper follows a VQA-style format, it’s not clear that this setup is necessary. Since free-form text outputs can naturally represent hierarchical answers, it’s unclear what is gained by converting the task into VQA format. Other works (e.g., H-CAST [1]) demonstrate inconsistency directly through classification without such framing.\n\n\n**2. Unclear justification for two-stage design.**\n The method predicts the most specific (leaf) node and then refines coarse predictions based on it. However, given a predefined taxonomy, all parent nodes can be deterministically derived from the leaf. It’s not fully explained why explicit reasoning is needed instead of simple taxonomy lookup.\n\n\n**3. Weak motivation for using GRPO.**\n The choice of GRPO for enhancing generalization is insufficiently justified. It seems more like adopting a recent RL technique rather than one particularly suited to hierarchical reasoning. A stronger rationale or comparative study with alternative methods would help.\n\n\n**4. Limited analysis and interpretability.**\n The ablation studies focus solely on numerical performance changes within benchmarks. More qualitative analyses—such as visual examples of where inconsistency occurs or how the method corrects specific cases—would significantly strengthen the paper’s clarity and insight."}, "questions": {"value": "Please refer to the weaknesses above. In particular, I would appreciate clarification on:\n\n1. The necessity of using a VQA-style formulation instead of direct classification. Can this method be applied to hierarchical classification tasks as in [1]?  \n\n2. The motivation for predicting coarse labels from the leaf node rather than using predefined taxonomy relations.\n\n3. The specific reason for adopting GRPO over other possible reinforcement or alignment methods.\n\n4. Any qualitative or interpretive evidence that demonstrates how the proposed reasoning actually improves hierarchical consistency.\n\n[1] Visually Consistent Hierarchical Image Classification, ICLR, 2025"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Dx3Z1LYrUH", "forum": "jbiuFXON4z", "replyto": "jbiuFXON4z", "signatures": ["ICLR.cc/2026/Conference/Submission8063/Reviewer_CRLF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8063/Reviewer_CRLF"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8063/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761948699467, "cdate": 1761948699467, "tmdate": 1762920053416, "mdate": 1762920053416, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces VL-Taxon, a two-stage, hierarchy-aware reasoning framework to improve both leaf-level accuracy and Hierarchical Consistent Accuracy (HCA) in taxonomic classification with VLMs. Stage-1 performs explicit top-down reasoning to predict the most specific (leaf) class in an open-set manner; Stage-2 answers downstream hierarchical questions conditioned on the Stage-1 leaf prediction to enforce cross-level consistency. Training uses a hybrid SFT→GRPO recipe (LoRA, one epoch each, group size 8) on a subset of iNat21-Plant; evaluation spans iNat21-Plant/Animal and CUB-200 under a similar-choice protocol. Empirically, a 7B Qwen2.5-VL backbone trained with VL-Taxon outperforms the 72B version on HCA and leaf accuracy on iNat21 datasets and shows large gains vs. LLaVA-OV and InternVL baselines; ablations suggest both the two-stage design and explicit reasoning are necessary."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Directly addresses the widely observed hierarchy failure mode in VLMs with an inference + training recipe rather than only prompting.\n\nStage-1 open-set leaf prediction reduces answer-set leakage; Stage-2 conditioning formalizes hierarchy alignment; GRPO rewards reflect both formatting and correctness.\n\n7B surpassing 72B (Qwen2.5-VL) highlights training/inference strategy over sheer size—consistent with broader open-source reports on Qwen2.5-VL capability.\n\nHybrid SFT→GRPO aligns with the trajectory of RL for reasoning in LLMs/VLMs."}, "weaknesses": {"value": "The paper compares mainly to general VLMs. It should include ProTeCt (HCA/MTA metrics origin) and hierarchy-aware CLIP variants (hyperbolic embeddings, hierarchical attention) under the same similar-choice protocol to isolate the benefit of two-stage reasoning vs. better text encoders/prompts.\n\nFinetuning exclusively on plants may bias reasoning templates (authors note Plantae priors). The cross-domain gains are impressive but would be stronger with balanced plant/animal SFT or with unseen-taxonomy splits and leakage checks.\n\nResults rely on a multiple-choice “similar-choice” setup (SigLIP similarity). Open-ended taxon name generation and noisy real-world labels could behave differently. An open-ended, non-MC evaluation and calibration of hierarchical uncertainty would improve external validity.\n\nWhile LoRA ranks, lr, batch sizes, and GRPO G/β are given, training token counts, wall-clock, GPU types, and prompt templates (full) would help reproducibility and fair cost comparisons against single-stage SFT.\n\nInclude newer LLaVA-OV 1.5 releases and InternVL3.5 variants measured under the same hierarchy benchmark for completeness."}, "questions": {"value": "Please add ProTeCt and hyperbolic CLIP baselines under your protocol (same images, options), and report HCA/MTA side-by-side.\n\nWhat is the effect of removing format reward, or using partial-credit hierarchical rewards (e.g., +1 for each correct node on the path) vs. 0/1?\n\nHow does Stage-1 behave with unseen genus/species strings (misspellings, synonyms)? Any normalization/canonicalization step?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3JZfOCqKWz", "forum": "jbiuFXON4z", "replyto": "jbiuFXON4z", "signatures": ["ICLR.cc/2026/Conference/Submission8063/Reviewer_WqLj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8063/Reviewer_WqLj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8063/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761970738716, "cdate": 1761970738716, "tmdate": 1762920052944, "mdate": 1762920052944, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes VL-Taxon, a two-stage top-down hierarchical reasoning framework (Stage 1: predict leaf → Stage 2: answer all levels conditioned on Stage 1) plus GRPO-based hybrid fine-tuning (SFT→GRPO). It reports improvements in HCA and Acc_leaf on iNat21-Plant/Animal, CUB-200, claiming the 7B model surpasses 72B on some sets (Tables 3, 4-5-6 and §4). However, ImageNet-derived hierarchical benchmarks are excluded, and results are presented with single seed, no standard deviations, making generalization and reproducibility assessment difficult."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Appropriate problem definition: Explicitly distinguishes HCA (Eq. 3) from leaf accuracy (Eq. 4), clarifying the HCA ≤ Acc_leaf relationship. Proper targeting of hierarchical consistency.\n2. Simple procedure with consistent improvement signals: Two-stage reasoning and hybrid training (Tables 4, 6) show broad HCA gains. The HCA(L) analysis (leaf-correct conditional HCA, Table 5) separating intermediate-level consistency improvements is compelling."}, "weaknesses": {"value": "1. Lack of statistical rigor (single seed, no standard deviations)\nAll numbers in Tables 3-6 are single values without std/CI. GRPO and prompt-based pipelines are sensitive to seed/option construction, making current one-shot numbers insufficient for reproducibility/significance assessment. Require ≥3-5 seed mean±std and significance tests.\n2. Unanalyzed cascade failure modes\nSince Stage 2 is conditioned on Stage 1 leaf result, Stage 1 errors could lead Stage 2 to solidify consistent but incorrect hierarchies. Authors analyzed success cases with HCA(L) (Table 5) but not leaf-incorrect conditional failure patterns (e.g., \"Does Stage 2 mitigate/amplify when leaf is wrong?\"). Essential for deployment stability assessment."}, "questions": {"value": "Major questions\n1. Seed/variance: Can you provide seed≥3 results with statistical significance for Tables 3-6?\n2. Choice bias: Can you compare similar-choice impact (human-verified vs SigLIP choices)? Open-ended performance?\n3. Cascade analysis: Quantitative impact of Stage 2 on HCA when leaf is incorrect (mitigation/amplification rates)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CqmAr30Zay", "forum": "jbiuFXON4z", "replyto": "jbiuFXON4z", "signatures": ["ICLR.cc/2026/Conference/Submission8063/Reviewer_2YhU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8063/Reviewer_2YhU"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8063/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762010130133, "cdate": 1762010130133, "tmdate": 1762920052148, "mdate": 1762920052148, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles a well-observed failure mode in vision–language models (VLMs): even when leaf (species) predictions are correct, intermediate taxonomic levels are inconsistent. It proposes VL‑Taxon, a two‑stage, top‑down hierarchical reasoning framework: Stage 1 performs open‑set specific (leaf) classification by explicitly reasoning through the hierarchy; Stage 2 conditions on the Stage 1 leaf to answer multiple‑choice questions at each level, enforcing cross‑level consistency. A hybrid first SFT then GRPO regime (dataset split by species) further stabilizes formatting and accuracy. Experiments on iNat21‑Animal/Plant and CUB‑200 show sizable gains in hierarchical consistent accuracy (HCA) and leaf accuracy over strong VLM baselines."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. Ablations diagnose what matters. Removing top‑down reasoning or the first stage degrades HCA across datasets, and HCA(L) analyses confirm gains arise from better intermediate‑level coherence, not only leaves.\n2. Cross‑domain generalization despite one‑domain fine-tuning. Trained solely on iNat21‑Plant, the model achieves SOTA on iNat21‑Animal, underscoring transferability of the hierarchical procedure."}, "weaknesses": {"value": "1. Motivation is weak in the Introduction. The paper does not crisply state the concrete research question upfront (what, precisely, is broken and why existing approaches fail), nor does it articulate a falsifiable hypothesis that the later sections test. This blurs the problem–solution–evidence thread.\n\n2. Problem statements are imprecise and under-specified. The two stated issues—(i) inconsistent hierarchical listings across levels and (ii) limited generalization—are framed as symptoms rather than formally defined problems. There is no clear operational definition, scope (which taxonomic depths, which domains), or measurable target for “generalization,” making it hard to judge whether the method addresses them.\n\n3. Missing simple supervised CNN/ViT baselines and rationale for using VLMs. A small supervised CNN/ViT trained on the same data can achieve higher leaf accuracy (and thus HCA via ancestor mapping). The paper neither reports such baselines nor justifies the added complexity and cost of VLMs with commensurate benefits (e.g., open-worldness, label sparsity, or zero-shot transfer).\n\n4. Undefined term: “unconditional (direct) listing.” The phrase is introduced (lines 89–90) without a prior, explicit definition or a precise contrast with “conditional” listing. It is unclear whether it refers to free-form hierarchical generation, MCQ without priors, or another setting.\n\n5. Ambiguous visuals: unclear boundaries in Fig. 1 (Left) and Fig. 2 (Left). The figures lack clear delineation (boxes/edges/level separators), making it difficult to see where one level/path ends and another begins. This weakens the diagnostic message those figures are supposed to convey.\n\n6. Tables 1 and 2 are insufficiently motivated and prematurely placed. The paper does not state the research questions first and then use the tables to test specific hypotheses. As presented, it is unclear what each table is designed to prove (e.g., which hypothesis about listings, priors, or generalization), why these results appear before a rigorous problem statement, and how they tie into the subsequent method.\n\n7. Limited technical contribution. The evaluations are largely reuses of existing pieces: the training objectives in Eq. (1)–(2) follow standard likelihood/reward formulations, and the metrics in Eq. (3)–(4) (hierarchical consistency and leaf accuracy) are definitions rather than new measures. The proposed two-stage pipeline mainly rearranges known components (prompted hierarchical listing + conditioned MCQ + off-the-shelf GRPO/LoRA) without introducing a new model architecture, loss, or theory. As a result, the contribution feels procedural/engineering rather than technically novel, and the paper would benefit from clearer articulation of what is genuinely new versus what is borrowed."}, "questions": {"value": "See the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ITkZYbr0wt", "forum": "jbiuFXON4z", "replyto": "jbiuFXON4z", "signatures": ["ICLR.cc/2026/Conference/Submission8063/Reviewer_LeDB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8063/Reviewer_LeDB"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission8063/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762105784742, "cdate": 1762105784742, "tmdate": 1762920051839, "mdate": 1762920051839, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}