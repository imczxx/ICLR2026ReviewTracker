{"id": "ICz7ymsRTd", "number": 21863, "cdate": 1758322765347, "mdate": 1763249570671, "content": {"title": "Model Fusion via Neuron Interpolation", "abstract": "Model fusion aims to combine the knowledge of multiple models by creating one representative model that captures the strengths of all of its parents. However, this process is non-trivial due to differences in internal representations, which can stem from permutation invariance, random initialization, or differently distributed training data. We present a novel, neuron-centric family of model fusion algorithms designed to integrate multiple trained neural networks into a single network effectively regardless of training data distribution. Our algorithms group intermediate neurons of parent models to create target representations that the fused model approximates with its corresponding sub-network. Unlike prior approaches, our approach incorporates neuron attribution scores into the fusion process. Furthermore, our algorithms can generalize to arbitrary layer types. Experimental results on various benchmark datasets demonstrate that our algorithms consistently outperform previous fusion techniques, particularly in zero-shot and non-IID fusion scenarios.", "tldr": "Fusing models by grouping neurons using L2 distance, representing groups in the fused model, and boosting performance with importance scores", "keywords": ["Model Fusion", "Neuron Importance", "Non-IID Splits", "Layer Alignment"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/172025b0c7201230d24df8e76c53f38181ac065e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The process of model fusion is non-trivial, resulting the three key gaps in prior research, including reproducibility, base model quality, and heterogeneous data. Thus, this paper proposes a neuron-centric family of model fusion algorithms regardless of training data distribution as these algorithms incorporate neuron attribution scores into the fusion process."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. It casts fusion as a principled representation matching problem, yielding a two-stage algorithm, which measure grouping error and approximation error. It decouples the traditional objective by introducing an auxiliary vector, enabling a more tractable decomposition of the cost function.\n2. It incorporates neuron saliency into alignment, improving performance across our methods and enhancing existing approaches. \n3. It provides a flexible opensource re-implementation of existing algorithms."}, "weaknesses": {"value": "1. This method view DNN as a function parameterized by weights and for many model architectures, this function can be decomposed into many subfunctions. However, the rapid development of network architecture has made many SOTA network architectures no longer cascading, but containing many intricate connections. The authors do not discuss these complex network architectures.\n2. Does a collection of pretrained base models to share the same network architecture, that is, do they need to be siamese networks? Is it possible for models with different network architectures to merge?\n3. It lacks the comparison with SOTA model fusion methods, especially those proposed in the recent two years."}, "questions": {"value": "1. For the three key gaps in prior research, a more intuitive explanation or illustration is needed as some gaps, especially the third gap, are professionally in-depth and difficult to understand.\n2. In Eq. (1), $s_j$ is not introduced.\n3. For data of different distributions, whether the auxiliary vector needs to be retrained as the optimal solution of the grouping error may be changed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "w6fkp8wG95", "forum": "ICz7ymsRTd", "replyto": "ICz7ymsRTd", "signatures": ["ICLR.cc/2026/Conference/Submission21863/Reviewer_MnPz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21863/Reviewer_MnPz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21863/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761570912079, "cdate": 1761570912079, "tmdate": 1762941960159, "mdate": 1762941960159, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new family of model fusion algorithms, termed \"Neuron Interpolation,\" designed to merge multiple trained neural networks into a single representative model. The core idea is to frame fusion as a layer-by-layer representation-matching problem. The method operates in two stages per level: 1) a \"grouping\" step, which clusters the neuron outputs of all parent models (using K-means or Hungarian matching) to find importance-weighted \"target\" cluster centers , and 2) an \"approximation\" step, which trains the weights of the fused model's current level to match these target centers. The authors introduce two main variants: Hungarian Fusion (HF) for one-to-one matching of equal-sized models and K-means Fusion (KF) for the general case. A key contribution claim is the incorporation of neuron attribution (saliency) scores into this process. The paper presents experiments across various data distributions (full, non-IID, and \"sharded\") , claiming to significantly outperform prior methods like OTFusion and Git Re-Basin, especially in challenging zero-shot scenarios."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- **Problem Motivation:** The paper correctly identifies a significant and practical problem: existing fusion methods struggle in zero-shot and non-IID settings, which are common in real-world applications like Federated Learning.\n- **Flexible Framework:** The proposed two-stage (grouping, fitting) framework is flexible. The K-means Fusion (KF) variant can naturally handle fusing models of different widths  (as shown in Table 1, if it were filled out), and the gradient-based variant can be applied to arbitrary differentiable layers"}, "weaknesses": {"value": "- **High Complexity and Sensitivity:** The authors' best method (gradient-based KF) is admitted to be \"sensitive to hyperparameters\" and its lack of robustness is shown by requiring two different settings for the paper's own experiments. It is also computationally expensive, running 16-23x slower than baselines (Table 10).\n- **Overstated Saliency Contribution:** The claim of being the \"first\" to use saliency scores is factually incorrect, as the authors admit in Appendix C that prior work (Singh and Jaggi, 2020) already proposed it. Furthermore, the empirical gain from these scores is minimal (Tables 6, 7), contradicting the abstract's emphasis on this contribution.\n- **Limited Novelty:** The method's novelty is limited, as it combines two well-known concepts: 1) neuron alignment via matching/clustering (as in OTFusion) and 2) multi-teacher feature-based distillation (which the authors call \"fitting\"). This combination is an incremental step, not a fundamental breakthrough.\n- **Poor Presentation of Results:** The experimental section is poorly structured and difficult to follow. Critically, the authors often present tables of results without adequately discussing them or, in some cases, even not referencing them in the main text. This is a major oversight that hinders review."}, "questions": {"value": "1. **Missing Related Work on Heterogeneity:** The related work section appears to miss some key references focused on heterogeneity. Could the authors elaborate on how their work, especially KF, differs from and compares to the cross-layer alignment method for heterogeneous networks in [1]? Furthermore, given the strong Federated Learning (FL) motivation, how does this approach relate to other federated methods designed to address client heterogeneity, such as [2]?\n\n2. **Clarification of HF for Multi-Model Fusion:** The Hungarian Fusion (HF) method is described as solving a one-to-one matching problem, which is well-defined for the two-model case. However, the paper also presents results for multi-model fusion. How is the one-to-one matching problem formulated and solved when fusing $N > 2$ models? \n\n3. **Addressing Error Propagation:** The paper claims a key weakness of prior work is \"ignoring how the fused model evolves as the algorithm iterates through the levels... without accounting for potential changes [in] previous level outputs\" (Lines 162-165). However, in the simple two-model case with linear levels and uniform importance, HF seems to reduce to a process very similar to OTFusion. Could the authors clarify the *exact* mechanism by which their method solves this alleged error propagation issue?\n\n[1] Nguyen, Dang, et al. \"On cross-layer alignment for model fusion of heterogeneous neural networks.\" ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) . IEEE, 2023.\n\n[2] Makhija, Disha, Nhat Ho, and Joydeep Ghosh. \"Federated self-supervised learning for heterogeneous clients.\"arXiv preprint arXiv:2205.12493 (2022)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "C0pOy6wJDE", "forum": "ICz7ymsRTd", "replyto": "ICz7ymsRTd", "signatures": ["ICLR.cc/2026/Conference/Submission21863/Reviewer_54JN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21863/Reviewer_54JN"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21863/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761892909456, "cdate": 1761892909456, "tmdate": 1762941959913, "mdate": 1762941959913, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a neuron-level approach to model fusion that decomposes the fusion objective into two complementary components: (i) grouping neurons from multiple models according to similarity and importance, and (ii) fitting a fused network’s neurons to the cluster centroids derived from these groups. Two algorithmic variants are presented:\n\n- Hungarian Fusion (HF): a one-to-one neuron matching method for models with identical widths, formulated as a linear sum assignment problem.\n- K-means Fusion (KF): a general-width method that clusters neurons across models using importance-weighted K-means.\n\nThe method leverages saliency scores (Conductance and DeepLIFT) to guide both grouping and fitting steps, aiming to emphasize important neurons during fusion. Experiments are performed on CNN (VGG) and ViT architectures across IID, Non-IID, and sharded data settings, with and without fine-tuning, claiming consistent improvements over baseline fusion methods such as Git-Rebasin and OTFusion.\n\nThe paper also claims partial theoretical guarantees for the linear case and reports practical improvements on mid-scale datasets such as CIFAR-100 and Tiny-ImageNet."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The decomposition of the fusion objective into grouping and approximation stages is a useful formalization. It reframes neuron matching as a clustering-and-refitting process, connecting prior permutation and alignment-based methods to a broader optimization viewpoint.\n- Integrating saliency measures to inform neuron grouping and weighting adds a novel, biologically-inspired dimension to the fusion literature, which has largely focused on structural similarity rather than neuron importance.\n- The modular structure could inspire broader frameworks for neuron-level model alignment and repair.\n- The notion of importance-weighted neuron grouping could be extended to parameter-efficient transfer and federated learning settings.\n- Even if limited by data reliance, the approach provides a pathway toward more interpretable fusion via neuron attribution."}, "weaknesses": {"value": "- **Title clarity**: Since “interpolation” is a standard aggregation term in the model merging literature, consider renaming to reflect the neuron-centric mechanism or saliency usage.\n- While the neuron clustering view is fresh, the method seems to **heavily build on Git-Rebasin’s activation matching** and other alignment-based model fusion works (e.g., _Ainsworth et al., Git Re-basin: Merging Models Effectively, 2023_). The contribution mainly lies in incorporating saliency and centroid fitting, rather than introducing an entirely new paradigm. Claims of generality to “arbitrary differentiable levels” are not supported, since the derivations rely on layer-wise alignment and assume comparable architectures.\n- **Fusion-data dependence**: Both neuron grouping (activations) and weight refitting (non-linear levels) depend heavily on a “fusion dataset.” However, no ablation explores sensitivity to data quantity or distribution. This weakens claims of applicability to federated learning, where shared data are scarce.\n- **Baselines**: Missing strong contemporary baselines (e.g., permutation+LS fusion, repair/rescaling methods, and data-free fusion). Ensembles outperform MIN in non-IID regimes.\n- **Scalability**: Experiments are confined to VGG and ViT-small; no scaling to large models (e.g., ResNet-50, ViT-B/16) or multi-model setups (K>4). Runtime and memory comparisons lack depth."}, "questions": {"value": "1.  How does performance vary as fusion data become more limited or non-IID? Can the approach be adapted for data-free or privacy-restricted settings?\n2. Does the alternating grouping/fitting procedure converge empirically? Are there oscillations in neuron assignments or objective values?\n3. How stable are the importance weights across different baselines and input samples? Does randomizing them degrade performance significantly?\n4. Are gains mainly from refitting the classification head?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ETY5l76LCC", "forum": "ICz7ymsRTd", "replyto": "ICz7ymsRTd", "signatures": ["ICLR.cc/2026/Conference/Submission21863/Reviewer_SE4e"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21863/Reviewer_SE4e"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21863/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761947048849, "cdate": 1761947048849, "tmdate": 1762941959588, "mdate": 1762941959588, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a neuron-centric model fusion framework that casts fusion as a layer-wise representation matching problem. The method operates in two stages per level: (1) a \"grouping\" step that clusters concatenated neuron outputs from base models to define a set of target representations (cluster centers), and (2) an \"approximation\" step that optimizes the fused model's current level to match these targets. The objective function (Eq. 1) is novel in its explicit incorporation of neuron attribution scores (e.g., Conductance, DeepLIFT) to weight the importance of matching specific neurons. The authors introduce two main variants: Hungarian Fusion (HF) for 1:1 matching of equal-width models and K-means Fusion (KF) for the general case, with both linear and gradient-based optimization schemes for the approximation step."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed framework is intuitive, flexible, and moves beyond simple weight permutation (like OTFusion or Git Re-Basin ) by actively fitting a new sub-network to an intermediate target representation\n- The incorporation of neuron attribution scores into the fusion objective is a novel contribution, theoretically allowing the process to prioritize salient features\n- The empirical results are strong, especially in zero-shot and non-IID \"sharded\" scenarios (Table 2, 15), where the method (KF Gradient) succeeds while established baselines like OTFusion fail completely\n- The ResNet compression experiment (Table 7) is a compelling demonstration of the method's strength, showing a >2x accuracy improvement over standard Knowledge Distillation using the same limited data"}, "weaknesses": {"value": "- The gradient-based variants, which produce the best results, are admittedly sensitive to hyperparameters. The paper provides two starkly different configurations (Setting 1 vs. Setting 2, Table 9)  without a clear ablation or principle for choosing between them. This significantly undermines the method's robustness and practicality\n- The central novelty claim—incorporating attribution scores —is weakly supported by the main experimental results. For the flagship ViT experiments (Table 15, 16), the gains from using Conductance or DeepLIFT over uniform weights are consistently marginal or non-existent. For example, in Table 16 (fine-tuned), KF Gradient Uniform (75.2%) performs identically to DeepLIFT (75.2%) and is on par with Conductance (75.4%). The paper fails to analyze why the scores help significantly in some niche cases (VGGs, Table 13 ) but not in the main ViT results.\n- In the challenging sharded setups (Table 2, 15), standard Knowledge Distillation (KD) and Linear Probing (LP) are surprisingly strong baselines that the paper does not sufficiently contextualize. For the 4-way ViT split (Table 15), KF Gradient (43.5%) is only marginally better than KD (40.3%). The authors state that their \"Setting 2\" (used for most non-IID models) is similar to LP, as most gains occur at the head. This suggests the complex, layer-wise grouping may be superfluous in these settings.\n- The paper dismisses FedMA as a \"non-zero-shot\" baseline because it requires \"retraining... after the alignment of every layer\". However, the proposed \"Gradient version of KF\" also performs optimization (i.e., retraining) at every level via SGD. This distinction seems artificial, and the lack of comparison to FedMA is a clear omission.\n- The runtime comparison (Table 10) shows the linear variants (HF/KF Linear) are 1-2 orders of magnitude slower (14x-83x) than OTFusion. This makes them practically unusable as fast alternatives, while the gradient-based methods are presumably even slower."}, "questions": {"value": "- The empirical benefit of attribution scores is marginal in key ViT results (Table 15, 16). Can you provide a clear hypothesis for when these scores are beneficial and why they fail to provide significant gains for ViTs?\n- Given that \"Setting 2\" (used for most non-IID models ) is described as degenerating to Linear Probing, does this imply the complex layer-wise grouping is unnecessary for these scenarios?\n- How does the proposed gradient-based KF, which optimizes weights level-by-level, fundamentally differ in methodology and computational cost from FedMA, which you dismissed for its layer-wise retraining?\n- The ResNet compression experiment (Table 7)  is strong, but it compares against standard KD. How does your method compare to more advanced, layer-wise distillation techniques?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qrxTFtgYPR", "forum": "ICz7ymsRTd", "replyto": "ICz7ymsRTd", "signatures": ["ICLR.cc/2026/Conference/Submission21863/Reviewer_kkpb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21863/Reviewer_kkpb"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21863/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762014999251, "cdate": 1762014999251, "tmdate": 1762941959147, "mdate": 1762941959147, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}