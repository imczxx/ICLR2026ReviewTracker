{"id": "iD8uUeCBy5", "number": 23461, "cdate": 1758344133403, "mdate": 1759896813755, "content": {"title": "Steering Vector Transfer via Orthonormal Transformations and Semantic Pairing", "abstract": "Steering vectors—directions in activation space encoding behavioral traits like formality or creativity—enable fine-grained control over language model outputs but must be regenerated for each new model, creating deployment barriers. We present a method for transferring these vectors between different language models by learning structure-preserving transformations while matching corresponding text pairs across models. Our approach achieves strong alignment (0.50-0.56 cosine similarity, where 1.0 represents perfect alignment and 0.0 represents random chance) across all model pairs tested. Crucially, we demonstrate that semantic pairing—ensuring each text contrast is matched across models during training—improves transfer performance by 72%: proper pairing achieves 0.529 cosine similarity compared to 0.308 with shuffled pairs within traits and 0.00 with random pairing across traits. We evaluate our method across 26 behavioral traits on three architecturally distinct models (Gemma-7B, LLaMA-3-8B, and Mistral-7B), using dimensionality reduction to handle their different hidden dimensions. Our results provide evidence for the Platonic Representation Hypothesis, showing that different language models encode behavioral preferences in similar geometric structures. This enables practical reuse of curated steering vectors across model families and advances our understanding of how neural networks represent human preferences.", "tldr": "Evidence for Platonic Hypothesis: LLMs share behavioral geometry, enabling steering vector transfer via rotations+scaling. Semantic pairing critical: 0.31→0.53 vs 0.00 without it.", "keywords": ["steering vectors", "cross-model transfer", "representation alignment", "Procrustes analysis", "semantic pairing", "language models", "behavioral control", "linear transformations", "orthonormal transformations"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ac6578e001a0865ea4b945e6b2f4897787c13f21.pdf", "supplementary_material": "/attachment/c2008e3d9469ce845cfee3302c7f900806157ec2.zip"}, "replies": [{"content": {"summary": {"value": "This paper studies the cross-model transferability of steering vectors, which is achieved using the proposed orthonormal transformations. To ensure an accurate transformation, the authors employ the semantic pairing (i.e.,  row i in the source matrix corresponds to the exact same text contrast pair in the target matrix). The authors experimentally show that: 1) cross-model transferability is possible, 2) semantic pairing enhances transferability, and 3) objective linguistic traits transfer better than subjective ones."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. A orthonormal-transformation-based method for cross-model transferability of steering vectors is proposed\n2. The authors show that objective linguistic traits transfer better than subjective ones."}, "weaknesses": {"value": "The paper's primary contribution appears to be significantly diminished by an incomplete review of prior studies. A body of existing literature has already explored the transferability of steering vectors, including both cross-lingual [1] and cross-model scenarios [2].\n\nSpecifically, previous research[2] has established that simple linear transformation can effectively enable behavioral control and steering vector alignment across diverse LLMs. Such transformations can handle various traits and even lead to emergent weak-to-strong generalization. Consequently, the method proposed, which imposes an orthogonality constraint on linear transformations, should be framed as an incremental refinement rather than a very novel method.\n\nIn this light, the paper's contributions are more limited than claimed. The finding that objective linguistic traits exhibit superior transferability is an interesting observation, but it is derived exclusively under the orthonormal assumption, and its broader applicability remains unverified. Most critically, the concept of \"semantic pairing\" is presented as a significant insight. However, maintaining correspondence between input and output variables is a standard and essential precondition for any constrained optimization or supervised learning task. For example, it is axiomatic that one must preserve the integrity of data-label pairs (e.g., (x, y)) during model training. Therefore, highlighting the performance drop from \"shuffling labels\" (i.e., Not using semantic pairing)—a methodologically unsound practice—serves more as a strawman comparison than as a validation of a novel principle.\n\nReference\n1. https://aclanthology.org/2024.findings-emnlp.96.pdf\n2. https://aclanthology.org/2025.acl-long.185.pdf"}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sEChzAv1pj", "forum": "iD8uUeCBy5", "replyto": "iD8uUeCBy5", "signatures": ["ICLR.cc/2026/Conference/Submission23461/Reviewer_M6ra"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23461/Reviewer_M6ra"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23461/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761622756329, "cdate": 1761622756329, "tmdate": 1762942670809, "mdate": 1762942670809, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the cross-model transfer of steering vectors between different LLM families. The method aligns paired texts across models and learns an orthonormal map to transport steering directions. While the paper introduces a compelling approach to alignment, it focuses primarily on the construction of the mapping without adequately validating how effective the alignment is in practice."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper addresses an interesting problem of transferring steering vectors across models, which not only has practical implications but also provides evidence toward a universal geometry in LLM representations.\n- Evaluation is conducted on a broad dataset covering 26 traits, demonstrating the method’s versatility.\n- The proposed method is simple and easy to implement, which enhances its reproducibility and accessibility."}, "weaknesses": {"value": "- Prior work on transferring or aligning representations and steering vectors is not sufficiently discussed (e.g., [1]). At minimum, the paper should include a comparative summary and a results table against representative baselines such as orthogonal Procrustes, unconstrained linear maps, CCA/PLS, and causal-tracing/latent-alignment variants.\n- Although the claims span Gemma, LLaMA, and Mistral model families, experiments are only conducted on Gemma-7B-Instruct, LLaMA-3-8B-Instruct, and Mistral-7B-Instruct. To better support claims of generality, at least one larger model (e.g., 13B/30B/70B), one smaller model (e.g., 2B/3B), and one base (non-instruction-tuned) variant should be included to assess whether instruction tuning contributes significantly to alignment.\n- The current evaluation focuses on geometric fit, but does not directly assess the downstream effectiveness of transferred steering. The paper should include an analysis of performance degradation (if any) between original and transferred steering vectors. Without behavioral validation, it remains unclear whether the alignment is functionally meaningful, or whether any alignment exists at all. The method relies on a strong assumption that hidden state geometry is similar across models, which is not empirically validated.\n- The paper states that the transformation in Eq. 1 is rotational and scaled, but can $R$ also represent a reflection? What would be the implications if this were the case?\n- Section 5.2 selects the sixth-to-last layer across all models (lines 324–326) without any justification. Clarification or ablation over different layers would strengthen the choice.\n- Text in Figure 1 is too small and difficult to read. The visualization should be made clearer and more self-contained; currently, it depends too much on the main text for interpretation.\n- References to the appendix are not hyperlinked, which hinders navigation.\n- How was class imbalance handled during training and evaluation? Could PCA be biased toward dominant traits due to data imbalance?\n- Please report the memory complexity of the full pipeline, including hidden state extraction and PCA computation.\n- A cosine similarity around 0.5 may not be intuitively meaningful. Can the authors explain how to interpret this magnitude in context? What constitutes a “good” similarity score in this setting?"}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ph1KVotbth", "forum": "iD8uUeCBy5", "replyto": "iD8uUeCBy5", "signatures": ["ICLR.cc/2026/Conference/Submission23461/Reviewer_JrJq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23461/Reviewer_JrJq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23461/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980151447, "cdate": 1761980151447, "tmdate": 1762942670556, "mdate": 1762942670556, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "They transfer steering vectors across models from different families with different architectures. In particular, they first PCA the steering vectors to get a set of principal components, then learn the transfer in PC space, then reconstruct the final steering vector. They also claim that semantic pairing is important for transfer performance. They use the cosine similarity between the transferred vector and the steering vector if it was done on the new model, and find that they can get a cosine similarity of up to 0.56."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "* Doing steering vector transfer through Principal Components first is an interesting idea.\n* They demonstrate their idea across several model families."}, "weaknesses": {"value": "* Steering vector transfer has been done before (e.g. by [Huang et al. (2025)](https://arxiv.org/abs/2501.02009v2)) and is not particularly novel. \n* The only metric used in this paper to measure transfer is cosine similarity. What does a cosine similarity of 0.5 mean? Is it twice as good as 0.25? Ultimately, since steering vectors are used to influence model behavior, it is insufficient to only use cosine similarity to measure the effectiveness of transfer. You also need to look at steering outcomes. \n* There is also a lack of comparable baselines in terms of methods. For example, semantic pairing might be only relevant to this proposed method where it is sensitive to individual prompts."}, "questions": {"value": "Clarifications\n* How is this work meaningfully different from Huang et al. (2025)? \n* The steering vector here is calculated as differences between hidden states of a contrast pair (Line 186). Can I clarify that this means that $n$ in line 205 is the number of total contrast pairs then, and not the number of traits? \n* Follow-up Question: If so, doesn't this mean that the learned transformation is sensitive to the prompt pairs (the $n$ dimension), which naturally explains why semantic pairing is important? With a more typical method like differences-in-mean, where you first take the mean vector across the set of prompts, the semantic pairing finding would not apply.\n\nFeedback\n* The Figure fonts are far too small to be read.\n* Most of the citations should be done in parentheses with `citep{}`.\n* The font is different from the standard ICLR submission, which makes it somewhat harder to read.\n* L176: ...is detailed in Section 3 > Should this be 4?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sKlrilNKl7", "forum": "iD8uUeCBy5", "replyto": "iD8uUeCBy5", "signatures": ["ICLR.cc/2026/Conference/Submission23461/Reviewer_sgkg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23461/Reviewer_sgkg"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23461/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993168622, "cdate": 1761993168622, "tmdate": 1762942670319, "mdate": 1762942670319, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors demonstrate the transfer of steering vectors of behavioral traits between the models using a method based on dimensionality reduction and procrustes alignment. They compare three modes: 1) sentence-pairing, 2) trait-level pairing, and 3) trait scrambling and report the cosine similarity of the transferred vector to the target vector. The cosine similarity is the highest at the sentence level matching, compared to trait pairing only, and the scrambling gives a near-zero. They compare the performance per trait, showing that objective traits are better transferred than the subjective ones."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Well designed experiments: good baseline comparison on multiple levels: trait matching and full scrambling. \n\n2. Empirical difference is convincing: A Clear relative difference in cosine similarities between the comparing modes. \n\n3. Extensive dataset : The Authors curated and additionally collected a dataset for diverse behavioral traits."}, "weaknesses": {"value": "1. Cosine similarity as the only metric. \nI am mostly concerned that a mere geometric measure of transferred vector (cosine similarity) might be not significant for actual ‘behavior transfer’ which is the ultimate goal.. I agree that there is a clear empirical difference in the cosine similarity from the baseline, but the authors do not verify the actual behavioral difference elicited by this steering vector. It is plausible that the high cosine similarity won’t guarantee the intended behavioural shift. Direct evidence on the behavioral change by injecting the transferred vector is needed to support what the authors claim and show the validity of the proposed approach. In a similar vein, there is a comparative difference in cosine similarity between different methods, but this might not be reflected ultimately in the generated outputs.  \n\n2. Train / test split\nThe authors use a train/test split that covers the same behavioral traits. With the semantic pairing, I think finding high cosine similarity is somewhat obvious in the current split regime. To claim representational universality, especially from the Platonic Representation Hypothesis view, I think a fairer setting would be having a disjoint train/test set of traits. I think the current method and experimental results show that identical stimuli yield partially correlated representations, rather than representational universality. And this seems to be already reflected in the result of objective behavior being much easier to transfer, since there are probably higher lexical/template similarities than true ‘traits’."}, "questions": {"value": "Here are minor questions and comments. \n\n1. How sensitive is the result to PCA ‘k’ selection?\n2. Why the 6th to last layers? How sensitive is the result to the choice of the layers for hidden states extraction?\n3. There are lots of citations that miss parentheses within the sentence. E.g. line 40\n4. It was confusing for me to understand if the steering vector is collected per sentence and used for alignment, or use the averaged/common direction of those as a single trait vector. Also, some notions are not clearly defined (e.g. line 205  - I had to infer what is dimension n ) \n5.It seems like there is a mismatch in the numbers in Figure 2c and in the text. In the figure, it is 53% and often in the text, it reports 58%.\n\n\nGiven the insufficient evidence, I’m giving 2 - I’m willing to increase my score if the authors improve/clarify the points in the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "Ethics concern was cleary mentioned in the Ethics Stament."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "kSM5nBm9LC", "forum": "iD8uUeCBy5", "replyto": "iD8uUeCBy5", "signatures": ["ICLR.cc/2026/Conference/Submission23461/Reviewer_kBxn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23461/Reviewer_kBxn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23461/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761999744347, "cdate": 1761999744347, "tmdate": 1762942669511, "mdate": 1762942669511, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}