{"id": "sJHf6crz89", "number": 17134, "cdate": 1758272596991, "mdate": 1759897194630, "content": {"title": "A Bio-Inspired Sound Localization Spiking Neural Network with Unsupervised Local Plasticity and Proximity Learning", "abstract": "In this paper, we propose an unsupervised learning principle that leverages the neuro-inspired local plasticity and biophysiological characteristics of the brain for the learning of spiking neural networks (SNNs) without labels. The learning principle synergistically combines morphological features and biochemical phenomena in the brain cortex, guiding networks to self-organize their connectivity without global error backpropagation. The learning principle is based on two local plasticity rules. One is latency-mediated spike timing-dependent plasticity, formulated by combining the original STDP with axonal latency. The other is proximity learning, mediated by the volume transmission of neurotransmitters among neurons. We successfully applied these plasticity rules to a spiking model of the avian auditory cortex and observed the self-organization of the network, which results in the accurate localization of sound sources. After being trained using interaural time difference (ITD)-encoded spike trains, the network converged to synaptic connectivity resembling the famous Jeffress model. The performance evaluation results presented demonstrate that the proposed learning principle enables the SNN to localize sound sources with accuracy and resolution higher than those achieved by supervised learning rules.", "tldr": "This paper proposes a new unsupervised local learning principle that leverages biological mechanisms for efficient learning; its integration with a bio-inspired SNN demonstrates a record-high accuracy with a human-level resolution.", "keywords": ["unsupervised learning", "spike-timing-dependent plasticity (STDP)", "spiking neural network (SNN)", "neuromorphic system", "self-organization", "sound source localization (SSL)"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d0f60ea970a51c3e29badb5d62e691de6a64a32d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents an unsupervised learning principle for spiking neural networks (SNNs) that aims to achieve biologically plausible self-organization without relying on global error backpropagation. The proposed mechanism integrates two bio-inspired rules: latency-mediated spike-timing-dependent plasticity (LM-STDP), which incorporates axonal delays into synaptic updates, and volume transmission-induced proximity learning (VT-PL), which models neurotransmitter diffusion among neighboring neurons. The method is evaluated on a sound source localization (SSL) task, demonstrating accurate one-degree localization and synaptic organization similar to the Jeffress model."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The emphasis on unsupervised local plasticity rules is valuable for both neuroscience modeling and neuromorphic computing.\n\n2. The work has clear biological grounding. It references established auditory neuroscience models and data, including Jeffress, short-term depression mechanisms, and neurophysiological constants."}, "weaknesses": {"value": "1. While LM-STDP and VT-PL are each inspired by biological phenomena, the mechanistic rationale for their combination is not clearly established. The interaction between latency effects and volume transmission remains heuristic rather than analytically or experimentally justified. It is unclear whether the synergy arises naturally or was tuned for this specific task.\n\n2. The evaluation is confined to a single SSL task. It remains uncertain whether the proposed learning rule can scale to more complex tasks, modalities, or architectures\n\n3. Although Table 2 compares accuracy and resolution with earlier SSL works, it does not include recent SNN frameworks using surrogate gradients or biologically constrained BPTT variants. Additionally, it is unclear why the proposed method is better than BPTT.\n\n4. The paper reports that all weights converge to binary extremes (0 or maximum) after 30 epochs. This all-or-none behavior may indicate an overly aggressive learning dynamic and could compromise representational flexibility or robustness under noisy inputs.\n\n5. Real auditory signals involve noise and non-stationarity. The current experiments lack robustness evaluations."}, "questions": {"value": "1. What theoretical or empirical evidence supports combining LM-STDP and VT-PL? Could one rule alone suffice for partial learning?\n\n2. Can this dual-rule learning principle be extended to more complex SSL tasks?\n\n3. How does the proposed training compare computationally to BPTT?\n\n4. How does the model behave with noisy inputs, and does learning still converge stably?\n\n5. How sensitive are the results to key parameters?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Am0HYjk7cj", "forum": "sJHf6crz89", "replyto": "sJHf6crz89", "signatures": ["ICLR.cc/2026/Conference/Submission17134/Reviewer_pspf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17134/Reviewer_pspf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17134/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761537349341, "cdate": 1761537349341, "tmdate": 1762927127664, "mdate": 1762927127664, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a SNN-based method for high-precision SSL. The backbone of the proposed SNN is similar to the conventional Jeffress model that leverages the sound signal arrival disparity between left and right receivers depending on the sound source location. The STDP learner can fine-tune the disparity between the two receivers, which allows higher angle resolutions. Further, the proposed proximity learning can encourage the neurons with low synaptic weights, which otherwise likely turn into dead neurons. As a result, the proposed method achieves higher accuracy of SSL than several emerging methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1.\tTechnical novelty. Although the learners used are renowned, the application of these learners to SSL tasks is novel.\n2.\tHigh performance: The proposed method achieves higher performance than “emerging” methods."}, "weaknesses": {"value": "1.\tLimited scientific novelty: As such, this method is based on two well-known physiological rules (STDP and proximity learning), which are just used to Jeffress model-like SNNs.\n2.\tLimited impact: This method is only for SSL, which has very limited impact. The present manuscript does not address any other application domains of larger impact.\n3.\tWeak performance evaluation: The technical evaluation of the proposed method is weak, which includes accuracy only. There are a number of aspects that should be considered, like complexity, wallclock time, parallelism, and so forth. Further, this work should be compared with the conventional works along with emerging works."}, "questions": {"value": "What are technical advantages of this work over the Jeffres model?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Zqz2LE0nst", "forum": "sJHf6crz89", "replyto": "sJHf6crz89", "signatures": ["ICLR.cc/2026/Conference/Submission17134/Reviewer_7Nrx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17134/Reviewer_7Nrx"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17134/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761795018932, "cdate": 1761795018932, "tmdate": 1762927126921, "mdate": 1762927126921, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a biologically inspired, unsupervised learning principle for spiking neural networks that combines\n- a latency-mediated STDP (LM-STDP) which explicitly leverages axonal propagation delays,\n- and a volume-transmission proximity learning (VT-PL) mechanism that models neurotransmitter spillover to neighboring neurons."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The results are impressive, demonstrating 100% accuracy with a 1-degree resolution, outperforming all four supervised counterparts used for comparison. The biological plausibility and unsupervised nature make it highly relevant for energy-efficient, on-chip applications."}, "weaknesses": {"value": "The paper is well written, with clear biological motivation. Yet, it is unclear if the learning process is entirely unsupervised, since I read in line 342: \"The results are impressive, demonstrating 100% accuracy with a 1-degree resolution, outperforming many supervised counterparts. The biological plausibility and unsupervised nature make it highly relevant for energy-efficient, on-chip applications.\" This implies that during training, the system knows which NL neuron should fire (the \"expected winner\") for a given ITD. This is a form of weak supervision or a structured input paradigm.\n\nThe paper reports a perfect accuracy, it is unclear however how the proposed model would perform under realistic acoustic settings with noise, reverberation. Besides, I would recommend to add a discussion on scalability and generalisation, since the network is evaluated on a very specific task with synthetic spike pairs with controlled ITD/ILD and firing rates."}, "questions": {"value": "What is the exact of supervision? This should ABSOLUTELY be clarified if the paper is accepted.\n\nCould you discuss the robustness, scalability, and generalisation capabilities of the presented model?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DOIMtGSytV", "forum": "sJHf6crz89", "replyto": "sJHf6crz89", "signatures": ["ICLR.cc/2026/Conference/Submission17134/Reviewer_C6N5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17134/Reviewer_C6N5"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17134/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927939396, "cdate": 1761927939396, "tmdate": 1762927126459, "mdate": 1762927126459, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to provide a bio-inspired solution to sound location via two main ideas: a latency-mediated spike timing-dependent plasticity rule, and the volume transmission of neurotransmitters."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**Pros**:\n- Being biologically inspired and plausible makes this work pretty interesting; \n- The proposed solution is unsupervised, and offers good performance for sound localization."}, "weaknesses": {"value": "**Cons**:\n\n- One of the two key ideas, a latency-mediated spike timing-dependent plasticity rule, is not fully clearly described. The authors should provide a better motivation and a deeper insight of this learning rule. It seems to be designed specifically for sound localization based on the Jeffress model.\n\n- The other idea,  use of the volume transmission of neurotransmitters, is a simple twist. It amounts to redirecting part of the total postsynaptic current to nearby neurons. How is going to improve the performance? Any insights? \n\n- The application space of the proposed techniques is pretty narrow; they seem to work only for one application and one model (Jeffress model); The authors should discuss the broader generality of their approach."}, "questions": {"value": "- While both proposed ideas are somewhat biologically inspired, their relevance and insights regarding the learning process are not missing. The authors should provide more in-depth discussions to justify their design choices."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VIy0k6VjD0", "forum": "sJHf6crz89", "replyto": "sJHf6crz89", "signatures": ["ICLR.cc/2026/Conference/Submission17134/Reviewer_Wcen"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17134/Reviewer_Wcen"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17134/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761954825025, "cdate": 1761954825025, "tmdate": 1762927126166, "mdate": 1762927126166, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}