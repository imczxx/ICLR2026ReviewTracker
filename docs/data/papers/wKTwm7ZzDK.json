{"id": "wKTwm7ZzDK", "number": 21088, "cdate": 1758313650361, "mdate": 1759896942667, "content": {"title": "Adaptive Friend Agent: Personalized Multi-User Memory for Conversational AI", "abstract": "Most conversational AI systems today are designed to engage a single user, which limits their effectiveness in real-world, multi-user settings. This work presents the Adaptive Friend Agent (AFA), a personalized conversational agent framework that supports long-term, user-specific interaction across multiple individuals. AFA integrates off-the-shelf speaker recognition to distinguish users by voice, retrieves relevant conversational memory from a per-user vector database, and generates personalized responses using a large language model (LLM). To train and evaluate the system, Personalized Agent chaT (PAT) is introduced, a large-scale synthetic dataset simulating human-AI persona-grounded conversations. PAT includes over 58,000 dialogue turns covering diverse scenarios and user profiles. Experimental results show that AFA, when fine-tuned using PAT with the LLaMA-70B model, outperforms strong commercial and ablated baselines on BLEU and ROGUE metrics. Ablation studies confirm the critical role of the memory module and speaker identification in supporting coherent and personalized dialogue. AFA represents a practical step toward scalable conversational agents capable of adapting to individual users in shared environments.", "tldr": "", "keywords": ["Multi-user personalization", "Memory-augmented conversational agents", "Datasets and benchmarks", "Large language models (LLMs)"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/039bde48898ea392b5295570d816f7fe528c9f90.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors introduce Adaptive Friend Agent (AFA) - a system for LLM conversation in a multi-user environment. They base AFA on speaker identification + speaker specific conversation history and speaker s pecific memory.\n\nThey create a synthetic dataset called PAT with (persona + user query + contextualized user response) with Llama 405B. They show that existing LLMs benefit from using persona to generate relevant responses and show that fine-tuning a LLAMA model on PAT shows the best performance on PAT compared to non-finetuned models."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper covers an original field : how to adapt a LLM to a multi-user environment\n- Their speaker identification + persona update/memory update / persona specific responses is well engineered and adapts well to real-world use cases"}, "weaknesses": {"value": "- claim \"we create [...] the first ever dataset that contains dialogue between AI and a Human\" -> this is debatable as the dataset is synthetic, there are existing human-AI interaction datasets such as OpenAssistant Conversations or Tulu SFT dataset with user/assistant pairs for LLM SFT\n- the approach of using speaker identification + per-speaker history/persona is sound - but it is not compared against any baselines. The experiment/comparison is comparing existing LLMs on generating responses on the synthetic dataset (generated with LLAMA). \n- The fine-tuned LLAMA model is apparently fine-tuned on the same dataset that it is evaluated on - putting the other models at a disadvantage. \n- Performance on the persona+query+response benchmark is unrelated to the multi-user system that's described earlier, it is a single user task.\n- The models are evaluated based on BLEU and ROUGE metrics, which tend to measure token overlap -  since the dataset is synthetic, this will bias results towards giving a higher score to the model that generated synthetic responses (LLAMA)\n- There is one experiment for persona vs no-persona responses but no experiment regarding adaptive memory and no experiment regarding correctly identifying speakers multi-speaker environments."}, "questions": {"value": "Could you please provide more details on how the LLAMA model was fine-tuned and evaluated?\nHow does adaptive memory work in your system? What is the impact of using dynamic memory vs no memory?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "LSmjqYkCpN", "forum": "wKTwm7ZzDK", "replyto": "wKTwm7ZzDK", "signatures": ["ICLR.cc/2026/Conference/Submission21088/Reviewer_mNQc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21088/Reviewer_mNQc"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21088/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761509990542, "cdate": 1761509990542, "tmdate": 1762941247159, "mdate": 1762941247159, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a dialogue agent designed to support user-specific, long-term interactions across multiple users. To achieve this, the system maintains a user memory bank that stores user-specific history. For each user, the bank stores a summarized long-term memory and the complete most recent ten conversations, along with the extracted user persona. The model employs an off-the-shelf speaker identification module to distinguish among users and, accordingly, construct or access each user’s memory and persona. Dialogue history summarization and persona extraction are implemented using an off-the-shelf commercial LLM (GPT-4o).\n\nFor response generation, the agent incorporates both the user-specific persona and relevant historical information retrieved from the corresponding memory. To further enhance performance, the authors introduce a persona-oriented dataset named Personalized Agent chaT (PAT), curated using large language models (GPT-4o and LLaMA-405B). They construct diverse personas by extracting and extending personality traits from an existing dataset (MSC) and automatically generate question–answer pairs under LLM-generated scenarios. Experimental results show that an LLaMA-70B model fine-tuned on PAT outperforms several proprietary models on the PAT test set."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "i. The idea of maintaining a user-specific memory bank for long-term, personalized dialogue has clear practical application value. The paper’s effort to implement such a system is meaningful.\n\nii. The curation of a new persona dataset generated under diverse scenarios provides a potentially useful resource for future studies."}, "weaknesses": {"value": "i. In its current form, the paper does not meet the quality standards required for publication due to significant issues in writing, formatting, and overall presentation. These include:\n\n- References are not properly formatted. Citations should be enclosed in parentheses, but are currently inconsistent throughout.\n\n- Lines 116–125 are a paraphrased version of lines 98–107. This repetition appears to be an editing mistake.\n\n- Table 3, which presents the main experimental results, is incomplete, with several columns missing, and it exceeds the confined text area.\n\n- There is a reference typo in line 215 that should be corrected.\n\nii. Lack of novelty and, in its current form, reads more like an implementation report rather than a research paper.\n\nAlthough the authors present a new dataset, there is little to suggest an original contribution to the field in terms of system design or methodology. They claim their system is long-term and user-specific. However, summarization of dialogue as long-term memory is not new [1]. For user-specific, they just use an off-the-shelf speaker identification module to distinguish among users and maintain a user database. This approach seems more like an engineering solution rather than a novel research contribution.\n\niii. Lack of Alignment with Main Motivation and Insufficient Evaluation"}, "questions": {"value": "While the curation of a new persona dataset under diverse scenarios is a positive contribution, its relevance to the paper's core motivation—“building a long-term, user-specific system”—is unclear. The dataset does not include long-term dialogue history or multi-user scenarios, which are essential components of the paper's claimed objective. Instead, the dataset primarily consists of common persona data with a variety of personas and persona-based dialogues, which may not fully support the goal of a long-term, user-specific system.\n\nFurthermore, the experiments do not adequately evaluate the quality and effectiveness of the dataset. The models were tested on the in-distribution dataset, and the performance of the fine-tuned models is unsurprising. A model fine-tuned specifically on the training data will naturally outperform a zero-shot model. Additionally, using metrics like BLEU or ROUGE can only evaluate the model’s ability to mimic language patterns in the training data rather than its ability to capture meaningful, long-term user interaction. Thus, the evaluation lacks a clear demonstration of the dataset’s utility in the context of the paper's proposed system.\n\n[1] https://arxiv.org/abs/2308.15022"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ij6i0gWhOX", "forum": "wKTwm7ZzDK", "replyto": "wKTwm7ZzDK", "signatures": ["ICLR.cc/2026/Conference/Submission21088/Reviewer_fHka"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21088/Reviewer_fHka"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21088/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761808530928, "cdate": 1761808530928, "tmdate": 1762941246862, "mdate": 1762941246862, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents two core contributions: (1) the Adaptive Friend Agent (AFA), a retrieval-augmented generation (RAG) pipeline that produces personalized dialogues, and (2) a persona-rich dataset bootstrapped from MSC.\n\nAFA identifies each interlocutor by speaker ID, compresses the last 10 turns into a concise memory query with GPT-4o, retrieves relevant historical snippets from an external store, and fuses them into the live context.\n\nTo build the dataset, the authors extract speaker personas from the raw conversations, instantiate them in diverse interaction scenarios, prompt GPT-4o to generate new dialogues, and automatically validate the results.\n\nFine-tuning Llama-70B on this corpus yields responses that surpass those of closed-source LLMs on BLEU and ROUGE, demonstrating the value of both the RAG pipeline and the curated data."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. This paper curated a mutli-turn dialogue dataset."}, "weaknesses": {"value": "1. The approach lacks novelty: RAG, memory mechanisms, and LLM-synthetic data are already standard in both research and industrial settings.  \n2. Experiments rely solely on BLEU/ROUGE metrics that are now considered inadequate for assessing dialogue quality, coherence, or persona consistency.  \n3. Result analysis is minimal; the paper offers almost no ablation, error inspection, or discussion of what actually drives “personalized” generation.  \n4. Speaker ID is introduced but never justified; simply tagging utterances with an ID adds no textual personalization and falls outside the paper’s stated focus on content-level adaptation.\n5. The appendix reference on L215 is broken, and the Table on L368 exceeds page width."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "5QCQC6Gveh", "forum": "wKTwm7ZzDK", "replyto": "wKTwm7ZzDK", "signatures": ["ICLR.cc/2026/Conference/Submission21088/Reviewer_Gat5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21088/Reviewer_Gat5"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21088/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761835329335, "cdate": 1761835329335, "tmdate": 1762941245759, "mdate": 1762941245759, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Adaptive Friend Agent, a modular framework integrating speaker recognition, personalized memory, and LLM-based dialogue generation to support multi-user conversational systems.\nIt also introduces a synthetic dataset, Personalized Agent chaT, for model training and evaluation.\nThe paper claim that AFA, fine-tuned from LLaMA-70B, surpasses commercial and ablation baselines on BLEU/ROUGE metrics, and that memory and speaker identification are key contributors to its performance."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The system targets realistic multi-user environments (e.g., families, shared devices), combining identity detection and personalized response.\n2. The topic is very interesting and meaningful.\n3. The paper clearly describes four components: speaker identification, dynamic user profiles, persona synchronizer, and adaptive response generator, supported by detailed figures and workflow diagrams.\n4. Table 3 shows measurable BLEU/ROUGE gains when enabling adaptive persona fine-tuning for LLaMA-70B."}, "weaknesses": {"value": "1. Both fine-tuning and evaluation rely on the synthetic PAT dataset generated by LLMs. This raises serious data leakage and overfitting risks, the model may simply learn to mimic the synthetic data distribution rather than generalize.\n2. The architecture is an incremental combination of known components: pretrained speaker recognition, top-k semantic memory retrieval, and LLM generation. There is no new algorithmic innovation or theoretical insight separating AFA from prior “memory-augmented personalized LLM” work.\n3. The paper promises “Our code at Link” but provides no actual URL."}, "questions": {"value": "1. Do you have real human multi-speaker audio dialogues for evaluation? What is the actual speaker recognition error rate and its downstream effect?\n2. When will code, models, and data be released?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zWiycAPmm9", "forum": "wKTwm7ZzDK", "replyto": "wKTwm7ZzDK", "signatures": ["ICLR.cc/2026/Conference/Submission21088/Reviewer_nKcV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21088/Reviewer_nKcV"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21088/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761849406225, "cdate": 1761849406225, "tmdate": 1762941236860, "mdate": 1762941236860, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Adaptive Friend Agent (AFA), a modular conversational method for multi-user personalization. AFA uses (i) speaker identification (SpeechBrain embeddings) to route utterances to a user, (ii) a Dynamic User Profile Store with short-term “temporary” buffers and long-term “permanent” summaries, (iii) a Persona Synchronizer that continually updates user traits from interactions, and (iv) an Adaptive Response Generator (LLM) conditioned on retrieved, per-user memories.\nTo support training/evaluation, the authors introduce PAT, a synthetic dataset of 50k persona-grounded query–response pairs across 12 everyday scenarios (e.g., travel, shopping, emotional support)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper presents a clear pipeline (speaker ID → memory → persona update → adaptive generation), which is conceptually coherent and easy to follow. This makes the system replicable and highlights the interaction between perception and personalization components.\n\nThe dual-layered memory (temporary and permanent) is a thoughtful design that balances short-term contextual relevance with long-term user modeling. This mirrors how memory compression is treated in recent personalized dialogue agents.\n\n\nThe introduction of PAT significantly enriches evaluation resources for persona-grounded dialogue. Its multi-domain coverage and persona variety demonstrate commendable effort in dataset curation and scalability. Large synthetic corpus spanning 12 scenarios and 133 personas, with basic LLM-as-judge validation."}, "weaknesses": {"value": "The paper positions AFA against: (1) multi-session personalization (MSC) and memory-augmented dialogue (MemoryBank, MemoChat), and (2) persona-based chat (PersonaChat, RAP), arguing novelty in simultaneous multi-user handling via speaker recognition plus per-user memory stores that evolve over time.  The framing is reasonable; however, the empirical comparison is largely intra-system (AFA variants) and across base models rather than against recent multi-user assistants beyond citations, limiting external validity.\n\n\nSince both training and testing rely on the PAT dataset generated via LLM prompting, results may reflect distributional alignment rather than genuine generalization. A real-user or human-annotated evaluation is essential for stronger validity.\n\nThe evaluation metrics (BLEU, ROUGE, Distinct) primarily measure surface overlap and lexical diversity, not deeper personalization qualities such as factual recall of user traits or persona consistency.\n\nAlthough the abstract claims that memory and speaker ID modules are critical, the paper lacks detailed ablation studies, statistical variance, and error analyses to substantiate this claim quantitatively.\n\nThe paper stores and updates per-user voice embeddings and persona data but does not address data retention policies, consent mechanisms, or safeguards. This is an omission for deployable personalization systems."}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety"]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7qzkuNjFuc", "forum": "wKTwm7ZzDK", "replyto": "wKTwm7ZzDK", "signatures": ["ICLR.cc/2026/Conference/Submission21088/Reviewer_Dtqe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21088/Reviewer_Dtqe"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission21088/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966850894, "cdate": 1761966850894, "tmdate": 1762941176439, "mdate": 1762941176439, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}