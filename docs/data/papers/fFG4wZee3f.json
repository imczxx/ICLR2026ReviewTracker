{"id": "fFG4wZee3f", "number": 4528, "cdate": 1757698338635, "mdate": 1759898028141, "content": {"title": "Risk Phase Transitions in Spiked Regression: Alignment Driven Benign and Catastrophic Overfitting", "abstract": "This paper analyzes the generalization error of minimum-norm interpolating solutions in linear regression using spiked covariance data models. The paper characterizes how varying spike strengths and target-spike alignments can affect risk, especially in overparameterized settings. The study presents an exact expression for the generalization error, leading to a comprehensive classification of benign, tempered, and catastrophic overfitting regimes based on spike strength, the aspect ratio $c=d/n$ (particularly as $c \\to \\infty$), and target alignment. Notably, in well-specified aligned problems, increasing spike strength can surprisingly induce catastrophic overfitting before achieving benign overfitting. The paper also reveals that target-spike alignment is not always advantageous, identifying specific, sometimes counterintuitive, conditions for its benefit or detriment. Alignment with the spike being detrimental is empirically demonstrated to persist in nonlinear models.", "tldr": "", "keywords": ["Random Matrix Theory", "Spiked Model", "Linear Regression", "Generalization"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c5cea082bee1e66b6a4fa9e07cc1dfe0abb24391.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper analyzes the performance of min-norm interpolators under a spiked covariance assumption for the data in high-dimensional linear regression. The authors consider the asymptotic proportional regime where both $n$ (number of samples) and $d$ (input dimension) diverge to infinity with a fixed aspect ratio $c = d/n$, and specifically examine scenarios where the spike in the covariance is correlated with the teacher vector. \nAfter deriving the limiting value of the excess risk, the authors classify different conditions leading to benign, tempered, or catastrophic overfitting in the overparameterized regime. The main theoretical finding is that increasing spike correlation can, counterintuitively, induce catastrophic overfitting. \nThe authors provide limited empirical evidence suggesting that analogous phenomena appear in 3-layer ReLU networks under similar data conditions."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper presents several technical strengths:\n\n- The paper shows a high degree of mathematical rigor: The theoretical analysis appears sound, with the novel results properly recovering the known results from Hastie et al. 2020 as special cases. The generalization to spiked covariance models beyond isotropic settings is a natural extension of existing literature.\n\n- The systematic classification of overfitting behaviors (benign, tempered, catastrophic) across different parameter regimes provides a detailed characterization of the problem space. Table 1 is especially effective in summarizing the different cases.\n\n- The paper uncovers counterintuitive yet interesting behaviors, particularly that alignment with the spike is not universally beneficial and that increasing spike strength can worsen generalization before improving it."}, "weaknesses": {"value": "While I recognize the substantial theoretical effort invested in this work, I believe the paper in its current form has some significant presentation and validation issues that limit its readability and impact, especially for the broader machine learning community not only interested in theory.\n\nMy main concerns are the following:\n\n1. The paper lacks in accessibility. The paper prioritizes mathematical formalism over intuitive explanations, with limited discussion of *why* these behaviors emerge or *when* practitioners should expect them. \nFor a venue like ICLR that serves a diverse ML community, the paper should consider a more accessible presentation alongside mathematical rigor. \n   \n   *Specific recommendation*: Each major theorem should be followed by an intuitive explanation section that uses simple examples or visualizations to explain the underlying mechanisms. For instance, why does increasing spike strength lead to catastrophic overfitting before benign overfitting? What is the intuitive mechanism?\n\n2. The data model (first display on page 1) represents a significant simplification - a rank-one spike plus isotropic noise. While mathematically tractable, it is unclear whether this captures realistic data structures encountered in modern machine learning. Real data show both hierarchical structure and other types of correlation with the ground truth rule. Additionally, real data have been shown to follow power law covariance structure.\n   \n   Moreover, even from a purely theoretical perspective, the way non-linearity and model misspecification are captured through the two coefficients $\\alpha_Z$ and $\\alpha_A$ (which differentially weight the spike and bulk components) is quite restrictive. This specific parametric form of non-linearity—where the target depends linearly on spike and bulk components but with different coefficients—represents only a narrow class of possible misspecifications. \n   \n   *Specific recommendation*: (a) Include a discussion about the relationship between the spiked covariance model and real-world data, with empirical evidence showing when real data approximately satisfies these assumptions. (b) Discuss the limitations of the $(\\alpha_Z, \\alpha_A)$ parameterization for capturing general forms of model misspecification, and acknowledge what types of practical scenarios this does and does not cover. (c) Consider extending the analysis to more realistic spectral structures or more general misspecification models, even if only as future work.\n\n3. The experimental section requires substantial expansion and can be greatly improved to better justify the studied model:\n   - Only one experimental setup is shown (3-layer ReLU networks, Figure 4)\n   - No experimental details are provided in the main paper, forcing readers to search Appendix B for minimal additional information\n   - The connection between the linear theory and nonlinear experiments is not rigorously established\n   - No experiments on real datasets are provided\n   \n   *Specific recommendation*: Add experiments on: (a) deeper networks with different architectures, (b) different activation functions, (c) real-world datasets where spike structure can be validated, (d) ablation studies showing which theoretical predictions transfer to practice\n\n4. Even considering Appendix B, the experimental details are insufficient for reproduction. Critical information missing includes: exact network initialization, optimization hyperparameters beyond learning rate and epochs, how the spike direction and alignment are constructed, how results are aggregated across trials, and the random seeds used.\n   \n   *Specific recommendation*: Provide complete experimental details in a dedicated section or supplementary code repository, following ICLR reproducibility guidelines.\n\n5. The term \"phase transition\" in the title and throughout suggests sharp, discontinuous changes in behavior. \nHowever, Figure 3 and the mathematical expressions suggest smooth, continuous transitions from positive to negative coefficients except for the case of $c=1$ which has been extensively discussed in the literature.\nThis is more accurately described as a trade-off or crossover phenomenon rather than a phase transition in the statistical physics sense.\n   \n   *Specific recommendation*: Either provide evidence of sharp transitions (e.g., derivatives of risk with respect to parameters showing discontinuities) or adjust the terminology throughout the paper to more accurately reflect the continuous nature of these transitions.\n\nAdditional minor concerns:\n\n6. The proof sketch in Section 3.4 that explains the risk decomposition is deferred to near the end of the paper. This interpretable decomposition should appear much earlier to help readers understand the subsequent results. \n\n7. The paper would benefit from a section explicitly discussing what practitioners should take away from this work. When should they worry about alignment? How can they diagnose whether their setting corresponds to the catastrophic regime? What are actionable recommendations that one gains by understanding this model?"}, "questions": {"value": "Most of my questions for the authors are connected to what was previously written in the Strengths and Weaknesses sections.\n\n1. Have the authors tried to verify the theoretical predictions with other network architectures beyond 3-layer ReLU networks? For example, does the same behavior on synthetic data appear for Convolutional networks or Residual networks?\n   After establishing the phenomenon on synthetic data, do similar alignment-dependent phase transitions appear on real-world datasets for the same models?\n\n2. Can the authors provide guidance on how practitioners can determine whether their data exhibits spiked covariance structure? What are the practical tools or diagnostics that would indicate when this theory applies? Has this been shown on some specific datasets for example? This would greatly enhance the practical relevance of the work.\n\n3. The paper shows one experiment with nonlinear networks but provides no theoretical justification for why the linear analysis should transfer. Can the authors provide:\n   - Theoretical analysis (even informal or pointing to relevant references) of why these phenomena persist in nonlinear models?\n   - More extensive empirical validation showing the boundaries of when the theory does and does not apply?\n\n4. Given that the $(\\alpha_Z, \\alpha_A)$ parameterization represents a specific form of misspecification, can the authors comment on what types of real-world problems might naturally exhibit this structure? Are there examples from machine learning practice where targets are known to have this differential dependence on principal and bulk components?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "iSeOXGJR5g", "forum": "fFG4wZee3f", "replyto": "fFG4wZee3f", "signatures": ["ICLR.cc/2026/Conference/Submission4528/Reviewer_ywoE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4528/Reviewer_ywoE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4528/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761147104317, "cdate": 1761147104317, "tmdate": 1762917424359, "mdate": 1762917424359, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors study a min-L2-norm regression task.\nThe data x is a Gaussian along a direction u plus an isotropic bulk, while the labels y are a linear model of the projection of x on direction u plus a linear model of the bulk part.\nThe predictor is a linear model learned with min-L2-norm regression.\n\nThey study:\nGeneralization: MSE evaluated on a new data point (including noise, and possibly with different coefficients in the target function - to model covariate shift). They consider the excess risk to remove the noise plateau.\nAlignment: how beneficial it is to have the task weights aligned to the hidden direction u for the generalization? \nOverfitting: when c -> infinity (n << d, few samples, perfect fitting of dataset is possible), does the generalization go to zero (benign), to a constant (tempered) to infinity (catastrophic)? \n\nThey consider both the scaling in which the spike dominates, as well as the one in which the spike is of the same order of the noise (spectrally).\n\nTheir main result is Theorem 5, providing a full risk decomposition for the setting under consideration. \nIn Section 3 they study generalization, alignment and overfitting in the case of, respectively:\n- Section 3.1: well specified problem, in which the target function is linear in x (and not linear in the spike and bulk contributions of x)\n- Section 3.2: missspecification but no covariate shift: the target function is not linear in x, but testing is done with the same target function as the training data\n- Section 3.3: missspecification and covariate shift: the target is non-linear in x as in the previous case, and testing is done with a structurally identical target, but with spike-bulk contributions altered.\n\nTable 1 classifies all the regimes studied by the authors."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The authors provide a complete classification of overfitting in linear regression, studying in particular how alignment between data structure and task helps or hinders generalisation, in a toy but fully controllable learning setting. This creates a nice benchmark to understand the phenomenon in more complicated settings (non-linear estimators for e.g.)."}, "weaknesses": {"value": "It is unclear to me how specific the results are to the data model. The authors do not discuss which elements may generalize to more complicated data, and which are surely specific.\n\nThe presentation is a bit heavy in Section 3. The authors present the classification of behaviors, but provide little intuition on why the behaviors observed make sense, or why it challenges common beliefs. This results in a bit of a dry description of the phenomenology, from which is difficult to gather a more general take home message (which is more nicely summarised in lines 60-70).\nMaybe this is not possible, but I invite the authors to see whether this element can be improved."}, "questions": {"value": "In your work you consider min-norm interpolation, i.e. the limit lambda -> 0^+ of ridge regression with regularization strength lambda. How hard would it be to generalize your results to finite lambda? Would that make sense in the context of studying overfitting? \n\nTypos:\n- line 45-46: z and a should be defined clearly given X in line 34. Are they the columns of Z, A? This gets defined only in line 180\n- line 45-46: what is the dimensionality of y? It seems a scalar, but is boldfaced. Same for epsilon in eq 2.\n- line 103: \"we shall ...\" seems to miss a verb\n- Figure captions sometimes lack the values of parameters (such as d and n etc) at which the curves/experiments are plotted"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qaPOguKwwQ", "forum": "fFG4wZee3f", "replyto": "fFG4wZee3f", "signatures": ["ICLR.cc/2026/Conference/Submission4528/Reviewer_KtDe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4528/Reviewer_KtDe"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4528/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761746509849, "cdate": 1761746509849, "tmdate": 1762917423901, "mdate": 1762917423901, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the generalization error of linear regression using spiked covariance data models, characterizing the impacts of spike strength, target-spike alignment, target model misspecification, and train-test covariate shift. The theoretical output of the paper is an exact expression for the generalization error in the considered setting. This allows the authors to identify the regimes where spike strength and target-spike alignment lead to improved generalization."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. Rigorous asymptotic analysis of the generalization error of linear regression in a setting involving multiple interesting variables (i.e., spike strength, target-spike alignment, target model misspecification, and train-test covariate shift).\n\n2. The writing of the paper (including figures and theoretical results) is of good quality. Therefore, it is easy to follow.\n\n3. The studied setting is somewhat interesting, and it can be useful for understanding some effects of data distribution on the generalization error.\n\n4. The paper includes experimental extension (results) for multilayer neural networks, which is beneficial, although the experimental results are also limited to the synthetic data setting considered in the paper."}, "weaknesses": {"value": "1. The paper lacks highly relevant literature and contextualization relative to the prior work. Specifically, there are at least three papers (about generalization errors with spiked covariance) that are quite related to this work but not mentioned in the paper:\n- [1] studied \"generalization for least squares regression with spiked covariances\", which is also the fundamental topic of this work. Also, the settings are quite similar for [1] and this paper.\n- [2,3] analyzed two-layer neural networks with spiked covariance, which leads to spiked covariance for the features learned by the model (as discussed in the introduction of this work as well), so these works are also relevant. Specifically, [2] focused on the effect of spike magnitude and spike-target alignment, which is also the focus of this paper. \nTherefore, without proper contextualization relative to these prior works, this paper is weak in terms of positioning and novelty.\n\n2. The fundamental theoretical challenge relative to the prior work should be discussed. Specifically, considering the closeness of this work to related setups in [1], Hastie et al. (2022), Sonthalia & Nadakuditi (2023), and [4], the difference in the proof/derivation techniques should be explicit. Since this is currently missing, the results in this work can be considered trivial generalizations/extensions of the other results. \n\n3. The motivation for this specific data model (in line 45) is unclear. While being the main object of study and the source of most of the claimed results, the authors do not explicitly motivate the data model $\\mathbf{y} = \\alpha_Z \\boldsymbol{\\beta}^T \\mathbf{z} + \\alpha_A \\boldsymbol{\\beta}^T \\mathbf{a} + \\boldsymbol{\\epsilon}$, other than saying it is a non-linear function of $\\mathbf{x} = \\mathbf{z} + \\mathbf{a}$ for different $\\alpha_Z, \\alpha_A$ cases (introducing mis-specification).\n\n4. Considering that the target is a non-linear function of the input (a.k.a. mis-specificed case in the paper), studying the performance of a linear model becomes irrelevant (not that interesting). What is the point of studying this case?\n\n5. The benefit of spike-target alignment on the generalization is known in the literature [2]. On the other hand, most of the cases where the alignment hurts the generalization in this paper can be attributed to the lack of proper regularization. For example, in most of the figures where the alignment is harmful, the authors set the spike magnitude $\\theta = O(\\sqrt{c})$ with respect to $c = d/n$ (ratio of dimension to samples) and let $c \\to \\infty$. In this case, the model is highly overparameterized, and the norm of the input is large (due to the spike magnitude), but there is no explicit regularization beyond the implicit nature of the min-norm solution.\n\n6. Spiked covariance with a single spiked direction (Assumption 1) is considered, limiting the practical relevance of the found explicit expression for the generalization error. Also, the practical relevance of the considered target $\\mathbf{y}$ model seems unclear.\n\n\n**Related work that are not mentioned in the paper:**\n\n*[1] Li, Jiping, and Rishi Sonthalia. \"Generalization for least squares regression with simple spiked covariances.\" arXiv preprint arXiv:2410.13991 (2024).*\n\n*[2] Demir, Samet, and Zafer Dogan. \"Random features outperform linear models: Effect of strong input-label correlation in spiked covariance data.\" arXiv preprint arXiv:2409.20250 (2024).*\n\n*[3] Demir, Samet, and Zafer Dogan. \"Asymptotic Analysis of Two-Layer Neural Networks after One Gradient Step under Gaussian Mixtures Data with Structure.\" International Conference on Learning Representations (2025).*\n\n*[4] Li, Xinyue and Rishi Sonthalia. \"Least squares regression can exhibit under-parameterized double\ndescent.\" Advances in Neural Information Processing Systems (2024).*"}, "questions": {"value": "1. What is the positioning of this paper in comparison to the papers I mentioned in weaknesses 1 and 2?\n\n2. What is the motivation of the specific data model (in line 45)? If it is to introduce a non-linear function of $\\mathbf{x}$, why don't you use $\\sigma(\\boldsymbol{\\beta}^T \\mathbf{x})$ for some nonlinear $\\sigma: R \\to R$?\n\n3. Is it possible to connect the data model to the one I just mentioned?\n\n4. If the target is a non-linear function of the input (as stated in lines 49-50), how can we expect the linear regression to perform well? What is the point of studying this case?\n\n5. What happens if you apply ridge regression (with a regularization constant that increases with $c$ (ratio of dimension to samples)) in Figure 1a, for example?\n\n6. Could the authors explain the practical relevance of their setting (specifically, their data model of input and target)? Also, is it possible to identify real-world datasets/scenarios that approximately satisfy the assumptions and experiment with them?\n\n7. Is it possible to extend the assumption to multiple spikes?\n\n8. Is the setting (together with the assumptions) of this work enough to characterize the generalization error for neural networks trained with one gradient step (Dandi et al. 2024; Moniri et al. 2023; and [3] above)? If so, it would be a strength?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "F5R2hqSjUE", "forum": "fFG4wZee3f", "replyto": "fFG4wZee3f", "signatures": ["ICLR.cc/2026/Conference/Submission4528/Reviewer_uSkU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4528/Reviewer_uSkU"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4528/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761928802727, "cdate": 1761928802727, "tmdate": 1762917423622, "mdate": 1762917423622, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studied the asymptotic generalization error of the minimum-norm interpolation solution of linear regression when the data has a rank-one signal in the population covariance. Under the proportional limit, the authors derived a systematic description of the generalization error with respect to the aspect ratio, the signal strength, the alignment between target direction and data signal, model misspecification, and train–test covariate shift. This detailed analysis gives us a full picture of benign, tempered, and catastrophic overfitting regimes. For instance, when the target is aligned with the data signal, increasing signal strength can have a transition from\ntempered overfitting to catastrophic overfitting, then to tempered overfitting, and then to benign overfitting,"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This paper is well-written, and the statements are clear to me. This paper provides a comprehensive understanding of how varying signal strengths and target-input alignments impact risk in overparameterized settings. The transition between benign and catastrophic overfitting is an important and interesting topic for generalization theory and the ML community. It also includes extensive simulations for both linear and nonlinear networks."}, "weaknesses": {"value": "The main limitation of this paper is the model assumption. This paper only studies a linear model, which may not generalize well to nonlinear models for the transition between benign and catastrophic overfitting. Besides, it only considers the minimum-norm interpolation solution. It would be more beneficial to generalize these results to the ridge regression case, where altering the regularization parameter may yield more diverse outcomes. Additionally, the regimes of benign, tempered, and catastrophic overfitting are highly intricate from a theoretical perspective. It would be beneficial to provide some heuristic explanations of why these phenomena occur differently in various cases."}, "questions": {"value": "1. What is $(\\tilde{X},\\tilde{y})$ in Theorem 1? Do you only consider one test data point $(\\tilde{x},\\tilde{y})$? Please clarify the notion $\\tilde{Z},\\tilde{A}$ in all theorems. For instance, in Theorem 5, are you considering $\\tilde{Z},\\tilde{A}$ as vectors $\\tilde{z},\\tilde{a}$?\n\n2. Do you assume $\\alpha_A\\neq \\tilde{\\alpha}_A$ in Theorems 3 and 4? Why is there no $\\alpha_A$ in the limit of $\\mathcal{R}_c$ in Theorem 4? It would be better to clearly state the equal operator norm and equal Frobenius norm conditions in Theorems 3 and 4, respectively.\n\n3. Can you compare the test errors of training 3-layer ReLU networks in section 3.5 and linear regression on the same training and test datasets? Are the test losses for 3-layer ReLU networks always smaller than linear regression model?\n\n4. Typo: line 1592: (Lemma 12\n\n5. Where do you use Lemmas 13 and 15? Can you explain the application of the Gaussian hypercontractivity in the proofs?\n\n6. Why do you need to assume $v$ in (1) has i.i.d. standard normal entries? In Assumption 2, do you need to assume independent entries of $A$, or is it uncorrelated enough? There should be a detailed discussion on the three conditions of Assumption 2. Can we use the first two conditions to imply the last condition of the Marchenko–Pastur law?\n\n7. In (2), can you consider $\\beta_*$ as a fixed vector? Why do we need to assume that it is uniformly distributed in some subspace?\n\n8. In this paper, you focus on the overfitting regime. How about the underfitting case when $c\\to 0$?\n\n9. Is there a heuristic explanation of Figure 2a? Why could there be a region where the aligned risk is lower than the anti-aligned risk, but the aligned risk becomes strictly larger outside this region?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wKa76VFDk4", "forum": "fFG4wZee3f", "replyto": "fFG4wZee3f", "signatures": ["ICLR.cc/2026/Conference/Submission4528/Reviewer_bT6s"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4528/Reviewer_bT6s"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4528/-/Official_Review"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762941828021, "cdate": 1762941828021, "tmdate": 1762941828021, "mdate": 1762941828021, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}