{"id": "MuTv2itpoj", "number": 7573, "cdate": 1758028151102, "mdate": 1759897845379, "content": {"title": "ELPO: Ensemble Learning Based Prompt Optimization for Large Language Models", "abstract": "The remarkable performance of Large Language Models (LLMs) highly relies on crafted prompts. \nHowever, manual prompt engineering is a laborious process, creating a core bottleneck for practical application of LLMs. \nThis phenomenon has led to the emergence of a new research area known as Automatic Prompt Optimization (APO), which develops rapidly in recent years.  \nExisting APO methods such as those based on evolutionary algorithms or trial-and-error approaches realize an efficient and accurate prompt optimization to some extent. \nHowever, those researches focus on a single model or algorithm for the generation strategy and optimization process, which limits their performance when handling complex tasks. \nTo address this, we propose a novel framework called $\\textbf{E}$nsemble $\\textbf{L}$earning based $\\textbf{P}$rompt $\\textbf{O}$ptimization (ELPO) to achieve more accurate and robust results. \nMotivated by the idea of ensemble learning, ELPO conducts voting mechanism and introduces shared generation strategies along with different search methods for searching superior prompts. \nMoreover, ELPO creatively presents more efficient algorithms for the prompt generation and search process. \nExperimental results demonstrate that ELPO outperforms state-of-the-art prompt optimization methods across different tasks, e.g., improving F1 score by 7.6 on ArSarcasm dataset.", "tldr": "This paper proposes an ensemble learning based algorithm called ELPO to realize robust and accurate results in automatic prompt optimization.", "keywords": ["automatic prompt optimization", "ensemble learning", "large language models", "prompt engineering"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5bc2d99434d151ac7ff54e8803b4e6111d28e7fc.pdf", "supplementary_material": "/attachment/1b5fc2319db59ba4af41e9367e6503055c6e3910.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces (ELPO, a novel framework that enhances the effectiveness of LLMs through automatic prompt optimization. Unlike existing approaches that depend on a single generation or search strategy, ELPO adopts an ensemble learning paradigm that integrates multiple search methods and shared generation strategies under a voting mechanism, enabling more accurate and robust prompt discovery. Furthermore, ELPO proposes efficient algorithms for prompt generation and search, improving both optimization stability and adaptability across diverse tasks. Extensive experiments show that ELPO consistently outperforms state-of-the-art prompt optimization methods, demonstrating its strong generalization ability and superior performance on various benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The main strength of this paper is its significant performance improvement over existing prompt optimization methods. The proposed ELPO framework achieves consistently higher results across multiple benchmarks, clearly demonstrating its effectiveness in optimizing prompts for Large Language Models. By leveraging ensemble learning to combine diverse search and generation strategies, ELPO enhances the quality of discovered prompts and achieves state-of-the-art performance in various evaluation settings. The results convincingly show that the ensemble-based design leads to more accurate and reliable optimization outcomes, establishing ELPO as a strong and effective approach within the field of automatic prompt optimization."}, "weaknesses": {"value": "1. Unclear technical novelty and framing. The paper does not clearly articulate which components are genuinely novel versus straightforward extensions. While results suggest that incorporating diverse generators drives most of the gains, the manuscript does not clearly explain how these generators are integrated. Is there any critical design?\n\n2. Unsupported claims about Bayesian Search + MAB. The introduction claims the method is the first to combine Bayesian optimization with MAB, but there is no targeted ablation or analysis isolating this design choice.\n\n3. Hard-Case Tracking lacks differentiation. The paper states it “creatively” proposes Hard-Case Tracking focusing on recurrent error samples, but leveraging error cases for iterative refinement is common. It remains unclear how ELPO’s variant differs from prior methods.\n\n4. Incomplete ablations on key design choices. ELPO contains several moving parts (ensemble of generators, voting, search components...), yet the paper does not rigorously demonstrate the contribution of each (e.g. search).\n\n5. No evaluation of efficiency. The introduction claims “substantial” efficiency improvements, but there are no metrics or token-cost analyses to substantiate this.\n\n6. Limited model coverage undermines robustness claims. Experiments are run only on GPT-4o, which makes it hard to assess robustness or generalization across base models. Replicate on multiple families (e.g., Claude, Gemini, Qwen, Llama) to demonstrate model-agnostic benefits."}, "questions": {"value": "See the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YwL2qwhJwP", "forum": "MuTv2itpoj", "replyto": "MuTv2itpoj", "signatures": ["ICLR.cc/2026/Conference/Submission7573/Reviewer_s7p7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7573/Reviewer_s7p7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7573/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761042411309, "cdate": 1761042411309, "tmdate": 1762919668615, "mdate": 1762919668615, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "While Large Language Models (LLMs) are powerful, their performance hinges on expertly designed prompts. Since manual prompt engineering is labor-intensive, and Automatic Prompt Optimization (APO) aims to optimize such scenarios. Current APO methods, though somewhat effective, are often limited to a single technique, which struggles with complex tasks. This paper proposes a framework called Ensemble Learning-based Prompt Optimization (ELPO). ELPO's key innovations are: 1) Hard-Case Tracking to learn from repeated errors, 2) a high-dimensional Bayesian search for efficient optimization, and 3) ensemble voting that leverages a diverse set of high-performing prompts."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The method is clear to understand and this paper is well-written.\n* The proposed ELPO achieves remarkable scores on several datasets compared with baselines."}, "weaknesses": {"value": "* The contributions are somehow incremental, ensembling previous prompt optimization methods with careful and further design in three phases: 1) prompt generation by the following methods: a) bad case reflection[1], b) evoprompt[2], c) OPRO; 2) search phrase: a) Bayesian, b) UCB[1], c) population[2,4]; 3) Voting: intuitive ensembling voting and aggregating. \n* The method is not very novel, just aggregation of previous methods.\n* The experimental setting including parameters are not given. How many steps does each method cost in the table 1? \n\n# References\n[1] Pryzant, Reid, et al. \"Automatic Prompt Optimization with\" Gradient Descent\" and Beam Search.\" The 2023 Conference on Empirical Methods in Natural Language Processing.\n[2] Guo, Qingyan, et al. \"Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers.\" The Twelfth International Conference on Learning Representations.\n[3] Yang, Chengrun, et al. \"Large language models as optimizers.\" The Twelfth International Conference on Learning Representations. 2023.\n[4] Zhou, Yongchao, et al. \"Large language models are human-level prompt engineers.\" The eleventh international conference on learning representations. 2022."}, "questions": {"value": "* When it comes to ensemble, trade-offs between overhead and performances are very important. Could the authors give more in-depth cost analysis, both for time and API cost? \n* See weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7kgADohTac", "forum": "MuTv2itpoj", "replyto": "MuTv2itpoj", "signatures": ["ICLR.cc/2026/Conference/Submission7573/Reviewer_gCQa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7573/Reviewer_gCQa"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7573/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761830076039, "cdate": 1761830076039, "tmdate": 1762919668110, "mdate": 1762919668110, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ELPO, a new framework for Automatic Prompt Optimization (APO). The authors argue that existing APO methods are often limited because they rely on a single generation strategy or optimization algorithm, which can struggle with complex tasks. To address this, ELPO adopts an ensemble learning approach across the entire optimization pipeline: It first creates a diverse pool of candidate prompts by using three parallel generation strategies: Bad-Case Reflection, Evolutionary Reflection, and Hard-Case Tracking. To avoid the high cost of evaluating every candidate prompt, ELPO uses two parallel search algorithms to select the most promising ones. They believe this kind of combination can complement each method. Finally, instead of selecting a single best prompt, ELPO aggregates predictions from multiple high-performing, diverse prompts. It uses a weighted voting mechanism, where weights are optimized to maximize the macro F1-score, to produce the final output.\n\nThe authors evaluate ELPO on six datasets (including LIAR, BBH, and GSM8K)  and show that it consistently outperforms state-of-the-art baselines like APE, ProTeGi, Promptbreeder, and EvoPrompt etc. Ablation studies confirm the positive contribution of the diverse generators and the ensemble voting strategy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.  The central idea of applying ensemble learning principles to the entire APO pipeline (generation, search, and final prediction) is a good attempt for research. It directly addresses a well-known limitation of single-algorithm optimizers.\n2.  The method demonstrates significant and consistent performance gains over a wide range of strong, recent baselines across six diverse tasks. The improvements on challenging datasets like LIAR and BBH-navigate are particularly impressive.\n3.  The proposed Hard-Case Tracking is an interesting method that addresses a key weakness in feedback-based optimizers by moving from a myopic, single-prompt error view to a global, population-wide \"hard case\" analysis.\n4.  The authors provide clear ablation studies in Table 2 and Table 3 that effectively validate the contributions of the multi-generator framework and the weighted voting strategy, respectively."}, "weaknesses": {"value": "1.  The framework's primary weakness is its significant complexity and likely computational cost. ELPO runs three generation algorithms, two search algorithms, and an additional weight optimization step. This is almost certainly more expensive (in terms of LLM calls to the optimizer) than the single-algorithm baselines. The paper claims \"efficiency\"  and \"conserves resources\", but this is only relative to a naïve evaluation of all candidates, not relative to the baselines. The lack of a cost-performance comparison makes it difficult to assess if ELPO is truly more efficient or just finds better prompts through a much more expensive search.\n2.  The Ensemble Voting mechanism requires running M different prompts through the task LLM for every single query at inference time. This multiplies inference cost and latency by M. This is a major practical drawback that seems to conflict with the paper's motivation of solving a \"core bottleneck for practical application\". This trade-off is not discussed.\n3.  It is unclear how the two parallel search methods (Bayesian and MAB) interact. Are their results pooled? Do they select prompts in sequence? The pipeline diagram and text do not sufficiently detail how this dual-search mechanism is unified to produce the set of prompts for evaluation.\n4. Another concern here is whether we still need to search for more robust and effective prompting methods nowadays. Since the power of LLM is now quite strong, and can tolerate even typos or simple logical problems."}, "questions": {"value": "1.  Could the authors provide a comparative analysis of the total computational cost (e.g., total number of optimizer LLM calls) required for ELPO to reach its reported performance versus the baseline methods? A plot of final performance vs. LLM calls would be very insightful.\n2.  Following on the high inference cost of ensemble voting: How does the performance of the single best prompt found by ELPO (before the voting step) compare to the final ensemble result and the baselines? This would help disentangle the gains from the superior search process versus the expensive inference-time ensemble."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "o0LjVtMput", "forum": "MuTv2itpoj", "replyto": "MuTv2itpoj", "signatures": ["ICLR.cc/2026/Conference/Submission7573/Reviewer_LBgm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7573/Reviewer_LBgm"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7573/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761830332061, "cdate": 1761830332061, "tmdate": 1762919667690, "mdate": 1762919667690, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ELPO (Ensemble Learning based Prompt Optimization), a framework for automatic prompt optimization that combines multiple generation strategies and search methods with ensemble voting. The approach introduces three prompt generation methods (Bad-Case Reflection, Evolutionary Reflection, and Hard-Case Tracking), two efficient search strategies (Bayesian Search and Multi-Armed Bandit Search), and a weighted ensemble voting mechanism. Experiments on six datasets (LIAR, BBH-navigate, ETHOS, ArSarcasm, WSC, GSM8K) demonstrate improvements over existing methods like APE, ProTeGi, OPRO, PromptBreeder, and EvoPrompt."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- ELPO provides a comprehensive pipeline integrating generation, search, and voting in a principled manner\n\n- The paper addresses prompt optimization from multiple angles (generation diversity, search efficiency, robustness via ensembling)\n\n- The focus on black-box optimization makes the approach applicable to commercial LLM APIs\n\n- Consistent improvements across diverse tasks (fact-checking, navigation, hate speech detection, sarcasm detection, reasoning)\n\n- The global tracking of difficult cases across prompts is a useful addition to existing feedback-based methods"}, "weaknesses": {"value": "- Lack of statistical testing, incomplete ablations, missing computational cost analysis\n- Why should this ensemble approach work? What are the theoretical guarantees? Under what conditions might it fail?\n- Embedding methods, optimization procedures, and exact algorithmic integration are underspecified\n- The approach requires running multiple generators, search strategies, and ensemble voting. Is the improvement worth this complexity?\n- Scalability questions: How does ELPO perform with:\n1. Larger candidate pools?\n2. More complex tasks requiring longer prompts?\n3. Different LLM families (GPT vs Claude vs Llama)?\n4. Limited API budgets?"}, "questions": {"value": "- Can you provide comprehensive analysis showing search efficiency across all datasets? Specifically: (a) Top-k precision (what % of selected prompts are truly in top-k?), (b) Oracle gap (performance difference between selected prompts and true best), (c) Computational savings in terms of total evaluations? \n- Can you provide ablations for: (a) Each generator independently, (b) Each search method independently, (c) Voting strategies (single best vs average vs weighted), (d) Different ensemble sizes?\n- Can you report standard deviations, confidence intervals, or conduct significance tests (e.g., paired t-tests) across the 3 runs?\n- What embedding model is used for Bayesian Search and MAB? How sensitive are results to this choice?\n- What optimization algorithm solves the constrained problem in line 365? How is F1_macro made differentiable w.r.t. weights w?\n- What is the total number of LLM API calls required by ELPO vs baselines? What is the wall-clock time and estimated dollar cost?\n- How does ELPO perform when: (a) Using different task models (GPT-4, Claude, Llama)? (b) Using different optimizer models? (c) Applied to longer-form generation tasks?\n- Can you analyze cases where ELPO performs worse than simpler baselines? What types of tasks or prompts are challenging?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gL2FGK2flM", "forum": "MuTv2itpoj", "replyto": "MuTv2itpoj", "signatures": ["ICLR.cc/2026/Conference/Submission7573/Reviewer_ML5W"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7573/Reviewer_ML5W"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7573/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762014728639, "cdate": 1762014728639, "tmdate": 1762919667273, "mdate": 1762919667273, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}