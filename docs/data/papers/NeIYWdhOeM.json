{"id": "NeIYWdhOeM", "number": 14205, "cdate": 1758230268467, "mdate": 1763771411478, "content": {"title": "Bridged Clustering for Representation Learning: Semi-Supervised Sparse Bridging", "abstract": "We introduce Bridged Clustering, a semi-supervised framework to learn predictors from any unpaired input $\\mathcal{X}$ and output $\\mathcal{Y}$ dataset. Our method first clusters $\\mathcal{X}$ and $\\mathcal{Y}$ independently, then learns a sparse, interpretable bridge between clusters using only a few paired examples. At inference, a new input $x$ is assigned to its nearest input cluster, and the centroid of the linked output cluster is returned as the prediction $\\hat{y}$. Unlike traditional SSL, Bridged Clustering  explicitly leverages output-only data, and unlike dense transport-based methods, it maintains a sparse and interpretable alignment. Through theoretical analysis, we show that with bounded mis-clustering and mis-bridging rates, our algorithm becomes an effective and efficient predictor. Empirically, our method is competitive with SOTA methods while remaining simple, model-agnostic, and highly label-efficient in low-supervision settings.", "tldr": "", "keywords": ["Semi-supervised Learning", "Clustering"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6c7761c0d14687f608602517161d13b88a746f2d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces Bridged Clustering, a semi-supervised learning framework designed to learn predictors from unpaired input and output datasets. The method first clusters the input space and output space independently, then learns a sparse, interpretable bridge between clusters using a small set of paired examples. At inference, a new input is assigned to its nearest input cluster, and the centroid of the linked output cluster is returned as the prediction. The approach is model-agnostic, computationally efficient, and supports bidirectional inference. Theoretical analysis shows that the predictor's risk is bounded under certain mis-clustering and mis-bridging rates. Empirical results on multimodal datasets (BIOSCAN, WIT, Flickr30k, COCO) demonstrate competitive performance against a wide range of baselines, especially in low-supervision regimes."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed BC is model-agnostic and easy to implement, relying on standard clustering and majority-vote bridging. Its sparse, interpretable mapping between input and output clusters offers transparency absent in dense transport or deep generative models.\n2. Evaluation across multiple modalities (vision, language, genomics) under both inductive and transductive settings, along with comparisons to a wide range of baselines, demonstrates robustness and generality."}, "weaknesses": {"value": "1. The method assumes that input and output spaces can be cleanly partitioned into clusters that align one-to-one. This may not hold in real-world data with overlapping or hierarchical categories. When clusters poorly capture latent structure (e.g., in the WIT dataset), predictive performance degrades notably. This limits robustness in high-dimensional or weakly separable spaces.\n2. Although the method’s interpretability is emphasized, no concrete visualization or case study (e.g., cluster bridges on BIOSCAN or COCO) is provided to illustrate interpretability in practice.\n3. Predictions are always the centroid of the output cluster, which may be too coarse for tasks requiring fine-grained outputs. The model does not refine predictions with additional supervision beyond the bridge."}, "questions": {"value": "1. Since the method heavily relies on representation separability (∆X, ∆Y), how sensitive is performance to pretrained encoder choice? Have the authors experimented with self-supervised embeddings?\n2. Empirically, the paper reports success with as few as one labeled pair per cluster. Is there a theoretical lower bound on the number of pairs required to guarantee reliable bridging under bounded εX, εY?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "ZW9e4l0ypu", "forum": "NeIYWdhOeM", "replyto": "NeIYWdhOeM", "signatures": ["ICLR.cc/2026/Conference/Submission14205/Reviewer_KEPX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14205/Reviewer_KEPX"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14205/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761489320510, "cdate": 1761489320510, "tmdate": 1762924664202, "mdate": 1762924664202, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose BRIDGED CLUSTERING, an algorithm leveraging both input x, output y data and a small paired (x,y) dataset. The algorithm is very simple, both input and output sets are independently clustered, and an input to output cluster mapping is found through majority voting in the paired dataset. The authors provide a mis-clustering analysis with data generated under sub-gaussian mixtures. The effectiveness is validated empirically on 4 datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well written and easy to follow. The notation is also coherent and intuitive.\n- The algorithm is extremely simple yet well motivated, defined and atomized. The algorithm seems to work well empirically."}, "weaknesses": {"value": "### Major\n- My main issue is that all this method reduces all intra cluster variation to 0, which is even more pronounced if the output-only data has high variations. For instance in the image captioning task (L337), any intra-cluster variation in images is lost and all images get the same caption. This strongly limits the applicability of such algorithm. Based on the problem formulation and analysis, the algorithm is only applicable to data derived from categorical latents.\n\n### Minor\n- Limited empirical validation.\n- L083: “leverages output-only data” this is confusing because it also leverages input data."}, "questions": {"value": "- About the terminology: what does “output-only data mean?” In my understanding, this can only be defined is you define a learner that maps inputs to outputs. I think this should be better explained in the introduction. Because given an unnannotated dataset, there is no notion of input/output. L089 reinforces my claim because you state that you can do bidirectional inference.\n- All empirical evaluations seem to be done in a very controlled setup. Why did you limit yourselves to 7 groups? Do you think this would work on more complex datasets?\n- L063: “once” should be “if” ?\n\nOverall, I think the paper reads well and my rating would be around borderline. Given that I cannot give a rating of 5, I put 4 as a start but am willing to increase my rating based on the reply and the other reviews."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FmeWSyRBDK", "forum": "NeIYWdhOeM", "replyto": "NeIYWdhOeM", "signatures": ["ICLR.cc/2026/Conference/Submission14205/Reviewer_q4Wf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14205/Reviewer_q4Wf"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14205/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761939884660, "cdate": 1761939884660, "tmdate": 1762924662395, "mdate": 1762924662395, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Bridged Clustering (BC), a semi-supervised framework for learning predictors when one has unpaired inputs $X$ and unpaired outputs $Y$ plus a small paired set $S$.\n\nThe method: (i) clusters $X$ and $Y$ independently; (ii) learns a sparse cluster-to-cluster bridge from the few paired examples via majority vote; (iii) predicts by assigning a test input to its nearest input cluster and returning the centroid of the linked output cluster (and symmetrically $Y \\rightarrow X$).\n\nExperiments on BIOSCAN (bioinformatics) and vision-language datasets (COCO, Flickr30k, WIT) show BC is competitive with SSL, unmatched regression, and transport baselines; it tends to win on BIOSCAN/COCO/Flickr30k and is competitive (but not best) on WIT."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Focuses on the under-served regime with large unpaired $X$ and $Y$ plus a tiny paired set, using independent clustering and a sparse bridge-distinct from classical SSL and from purely distributional coupling.\n\n2. Model-agnostic encoders and off-the-shelf clustering.\n\n3. Four datasets across modalities; many seeds and settings; BC generally wins on BIOSCAN/COCO/Flickr30k and is competitive on WIT."}, "weaknesses": {"value": "1. Performance hinges on embedding quality and (near-)correct $C$. There is no systematic study of mis-specifying $C$ or robustness to imbalanced/overlapping clusters; theory assumes separation.\n\n2. Majority-vote induces a deterministic mapping $A:[C]\\to[C]$. In multi-modal or hierarchical relations, a soft/multi-edge bridge may reduce $\\varepsilon_B$.\n\n3. The main metric is embedding-space MSE; this may not fully capture downstream utility."}, "questions": {"value": "1. For captioning/retrieval, could you report Recall@K / median rank and human-readable examples to complement embedding MSE?\n\n2. Section 5.3 claims linear-time scaling once $C \\ll n$. Please include wall-clock vs. $n,d$, and $C$ across datasets."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "eqlKdd0tzV", "forum": "NeIYWdhOeM", "replyto": "NeIYWdhOeM", "signatures": ["ICLR.cc/2026/Conference/Submission14205/Reviewer_Ng8v"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14205/Reviewer_Ng8v"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14205/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980826890, "cdate": 1761980826890, "tmdate": 1762924657856, "mdate": 1762924657856, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The article presents Bridged Clustering (BC), a semi-supervised framework for learning mappings between unpaired input–output datasets. The method first clusters each domain independently and then learns a sparse, interpretable “bridge” between clusters using a small set of paired samples. During inference, a new input is assigned to its input cluster and mapped to the centroid of the linked output cluster. The authors provide theoretical analysis (risk bounds under mis-clustering and mis-bridging rates) and evaluate BC across four multimodal datasets (BIOSCAN-5M, WIT, Flickr30k, COCO). The method outperforms or matches strong baselines in most cases while being model-agnostic and computationally efficient."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is clear about its motivation: learning from both input-only and output-only data is an underexplored problem.\n- Simple and interpretable design that remains competitive with complex baselines.\n- Strong empirical performance on diverse modalities with extremely low supervision.\n- Training and inference scale linearly in data size, unlike OT/GW baselines."}, "weaknesses": {"value": "- Method performance is heavily dependent on clustering quality; the paper could discuss robustness or adaptive clustering strategies.\n\n- Theoretical analysis, while rigorous, lacks intuitive explanation or ablation support.\n\n- Limited discussion of failure modes and sensitivity to hyperparameters like the number of clusters.\n\n- Sparse bridge formulation may be too restrictive for many-to-many mappings.\n\n- Baseline tuning is relatively light, might weaken empirical fairness while comparing.\n- No sufficient discussion on fixed cluster selection. \n- Missing comparison with recent simCLR based methods like SCAN, NNM or so."}, "questions": {"value": "- How sensitive is BC to the choice of cluster count?\n\n- Majority voting seems too simple, could soft or probabilistic bridges (e.g., weighted votes) improve results in overlapping clusters?\n- Is it possible to provide runtime comparison in actual time not in complexity?\n\n- How does clustering method choice (k-means vs spectral, DBSCAN, etc.) affect performance?\n\n- Have you tested robustness under noisy embeddings or partially misaligned clusters?\n\n- Could the approach generalize to continuous or hierarchical output spaces?\n- What about imbalance dataset?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pjoHaDjcHY", "forum": "NeIYWdhOeM", "replyto": "NeIYWdhOeM", "signatures": ["ICLR.cc/2026/Conference/Submission14205/Reviewer_uHM4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14205/Reviewer_uHM4"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14205/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994395921, "cdate": 1761994395921, "tmdate": 1762924656595, "mdate": 1762924656595, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}