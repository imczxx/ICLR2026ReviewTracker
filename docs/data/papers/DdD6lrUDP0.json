{"id": "DdD6lrUDP0", "number": 15813, "cdate": 1758255615760, "mdate": 1759897280427, "content": {"title": "SQLGovernor: An LLM-powered SQL Toolkit for Real World Application", "abstract": "SQL queries in real-world analytical environments—whether written by humans or generated automatically—often suffer from syntax errors, inefficiency, or semantic misalignment, especially in complex OLAP scenarios. \nTo address these challenges, we propose SQLGovernor, an LLM-powered SQL toolkit that unifies multiple functionalities—including syntax correction, query rewriting, query modification, and consistency verification—within a structured framework enhanced by knowledge management.\nSQLGovernor introduces a fragment-wise processing strategy to enable fine-grained rewriting and localized error correction, significantly reducing the cognitive load on the LLM. It further incorporates a hybrid self-learning mechanism guided by expert feedback, allowing the system to continuously improve through DBMS output analysis and rule validation.\nExperiments on benchmarks such as BIRD and BIRD-CRITIC, as well as industrial datasets, show that SQLGovernor consistently boosts the performance of base models by up to 10\\%, while minimizing reliance on manual expertise. Deployed in production environments, SQLGovernor demonstrates strong practical utility and effective performance.", "tldr": "", "keywords": ["Query Processing and Optimization; Large Language Model; Data Governance"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0cda3276d6f0a224cbcce05acd72ca375ba65646.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes SQLGovernor, an LLM-powered SQL toolkit designed for real-world OLAP applications. It unifies four functionalities—syntax correction, query rewriting, semantic modification, and equivalence verification—within a single framework supported by a knowledge management module. The system introduces a fragment-wise processing strategy for decomposing complex SQLs, and a hybrid self-learning mechanism that incrementally updates its rule base through DBMS log analysis and expert feedback. Experiments on BIRD, BIRD-CRITIC, and an internal Payment-SQL dataset show consistent improvements over baselines, with up to 10% gain in execution and verification metrics and notable runtime savings in production deployments."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Provides a comprehensive, unified SQL toolkit that integrates multiple submodules and mitigates fragmentation in SQL processing pipelines.\n- Demonstrates strong practical value with measurable performance gains and deployment evidence in real industrial environments.\n- Uses realistic datasets (BIRD, BIRD-CRITIC, Payment-SQL) and well-structured evaluation protocols, illustrating both academic and applied significance."}, "weaknesses": {"value": "- The paper’s learning component is limited—no parameter-level model training or end-to-end optimization is presented; improvements mainly stem from rule-based augmentation and prompt engineering.\n- Computational overhead is nontrivial (up to 2× latency increase), which may hinder real-time or high-throughput applications.\n- Generalization and theoretical insight are weak; the framework focuses on system integration rather than proposing new machine learning principles.\n- Evaluation primarily covers SELECT-based OLAP queries; applicability to broader SQL tasks (e.g., transactional workloads, multi-schema joins) is unclear.\n- Comparative scope is limited to open-source models (Qwen, CodeS, XiYan); no comparison against closed-source strong baselines (e.g., GPT-4, Claude).\n\nThis paper is technically solid and highly practical, but it falls short of ICLR’s focus on fundamental learning contributions. It would likely be more suitable for a **Demo or Industry Track at SIGMOD/VLDB/WWW**, unless the authors reframe the self-learning process as a genuine, learnable mechanism with quantitative evidence of adaptation."}, "questions": {"value": "- How transferable are the learned rules across different DBMS engines or schema domains?\n- Can the authors clarify whether the LLM ever adapts parameters through fine-tuning or reinforcement, or if all improvements are symbolic/knowledge-based?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2OngPTNiV7", "forum": "DdD6lrUDP0", "replyto": "DdD6lrUDP0", "signatures": ["ICLR.cc/2026/Conference/Submission15813/Reviewer_4rsk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15813/Reviewer_4rsk"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15813/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761571535782, "cdate": 1761571535782, "tmdate": 1762926042938, "mdate": 1762926042938, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "SQLGovernor is an LLM-powered SQL toolkit for OLAP workloads with four tools (syntax corrector, query rewriter, query modifier, equivalence verifier) backed by a knowledge management system. Key contributions: (1) fragment-wise processing that decomposes complex queries into subqueries for localized analysis, (2) hybrid self-learning that generates rules from execution logs with periodic expert validation, (3) unified framework integrating multiple SQL tasks. Evaluated on BIRD, BIRD-CRITIC, and an industrial dataset (Payment-SQL), showing 6-10% improvements over base models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Real production deployment with industrial dataset: Payment-SQL (50 queries, avg 421 tokens, max 1169 tokens) represents actual OLAP complexity. System is deployed and improving over time \n\n2. Practical hybrid approach to knowledge management: Combining LLM rule generation with periodic expert validation (every 2 weeks) is more scalable than pure manual curation. Automatic deduplication via embeddings + DBSCAN prevents rule bloat.\n\n3. Strong empirical results on complex queries: Largest gains on \"Challenging\" category of BIRD (+8.28% for CodeS-15B). On Payment-SQL: 45.92% ETOG vs 31.25% for GenRewrite, 14.56% for Qwen2.5."}, "weaknesses": {"value": "1. Lacks focused validation of individual contributions: Paper presents 4 tools + knowledge management + fragment processing + self-learning + intent classification but validates none in isolation. Which components actually contribute to the 6-10% gains? Without ablations, impossible to assess if any individual contribution is significant. Recommend narrowing scope to 2-3 core technical contributions with rigorous validation rather than presenting multiple components without understanding their individual impact.\n\n2.  Missing baseline comparisons\n - No comparison with DBMS optimizers. PostgreSQL already does LEFT JOIN+NOT NULL→INNER JOIN  and IN(SELECT)→JOIN.\n - No comparison with simple GPT-4/Claude prompt + schema (the obvious baseline). The multi-stage pipeline might perform worse than one well-crafted prompt\n\n3. Fragment processing: unvalidated core contribution\n - No ablation comparing WITH vs WITHOUT fragment processing on same queries\n - With modern long-context LLMs (Gemini 2.5 Flash 1M context), 421-token queries likely don't need decomposition\n - Fragment processing prevents cross-fragment optimizations (e.g., merging two subqueries scanning same table requires seeing both fragments together)\n\n4. Query Modifier intent classification appears unnecessary\n - Classification accuracy: 78.9% with 21% error rate that propagates downstream\n - No ablation showing category-specific prompts outperform generic prompts\n - Modern LLMs (GPT-4, Claude) can infer modification type from request text - explicit pre-classification adds latency and error without proven benefit\n - Categories are limited (4 types, with \"other\" as catch-all)\n - Qwen3-32B direct classification: 84.3% accuracy vs embedding approach: 78.9% - why not just use LLM directly? Saving 0.18s on classification but losing 5.4% accuracy seems like bad trade-off that needs further justification\n\n5. Correctness concerns with no mitigation strategy\n - Equivalence verifier: 78.9% accuracy means 21% of rewrites are incorrectly validated\n - No production safeguards discussed: dry-run testing, gradual rollout, result checksums, automatic rollback\n - Rules stored as vague natural language descriptions, not executable logic - inconsistent LLM interpretation\n - What happens when bad rewrites reach production?\n\n6. Self-learning mechanism under-evaluated\n - Claims 25-35% cost reduction with no supporting evidence\n - Expert rejection rate not reported - if 80% of auto-generated rules are rejected, system just overwhelms experts\n - Rules are well-known patterns (LEFT JOIN→INNER, IN→JOIN, COUNT DISTINCT decomposition) documented since 1990s-2000s, not novel discoveries. Why not bootstrap from 30+ years of database research literature instead of rediscovering?"}, "questions": {"value": "Q1: Which components actually matter?\nPlease provide ablations isolating each major component's contribution: (a) fragment processing vs full-query, (b) intent classification vs direct LLM modification, (c) self-learning vs static expert rules, (d) knowledge retrieval vs no retrieval. \n\nQ2: Why not use obvious baselines?\nWhat's the performance of: (a) GPT-4 with simple one-shot prompt + schema vs your multi-stage pipeline, (b) well-tuned optimizer parameters?\n\nQ3: Does fragment processing help modern LLMs?\nWith Gemini 2.0 Flash (1M context), GPT-5, or Claude 3.5, at what query length does fragment processing provide measurable benefit? Your queries average 421 tokens - well within single-pass capability. \n\nQ4: How do you ensure correctness in production?\nWith 21% verifier error rate: (a) What safeguards prevent inefficient rewrites from reaching production? (b) Have you measured incidents of bad rewrites?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hvlS28imIb", "forum": "DdD6lrUDP0", "replyto": "DdD6lrUDP0", "signatures": ["ICLR.cc/2026/Conference/Submission15813/Reviewer_2gqq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15813/Reviewer_2gqq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15813/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761632655331, "cdate": 1761632655331, "tmdate": 1762926042646, "mdate": 1762926042646, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents SQLGOVERNOR, an LLM-powered SQL toolkit designed for real-world analytical (OLAP) workloads. Unlike prior systems that focus narrowly on text-to-SQL or isolated SQL debugging tasks, SQLGOVERNOR proposes a unified multi-tool framework that includes syntax correction, query rewriting, semantic refinement, and consistency verification. The authors propose a fragment-wise processing strategy that recursively decomposes complex SQL into fragments (e.g., CTEs, subqueries) for localized optimization and correction, reducing the cognitive load on LLMs. The system also introduces an expert-guided hybrid self-learning mechanism, enabling rule extraction from DBMS logs and execution traces, validated and incorporated into a knowledge base over time. Experiments on BIRD, BIRD-CRITIC-Flash, and Payment-SQL workloads show performance improvements in accuracy and query efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1. The problems addressed in the paper are well motivated in OLAP, especially the problems beyond NL2SQL.\n\nS2. The fragments-based SQL decomposition with LLMs is reasonable and shows some promising results.\n\nS3. The proposed system integrates post-processing pipeline for SQL beyond NL2SQL and self-improving rule generation grounded in DBMS feedback."}, "weaknesses": {"value": "W1. The framework presents a broad toolkit, but the contributions are spread across many components. This makes the system feel somewhat fragmented, with each element receiving limited conceptual depth. A stronger anchoring around a single core technical innovation would significantly strengthen the work.\n\nW2. The proposed solution does not provide any formal guarantee of semantic preservation for rewriting (LLM + heuristics only).\n\nW3. The rule extraction stability and failure handling are not clearly explained. And knowledge base curation cost is not fully evaluated at scale. The authors should provide case studies of rule synthesis failures and mitigation.\n\nW4. The performance overhead raises practicality concerns, particularly for real-time or latency-sensitive query systems. A more detailed latency breakdown per module, along with error analyses, would significantly strengthen the evaluation."}, "questions": {"value": "Q1. How often does the rule-extraction process generate incorrect or redundant rules (false positives), and how costly is expert validation?\n\nQ2. Can fragment processing harm optimization opportunities by breaking global context?\n\nQ3. Does the toolkit support incremental feedback loops with execution feedback (runtime, cost estimates) beyond correctness logs?\n\nQ4. When LLM rewrites harm performance and how does SQLGOVERNOR handle SQL dialects (e.g., Snowflake, Oracle analytic functions)?\n\nQ5. What guardrails exist to prevent catastrophic LLM rewrites in production?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "mGOpFRdxdM", "forum": "DdD6lrUDP0", "replyto": "DdD6lrUDP0", "signatures": ["ICLR.cc/2026/Conference/Submission15813/Reviewer_mZXb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15813/Reviewer_mZXb"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15813/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762124951547, "cdate": 1762124951547, "tmdate": 1762926042077, "mdate": 1762926042077, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SQLGovernor, a unified LLM-powered toolkit for SQL governance (syntax correction, rewriting, modification, equivalence verification) with fragment-wise processing and a hybrid, expert-guided knowledge base. It shows consistent improvements on BIRD/BIRD-CRITIC and strong rewriting gains on an industrial Payment-SQL dataset."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1. Practical unified toolkit targeting real OLAP issues; clear modularization (Corrector/Rewriter/Modifier/Verifier).\nS2. Sensible design ideas: fragment-wise scoping, selective schema inclusion, knowledge retrieval.\nS3. Empirical gains over strong baselines; Payment-SQL demonstrates large end-to-end efficiency benefits."}, "weaknesses": {"value": "W1. Reproducibility and portability of industrial gains. Payment-SQL results are hard to reproduce (missing full env/specs, cold-cache controls, scripts); gains may depend on engine-specific hints/optimizers (e.g., MAPJOIN), with limited cross-DBMS evidence.\n\nW2. Fragment processing underspecified; semantic safety not assured. Core partition/recomposition lacks rigorous handling of correlated subqueries, window frames, HAVING/ORDER/LIMIT, and CTE materialization; no systematic stress tests or guarantees that local fixes preserve global semantics.\n\nW3. Equivalence verification too weak for safety-critical use. Limited to SELECT-based queries with ~78.9% accuracy; lacks hybrid fallback (SMT/constraint checks) on high-risk cases, error-mode analysis, and calibrated confidence/intervals.\n\nW4. Insufficient attribution and ablations (incl. self-learning risks). No clean isolation of contributions (fragment vs whole-query; retrieval vs none; self-learning on/off); limited sensitivity/drift control for induced rules, weak reporting on expert veto/rollback; potential retrieval contamination not audited.\n\nW5. Cost–quality and statistical rigor gaps. latency overhead without concrete mitigation (caching/pruning/fast paths) or Pareto analysis; baseline fairness/configs under-specified; improvements lack error bars, significance tests, or variability across seeds."}, "questions": {"value": "1. Can you release full Payment-SQL replication assets (DDL, data mock or generators, execution scripts, engine configs) and show cross-DBMS results (e.g., Postgres/StarRocks/SparkSQL) to establish portability?\n2. How do you guarantee semantic preservation with fragments in the presence of correlated subqueries, window frames, and HAVING/ORDER/LIMIT interactions? Any formal invariants or comprehensive stress suite?\n3. Can you add a hybrid verifier: selective SMT/constraint checks on uncertain or high-impact rewrites, with calibrated thresholds to contain risk?\n4. Please provide an ablation that toggles: {fragment on/off} × {knowledge retrieval on/off} × {self-learning on/off}, with statistical significance and error bars.\n5. What mechanisms prevent knowledge drift/bloat (misinduced rules)? Report expert veto rates, rollback policies, and rule lifecycle metrics.\n6. Can you present a cost–quality Pareto curve (latency vs EX/VES/SR) and concrete latency reductions via caching/pruning/fast-paths?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wzBsa8imVT", "forum": "DdD6lrUDP0", "replyto": "DdD6lrUDP0", "signatures": ["ICLR.cc/2026/Conference/Submission15813/Reviewer_P6Ns"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15813/Reviewer_P6Ns"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15813/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762233556438, "cdate": 1762233556438, "tmdate": 1762926041535, "mdate": 1762926041535, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}