{"id": "eiEIKGuqaf", "number": 8206, "cdate": 1758074230203, "mdate": 1763707631171, "content": {"title": "Hidden Breakthroughs in Language Model Training", "abstract": "Loss curves are smooth during most of model training, so visible discontinuities stand out as possible conceptual breakthroughs. Studying these breakthroughs enables a deeper understanding of learning dynamics, but only when they are properly identified. This paper argues that similar breakthroughs occur frequently throughout training but they are obscured by a loss metric that collapses all variation into a single scalar. To find these hidden transitions, we introduce POLCA, a method for decomposing changes in loss along arbitrary bases of the low-rank training subspace. We use our method to identify clusters of samples that share similar changes in loss during training, disaggregating the overall loss into that of smaller groups of conceptually similar data. We validate our method on synthetic arithmetic and natural language tasks, showing that POLCA recovers clusters that represent interpretable breakthroughs in the model's capabilities. We demonstrate the promise of these hidden phase transitions as a tool for unsupervised interpretability.", "tldr": "We decompose changes in loss along an arbitrary basis of the low rank training subspace to find breakthroughs obscured in the aggregate loss", "keywords": ["interpretability techniques", "loss disaggregation", "phase transitions"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c928f33462df1d4692724cb92947f68af9137ef3.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors introduce a new method (POLCA) for decomposing per-sample loss trajectories over training and validate this clustering as an interpretability technique in a synthetic arithmetic setting and a natural language setting. \n\nThe methodology involves approximating the change in per-sample loss between successive checkpoints using a second-order Taylor approximation in the weight update restricted to a subspace constructed from the top-k eigenvalues of the Hessian at each of a set of $T$ intermediate checkpoints. For efficiency, the authors additionally approximate the aggregate Hessian using a per-sample Hessian. This decomposes the loss into a set of \"projected losses,\" one for each basis element. \n\nTo use POLCA for interpretability, the authors cluster the projected loss trajectories. They demonstrate that clustering the projected losses splits samples into interpretable clusters and provide evidence that this beats baselines like clustering (non-decomposed) per-sample losses."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "**Problem**: The problem of finding ways to decompose the training trajectory is important and of growing interest, given the rise of the communities working on learning dynamics and developmental interpretability.  \n\n**Technique**: The general approach of modeling updates to losses using a Taylor approximation (plus various additional approximations) and clustering trajectories seems sensible and clever. Some of the particular choices around basis construction seem rather ad hoc. Still, this technique seems likely to become a go-to method and baseline for decomposing loss trajectories."}, "weaknesses": {"value": "**Interpretation**: Section 4 and the Figure 3–4 captions are missing a discussion of what \"recover the skill of X\" means. My concern here would be largely addressed if there were a description of how the ground-truth is established in the arithmetic setting (how do you know what the \"skills\" are here?). Section 5 is in a better place because it includes a discussion of how clusters are automatically labeled, but lines 450–451 are still vague. Does this mean that you manually come up with names for the labels in Figures 5 and 9–11? If this involves a manual labeling stage, then the tables in these figures should also report how accurate these hypotheses are (i.e., what fraction of in-cluster samples are explained by the given hypothesis?) It should be relatively simple to write automated tests once the tests have been formulated.  \n\nIf you address all of the above concerns, then I will change my review from a \"weak accept\" to an \"accept.\" Note: I am open to being convinced to change this even if you do not manage to run substantive new experiments and focus on making the writing around this clearer. \n\n**Benchmarks**: The baselines and ablations in appendices G and H are solid, but the benchmarking is still quite weak. In particular, I don't understand why I should trust the \"carry skill homogeneity\" metric. I would like to see some benchmarking on additional metrics/tests in the natural language setting. I'm sure it's possible to derive suitable benchmarking metrics from the automatic labeler.\n\nIf you address my previous concerns and significantly buttress the benchmarking, then I will change my review to a \"strong accept.\"\n\n**Compute**: The paper is missing a discussion of computational complexity. Hessians are expensive, even when you restrict to the top-k eigenvalues. This could be in the appendices. (The rest of this paragraph is optional.) It would also be valuable to include a (brief) comparison of the computational complexity against the baselines. In particular, I'm interested in understanding how much more compute-intensive second-order POLCA is versus first-order POLCA. If you get second-order POLCA essentially for free, then that would be worth mentioning as a strength in the main body. \n\n**Hyperparameters**: It is not clear what hyperparameters are being used for POLCA. This would be addressed by an additional set of tables in the appendices detailing the hyperparameters used for the Hessian estimation and the hyperparameters used for HDBSCAN. The paper would also benefit from some additional ablations to POLCA hyperparameters. I'd also be interested in a comparison to other clustering algorithms (though this is a marginal addition)."}, "questions": {"value": "Questions:\n- Is $B$ in (2) the same as $B_T$ from Section 3? Or is it $B_t$ for each individual timestep? \n- Some of these cluster error bars are super wide in figures 10–11. That suggests to me that the clustering technique is running into problems. Why cluster just the projected losses and not the full $Tk$ decomposed loss vector? What other ways have you thought about for constructing the basis? Why this one? \n- Do you really need this evolving Hessian? Why not just project against (the top Tk eigenvectors of) the final Hessian?\n- How accurate is this aggregate-to-per-sample-Hessian approximation in Appendix C really? Do you have an empirical comparison? \n\nSuggestions:\n\n**Improve the description of the method.** I found difficult to parse lines 224–240 the first time around. I didn't realize that \"we use a second-order approximation\" here referred to \"[adding on an additional quadratic term in (1)]\" rather than \"we use a second-order approximation [in order to choose the basis B].\" \n\nMy recommendation:\n- In (1), show the full second-order expansion. \n- Subsequently, define the LCA as the first-order term in this expansion. This would be a new equation (2)\n- On line 224, rephrase to \"we use the full second-order approximation in (1)\"\n- On line 235, rephrase to \"Exact computation of the second-order term in (1) would be intractable.\"\n\n**Put the clusters online!** It would be super valuable to be able to browse through the clusters on an interactive website. LLMs make this super easy nowadays."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GWD2PGWyKy", "forum": "eiEIKGuqaf", "replyto": "eiEIKGuqaf", "signatures": ["ICLR.cc/2026/Conference/Submission8206/Reviewer_sGxR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8206/Reviewer_sGxR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8206/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761692907371, "cdate": 1761692907371, "tmdate": 1762920156669, "mdate": 1762920156669, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General comment"}, "comment": {"value": "We thank the reviewers for their helpful and positive feedback. We appreciate how reviewers thought the method is a “seminal idea” [VeXn] and the problem is “well-motivated” [f3uN], “interesting and pertinent” [rAUf] and “important” [sGxR]. They agreed that our method has a solid theoretical foundation; in particular, reviewer f3uN mentioned the “clean derivation”, while reviewer rAUf said it is “well justified theoretically” and reviewer VeXn noted that the “mathematical justification and description is sound.” The reviewers also found our experiments to have “compelling results” [f3uN] and do a “remarkable job” at unsupervised analysis [VeXn]. We address the main concerns brought up by the reviewers below. \n\n1. **Definition of “breakthroughs in the loss”**\n\nAll of the reviewers brought up questions about what exactly a “breakthrough” means in the context of our paper. We have added Section 3.4 to make it clear that a training breakthrough in this context is a set of points that have a sudden change in the projected or exact loss and have run new experiments in Table 1 to compute which clusters have hidden breakthroughs. These experiments verify that POLCA discovers more clusters with breakthroughs than other approaches in the arithmetic setting. We have also revised Section 3, 4, and 5 in the paper to address the specific concerns brought up by each reviewer. \n\nOne shared question brought up by reviewers f3uN and rAUf is whether non-monotonic clusters can still represent breakthroughs. We argue that breakthroughs can still occur in non-monotonic clusters because (especially in the more complex natural language setting) there are a variety of skills for which learning one skill can cause changes in how the model performs predictions for the other and thus cause an opposite trend for the other skill. For instance, in the natural language setting, learning to predict a semicolon after an independent clause could affect how the model predicts periods at the end of a sentence. \n\n2. **Clarification of hyperparameter and method choices**\n\nThe reviewers ask for further elaboration on our choices for discarding oscillatory vectors [f3uN, rAUf, VeXn] as well as the basis construction [rAUf, sGxR] and automatic labeling [sGxR] and hyperparameter [VeXn, sGxR] details. We have revised the experimental and method sections to clarify these questions and have added details in Appendices D and H to provide a description of the reasoning for our basis construction and hyperparameter choices.\n\n3. **Benchmarking**\n\nReviewer sGxR requested additional benchmarking metrics in the synthetic and natural language settings. We have added additional standard clustering metrics in Appendices G and H, which further demonstrate that POLCA finds the highest quality clusters with respect to the carrying skill. \n\n4. **Computational complexity**\n\nReviewers f3uN and sGxR asked for additional discussion of the computational complexity of our method and how it can be applied at scale. The main challenge of scaling is computing the Hessian basis (however, we show in Appendix H that it is likely possible to use a different basis that is easier to compute with limited impact on the cluster quality) and ensuring that checkpoints are sampled at sufficient frequency. We have added additional discussion of the computational challenges of scaling this approach to the limitations section of the revised paper."}}, "id": "mplfhmhyTP", "forum": "eiEIKGuqaf", "replyto": "eiEIKGuqaf", "signatures": ["ICLR.cc/2026/Conference/Submission8206/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8206/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8206/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763707709841, "cdate": 1763707709841, "tmdate": 1763707709841, "mdate": 1763707709841, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The manuscript \"Hidden breakthroughs in Language Model Training\" introduces POLCA, an unsupervised learning analysis of the loss-function trajectory in training. The overall loss is projected onto a suitably defined orthogonal basis and decomposed in contributions for each data point. Subsequently, the decomposed trajectories are analyzed with the HDBSCAN (a density-based and hierarchical) clustering algorithm, chosen mainly for its ability to single out outliers and deal with variable density in the representation space."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The authors compare their approach to the previously introduced Loss Change Allocation (LCA) and convincingly debate that the introduced POLCA differs significantly from LCA. The mathematical justification and description is sound and the authors take great care to describe computationally feasible implementation solutions.\nAs for any unsupervised learning analysis, it is very difficult to define objective performance indicators as well as design demonstrative datasets where the algorithm finds what it is expected to find, without being too trivial. Keeping in mind these inherent difficulties, it is my opinion that the authors do a remarkable job in both aspects.\nAs seminal idea, the paper is polished enough to be publishable."}, "weaknesses": {"value": "However, I see a few weaknesses:\n- The authors use frequently terms like \"(conceptual) breakthrough\", \"phase transition\", \"skill\", without providing a proper scientific definition of them. As much as these terms are used in the related (and cited) literature, it would be better to attempt a self-contained definition to avoid talking to a very specific audience only.\n- it looks to me that nothing in the introduced methodology is specific to language models, but rather it could be applied to any (deep) network, with obviously different narrative related to the found clusters. It would be good to comment on this observation.\n- It is unclear if there is a somewhat optimal choice for k (for the top k ranked eigenvectors) and the frequency of checkpoints. There is a tension between computational burden and explicative power, but it would be nice to know if there is any suggested \"light\" analysis one may do preliminarily on the model and training data to assess good values of those parameters.\n- I did not find a description on how to, in practice, \"discard the oscillatory directions which do not provide an overall decrease in  loss over the course of training according to POLCA.\" (lines 200-201)"}, "questions": {"value": "I'd like the weaknesses points to be addressed"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Wqe1OGVCgf", "forum": "eiEIKGuqaf", "replyto": "eiEIKGuqaf", "signatures": ["ICLR.cc/2026/Conference/Submission8206/Reviewer_VeXn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8206/Reviewer_VeXn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8206/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761875951694, "cdate": 1761875951694, "tmdate": 1762920156211, "mdate": 1762920156211, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work investigates how training breakthroughs, sharp decreases in training loss attributable to a meaningful change in the model’s predictions, can be automatically discovered. Analyzing the loss aggregated over all examples can allow for the discovery of some breakthroughs. However, the authors argue that the interplay of how the model learns new skills, as well as how different examples may require different skills for correct prediction, leaves some breakthroughs obscured. To discover new breakthroughs, the authors propose a new approach, POLCA, that determines using a Taylor approximation the change in loss attributable to a specific direction in parameter space. Applying clustering methods to the projected loss of specific examples helps elucidate human interpretable features that the model has learned in order to decrease the loss. The authors experiment with their approach on a synthetic addition task with pre-specified skills, as well as a general task of language modelling over a natural language dataset. They demonstrate that POLCA can discover breakthroughs that are obscured in the aggregated, unprojected loss."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is well presented, with clear writing, high quality and intuitive figures, and a strong argumentative flow.\n- The selected problem of discovering training breakthroughs is interesting and pertinent to many areas, such as interpretability and the study of model training dynamics.\n- The new method, POLCA, is intuitive, well justified theoretically, and provides a satisfying means for attributing changes in loss to different directions in the parameter space. While it bears a strong similarity to its predecessor LCA, the change to an arbitrary basis over the parameter space is important, as these training breakthroughs should not be expected to be attributable to individual weights in the model.\n- The chosen experimental settings (synthetic counting task and natural language modelling) are good choices for both explanatory and argumentative purposes.\n- Some presented results are very interesting and convincing. For instance, demonstrating that there is a clear clustering on digit but not on carry skill (Figure 3) is interesting, and justifies the need for additional methods for discovering training breakthroughs."}, "weaknesses": {"value": "- [W1] The results presented are not entirely convincing in terms of showing that POLCA discovers training breakthroughs based on human interpretable features. In figure 4c and section 4.2, for instance, the authors claim that the first basis vector “recovers the digit skill”. However, clusters 1 and 3 are composites of multiple different digit positions, so it is difficult to say that all of those examples are having their loss improve because of the same skill, especially since one digit is excluded.\n- [W2] It is not always clear that the projected loss trajectories imply a training breakthrough. For figure 4a, does the slight decline of cluster 1 imply a training breakthrough? What is the implication that cluster 3 has a sharper projected loss drop, but has very few examples prescribed to it? Figure 5 shows directions where projected loss for some examples increases while for others it decreases. Why would the understanding of one human interpretable concept reduce understanding of a related concept?\n- [W3] It’s unclear how the method should be applied given certain methodological choices and the results presented. See [Q1] and [Q2]."}, "questions": {"value": "- [Q1] Notably only two of the 22 basis vectors collected for the experiment in Section 5.1 are presented in the main text, and 5 in the Appendix. This is after discarding several basis vectors as well. How should one think of these vectors, meant to represent a “breakthrough” since they present a mean decrease in the loss, when they also don’t provide a meaningful interpretation? Is POLCA meant to provide a set of results that have to be further interpreted and classified, rather than presenting a set of vectors that are inherently important?\n- [Q2] On line 315 and 316, it is mentioned that tokens are discarded if their loss increases along a given basis vector. How many tokens are typically discarded this way? If some tokens have their loss increase along this direction, how can we know it still represents a training breakthrough?\n- [Q3] Line 198 of section 3.1 states that by repeatedly adding top eigenvectors from successive checkpoint Hessians, directions of long-term stable movement will be added. However, since each successive Hessian is projected onto the nullspace of the current set of vectors, is this not more likely to collect directions reflective of local oscillations, as the stable directions are likely already represented in the collected set of vectors?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jFRkZ4sMvY", "forum": "eiEIKGuqaf", "replyto": "eiEIKGuqaf", "signatures": ["ICLR.cc/2026/Conference/Submission8206/Reviewer_rAUf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8206/Reviewer_rAUf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8206/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761919854458, "cdate": 1761919854458, "tmdate": 1762920155776, "mdate": 1762920155776, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose to decompose the learning process of neural networks into contributions based on subsets of the data and directions in parameter space, so as to more clearly exhibit “hidden” phase transitions or breakthroughs corresponding to individual concepts. This kind of study of neural network development is an emerging area of interest and they propose a new simple and (perhaps) scalable methodology POLCA for discovering these breakthroughs and attributing them to patterns in the data distribution. This methodology is tested in two settings: multi-digit addition where interpretable breakthroughs are found by the method, and language model training (40m parameters) where the results are interpretable but more mixed (in my opinion)."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "* Well motivated problem, and a clean derivation of a simple methodology for addressing it  \n* The paper is very clearly written, with appropriate and well-captioned figures  \n* Some quite compelling results in a toy setting with addition and carrying  \n* The automatic labelling for clusters in the language model setting seems to be well-done, I found this interesting in its own right."}, "weaknesses": {"value": "* Major: I am not completely convinced by the framing of “breakthroughs in the loss” being discovered in the smooth learning curve via POLCA for the larger language models. If I can summarise (8) we decompose the loss into a sum of components, which may be positive or negative. By their nature (since they depend on narrower subsets of the data distribution and directions in parameter space) these components will tend to have much more variety in their behaviour over training, and by construction them sum to something we know is generically fairly featureless. It is therefore no surprise to see empirically that there is such variation. This seems not sufficient in my mind to justify language like “breakthroughs in the loss projected onto that basis” in e.g. Fig 5\\. In both cases the projected losses either seem fairly uninteresting (cluster 2 in 5(a)(i) and cluster 3 in 5(b)(i)) or non-monotonic. Could the authors elaborate further on why I should look at these plots and see a strong analogy to Fig 4 (where I do agree with the interpretation of hidden breakthroughs).  \n* Minor: in both spirit and methodology the study here seems quite close to that used by Michaud et al (2024) and I think it is worth addressing the novelty of POLCA relative to that work directly.  \n* Minor: I think many of the figures with training steps on the x-axis would benefit from being plotted in log-scale. For instance all the interesting information in Fig 4 is compressed into the very beginning of the plot, making it hard to distinguish the clusters."}, "questions": {"value": "* What is the reasoning for excluding basis vectors where the loss increases? It does seem like even when projected onto the remaining basis vectors loss increases are typical for many clusters at some point in training.  \n* The only limit to scalability I see here is approximation of Hessians, which is quite memory intensive at scale. The experiments done here are in relatively small models but I do not doubt this could be done at larger scale. Could the authors comment on any significant limitations here?  \n* The aggregated loss decreases, but it has been widely observed that some individual token losses have non-monotonic behaviour. Even if we see a clear “breakthrough” trend where the projected loss plateaus, decreases and then plateaus, I’m unsure whether I would think of that as a genuine breakthrough. It would seem to depend on how semantically coherent the cluster is. Can the authors confirm that this concern is what is motivating the details in the “automatic labelling” section e.g. the 70% threshold? I may be incorrect, but this “unity” of the cluster seems to be quite a crux for the methodology and I’d appreciate seeing more detail on it."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZsnRvtPOV1", "forum": "eiEIKGuqaf", "replyto": "eiEIKGuqaf", "signatures": ["ICLR.cc/2026/Conference/Submission8206/Reviewer_f3uN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8206/Reviewer_f3uN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8206/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986079279, "cdate": 1761986079279, "tmdate": 1762920155240, "mdate": 1762920155240, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}