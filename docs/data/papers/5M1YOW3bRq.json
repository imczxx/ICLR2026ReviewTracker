{"id": "5M1YOW3bRq", "number": 24254, "cdate": 1758354611995, "mdate": 1763717043988, "content": {"title": "A foundation model with multi-variate parallel attention to generate neuronal activity", "abstract": "Learning from multi-variate time-series with heterogeneous channel configurations remains a fundamental challenge for deep neural networks, particularly in clinical domains such as intracranial electroencephalography (iEEG), where channel setups vary widely across subjects. In this work, we introduce multi-variate parallel attention (MVPA), a novel self-attention mechanism that disentangles content, temporal, and spatial attention, enabling flexible, generalizable, and efficient modeling of time-series data with varying channel counts and configurations. We use MVPA to build MVPFormer, a generative foundation model for human electrophysiology, trained to predict the evolution of iEEG signals across diverse subjects. To support this and future efforts by the community, we release the Long-term iEEG dataset, the largest publicly available iEEG dataset to date, comprising nearly 10,000 hours of recordings from heterogeneous clinical sources. MVPFormer leverages MVPA to achieve strong generalization across subjects, demonstrating expert-level performance in several iEEG tasks. MVPFormer surpasses state-of-the-art (SOTA) Transformer baselines in seizure detection across the Long-term, the MAYO, and the FNUSA datasets, while also achieving SOTA performance on four Brain TreeBank iEEG decoding tasks (volume, pitch, onset, and speech). We further validate MVPA on standard time-series forecasting and classification tasks, where it matches or exceeds the performance of existing attention-based models. Together, our contributions establish MVPA as a general-purpose attention mechanism for heterogeneous time-series and MVPFormer as the first open-source, open-weights, and open-data iEEG foundation model with SOTA clinical performance.", "tldr": "We introduce MVPA, a new attention mechanism for multi-variate time-series, and use it to build MVPFormer, a foundation model that achieves state-of-the-art performance on multiple tasks and is trained on the largest open iEEG dataset to date.", "keywords": ["time-series", "ieeg", "neurology", "foundation model", "attention", "transformer"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/289d6e2a062874c54ed0fd76c704d00995d7d00e.pdf", "supplementary_material": "/attachment/ef0b961c53b83a7335a61fcc33154263428b3f24.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces Multi-Variate Parallel Attention (MVPA), a novel self-attention mechanism that addresses the challenges of multi-variate time-series data with heterogeneous channel configurations. The MVPA mechanism is designed to handle time-series signals that vary across different subjects, particularly in clinical domains like intracranial electroencephalography (iEEG). The model efficiently separates attention into three components: content-based, time-based, and channel-based attention, enabling flexible processing of data without relying on fixed channel positions or global positional encodings. The authors apply MVPA to develop MVPFormer, a foundation model for human electrophysiology, which is trained on the Long-term iEEG dataset, the largest publicly available iEEG corpus. MVPFormer achieves superior generalization across subjects and outperforms state-of-the-art (SOTA) models in several clinical tasks such as seizure detection, while also excelling in general time-series forecasting and classification tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The introduction of the Multi-Variate Parallel Attention (MVPA) mechanism is innovative and addresses the challenge of heterogeneous channel configurations in multi-variate time-series data. The way MVPA separates content, temporal, and spatial attention is novel and can be generalized to other time-series domains beyond iEEG.\n\n2. The MVPFormer model, powered by MVPA, shows impressive performance in several iEEG-related tasks, including seizure detection, outperforming existing models. The model demonstrates expert-level performance on the Long-term iEEG dataset and outperforms SOTA methods across various clinical benchmarks.\n\n3. The paper releases the Long-term iEEG dataset, the largest publicly available iEEG dataset to date, containing nearly 10,000 hours of recordings. This is a significant contribution to the research community, addressing the issue of data scarcity in iEEG research.\n\n4. The commitment to open-source the dataset, code, and weights is a major advantage for reproducibility and allows other researchers to build upon this work.\n\n5. The use of MVPA and MVPFormer is not limited to iEEG but is shown to generalize well to classical time-series forecasting and classification tasks, offering a broader impact in the field of time-series modeling."}, "weaknesses": {"value": "1. While the results on seizure detection are impressive, the paper lacks a detailed real-world scenario evaluation, particularly regarding how the model would perform in a clinical setting with real-time data or noisy recordings. The authors should consider adding practical deployment considerations and edge-case performance, such as handling low-quality signals or data interruptions.\n\n2. MVPA introduces a level of computational complexity, especially in the time- and channel-based terms. While the paper provides solutions to mitigate this, it would benefit from more in-depth comparisons with simpler models that might achieve similar performance with less computational overhead.\n\n3. Although MVPFormer performs well in seizure detection and on Brain TreeBank tasks, the paper could benefit from broader evaluation across more clinical tasks (e.g., epilepsy classification or other cognitive tasks), especially those commonly encountered in clinical settings.\n\n4.While the Long-term iEEG dataset is a valuable contribution, it has limitations, such as lack of electrode location information, which may limit its utility in some clinical contexts. The paper mentions this but does not fully address how future versions of the dataset might overcome this limitation.\n\n5. While MVPFormer outperforms existing methods like Brant-2, BrainBERT, and others, a more detailed analysis of how these models compare in terms of generalization across different subjects and datasets would strengthen the argument for MVPA’s superiority. Specific examples of failure modes in the comparison would be helpful."}, "questions": {"value": "1. How does MVPA perform in scenarios with significantly different time series compared to iEEG, particularly in domains like financial time series or sensor data? Could the model’s flexibility be leveraged for other domains?\n\n2. While the results show strong generalization across subjects, could the model handle extremely varied electrode setups (e.g., patients with unusual electrode configurations)? How does MVPA cope with potential signal distortions caused by non-standard setups?\n\n3. With the Long-term iEEG dataset being very large (10,000 hours), what are the limitations in terms of processing and inference time when scaling to even larger datasets, especially in real-time clinical settings?\n\n4. Could MVPFormer's real-world clinical application be affected by variability in electrode placement (e.g., anatomical differences across patients)? Have you tested MVPFormer on data from patients who have had non-standard electrode placements due to medical conditions?\n\n5.While MVPFormer is open-source, how are you ensuring patient privacy and safety when providing access to the dataset and model weights? Are there any restrictions on data sharing due to privacy concerns that might hinder the broader clinical adoption of this model?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Skyiz96g7c", "forum": "5M1YOW3bRq", "replyto": "5M1YOW3bRq", "signatures": ["ICLR.cc/2026/Conference/Submission24254/Reviewer_dxZg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24254/Reviewer_dxZg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761897620488, "cdate": 1761897620488, "tmdate": 1762943018592, "mdate": 1762943018592, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a new method for learning representations of multi-channel intracranial activity. The input is one embedding vector per segment of activity, augmented with position vectors for time and for channel. Gains in efficiency can be had by reusing attention computations for channels that share the same time. During pretraining, a discriminative loss is used. Downstream evaluation is done on a seizure detection task and audio-linguistic tasks. Additionally, the paper releases 10K hours of iEEG recordings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "●\tOverall, this paper represents a very strong contribution to the community.\n●\tReleases a large amount of data. I am personally not aware of a larger publicly available iEEG dataset. This is a big boon to the community. Especially so, since many other foundation models for intracranial signal train on private data, e.g., BrainWave.\n●\tEvaluation is thorough: the authors use their own seizure detection task as well as the Brain Treebank tasks.\n●\tPerformance on the epilepsy detection task exceeds the current state of the art"}, "weaknesses": {"value": "●\tAm I misunderstanding something? The paper refers to a \"generative\" objective, but the loss seems to be discriminative, i.e., an InfoNCE loss? The output of the model is in the embedding space, not neural activity, correct?\n●\tLine 364: The claim is that the choice of objective is justified by an ablation. But if I read appendix G.14 correctly, it seems that there is only justification for doing pretraining, not the specific type of pretraining, i.e., some other choice of pre-training objective. This is not a major weakness, but more precise wording is probably needed.\n●\tIn the related works section, it would be good to discuss various factored approaches that are proposed for spatio-temporal data. For example, for processing movies: https://arxiv.org/pdf/2106.05968."}, "questions": {"value": "●\tFor comparison, you can cite BrainWave: A Brain Signal Foundation Model for Clinical Applications https://arxiv.org/pdf/2402.10251. They have 35K hours of data. But most of it is EEG and most of it is private.\n●\tFigure 2: In the legend, what is \"two-step\"? It looks like this is defined in Fig 7 of the appendix, but it would be good to have that in the main text somewhere.\n●\tLine 329: \"We must also consider that our evaluation setup involves many more subjects and ictal events than are reported for human experts,\" — does this mean that the expert annotations contain false negatives? I.e., periods of activity that are not marked as seizures, but should be?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "wxrEQykYcC", "forum": "5M1YOW3bRq", "replyto": "5M1YOW3bRq", "signatures": ["ICLR.cc/2026/Conference/Submission24254/Reviewer_qWbc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24254/Reviewer_qWbc"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761960513799, "cdate": 1761960513799, "tmdate": 1762943018379, "mdate": 1762943018379, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Multi-Variate Parallel Attention (MVPA), an attention mechanism that splits attention into content, temporal, and channel components to better handle heterogeneous multi-channel time series. Building on MVPA, the authors train MVPFormer, a generative pre-trained foundation model for iEEG on a newly released “Long-term iEEG” corpus of about 10k recording hours. MVPFormer generalizes zero-shot across patients for seizure detection and performs competitively on four Brain TreeBank decoding tasks, while MVPA also matches or exceeds strong baselines on standard time-series forecasting and classification benchmarks. \n\nMain contributions include:\n1 MVPA: a self-attention variant that separately models content, time, and channel structure to support generalization under variable, heterogeneous channels.\n\n2 MVPFormer: a generative, MVPA-powered foundation model for electrophysiology that outperforms vanilla-attention baselines for seizure detection and improves over a matched discriminative model.\n\n3 Long-term iEEG dataset: release of a large public corpus, roughly 9,300 to 10,000 hours across 68 subjects, enabling open data, code, and weights for the community."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1 MVPA factorizes self-attention into content, time, and channel to handle heterogeneous, variable-channel signals that standard attention struggles with. MVPFormer’s generative pretraining and the Long-term iEEG corpus add fresh angles on both model and data.\n\n2 The method is solid  and scalable, with a coherent pretraining recipe followed by light adaptation.\n\n3. The three MVPA components and their roles in the logits are well-explained with figures. Pretraining and fine-tuning protocols are modular, and the dataset description is specific enough to judge external validity.\n\n4  Addressing variable, heterogeneous channels is a core deployment blocker, and MVPA tackles it directly. The approach likely transfers beyond iEEG, while the large open corpus and a usable pretrained model can accelerate community progress."}, "weaknesses": {"value": "1 Zero-shot tests use manual channel selection at inference, and preprocessing, post-processing, and thresholds are not harmonized across baselines. The reported gains may stem from pipeline differences rather than the core method.\n\n\n2 Overstated “expert-level” claim: A single Kappa threshold from prior work is used instead of a same-dataset, same-protocol human comparison. No per-subject confidence intervals or significance tests are reported.\n\n3 The MVPA decomposition lacks a rigorous derivation and error bounds. How summed logits are scaled or weighted is unclear, and notation/dimensions are inconsistent in places.\n\n4: The stated complexity does not square with a local-window content term, and there are no reproducible runtime or memory curves versus sequence length, channel count, or window size. Missing direct comparisons with other efficient attention variants.\n\n5: Pretraining choices (negative sampling strategy, temperature, hard negatives, sample count) are not systematically ablated. Cross-dataset protocols differ, and strong baselines are not adapted for channel heterogeneity, weakening SOTA claims."}, "questions": {"value": "1 Can you provide a fully automatic end-to-end inference pipeline with no manual channel selection, and report side-by-side results on the same test set? Use identical preprocessing, post-processing, and thresholding across all models, select thresholds on a shared validation split, and include per-subject distributions with 95% CIs plus clear leakage controls (window overlap, session boundaries). \n\n2 Can you give a rigorous derivation from dual-encoding attention to the sum of content, time, and channel terms, stating the conditions under which cross terms are dropped and providing error bounds? Please clarify how the summed logits are scaled or weighted (and whether weights are learnable). Show ablations that remove each term, swap relative for absolute encodings, and vary channel count; add a synthetic study to demonstrate when each component is required.\n\n3 Can you release reproducible runtime and memory curves versus sequence length T, channel count C, and local window L, reflecting the expected O(T·C·L) behavior for the content term? Provide controlled throughput comparisons on the same hardware and batch size against strong efficient-attention baselines (axial or factorized attention, linear-time variants, FlashAttention with GQA), with scripts and fixed seeds.\n\n4 Can you supply a same-dataset, same-protocol head-to-head with human experts, including inter-rater agreement, event-level error breakdowns, and statistical tests? Please adapt strong baselines for channel heterogeneity, enforce a unified evaluation protocol across datasets, and add few-shot curves to separate pretraining benefits from protocol artifacts. If the method still leads under these stricter comparisons, the “expert-level” statement becomes defensible."}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety", "Yes, Potentially harmful insights, methodologies and applications", "Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "details_of_ethics_concerns": {"value": "Privacy, security, safety: Long-duration human iEEG can be re-identified when linked with site or timing metadata, and the paper does not document a de-identification audit, adversarial linkage tests, or access controls.\n\nResponsible research practice: IRB approval and consent for open release are not clearly stated, label provenance and annotator compensation are unspecified."}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5zck2tkHvR", "forum": "5M1YOW3bRq", "replyto": "5M1YOW3bRq", "signatures": ["ICLR.cc/2026/Conference/Submission24254/Reviewer_cFg6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24254/Reviewer_cFg6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986703630, "cdate": 1761986703630, "tmdate": 1762943018133, "mdate": 1762943018133, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Multi-variate Parallel Attention (MVPA), which disentangles content, temporal, and spatial attention to handle heterogeneous time-series with varying channel configurations, and applies it to build MVPFormer, an iEEG foundation model achieving SOTA results on seizure detection and decoding tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well-written with a clear motivation for the problem and an architectural approach.\n\n- The strong architecture design enables practical foundation models for clinical iEEG\n\n- MVPA's decomposition of attention into content, temporal, and spatial components is novel and specifically addresses the real-world challenge of heterogeneous channel configurations in clinical data.\n\n- The model demonstrates superior performance on seizure detection across three datasets and competitive results on Brain TreeBank decoding tasks and standard time-series benchmarks."}, "weaknesses": {"value": "- The model is trained only on iEEG data, whereas foundation models typically leverage diverse datasets across multiple domains and modalities.\n- The model is fine-tuned on target tasks, so calling evaluation on \"unseen subjects\" zero-shot is inaccurate. Normally, a true zero-shot would require no task-specific training data. Should be called fewshots? \n- Section 5.3 abruptly shifts to generic time-series forecasting and classification tasks, creating a disjointed narrative that dilutes the paper's clinical focus.\n- The paper is missing an ablation study of the proposed attention and the tree components in the main body."}, "questions": {"value": "What specific criteria define a foundation model in your view, and how does MVPFormer satisfy these conditions, given that it's trained on a single modality (iEEG) from one domain and requires fine-tuning for downstream tasks rather than demonstrating broad zero-shot generalization?"}, "flag_for_ethics_review": {"value": ["Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SnKGa68cQw", "forum": "5M1YOW3bRq", "replyto": "5M1YOW3bRq", "signatures": ["ICLR.cc/2026/Conference/Submission24254/Reviewer_oKKd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24254/Reviewer_oKKd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762027407301, "cdate": 1762027407301, "tmdate": 1762943017728, "mdate": 1762943017728, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "We are deeply grateful to all Reviewers for their dedicated service and for providing thoughtful and interesting feedback.\n\nWe have taken all the reviews to heart and have updated the manuscript to reflect all the changes made following the Reviewers' suggestions. In addition to the individual responses, we wish to highlight here the main improvements to our work.\n\nAs suggested by Reviewers oKKd and cFg6, we have added ablations of all three components of our multi-variate parallel attention (MVPA) on the 3 general time-series forecasting tasks.\n\n|  | MVPA | Content-only | Time-only | Channel-only | None |\n|---|---|---|---|---|---|\n|  | MSE ↓ | MSE ↓ | MSE ↓ | MSE ↓ | MSE ↓ |\n| ETTh1 | **0.45** | 0.46 | 0.46 | 0.46 | 0.47 |\n| ETTh2 | **0.38** | 0.38 | 0.38 | 0.38 | 0.40 |\n| Weather | **0.25** | 0.27 | 0.27 | 0.26 | 0.27 |\n\nThe results show that **all three components are necessary to achieve the full performance of MVPA**, and that the difference is more pronounced when the signal is more strongly multi-variate (21 channels of Weather vs 7 channels of ETTh1/2).\n\nAs suggested by Reviewer cFg6, we have added an automated channel selection step, producing a fully automated end-to-end evaluation pipeline that ensures maximum fairness in comparisons.\n\n| Model | Attention | Kappa ↑ | f1 ↑ | sens ↑ | fp/h ↓ |\n|---|---|---|---|---|---|\n| MVPFormer | MVPA | 0.61 | 0.59 | 0.72 | 0.15 |\n| MVPFormer-S | MVPA | 0.57 | 0.53 | 0.71 | 0.12 |\n| Brant-2 | Vanilla | 0.06 | 0.01 | 0.01 | 0.11 |\n| BrainBERT | Vanilla | 0.00 | 0.00 | 0.00 | 0.00 |\n| MV-Llama | Vanilla | 0.11 | 0.01 | 0.01 | 0.02 |\n\nRemarkably, the introduction of **this pipeline increases the performance of our models to 0.61 and 0.57 Kappa scores**, respectively. We also follow Reviewer cFg6's suggestion and include 95% confidence intervals in all our seizure detection results on the Long-term iEEG dataset, strengthening the statistical validity of our evaluation.\n\nWe also implement Reviewer dxZg's suggestion to evaluate MVPFormer's resilience to noise, which is a fundamental characteristic in potentially noisy clinical environments.\n\n|          | Episodic  |       |       |       | Raw    |\n| :------- | :-------- | :---- | :---- | :---- | :---- |\n| SNR      | Kappa ↑ | f1 ↑    | sens ↑  | fp/h ↓  | f1 ↑    |\n| None     | 0\\.61     | 0\\.59 | 0\\.72 | 0\\.15 | 0\\.51 |\n| 60dB     | 0.58         | 0.54     | 0.71     | 0.12     | 0.49    |\n| 50dB     | 0\\.54     | 0\\.50 | 0\\.72 | 0\\.13 | 0\\.47 |\n| 40dB     | 0\\.36     | 0\\.34 | 0\\.74 | 0\\.46 | 0\\.31 |\n| 30dB | 0\\.12     | 0\\.12 | 0\\.71 | 1\\.22 | 0\\.10 |\n\nOnce more, the results show that **our model is designed with clinical relevance in mind, as it maintains expert-level performance up to 50dB SNR**.\n\nIn the context of this review period, we have also updated our runtime and memory usage baselines to include other attention variants, such as linear attention and Flash Attention. We have reworked all relevant aspects of the manuscript as suggested by the Reviewers, and are convinced that our work is now better and clearer thanks to all the feedback.\n\nWe remain available to address any further concerns and are looking forward to engage in interesting discussions with all the Reviewers."}}, "id": "xLFp3RKSyZ", "forum": "5M1YOW3bRq", "replyto": "5M1YOW3bRq", "signatures": ["ICLR.cc/2026/Conference/Submission24254/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24254/Authors"], "number": 12, "invitations": ["ICLR.cc/2026/Conference/Submission24254/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763716953596, "cdate": 1763716953596, "tmdate": 1763716953596, "mdate": 1763716953596, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}