{"id": "WgZ9C4q9nH", "number": 21877, "cdate": 1758323034713, "mdate": 1759896898702, "content": {"title": "ZIP-FIT: Embedding-Free Data Selection via Compression-Based Alignment for Code", "abstract": "Data selection is crucial for optimizing language model (LM) performance on specific tasks, yet most existing methods fail to effectively consider the target task distribution. Current approaches either ignore task-specific requirements entirely or rely on approximations that fail to capture the nuanced patterns needed for tasks like Autoformalization or code generation. We introduce \\texttt{ZIP-FIT}, a data selection framework that uses compression to directly measure the alignment between potential training data and the target task distribution. Our key insight is that compression-based similarity captures both syntactic and structural patterns relevant to the target task (like code), enabling more precise selection of task-relevant data for code. In extensive evaluations on Autoformalization and Python code generation, \\texttt{ZIP-FIT} significantly outperforms leading baselines like DSIR and D4. Models trained on \\texttt{ZIP-FIT}-selected data achieve their lowest cross-entropy loss up to 85.1% faster than these baselines, demonstrating that better task alignment leads to more efficient learning. In addition, \\texttt{ZIP-FIT} performs selection up to 65.8% faster than DSIR and two orders of magnitude faster than D4. In addition, we achieve 18.86% Pass@1 on HumanEval compared to LESS's 18.06% while being approximately 2000 times faster. Notably, \\texttt{ZIP-FIT} shows that smaller, well-aligned datasets often outperform larger but less targeted ones, demonstrating that a small amount of higher quality data is superior to a large amount of lower quality data.", "tldr": "", "keywords": ["data-curation", "llm"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d22d8605ba0b86751d03c871591a451242841b12.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes an efficient and embedding-free data selection method inspired by gzip compression. By comparing with related methods on code generation and autoformalization, the authors demonstrate that the proposed ZIP-FIT is simple and effective."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed method, inspired by gzip compression, is simple yet effective.\n2. ZIP-FIT demonstrates better performance and faster convergence speed compared with DSIR, D4, LESS."}, "weaknesses": {"value": "1. This paper only evaluates ZIP-FIT on program synthesis tasks. The proposed ZIP-FIT is a task-agnostic method, yet the authors only evaluate it on one task, which significantly limits the generalization of ZIP-FIT.\n2. Even for these two program synthesis tasks, the evaluation is not comprehensive and clear. For the limitation of comprehensiveness, the authors only evaluate on two datasets, HumanEval and ProofNet. Besides, the authors only show the results of one LLM, Gemma-2b. For example, the authors only show the pass@1 rates of Gemma-2-2b on HumanEval, without CodeGemma-2b. For the limitation of clear experiment settings, the authors do not reveal the details about training and prompting. For example, what is the setting in the first row in Table 1 and Table 2? Zero-shot performance? Or fine-tuning with full datasets?\n3. As the authors admit that ZIP-FIT is negatively influenced by the diversity of original datasets (I don't take this point as a weakness of the paper), there is no analysis on how much it is influenced by the diversity. A quantized relationship is required for estimation in real-world applications."}, "questions": {"value": "There are some missing references for tables and LaTeX compilation errors in the paper. Please have a check."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aRWXHVaE4v", "forum": "WgZ9C4q9nH", "replyto": "WgZ9C4q9nH", "signatures": ["ICLR.cc/2026/Conference/Submission21877/Reviewer_DPeZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21877/Reviewer_DPeZ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21877/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761649128798, "cdate": 1761649128798, "tmdate": 1762941967288, "mdate": 1762941967288, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a simple but effective method to select an aligned set of data from a large corpus to align language models to specific tasks. Instead of embeddings, n-grams or losses, the normalized compression distance is used. This allows fast data selection on CPU, and the experiments show that highly aligned data is selected on structured domains."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The method is simple, fast, and can be confidently applied to any domain with strong syntactic structures. Experiments show strong performance on domains where the task involves heavily structured elements (like code).\n\nWith the exception of some missing table references (line 255, line 290) and citations style (I'd cite a (method, author) combination as `method (authors)` instead of `method authors`, for example, `Lean4 (Moura et al. (2015))` on line 163), the presentation is clear and easy to follow."}, "weaknesses": {"value": "The paper considers \"only\" two benchmarks with highly specific domains. Given that the number of domains is small, it is reasonable to implement an even more domain-specific approach, for example, a simple regex test for finding `def \\w+\\(` can find documents with Python code, on CPU, without requiring compression. Complex domain combinations (like Multipl-E [1]) will allow to make a more definitive claim of the relevance of this method.\n\n[1] Cassano, F., Gouwar, J., Nguyen, D., Nguyen, S., Phipps-Costin, L., Pinckney, D., ... & Jangda, A. (2023). Multipl-e: A scalable and polyglot approach to benchmarking neural code generation. IEEE Transactions on Software Engineering, 49(7), 3675-3691."}, "questions": {"value": "Did you consider any experiments on plain-text tasks? Disregarding subtle semantics, I can imagine natural language structures the compress well, and ZIP-FIT might work better than expected.\n\nMinor:\n* There's some \\latex stuff going on on line 452.\n* As mentioned, there's some missing table references."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AjxzLVSaMP", "forum": "WgZ9C4q9nH", "replyto": "WgZ9C4q9nH", "signatures": ["ICLR.cc/2026/Conference/Submission21877/Reviewer_Z1tU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21877/Reviewer_Z1tU"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21877/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761862406229, "cdate": 1761862406229, "tmdate": 1762941967057, "mdate": 1762941967057, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ZIP-Fit, a compression-based data-selection method for domain-specific fine-tuning that avoids the use of embeddings or gradient features. It measures alignment between source and target data via Normalized Compression Distance, capturing syntactic and structural similarity. This enables efficient, task-relevant data selection, yielding better downstream accuracy, faster convergence, and lower compute cost than DSIR, D4, or LESS. Experiments on Python code generation and Lean4 autoformalization show higher Pass@1 and Pass@5 scores and much faster data selection and training."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "+ The investigated problem is timely, and the proposed ZIP-FIT method is refreshingly simple: compute a compression-based alignment score between each candidate source sample and the target examples, rank, and take top-K. There’s no embedding model to train, no gradient logging, no GPU-heavy similarity search.\n+ The paper demonstrates that smaller, well-aligned subsets selected by ZIP-FIT train faster and land at lower cross-entropy than larger but noisier mixtures. \n+ Experiments demonstrate strong downstream metrics on the HumanEval and math autoformalization.\n+ Detailed analysis. The paper doesn’t just report numbers. It correlates ZIP-FIT alignment scores with downstream cross-entropy loss across datasets and shows that higher compression-based alignment predicts lower loss after fine-tuning."}, "weaknesses": {"value": "- The scope of domains might be limited.  The paper itself acknowledges that compression-based alignment may miss higher-level paraphrastic/semantic similarity in natural language, where style can vary without changing meaning.\n- There are some presentation issues, including:\n- [line 091] “code-geneation” -> generation\n- [Fig. 4, Table 2] “AutoFormalization” or “Autoformalization”?\n- [line 255] “Table ??”\n- mixed usage of ‘k/K’, e.g., “353K”, “353k”, “695k”, etc."}, "questions": {"value": "- Q1: How exactly are target splits chosen for alignment?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "F16m7JwIQk", "forum": "WgZ9C4q9nH", "replyto": "WgZ9C4q9nH", "signatures": ["ICLR.cc/2026/Conference/Submission21877/Reviewer_W6Xv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21877/Reviewer_W6Xv"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21877/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761921407152, "cdate": 1761921407152, "tmdate": 1762941966739, "mdate": 1762941966739, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "ZIP-FIT is a simple, embedding-free data selection method for LM fine-tuning that uses compression to measure how well each candidate training example aligns with a small set of target examples: compute a Normalized Compression Distance (NCD)–based alignment, rank the source pool, and train on the top-K subset. The authors show this one-shot, CPU-only selector yields faster convergence and better downstream results than DSIR/D4 (and other baselines) on code generation and autoformalization—e.g., 18.86% Pass@1 on HumanEval in 32 s and 14.0% Pass@5 on Lean4, while running up to 65.8% faster than DSIR. The intuition is that structurally similar texts compress well together (low NCD), so compression acts as a cheap proxy for task alignment"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "ZIP-fit presents a resource efficient data selection technique that is embedding free and faster as compared to prior works. Further the proposed technique outperforms baselines in Lean4 and HumanEval Python generation over various open-source models."}, "weaknesses": {"value": "- The authors mention embedding-based (like BERT), and Continual pre-training-based selection metrics, but do not compare against them. Hence, the benefits of the technique cannot be truly seen against embedding-based baselines other than just that the proposed technique is computationally efficient.\n-  The paper does not show a finetune on all as a reference curve that the ZIP-fit method can be compared against\n- The zip-fit approach depends on the curation of a high-quality representative benchmark set. Further, there can be multiple ways towards solving the same problem (for instance, using for loops against while loops in Python and writing lambda functions). Hence, ZIP-fit selected data might not contribute towards learning multiple approaches of solving the same problem.  \n\n\nMissing citations: In various places citations are missing. Line 255, 290, 1215, 1320\nFormatting: The appendix is incorrectly formatted, and the discussion section contains some formatting code that the authors forgot to remove."}, "questions": {"value": "Please look at the weaknesses.\n\nOther questions:\n- What is the performance of a naive uniform/random sampling baseline on both tasks ? \n- What is the comparison with cross-entropy–difference (Moore–Lewis) selection ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "n/a"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "RFmzZZA9me", "forum": "WgZ9C4q9nH", "replyto": "WgZ9C4q9nH", "signatures": ["ICLR.cc/2026/Conference/Submission21877/Reviewer_JhTj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21877/Reviewer_JhTj"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21877/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990457382, "cdate": 1761990457382, "tmdate": 1762941966078, "mdate": 1762941966078, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces ZIP-FIT, a novel embedding-free data selection framework for fine-tuning large language models (LLMs), particularly in domain-specific tasks such as autoformalization and code generation."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper’s core insight — using compression as a proxy for task alignment — is conceptually elegant and computationally lightweight. Extensive experiments on two challenging domains (Autoformalization and Python Code Generation) demonstrate consistent improvements in both convergence speed and downstream performance. And the paper is well-written and easy to follow."}, "weaknesses": {"value": "1. While the method performs impressively on code and mathematical text, it remains unclear how well it generalizes to open-domain natural language tasks, where semantics and paraphrasing are more complex and less syntactically driven.\n2. ProofNet has limited linguistic variation, and its syntax regularity may inflate alignment correlations (R² = 0.9).\n3. Limited Benchmark Scope: the two domain Autoformalization and Python code generation in the experiments, share a highly structured syntax and low semantic ambiguity, making them especially favorable to compression-based similarity metrics.."}, "questions": {"value": "Please refer to the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8RpliBfIvy", "forum": "WgZ9C4q9nH", "replyto": "WgZ9C4q9nH", "signatures": ["ICLR.cc/2026/Conference/Submission21877/Reviewer_CJZu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21877/Reviewer_CJZu"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission21877/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762526948387, "cdate": 1762526948387, "tmdate": 1762941965349, "mdate": 1762941965349, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}