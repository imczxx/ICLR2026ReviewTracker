{"id": "ONGhOee3qt", "number": 1577, "cdate": 1756893653823, "mdate": 1759898200250, "content": {"title": "Distributed Specialization: Rare-Token Neurons in Large Language Models", "abstract": "Large language models (LLMs) struggle with representing and generating rare tokens despite their importance in specialized domains. We investigate whether LLMs develop internal specialization mechanisms through discrete modular architectures or distributed parameter-level differentiation. Through systematic analysis of final-layer MLP neurons across multiple model families, we discover that rare-token processing emerges via \\textit{distributed specialization}: functionally coordinated but spatially distributed subnetworks that exhibit three distinct organizational principles. First, we identify a reproducible three-regime influence hierarchy comprising highly influential plateau neurons, power-law decay neurons, and minimally contributing neurons which is absent in common-token processing. Second, plateau neurons demonstrate coordinated activation patterns (reduced effective dimensionality) while remaining spatially distributed rather than forming discrete clusters. Third, these specialized mechanisms are universally accessible through standard attention pathways without requiring dedicated routing circuits. Training dynamics reveal that functional specialization emerges gradually through parameter differentiation, with specialized neurons developing increasingly heavy-tailed weight correlation spectra consistent with Heavy-Tailed Self-Regularization signatures. Our findings establish that LLMs process rare-tokens through distributed coordination within shared architectures rather than mixture-of-experts-style modularity. These results provide insights for interpretable model editing, computational efficiency optimization, and understanding emergent functional organization in transformer networks.", "tldr": "", "keywords": ["large language models", "mechanistic interpretability"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b65692fdcfe47555a3503e3ad4ef66c9a7049ae5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper claims rare tokens are handled by distributed specialization rather than modularity, supported by (i) a \"plateau\" of highly influential last‑layer MLP neurons for rare tokens, (ii) coordinated but spatially scattered activations, (iii) no dedicated attention routing, and (iv) heavier‑tailed weight spectra for those neurons."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. **Relevant question**: The question of distributed representations is of obvious interest within interpretability. Techniques for dealing with distributed representations such as sparse autoencoders form the backbone of the mainstream interpretability stack as practiced at frontier labs like Anthropic.\n2. **Clear, testable framing** in investigating the modular vs. distributed hypothesis. \n3. **Cross‑model comparisons** (GPT‑2 and Pythia; Fig. 3 in Appendix, p. 13) hint at robustness across scale."}, "weaknesses": {"value": "The empirical case relies almost entirely on last‑layer analyses, has underspecified methodology (rare token selection, neuron clustering, MI estimation, spectral fitting), weak or inconsistent statistics (no uncertainty, minimal significance testing, mixed modularity results), and presentation/framing issues. As written, the core claim is overstated relative to the evidence.\n\nA. Core claim overreaches the scope of evidence\n\nThe conclusion \"LLMs process rare tokens via _distributed specialization_ and not modularity\" is drawn solely from last‑layer MLP analyses (explicitly chosen \"as it directly projects into the unembedding matrix,\" lines 105–106). However, the absence of modular signatures in this part of the model does not rule out modular circuitry in earlier parts of the model (earlier MLPs, attention blocks, residual stream). As such, the headline claim is stronger than the evidence base.\n\nB. The methodology is underspecified\n\nRare token selection: I’m mildly concerned about the 15% cutoff for rare tokens. The paper says robustness checks across thresholds were performed, but provides no results; please include these in the appendix. Also, tokens below the \"elbow point\" are excluded because they behave \"idiosyncratically,\" which likely removes the very cases most diagnostic for rare‑token behavior. I could imagine a stronger case being made for this, but it does require additional experimental evidence.\n\nNeuron clustering: It is unclear how the authors determine where to put the boundaries between the regimes. From what I can tell, the distinction between the plateau and power-law regimes seems arbitrary. If I squint when I glance at the common tokens, I believe I can make out some interesting discrete jumps also towards the left-hand side. The y-axis ranges for these tokens are wider, which could mask a slight plateau for common tokens. The evidence showing additional models (Figure 3) provides some weak evidence for a consistent plateau among rare tokens, but this is inconclusive.\n\nAll this is to say that the neuron clustering/regime separation methodology requires further specification. Ideally, this process should be automated using e.g. a principled change-point analysis, and additional metrics should be reported arguing for the final regimes as the correct set of regimes. \n\nMutual information: What probability distributions are being used (5) is missing a definition of the probability distributions? Many other details are missing: are the activations discretized and binned? What is the sample size? MI is very sensitive to these kinds of details. They should be reported and additional ablations should be run. \n\nC.  Statistics and reporting are weak\n\nThere are some statistical tests reported in Table 2, but this is otherwise missing from the other parts of the paper. Additionally, there are many different methodologies being invoked, but no hyperparameter ablations reported or included. There are many details of the experimental methodology that should be reported in appendices that are currently missing that not only make it difficult to reproduce but also make it difficult to evaluate whether the techniques are reliable. \n\nD. Presentation and framing issues\n\nThe paper is quite difficult to read, largely because of the current split into methodology and results. This split makes sense for most papers, but in this case, it is actually limiting because it requires the reader to remember five different methodologies when going through each results subsection. It would be much more effective to group each methodology together directly with the results. \n\nThis presentational challenge reflects a deeper framing/motivation issue. Currently, the paper presents a grab bag of different techniques. The reasons for choosing any particular technique is missing. \n\nThere are some other presentation issues:\n- The abstract states \"Training dynamics reveal that specialization emerges gradually … with increasingly heavy‑tailed spectra\" yet **no training‑trajectory plots or checkpoints** are presented in Sec. 4 (only cross‑sectional results). This is a direct mismatch between abstract and results.\n\n- Figure 1: This figure is not clearly self-explanatory. First, the figures should be labeled with what the colors of each stage correspond to. The `rank` can be better explained in the figure or caption. It's not immediately obvious from the figure that the ablated loss is per-neuron. When I first looked at this, I assumed it was per-sample (since this is common for ablations). The stage labels in the caption disagree with the labels and ordering of the regimes in lines 305–316.\n\n- Table 1 (& Sec 4.2): It is unclear from an immediate glance which columns are supposed to be rare vs common tokens. Why are these named according to the names from the regimes in the previous analysis? There is no justification at all for focusing in on regime-specific neurons rather than studying all neurons. \n\n- An open-source repo is mentioned but not provided. \n\nThis paper requires significant additional work to strengthen the experimental methodologies and weaken the conclusions drawn from these methodologies. I am unlikely to change my review, barring exceptional changes."}, "questions": {"value": "Questions:\n- Line 55: Is there a specific reason to cite mixture-of-experts as the inspiration for the modular hypothesis? From my understanding, the inspiration for looking for modularity goes back much further, both within interpretability and especially within neuroscience.\n\nSuggestions:\n- There is currently no mention of superposition/polysemanticity. I would strongly recommend grounding the discussion of modular vs. distributed representations in this existing literature.\n- Line 112: (Typo) Missing space between \"generalization\" and the opening parenthesis.\n- Lines 136–138: It is unclear how specialization follows from sparse coding and the IB framework. I would recommend clarifying this.  \n- Line 443: (Typo)\"On the other hans\""}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jt0rrbsOPI", "forum": "ONGhOee3qt", "replyto": "ONGhOee3qt", "signatures": ["ICLR.cc/2026/Conference/Submission1577/Reviewer_jNsm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1577/Reviewer_jNsm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1577/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761783227932, "cdate": 1761783227932, "tmdate": 1762915822264, "mdate": 1762915822264, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work analyses the phenomenon of rare-token processing within the Pythia and GPT-2 large language model (LLM) families, and specifically how such processing is organized within their architecture. It compares two hypotheses: the modular hypothesis, in which dedicated mechanisms and routings exist to process rare tokens, and the distributed hypothesis, in which the same computational substrates process both rare and common tokens. Its primary contribution is the finding that rare-token processing primarily occurs via distributed mechanisms in analyses that span attention heads (Gini coefficients, individual vs. group ablation) and MLP neurons (plateau neuron effective dimensionality and modularity) in the final few layers."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The authors conduct analyses across multiple model sizes for both Pythia and GPT-2 and show very consistent results for each of their five overarching results (hierarchical influence, activation coordination, spatial organization, attention routing, and functional specialization) across the families and sizes to tackle the distributed vs. modular hypothesis question in language models.\n\n2. The different analyses complement each other well, showing strong breadth. For example, the plateau neurons discovered in Section 4.1 are further analyzed in Section 4.2, 4.3 and 4.5."}, "weaknesses": {"value": "1. While the breadth of analysis is strong, the corresponding depth of each analysis feels shallow at times. First, and most importantly, as the authors acknowledge, this analysis is limited to final layer MLP neurons. As many lines of work show distinct layerwise phenomena, concluding that “LLMs implement distributed rather than modular specialization for rare token processing” (L89-90) may be overgeneralized, representing a significant caveat to the findings.\nAdditionally, each of the five overarching results is supported by a single diagnostic, without robustness tests or cross-method validation. Further analyses would be beneficial in supporting the claims. For example, extending the activation coordination analysis in Section 4.2 to weight-space similarities or comparing multiple community detection metrics in Section 4.3 could strengthen the claims.\n\n2. Regarding the terminology used, for the spatial organization analysis of MLP neurons, because the index of MLP neurons within a layer has no innate meaning, as the physical location within the brain does, the term “spatial” seems misused. The analysis method itself uses activations as the underlying metric, which is functional rather than spatial. Thus, it seems that this important axis through which to study the distributed vs. modular hypothesis in the original neuroscience context was not truly touched upon within the analyses, unless justified or explained further within the text.\n\n3. In L58-60, the “distributed hypothesis proposes that specialization emerges through parameter-level differentiation within shared computational substrates.” While the text does analyze specialization, further analysis of the notion of sharing beyond the layer level would be appreciated. For example, between rare tokens and common tokens, what is the overlap of the top ranked neurons by their influence? As in, how influential for common tokens is the most influential neuron for rare tokens? Do rare and common tokens share important neurons, not just the entire layer as a whole?\n\n4. Somewhat of a contradiction within the paper is that the fundamental existence of plateau neurons itself seems to suggest some degree of modularity rather than distributive processing. As in, because the plateau neurons seemingly occupy a coordinated subspace based on their activations, that subspace itself represents modular processing. While this is interesting in its own right, the authors should consider presenting and discussing this with more nuance to eliminate any confusion, as concepts extended from neuroscience may not map immediately to transformers\n5. The model that the data in Figure 1 is derived from is not specified. Is it from a single model? If so, is there any way to normalize and condense the information in Figure 3 and update Figure 1 with it? Showing data across multiple models in the main text may be more convincing.\n\nOverall, despite the timeliness and breadth of analysis, the analysis is limited to the final layer and the distributed vs modular hypothesis framework requires more nuance and explanation in the context of language models. These points weaken some of the central conclusions of the paper, motivating my score of 4."}, "questions": {"value": "1. The cutoff for the plateau vs. power-law vs. rapid decay regions is not specified. How are the cutoffs determined?\n2. Regarding Figure 3, when looking at the GPT-2 family, it seems that, for common tokens, low-rank neurons have lower log delta loss than would be predicted by a power law, almost manifesting as an inversion of the plateau neurons for rare tokens. Do the authors have any insight for this?\n3. It is understandable that analyses are conducted on older, densely routed language models due to the availability of their training data token distribution. However, do the authors have any insight on this phenomenon in more modern architectures, such as SwiGLU models? As mixture-of-experts architectures are mentioned, it seems that it would make sense to include such architectures as a control to demonstrate the modular hypothesis."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xuhULHGPCI", "forum": "ONGhOee3qt", "replyto": "ONGhOee3qt", "signatures": ["ICLR.cc/2026/Conference/Submission1577/Reviewer_DVTq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1577/Reviewer_DVTq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1577/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761800271677, "cdate": 1761800271677, "tmdate": 1762915821969, "mdate": 1762915821969, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates how LLMs process rare tokens. The authors test two competing theories: a “modular hypothesis,” which predicts clustered neurons, and a “distributed hypothesis,” which predicts spatially scattered but functionally coordinated subnetworks. The paper claims that LLMs develop distributed specialization based on an analysis of final-layer MLP neurons and identifies a unique “three-regime” influence hierarchy for rare tokens and finds these neurons are functionally coordinated but spatially distributed."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1: The paper tackles an important problem in mechanistic interpretability; namely, the question of how transformers process rare tokens is of high value to the community. The distinction between the modular and distributed framing is clear and grounded.\n\nS2: The identification of the three-regime structure for rare tokens. The influential plateau provides a clear method for identifying the subnetwork of rare-token neurons, and demonstrating that this plateau vanishes for common-token processing is convincing evidence of targeted specialization.\n\nS3: Showing a high correlation between rare and common token attention patterns and that single-head ablations have little effect whereas full-layer ablations are extremely damaging provides solid evidence towards the distributed theory."}, "weaknesses": {"value": "W1: In Table 3, the caption states “Modularity scores (Modul.) show inconsistent patterns, indicating distributed rather than clustered organization.” This table clearly shows higher modularity scores for Plateau compared to Random which contradicts the paper’s main claim.\n\nW2: These experiments only examine the final layer of the networks so it is an overreach that this implies the distributed hypothesis. It is possible these rare-token neurons are clustered MoE-style in earlier layers of the network and simply aggregated via a distributed network in the final layer.\n\nW3: Excluding the actual rarest tokens misses important data. It’s possible the \"distributed\" mechanism only applies to \"moderately-rare\" tokens (those below the 15th percentile but above the elbow) and the modular hypothesis applies to the rarest tokens. This paper’s findings are then limited to the “moderately-rare” tokens which reduces its applicability and scope."}, "questions": {"value": "Q1: Could you please clarify the interpretation in Table 3 taking into account W1 from above?\n\nQ2: Could you justify using mean-ablation over zero-ablation or resample-ablation? Given that specialized rare-token neurons are likely sparse, mean-ablation could be an unnatural choice.\n\nQ3: Are the “rare token neurons” from this work the same as the “token frequency neurons” in Stolfo et al. 2024?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1aJOw7yBxR", "forum": "ONGhOee3qt", "replyto": "ONGhOee3qt", "signatures": ["ICLR.cc/2026/Conference/Submission1577/Reviewer_GfPw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1577/Reviewer_GfPw"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1577/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971412856, "cdate": 1761971412856, "tmdate": 1762915821747, "mdate": 1762915821747, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper the authors investigate how LLMs handle rare tokens. They contrast two competing hypotheses: the modular hypothesis (functional separation) and the distributed hypothesis (“specialization emerges through parameter-level differentiation within shared computational substrates”). Through a variety of metrics they accumulate evidence which suggests that the distributed hypothesis is preferred."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "Strengths:\n\n* A wide range of metrics are applied to the problem  \n* A range of models up to 1.5B are examined  \n* The spectral differentiation does show significant differences between rare and random tokens"}, "weaknesses": {"value": "Weaknesses:\n\n* I am not convinced by the distinctions being made between rare and common token processing in Fig 1\\. The assertions about a “power law regime” seem to rely entirely on visual inspection of a log-log plot, which is not a valid methodology. There is no attempt made to fit a power law to the relevant segment  \n* The distinction between the two hypotheses in the introduction is hard for me to follow: terms like “spatially clustered”, “dedicated attention routing pathways” and so on all seem quite informal. Some of them are clarified later in the text, but overall the paper seems to proceed from a somewhat vague characterisation of its main hypothesis to a suite of low-level metrics which are asserted to capture the high level hypotheses. I am not convinced that this is the case, which means I find it hard to assess the significance of the empirical results."}, "questions": {"value": "Questions for the authors:\n\n* How exactly were the boundaries between the colored regions in Fig 1 determined?  \n* I do not find the references to cognitive neuroscience compelling in the current draft. Could you elaborate on why you have chosen to put this framing so prominently in the introduction?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "msLInsYp8j", "forum": "ONGhOee3qt", "replyto": "ONGhOee3qt", "signatures": ["ICLR.cc/2026/Conference/Submission1577/Reviewer_pApb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1577/Reviewer_pApb"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1577/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972742110, "cdate": 1761972742110, "tmdate": 1762915821625, "mdate": 1762915821625, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}