{"id": "aUlHK31TAz", "number": 24165, "cdate": 1758353473374, "mdate": 1763728259414, "content": {"title": "On Coreset for LASSO Regression Problem with Sensitivity Sampling", "abstract": "In this paper, we study coreset construction for LASSO regression, where a coreset is a small, weighted subset of the data that approximates the original problem with provable guarantees. For unregularized regression problems, sensitivity sampling is a successful and widely applied technique for constructing coresets. However, extending these methods to LASSO typically requires coreset size to scale with O(\\mathcal{G}d), where d is the VC dimension and \\mathcal{G} is the total sensitivity, following existing generalization bounds. A key challenge in improving upon this general bound lies in the difficulty of capturing the sparse and localized structure of the function space induced by the \\ell_1 penalty in LASSO objective. To address this, we first provide an empirical process-based method of sensitivity sampling for LASSO, localizing the procedure by decomposing the functional space into independent spaces, which leads to tighter estimation error. By carefully leveraging the geometric properties of these localized spaces, we establish tight empirical process bounds on the required coreset size. These techniques enable us to achieve a coreset of size \\tilde{O}(\\epsilon^{-2}d\\cdot((\\log d)^3\\cdot\\min(1,\\log d/\\lambda^2)+\\log(1/\\delta))), which ensures a  (1\\pm\\epsilon)-approximation for any \\epsilon,\\delta\\in(0,1) and \\lambda > 0. Furthermore, we give a lower bound showing that any algorithm achieving a (1+\\epsilon)-approximation must select at least \\Omega(\\frac{d\\log{d}}{\\epsilon^2}) rows in the regime where \\lambda=O(d^{-1/2}). Empirical experiments show that our proposed algorithm is at least 4 times faster than the existing LASSO solver and more than 9 times faster on half of the datasets, while ensuring high solution quality and sparsity.", "tldr": "", "keywords": ["LASSO regression", "sampling algorithm"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/405b12f405427f3d01f654f60a52383e4adc84ba.pdf", "supplementary_material": "/attachment/537bd17602ec11c085cf755ebe704ecce6b5ebfb.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces ``LASSO-Sens``, the first coreset construction method for the standard LASSO regression problem based on sensitivity sampling.\nThe key challenge in applying coreset techniques to LASSO stems from the complex, non-smooth geometry of the function space induced by the l1 penalty, which complicates standard analysis . The authors overcome this barrier by developing a localized empirical process method that effectively decomposes the function space into independent residual and l1 penalty components.\nThis new analysis yields a provably tight coreset size up to logarithmic terms. The authors confirm this bound is nearly optimal by providing a matching lower bound .\n\nExperimental results supplement the theory, demonstrating that ``LASSO-Sens`` is significantly more efficient (four times faster) than the standard LASSO solver and substantially outperforms a uniform sampling coreset baseline, all while maintaining high solution quality and sparsity."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "**High-Quality Presentation:** The paper is exceptionally well-written and easy to follow. The authors do an excellent job of situating their work within the existing literature, clearly motivating their approach and making the theoretical breakthroughs highly compelling.\n\n**Significant Theoretical Contribution:** The primary contribution, a comprehensive and provably near-tight coreset size bound, is a significant theoretical achievement. Overcoming the noted analytical hurdles of bounding the sampling error for the LASSO objective is a noteworthy accomplishment. *Though, I am unfamiliar with this field and defer to other reviewers to confirm the novelty of this result within the broader literature.*\n\n**Comprehensive Analysis:** The paper's theoretical claims are well-supported, complete with a matching lower bound in the relevant regime, which confirms the near-optimality of the proposed method. *Again, I defer to other reviewers to confirm that the relationship between $\\lambda$ and $d$ is common for comparing the here proven upper and lower bounds.*"}, "weaknesses": {"value": "The primary weakness of the paper lies in its experimental validation. While the theory is the main focus, the empirical results section feels underdeveloped and, in some cases, seems to contradict the narrative that LASSO-Sens is the superior practical approach.\n\n**Overstated Claims of Empirical Superiority:** The text emphasizes multiplicative speedups of ``LASSO-Sens`` over the full LASSO procedure. However, this comparison obscures a more critical one: the performance against the LASSO-Uniform baseline.\n\n**LASSO-Sens vs. LASSO-Uniform:** Across many of the provided plots (Figures 1, 2, and appendix figures), ``LASSO-Sens`` does not demonstrate a clear, significant advantage over ``LASSO-Uniform`` in terms of final loss . In several instances (e.g., Synthetic $\\lambda = 0.5, 1$), ``LASSO-Uniform`` even appears to achieve a better loss.\n\n**Lack of Statistical Rigor:** The plots do not include statistical error bars, and the text does not clarify if the results are from a single replication or averaged over many trials. Without this, it is impossible to determine if the small observed differences between ``LASSO-Sens`` and ``LASSO-Uniform`` are statistically significant or simply noise. Given that ``LASSO-Uniform`` is a lighter-weight approach (avoiding the sensitivity score computation), its comparable effectiveness in these experiments weakens the practical argument for the proposed method."}, "questions": {"value": "**Statistical Significance:** Are the results in Figures 1 and 2 (and appendix figures) from a single run or averaged over the 10 trials mentioned? Could you please add error bars (e.g., standard error or 95% CIs) to the plots to allow for a proper statistical comparison between ``LASSO-Sens`` and ``LASSO-Uniform``?\n\n**Practical Justification:** Given that ``LASSO-Uniform`` performs comparably, and sometimes better, than ``LASSO-Sens`` in the provided experiments, could you further emphasize the empirical justification for using the more complex sensitivity sampling method? The theoretical advantage is clear, but the practical advantage over this strong, simple baseline is not.\n\n**Cost of Sensitivities:** Do the runtimes reported for ``LASSO-Sens`` (e.g., in Table 1) include the pre-processing time required to compute the sensitivity scores? A clear breakdown of the (sampling vs. solving) costs for both coreset methods would be essential for a fair comparison."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qKLE64b94T", "forum": "aUlHK31TAz", "replyto": "aUlHK31TAz", "signatures": ["ICLR.cc/2026/Conference/Submission24165/Reviewer_VhuG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24165/Reviewer_VhuG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24165/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761835977217, "cdate": 1761835977217, "tmdate": 1762942968654, "mdate": 1762942968654, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies coresets for standard LASSO (least-squares + $\\ell_1$ penalty) using sensitivity sampling. The authors propose a sensitivity-based sampling algorithm for augmenting matrix A′ = [A −b] and localizing the function class into a residual $\\ell_2$ part and an $\\ell_1$‑penalty part, then, they apply empirical process and chaining tools to bound Gaussian diameter and metric entropy on the localized sets, and finally uses those bounds to show a coreset of size is smaller than linear regression."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Localizing the analysis into residual $\\ell_2$ and $\\ell_1$ penalty components and applying Gaussian/chaining bounds on each piece is a fresh and appropriate way to tackle the complexity introduced by the $\\ell_1$ term."}, "weaknesses": {"value": "- A thorough discussion and comparison with the existing literature, such as Avron et al and Chhaya et al, is missing."}, "questions": {"value": "1. In Theorem 7, why $\\log(\\frac{1}{\\delta})$ is an additive term in the coreset size?\n\n2. The lasso negative result in Chhaya et al seems to be general, that is, a smaller strong coreset or sketch or summarization is impossible for any $\\lambda$, i.e., the claim is independent of how the coreset is constructed and then analyzed. Can you clarify how your result negates this claim and if it does not negate, then how do you give a strong coreset guarantee on lasso. \n\n3. How is the coreset size using the localization of the function class related to other standard regularized regressions, such as ridge (Avron et al) and modified lasso?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wTenNpitqA", "forum": "aUlHK31TAz", "replyto": "aUlHK31TAz", "signatures": ["ICLR.cc/2026/Conference/Submission24165/Reviewer_FxuS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24165/Reviewer_FxuS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24165/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762024224624, "cdate": 1762024224624, "tmdate": 1762942968365, "mdate": 1762942968365, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper considers the problem of coreset construction with sensitivity sampling for LASSO. Note that the coreset construction via sensitivity sampling is a known method. The main contributions of this paper are providing theoretical guarantees for sensitivity sampling in LASSO. The authors then provide some experiments to validate their methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is clear and easy to follow."}, "weaknesses": {"value": "First things first, I am not an expert in this field, so my evaluation might be unreliable. I did not check the proof, and I will revisit it in the rebuttal phase. Here are my two cents on the paper's weaknesses.\n\n1. Comparison with sketching methods: I see that the experiments of this paper were only conducted with Vanilla LASSO, sensitivity sampling, and uniform sampling. However, they did not compare this method with other approaches for handling big data, like projection methods/sketching. As a general audience, I expect a comparison here, to see if I should really care about sensitivity sampling for LASSO, or if advanced sketching methods for LASSO should work for me/or even work better than the proposed method, when the number of samples ($n$) is large.\n\n2. Comparison with modified LASSO coreset: again, I see that the problems of sensitivity sampling with modified LASSO (using $\\|x\\|_1^2$ instead of $\\|x\\|_1$) are also considered. The authors should also compare their method with this one. Although the authors claimed that the modified LASSO introduces some unexpected correlation between features, it is good to know how their performance compares to their proposed approach. \n\n3. Cost of sensitivity score calculation: I see that the computation of the coreset score scales cubically ($O(d^3)$) with the number of features $d$. It should not be the problem for the case $d \\ll n$ as the authors considered. However, in a general high-dimensional case, $d$ will scale with $n$, and if $d/n = \\alpha$ for a constant $\\alpha$, there would be a serious problem. I expect that in such a case, sketching methods would work better. Can the authors comment on this point?\n\n4. Dependence on regularization parameter $\\lambda$: I see that the bound on the coreset size includes a term proposional to $1 / \\lambda^2$. I expect that things would get ugly when $\\lambda$ is close to 0 (e.g., weak regularization). Can the authors comment on this point?\n\nOverall, I am uncertain whether the experiments presented in this paper are sufficient. However, I think that the main punchline of this paper is not totally about the experiments, but the theoretical guarantees the authors established for the coreset construction with sensitivity sampling for LASSO. However, I am not an expert and can only have lukewarm support for this paper, with a low confidence score."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "KJ9PpbWb8q", "forum": "aUlHK31TAz", "replyto": "aUlHK31TAz", "signatures": ["ICLR.cc/2026/Conference/Submission24165/Reviewer_SFut"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24165/Reviewer_SFut"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24165/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762188539020, "cdate": 1762188539020, "tmdate": 1762942967994, "mdate": 1762942967994, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}