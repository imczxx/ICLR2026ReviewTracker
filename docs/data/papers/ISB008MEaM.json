{"id": "ISB008MEaM", "number": 14009, "cdate": 1758226814958, "mdate": 1759897396466, "content": {"title": "Bayesian Self-Distillation for Image Classification", "abstract": "Supervised training of deep neural networks for classification typically relies on hard targets, which promote overconfidence and often limit calibration, generalization, and robustness. Self-distillation methods aim to mitigate this by leveraging inter-class and sample-specific information present in the model’s own predictions, but often remain dependent on hard targets, limiting their effectiveness. With this in mind, we propose Bayesian Self-Distillation (BSD), a principled method for constructing sample-specific target distributions via Bayesian inference using the model’s own predictions. Unlike existing approaches, BSD does not rely on hard targets after initialization. BSD consistently yields higher test accuracy (e.g.\n+1.4\\% for ResNet-50 on CIFAR-100) and significantly lower Expected Calibration Error (ECE) (-40\\% ResNet-50, CIFAR-100) than existing architecture-preserving self-distillation methods for a range of deep architectures and datasets. Additional benefits include improved robustness against data corruptions, perturbations, and label noise. When combined with a contrastive loss, BSD achieves state-of-the-art robustness under label noise for single-stage, single-network methods. Code will be made available upon acceptance.", "tldr": "", "keywords": ["Self-distillation", "Knowledge Distillation", "Bayesian Methods", "Calibration", "Robustness", "Image Classification"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2c97089c53154802919d92e9fbfeb7df649a81d1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Bayesian Self-Distillation (BSD), which integrates ideas from self-distillation and evidence-based (Dirichlet) learning. Instead of using hard labels, BSD updates per-sample target distributions through a Bayesian process that treats model predictions as evidence. The method no longer relies on hard targets after initialization and is evaluated on CIFAR-10/100 and Tiny ImageNet. Experiments show moderate improvements in test accuracy and Expected Calibration Error (ECE), with additional robustness to label noise and data corruption."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Proposes a principled probabilistic view of self-distillation using Dirichlet updates.\n2. The method is lightweight and can be easily integrated into existing pipelines.\n3. Provides theoretical framing for “dark knowledge” and sample-specific uncertainty.\n4. Well-written and reproducible; includes clear algorithmic steps and ablation on γ and c."}, "weaknesses": {"value": "1. Limited improvement: Accuracy and calibration gains (ECE/NLL) are modest, often within 1–2 pp or comparable to label smoothing or Mixup which both also designed for acc and calibration.\n2. Since the objective is to learn the calibrated confidence distribution, maybe training with a calibration focus loss such as [1] may result in a more reliable dirlclet distribution.\n2. Small-scale evaluation: Only CIFAR-10/100 and TinyImageNet are used; ImageNet-scale or domain-shift (OOD) results are missing.\n3. Calibration not tested on OOD data: A model trained with soft labels should ideally generalize to distributional shifts, but this is not evaluated.\n4. Missing comparison to smoothing baselines: Methods such as Label Smoothing, Adaptive LS as BSD appears closely related.\n5. No warm-up or convergence analysis: The method may benefit from warm-up epochs or temperature schedules; this is not explored.\n6. Unclear practical gain: Given similar computational cost, it is unclear when BSD would be preferred over simpler smoothing strategies.\n\n[1] Dual focal loss for calibration"}, "questions": {"value": "As before"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9H8gDgkOH2", "forum": "ISB008MEaM", "replyto": "ISB008MEaM", "signatures": ["ICLR.cc/2026/Conference/Submission14009/Reviewer_cnVX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14009/Reviewer_cnVX"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14009/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761391887133, "cdate": 1761391887133, "tmdate": 1762924502950, "mdate": 1762924502950, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel training method termed Bayesian Self-Distillation (BSD), which employs a principled Bayesian framework to dynamically construct and evolve sample-specific soft target distributions during training, completely eliminating reliance on conventional hard targets after initialization. The core innovation of BSD lies in treating the model's own predictions as Bayesian evidence, enabling efficient updates via a conjugate Dirichlet prior and incorporating a discount factor to prevent target ossification. This approach allows the model to more effectively uncover and leverage inter-class relationships and sample-specific information called ‘dark knowledge’ inherent in the data, while inherently conferring strong robustness to label noise. Extensive experimental validation demonstrates that BSD consistently enhances the generalization capability and probability calibration of diverse deep architectures across multiple datasets, significantly outperforming existing mainstream self-distillation methods. Furthermore, while maintaining manageable computational cost, BSD achieves state-of-the-art performance among single-stage, single-network methods in handling noisy labels, thereby offering a theoretically grounded and practically effective solution for building more reliable and robust deep learning models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper demonstrates outstanding performance in theoretical elegance and experimental rigor. Its proposed Bayesian Self-Distillation framework establishes a theoretical system through rigorous mathematical derivation by adopting a Bayesian perspective to treat model predictions as dynamic evidence, leveraging the conjugate relationship between Dirichlet priors and multinomial likelihoods to derive efficient target update formulas, while innovatively introducing a discount factor to resolve confidence accumulation rigidity. \n\n2. This study designs a systematic and comprehensive evaluation scheme, not only compares BSD against traditional training and various self-distillation methods on accuracy and calibration metrics but also analyzes the impact of key hyperparameters through ablation studies, thoroughly investigates synergistic effects with different data augmentation strategies, and visually demonstrates BSD's enhanced capability to mine inter-class structures and sample-specific features. Particularly commendable is the detailed analysis of computational efficiency and memory overhead, coupled with candid discussions of current limitations and future directions."}, "weaknesses": {"value": "1. The authors themselves acknowledge that its effectiveness on very large-scale datasets, such as ImageNet, remains unvalidated, and the introduction of new hyperparameters like prior strength and discount factor complicates model interpretability. In the context of noisy labels, the Temporal Ensembling method proposed in 2016 surprisingly achieves comparable performance to BSD, which contradicts the paper's emphasis on \"strong robustness to label noise\" as a core advantage and raises doubts about the actual superiority of its noise resistance capability. \n\n2. Furthermore, this self-distillation approach, which relies entirely on the model's own predictions to update targets, is highly susceptible to cognitive rigidity and error amplification. If the model forms erroneous representations early due to data biases or training instability, BSD’s iterative mechanism continuously reinforces these deviations, which is a critical issue that the paper seemingly fails to address. Additionally, the source code for this paper has not been made publicly available, making it difficult to examine the implementation details of the method."}, "questions": {"value": "1.  The paper states in its introduction that methods using either soft or hard labels are significantly affected by noisy labels. Why does Temporal Ensembling (TE) from 2016, which also uses soft labels, achieve strong performance in the noisy label tests?\n\n2.  Self-distillation should, in theory, suffer from error amplification due to incorrect model predictions. Shouldn't this issue be explicitly discussed?\n\n3.  In Figure 6, why was the DLB method only trained for 100 epochs, while all other methods were trained for 200 epochs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "RKURxFqxsE", "forum": "ISB008MEaM", "replyto": "ISB008MEaM", "signatures": ["ICLR.cc/2026/Conference/Submission14009/Reviewer_s5Y5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14009/Reviewer_s5Y5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14009/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969102721, "cdate": 1761969102721, "tmdate": 1762924502598, "mdate": 1762924502598, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Bayesian Self-Distillation (BSD), a novel method for self-distillation in image classification. The core idea is to move away from supervision signals based on one-hot hard targets and instead use soft targets. The method frames the problem through a Bayesian inference lens: it models the latent class distribution with a Dirichlet prior and, at each step, uses the model's own current prediction as evidence to perform a Bayesian update, yielding a posterior distribution. This posterior, modulated by a discount factor to weigh new predictions more heavily over time, then serves as the new supervision signal. The experimental evaluation demonstrates that BSD achieves some improvements in accuracy, calibration (ECE), and robustness to corruptions and label noise across multiple datasets (CIFAR-10/100, Tiny ImageNet) and architectures (ResNet, DenseNet, ViT) when compared to other self-distillation techniques."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe core idea of treating the target distribution as a random variable to be inferred via a Bayesian update is novel in the context of self-distillation. Decoupling the training process from the original hard targets after initialization is a principled approach to leveraging the model's \"dark knowledge\" and allows for the creation of richer, sample-specific supervisory signals.\n2.\tThe paper is supported by comprehensive empirical evidence. BSD consistently outperforms existing architecture-preserving self-distillation methods in terms of raw accuracy, particularly on more complex datasets like CIFAR-100 and TinyImageNet. The improvements in model calibration are large. Furthermore, the method demonstrates superior robustness against data corruptions, perturbations, and especially label noise."}, "weaknesses": {"value": "1.\tThe central weakness of the paper is the conceptual justification for using the model's own prediction as \"observation\" or \"evidence\" in the Bayesian update rule. Bayesian inference is about updating a prior belief based on new evidence from the external world (i.e., observed data). In this work, the \"evidence\" is generated by the model itself. This is conceptually analogous to forming a belief about a coin's bias, and instead of actually flipping the coin to collect data, one simply imagines the outcome of a flip and uses that imagined outcome to update the belief. This fundamental step requires a much stronger justification than is currently provided.\n2.\tThe presentation of the method is overly reliant on mathematical formalism and fails to build sufficient intuition for the reader. The paper lacks a clear, high-level motivation for why this specific Bayesian framework is the right tool for the job. The method section consists primarily of a sequence of formulas without concrete examples to make the process tangible. The paper would be improved by focusing more on explaining the intuition behind the formulas."}, "questions": {"value": "1.\tRegarding Weakness 1: Could you provide a more detailed and intuitively acceptable explanation for why the model's current prediction can be treated as valid, external evidence within a Bayesian framework? I will raise my score if this point can be satisfactorily addressed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "1Effu9xY7R", "forum": "ISB008MEaM", "replyto": "ISB008MEaM", "signatures": ["ICLR.cc/2026/Conference/Submission14009/Reviewer_aqga"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14009/Reviewer_aqga"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14009/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762182368206, "cdate": 1762182368206, "tmdate": 1762924501924, "mdate": 1762924501924, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies bayesian self-distillation for image classification. It takes a bayesian version of the original targets per image during the training process in order to improve calibration and generalization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "* Some of the empirical findings are interesting. For example, Figure 3 that shows that the proposed method results in finding semantic patterns between different classes is interesting. Another interesting finding is Figure 6, where it is shown that the proposed method mitigates the double descent phenomenon. Although this feature is also appearing using another baseline method called Temporal Ensembling (TE) and is not unique to the proposed method. \n* Empirically, the proposed method outperforms other baseline, particularly, the closest one in nature which is the progressive self-knowledge distillation (PS-KD). This is shown both in terms of generalization (Table 1), and in my opinion, more so in terms of improvements brought to calibration (Table 2)."}, "weaknesses": {"value": "* The proposed method lacks novelty and sufficient reasoning on the main differences with the baseline counterparts. For example, an explanation of the motivation behind switching from PS-KD to the proposed method is missing. Why instead of the teacher model the original targets are used? Why this would be a better training strategy. The current empirical analysis to highlight the main differences between the proposed method and the similar baseline methods is insufficient and not convincing.\n* The empirical results are very limited for the scope of the paper. The standard deviation are missing from the tabular results. For example, if the authors observe that “The performance gains are most pronounced on the more complex datasets” it would be worth investigating this further to verify the statement beyond just 3 datasets."}, "questions": {"value": "The main question to the authors, as mentioned in the above section, is the motivation behind the proposed algorithm and a deeper comparison with other similar methods."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "T3KQayfFWs", "forum": "ISB008MEaM", "replyto": "ISB008MEaM", "signatures": ["ICLR.cc/2026/Conference/Submission14009/Reviewer_ht5v"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14009/Reviewer_ht5v"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14009/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762504241113, "cdate": 1762504241113, "tmdate": 1762924501404, "mdate": 1762924501404, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}