{"id": "Ze3diyHxr9", "number": 18014, "cdate": 1758282927765, "mdate": 1759897139335, "content": {"title": "PLG-DINO: Industrial Defect Detection via Prompt-Driven LoRA Adaptation in Grounding DINO", "abstract": "Large vision-language models (LVLMs) have demonstrated remarkable capabilities in aligning textual and visual modalities across diverse natural image datasets. Despite these advances, deploying them directly for industrial defect detection remains challenging, primarily due to significant domain discrepancies. Industrial images typically exhibit distinct visual characteristics such as complex textures, low contrast, metallic reflections, and subtle localized anomalies that differ fundamentally from natural scenes. Furthermore, the fine-grained semantic alignment between domain-specific textual prompts and their corresponding visual regions remains underexplored, thereby limiting the precise localization and recognition of defects. Compounding these issues, industrial datasets are often limited in annotated samples per defect category, rendering full-model fine-tuning impractical and prone to overfitting. To overcome these challenges, we propose a novel fine-tuning framework that combines low-rank adaptation applied selectively to the attention modules of the Grounding DINO architecture with a carefully designed prompt engineering strategy tailored for industrial defects. Our approach leverages lightweight, parameter-efficient updates together with semantically rich, domain-specific prompts, enabling effective adaptation of pretrained LVLMs using minimal labeled data. We construct a comprehensive dataset comprising approximately 30,000 high-resolution industrial images spanning a wide range of defect categories for rigorous evaluation. Extensive experiments demonstrate that our method consistently outperforms competitive baselines across diverse industrial scenarios,achieving superior detection accuracy as measured by both mAP@0.5 and AR across all sizes of defects, while requiring only a fraction of trainable parameters. Our work presents a scalable, annotation-efficient, and semantically aware solution for real-world industrial visual inspection, effectively harnessing the power of LVLMs.", "tldr": "", "keywords": ["Large Vision-Language Models；Industrial Defect Detection；Parameter-Efficient Fine-tuning"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4f4be9782617fa870226901a9f17fe2336744141.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes PLG-DINO, a fine-tuning framework for industrial defect detection that integrates Low-Rank Adaptation (LoRA) and soft prompt learning into the Grounding DINO architecture. The authors claim their method effectively adapts large vision-language models to industrial domains with minimal labeled data. A self-collected dataset of ~30,000 industrial images is introduced for evaluation. Experimental results suggest the proposed approach outperforms several LVLM-based and vision-only baselines in low-data regimes."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. The construction of a 30,000-image industrial defect dataset—if made publicly available—could be a valuable resource for the community."}, "weaknesses": {"value": "1. The core technical components—LoRA and prompt tuning—are not novel. While their combination in this specific context is sensible, the paper does not sufficiently justify what fundamental advance is being contributed beyond an application study. The proposed modifications (e.g., \"dynamic rank sparsity\") are neither motivated deeply nor compared against existing LoRA variants (e.g., DoRA, LoRA+).\n\n2. All experiments are conducted on a private dataset. The absence of evaluation on public benchmarks (e.g., MVTec AD, DAGM) severely limits the ability to assess generalizability.\n\n3. Comparisons against recent SOTA methods (e.g., Yoloe, Yolo-world, DetCLIPv3, OWL-ViT++) are missing.\n\n4. Despite emphasizing parameter efficiency, the paper provides no data on training time, inference speed, or memory footprint compared to full fine-tuning or other PEFT methods.\n\n5. The proposed method is directly fine-tuned on GroundingDINO and lacks technological creativity.\n\n6. The experimental table is overflowing and contains numerous error codes, making it unreadable."}, "questions": {"value": "I believe this paper is not ready for submission. Please carefully revise the formatting errors in the paper before resubmitting it. This is a matter of respect for the community."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yQynxnPFJr", "forum": "Ze3diyHxr9", "replyto": "Ze3diyHxr9", "signatures": ["ICLR.cc/2026/Conference/Submission18014/Reviewer_DR3Y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18014/Reviewer_DR3Y"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18014/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761814835800, "cdate": 1761814835800, "tmdate": 1762927807256, "mdate": 1762927807256, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a fine-tuning framework using low rank adaptation for industrial defect detection. The fine-tuning is done on the Grounding Dino architecture using a dataset curated by the authors."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- The problem of industrial defect detection is well motivated.\n- The evaluation includes comparisons against both vision-language models (Table 1) and traditional vision-only detectors (Table 2) across multiple metrics.\n- The curated dataset contains 30,000 images spanning 26 defect categories."}, "weaknesses": {"value": "## Major Weaknesses\n- The concept of fine-tuning different architectures using parameter efficient techniques has been explored for industrial defect detection previously as stated in the related works section. The paper doesn't introduce any major novel aspects to this fine-tuning procedure.\n- Section 4.6 claims \"The paper presents compelling visualization results\" but there are no visualizations in the paper. There are only 3 tables.\n- The ablation study in Table 3 is insufficient. Key components are missing:\n- No ablation for the prompt alignment loss Lp (Eq. 7) which is claimed as a core contribution\n- No ablation for MAE loss despite claiming it addresses weak supervision\n- No ablation for the claimed LoRA enhancements (LoRA-GA initialization, dynamic rank sparsity)\n- No comparison with full fine-tuning of Grounding DINO. Only the frozen pretrained baseline is compared, making it impossible to assess whether the added complexity is necessary.\n- In Section 3.3 the prompt construction process is not explained in detail. The paraphrasing and generation process are left ambiguous. Also there is no ablation study demonstrating the effectiveness of this paraphrasing procedure.\n- Section 3.4 introduces LoRA-GA and DS-LoRA as key enhancements but these are never validated experimentally and are not properly cited.\n\n\n## Minor Weaknesses\n- There are works that are used which are not cited. For example: LoRA-GA: Low-Rank Adaptation with Gradient Approximation, and DS-LoRA.\n- There are a lot of citations which are not correctly rendered and are just question marks like in lines: 132, 148-149, 264, 366, 381, 395\n- The citation style is incorrect throughout the paper. For example: \"... such as CLIP Radford et al. (2021)\" should be \"... such as CLIP (Radford et al., 2021)\""}, "questions": {"value": "- Will the curated dataset be publicly released? If so, with what license?\n- Can you provide the missing visualizations referenced in Section 4.6?\n- Could you address the other issues stated in the weakness section?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WQlBIYe5xO", "forum": "Ze3diyHxr9", "replyto": "Ze3diyHxr9", "signatures": ["ICLR.cc/2026/Conference/Submission18014/Reviewer_hUxo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18014/Reviewer_hUxo"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18014/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761937144910, "cdate": 1761937144910, "tmdate": 1762927806818, "mdate": 1762927806818, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes PLG-DINO, a framework for industrial defect detection that integrates prompt-driven soft tuning with LoRA-based parameter-efficient fine-tuning on Grounding DINO. By combining low-rank adaptation within attention layers and learned prompt tokens for defect semantics, PLG-DINO aligns textual prompts with visual regions while keeping adaptation lightweight and computationally efficient. The authors also curate a 30K-image industrial defect dataset covering diverse defect types and visual conditions to evaluate their approach. Experiments show that PLG-DINO outperforms both conventional vision-only detectors and other large vision-language model (LVLM)-based methods in terms of detection accuracy and recall."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well written and easy to follow, with clear motivation for addressing the domain gap between natural and industrial images.\n- The method achieves performance improvements over both LVLM-based and vision-only baselines, suggesting that lightweight adaptation can yield meaningful gains without full fine-tuning."}, "weaknesses": {"value": "- The novelty is somewhat limited, as the framework primarily combines two existing adaptation strategies (LoRA and prompt tuning) and applies them to a new domain. A deeper theoretical or methodological insight into their interaction would strengthen the contribution.\n- The paper lacks figure illustrations or qualitative visualizations, which would be essential to demonstrate the model’s localization quality and interpretability in real defect scenarios.\n- The dataset construction section could provide more comprehensive details on data diversity, annotation quality control, and comparisons with existing public industrial datasets."}, "questions": {"value": "Please see the weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "oLnDWD4NXe", "forum": "Ze3diyHxr9", "replyto": "Ze3diyHxr9", "signatures": ["ICLR.cc/2026/Conference/Submission18014/Reviewer_DjeF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18014/Reviewer_DjeF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18014/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761955525388, "cdate": 1761955525388, "tmdate": 1762927806328, "mdate": 1762927806328, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a parameter-efficient fine-tuning framework named PLG-DINO, which aims to solve the domain gap faced by Large Vision\nLanguage Models (LVLMs) when applied to industrial defect detection.  The PLG-DINO framework combines LORA and prompt learning based on Grounding DINO. A large-scale industrial defect dataset was collected and annotated, containing approximately 30,000 high-resolution images that cover a wide variety of defect types. Experimental results show PLG-DINO consistently outperforms other LVLM based benchmarks  and traditional vision only industrial detectors."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. It proposes a framework capable of rapidly adapting to new tasks (e.g., different production lines) with a small amount of annotated data. \n2. The experimental design and comparisons are very thorough. It is compared against various types of models (e.g., YOLO) and outperforms them all. \n3. It creates a dataset of approximately 30,000 high-resolution images for the Industrial Anomaly Detection (IAD) field."}, "weaknesses": {"value": "1. Limited Novelty: The core technologies (Grounding DINO, LoRA, Prompt Tuning) are existing ones. The main novelty lies in the combination and application of these techniques. Although the results are significant, the fundamental methodological innovation is relatively limited.\n2. The paper emphasizes parameter efficiency during training but does not discuss the model's inference speed. The absence of this comparison makes the assessment of its real-world applicability incomplete. \n3. The paper does not explicitly state whether the dataset will be publicly released or not. \n4. Typos: On pages 3, 5, 7, and 8 of the paper, there are multiple table references cited as \"??\"."}, "questions": {"value": "1. Will the authors plan to make this dataset publicly available to the research community? \n2. The Ablation Study clearly demonstrates the synergistic effect of LoRA and prompt tuning. Did the authors explore whether there is an optimal trade-off point between performance and the number of trainable parameters?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "oLOI0aoq2q", "forum": "Ze3diyHxr9", "replyto": "Ze3diyHxr9", "signatures": ["ICLR.cc/2026/Conference/Submission18014/Reviewer_cKRF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18014/Reviewer_cKRF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18014/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762013240121, "cdate": 1762013240121, "tmdate": 1762927805980, "mdate": 1762927805980, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes PLG-DINO, a framework that pairs prompt tuning with LoRA to adapt Grounding DINO for industrial defect detection. It also constructs a 30,000-image industrial dataset with text annotations to support the work."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The effort to apply parameter-efficient tuning (LoRA + prompt) to industrial defect detection addresses a real need for low-resource manufacturing scenarios.\n2. Building a large-scale industrial dataset with text annotations fills a gap left by smaller, vision-only datasets in existing research."}, "weaknesses": {"value": "1. There are no images to illustrate the dataset—readers cannot verify the visual traits of industrial defects or the quality of annotations.\n2. The proposed method lacks innovation; it simply combines existing prompt tuning and LoRA techniques without new mechanisms for industrial defect detection.\n3. Multiple formatting issues exist, such as incomplete Table 1, 2, 3, and Line 240, 244.\n4. Aligning visual features and prompt embeddings is illogical—these features belong to different spaces, and the paper does not explain why cosine similarity works or how this alignment is used during inference."}, "questions": {"value": "1. What is gradient approximation? How to get the gradient before initialization?\n2. Why does gradient approximation accelerate convergence?\n3. Why is sparsity needed for low-rank LoRA matrices?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vEjjP9wGOb", "forum": "Ze3diyHxr9", "replyto": "Ze3diyHxr9", "signatures": ["ICLR.cc/2026/Conference/Submission18014/Reviewer_SdUA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18014/Reviewer_SdUA"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission18014/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762164448073, "cdate": 1762164448073, "tmdate": 1762927805312, "mdate": 1762927805312, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}