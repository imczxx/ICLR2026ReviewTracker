{"id": "5gnEuw1dYd", "number": 3912, "cdate": 1757566856936, "mdate": 1759898063110, "content": {"title": "A Concept is More Than a Word: Diversified Unlearning in Text-to-Image Diffusion Models", "abstract": "Concept unlearning has emerged as a promising direction for reducing the risks of harmful content generation in text-to-image diffusion models by selectively erasing undesirable concepts from a model’s parameters. Existing approaches typically rely on keywords to identify the target concept. However, we show that this keyword-based formulation is inherently limited: concepts are multi-dimensional, can be expressed in diverse textual forms, and often overlap with related concepts in the latent space, making keyword-only unlearning brittle and prone to over-forgetting. To address this limitation, we propose \\textbf{Diversified Unlearning}, a distributional framework that represents a concept through a set of contextually diverse prompts rather than a single keyword. This richer representation enables more precise and robust unlearning. Through extensive experiments across multiple benchmarks and state-of-the-art baselines, we demonstrate that Diversified Unlearning consistently achieves stronger erasure, better retention of unrelated concepts, and improved robustness against adversarial recovery attacks. All experimental results and detailed implementations can be found at \\url{https://anonymous.4open.science/r/Diversified_Unlearning}", "tldr": "", "keywords": ["Machine Unlearning", "Diffusion Models", "Generative Models"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/25012ef1c079e9b8d7efcb413846879ac4b8636c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a Diversified Unlearning approach to enhance the robustness for concept unlearning tasks. The proposed method adds a set of contextually diverse prompts to augment the original keyword. This mechanism is realized by prompting ChatGPT to generate the context set. The experiment results demonstrate that the proposed method can achieve effective concept unlearning and be robust to adversarial attack prompts."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Improving the robustness of concept unlearning methods is crucial and practical for real-world trustworthy generative AI developments, especially for malicious attack prompts.\n2. The overall paper is easy to follow."}, "weaknesses": {"value": "1. In this paper, the contextualized prompts c are generated by ChatGPT. However, how to decide the number of contextualized prompts that need to be generated for each task?\n2. In addition, LLMs inevitably have hallucination issues. How to make sure the generated contextualized diverse prompts are reasonable and faithful, so that they can properly describe the variations of the target concept?\n3. Previous works, such as Receler (ECCV’24), adopt learnable prompt embeddings to handle the rephrased concepts by adversarial training. They also emphasize the focus on enhancing robustness. Comparing the contextualized prompts from ChatGPT with the learnable prompts would make the major claimed technical contributions more convincing. \n4. In lines 43-44, this paper claims that the proposed method is able to preserve the unrelated concepts. However, from Eq.3 and Eq.5, how to construct the unrelated set? It's impractical to cover every unrelated concept in the diffusion models. It would be beneficial to provide clearer clarifications and details in the paper."}, "questions": {"value": "1. How to ensure the output images contain safe concepts? It is possible that while the target concept is removed, it generates other unsafe concepts."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Rohzu0YGr9", "forum": "5gnEuw1dYd", "replyto": "5gnEuw1dYd", "signatures": ["ICLR.cc/2026/Conference/Submission3912/Reviewer_jidj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3912/Reviewer_jidj"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3912/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760971485653, "cdate": 1760971485653, "tmdate": 1762917095345, "mdate": 1762917095345, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Diversified Unlearning, a simple text-to-image unlearning framework that enhances the contextual diversity of textual prompts. For output-based unlearning methods, it introduces a diversified prompting strategy that replaces the target keyword with contextualized target prompts and contextualized anchor prompts. For attention-based methods, it proposes a diversified embedding mixup strategy that mixups target keyword embeddings and their contextualized counterparts.\nExperiments across five concept-erasure scenarios (i.e., celebrities, objects, copyrighted characters, nudity, and artistic styles) show that integrating the proposed method with five existing unlearning frameworks consistently improves erasure performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed method is simple yet effective in improving concept erasure performance.\n- The paper conducts comprehensive experiments across five unlearning domains and provides a detailed analysis of prompt diversity, exploring contextual complexity from level 0 to level 7 and varying the number of prompts from 5 to 50.\n- The paper is well-written and clear. The example in lines 239-242 helps me understand the diversified embedding mixup mechanism."}, "weaknesses": {"value": "- The method shows limited effectiveness in concept preservation. In the copyrighted concept erasure task (Table 1 right), preservation improvements are marginal, about 0.02 in LPIPS for ESD, AP, AGE, and ACE, and less than 1 point in CLIP-i, CLIP-t, and GPT scores. Similarly, in the nudity erasure task (Table 2), preservation improvements in FID and CLIP metrics are negligible or even degrade.\n- While the paper mentions adversarially trained unlearning approaches such as AdvUnlearn, R.A.C.E., Receler, or RECE, it does not compare against them experimentally. I’m interested in whether learning from soft prompts (as in those works) or learning from pre-defined textual prompts (as in this paper) leads to better robustness, so including those works in the experiments could provide better understanding.\n- Regarding the recovery attack experiments (sec. 4.4), details like the contextual level of prompts used and the total number of prompts are missing."}, "questions": {"value": "- How sensitive is the mixup hyper-parameter $\\alpha$ in the diversified embedding mixup? For example, will the method remain effective for attention-based unlearning if $\\alpha$ is reduced (e.g., to 0.6)?\n- Any insights or ideas on why the erasure performance drops a lot when level-4 prompts are used (Fig. 4a)?\n- In the ablation on the number of prompts (Fig. 4b), would the optimal number of prompts decrease if higher-complexity prompts (e.g., level-3) were used?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7zza0GP88L", "forum": "5gnEuw1dYd", "replyto": "5gnEuw1dYd", "signatures": ["ICLR.cc/2026/Conference/Submission3912/Reviewer_WWWB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3912/Reviewer_WWWB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3912/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761450085391, "cdate": 1761450085391, "tmdate": 1762917095122, "mdate": 1762917095122, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the limitations of current unlearning approaches that focus only on removing target concepts associated with specific keywords. Such keyword-based unlearning often struggles to effectively erase the full concept and tends to harm unrelated concepts. To overcome these limitations, the authors propose Diversified Unlearning, a distributional unlearning method that leverages LLM-generated diversified prompting. By replacing a single target keyword with a set of contextualized prompts, this method broadens the erasure scope, strengthens resistance against recovery attacks, and mitigates damage to unrelated concepts."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper shifts the perspective from keyword-based unlearning to distributional unlearning, offering a novel conceptualization of representing concepts as distributions. This perspective provides a promising direction for developing more robust unlearning techniques.\n2. The proposed approach functions as a plug-in module compatible with existing unlearning methods, effectively enhancing their performance.\n3. Extensive experiments on Stable Diffusion 1.4 demonstrate the effectiveness of the proposed method, achieving superior results compared with prior approaches."}, "weaknesses": {"value": "1. Although distributional unlearning is an insightful perspective, the paper lacks a systematic exploration of how distributional ranges differ across concept categories (e.g., celebrity, copyrighted character, explicit concept), and how corresponding contextualized prompts should be designed for each category.\n2. The improvement of the proposed method over robust unlearning methods such as [1][2] is not sufficiently demonstrated.\n3. All experiments are conducted on Stable Diffusion 1.4, leaving uncertainty about generalization to more recent models (e.g., Stable Diffusion 3.5, FLUX).\n\nMinor：\n1. The description of the preprocessing and postprocessing steps (lines 56–57) seems disconnected from the keyword-based unlearning process.\n\n[1] Zhang Y, Chen X, Jia J, et al. Defensive unlearning with adversarial training for robust concept erasure in diffusion models[J]. Advances in neural information processing systems, 2024, 37: 36748-36776.\n[2] Gong C, Chen K, Wei Z, et al. Reliable and efficient concept erasure of text-to-image diffusion models[C]//European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2024: 73-88"}, "questions": {"value": "1. Could the authors provide an ablation study on the hyperparameter $\\alpha$ introduced in Diversified Embedding Mixup to clarify its impact on performance?\n2. Why did the authors choose GPT-Score over identity similarity as the evaluation metric in Section 4.1?\n3. Table 10 shows that unlike other concepts (e.g., identity), the proposed method fails to improve artistic style unlearning. Could the authors clarify why this occurs?"}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety"]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "f84iKptZJW", "forum": "5gnEuw1dYd", "replyto": "5gnEuw1dYd", "signatures": ["ICLR.cc/2026/Conference/Submission3912/Reviewer_sj5a"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3912/Reviewer_sj5a"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3912/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761892368360, "cdate": 1761892368360, "tmdate": 1762917094903, "mdate": 1762917094903, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors propose a data augmentation method to produce more diverse samples, helping erase concepts from text-to-image diffusion models."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-written, easy for readers to follow.\n2. The proposed method is intuitive, targeting the issue."}, "weaknesses": {"value": "1. Require for more verifying experiments. \n\na) First, one immediately approach is to use prompts to construct pairs of data. For example, <p1, p2> where p1 is a prompt with the word nudity and p2 is the same prompt but without the word nudity. Then we use the pairwise data to train the model. In this scenaro, what is the advantage of this proposed method?\n\nb) How do we evaluate the precision of the sum operation directly on the embedding vectors. As we know, the latent space is complex and the embedding vector sum may destroy the original semantic.\n\nc) If the embedding vector sum destroys the original semantic, it indicates that the semantic in the prompts is not important in this task. Can we directly use embedding vectors generated randomly as $c$?\n\nd) In Eq5, why do we need to prepare $c_p$ additionally for preservation rather than using $c$ directly?\n\n2. The baselines are old. Please compare your methods with more recent methods, such as RECE, Receler and AdvUnlearn."}, "questions": {"value": "See weaknesses.\nI think that there are many concerns to be addressed. More experiments and discussions are needed to evaluate the proposed method. If the authors can give convincing evidence, I will raise my rating."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "0ykp9RLoft", "forum": "5gnEuw1dYd", "replyto": "5gnEuw1dYd", "signatures": ["ICLR.cc/2026/Conference/Submission3912/Reviewer_fJw7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3912/Reviewer_fJw7"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3912/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761905191692, "cdate": 1761905191692, "tmdate": 1762917094487, "mdate": 1762917094487, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}