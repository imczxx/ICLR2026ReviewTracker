{"id": "iM4o9a83F7", "number": 13899, "cdate": 1758224618164, "mdate": 1759897405136, "content": {"title": "Estimating Dimensionality of Neural Representations from Finite Samples", "abstract": "The global dimensionality of a neural representation manifold provides rich insight into the computational process underlying both artificial and biological neural networks. However, all existing measures of global dimensionality are sensitive to the number of samples, i.e., the number of rows and columns of the sample matrix. We show that, in particular, the participation ratio of eigenvalues, a popular measure of global dimensionality, is highly biased with small sample sizes, and propose a bias-corrected estimator that is more accurate with finite samples and with noise. On synthetic data examples, we demonstrate that our estimator can recover the true known dimensionality. We apply our estimator to neural brain recordings, including calcium imaging, electrophysiological recordings, and fMRI data, and to the neural activations in a large language model and show our estimator is invariant to the sample size. Finally, our estimators can additionally be used to measure the local dimensionalities of curved neural manifolds by weighting the finite samples appropriately.", "tldr": "", "keywords": ["Dimensionality", "estimator", "neuroscience"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3e01af55293c5753176bde8f7bbfc1e7fee8198e.pdf", "supplementary_material": "/attachment/a4b14106cb94a3fdb722567fc9d127bbbb80970d.zip"}, "replies": [{"content": {"summary": {"value": "This submission proposes a new estimator of the Participation Ratio (PR), a well-known tool to measure the global dimensionality in Machine Learning or Neuroscience. This novel estimator is proven to be less biased and more robust to measurement noise than the state-of-the-art. The main impact is that it needs fewer measurements to yield a precise estimate."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "I see the following strengths:\n- The topic fits exactly the scope of ICLR, ie. learning representation. This new estimator is helpful in gauging the 'quality' of a learned representation.\n- The paper is well written, postponing the gory technical details in the appendices. At first sight, reading the main body, I had the impression that the exposition was too simple, but the appendices evidence that the rationale is strong. I suggest to add more cross-references to the appendices. \n- The approach is deductive: first an analysis of the biases in the naive approach, then the deduction of the modifications to patch this caveat.\n- The new estimator is not entirely unbiased, but the study shows that the bias is significantly smaller\n- This main property is also demonstrated with convincing experiments.\n- The computation of the new estimator is expensive. Yet, the submission proposes an efficient implementation.  \n- The submission is dense as it also proposes two extensions: robustness to measurement noise with a double trial, and an integration of a weighting mechanism to estimate local dimensionalities, which can then be averaged into a global dimensionality."}, "weaknesses": {"value": "- W1: The experimental protocol only compares the new estimator to the naive PR estimate and Two-NN. There are many more estimators based on nearest neighbours, like Gride from Denti et al. (cited in the submission), the Hill estimator for local dimensionality and the likes (MLE, MoM, TLE, see the works of Michael Houle, James Bailey -- not cited in the submission), not to mentioned the `insane' estimator based on diffusion models (see A Geometric View of Data Complexity: Efficient Local Intrinsic Dimension Estimation with Diffusion Models, Kamkari et al., NeurIPS 2024).\n\n- W2: I expected some justifications about the noise correction based on double trials. On the same token, I do not understand how appendix B is related to the main body.\n\n- W3: I am not sure that the dimensionality estimator should be the arithmetic mean of local estimates. Some works argue that the harmonic mean is better. See for instance, page 11 of *A Survey of Dimension Estimation Methods*, Binnie et al."}, "questions": {"value": "- Suggestions: Adding pointers to the appendices in the main body will make the submission sharper. I also suggest numbering more equations to allow these precise cross-references. Another option would be to formulate results as Propositions whose proofs are given in the appendix... but I can live without this formalism. \n\n-  Q1: Fig. 1. What is the value of Q when P is varying (left)?  What is the value of $P$ when $Q$ is varying (right)?\n\n- Q2: Why $\\gamma_{col}$ ($\\gamma_{row}$) is a scaled copy of $\\gamma_{both}$ when $P$ (resp. $Q$) varies?\n\n- Q3: I am not convinced by the use of Mahalanobis distance to define the nearest neighbours. Typically, NN-based Local dimensionality estimators use plain Euclidean distance. What is the value of k for learning the local covariance matrix? You mention 4 neighbours in the main body.\n\nTypos:\n- Line 760: \"Consider $\\hat{t}^5$...\" but the following details the comptutation of $t^1$.\n- Line 907: Similarly"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "njRKWTfqW1", "forum": "iM4o9a83F7", "replyto": "iM4o9a83F7", "signatures": ["ICLR.cc/2026/Conference/Submission13899/Reviewer_uXtA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13899/Reviewer_uXtA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13899/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761039053036, "cdate": 1761039053036, "tmdate": 1762924407456, "mdate": 1762924407456, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies estimates of global manifold dimensionality from finite neural response matrices. It shows that the standard participation ratio (PR) is systematically biased in small-sample regimes and proposes a bias-corrected PR estimator that removes terms arising from index collisions in finite submatrices. Concretely, the sample matrix is modeled as a random submatrix of an underlying infinite matrix, obtained by independently and uniformly sampling stimuli and neurons. The authors derive unbiased estimators for the numerator and denominator of PR by averaging only over unequal indices and define γ_both as their ratio, with row-only and column-only variants (γ_row, γ_col). They further give a two-trial noise correction that cancels additive or multiplicative noise without requiring many repeats, and a weighted version that yields a local, noise-robust intrinsic dimensionality when weights select neighbors. Experiments on synthetic data recover ground-truth dimensionality, and applications to mouse V1 calcium imaging, macaque electrophysiology, human IT fMRI, and LLM activations show reduced dependence on P and Q compared to naive PR and TwoNN. Implementational tricks for unequal-index summations are provided."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Originality: Clear identification of finite-sample bias sources in PR and a general correction via unequal-index averaging. Weighted and two-trial extensions broaden utility\n* Quality: Solid derivations, sensible baselines, coverage across multiple data modalities\n* Clarity: Motivations, assumptions, and estimator definitions are well laid out; limitations are stated.\n* Significance: If adopted, this can standardize dimensionality reporting and reduce misleading sample-size effects across empirical work."}, "weaknesses": {"value": "* The estimator assumes independent, uniform sampling of rows and columns. In practice, electrophysiology probes capture spatially clustered units and often bias toward specific cortical layers or depths; calcium imaging has field-of-view and sparsity biases; fMRI voxels are not neuron samples at all. This undermines the \"random submatrix of the infinite one\" assumption and could introduce design-specific bias not removed by unequal-index averaging. Please analyze or simulate non-uniform, block-dependent, or layer-biased sampling and show robustness or an adjusted estimator that incorporates known inclusion probabilities via importance weights\n* The two-trial correction addresses additive or global multiplicative noise across trials. Real recordings can have correlated, heteroskedastic noise across neurons/time. Clarify which noise structures are neutralized by the cross-trial construction and which remain.\n* No variance estimates or confidence intervals are given for γ_both. A delta-method approximation for a ratio of U-statistics or a simple bootstrap over rows and columns would help readers gauge reliability.\n* The local estimator requires radius sweeps and unequal-index summations. Please report time and memory as functions of P and Q\n* No comparisons to other global measures used in practice (under finite samples) are made. No ablations included that vary manifold curvature, anisotropy, and rank-plus-tail spectra"}, "questions": {"value": "* How does γ_both behave under non-uniform sampling where inclusion probabilities differ by layer or receptive field location. Can your weighted estimator correct such sampling bias if weights are set to inverse inclusion probabilities?\n* The two-trial noise correction assumes independence of trial noise. How sensitive is γ_both to trial-to-trial drift or slow fluctuations that are shared across trials?\n* For the LLM study, can you report layerwise γ with and without centering and with language-balanced sampling to ensure that row sampling is not conflated with sentence-length distribution?\n* The supplement mentions different centered kernels for task vs neuron centering. Can you clarify in the main text when each is appropriate?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jUW7G0cXBO", "forum": "iM4o9a83F7", "replyto": "iM4o9a83F7", "signatures": ["ICLR.cc/2026/Conference/Submission13899/Reviewer_aVtZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13899/Reviewer_aVtZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13899/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761856468987, "cdate": 1761856468987, "tmdate": 1762924407029, "mdate": 1762924407029, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper examines the problem of estimating the manifold dimensionality (effective rank) formed from neural data under stimuli, how current approaches may be biased especially in small sample sizes, and a new bias-corrected estimator. The authors demonstrate this metric on diverse neural data and a LLM."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Very well written and organized. It tackles an important and broad problem in computational neuroscience with some applications to general ML models. Math appears correct and well derived."}, "weaknesses": {"value": "- Some jumps in the flow (e.g. how do line 266 and line 268 connect?) detracted from the clarity. \n\n- Some portions of the results are unclear or unexplained. Figure 2 shows how some estimators don't change as a function of the number of samples included. But some of the naive and other estimators are stable, though the difference in value of dimensionality is different. Which is correct, given no ground truth? (See Q, top right and bottom left). \n\n- Discussion and Limitations are too short; how feasible is this? How computationally expensive is it in practice?"}, "questions": {"value": "- How does this apply without inputs (e.g., spontaneous activity)? \n\n- Is treating the sample activation matrix as a random submatrix always appropriate? Neurons are certainly subsampled, but in many organisms much more of the network is directly observable. If we observe active neurons, is it likely to be a random subsample, or simple most neurons that are responsive to a certain input stimulus? And most samples on the stimulus input side are not randomly chosen either. \n\n- How much does the bias term contribute to the difference in estimators? E.g., how biased is biased? Line 312 denotes some bias as negligible without giving a value or order of magnitude. Line 358 seems to imply that 'most bias' means most change across number of samples. Figure 4 indicates that the new estimator is also biased?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Q8341Br33C", "forum": "iM4o9a83F7", "replyto": "iM4o9a83F7", "signatures": ["ICLR.cc/2026/Conference/Submission13899/Reviewer_kPsS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13899/Reviewer_kPsS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13899/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761922107443, "cdate": 1761922107443, "tmdate": 1762924406612, "mdate": 1762924406612, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}