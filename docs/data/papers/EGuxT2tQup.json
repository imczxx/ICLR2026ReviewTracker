{"id": "EGuxT2tQup", "number": 6856, "cdate": 1757998428421, "mdate": 1763646615869, "content": {"title": "Bridging Implicit-Explicit Representations for Ultra-Low Bitrate Image Compression", "abstract": "While recent VAE-based neural codecs achieve impressive results at low bitrates when optimized for perceptual quality, their performance degrades significantly under ultra-low bitrate conditions. To address this, generative methods that exploit semantic priors from pretrained models have emerged, revolutionizing ultra-low bitrate compression. However, these approaches remain constrained by a fundamental tradeoff between semantic faithfulness and perceptual realism. Methods relying on explicit semantic guidance preserve content accuracy but often lack textural fidelity, while those based on implicit representation can generate convincing details but may suffer from semantic drift. In this work, we introduce a unified framework that bridges this gap by coherently integrating explicit and implicit semantic representations. We condition a diffusion model with explicit high-level semantics while using reverse-channel coding to implicitly encode fine-grained information. In addition, a novel plugin encoder provides flexible control over the  distortion-perception balance. Extensive experiments demonstrate that our unified implicit–explicit compression framework achieves state-of-the-art rate–perception performance, outperforming existing approaches and surpassing DiffC by 23.49% and 12.25% DISTS-BD-Rate on the Kodak and DIV2K datasets, respectively.", "tldr": "ultra-low bitrate image compression", "keywords": ["image compression", "diffusion", "neural network"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6ff19e7fa5c0a80c137a02b847a41a248da82e32.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a dual semantic compression framework for ultra-low bitrate image compression. An explicit semantic encoder with tag-style prompts and plugin implicit semantic extractor capture high-level semantics and fine-grained visual details, respectively, achieving  distortion-perception tradeoff and flexible quality control. The proposed method consistently surpasses state-of-the-art approaches at extremely low bitrates."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "This paper aims to compress the images under ultra-low bitrate conditions. Specifically, an unified implicit-explicit compression framework is proposed which achieves state-of-the-art rate-perception performance. In addition, the paper is well-organized and well-written."}, "weaknesses": {"value": "1、\tThe paper lacks implementation details for the proposed dual representation compression framework. What loss functions are used in the paper and how is the framework trained? How to set the value of mixing coefficient during the training?\n2、\tIn the proposed framework, are the MSE and VAE encoders based on a similar network structure? Are z and z_wave both 4-channel features?\n3、\tHow can the conditions (c and y_hat) be embedded into the diffusion process? Is a CLIP model required to extract the semantic representation from the tag-style prompts?\n4、\tWhat are the encoding and decoding times of the proposed framework, which are important for image compression? The authors need to demonstrate how the inference time compares with that of other competitive compression approaches.\n5、\tWe believe that the CLIC_2020 dataset, rather than the DIV2K dataset, is the most widely used benchmark for image compression tasks. However, the authors do not present any comparisons based on the CLIC_2020 dataset, which comprises 428 images with diverse content. Please include comparisons in the manuscript.\n6、\tIn Fig. 4, why do the authors show the FID rather than the LPIPS metric for the DIV2K dataset? In Section 5.2, the authors do not analyse the comparisons in terms of FID. Additionally, Figures 8 and 9 in the supplementary file should be included in the main body of the manuscript.\n7、\tThe paper lacks comparisons to recent extreme image compression methods including RDEIC[1], StableCodec[2], DLF[3], ResULIC[4], and OSCAR[5].\n[1]. Li Z, Zhou Y, Wei H, et al. RDEIC: Accelerating Diffusion-Based Extreme Image Compression with Relay Residual Diffusion[J]. TCSVT2025.\n[2]. Zhang T, Luo X, Li L, et al. StableCodec: Taming One-Step Diffusion for Extreme Image Compression[J]. ICCV2025.\n[3]. Xue N, Jia Z, Li J, et al. DLF: Extreme Image Compression with Dual-generative Latent Fusion[J]. ICCV2025.\n[4]. Ke A, Zhang X, Chen T, et al. Ultra Lowrate Image Compression with Semantic Residual Coding and Compression-aware Diffusion[J]. ICML2025.\n[5]. Guo J, Ji Y, Chen Z, et al. OSCAR: One-Step Diffusion Codec Across Multiple Bit-rates[J]. NeurIPS2025."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "We hope the authors will address the concerns I raised in the 'Weaknesses' section of the review. If they have, I will increase the rating score."}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ir6BGjcSCc", "forum": "EGuxT2tQup", "replyto": "EGuxT2tQup", "signatures": ["ICLR.cc/2026/Conference/Submission6856/Reviewer_QG5r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6856/Reviewer_QG5r"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6856/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760931250658, "cdate": 1760931250658, "tmdate": 1762919112017, "mdate": 1762919112017, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The article presents an ultra-low bitrate image compression scheme based on conditional diffusion, which demonstrates optimal performance. Through extensive experiments conducted across multiple datasets, remarkable results have been achieved—further highlighting the scheme’s promising potential in terms of transferability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The application of RCC technology in diffusion-based compression schemes has not been thoroughly explored. This article presents an intriguing solution. Specifically, I believe the strengths of this article are as follows:\n1. Clear motivation and writing, allowing readers to follow the author's train of thought easily.\n2. The proposed solution is backed by compelling and thorough experiments, yielding satisfactory performance results.\n3. Following in the footsteps of DIFFC, this article represents a meaningful attempt at utilizing RCC technology in the field of image compression. The high transferability of the method holds significance for the advancement of this domain."}, "weaknesses": {"value": "1. Some architectures appear less novel, for instance, the introduction of dual branches has been previously explored in various diffusion-based methods, blending semantic and image controls.\n2. The article introduces ‘Tile-based Processing,’ from which the model benefits, yet this module lacks thorough elaboration, including aspects such as block quantity and complexity. Furthermore, the concepts of image segmentation and parallelism lack appeal.\n3. The article lacks in discussing the complexity of its experiments. Notably, the significant encoding latency introduced by RCC, combined with the use of a tile structure for image segmentation, raises doubts about the necessity of multiple RCC encodings. Additionally, segmenting images and separately extracting prompts via RAM might exacerbate encoding latency. Given the inherent decoding latency of diffusion architectures, a detailed exploration of the complexity of encoding and decoding is crucial for elucidating the feasibility of this algorithm."}, "questions": {"value": "1. What are the details of the Tile-based Processing scheme? Does the method of tiling vary for images of different resolutions? How does using different tiling methods affect the model's performance?\n2. Even though the increase in encoding complexity due to RCC is unavoidable, the authors should discuss the model's complexity in the paper. This discussion would provide valuable insights for the applicability and reference value of this research."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XGvzsv15to", "forum": "EGuxT2tQup", "replyto": "EGuxT2tQup", "signatures": ["ICLR.cc/2026/Conference/Submission6856/Reviewer_ZY7r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6856/Reviewer_ZY7r"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6856/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761750048912, "cdate": 1761750048912, "tmdate": 1762919111677, "mdate": 1762919111677, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a dual semantic compression framework that integrates explicit semantic representations (quantized latents and tag-style prompts) with implicit semantic representations (noise-corrupted latents via reverse-channel coding, RCC) for ultra-low bitrate image compression. The method conditions a diffusion model on explicit semantics while using RCC to encode fine-grained details, and introduces a plugin encoder to control the distortion–perception tradeoff without modifying the decoder. Experiments show strong performance, with 23.49% and 12.25% DISTS-BD-Rate improvements over DiffC on Kodak and DIV2K, respectively."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1) The paper clearly identifies the tradeoff between explicit approaches (semantic faithfulness but texture loss) and implicit ones (rich textures but semantic drift), and provides a principled framework to bridge this gap.\n2) The framework is compatible with various base codecs (e.g., DiffEIC, PerCo), and the plugin encoder enables controllable distortion–perception balance without retraining the decoder.\n3) The method achieves substantial gains in DISTS-BD-Rate over DiffC and produces visually pleasing reconstructions at extremely low bitrates."}, "weaknesses": {"value": "1) The paper should include a comparison with ResULIC (ICML 2025), which also explores diffusion-based ultra-low bitrate compression.\n2) Encoding and decoding times should be reported to assess real-world usability.\n3) Bitrate allocation for different components would clarify efficiency.\n4) Results on the CLIC dataset are missing, which is more commonly used in recent compression works.\n5) To substantiate claims of controllable perception, the authors should include FID variation curves and report FID scores in Table 1.\n6) The computation of CLIPSim should be clarified—since CLIP typically supports 224×224 inputs, how was it applied to full-resolution images?\n7) While the overall combination is effective, the individual techniques are largely borrowed from prior work: RCC for image compression originates from DiffC (Theis et al., 2022; Vonderfecht & Liu, 2025), Conditioning diffusion models on latent features follows PerCo and DiffEIC, Tag-style prompts are derived from RAM (Zhang et al., 2024), the primary contribution lies in integrating these existing components rather than introducing fundamentally new mechanisms.\n\nKe, A., Zhang, X., Chen, T., Lu, M., Zhou, C., Gu, J., & Ma, Z. Ultra Lowrate Image Compression with Semantic Residual Coding and Compression-aware Diffusion. In Forty-second International Conference on Machine Learning."}, "questions": {"value": "Please refer to weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ppq4PeyoO8", "forum": "EGuxT2tQup", "replyto": "EGuxT2tQup", "signatures": ["ICLR.cc/2026/Conference/Submission6856/Reviewer_qXeD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6856/Reviewer_qXeD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6856/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979509965, "cdate": 1761979509965, "tmdate": 1762919111165, "mdate": 1762919111165, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}