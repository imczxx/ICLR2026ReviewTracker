{"id": "PJ2z6s2gM3", "number": 18896, "cdate": 1758291830635, "mdate": 1759897074753, "content": {"title": "The emergence of the left-right asymmetry in predicting brain activity from LLMs' representations specifically correlates with their formal linguistic competence", "abstract": "When humans and large language models (LLMs) process the same text, activations in the LLMs correlate with brain activity measured, e.g., with functional magnetic resonance imaging (fMRI). Moreover, as the training of an LLM progresses, the performance in predicting brain activity from its internal activations improves more in the left hemisphere than in the right one. The aim of the present work is to understand the origin of this left-right asymmetry. Using the OLMo-2 7B language model, whose authors provide checkpoints during training, and fMRI data from English participants, we track the evolution of the left-right asymmetry and compare it with the evolution of the performance on several linguistic and non-linguistic benchmarks. We observe that the asymmetry co-emerges with the linguistic abilities of the LLM, attested either by its capacity to make accurate acceptability judgments on English sentences or to produce well-formed text. In addition, this change in left-right asymmetry does not correlate at all with arithmetic or formal language (Dyck) tasks, nor with text-based tasks involving world knowledge and reasoning. We generalize these results to another family of LLMs (Pythia) and another language, namely French. Our observations indicate that the left-right asymmetry in brain predictivity matches the progress in formal competence (knowledge of linguistic patterns) rather than functional competence (understanding and using language in the world).", "tldr": "As training progresses, the internal representations of an LLM become increasingly better at predicting brain activity, with a sudden increase in asymmetry between left and right hemispheres coinciding with the LLM's acquisition of formal competence.", "keywords": ["large language models", "training", "language processing", "brain lateralization", "fMRI", "phase transition", "syntax"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/343de590c87fc4646062577c31dbd9d66a6d0a74.pdf", "supplementary_material": "/attachment/45c3eb154a691d4e75e1bd4bc29b82071c39743b.zip"}, "replies": [{"content": {"summary": {"value": "This paper investigates why left-right hemispheric asymmetry arises when large language model (LLM) activations are used to predict human brain activity during language processing. Using training checkpoints from the OLMo-2 and Pythia model families, the authors track how brain predictivity evolves alongside model competence. They find that left-hemisphere dominance co-emerges with the model's acquisition of formal linguistic skills (e.g., syntax, grammatical acceptability) rather than with non-linguistic or reasoning abilities. The authors clain that this relationship generalizes across models, languages (English and French), and datasets. The results suggest that formal linguistic competence, not world knowledge or reasoning, drives LLM–brain alignment asymmetry."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "1. The study offers a cognitive-level explanation for hemispheric asymmetry in brain–LLM alignment, bridging neuroscience and computational linguistics.\n2. Tracking asymmetry evolution through training provides rare temporal insight into how representational properties emerge in LLMs.\n3. The separation of formal vs. functional linguistic competence provides a theoretically grounded interpretation of model–brain correspondence."}, "weaknesses": {"value": "1. Authors chose two language acceptability tasks (BLiMP and Zorro). Expts should have been done with more linguistic tasks to claim \"formal competence (knowledge of linguistic patterns)\" in the abstract. The same holds for functional competence tasks -- just two tasks do not justify a broad claim. For French the comparison is just on one linguistic and one non-linguistic task. Aren't ARC and Hellaswag linguistic tasks where the claim does not seem to hold -- what is the definition of a linguistic task?\n2. The study depends on one fMRI dataset where participants were listening to an audiobook. Will these observations and insights hold on other fMRI datasets where participants do other tasks in unclear?\n3. Line 168 says \"ARC and Hellaswag, the high-level comprehension benchmarks, are not aligned with the left-right brain score asymmetry.\" From Fig 2, to me it looks like alignment is high for ARC easy task. Is there a metric and a threshold for this alignment based on which these claims of alignment vs not are made?\n4. Given Fig 4, Fig 1 is redundant.\n5. French expt should have been done with some model trained specifically for French. French results do not seem to be convincing. \n6. It would be nice to do this experimentation to observe patterns across different brain regions rather than just hemisphere level results."}, "questions": {"value": "1. It would be nice to know x_0 vs \\beta fit for the 2 french expts. \n2. You argue that left-right asymmetry reflects formal linguistic competence rather than functional competence. How do you rule out the possibility that this asymmetry instead reflects differences in training data distribution or token-level statistics rather than linguistic structure\n3. You report correlations between training progression and asymmetry. Did you test lag effects (e.g., whether changes in linguistic competence precede or follow changes in brain predictivity)?\n4. Do you think these results would hold for languages with different lateralization patterns (e.g., logographic or morphologically rich languages)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "HeMCVsEqGB", "forum": "PJ2z6s2gM3", "replyto": "PJ2z6s2gM3", "signatures": ["ICLR.cc/2026/Conference/Submission18896/Reviewer_K8zy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18896/Reviewer_K8zy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18896/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761231331527, "cdate": 1761231331527, "tmdate": 1762930866707, "mdate": 1762930866707, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the origins and potential causes of the “left-right asymmetry” observed in LM-brain alignment --- i.e., the phenomenon that LM activations are more aligned with brain activity in humans’ left hemispheres than right hemispheres. The authors investigate how this asymmetry evolves across checkpoints of an LM’s training process, evaluating LMs on a variety of linguistic and non-linguistic tasks, in both English and French. The authors find that the left-right asymmetry co-emerges with the LM’s functional linguistic abilities."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The topic of understanding representational alignment across LMs and human brains is interesting and timely.\nIt is also a plus that the findings are validated in languages beyond English."}, "weaknesses": {"value": "The focus on distinguishing formal/functional competence could have been motivated more clearly. The question “Is the left-right asymmetry driven more by one type of competence than the other?” (l. 066) comes a bit out of nowhere. If we did find that the asymmetry was driven more by one particular kind of competence, what implications would that have? What would be the theoretical importance of investigating this question, either for neuroscience or AI? Since this question is central to the paper’s experiments and analyses, I found the overall high-level takeaways a bit unclear.\n \nAlso, acceptability combines many factors, including formal as well as functional language competence. More generally, it would have been useful to cover more tasks beyond syntax for analyzing functional language competence.\n \nI was also unsure about some of the experimental design choices. For example, in the text generation experiment, how were the five seed prompts chosen? What temperature did you use to sample outputs from the models? Did you perform any manual validation of the generated sentences? \n \nFinally, I felt that the focus on tracking left-right asymmetry across training time was not clearly motivated. Couldn’t you also evaluate a large set of models and see how asymmetric brain scores correlate with task performance? To be clear, I think the training time analyses are interesting, but I found it a bit unclear what theoretical question they are answering."}, "questions": {"value": "Below are some questions and more minor suggestions.\n \nIt was unclear in the text which of the evaluation datasets were novel, and which were taken from previously published work (e.g., BLiMP, Zorro, HellaSwag, ARC). Please add in-text citations for the datasets that are not novel.\n \nIn Section 2.1, does it make sense to average across voxels of different individuals? Does the spatial normalization process take care of this?\n \nSection 2.3 was a bit hard to follow, especially since it is so far ahead of the figures.\n \nIt’s not accurate to say that the models are making “acceptability judgments on sentences” for the BLiMP and Zorro benchmarks (l. 440). You are comparing the probabilities of strings, not asking models for acceptability judgments, correct?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ztdqIPNxQu", "forum": "PJ2z6s2gM3", "replyto": "PJ2z6s2gM3", "signatures": ["ICLR.cc/2026/Conference/Submission18896/Reviewer_66aJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18896/Reviewer_66aJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18896/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761937390672, "cdate": 1761937390672, "tmdate": 1762930866149, "mdate": 1762930866149, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tests the brain alignment to left and right brain hemispheres (from the Le Petit Prince fMRI dataset) of LLMs over training (OLMo-2 7B, Pythia 2.8 and 6.9B).\nThis is inspired by a recent finding that LLMs predict the left hemisphere slightly better (Bonnasse-Gahot & Pallier, 2024).\nDifferences in models' brain alignment scores across hemispheres are compared to their formal and functional competencies via 7 different benchmarks. The authors claim a strong correspondence during training of brain alignment to formal, but not functional competencies."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. correspondence between performance (on BLiMP, Zorro, ARC Easy) seems to mirror the left-right brain alignment asymmetry very closely. I have rarely seen task scores and biology measurements mirror each other this closely. The findings are consistent with a recent study by AlKhamissi et al. (2025), although the correspondence of formal competencies with the left-right asymmetry seems to be even stronger than with brain alignment overall.\n\n2. findings are generalized across multiple models.\n\n3. findings are generalized across multiple languages (English, French).\n\nCode available in supplement, and GitHub release promised upon acceptance."}, "weaknesses": {"value": "My main concern is that the difference in L vs R hemisphere alignment is rather marginal: The overall difference in brain alignment between left and right hemispheres reaches a maximum of 0.02 -- is this a difference that we really think is crucial to investigate? I am genuinely asking, it just seems like a small quantitative phenomena to me but the correspondence with formal competencies is so striking.\n\nFrom another perspective there is a lack of explanation for why the field should care about this left-right asymmetry. Classic neuroscience studies have claimed a left lateralization of the human language network (e.g., Fedorenko et al.) but with LLMs going well beyond core language processing, it's not obvious to me that we should expect them to be more predictive of the left hemisphere.\n\nIt would also have been great to test this on more than one fMRI dataset, but I understand that more models and more datasets would always be nice :)"}, "questions": {"value": "Please help us understand why the left-right asymmetry in models' brain alignment is important."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "oM7SYVL0DK", "forum": "PJ2z6s2gM3", "replyto": "PJ2z6s2gM3", "signatures": ["ICLR.cc/2026/Conference/Submission18896/Reviewer_uPnb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18896/Reviewer_uPnb"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18896/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761941409573, "cdate": 1761941409573, "tmdate": 1762930865265, "mdate": 1762930865265, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies why large language models (LLMs) show a left-right hemispheric asymmetry in predicting human brain activity. The main hypothesis is that this asymmetry arises when the LLM gains \"formal linguistic competence\" (like grammar), not \"functional competence\" (like reasoning or world knowledge).\nThe authors analyze how the alignment between LLM representations and fMRI signals changes during training, using the OLMo-2 7B model and both English and French data."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear focus on a specific neuroscience question.\n2. Striking correlation between formal linguistic gains and L-R asymmetry."}, "weaknesses": {"value": "1. The automatic scoring of generated text depends on another LLM (DeBERTa), raising concerns about model-induced bias.\n2. The quantitative analysis uses very few data points, possibly making the conclusions unstable.\n3. Averaging fMRI signals across subjects may mask individual differences."}, "questions": {"value": "1. How do the authors rule out bias in using a model (DeBERTa) to judge another model’s outputs?\n2. Why is there no L-R effect for Dyck despite it being a purely formal task?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "yMJaCFwMWH", "forum": "PJ2z6s2gM3", "replyto": "PJ2z6s2gM3", "signatures": ["ICLR.cc/2026/Conference/Submission18896/Reviewer_V7qQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18896/Reviewer_V7qQ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18896/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971497388, "cdate": 1761971497388, "tmdate": 1762930864705, "mdate": 1762930864705, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}