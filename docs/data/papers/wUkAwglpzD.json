{"id": "wUkAwglpzD", "number": 6131, "cdate": 1757953755900, "mdate": 1763455059821, "content": {"title": "Fine-grained Contrastive Learning for ECG-Report Alignment with Waveform Enhancement", "abstract": "Electrocardiograms (ECGs) are essential for diagnosing cardiovascular diseases. However, existing ECG-Report contrastive learning methods focus on whole-ECG and report alignment, missing the link between local ECG features and individual report tags.\nIn this paper, we propose FG-CLEP (Fine-Grained Contrastive Language ECG Pre-training), which achieves fine-grained alignment between specific ECG segments and each tag in the report via tag-specific ECG representations. Furthermore, we found that nearly 55\\% of ECG reports in the MIMIC-ECG training dataset lack detailed waveform features, which hinders fine-grained alignment. To address this, we introduce a coarse-to-fine training process that leverages large language models (LLMs) to recover these missing waveform features and validate the LLM outputs using a coarse model. Additionally, fine-grained alignment at the tag level, rather than at the report level, exacerbates the false negative problem, as different reports may share common tags. To mitigate this, we introduce a semantic similarity matrix to guide the model in identifying and correcting false negatives. \nExperiments on six datasets demonstrate that FG-CLEP significantly improves fine-grained alignment, outperforming state-of-the-art methods in both zero-shot prediction and linear probing. Meanwhile, the fine-grained reports we generate also enhance the performance of other methods.", "tldr": "", "keywords": ["ECG", "fine-grained alignment", "multimodal contrastive learning"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/12c470d6e1f1c107ed1564f82426b9a858ac4623.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents FG-CLEP, a fine-grained ECG–report alignment model that links ECG patches with report tags."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Introduces a cross-attention patch-tag alignment and LLM-based fine-grained training pipeline for ECG-text pretraining."}, "weaknesses": {"value": "- This work has limited technical novelty. The work depends on the LLM usage instead of core modeling. Also, the LLM-generated GF reports are clinically unverifiable and risk introducing noise or bias and especially even label leakage when doing zero-shot experiments. \n\n- Lack comparisions with recent ECG-text modeling works."}, "questions": {"value": "- How to ensure ECG patches with specific patch length align to any of clinical report tags?  \n\n- Please compare the work with recent advances on ECG-Text pretraining works [1,2]. In many evaluation setting, the performance are poorer than them, whether the work uses “FG-” or not.  \n\n- Furthermore, [2] also point out the close problem with false negative samples (report level). Please provide additional experiments to compare N3S in [2] and the FNM in this work. \n\n- Please add linear probing experiment with METS model and compare with the work. \n\n- In ablation study, w/o Fine-Grained Alignment performance is very close (<1%) with the proposed model (default) while the w/o Fine-Grained Report performance is clearer. Does this show that the work highly rely on additional LLM usage and used trick like ensemble? \n\n- Furthermore, looking at linear probing results (table 2), where only ECG encoder is used, the gap between with “FG-“ and without “FG-” is minor. Does this mean the “FG-” just slightly boost the ECG encoder (which I suppose, is the core component in real-world deployment). \n\n- Figure 4 is not mentioned in any text.  \n\n- It seems to be unable to access to the code provided.  \n\n[1] Wang, Fuying, Jiacheng Xu, and Lequan Yu. \"From Token to Rhythm: A Multi-Scale Approach for ECG-Language Pretraining.\" Forty-second International Conference on Machine Learning.  \n\n[2] Hung, Manh Pham, Aaqib Saeed, and Dong Ma. \"Boosting Masked ECG-Text Auto-Encoders as Discriminative Learners.\" Forty-second International Conference on Machine Learning."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "hleVmX47GM", "forum": "wUkAwglpzD", "replyto": "wUkAwglpzD", "signatures": ["ICLR.cc/2026/Conference/Submission6131/Reviewer_YzBY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6131/Reviewer_YzBY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6131/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761295724748, "cdate": 1761295724748, "tmdate": 1762918485214, "mdate": 1762918485214, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents FG-CLEP, an innovative framework that advances ECG–text alignment by introducing fine-grained contrastive learning between ECG patches and report tags."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper presents FG-CLEP, an innovative framework that advances ECG–text alignment by introducing fine-grained contrastive learning between ECG patches and report tags. Its coarse-to-fine training pipeline, which integrates large language models (LLMs) for recovering missing waveform features, demonstrates strong methodological creativity and practical relevance. Extensive experiments across six datasets show consistent performance gains in both zero-shot and linear probing tasks, validating the model’s robustness and generalizability. Visualizations (activation maps and retrieval results) provide qualitative support for fine-grained alignment."}, "weaknesses": {"value": "The dependence on LLMs for generating waveform features may introduce bias or inconsistency, even with CLEP-based validation.  \nThe evaluation lacks human expert assessment of fine-grained alignment quality beyond AUC metrics, limiting interpretability claims. \nThe training efficiency and computational cost of multi-stage fine-tuning and LLM querying are not clearly quantified, raising concerns about scalability in clinical deployment. \nThe model’s reliance on tag-level alignment assumes structured report formats, which may not generalize across healthcare systems or languages. \nWhile the paper claims improvements in zero-shot settings, statistical significance testing is not reported. \nThere are several writing issues, i.e., the legend of Fig.2 is incomplete (line 230); ref information is incomplete (line 286)."}, "questions": {"value": "How does FG-CLEP perform on free-text clinical reports rather than tag-based structured ones?\n\nWhat are the computational and time costs of the coarse-to-fine training pipeline when scaling to larger datasets?\n\nHave you evaluated the clinical interpretability of tag-specific ECG activations with cardiologists?\n\nHow sensitive is FG-CLEP to LLM hallucinations or errors during waveform feature generation, especially when the validation threshold varies?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NIdTuHrKub", "forum": "wUkAwglpzD", "replyto": "wUkAwglpzD", "signatures": ["ICLR.cc/2026/Conference/Submission6131/Reviewer_4kU3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6131/Reviewer_4kU3"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6131/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761787250342, "cdate": 1761787250342, "tmdate": 1762918484651, "mdate": 1762918484651, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a coarse-to-fine training process that leverages large language models (LLMs) to recover these missing waveform features and validate the LLM outputs using a coarse model. Besides, authors introduce a semantic similarity matrix to guide the model in identifying and correcting false negatives. Experiments demonstrate the superior performance of the proposed approach."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The problem of ECG–language pretraining is important and has clear clinical relevance.\n\n2. The proposed framework is well-motivated and technically sound; the LLM-enriched waveform features are novel.\n\n3. Experiments across multiple tasks show competitive or superior performance."}, "weaknesses": {"value": "1. In the “Fine-Grained Contrastive Learning Objective,” it appears that a single tag is randomly sampled per ECG. If so, this could ignore information from other relevant segments and reduce feature richness. Please clarify the sampling procedure and consider reporting results with multi-tag aggregation or coverage-controlled sampling.\n\n2. While the tag sampling strategy plausibly aligns better with zero-shot text prompts and could help zero-shot performance, the improvements on linear probing are small. This suggests the proposed fine-grained objective may not meaningfully strengthen the learned ECG representation. A targeted ablation contrasting zero-shot and linear-probe gains would help.\n\n3. The LLM-enriched waveform reports are an interesting idea. However, Table 3 indicates that mitigating false negatives has a larger impact than the fine-grained training itself. Please isolate these effects: show results applying the false-negative technique to the original reports (without LLM enrichment) to quantify each component’s contribution.\n\n4. Figure 5 is difficult to interpret and adds limited insight. An ECG retrieval analysis (e.g., text→ECG or ECG→text or ECG→ECG retrieval with qualitative examples and recall@k) would be more informative for assessing alignment quality."}, "questions": {"value": "1. How are ECG patches defined (temporal windows, lead-wise splits, or both)? What does $N_{lead}$ denote precisely? If patches are fixed windows, how do you ensure complete morphology is captured (e.g., P–QRS–T cycles) rather than fragmented?\n\n2. How are labels for “false negative” tags identified or constructed in training? Please detail the detection heuristic, thresholds, and any human verification.\n\n3. Are the results in Table 3 from linear probing or zero-shot classification, and on which dataset(s)? Briefly state the evaluation protocol to make the comparison interpretable.\n\n4. Please highlight the best results (e.g., boldface) to improve readability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "uOQCPLXm0T", "forum": "wUkAwglpzD", "replyto": "wUkAwglpzD", "signatures": ["ICLR.cc/2026/Conference/Submission6131/Reviewer_NT2L"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6131/Reviewer_NT2L"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6131/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761883535736, "cdate": 1761883535736, "tmdate": 1762918484173, "mdate": 1762918484173, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}