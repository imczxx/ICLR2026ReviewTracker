{"id": "NcvmuiLuZn", "number": 11248, "cdate": 1758194312124, "mdate": 1759897598646, "content": {"title": "Noise-to-Process Transformation: A Weak-Prior Paradigm for Single-Trajectory Stochastic Process Modeling", "abstract": "Stochastic processes offer a principled framework for trajectory-level uncertainty modeling from limited observations. Prior-driven methods (e.g., Gaussian processes) remain viable with scarce data but hinge on strong structural priors, whereas data-driven meta-approaches learn flexible representations yet typically require multi-trajectory supervision. To achieve flexibility from a single trajectory without strong priors, we introduce a noise-to-process (N2P) paradigm: a shared base-noise process \\(Z\\) is pushed through a single measurable generator $G_\\theta$ to produce a full trajectory $X=G_\\theta(Z)$, making projective consistency intrinsic by design. Instantiating the paradigm, we propose Deconvolution-Based Process Transformation (DBPT), a deconvolution-based generator that captures long-range, inter-temporal dependence. Across synthetic and diverse real single-trajectory tasks, DBPT delivers flexible uncertainty modeling and competitive performance to prior- and data-driven baselines.", "tldr": "This study introduces a noise-to-process transformation paradigm for weak-prior stochastic process modeling from single-trajectory.", "keywords": ["Stochastic Processes; Weak-Prior Modeling;"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b0d74e88e28da6dedc72c2a5c76a7e4a4b67e087.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces the Noise-to-Process (N2P) framework, transforming a sample from a base-noise process (Z) into a single trajectory (X) that remains consistent with observed data, supported by substantial theoretical development. Building on this, the authors propose a Deconvolution-Based Process Transformation (DBPT) implementation, which shows improvements over existing baselines on the MNIST and CIFAR datasets."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* **Thorough literature review**: Clearly situates the paper within prior work and explains both its positioning and novelty.\n\n\n* **Sound theoretical development**: Provides extensive theory development to justify the method design."}, "weaknesses": {"value": "*  The biggest concern is that the empirical performance seems weak. The proposed method shows superior results on MNIST/CIFAR at (32x32), but performs worse than WGP on the BIA and PDB benchmarks. The baselines and datasets are also kind of weak: the paper should at least test at (64x64), and more challenging datasets would be welcome. Most baselines are pre-2018, with only one (Bartosh et al., 2025) that is recent, including more recent baselines will strengthen the experiment part.\n\n* Line 96: the proof of Proposition 2 is referred to Proposition 10, but no proof is provided for Proposition 10. \n\n* The discussion of “Prior-driven Approaches” is not accurate. Line 222 states, “Despite these advances, learning remains anchored to a predefined prior scaffold,” This is a strong claim, and the prior over stochastic processes can be learned directly from data via flow/diffusion models (e.g., Shi et al., 2025), which enables exact (or principled) posterior sampling.  Reference: Shi et al., Stochastic Process Learning via Operator Flow Matching, 2025.\n\n* The paper introduces a theoretically index-agnostic paradigm but instantiates it with a specific, practical architecture (DBPT) that is, by its deconvolutional nature, tied to a discrete (regular) grid and its specific training resolution. The authors should explicitly acknowledge the gap between the theoretical advantages of the paradigm and the practical limitations of the implementation.\n\n* Super-resolution experiments are missing. While the DBPT design seems applicable for super-resolution, its convolutional constraints likely limit evaluation to the specific training resolution. In contrast, general NP or operator-learning–based models often enable zero-shot evaluation at different resolutions (e.g., train on 64x64, evaluate on 128x128 or higher) without retraining. \n\n*  The ablation study in Appendix J is confusing. The Transformer-based model seems to perform very poorly , while the deconvolution architecture is significantly better. This large performance gap raises suspicion that the Transformer model may not be correctly implemented or tuned. Given that numerous state-of-the-art models in computer vision and generative modeling use Transformers as backbones and consistently show advantages over convolution-based models, I strongly suggest the authors detail the settings for this part and consider trying either a standard ViT (Vision Transformer) or a (multi-layer) cross-attention architecture\n\n* Typos :  \n1) Line 269. “Figure 2 present” should be “presents” \n2) Line 292,  “GP demonstrate” should be “demonstrates”. \n3) Line 302, “The synthetic experiment demonstrate” should be “experiments” \n4) Line 1063, “rising from !1 min” check the typo"}, "questions": {"value": "See weaknesses. I’m inclined to raise my score if those concerns are resolved."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "n4AtdebJnw", "forum": "NcvmuiLuZn", "replyto": "NcvmuiLuZn", "signatures": ["ICLR.cc/2026/Conference/Submission11248/Reviewer_Rozw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11248/Reviewer_Rozw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11248/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760919797693, "cdate": 1760919797693, "tmdate": 1762922407657, "mdate": 1762922407657, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a “Noise-to-Process (N2P)” framework, claiming to model stochastic processes from a single trajectory via a generative mapping (X = G_\\theta(Z)) from a shared noise process. A specific instantiation, Deconvolution-Based Process Transformation (DBPT), is introduced and trained using a masked mean squared error (MSE) objective. The authors argue that this approach enables process-level uncertainty modeling under weak priors without requiring multiple trajectories, in contrast to Neural Processes (NP) or Gaussian Process (GP) models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.The paper is clearly written and attempts to unify process modeling ideas (GP, NP, neural SDEs) under a shared noise-to-function framework.\n\n2.The experimental results cover diverse tasks (synthetic, time series, image completion) and demonstrate reasonable reconstruction quality."}, "weaknesses": {"value": "The proposed N2P framework largely restates existing ideas found in Variational Implicit Processes, Normalizing Flow GPs, or Neural SDEs. The notion of generating a stochastic process via a measurable transformation of a base noise process (e.g., a Gaussian or Wiener process) is well established in prior literature. The contribution here is mainly terminological (“weak prior paradigm”) rather than methodological.\n\nDespite the stochastic notation, the training objective reduces to a deterministic regression with noise regularization:\n$$\nL = E_Z[\\frac{1}{\\tau_o}|R_{\\tau_o}(G_\\theta(Z)) - O|_F^2].\n$$\nThere is no explicit likelihood, no KL regularization, and no posterior inference—thus no genuine process-level probabilistic learning. In effect, the method behaves like a conditional generator (akin to a GAN without a discriminator) trained purely with an MSE loss.\n\nThe comparison with Neural Processes (NP) is also misleading. The claim that NP “requires multiple trajectories” is not accurate; NP frameworks can, in principle, operate on single trajectories, though with limited generalization. More importantly, NP remains a proper probabilistic model with explicit latent variables and variational inference, whereas N2P collapses to deterministic regression. The distinction the paper emphasizes (task-level z vs noise process Z) is not substantial.\n\nThe experimental evaluation is limited. Reported improvements over baselines are modest and could easily result from architectural capacity or convolutional inductive biases. There is no ablation study to isolate the effect of the proposed “noise process” component, and the claims of “single-trajectory learning” are not convincingly demonstrated—the model still relies on dense sampling along one trajectory, which effectively provides many supervision points.\n\nThe paper does not compare against recent and strong baselines in process learning and uncertainty-aware meta-learning, such as Attentive Neural Processes (Kim et al., 2019), Convolutional Conditional Neural Processes (Gordon et al., 2019), Transformer Neural Processes (Nguyen & Grover, 2022), and Neural Diffusion Processes (Dutordoir et al., 2023).\n\nIt also fails to cite or discuss several directly relevant works. Most notably, Variational Implicit Processes (Garnelo et al., ICML 2019) and “Functional Variational Inference based on Stochastic Process Generators” (Chao Ma, NeurIPS 2021) already introduced the same “noise-to-function” formulation with proper probabilistic objectives. Similarly, the idea of mapping base noise to structured samples has long existed in GANs and Normalizing Flow models. By omitting these foundational references and not clarifying its novelty relative to them, the submission overstates its originality and misrepresents its contribution.\n\nThe experimental validation is limited in both scale and diversity. Most experiments are confined to small, overused datasets such as MNIST and CIFAR-10. These benchmarks are no longer considered sufficient for demonstrating generalization or scalability in the ICLR community, as their challenges have been largely saturated. The paper does not evaluate on larger, more complex datasets or real-world continuous process data, making it difficult to assess whether the proposed framework meaningfully improves process-level modeling beyond toy examples.\n\nWhile the paper’s narrative is appealing—“learning stochastic processes from a single trajectory under weak priors”—the technical substance does not support this claim. The approach amounts to deterministic regression with injected noise and lacks both probabilistic rigor and meaningful novelty. The comparison with Neural Processes is conceptually misleading, and the theoretical contributions are largely decorative. \n\nAdditionally, several presentation and technical issues reduce the clarity of the paper. Many equations appear without numbering, making it difficult to reference them in the text. In addition, some lemmas and corollaries are stated without proof or with only vague intuitive arguments. For a paper that emphasizes theoretical grounding, the absence of formal derivations undermines the claimed rigor and makes it hard to verify correctness."}, "questions": {"value": "1. The paper claims to enable single-trajectory stochastic process learning, yet the training still relies on densely sampled points from the same trajectory. How does the method behave under sparse or partially observed data? Is there any theoretical or empirical analysis of sample complexity?\n\n2. The notion of a “weak prior” is central to the paper’s narrative. Could the authors formally define what constitutes a “weak” prior in this context and explain how it differs quantitatively from priors in GP or Neural SDE models?\n\n3. The training loss is a plain MSE （page 4） with Monte Carlo noise resampling. How does this loss capture process-level uncertainty rather than simple reconstruction accuracy? Have the authors considered using an explicit likelihood-based or probabilistic objective instead?\n\n4. Compared with *Variational Implicit Processes* (VIP) (Garnelo et al., ICML 2019), the proposed method removes the variational posterior and KL term. What is the theoretical justification for this simplification? Does this mean the model is optimized purely under empirical risk minimization without probabilistic inference semantics?\n\n5. Theoretical elements such as Kolmogorov consistency and measurability are presented at length. Do these properties impose any actual constraints or provide practical benefits for model training and inference, or are they purely formal?\n\n6. The experiments omit comparisons with recent state-of-the-art Neural Process and process-learning models (e.g., Attentive NP, Transformer NP, Neural Diffusion Processes). Were these baselines tested, and if not, how do the authors justify the fairness of their empirical evaluation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tYefmOyQHg", "forum": "NcvmuiLuZn", "replyto": "NcvmuiLuZn", "signatures": ["ICLR.cc/2026/Conference/Submission11248/Reviewer_C7wr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11248/Reviewer_C7wr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11248/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761145522260, "cdate": 1761145522260, "tmdate": 1762922407133, "mdate": 1762922407133, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a ``noise-to-process'' (N2P) paradigm for learning stochastic processes from a single, sparsely observed trajectory. The key idea is to learn a single, parameterized generator $G_{\\theta}$  that maps a shared base-noise process $Z$ to a full trajectory $\\bar{X} = G_{\\theta}(Z)$. This design ensures projective consistency by construction, as all finite-dimensional marginals are projections of the same joint sample. The authors instantiate this paradigm with Deconvolution-Based Process Transformation (DBPT), which uses a noise encoder and a multi-scale deconvolutional decoder to capture inter-temporal dependencies. DBPT is evaluated on synthetic data, financial time series, image completion, and black-box optimization, comparing against prior-driven (e.g., GPs, SDEs) and data-driven (e.g., CNPs) baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The general idea of the paper is easy to follow. \n\n* The `noise-to-process' paradigm, in its abstract form, bears a conceptual resemblance to frameworks like transformed GPs that map a base process through a nonlinear function. However, the significant novelty of this work lies in its concrete formulation for the single-trajectory regime and the introduction of the DBPT architecture, which uses a shared noise process and a deconvolutional decoder to explicitly enforce projective consistency and capture long-range dependencies."}, "weaknesses": {"value": "Some limitations in my eyes are as follows:\n\n* **Writting**. The writting and organization of the paper can be improved. For example, the citation commands (e.g., \\citet vs. \\citep) appear to be used wrongly and inconsistently, which affects the flow of the narrative. Several acronyms are introduced without full definitions at first use.  \n\n*  The experiment section can be better explained. For example, in terms of time-series MSE, what is the MSE here? Prediction or imputation?\n\n*   **Limitation of Discrete Index Sets:** The entire framework is built upon a discretized index set $\\mathcal{T}$. While Corollary 13 states that the model is *compatible* with Kolmogorov extension to a continuum, this is an existence result. In practice, the trained DBPT model is fixed to its training grid. Making predictions at arbitrary, new time points not in $\\mathcal{T}$ would require re-discretization and potentially retraining, which is a significant limitation compared to native continuous-time models like GPs or Neural SDEs. The method lacks **native continuous-index inference**.\n\n*   **Dependence on Generator and Noise Specifications:** The quality of the learned stochastic process is entirely dependent on the representational capacity of  $G_{\\theta}$ and the characteristics of the base noise $Z $. While the deconvolution decoder is a good choice, the framework is susceptible to issues common in generative models, such as potential **mode collapse** or failure to capture the full complexity of the target process's randomness, especially if the architecture or noise dimension is poorly chosen. \n\n*   **Scalability and Computational Cost:** The claim of ``lightweight computation'' (Appendix E) is supported for the presented tasks, but this may not scale well. Generating the *entire trajectory* in one forward pass means that for very high-resolution index sets (e.g., megapixel images or extremely long sequences), the memory and computation cost of the deconvolutional decoder could become prohibitive. A more nuanced discussion of the **computational complexity in  $|\\mathcal{T}|$** and its scaling limits would be helpful.\n\n*   **Depth of Comparison with State-of-the-Art:** The baseline selection is relatively dated (except SDE matching); a comparison with more recent and powerful sequence models, such as single-sequence diffusion models (see question section) or Gaussian process state-space models, would strengthen the evaluation."}, "questions": {"value": "1. The theoretical guarantee of projective consistency is a key advantage. Could you design a simple quantitative experiment to empirically verify this property on a held-out test? For example, by showing that the marginal distribution at a point  $t$, computed from different higher-dimensional joint distributions that includet, remains consistent, which might not be the case for a method like CNP.\n\n2. The masked MSE objective is simple, but it only supervises the mean (implicitly). While uncertainty emerges from noise resampling, the training signal doesn’t directly optimize calibration (e.g., via NLL or CRPS). Maybe it should note that this is a pragmatic choice, but may limit distributional fidelity compared to likelihood-based methods.  And also, in terms of performance metrics, including CRPS and other uncertainty quantification metrics would be beneficial. \n\n3. In sparse data regimes, I suspect that overfitting can be an issue. At least, training the network here seems not data-efficient to me. Can the authors explain more about this, particularly compared to GP+DKL?\n\n4. The paper shows an ablation on the decoder architecture. Could you provide more analysis on the sensitivity to the dimension and distribution of the base noise $Z$? What happens if  $d_z $ is too small or too large? Are there guidelines for choosing $Z$ for a new problem?\n\n5. There are a series of papers about ``Diffusion Generative Models in Infinite Dimensions'' and ``Score-based Diffusion Models in Function Space'', which also transform the noise into a random process. There was a lack of discussion of comparisons in the paper. In my opinion, this paper should also compare to the Transformed Gaussian Processes (TGP) using Normalizing Flow, since TGP is also strongly related to this paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gW0aIdsGyf", "forum": "NcvmuiLuZn", "replyto": "NcvmuiLuZn", "signatures": ["ICLR.cc/2026/Conference/Submission11248/Reviewer_FTEz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11248/Reviewer_FTEz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11248/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761536896068, "cdate": 1761536896068, "tmdate": 1762922406750, "mdate": 1762922406750, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work proposed a noise to stochastic process (N2P) framework that consists of two parts, a shared base process and a shared generator to transform the base process to observable trajectories. The work aims at solving the prior constraints of existing approaches like SDE-based approaches or structured GP-based approaches. The work further proposed an instantiation of the N2P framework called deconvolution based process transformation (DBPT) where the base process are IID Gaussians on a finite discrete time grid and the common generator is a deconvolution network. The work evaluate the proposed DBPT on both time-series modelling and image completion tasks and conducted ablation study on"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The experiment section of the work considers a divers set of tasks including time series modeling, image modeling and black-box optimization.\n2. The presentation is well structured with a general N2P framework followed by DBPT as the the concrete instantiation of the N2P framework and the technical details. The work makes a clear distinction between N2P as the theoretical framework and DBPT as a methodological contribution.\n3. The work also studies different architecture choice for DBPT to justify the choice of a deconvolution architecture."}, "weaknesses": {"value": "1. In Section 2.1, the work grounds the theoretical results on the basis of finite or countable time grid T. First, I can not see how a generator $G_\\theta$ take an infinite number of $Z_t$s as inputs. Considering the actual DBPT model operates on a predefined, finite, discrete grid, the actual instantiation of the N2P framework is underwhelming and makes the grandiose theoretical result of Section 2.2 which invokes the Kolmogorov Extension Theory unnecessary.\n2. The experiment results on finance related data is very weak. \n3. The work compares against conditional neural processes and SDE matching as baselines from the SDE-based approaches and neural process families. More recent and stronger baselines like latent SDE [1, 2], attentive and transformer neural processes[3, 4], gaussian neural processes [5, 6] should be compared against.\n\nReferences:\n\n[1] Li, Xuechen, et al. \"Scalable gradients for stochastic differential equations.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2020.\n\n[2] Deng, Ruizhi, et al. \"Continuous latent process flows.\" Advances in Neural Information Processing Systems 34 (2021): 5162-5173\n\n[3] Kim, Hyunjik, et al. \"Attentive neural processes.\" arXiv preprint arXiv:1901.05761 (2019).\n\n[4] Nguyen, Tung, and Aditya Grover. \"Transformer neural processes: Uncertainty-aware meta learning via sequence modeling.\" arXiv preprint arXiv:2207.04179 (2022).\n\n[5] Bruinsma, Wessel P., et al. \"The Gaussian neural process.\" arXiv preprint arXiv:2101.03606 (2021).\n\n[6] Markou, Stratis, et al. \"Practical conditional neural processes via tractable dependent predictions.\" arXiv preprint arXiv:2203.08775 (2022)."}, "questions": {"value": "1. If we restrict the setup to a finite, discrete, and pre-defined time grid, is there any fundamental difference between the proposed N2P framework and the existing neural processes framework?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "pHjtKGlJ9A", "forum": "NcvmuiLuZn", "replyto": "NcvmuiLuZn", "signatures": ["ICLR.cc/2026/Conference/Submission11248/Reviewer_ZGqT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11248/Reviewer_ZGqT"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11248/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761807577768, "cdate": 1761807577768, "tmdate": 1762922406239, "mdate": 1762922406239, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}