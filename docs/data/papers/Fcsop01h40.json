{"id": "Fcsop01h40", "number": 1765, "cdate": 1756916365659, "mdate": 1759898187971, "content": {"title": "CoPRS: Learning Positional Prior from Chain-of-Thought for Reasoning Segmentation", "abstract": "Existing works on reasoning segmentation either connect hidden features from a language model directly to a mask decoder or represent positions in text, which limits interpretability and semantic detail. To solve this, we present CoPRS, a Multi-modal Chain-of-Thought (MCoT)–based positional perception model that bridges language reasoning to segmentation through a differentiable and interpretable positional prior instantiated as a heatmap. By making the reasoning process clear via MCoT and expressing it as a dense, differentiable heatmap, this interface enhances interpretability and diagnostic analysis and yields more concentrated evidence on the target. A learnable concentration token aggregates features of the image and reasoning text to generate this positional prior, which is decoded to precise masks through a lightweight decoder, providing a direct connection between reasoning and segmentation. Across the RefCOCO series and ReasonSeg, CoPRS matches or surpasses the best reported metrics on each standard split under comparable protocols, with performance at or above prior state of the art across both validation and test partitions. Extensive experiments reveal that the quality of the heatmap strongly influences the resulting mask quality, supporting a consistent association between the reasoning output and downstream mask generation. Collectively, these findings support the utility of this paradigm in bridging reasoning and segmentation and show advantages in concentration driven by reasoning and predicting masks more precisely. Code, checkpoints and logs will be released.", "tldr": "This paper introduces CoPRS, a reasoning segmentation model that first uses \"chain-of-thought\" to generate an interpretable positional prior (i.e., an explicit heatmap), hinting at where in the image it's focusing before decoding the final mask.", "keywords": ["Reasoning Segmentation", "Reinforcement Learning", "Positional Prior", "Multi-Modal Chain-of-Thought"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/76b385a7dafdf33403c70f8717170b19a43b0e15.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces CoPRS, a multimodal chain-of-thought (MCoT)-based method for reasoning segmentation that bridges language reasoning to pixel-level segmentation via a differentiable positional prior (heatmap). The key contributions include:  \n\n- A novel interface using a learnable \"concentration token\" to generate positional priors from MCoT reasoning, providing interpretable intermediate heatmaps.  \n- A unified training framework combining Group Relative Policy Optimization (GRPO) for language reasoning and segmentation supervision for mask refinement.  \n- State-of-the-art performance on RefCOCO series and ReasonSeg benchmarks, with ablation studies demonstrating the correlation between heatmap quality and segmentation accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "*Originality*: The integration of MCoT reasoning with dense positional priors offers a fresh perspective compared to existing latent-feature or text-coordinate paradigms. The use of GRPO for joint language-reasoning segmentation optimization is a creative combination of reinforcement learning and segmentation tasks.  \n*Clarity*: The architecture diagram (Figure 2) effectively illustrates the pipeline. The distinction between training modes (GRPO vs. supervised) is well articulated.  \n*Significance*: Addresses a critical gap in interpretability for reasoning segmentation systems. The reported 3B/7B model improvements over text-coordinate baselines (e.g., +4.7 cIoU over Seg-R1 on RefCOCOg) demonstrate practical value."}, "weaknesses": {"value": "*Limited Baseline Comparison*: While compared to latent-reasoning and text-based methods, there is no direct comparison with recent hybrid approaches like PerceptionGPT-R1 or RAS-13B under identical training protocols. This leaves uncertainty about absolute performance claims.  \n*Ablation Depth*: The GRPO hyperparameter study (Table 4) only tests sampling numbers {2,4,8} without justifying this range. More analysis is needed on how group size affects exploration-exploitation tradeoffs in segmentation contexts.  \n*Methodological Ambiguity*: The heatmap generation process (Eq. 3-4) lacks critical implementation details, e.g., how the MLP maps vision backbone outputs to keys, or why two convolutional layers were chosen for F<sup>fuse</sup>. This hinders reproducibility.  \n*Theoretical Limitations*: While empirical correlations are shown, there is no formal analysis of why GRPO’s group-relative advantages are particularly suited for segmentation tasks compared to standard PPO."}, "questions": {"value": "**Q1**: How does CoPRS handle ambiguous positional priors in crowded scenes (Figure 5)? The failure cases suggest sensitivity to instance density – could multi-scale features or contrastive learning between instances mitigate this?  \n**Q2**: For GRPO sampling numbers (Table 4), what computational overhead does G=8 introduce compared to G=2? A latency/accuracy tradeoff analysis would help practitioners.  \n**Q3**: The correlation analysis (Figure 3) shows association but not causation between heatmaps and masks. Could you disentangle whether performance gains stem primarily from GRPO-enhanced reasoning or the decoder architecture?  \n**Suggestion 1**: Add comparisons with RAS-13B and PerceptionGPT-R1 using comparable model sizes.  \n**Suggestion 2**: Include an ablation on the vision backbone (e.g., ViT-H vs. ViT-L) to clarify performance dependencies.  \n**Suggestion 3**: Provide pseudocode or extended equations for the heatmap generation process (Section 3.1) to improve reproducibility.  \n\n**Rebuttal Potential**: Addressing the baseline comparison gap (Suggestion 1) and providing theoretical justification for GRPO’s effectiveness in segmentation could significantly strengthen the contribution narrative. Clarifying the heatmap implementation details (Suggestion 3) would enhance methodological rigor."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "l1Aq04uFid", "forum": "Fcsop01h40", "replyto": "Fcsop01h40", "signatures": ["ICLR.cc/2026/Conference/Submission1765/Reviewer_XDcj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1765/Reviewer_XDcj"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1765/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761812330484, "cdate": 1761812330484, "tmdate": 1762915883495, "mdate": 1762915883495, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces CoPRS, a novel Multi-modal Chain-of-Thought (MCoT)-based framework that connects language reasoning to visual segmentation through a differentiable positional prior represented as a heatmap. The model integrates a learnable concentration token within a multimodal LLM to aggregate textual reasoning and visual context, producing a heatmap that serves as an interpretable intermediate between reasoning and segmentation. The approach is trained end-to-end by combining Group Relative Policy Optimization (GRPO) for reasoning and supervised segmentation losses for mask prediction.\n\nEmpirically, CoPRS achieves state-of-the-art results on the RefCOCO, RefCOCO+, RefCOCOg, and ReasonSeg benchmarks, demonstrating both superior performance and better interpretability compared to prior latent- or text-based reasoning methods. The paper also presents correlation analyses showing that the quality of the learned heatmap aligns strongly with final segmentation accuracy, highlighting the causal link between reasoning and perception."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Overall, writing is clear with intuitive figures. \n\n- The paper introduces an interpretable and differentiable positional prior as an intermediate representation linking language reasoning (via MCoT) to visual segmentation.\n\n- The joint GRPO + supervised objective elegantly integrates reasoning quality and mask precision within a single training loop.\n\n- The heatmap prior provides transparent evidence of where the model is “attending,” supporting qualitative interpretability and quantitative correlation analysis (R > 0.7 between heatmap and mask quality).\n\n- Consistently outperforms both latent reasoning (e.g., LISA, SegLLM) and text-based reasoning methods (e.g., Seg-Zero, Text4Seg) across all RefCOCO variants and ReasonSeg.\n\n- Experimental details are available to reproduce the result. \n\n- The ablation studies on different setups (training mode, reward function, etc) demonstrate further the advantage of the proposed method."}, "weaknesses": {"value": "- The core modules (GRPO, SAM decoder, etc) are existing frameworks; the contribution mainly lies in combining them rather than introducing fundamentally new architectures. Further clarifications on the technical novelty would strengthen the paper.\n\n- Results are tied to Qwen2.5-VL and SAM encoders; unclear how robust the method is across different MLLM backbones or smaller models.\n\n- Although some failure cases are available in the appendix, the paper does not discuss the limitations of the proposed method explicitly in the main text. Adding discussions on limitations will enhance the clarity of the paper. \n\n- GRPO-based multimodal optimization on large MLLMs is computationally heavy; practical feasibility for wider adoption is not discussed."}, "questions": {"value": "- How sensitive is CoPRS to the design of the concentration token prompt (e.g., `<REF_POS>`)?\n\n- Does the GRPO-based reward generalize to new reasoning templates unseen during training? (Does the RL signal capture general reasoning ability rather than just overfit to specific CoT structures?)\n\n- Can the positional prior mechanism transfer to other grounding tasks (e.g., referring tracking or VQA grounding)? (Is the proposed differentiable positional prior is a general paradigm?)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "mbPR1zd1CX", "forum": "Fcsop01h40", "replyto": "Fcsop01h40", "signatures": ["ICLR.cc/2026/Conference/Submission1765/Reviewer_HRqs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1765/Reviewer_HRqs"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1765/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761852333046, "cdate": 1761852333046, "tmdate": 1762915883202, "mdate": 1762915883202, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Free-form Reasoning Segmentation requires coupling language reasoning with visual segmentation. Existing work either uses latent reasoning which offers limited interpretability or text-based reasoning which has limited flexibility. This paper introduces CoPRS, which produces concentration tokens through multimodal chain-of-thought, which are then used to generate heatmaps over the images through attention, and finally producing the segment masks. All components of CoPRS are trained end-to-end using two objectives: a GRPO objective over the output tokens and a supervised segmentation objective over the heatmap and the final predictions. Experiments show that CoPRS achieves competitive performance on RefCOCO and ReasonSeg over existing methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "End-to-end training that allows the model to learn to perform CoT reasoning, generate the query embeddings, and generate the mask simultaneously. \n\nThe approach shows strong results across two benchmarks, comparing against an extensive set of existing methods.\n\nThe paper is well-written and easy to follow."}, "weaknesses": {"value": "The paper aims to balance interpretability and representational fidelity by generating heatmaps over the images as positional priors. However, this heatmap generation process itself is not interpretable. From my understanding, the training objective encourages the heatmap to match the ground truth masking, which could be seen as a one of the latent reasoning methods discussed in the introduction, and suffers the same downsides of interpretability. \n\nCoPRS relies on a vision backbone to produce the key embeddings that are used to generate the positional prior. This introduces additional computation compared to other methods. Furthermore, the quality of the vision backbone model seems very important, but the paper does not examine the effect of it on the overall performance. \n\nTable 5 and 6 shows ablation on the model’s training objectives. However, there is no in-depth analysis of these results. How are the weights decided?"}, "questions": {"value": "I don’t quite see how H_prior can always be visualized as in figure 2. Does H_prior always have the fixed dimension size equal to the image? What does each element in K represent? \n\nHow does this differ from latent reasoning method where the latent reasoning is done via an attention mechanism where the attention scores can be extracted (ex. the coder in PixelLM)? Wouldn’t the attention score also be interpreted as heatmaps? \n\nI don’t think it is mentioned in the paper, what is CoPRS an acronym for?\n\nMinor:\n\nTypo: line 297, 406\n\nThe citation for SegLLM is incorrect."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zU1RdGHqsu", "forum": "Fcsop01h40", "replyto": "Fcsop01h40", "signatures": ["ICLR.cc/2026/Conference/Submission1765/Reviewer_eH3B"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1765/Reviewer_eH3B"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1765/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761964741442, "cdate": 1761964741442, "tmdate": 1762915882990, "mdate": 1762915882990, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes CoPRS, a CoMT approach that extracts a query from the MLLM. The query is used to generate a differentiable heatmap with cross-attention and acts as a positional prior to the segmentation decoder. The key contributions are:\n- A dense, differentiable heatmap is an interpretable link of the MLLM and mask generation. \n- A training framework that combines GRPO and supervised objective.\n- CoPRS achieves good results on RefCOCO series and ReasonSeg."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper addresses a relevant multimodal problem, bridging language reasoning with spatial localization.\n- The positional prior offers intermediate interpretability, given the correlation between the quality of the prior and that of the final segmentation mask\n- Clear empirical gains on evaluation benchmarks.\n- Cleverly combining reinforcement learning with supervised learning"}, "weaknesses": {"value": "- The new architecture adds complexity that must be quantified to justify a reduction in speed by the performance gains.\n- Although CoT reasoning is emphasized, the actual CoT outputs and their role are not examined. There is no evidence that linguistic reasoning aligns with the generated heatmap.\n- Interpretability was studied only through correlation between the heatmap and the final mask, both in the visual domain. The interpretability role of reasoning is unclear.\n- GRPO, although more efficient than PPO, is still expensive on a large backbone. The ablation only compares with/without GRPO, without exploring how reasoning reward affects segmentation quality."}, "questions": {"value": "- How sensitive are the reported gains to the MLLM backbone? Ablations with a smaller model or from a  different family (e.g. LLaVa) will show how dependent the model is on the specific architecture.\n- In the GRPO reward design, the choice “0.7 for mask and 0.3 for CoT” might be reasonable, but it is left unexplained.\n- How correct are the CoT reasoning trajectories, and how do they contribute to interpretability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lPr4POFoie", "forum": "Fcsop01h40", "replyto": "Fcsop01h40", "signatures": ["ICLR.cc/2026/Conference/Submission1765/Reviewer_vsKC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1765/Reviewer_vsKC"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1765/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761965504442, "cdate": 1761965504442, "tmdate": 1762915882748, "mdate": 1762915882748, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}