{"id": "Ktd8Zus4G8", "number": 18019, "cdate": 1758282960805, "mdate": 1759897139252, "content": {"title": "CC-Time: Cross-Model and Cross-Modality Time Series Forecasting", "abstract": "With the success of pre-trained language models (PLMs) in various application fields beyond natural language processing, language models have raised emerging attention in the field of time series forecasting (TSF) and have shown great prospects. However, current PLM-based TSF methods still fail to achieve satisfactory prediction accuracy matching the strong sequential modeling power of language models. To address this issue, we propose Cross-Model and Cross-Modality Learning with PLMs for time series forecasting (CC-Time). We explore the potential of PLMs for time series forecasting from two aspects: 1) what time series features could be modeled by PLMs, and 2) whether relying solely on PLMs is sufficient for building time series models. In the first aspect, CC-Time incorporates cross-modality learning to model temporal dependency and channel correlations in the language model from both time series sequences and their corresponding text descriptions. In the second aspect, CC-Time further proposes the cross-model fusion block to adaptively integrate knowledge from the PLMs and time series model to form a more comprehensive modeling of time series patterns. Extensive experiments on nine real-world datasets demonstrate that CC-Time achieves state-of-the-art prediction accuracy in both full-data training and few-shot learning situations.", "tldr": "", "keywords": ["Time Series Forecasting;  Pretrained Language Models"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/70c23b69823c50cf7895f230663580d63b48b82b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes CC-Time, a Cross-Model and Cross-Modality framework for time series forecasting that integrates the strengths of pre-trained language models and time-series-specific models. Traditional forecasting approaches either focus on numerical modeling of temporal patterns or exploit PLMs for sequence understanding, but each alone is limited. CC-Time bridges this gap by combining both paradigms and leveraging semantic knowledge from text to model complex temporal and channel correlations.The framework contains a PLM branch, a time-series branch, and a cross-model fusion module. The PLM branch introduces a cross-modality modeling mechanism, combining time-series data with automatically generated channel text descriptions to help PLMs capture both temporal dependencies and semantic relationships among channels. The time-series branch, built on a transformer structure, models fine-grained numerical temporal dynamics. The cross-model fusion block adaptively integrates multi-level features from both branches using attention and gating mechanisms, yielding a unified representation that captures both semantic and quantitative aspects of time series data.\nExperiments conducted on real-world datasets from diverse domains such as energy, weather, and traffic show that CC-Time achieves state-of-the-art prediction accuracy under both full-data and few-shot settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This paper is original in proposing a cross-model and cross-modality framework that unites pre-trained language models with time-series-specific architectures for forecasting. The idea of using automatically generated channel text descriptions to inject semantic knowledge into time-series modeling is interesting. The paper is well-structured. Its comprehensive experiments across multiple datasets and settings demonstrates strong generalization and robustness.  In terms of clarity, the paper is clearly written, well-organized, and supported by informative figures that make the architecture and motivation easy to follow. In all, this paper opens new directions for multimodal and cross-domain modeling in time-series research."}, "weaknesses": {"value": "* The paper does not provide a detailed hyperparameter sensitivity analysis, leaving some uncertainty about the robustness and stability of the proposed framework across different parameter settings.\n* The paper demonstrates that CC-Time captures richer correlations, but remains a little bit unclear how these align with real-world semantics or physical dependencies among channels."}, "questions": {"value": "* What is the computational overhead of the two branches？\n\n* Since the model relies on automatically generated channel text descriptions, how does the quality of these descriptions affect performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "deDuEVCXHA", "forum": "Ktd8Zus4G8", "replyto": "Ktd8Zus4G8", "signatures": ["ICLR.cc/2026/Conference/Submission18019/Reviewer_QNfh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18019/Reviewer_QNfh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18019/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760500525635, "cdate": 1760500525635, "tmdate": 1762927810217, "mdate": 1762927810217, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces CC-Time, a dual-branch architecture that integrates large language models (LLMs) and time-series-specific models for time series forecasting (TSF). The model addresses two key questions: (1) how to enable pre-trained language models (PLMs) to jointly capture temporal dependencies and variable correlations, and (2) how to leverage the complementary strengths of LLMs and traditional time-series models through adaptive fusion.To this end, the authors propose Cross-Modality Learning to enhance correlation modeling between numerical and textual representations, and a Cross-Level Fusion (CLF) block to integrate features from different representational levels. Experiments on nine real-world datasets show consistent performance improvements in both full-data and few-shot settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Novel integration of PLMs and TS models: The paper presents a thoughtful framework that unites semantic (LLM-based) and numerical (Transformer-based) modeling. The design of the CLF block reflects careful consideration of cross-representational learning in time series forecasting.\n\n2. Innovative cross-modality correlation modeling: Incorporating text-based variable descriptions and a correlation extractor allows the model to capture both global and local dependencies from semantic and numeric perspectives.\n\n3. Strong empirical validation: Experiments cover a broad range of datasets and forecasting horizons, consistently showing superior results over LLM-based and TS-specific baselines. Few-shot evaluations further demonstrate the potential of LLMs for low-data forecasting.\n\n4. Comprehensive component analysis: The paper provides ablation studies on cross-level fusion and cross-modality correlation modules, along with model-depth and freezing analyses that strengthen the empirical soundness of the claims."}, "weaknesses": {"value": "1. Lack of explicit modality alignment between time-series embeddings and PLM semantic space: The paper directly feeds time-series embeddings into the pre-trained PLM without introducing any explicit alignment constraint between the numerical and linguistic modalities. This raises concerns about whether the frozen PLM can effectively interpret unaligned numeric encodings, especially since no contrastive or projection-based objective is applied to bridge the representational gap. As a result, the semantic structure within the PLM may not correspond to the statistical dynamics of the time-series features, potentially limiting the PLM’s contribution during fusion.\n\n2. Limited interpretability of the correlation modeling process: While the paper proposes both a correlation extractor and PLM-based correlation layers to capture global and local dependencies across variables, the modeling results are not visually or quantitatively analyzed. \n\n3. Insufficient ablation to isolate the PLM branch’s contribution: The proposed Cross-Model Fusion integrates semantic correlations from the PLM with numerical representations from the time-series model. However, the paper lacks an ablation experiment isolating the PLM branch’s effect, which is essential to determine whether the semantic representations learned by the PLM genuinely enhance forecasting performance. Without such analysis, it is unclear whether the observed gains primarily come from the PLM, the time-series backbone, or their interaction. This omission weakens the causal interpretability of the architecture’s design claims."}, "questions": {"value": "1. Would it be beneficial to introduce an explicit alignment objective (e.g., contrastive loss or learned projection) to map time-series embeddings into the PLM’s semantic space? If the PLM remains largely frozen, how does it meaningfully process such unaligned numerical representations?\n\n2. Can the authors provide visualization or quantitative analysis (e.g., inter-channel correlation maps or attention weight distributions) to validate the correctness and interpretability of the extracted correlations?\n\n3. Could the authors include a control experiment where the PLM branch is removed or replaced with a lightweight MLP to confirm that the semantic correlations extracted by the PLM provide measurable improvements to the TS branch’s predictive accuracy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HormqW7qTF", "forum": "Ktd8Zus4G8", "replyto": "Ktd8Zus4G8", "signatures": ["ICLR.cc/2026/Conference/Submission18019/Reviewer_NQT5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18019/Reviewer_NQT5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18019/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761738088641, "cdate": 1761738088641, "tmdate": 1762927809691, "mdate": 1762927809691, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper works on time series forecasting (TSF) and presents CC-Time, a dual-branch framework integrating LLM and traditional TSF models. CC-Time addresses two core questions: which time series features PLMs can model, and whether PLMs alone suffice for TSF.\nCC-Time adopts cross-modality learning, which combines time series and text (that describe channels), to capture temporal dependencies and channel correlations. Further, it introduces cross-model fusion (CMF) block to adaptively integrate knowledge from both branches. Extensive experiments have been conducted to validate the effectiveness of proposed modules."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. It's reasonable to incorporate the ability of LLMs into traditional TSF models in a multimodal manner.\n2. It's interesting to use ChatGPT to describe each channel, making the essence and functionality of each channel more clear, which may help to better model channel-wise correlations and improve interpretability.\n3. The CMF block seems to be novel and reasonable.\n4. Extensive experiments have been conducted to validate the effectiveness of modules. Particularly, this paper works on full-data and few-shot settings to provide robust evaluation."}, "weaknesses": {"value": "1. A discussion between CC-Time and existing multimodal TSF methods (that also use both time series and textual data) is strongly recommended, which would make the contribution of this work more prominent.\n- What are the differences between the constructed textual input, in terms of both method and motivation.\n- Prompt length.\n- Why such textual input can make your multimodal data fusion unique (compared to existing methods like Time-LLM, TimeCMA).\n2. The computational cost of each module (particularly the attention-related modules), and efficiency analysis are recommended.\n3. In Table 3 and Appendix F.1, the reasons why introducing larger LLMs cannot further boost the performance of TSF is not clear.\n4. This paper captures channel-wise correlations near the input end, and TimeCMA puts similar-purpose module after data fusion (i.e., near the output end), an experiment (conducted under the same conditions) studying the positions of channel-wise correlation capturing is missing."}, "questions": {"value": "N.A."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "rwWCF5e5mx", "forum": "Ktd8Zus4G8", "replyto": "Ktd8Zus4G8", "signatures": ["ICLR.cc/2026/Conference/Submission18019/Reviewer_xBLS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18019/Reviewer_xBLS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18019/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761815355037, "cdate": 1761815355037, "tmdate": 1762927809161, "mdate": 1762927809161, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes CC-Time, a framework for time series forecasting that attempts to leverage Pre-trained Language Models (PLMs). The stated contributions are: 1) Cross-Modality learning, using time series data and corresponding textual descriptions (semantic and statistical) to model channel correlations; and 2) Cross-Model fusion, via a CMF Block, to integrate features from the PLM branch and a dedicated Time Series (TS) branch."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper attempts a novel cross-modal fusion approach, and the idea of using PLMs to process channel correlations is explored. The design of the Cross-Model Fusion (CMF) Block is architecturally complex, utilizing multiple attention mechanisms to integrate information from the two heterogeneous branches.\n\n2. Given the model's complexity, the authors have conducted numerous ablation studies. The experiments in Figure 3, Figure 9, and Appendix E attempt to demonstrate the necessity of the model's key components (though, as noted in the weaknesses, key ambiguities remain).\n\n3. The model reports SOTA or competitive results on multiple datasets. The inclusion of comparisons against time series Foundation Models in a few-shot setting (Section 4.2 and Table 11) is a relevant experimental point, but the validity of these results is questionable given the methodological flaws."}, "weaknesses": {"value": "1. **(Most Serious Issue) Dependency on Text Source and Generalizability**: The paper's primary methodological flaw is its dependency on an external LLM. While using an LLM to auto-generate text (Appendix A) solves the problem of missing text modalities in existing datasets, it builds a part of the model's performance on an uncontrolled, external black-box tool.\n\n   * **Concerns about Text Quality**: We are concerned about the quality of the LLM-generated text.\n   * **Concerns about Specific Datasets**: For a dataset like **Traffic** (with 862 channels), where channels represent sensors at different locations, can an LLM generate meaningful and **differentiated** descriptions for all 862 sensors? If the LLM just produces 862 copies of \"This is a traffic sensor,\" the cross-modal innovation becomes meaningless.\n   * **Question**: Could the authors provide examples of the (LLM-generated) text descriptions for several different channels from the **Traffic** dataset in their rebuttal?\n   * **Motivation**: Overall, the motivation behind this article is somewhat strange. It seems that the text was added simply to introduce multimodality, and the quality of such text information is questionable.\n\n\n2. **Source of Performance Gain: Semantics vs. Statistics**: Closely related to point 1, it is a reasonable inference that the performance gains may come more from the **\"Statistical Information\"** in the text description, rather than the \"Semantic Description\".\n\n   * For datasets like Traffic, if (as we suspect) the \"semantic descriptions\" for different channels are highly similar or generic, the primary source of information for the PLM branch to differentiate channels becomes the \"statistical information\".\n   * If this is the case, the novelty of this paper would be severely diminished, reducing the contribution to \"a method for fusing statistical priors as auxiliary features into a time series model,\" rather than cross-modal semantic fusion.\n\n3. **Ambiguous Ablation for Weakness #2**: **Appendix F.3 (Figure 9)** is critical for clarifying point 2, but its description is ambiguous.\n\n   * **Question**: Can the authors explicitly confirm whether the \"w/o Text\" condition refers to: (A) removing *both* the semantic description and the statistical information, or (B) removing *only* the semantic description but *retaining* the statistical information?\n   * This ambiguity also applies to the other experiments in that figure (\"Add Noise\", \"Random Text\"): are these interventions applied only to the semantic portion, or to both? Clarifying this is essential to evaluate the true contribution of \"semantics\".\n\n4. **Necessity of the PLM Auxiliary Loss**: The model only uses the output of the TS branch during inference (Section 3.4), meaning the PLM loss ($\\\\mathcal{L}\\_{plm}$) primarily functions as an auxiliary training objective.\n\n   * \\*\\*Appendix F.2 (Figure 8)\\*\\*tests the loss weight $\\\\lambda$ and finds $\\\\lambda=0.6$ to be optimal, which does suggest the loss is useful.\n   * **Question**: However, to clearly prove its \"necessity,\" the most critical ablation would be the result for $\\\\lambda = 0$ (i.e., completely removing this loss). Can the authors provide the experimental data for $\\\\lambda = 0$?\n\n5. **Weak Conclusion from CKA Analysis**: The CKA analysis in **Figure 5** is interesting, but the conclusion drawn is unconvincing.\n\n   * The authors find that the CKA value of CC-Time is intermediate between the two model classes (PLM-based and TS-specific) and therefrom infer that the model captures \"appropriate\" complex features.\n   * An intermediate CKA value is somewhat \"inevitable\" as the model is, by design, a hybrid (or average) of the two feature types. This result is not surprising.\n   * **Question**: The authors fail to provide a convincing analysis of the causal link between an intermediate CKA value and low error, beyond simple correlation. Why is being \"in the middle\" necessarily \"appropriate\" or \"superior\"? The current analysis reads more as a phenomenon-observation rather than a deep insight.\n\n6. **Misleading Terminology (\"Cross-Model\")**: The term \"Cross-Model\" is potentially misleading. In the community, this often implies the integration or interaction of multiple independent models (e.g., multiple expert PLMs). However, the paper's architecture involves only *one* PLM and *one* TS-specific model. Therefore, the fusion is more accurately a \"Cross-Paradigm\" (PLM vs. TS) fusion, not a \"Cross-Model\" fusion in the plural sense. The term inflates the architectural complexity."}, "questions": {"value": "See the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XrS6Ja7ogQ", "forum": "Ktd8Zus4G8", "replyto": "Ktd8Zus4G8", "signatures": ["ICLR.cc/2026/Conference/Submission18019/Reviewer_L1sA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18019/Reviewer_L1sA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18019/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761895070416, "cdate": 1761895070416, "tmdate": 1762927808735, "mdate": 1762927808735, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}