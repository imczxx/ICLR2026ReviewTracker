{"id": "B0W5XcWNSl", "number": 12858, "cdate": 1758210994168, "mdate": 1759897481156, "content": {"title": "Are We Merely Justifying Results ex Post Facto? Quantifying Explanatory Inversion in Post-Hoc Model Explanations", "abstract": "Post-hoc explanation methods provide interpretation by attributing predictions to input features. Natural explanations are expected to interpret how the inputs lead to the predictions. Thus, a fundamental question arises: Do these explanations unintentionally reverse the natural relationship between inputs and outputs? Specifically, are the explanations rationalizing predictions from the output rather than reflecting the true decision process? To investigate such explanatory inversion, we propose Inversion Quantification (IQ), a framework that quantifies the degree to which explanations rely on outputs and deviate from faithful input-output relationships. Using the framework, we demonstrate on synthetic datasets that widely used methods such as LIME and SHAP are prone to such inversion, particularly in the presence of spurious correlations, across tabular, image, and text domains. Finally, we propose Reproduce-by-Poking (RBP), a simple and model-agnostic enhancement to post-hoc explanation methods that integrates forward perturbation checks. We further show that, under the IQ framework, RBP theoretically guarantees the mitigation of explanatory inversion. Empirically, RBP can reduce inversion by 1.8% on average across iconic post-hoc explanation approaches and domains.", "tldr": "We identify and mitigate explanatory inversion, where explanations rely on outputs, not inputs, using a new quantification framework and robust enhancement method.", "keywords": ["Post-hoc Explanation"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b49ae62a388a609b4645da608c01e83a58ebbf5f.pdf", "supplementary_material": "/attachment/0563b29449e83fbf25e2d5840e14bb19e6b3401e.zip"}, "replies": [{"content": {"summary": {"value": "This paper examines whether common post-hoc explanation methods unintentionally invert the causal link between inputs and outputs - rationalizing predictions rather than reflecting true model reasoning. The authors propose Inversion Quantification (IQ), a framework that measures this effect via Reliance on Outputs (R) and Faithfulness (F), combined into an Inversion Score (IS). They also introduce Reproduce-by-Poking (RBP), a model-agnostic perturbation technique that stabilizes attributions and reduces inversion.\nThrough theoretical analysis and experiments on tabular, image, and text datasets, the authors show that explanatory inversion is widespread and that RBP reduces inversion by roughly 1.8% on average. The work exposes a key limitation of post-hoc explainers and offers a quantitative, general remedy."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The concept of explanatory inversion offers a fresh theoretical perspective on an underexplored failure mode of post-hoc explanations.\n\n- The IQ formulation is broadly applicable, combining existing intuitions of faithfulness and output dependence into a coherent, quantifiable metric.\n\n- Definitions and theorems (e.g., relating inversion score to ground-truth alignment) are clearly motivated and mathematically justified.\n\n- The proposed RBP method is conceptually intuitive and easily integrated with standard explanation tools.\n\n- Synthetic datasets and spurious feature injection tests convincingly demonstrate how inversion manifests and how RBP mitigates it.\n\n- Visuals effectively illustrate inversion phenomena, aiding reader understanding.\n\n- The inclusion of tabular, image, and text domains strengthens claims of generality."}, "weaknesses": {"value": "- There has been several definition of faithfulness metrics for feature attributions in literature [1,2,3,4,5]. It would be helpful to understand the motivation and justification for another faithfulness metric.\n\n- RBP's dependence on perturbations could be costly for large-scale models; runtime comparisons or mitigation strategies would strengthen the paper.\n\n- The evaluation remains primarily synthetic. More realistic, high-dimensional tasks would better validate generalizability.\n\n[1] Yoon, Jinsung, James Jordon, and Mihaela Van der Schaar. \"INVASE: Instance-wise variable selection using neural networks.\" International conference on learning representations. 2018.\n\n[2] Jethani, Neil, et al. \"Have we learned to explain?: How interpretability methods can learn to encode predictions in their interpretations.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2021.\n\n[3] Li, Xuhong, et al. \"M4: A Unified XAI Benchmark for Faithfulness Evaluation of Feature Attribution Methods across Metrics, Modalities, and Models.\" (2023).\n\n[4] Zhao, Zhixue, and Nikolaos Aletras. \"Incorporating Attribution Importance for Improving Faithfulness Metrics.\" The 61st Annual Meeting Of The Association For Computational Linguistics. 2023.\n\n[5] Puli, Aahlad, Nhi Nguyen, and Rajesh Ranganath. \"Explanations that reveal all through the deﬁnition of encoding.\" Advances in Neural Information Processing Systems 37 (2024): 99965-100006."}, "questions": {"value": "- What is the motivation for another faithfulness metric given existing metrics in the literature?\n- In line 171-172, why should the ideal explanation has Reliance on Outputs (R) equals to 0? Wouldn't it be possible that a completely faithful feature attribution $a$ correlated with output $M(x)$, specifically in the case where there is no spurious feature? Do we expect such an feature attribution to have 0 Reliance on Outputs?\n- Could the authors provide more intuition of what specific Inversion Score values means in practice? For example, what ranges might correspond to acceptable or severe inversion?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wylHg8uzGp", "forum": "B0W5XcWNSl", "replyto": "B0W5XcWNSl", "signatures": ["ICLR.cc/2026/Conference/Submission12858/Reviewer_evSj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12858/Reviewer_evSj"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12858/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761314520392, "cdate": 1761314520392, "tmdate": 1762923652141, "mdate": 1762923652141, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the potential issue of “explanatory inversion” in post-hoc explanation methods (e.g., LIME, SHAP, IG), where explanations may rely more on model outputs than on the true input–output causal relationships. The authors propose the Inversion Quantification (IQ) framework to measure the degree of output reliance (R) and explanation faithfulness (F), defining a combined metric Inversion Score (IS). They also introduce Reproduce-by-Poking (RBP), which incorporates forward perturbation checks to mitigate explanatory inversion and enhance explanation stability."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "S1: The paper introduces the concept of “explanatory inversion,” highlighting a previously overlooked issue of reverse dependence in post-hoc explanations. The problem definition is novel and meaningful.\n\nS2: The proposed RBP method is simple and generalizable—it enhances the robustness of existing explanation methods through additional perturbation checks and can be applied across various interpretability frameworks.\n\nS3: The paper not only formalizes the IQ framework but also provides theoretical results (e.g., the upper-bound relationship between IS and alignment) with corresponding proofs."}, "weaknesses": {"value": "W1: The methodological novelty is somewhat limited. The RBP approach is conceptually similar to existing stability or robustness verification techniques, such as SmoothGrad.\n\nW2: The theoretical section is somewhat verbose; some proofs (especially Theorem 3.7) are overly formal and lack intuitive interpretation, which could be simplified.\n\nW3: The definitions in Equations (2), (3), and (4) should be clarified (e.g., how Δa and ΔM are computed and how baselines are chosen). The physical meaning and tuning guidelines for the RBP hyperparameter λ should also be better explained.\n\nW4: Several sections are lengthy and repetitive (particularly Section 3), which affects readability."}, "questions": {"value": "The paper defines the Reliance on Outputs (R) and Faithfulness (F) metrics using Δa and ΔM, but the procedures for computing these quantities are somewhat unclear. How exactly are the perturbations applied (e.g., additive Gaussian noise, feature masking, or sampling-based methods)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dbeuHneMuk", "forum": "B0W5XcWNSl", "replyto": "B0W5XcWNSl", "signatures": ["ICLR.cc/2026/Conference/Submission12858/Reviewer_Y1ex"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12858/Reviewer_Y1ex"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12858/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761917868915, "cdate": 1761917868915, "tmdate": 1762923651458, "mdate": 1762923651458, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates *explanatory inversion* -- the tendency of post-hoc explanation methods (e.g., LIME, SHAP) to rationalize model outputs instead of faithfully reflecting input–output relationships. The authors propose *Inversion Quantification (IQ)*, a framework that measures the degree to which explanations depend on model outputs rather than inputs, and introduce *Reproduce-by-Poking (RBP)*, a perturbation-based enhancement aimed at mitigating inversion. Through synthetic datasets across tabular, image, and text domains, they demonstrate that standard explanation methods are susceptible to inversion, while RBP reduces such effects empirically."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The abstract and research question are well-motivated.  \n- Presents a interesting framing of an underexplored failure mode in explainability--\"explanatory inversion\"--which complements prior work on faithfulness, robustness, and sensitivity.  \n- Provides formal definitions (Def. 3.1) and connects them to measurable quantities (reliance on outputs and faithfulness), clarifying conceptual distinctions from existing metrics.  \n- Highlights conceptual novelty and introduces the IQ framework as a unifying diagnostic for when explanations are output-driven.  \n- Results are explored across modalities (tabular, image, text) and show robustness of RBP in reducing inversion effects."}, "weaknesses": {"value": "- Fig. 1 illustrates general issues with explanations but fails to convey the causal intuition of *how* inversion arises.  \n- Several references (L94–L100) are outdated (average > 5 years); the paper omits discussion of more recent reliability metrics and benchmarks addressing similar concerns.  \n- Experimental validation is limited to synthetic datasets with simple spurious-feature injections (L335–L360); it remains unclear whether explanatory inversion occurs or can be mitigated on real-world tasks.  \n- The comparison of IQ to other metrics (Appendix C) seems superficial--unclear whether IQ is derivable from, or orthogonal to, existing measures.  \n- RBP’s relation to sensitivity analysis (Sec. 4) is not well distinguished; the novelty beyond forward perturbation checks is limited.  \n- Table 1 is dense and small, with several metrics; the main body could highlight key takeaways and move detailed results to the appendix.  \n- Overall, the contribution is conceptual and diagnostic rather than algorithmic, making it more suitable as a *position or perspective paper* than a technical contribution."}, "questions": {"value": "- Can IQ be theoretically linked to or derived from existing measures such as sensitivity or infidelity in certain settings?  \n- How does RBP differ formally from standard sensitivity analysis or robustness checks?  \n- Could the authors demonstrate explanatory inversion on real-world datasets or pretrained models to establish external validity?  \n- Why wasn’t Definition 3.1 extended to a conditional comparison framework (e.g., attribution distributions given M(x) vs. unconditional)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SHM6LykU2K", "forum": "B0W5XcWNSl", "replyto": "B0W5XcWNSl", "signatures": ["ICLR.cc/2026/Conference/Submission12858/Reviewer_4UbW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12858/Reviewer_4UbW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12858/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761935273713, "cdate": 1761935273713, "tmdate": 1762923651213, "mdate": 1762923651213, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In the context of post hoc explanation models, the authors raise an important question -do these explanations unintentionally reverse the natural relationship between inputs and outputs? To investigate such explanatory inversion, we propose Inversion Quantification (IQ), a framework that quantifies the degree to which explanations rely on outputs and deviate from faithful input-output rela- tionships. The proposed method works in conjunction with existing methods, and it is not a novel XAI technique by itself."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses an important aspect of the XAI model relying heavily on predictions and not the relationship between input and the output."}, "weaknesses": {"value": "1. Clarity of the problem statement: The hypothesis in the problem statement is grounded in a post-hoc explanation method that over-relies on the model’s output in generating attributions, rather than accurately reflecting the relationship between inputs and predictions- the authors need to establish this problem with concrete references and examples. Methods such as LIME fit a local surrogate to approximate the decision boundary of black box model, indicating that the decision process is considered when generating explanations. Authors should present clear counter examples where explanations from LIME, SHAP, IG or similar methods largely mirror the output label rather than the underlying decision rationale, and by citing representative studies that exhibit this mismatch. Explain why those cases arise and how the proposed approach detects or remedies the gap.\n2. If the core issue is incorrect explanations, the authors could have considered uncertainty based explanation approaches such as “Reliable Post Hoc Explanations” (BayesLIME/BayesSHAP)and “Select Wisely and Explain”(UnRAVEL) as they avoid/reduce unstable explanations, and make sure the explanation is evidence backed, as indicated by the model.\n3. In section 3 there are multiple definitions for a and epsilon, authors need to set a fixed notation for better understanding.\n4. The Related Work omits several recent post hoc XAI methods such as GLIME, UnRAVEL, Reliable Post Hoc Explanations, RISE, S-CFE etc., and modern faithfulness tests such as ROAR remove and retrain, randomized masking, and the Infidelity and Sensitivity matrices. These methods offer appropriate baselines and validation matrices for the proposed inversion score and for RBP, and hence they are relevant. \n5. The definition for inversion score, combines Reliability R and Faithfulness F but, apart from the choice of p, the paper offers no clear intuition or proof for this additive combination, which makes it hard to interpret. In addition, the paper does not evaluate explanations with metrics such as Infidelity. Infidelity captures the expected mismatch between an explanation and the model response under principled perturbations, and hence, including these would help diagnose failure modes that R and F may miss.\n6. The paper does not state how perturbations are generated for RBP, whether they are random, or guided. Moreover, there is no mathematical proof or theoretical argument showing that RBP reflects the model’s decision process rather than merely its outputs, leaving the claim of decision process dependence unfulfilled.\n7. The main results rely only on synthetic datasets. Please include standard benchmark datasets such as Adult Income, CIFAR, ERASER etc. that are used with baselines such as LIME, SHAP, and Integrated Gradients, and demonstrate that RBP delivers more faithful explanations against these established methods. Also include evaluation matrices such as ROAR (RemOve And Retrain), Infidelity and Sensitivity. This will show that the claimed gains persist under widely accepted datasets and are not just for synthetic settings.\n8. In Fig. 5c, the number of perturbations vary only from 1 to 5, with a small budget, the claim that the IS measure is stable is not reliable. Please show convergence of IS as the number of perturbations increase. In Figure 5d, authors refer to a perturbation noise\nmagnitude, but the paper does not define this quantity. Please specify this so that the\nresults are interpretable and reproducible.\n9. In Section 5.5 the authors claim real world generalisation, but two gaps remain. The evidence is limited to image datasets and does not cover other domains. Moreover, the section does not actually apply the proposed RBP method to the shown examples, which leaves the practical behavior of RBP unquantified."}, "questions": {"value": "The main issues remain lack of novelty and point number 5 above. The authors must provide clarification regarding the above mentioned points."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DexhkYp5Vv", "forum": "B0W5XcWNSl", "replyto": "B0W5XcWNSl", "signatures": ["ICLR.cc/2026/Conference/Submission12858/Reviewer_RVJD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12858/Reviewer_RVJD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12858/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762079606940, "cdate": 1762079606940, "tmdate": 1762923650763, "mdate": 1762923650763, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}