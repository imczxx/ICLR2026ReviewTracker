{"id": "vLFJ2piNO6", "number": 20028, "cdate": 1758301678472, "mdate": 1759897005656, "content": {"title": "NEOL: REWARD-GATED ONLINE PLASTICITY FOR SCALABLE NEUROEVOLUTION", "abstract": "NeuroEvolution of Augmenting Topologies (NEAT) excels at discovering neural architectures and weights for control tasks (Stanley & Miikkulainen, 2002a).However, direct-encoding forces evolution to discover each connection strength individually; in high-dimensional weight spaces, this yields weak credit assignment and poor scaling on large continuous-control problems (Stanley et al., 2009; Peng et al., 2018). We propose NeuroEvolutionary Online Learning (NEOL), which decouples learning signals: the outer loop uses NEAT for topology search, while an inner, reward-modulated local plasticity rule (Hebbian, Oja, or BCM (Hebb, 1949; Oja, 1982; Bienenstock et al., 1982)) adapts synaptic weights online within episodes. Under fixed interaction budgets and multiple seeds across four standard control benchmarks spanning discrete and continuous action spaces, NEOL achieves higher final returns, tighter variability, and better sample efficiency than pure NEAT; gains are most pronounced in continuous control. These improvements are statistically significant (Wilcoxon rank-sum tests), and ablations indicate that benefits persist even when standard genetic weight mutation is reduced or disabled, evidencing a division of labour between structural evolution and online synaptic credit assignment. A simple, gradient-free separation of\ntopology search and reward-gated online plasticity reliably boosts performance and robustness, offering a practical template for linking neuroevolution with online learning and a scalable path toward more adaptive neuroevolutionary agents.", "tldr": "", "keywords": ["NeuroEvolution", "Online Learning", "Synaptic Plasticity", "Optimisation", "Evolutionary Algorithm"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/36e01aabbb74314c8bb6f0fce44f06c33abc6c1d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a method for simultaneously evolving neural network topology and synaptic weights using an outer-loop/inner-loop framework, and evaluates it on four benchmark tasks."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- The idea of co-evolving topology and synaptic weights in a nested-loop framework is conceptually interesting and, to the best of my knowledge, relatively underexplored in the current literature."}, "weaknesses": {"value": "1. **Misalignment of the Outer-Loop/Inner-Loop Framework:**  \nWhile the separation of topology evolution (outer loop) and weight adaptation (inner loop) is structurally reasonable, the experimental design raises concerns about the authors’ understanding of the fundamental purpose of such a nested-loop architecture. Typically, the outer loop is expected to optimize meta-parameters (e.g., network topology, learning rules, or plasticity coefficients) across a *distribution* of tasks, so that the inner loop can generalize to *new, related tasks* using the optimized meta-knowledge. However, this paper applies the framework to a *single, stationary task*, which undermines the very rationale for using an outer-loop/inner-loop structure. This design choice appears conceptually flawed and limits the significance of the results.\n\n2. **Over-Simplification of Synaptic Plasticity:**  \nThe paper adopts a *fixed, homogeneous* plasticity rule (i.e., a single, hand-tuned learning rate η) across all synapses. This is a significant oversimplification. A core objective in many prior works is to *evolve* plasticity rules or their hyperparameters (e.g., learning rates, modulatory signals) in the outer loop, enabling task-specific adaptation. The use of a uniform, human-specified plasticity coefficient not only reduces biological plausibility but also limits the adaptability and expressiveness of the model. The contribution thus risks appearing as an ad-hoc combination of topology evolution and plasticity (i.e., “A+B”) without a principled integration.\n\n3. **Limited and Weak Baselines:**  \n   The empirical evaluation lacks breadth and depth. Several relevant and recent works are omitted, particularly those that integrate plasticity with meta-learning, recurrent memory, or neuromodulation. For instance:\n   - [1]: Growing with Experience: Growing Neural Networks in Deep Reinforcement Learning\n   - [2]: Neuroplastic Expansion in Deep Reinforcement Learning\n   - [3] Soltoggio, Andrea, et al. \"Evolutionary advantages of neuromodulated plasticity in dynamic, reward-based scenarios.\" Proceedings of the 11th international conference on artificial life (Alife XI). MIT Press, 2008.\n   - [4] Mishra, Nikhil, et al. \"A Simple Neural Attentive Meta-Learner.\" International Conference on Learning Representations. 2018.\n   - [5] Joachim Winther Pedersen and Sebastian Risi. Evolving and merging hebbian learning rules: increasing generalization by decreasing the number of rules. In Proceedings of the Genetic and Evolutionary Computation Conference, pp. 892–900, 2021.\n   - [6] Wang, Fan, et al. \"Evolving Decomposed Plasticity Rules for Information-Bottlenecked Meta-Learning.\" Transactions on Machine Learning Research.\n\n4. The paper requires substantial revision for clarity and precision. For example:\n   - The definition of “M” as “a total number of samples or a total number of interactions with an environment Env until time horizon T” is ambiguous. Please clarify whether M refers to episodes, steps, or transitions, and whether it is fixed or task-dependent.\n   - The term “credit assignment” is used repeatedly (e.g., “reward-gated and behaviorally relevant credit assignment”), but its technical meaning is unclear in context. Is this referring to temporal credit assignment in RL, or to a biologically inspired learning signal? If the latter, please explicitly connect it to the plasticity rule and justify its relevance."}, "questions": {"value": "See the weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7GsNQIPGWx", "forum": "vLFJ2piNO6", "replyto": "vLFJ2piNO6", "signatures": ["ICLR.cc/2026/Conference/Submission20028/Reviewer_bgzr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20028/Reviewer_bgzr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20028/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761536572545, "cdate": 1761536572545, "tmdate": 1762932926138, "mdate": 1762932926138, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose NeuroEvolutionary Online Learning (NEOL), a hybrid framework that explicitly decouples structural evolution from weight adaptation. In NEOL, an outer loop employs standard NEAT for topological search, while a novel inner loop performs online, within-episode weight adaptation using reward-modulated local synaptic plasticity rules (specifically Hebbian, Oja's, and BCM). The method is evaluated on four classic control benchmarks (CartPole, LunarLander, BipedalWalker, Hopper), comparing the NEOL variants against a standard NEAT baseline. The results demonstrate that NEOL achieves statistically significant improvements in final return, sample efficiency (as measured by a custom SCORE metric), and solution robustness (lower variance), with gains being most pronounced in the continuous control tasks."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The experimental comparison to NEAT is thorough. The use of 30 random seeds, multiple benchmarks spanning discrete and continuous action spaces, and appropriate statistical testing (Wilcoxon rank-sum) provides strong evidence for the central claim: that NEOL is a superior alternative to standard NEAT."}, "weaknesses": {"value": "- The paper's motivation rests on NEAT's poor scaling, a problem that other methods (e.g., HyperNEAT, NEAT-PGS, modern Evolution Strategies) also purport to solve. More importantly, to position NEOL as a practical and relevant algorithm, it must be compared against standard gradient-based RL algorithms (e.g., PPO, SAC) or at least modern gradient-free methods (e.g., Salimans et al., 2017) on the same continuous control tasks. Without this context, it is impossible to know if NEOL is a competitive learning algorithm in 2026 or merely a better version of NEAT.\n\n- While the specific implementation within NEAT may be novel, the high-level concept of a two-timescale system (outer-loop evolution, inner-loop plasticity/learning) is a foundational concept in the field (e.g., the Baldwin effect, and more directly, the extensive work on evolving plastic ANNs cited by the authors, such as Soltoggio et al., 2008, and Najarro & Risi, 2020). The plasticity rules (Hebb, Oja, BCM) and their reward-modulation (Frémaux & Gerstner, 2016) are also pre-existing. The paper's contribution is more an effective engineering integration and rigorous comparison rather than a fundamental mechanistic breakthrough"}, "questions": {"value": "1. The paper states it primarily uses a Lamarckian scheme (WRITE_BACK=True, Line 309), where adapted weights are inherited. An ablation (WRITE_BACK=False) is mentioned but no data is presented. How critical is this Lamarckian property? Does a purely Darwinian approach (where plasticity is only for evaluation fitness, but weights are not written back to the genome) also achieve significant gains over NEAT? This is a key mechanistic question.\n\n2. How does NEOL's final performance and, critically, its sample efficiency (in wall-clock time or total environment steps) compare to well-tuned implementations of PPO or SAC on the Hopper-v3 and BipedalWalker-v3 tasks? This context is essential for positioning the work.\n\n3. Could you clarify the \"fixed total interaction budget B\" (Line 317)? The SCORE metric (Eq 4) is an AUC, which is dependent on the total time horizon $T$ (or total samples $M$). How was $B$ used to normalize runs with different population sizes (e.g., $P=50$ vs. $P=300$)? Does a larger population run for fewer generations to maintain the same $B$? This is unclear."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "l3h5lLmrHw", "forum": "vLFJ2piNO6", "replyto": "vLFJ2piNO6", "signatures": ["ICLR.cc/2026/Conference/Submission20028/Reviewer_q1Gg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20028/Reviewer_q1Gg"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20028/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761905499313, "cdate": 1761905499313, "tmdate": 1762932925331, "mdate": 1762932925331, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces NEOL, a hybrid framework that integrates reward-modulated local plasticity into the NEAT algorithm. The central idea is to decouple topology evolution (handled by NEAT) from weight adaptation (handled by fixed online learning rules such as Hebbian, Oja, or BCM).\n \nDuring each episode, synaptic weights adapt online according to a biologically inspired rule gated by a reward signal. After the episode, cumulative reward is used as the fitness signal for evolution. The authors show that NEOL improves convergence speed, fitness stability, and final performance over standard NEAT across several classic control benchmarks (CartPole, MountainCar, Acrobot, LunarLander)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper addresses an important research direction, combining evolution and life-time learning \n\n2.The experiments demonstrate faster and more stable convergence, even in environments that do not require lifetime adaptation. The authors provide reasonable mechanistic explanations (reward smoothing and intrinsic regularization from Oja/BCM rules).\n\n3. The approach could easily be applied to other neuroevolution algorithms beyond NEAT."}, "weaknesses": {"value": "1. Evaluation is restricted to low-dimensional control tasks  that do not require within-lifetime adaptation. This makes it difficult to assess NEOL’s claimed advantage as an “online learning” or “adaptive” system. What about the T-maze or something GoalDirection HalfCheetah? \n2. No separate hyperparameter tuning between NEAT and NEOL. Both methods use the same NEAT settings, except for additional plasticity parameters. \n3. NEOL is compared only to NEAT and an ablated NEAT (η=0). Missing are comparisons to e.g. Najarro & Risi (2020) and other meta-plasticity or evolutionary meta-learning methods. \n4. Limited novelty and missing early work. Other approaches have already combined NEAT with plasticity and are not mentioned, e.g. \"Evolving adaptive neural networks with and without adaptive synapses\" by Stanley et al."}, "questions": {"value": "1. Have you attempted any environments requiring within-lifetime adaptation (e.g., GoalDirection Cheetah, T-Maze)?\n2. How is the approach different to adaptive NEAT by Stanley et al?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DgohVwdlzo", "forum": "vLFJ2piNO6", "replyto": "vLFJ2piNO6", "signatures": ["ICLR.cc/2026/Conference/Submission20028/Reviewer_XEuE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20028/Reviewer_XEuE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20028/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762000823241, "cdate": 1762000823241, "tmdate": 1762932924476, "mdate": 1762932924476, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose NEOL, a Neuroevolution approach that combines NEAT for evolving topologies of neural network architectures with online learning mechanims implemented via Hebbian learning (or similar). The authors show that this approach surpasses NEAT in performance across several locomotion task in an RL setting."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The approach is well motivated and the authors explain it clearly. The experimental setting is sensible with a collection of the popular RL tasks serving as way to compare both approaches."}, "weaknesses": {"value": "First, the claim feels very weak, but more importantly, it has already been done (https://www.cs.utexas.edu/~nn/downloads/papers/stanley.cec03.pdf). The authors need to explain what is new regarding their approach and why this is interesting compared to previous work.\n\nHowever, even if it was a completely novel approach, it is not clear to me that it is that surprising. Under a Lamarckian setting, if the changes in model weight transfer to offspring during evolution, then is it really that surprising that NEOL surpasses NEAT? That's the minimum I would expect, unless I am misunderstanding something. The authors claim that they include this control but don't show it."}, "questions": {"value": "1. How does this compare to standard RL. Is there a particular setting where this is better? I am happy to also disregard this question if the authors give me some justification (e.g. they wish to explore more biologically plausible models), but they they need to give me a biologically interesting question they wish to answer. Currently there is a biological inspiration, but no particular question they wish to answer.\n2. How much of the learning is driven by topological changes? Do models become deeper for example? There is currently no analysis of how the model is driving performance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DtGLGVAMxC", "forum": "vLFJ2piNO6", "replyto": "vLFJ2piNO6", "signatures": ["ICLR.cc/2026/Conference/Submission20028/Reviewer_w2fR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20028/Reviewer_w2fR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20028/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762021886635, "cdate": 1762021886635, "tmdate": 1762932923685, "mdate": 1762932923685, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}