{"id": "KXJ5TU1q7B", "number": 8120, "cdate": 1758065728649, "mdate": 1763104296236, "content": {"title": "CoLaSplat: Compact Language 3D Gaussian Splatting", "abstract": "Language 3D Gaussian Splatting (3DGS) has exhibited promising advancements in open-vocabulary 3D scene understanding, incorporating semantic features from pretrained vision-language models into Gaussians to encode the semantic information of a scene. However, language-embedded 3DGS suffers from high computational and storage costs due to the massive number of Gaussians and the extra high-dimensional semantic attributes, which hinder its practical application. Existing compression methods primarily reduce 3DGS model redundancy through pruning or quantization, which can be sequentially applied to obtain a highly compressed language-embedded 3DGS model as a straightforward solution. However, all the existing approaches are not designed for compressing language 3DGS, where rich semantic features are ignored during the compression stages, leading to severe semantic information loss and significantly degraded scene understanding performance. Furthermore, the disjoint nature of the pruning and quantization stages results in lower rendering quality. To address these issues, we propose CoLaSplat, a unified compression framework for compact language 3DGS. CoLaSplat formulates semantic learning, sparsification, and vector quantization as a single optimization problem, constrained by the number of Gaussian primitives and vector quantization objective, seamlessly integrating the optimization procedure into the training process and incorporating language embeddings. To solve the unified optimization problem, we develop an efficient primal-dual optimization scheme by solving their associated subproblems and updating the variables separately, progressively compacting the model while preserving semantic and RGB rendering fidelity. Moreover, we theoretically analyze the convergence and stability of the proposed framework. Extensive experiments on 3D semantic segmentation and object localization demonstrate that our proposed CoLaSplat brings substantial efficiency gains while maintaining high task performance. Specifically, CoLaSplat achieves up to $15\\times$ model size reduction, $147\\times$ faster inference, and $6.7\\times$ lower memory usage.", "tldr": "A unified framework for training and compressing language 3DGS models, producing highly compact and semantically accurate representations.", "keywords": ["Language 3D Gaussian Splatting", "3DGS Compression", "Scene Understanding", "Open Vocabulary Querying"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/bb09c3be064d43f1edc87f8a86212db502ee2751.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes CoLaSplat, a unified compression framework for language-embedded 3D Gaussian Splatting (3DGS). Instead of applying pruning and quantization as separate post-hoc stages, the method formulates semantic learning + sparsification + vector quantization as a single constrained optimization and solves it with a four-step primal‚Äìdual scheme (primal update, sparsification via cardinality projection, k-means‚Äìstyle vector quantization, dual update)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is well written and easy to follow. \n2. The method itself is pretty simple yet efficient. \n3. This paper is the first paper working on the language Gaussian Splatting compression, and got the state of the art results. \n4. The paper gives a pretty comprehensive mathematical formuilation of the optimization process. Convergence reasoning provided in Appendix C.\n5. Thanks for providing a code and show me what is the main logic in the code. This really helps me to understand the paper."}, "weaknesses": {"value": "1. Results are on LERF and 3D-OVS; both are useful but relatively small. Adding more diverse scenes (e.g., indoor/outdoor mixes, cluttered small-object scenes) would better stress pruning effects on fine geometry/rare semantics. Please refer to SceneSplat [1] and SceneSplat++ [2] for more language-embeded 3dgs data.\n\n2. Baseline results on 3D-OVS is pretty outdated. FMGS [3], LUDVIS [4], OccamLGS [5], and SceneSplat [1] are having better results now. LangSplat also has a V2. Can you please include the recent baselines? \n\n3. The whole idea is pretty similar in 3DGS compression series works. For example, the K-means codebook is introduced in CompGS [6],  SUNDAE is pruning [7] and there's a lot of other methods in this field as well. I won't list them all. I did notice that author mentioned these methods in literature. However, what if you use these methods directly on the language 3DGS? This work seems to work on LangSplat like idea, which is per-gaussian language feature. And these 3dgs compression methods, like k-means vector quantization, or any other quantization could be easily added to language features, the geometry-based pruning or opacity-based pruning can be also easily applied. But author has no discussion what will happen with simply applying these method. \n\n4. I didn't totally understand what is card(o) here and the meaning of cardinality of opacities. And what is the obstacle to make card(o) differentiable? What is this sparsity constraint different from directly pruning gaussians with high opacity? \n\n5. I am very happy to see that in this community that someone introduces dynamic system and optimal control into 3DGS. However, from the Sec 4.2, this method seems to be applicable to any kind of gaussian splatting instead of language gaussian splatting. I didn't see any language-specific design, as opacity is treated as an important term and all of the other terms including gaussian parameters and language features are treated same. \n\n6. Training LangSplat from my experience is pretty hard. Can you also report training time? \n\n7. Thanks for providing the code. However, I cannot find the provided checkpoint mentioned in README.md. \n\n[1] SceneSplat: Gaussian Splatting-based Scene Understanding With Vision-Language Pretraining. \n[2] SceneSplat++: A Large Dataset and Comprehensive Benchmark for Language Gaussian Splatting.\n[3] FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding\n[4] LUDVIG: Learning-Free Uplifting of 2D Visual Features to Gaussian Splatting Scenes\n[5] Occam's LGS: An Efficient Approach for Language Gaussian Splatting\n[6] CompGS: Smaller and Faster Gaussian Splatting with Vector Quantization\n[7] SUNDAE: Spectrally Pruned Gaussian Fields with Neural Compensation"}, "questions": {"value": "1. Can you please specify how each part of the optimization affecting the results? I can understand that each part is important in the ablation study. But for each part, I can find some examples in compressed 3dgs paper (mentioned in the weaknees part) that have some easy implementation. Can you add a comparison of what will happen if you directly adopt those techniques? \n2. Can you also compare with other 3DGS compression methods? Like directly apply your method on 3DGS, or 3DGS with inverse rendering features? \n3. Other questions are already in the weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "WmpsJLvKUV", "forum": "KXJ5TU1q7B", "replyto": "KXJ5TU1q7B", "signatures": ["ICLR.cc/2026/Conference/Submission8120/Reviewer_8x7N"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8120/Reviewer_8x7N"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8120/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761408957856, "cdate": 1761408957856, "tmdate": 1762920098765, "mdate": 1762920098765, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "P21pfpd2f9", "forum": "KXJ5TU1q7B", "replyto": "KXJ5TU1q7B", "signatures": ["ICLR.cc/2026/Conference/Submission8120/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8120/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763104295539, "cdate": 1763104295539, "tmdate": 1763104295539, "mdate": 1763104295539, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a method for a language-embedded 3D Gaussian Splatting. Author observed that prior work raising memory concern for 3DGS or semantic field but compression for 3DGS geometry/appearance and for language features has largely been developed separately. Authors argue that these independent techniques are not optimal for language-embedded 3DGS and motivate a unified compression approach tailored to the joint representation. The main idea is a compression framework that considers the full characteristics of language-embedded 3DGS. They propose an iterative primal‚Äìdual optimization scheme and provide mathematical justification for its advantages in the target setting. On standard benchmarks, the authors claim that the method achieved notable gains in memory footprint and rendering speed."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Writing quality: Clear exposition.\n- Mathematical development: The derivations are well structured and easy to follow."}, "weaknesses": {"value": "**Baselines may be too weak** \n- If the claim is that prior compressions are not suitable for language-embedded 3DGS, then the minimum baselines should include:\n\n  - A 3DGS compression method + a separate language-feature compression method combined together.\n\n  - or at least, A LangSplat-style setup (pretrained 3DGS + fitted language embeddings) compared against your unified compression while updating only the language embeddings on top of a **compressed 3DGS**.\n- These would better test whether the unified approach offers intrinsic advantages over ‚Äúseparate compressions.‚Äù\n\n**Experimental explanations needed** \n- Task mismatch with OpenGaussian.\n\n  - OpenGaussian focuses on 3D activations, so a direct comparison to your Section 2 setup seems odd; please clarify evaluation alignment.\n- PSNR discrepancy across LangSplat vs. OpenGaussian.\n\n  - As far as I understand both methods are just for attaching language embeddings to the 3DGS. In this case, 3DGS itself should remains the same why do PSNR values differ? Please explain the training/inference protocols that lead to this gap.\n\n**Minor points**\n- Consider a related-work discussion vs. Dr. Splat and ICCV CF^2, which also touch on efficiency/representation trade-offs.\n- Line 391: You mention selecting an appropriate Œ∫; how is this value determined in practice?\n- Training details : It is stated that joint and alternating optimization are repeated every 50 steps‚Äîdoes this mean 40,000 base steps with an additional 10,000 steps every 50 iterations, or something else? Please clarify the schedule precisely.\n- Sparsification vs. densification: If both run during training, won‚Äôt they conflict? How does interleaving them mid-training compare to applying sparsification post-training on a fixed model?"}, "questions": {"value": "Addressed within the Weaknesses and Minor points above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "oxLnISROPZ", "forum": "KXJ5TU1q7B", "replyto": "KXJ5TU1q7B", "signatures": ["ICLR.cc/2026/Conference/Submission8120/Reviewer_CXiq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8120/Reviewer_CXiq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8120/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761832855512, "cdate": 1761832855512, "tmdate": 1762920098431, "mdate": 1762920098431, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an algorithm for learning language embeddings on top of 3D Gaussian representation. While the previous studies often takes two training stages, one for optimizing 3D Gaussians and the other for embedding language features, the paper merges these steps into a single optimization step."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "First of all, this paper produces a promising result in reduced model size, faster inference, and low memory usage. By optimizing 3D Gaussian by minimizing the RGB rendering loss as well as proposed losses, this paper remarkably prunes out the redundant Gaussians, which I believe the reason for the efficiency of this paper.\n\nWhile the authors claim that the 'co-optimization of semantic learning, sparsification, and vector quantization' are novel, but I cannot clearly catch its novelty. I will describe my observation in the next section."}, "weaknesses": {"value": "Overall, the authors put lots of efforts on description of the single optimization strategy. However, I cannot clearly catch the overall training pipeline (__Q3__) due to lots of missing details (__Q3__, __Q2__, __W3__). Moreover the experiment setup is problematic (__W1__, __W3__), and I do want to know about the theoretical necessity of the co-optimization beyond the experimental / empirical results (__W2__).\n\n__W1. Unfair comparison__  \nThe comparison presented in the submission appears unfair. Prior works such as LangSplat and OpenGaussian primarily focus on designing better mechanisms for embedding CLIP features into 3D Gaussians. For example, LangSplat employs an autoencoder to compress 512-D CLIP features, while OpenGaussian introduces a codebook-based embedding mechanism.\n\nIn contrast, the proposed method introduces a sparsification strategy that prunes redundant Gaussians for the target task. While this may indeed be a novel contribution, the paper lacks fair baseline comparisons to isolate the benefit of this sparsification. Specifically, a stronger evaluation would include variants such as 3DGS + existing Gaussian pruning methods + LangSplat/OpenGaussian, since prior works do not incorporate pruning for open-vocabulary 3D scene understanding. Without such baselines, it is difficult to attribute performance gains solely to the unified optimization framework.\n\nThis issue becomes more critical because the abstract explicitly highlights model size reduction and memory efficiency as key contributions. Therefore, comparisons with fair pruning-augmented baselines are essential.\n\n__W2 Why unified / single optimization is necessary?__  \nWhile the paper claims novelty by unifying semantic learning, sparsification, and vector quantization into a single optimization step, the motivation for this unification is unclear.\n\n_W2-1 What is the benefit of co-optimization?_  \nIf the unified optimization substantially reduces overall training time or improves convergence efficiency, such results should be clearly reported. However, no experiments demonstrate improvements in training speed or optimization stability.\n\nFurthermore, one could sequentially apply pruning and quantization to existing methods such as LangSplat or OpenGaussian. This sequential approach would also achieve model-size and memory improvements, raising the question: Why is a unified optimization scheme fundamentally better?\nA direct comparison between: __Unified optimization (proposed) vs Sequential pipeline (prior methods + pruning/quantization)__ would help justify the methodological design. In addition to empirical results, a theoretical explanation supporting the necessity of unification would strengthen the contribution.\n\n_W-2 Why optimize Gaussian parameters from scratch?_  \nUnlike previous language-3DGS works that rely on pre-optimized 3DGS Gaussians (following Kerbl et al.), this paper optimizes Gaussian parameters from scratch, jointly minimizing rendering and semantic losses. This appears to be motivated by the need to prune Gaussians during training.\n\nHowever, the sparsification update described in Section 4.2 can also be applied on top of pre-optimized Gaussians. If my understanding is incorrect, clarification is needed.\n\nAs written, the current setup mixes 3DGS training efficiency with open-vocabulary semantic alignment, complicating direct comparison with existing methods. It would be more convincing if the method were also evaluated starting from pre-optimized 3DGS, consistent with LangSplat and OpenGaussian.\n\n__W3 Missing details and insufficient analysis__  \nThe paper states in line 191 that an autoencoder is used to compress 512-D CLIP embeddings, similar to LangSplat. However, the dimensionality of the compressed embeddings is not provided. This information is critical for understanding memory savings and representation quality.\n\nAdditionally, the proposed vector quantization strategy resembles the codebook training in OpenGaussian. Given that both methods employ similar training objectives for quantization/codebook learning, it remains unclear whether the performance improvements stem primarily from the unified optimization framework or other factors. More ablation or diagnostic experiments‚Äîparticularly comparing the codebook quality between this paper and OpenGaussian‚Äîwould help clarify this point.\n\n__W4. Misleading statement__  \nIn Lines 19-21, _\"However, all the existing approaches are not designed for compressing language 3DGS, where rich semantic features are ignored during the compression stages ...\"\n\nHowever, in the recent paper, Dr.Splat [B], this paper does not compress, but keep the 512-D CLIP embeddings by Product Quantization. It is more closer to _quantization_ rather than to _compression_. Accordingly, __not__ all the existing methods compress the CLIP embeddings for this task which contradicts with the statements in Line19-21."}, "questions": {"value": "__Q1. Training time comparison will be helpful.__  \n\n__Q2. learnable language vector __f__ or indices of codebook vector?__  \nIn Line 232 of the manuscript, the proposed method also introduce the Gaussian parameter theta that involves the learnable language vector. If so, I am quite confused with the statement in Line 259, _\"The unified optimization objective in Eq. 5 involves two non-differentiable components ... the penalty itself is differentiable but the discrete assignment is not\"_\n\nIf the method assigns the index of the codebook vector on top of 3D Gaussians, it is true that the discrete assignment is not differentiable as stated in Line 261. However, I am not sure why the authors also introduce the language vector __f__? I personally expect that __f__ is not used, but I would like to double-check the implementation details. \n\n+ it will be appreciated to revise Lines 230-238 to clearly describe the parametrization details.\n\n__Q3. Does the authors also use autoencoder?__  \nIn Line 189, _\"LangSplat (Qin et al., 2024) employs an autoencoder to map CLIP embeddings\ninto a compact latent space for efficient rendering and reconstructs the full features when needed.\nOur approach also adopts both strategies.\"_\n\nHowever, in the methodology section, I cannot find where the autoencoder is used. When optimizing the codebook, does the authors follow the Vector Quantized Variational Autoencoder (VQ-VAE) [A] ? It is highly ambiguous how the training procedures are designed.\n\n__Q-others. Please refer to the weakness sections and I hope to read the authors' responses.__\n\n__Review summary__  \nThe paper proposes a unified framework combining semantic learning, sparsification, and vector quantization for compact language-embedded 3DGS, but several concerns remain. First, the comparisons are not fair, as prior works like LangSplat and OpenGaussian do not incorporate pruning; stronger baselines combining them with existing pruning methods are needed, especially given the paper‚Äôs emphasis on model-size reduction. Second, the motivation for unifying all optimization steps is unclear, and the paper does not demonstrate why this co-optimization is superior to a sequential pipeline or why re-optimizing Gaussian parameters from scratch is necessary instead of starting from pre-optimized 3DGS as prior work does. Finally, several technical details are missing‚Äîsuch as the dimensionality of the compressed CLIP features‚Äîand it remains unclear whether performance gains stem from the unified optimization or simply from codebook-related improvements similar to OpenGaussian. \n\n__References__   \n[A] Neural Discrete Representation Learning, Neurips 2017\n[B] Dr.Splat, CVPR 2025"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4Yj9LHLxaF", "forum": "KXJ5TU1q7B", "replyto": "KXJ5TU1q7B", "signatures": ["ICLR.cc/2026/Conference/Submission8120/Reviewer_M3pa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8120/Reviewer_M3pa"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8120/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761929256215, "cdate": 1761929256215, "tmdate": 1762920097930, "mdate": 1762920097930, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes CoLaSplat (Compact Language 3D Gaussian Splatting), a unified framework for compressing language-embedded 3D Gaussian Splatting (3DGS) models used in open-vocabulary 3D scene understanding. \nUnlike existing sequential pruning and quantization methods, CoLaSplat integrates semantic learning, sparsification, and vector quantization into a single optimization problem solved by a primal-dual optimization scheme. \nThis unified approach jointly optimizes Gaussian parameters to preserve semantic and rendering fidelity while drastically reducing redundancy. \n\nCoLaSplat achieves smaller model size and lower GPU memory, while maintaining or improving segmentation and localization accuracy on 3D-OVS and LERF benchmarks. \n\nThe paper also provides theoretical convergence guarantees and open-sources code and data to support reproducibility.\n\nThis reviewer looks forward to the authors‚Äô rebuttal and revision responses and would be glad to reassess the rating after the discussion."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "- Novel unified semantic 3DGS optimization: First method to jointly optimize compression and semantic alignment for language-embedded 3DGS, bridging a key efficiency‚Äìsemantics gap.\n\n- Strong efficiency-performance balance: Delivers significant compression without degrading visual or semantic quality, validated across multiple datasets and metrics.\n\n- Reasonable evaluation: Benchmarked against five strong baselines with clear gains in mIoU, memory, and FPS, and supported by ablations on pruning and quantization effects.\n\n- Reproducibility: Public code, datasets, and detailed algorithmic descriptions (Algorithm 1, Appendix C) enhance transparency and replicability."}, "weaknesses": {"value": "- Practical complexity: The proposed optimization framework introduces additional computational overhead. However, the paper lacks an analysis or comparison of training time and overall computational cost. \n\n- Overclaim: In the abstract and introduction, the authors claim a 147√ó faster inference. Where does this number come from? Compared to which baseline?\n\n- FPS may be misleading 1 (Tables 1 and 2): Is the rendering speed comparison based on RGB images or feature maps? Additionally, did the authors apply any extra optimizations, such as CUDA acceleration? This reviewer finds Table 4 confusing, where even without pruning, the FPS (262) remains nearly unchanged. Where, then, does the reported speed gain originate? Vector quantization only affects to the memory or storage, not the computational time, right?\n\n- FPS may be misleading 2 (Tables 1 and 2): The term \"3D semantic segmentation\" in LangSplat [Qin et al.] does not actually refer to 3D segmentation; instead, the evaluation measures 2D mask accuracy projected from 3D relevance.\nIn contrast, OpenGaussian operates in a fundamentally different regime. It directly queries and localizes 3D volumes without rendering.\nMoreover, since OpenGaussian performs direct 3D-space queries without 2D rendering, as discussed in [C1], the overall computational complexity and cost of the entire system are significantly lower than those of any rendering-based approaches (including Feature-3DGS, GS-Grouping, LEGaussian, and LangSplat).\nTherefore, comparing FPS results in Tables 1 and 2 with those rendering-based methods is inappropriate.\n\n[C1] Dr. Splat: Directly Referring 3D Gaussian Splatting via Direct Language Embedding Registration, CVPR 2025.\n\n- Missing citation and comparison: OpenGaussian and [C1] belong to a different methodological category from other competing approaches. Reference [C1] is missing in the citations.\nThe related work section should clearly distinguish these approaches from others including the proposed method. This distinction should also be reflected in the experimental comparisons.\n\n- Missing Q as a function argument in Eq. (7) and Appendix C: This issue is critical. Up to Eq. (6), \nùëÑ is treated as an optimization variable under the minimization operator, but it is suddenly omitted in Eq. (7) and in Appendix C. This is not a mere typographical error. The optimization process over \nùëÑ must be considered in the proof. Consider revising the proof accordingly or omitting the proof entirely. Even without the theoretical proof, the contribution remains substantial (especially since convergence results for non-convex and non-smooth augmented Lagrangian multiplier methods up to a critical point are already well-established and do not constitute a novel contribution).\n\n- Ablation breadth:The ablation studies are limited to pruning and quantization removal. Additional empirical analyses on parameter sensitivity or convergence robustness would further substantiate the claims. Although a theoretical convergence analysis is provided, corresponding empirical validation should also be included.\n\n- No semantic degradation analysis: The paper does not analyze subtle semantic drift due to quantization, relying solely on global mIoU metrics."}, "questions": {"value": "Please check the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "dj4pas4QRi", "forum": "KXJ5TU1q7B", "replyto": "KXJ5TU1q7B", "signatures": ["ICLR.cc/2026/Conference/Submission8120/Reviewer_LpAn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8120/Reviewer_LpAn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8120/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762030061460, "cdate": 1762030061460, "tmdate": 1762920097510, "mdate": 1762920097510, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}