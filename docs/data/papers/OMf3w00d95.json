{"id": "OMf3w00d95", "number": 9303, "cdate": 1758118233010, "mdate": 1759897732509, "content": {"title": "CoT-Evo: Evolutionary Distillation of Chain-of-Thought for Scientific Reasoning", "abstract": "While chain-of-thought (CoT) distillation from advanced large language models (LLMs) has proven effective in general reasoning tasks, it struggles in scientific domains where even advanced models often produce incorrect or superficial reasoning due to high complexity and specialized knowledge requirements. Directly distilling from such flawed outputs results in low-quality training data and limits the performance of smaller student models. To overcome this, we propose CoT-Evo, an evolutionary CoT distillation framework. It begins by constructing a diverse pool of reasoning trajectories from multiple LLM thinkers, enriches them with automatically retrieved domain knowledge, and iteratively refines the trajectories using novelty-driven selection, reflective recombination and mutation. The refinement is guided by a fitness function that evaluates answer correctness, coherence, and effective knowledge utilization. This results in a high-quality CoT dataset tailored for scientific reasoning. We employ this evolved dataset to fine-tune a compact model, which achieves state-of-the-art performance on scientific reasoning benchmarks. Our work establishes a scalable approach to synthesizing high-fidelity scientific reasoning data from diverse and fallible LLMs.", "tldr": "We propose CoT-Evo, an evolutionary distillation framework that constructs diverse CoTs from multiple LLMs and iteratively refines them into high-quality CoTs for scientific reasoning.", "keywords": ["Long CoT Distillation", "Scientific Reasoning", "Evolutionary Algorithm"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/602bad29ad3d57c3a75a62c8a00fb3c0e1ce8809.pdf", "supplementary_material": "/attachment/b720667c871e76f819058b7079b5d6277e8d4133.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces CoT-Evo, an evolutionary CoT distillation framework for scientific reasoning. It generates diverse reasoning trajectories from multiple LLMs, enriches them with domain knowledge, and iteratively refines them using novelty-driven selection and recombination guided by a fitness function. The resulting dataset is used to fine-tune three compact-sized models, achieving strong performance on scientific reasoning benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-written and easy to follow.\n\n2. It introduces an evolutionary framework where novelty-driven selection, reflective recombination, and mutation are used to iteratively refine reasoning trajectories, which is shown to be effective and well-motivated.\n\n3. Fine-tuning three 7–8B models with the resulting dataset achieves strong performance, demonstrating the effectiveness of the proposed method."}, "weaknesses": {"value": "1. Currently, the paper evaluates scientific reasoning only on BioProBench and ChemCoTBench. It would be helpful to include additional benchmarks, such as the well-known GPQA-diamond, to better demonstrate the effectiveness of the evolved CoT dataset.\n\n2. The paper does not report the reasoning performance of the student model after each iteration of CoT evolution. Showing how the selected CoT data at each iteration contributes to model improvement would provide more insight into the co-evolution process.\n\n3. CoT-Evo is specifically designed for scientific reasoning, but the paper does not evaluate its applicability to other complex reasoning domains, such as code reasoning, mathematical problem solving, or logical reasoning."}, "questions": {"value": "See the weaknesses section"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PNWxUSKD6r", "forum": "OMf3w00d95", "replyto": "OMf3w00d95", "signatures": ["ICLR.cc/2026/Conference/Submission9303/Reviewer_7Nvu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9303/Reviewer_7Nvu"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9303/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761464685402, "cdate": 1761464685402, "tmdate": 1762920939666, "mdate": 1762920939666, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem in COT distillation for scientific reasoning: advanced LLM teachers often produce flawed reasoning. Distilling from these flaws limits student model performance.\n\nTo solve this, the authors propose COT-Evo, a novel \"Evolutionary CoT Distillation\" framework. The core idea is to actively \"evolve\" and \"synthesize\" higher-quality reasoning paths rather than just selecting existing ones.\n\nThe framework initializes a diverse pool of CoTs from multiple \"LLM Thinkers.\" It then iteratively optimizes this pool using an evolutionary loop: 1) Fitness Evaluation (correctness, length, knowledge use), 2) Novelty-Driven Selection (balancing quality and diversity), and 3) Recombination/Mutation (integrating strengths and fixing errors). This process generates a high-fidelity \"evolved\" dataset used to fine-tune student models.\n\nExperimental results show that models trained on the COT-Evo dataset achieve better performance on challenging scientific benchmarks (BioProBench and ChemCoTBench)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Creatively applies evolutionary algorithms and novelty-driven selection to synthesize superior reasoning, moving beyond the traditional \"select-the-best\" paradigm. Clearly identifies and offers a promising solution to the critical problem of distilling from \"fallible\" teachers in complex scientific domains.\n\nRobust validation on challenging benchmarks with comprehensive baselines. In-depth analysis and ablations effectively prove that performance gains come from higher-quality data, not just increased sampling."}, "weaknesses": {"value": "The framework is computationally intensive, requiring multiple LLM thinkers and repeated LLM calls within the evolutionary loop. The practical overhead compared to baselines is not fully quantified.\n\nThe framework relies on an LLM for critical steps (fitness, recombination, mutation, and quality evaluation), creating a potential point of failure if the judge is biased or flawed.\n\nThe evolutionary process may be sensitive to hyperparameters (e.g., a small population size $n_{pop}=6$ and $k=2$). The justification for these specific choices is limited."}, "questions": {"value": "Q1: The COT-Evo framework appears significantly more computationally intensive (e.g., in total tokens or LLM calls) than baselines like MT or BoK, given the iterative evaluation and generation loop. It would greatly strengthen the paper to include a quantitative discussion on this. For instance, could you provide a comparison of the approximate token consumption required to generate the dataset versus the baselines? Alternatively, an analysis of performance under an equivalent, fixed token budget would be very insightful for assessing the method's practical efficiency.\n\nQ2: While Figure 3 helpfully explores the budget ($B$) and population size ($n_{pop}$), could you provide more justification for the selection of other key parameters, such as the fitness weights ($\\lambda_1, \\lambda_2$) and the $k$-nearest neighbors value ($k=2$)? Even a brief explanation of how these were chosen, or a discussion of their sensitivity, would be valuable for reproducibility.\n\nQ3: Since the \"Recombination\" operation is well-defined as a \"guided generation\" process (using a prefix from $t_o$ and information from $t_p$), the analogy to a traditional EA \"crossover\" might not be necessary and could potentially cause confusion for readers familiar with classic EA terminology. Clarifying it simply as a novel, guided operator might be more straightforward."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4npLvbWAWc", "forum": "OMf3w00d95", "replyto": "OMf3w00d95", "signatures": ["ICLR.cc/2026/Conference/Submission9303/Reviewer_pgWS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9303/Reviewer_pgWS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9303/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761836139067, "cdate": 1761836139067, "tmdate": 1762920939299, "mdate": 1762920939299, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Existing CoT distillation methods in scientific domains are vulnerable to issues of faulty reasoning and knowledge deficiency. Prior approaches either perform single-chain compression/pruning or select a single chain from multiple teachers, lacking the ability to refine and integrate reasoning at a fine-grained level. This paper proposes an evolutionary CoT distillation framework, COT-EVO, which emphasizes intra-chain recombination and mutation rather than merely inter-chain selection."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Proposes a novel evolutionary CoT distillation framework that introduces the concept of genetic algorithms into reasoning-path optimization. Demonstrates improved performance of small models in scientific reasoning tasks, with ablation studies verifying the effectiveness of the recombination, mutation, and novelty selection components."}, "weaknesses": {"value": "The authors did not conduct direct comparisons with recent process-level distillation or evolutionary reasoning methods such as TwT, Retro-Search, and BREAD, leaving the unique contribution of COT-EVO unclear.\n\nThe paper does not compare its method with standard CoT under equal compute (equal token count) conditions.\n\nSome of the reported performance improvements are not statistically significant.\n\nThe method is only validated on small-scale models, and it remains uncertain whether the gains would persist for larger models."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cqcOMVU2vh", "forum": "OMf3w00d95", "replyto": "OMf3w00d95", "signatures": ["ICLR.cc/2026/Conference/Submission9303/Reviewer_tiKN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9303/Reviewer_tiKN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9303/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989348348, "cdate": 1761989348348, "tmdate": 1762920938813, "mdate": 1762920938813, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes CoT-Evo, an evolutionary distillation framework for generating high-quality Chain-of-Thought (CoT) data specialized for scientific reasoning. Instead of simply selecting CoTs from one or multiple teachers, CoT-Evo iteratively evolves reasoning trajectories through an evaluation–selection–variation–update loop. It combines ideas from genetic algorithms and novelty search to maintain reasoning diversity, integrates reflective recombination and mutation operations, and uses a composite fitness function evaluating correctness, coherence, and knowledge usage. Experiments on BioProBench and ChemCoTBench demonstrate substantial gains over single-teacher, multi-teacher, and best-of-K distillation baselines, with notable improvements even against large teacher LLMs."}, "soundness": {"value": 1}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-organized, and the pipeline diagram (Figure 1) is visually appealing and instrumental in understanding the full workflow. It clearly depicts the multi-thinker initialization, novelty-driven selection, recombination, and mutation processes, providing an intuitive grasp of the iterative framework.\n\n2. The focus on scientific reasoning is timely and important. This area is under-explored compared with mathematical or commonsense reasoning, and the paper explicitly tackles the difficulty of distilling reasoning traces in scientific domains.\n\n3. Experimental results show large performance improvements across all evaluated datasets compared to strong baselines (single-teacher, multi-teacher, and best-of-K). Ablations also indicate that proposed components contribute meaningfully to performance."}, "weaknesses": {"value": "1. Although the motivation centers on scientific reasoning, the method itself is very general and could apply equally to other reasoning domains. However, the paper does not include any cross-domain experiments to validate this generality. As a result, it remains unclear why this method uniquely addresses the challenges of scientific reasoning - particularly the lack of verifiable or reliable reward signals. The intra-chain aggregation and evolutionary refinement do not appear to inject additional domain knowledge beyond what the teacher already provides.\n\n2. The evaluation-selection-variation-update process is complex and involves multiple heuristics (novelty search, recombination triggers, mutation modes). The empirical section shows better results but does not convincingly justify why this evolutionary loop is necessary compared with simpler or alternative distillation techniques. Comparisons with other distillation baselines or under the token-budget-controlled settings would make the argument more convincing.\n\n3. The two key points raised in the Introduction: (1) single-teacher bias and pruning insufficiency, and (2) multi-teacher diversity without fine-grained control are not unique to scientific reasoning. These limitations apply to CoT distillation in general. Therefore, the framing as “scientific reasoning-specific” seems somewhat overstated."}, "questions": {"value": "1. Could you clarify why the proposed evolutionary process particularly benefits scientific reasoning rather than other reasoning domains? Is there empirical or theoretical evidence that the novelty-driven selection aligns better with the nature of scientific reasoning tasks?\n\n2. Since the framework is general, it would be informative to include non-scientific benchmarks to test generalizability and demonstrate the method’s effectiveness beyond science.\n\n3. Regarding efficiency, how does CoT-Evo’s compute cost compare to standard multi-teacher distillation or rejection-sampling pipelines? Could a smaller population or fewer iterations retain most of the gains?\n\n4. In the fitness design, the length appropriateness and knowledge usage scores seem somewhat ad-hoc. How sensitive is the final performance to these weighting hyperparameters (λ₁, λ₂)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3NKe85kYCP", "forum": "OMf3w00d95", "replyto": "OMf3w00d95", "signatures": ["ICLR.cc/2026/Conference/Submission9303/Reviewer_9BYm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9303/Reviewer_9BYm"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9303/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762162393358, "cdate": 1762162393358, "tmdate": 1762920938272, "mdate": 1762920938272, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}