{"id": "HIXPyQ1aMq", "number": 11933, "cdate": 1758204721225, "mdate": 1759897544779, "content": {"title": "How Do Language Models Speak Languages? A Case Study on Unintended Code-Switching", "abstract": "Unintended code-switching, which refers to the phenomenon where LLM unexpectedly switch languages, poses a fundamental challenge in the multilingual capabilities in LLMs.\nHowever, the fundamental properties of their underlying circuits, such as what they consist of, where they emerge in the network, and how to mitigate their effects, remain unexplored.\nExisting works on the mechanistic interpretability depend on additional training (e.g., sparse autoencoders) or manual annotation, both of which pose limitations in real-world scenarios.\nIn this work, we introduce a scalable circuit discovery framework that causally localizes multilingual neurons, describes their functional patterns, and groups neurons into circuits.\nWe find that the circuits for multilingual generation fall into two different regimes: a language regime which acts as a lingual key to detect language patterns, and a semantic regime which functions as a contextual value to retrieving language-agnostic semantics.\nThese two regimes, in normal cases, converge smoothly to make final predictions, but in code-switching scenarios, semantics dominate the circuit, overriding typical language pathways and destabilizing outputs.\nFurthermore, we fine-tune the identified language sub-circuit ($\\sim0.019$\\% of all neurons), reducing the code-switching rate by $20.8$\\% with minimal parameter updates, validating the effectiveness of the discovered circuits for practical scalability. Our work serves as a preliminary exploration of multilingual generation circuits, offering actionable insights for neuron-based mechanistic interpretability.", "tldr": "", "keywords": ["Mechanistic Interpretability;  Large Language Models;"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b66393443b9213964a21cc16d3de76a2e72abffd.pdf", "supplementary_material": "/attachment/eabcacb4e5a76ea61e86a120159635f4eee9f393.zip"}, "replies": [{"content": {"summary": {"value": "This paper investigates the neural circuits behind unintended code-switching in multilingual LLMs. Using a proposed causal discovery framework, it identifies two key regimes: a language circuit that detects linguistic patterns and a semantic circuit that retrieves language-agnostic meaning. The study shows that imbalances between these regimes trigger code-switching and that fine-tuning the language sub-circuit significantly reduces this behavior with minimal updates."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "- This study conducts analysis on the cause of language-switching; The research theme is important for safety and intriguing.\n- The proposed method is quite interesting.\n- The authors conducted a comprehensive experiments using two models, multiple languages, multiple benchmarks, ensuring the findings and effectiveness."}, "weaknesses": {"value": "- Although this study is quite interesting, there are significant issues for the readability of this paper. Please look at \"Questions\" for the detail.\n- Equation (3): I think this equation assumes d(a_l) / d(a_e) = 1, but is this assumption reasonable? Any comment?\n- 4.3: This chapter is important because this experiment result is a direct ground for the claim about \"the language confusion is the result of competition between language-specific circuits and semantic circuits\". So, in order to supplement the claim, I think we need an extensive experiments, for example how about strengthen the circuits of language neurons instead of ablating semantic circuits?"}, "questions": {"value": "- L166: Atteibution Patching: This is an explanation of the existing work, so I think this paragraph should move to outside Chapter 3 (Method). For example, how about creating preliminary chapter?\n- Equation(1): This equation is important as a fundamental information to understand the proposed method (Hierarchical Attribution Patching). I recommend that the authors write more detailed derivation of this equation.\n- Equation(3): Likewise, I recommend that the authors write more detailed derivation of this equation.\n- L190: What is the definition of \"late neuron\" and \"early neuron\"?\n- L167: does neuron \"n \\in R^d\" refer to \"a column of the MLP down-projection\" as described at the footnote in page4?\n- L220: What is a definition of \"e\"?\n- L222: What is a definition of activation()?\n- L261: does metric m refer to equation(2)? or something else?\n- L264: What is a detailed definition of m(\\phi) and m(M)? I could not clearly understand the exact process based on the current description.\n- L350: What is a definition of \"Averaged attribution ratios\"? Please explain the details."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tI0xrb8BIO", "forum": "HIXPyQ1aMq", "replyto": "HIXPyQ1aMq", "signatures": ["ICLR.cc/2026/Conference/Submission11933/Reviewer_EbfB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11933/Reviewer_EbfB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11933/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761619671040, "cdate": 1761619671040, "tmdate": 1762922937299, "mdate": 1762922937299, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates how multilingual language models internally represent languages and why they sometimes code-switch unexpectedly. The authors develop a hierarchical circuit-discovery framework that traces causal pathways from neurons to model outputs. They use attribution patching and neuron-level interventions to isolate circuits responsible for language versus semantic processing. Through controlled experiments, they find that disabling or amplifying a very small subset of neurons (around 0.02% of total) significantly alters the rate of code-switching, supporting the view that unintended switching results from competition between language and semantic circuits. The method also enables lightweight mitigation through targeted fine-tuning, which reduces code-switching by more than 20% without harming general performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The study provides a clear and rigorous causal framework for analyzing multilingual behavior in large models, going beyond correlational neuron activation studies. Its conceptual contribution lies in formalizing code-switching as a competition between distinct subcircuits and providing empirical validation through targeted interventions. The approach is carefully designed: attribution patching, hierarchical tracing, and neuron-level ablations are combined coherently. The experiments are extensive and include both diagnostic and corrective analyses, showing consistent causal effects across two model architectures and multiple languages.\n\nThe paper is also methodologically elegant and transparent. It integrates interpretability techniques into a reproducible pipeline, avoiding heuristic prompt-based evaluation. The figures and tables clearly illustrate how the identified neurons affect behavior, and the mitigation results demonstrate a practically relevant application. Overall, the paper balances mechanistic insight with empirical robustness, offering one of the most convincing analyses to date of language competition inside multilingual LLMs."}, "weaknesses": {"value": "While the framing of language and semantic circuits is intellectually appealing, the novelty is moderate because the main components‚Äîattribution patching, neuron labeling via LLMs, and targeted ablation‚Äîare adaptations of existing interpretability tools. The paper‚Äôs originality therefore lies in its integration and application rather than in new methodology. A deeper theoretical justification of the ‚Äúcompetition‚Äù model or mathematical analysis of how these circuits interact would strengthen the contribution.\n\nThe evaluation scope is also somewhat limited. Only two model families are studied, both decoder-only transformers with similar architectures. Attention circuits are not analyzed in depth, leaving open whether the phenomenon is primarily MLP-based or distributed across attention heads. The neuron description and grouping process depends on LLM judgments, which, although checked for precision, could introduce bias. Finally, the mitigation results focus on controlled test sets rather than naturally occurring code-switched corpora, so the real-world generality of the fix is uncertain."}, "questions": {"value": "1. How sensitive are the results to model architecture and scale? Have you tested whether the same type of language-semantic circuit separation appears in models such as Mistral or Gemma?\n\n2. The hierarchical attribution assumes approximate linearity in the residual stream. How does nonlinearity between layers affect the faithfulness of the discovered circuits?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "S1da3uzyJH", "forum": "HIXPyQ1aMq", "replyto": "HIXPyQ1aMq", "signatures": ["ICLR.cc/2026/Conference/Submission11933/Reviewer_inWb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11933/Reviewer_inWb"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11933/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761930971644, "cdate": 1761930971644, "tmdate": 1762922936769, "mdate": 1762922936769, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "# üß© Summary\nThis paper explores the mechanistic basis of **unintended code-switching** in multilingual large language models (LLMs).  \nThe authors propose a **causal circuit discovery framework** that identifies neuron-level structures involved in multilingual text generation.  \nThe framework integrates:\n1. **Circuit Localization** ‚Äì a hierarchical extension of *Attribution Patching* (Nanda, 2022), tracing neuron-to-neuron causal connections;  \n2. **Neuron Description** ‚Äì using an auxiliary LLM to generate textual explanations from token projections and activation samples;  \n3. **Neuron Grouping** ‚Äì clustering neurons into interpretable ‚Äúsuper-neurons‚Äù based on these descriptions.  \n\nThrough experiments on **Qwen2.5-7B** and **LLaMA3.1-8B**, the authors show that multilingual generation involves two interacting subsystems:  \na **Language sub-circuit** maintaining linguistic context, and a **Semantic sub-circuit** capturing language-agnostic meaning.  \nThey argue that unintended code-switching arises when semantic circuits dominate language circuits, and that fine-tuning only ~0.019% of neurons mitigates this by **20.8%**."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- **Novel application of mechanistic interpretability.**  \n  Code-switching is an interesting and underexplored multilingual behavior, and analyzing it through causal circuit tracing is conceptually fresh.  \n\n- **Detailed technical description.**  \n  The paper provides pseudo-code (Algorithm 1), datasets, and hyperparameters, making the procedure relatively transparent.\n\n- **Empirical support.**  \n  Ablation and fine-tuning experiments show that identified neurons have tangible, directionally causal influence on multilingual output.\n\n- **Clear organization.**  \n  The presentation of results‚Äîparticularly Figures 1‚Äì3 and Tables 1‚Äì5‚Äîis systematic and accessible."}, "weaknesses": {"value": "### 1. Limited generality despite broad framing\nThe paper describes its framework as ‚Äúuniversal,‚Äù but this appears to refer to universality *within multilingual generation*.  \nAll methodological components‚Äîthe contrastive data construction, logit-difference metric, and grouping prompts‚Äîare defined specifically for language variation (e.g., English vs. French tokens).  \nAs such, its applicability to **non-linguistic circuits** (e.g., reasoning, arithmetic, syntax) remains **untested**, not necessarily impossible.  \nTo claim methodological generality, experiments on other capabilities would be required.\n\n### 2. Ambiguity in the significance of the phenomenon\nWhile the introduction states that code-switching undermines the multilingual reliability of LLMs, the **broader motivation and impact** of identifying its neural cause remain underdeveloped.  \nThe work does not clearly articulate whether the findings  \n(a) inform multilingual training design,  \n(b) improve robustness or safety, or  \n(c) offer theoretical insight into cognitive code-switching.  \nThus, the study risks appearing descriptive rather than explanatory.  \nClarifying the *scientific or practical value* of uncovering these circuits would substantially strengthen the paper.\n\n### 3. Causal rigor and robustness\nThe causal evidence relies on attribution ratios and targeted suppression, which demonstrate directional sensitivity but not sufficiency.  \nThe hierarchical patching assumes local linearity (SiLU removal) and uses fixed hyperparameters (œµ = 0.001, L = 5) without sensitivity analysis.  \nThese limitations are acknowledged (Appendix A.1.5) but not explored experimentally.\n\n### 4. Neuron description methodology\nThe LLM-based ‚ÄúNeuron Description‚Äù step increases readability but adds interpretive variability.  \nTable 9 reports only moderate alignment (‚âà 0.7 precision) between explanations and activations.  \nWhile the authors argue that textual descriptions capture superposed neurons better than static token lists, this claim is qualitative.  \nQuantitative comparisons or human evaluations would help establish whether such descriptions meaningfully improve interpretability.\n\n### 5. Evaluation and reproducibility\nThe behavioral metrics (LPR/LCR) rely on heuristic language identification and LLM-assisted annotation (Appendix A.4.3), which may misclassify loanwords or named entities.  \nA small-scale human evaluation would increase confidence.  \nThe reproducibility statement mentions partial code in supplementary materials and a plan for full release upon acceptance‚Äîhelpful, but not yet public.  \nComputation cost (GPU-hours) is also unreported.  \nMinor typos remain (e.g., *none-code-switched ‚Üí non-code-switched*)."}, "questions": {"value": "1. Could you clarify how identifying the cause of code-switching advances LLM robustness or linguistic understanding?  \n2. How generalizable is the proposed framework to **non-linguistic circuits**, and what modifications would be required?  \n3. How stable are the LLM-based neuron descriptions across random seeds or different explainer models?  \n4. Have you tested sensitivity to key hyperparameters (œµ, L) in hierarchical patching?  \n5. Can you provide quantitative comparisons with Sparse Autoencoder or ATP\\* frameworks?  \n6. Has any human validation been performed for the LPR/LCR metrics?  \n7. What is the approximate runtime (GPU-hours) for one full circuit-discovery pipeline?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "unzY83oidc", "forum": "HIXPyQ1aMq", "replyto": "HIXPyQ1aMq", "signatures": ["ICLR.cc/2026/Conference/Submission11933/Reviewer_NJME"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11933/Reviewer_NJME"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11933/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979203367, "cdate": 1761979203367, "tmdate": 1762922936409, "mdate": 1762922936409, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates unintended code-switching in multilingual LLMs, a phenomenon where models unexpectedly switch between languages during generation. The authors propose a causal circuit discovery framework that identifies, interprets, and groups multilingual neurons into circuits governing linguistic behavior. Using attribution patching, they reveal two main circuit regimes: (1) language circuits that detect language patterns, and (2) semantic circuits that represent language-agnostic meaning. They argue that code-switching arises from competition between these circuits when semantic activations override language-specific ones. Experiments on Qwen2.5-7B and Llama3.1-8B show that fine-tuning a small set of language-specific neurons (‚âà0.02%) reduces code-switching by ~20% without hurting task performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Novel mechanistic approach: The paper introduces a scalable, neuron-level causal tracing method that extends attribution patching, addressing a gap in multilingual interpretability research.\n\n- Insightful hypothesis: It identifies competition between semantic and linguistic circuits as the mechanistic source of code-switching, a plausible and interpretable explanation.\n\n- Strong empirical results: The selective neuron fine-tuning experiments are efficient and demonstrate measurable improvement (20.8% reduction) in code-switching.\n\n- Method generality: The framework is model-agnostic and tested across two different LLMs and several languages, showing robustness.\n\n- Clear connection to interpretability: The combination of automatic neuron description and grouping makes a step toward more interpretable circuit-level analysis."}, "weaknesses": {"value": "- Overstated causal claims: The method‚Äôs causal validity is not convincingly demonstrated‚Äîgradient-based attribution and patching only provide correlational evidence under strong linearity assumptions.\n\n- Limited theoretical grounding: The ‚Äúcompetition between semantic and language circuits‚Äù hypothesis lacks rigorous formalization and is supported mainly by qualitative visualizations.\n\n- Reproducibility concerns: Although implementation details are mentioned, many core components (e.g., neuron labeling prompts, clustering procedure, dataset construction) depend on opaque LLM judgments."}, "questions": {"value": "as suggestion you might also want to use a token-level or sequence-level code-switching detection approaches.\nFor instance, for code-switch language identification: https://aclanthology.org/2024.acl-short.43/ which uses models like https://aclanthology.org/2023.findings-emnlp.410/ to automatically detect and classify code-switched content."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SzBrZPzK24", "forum": "HIXPyQ1aMq", "replyto": "HIXPyQ1aMq", "signatures": ["ICLR.cc/2026/Conference/Submission11933/Reviewer_MZtA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11933/Reviewer_MZtA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11933/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997930836, "cdate": 1761997930836, "tmdate": 1762922935974, "mdate": 1762922935974, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}