{"id": "HW2jd9vfCU", "number": 16282, "cdate": 1758262656495, "mdate": 1759897250227, "content": {"title": "Pathway to $O(\\sqrt{d})$ Complexity bound under Wasserstein metric of flow-based models", "abstract": "We provide attainable analytical tools to estimate the error of flow-based generative models under the Wasserstein metric and to establish the optimal sampling iteration complexity bound with respect to dimension as $O(\\sqrt{d})$.\nWe show this error can be explicitly controlled by two parts: the Lipschitzness of the push-forward maps of the backward flow which scales independently of the dimension; and a local discretization error scales $O(\\sqrt{d})$ in terms of dimension. The former one is related to the existence of Lipschitz changes of variables induced by the (heat) flow. The latter one consists of the regularity of the score function in both spatial and temporal directions.\n\nThese assumptions are valid in the flow-based generative model associated with the F&ouml;llmer process under the Gaussian tail assumption. As a consequence, we show that the sampling iteration complexity grows linearly with the square root of the trace of the covariance operator, which is related to the invariant distribution of the forward process.", "tldr": "", "keywords": ["Flow-based model", "complexity bound", "early stopping", "Wasserstein metric"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/981e48578d9a9a6ab6e61a209a21d54292f18fea.pdf", "supplementary_material": "/attachment/a555a2b6a9b9ed301f71993a01d2bb908d29e8b9.zip"}, "replies": [{"content": {"summary": {"value": "The paper under consideration provides with theoretical guarantees of convergence for a class of flow models built upon the Föllmer process. The Föllmer process is solution to a linear stochastic differential equation, it interpolates between a Gaussian probability measure and a target distribution in finite time. The generative models considered here are obtained considering the time-reversal of the Föllmer process and mimicking its marginal flow through an ordinary differential equation whose velocity field is given in terms of the score function of the forward flow. The main contribution of this work is to obtain convergence guarantees in Wasserstein distance that imply that the number of iterations required to achieve a given precision  is $O(\\sqrt{d})$. The most relevant assumption required is that the data distribution is a perturbation of a Gaussian distribution. More precisely, the authors work under what they call *Gaussian tail assumption* (Ass. 3.7). Other relevant assumptions include Lipschitzianess of the approximated scores and a $L^2$ bound for the difference between the true scores and the approximated one. The main challenge in obtaining these bounds, as in most theoretical works on diffusion models, is to handle the time-discretization error. In order to do this, the authors show that the backward velocity field is globally Lipschitz in space, with a time-dependent constant. Moreover, they also show that time-derivative grows at most linearly in the space variable."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The strength of the paper lies in the fact that their complexity bound scales like $O(\\sqrt{d}/\\varepsilon_0)$, where $\\varepsilon_0$ is the sought precision. This behavior is optimal, and thus the result is of interest for the community of researchers interested in the theoretical aspects of score diffusion models and flow models."}, "weaknesses": {"value": "The main problem is in the novelty of the results.\n\n- Theorem 3.5 appears to me to follow from Cauchy-Lipschitz theory and and application of Gronwall's lemma, perhaps in a non-standard context. If I am wrong, I'd be happy to review my statement.\n- Theorem 3.8 is theoretically interesting as it proposes two-sided bounds for time and space derivatives of the score function. However, similar bounds have already been obtained before in various settings, which are comparable to the Gaussian tail assumption. Some of these contributions are mentioned in the paper. I also suspect that  given the natural connection between the score and Hamilton-Jacobi equations, recent results on the propagation of convexity for HJB  equations such as [1] could be leveraged to obtain dimension free bounds for $ DV $ in a far more general setting than the Gaussian tail assumptions. For example, [1] shows that these new propagation of convexity results recover as a special case the results of Pedrotti and Brigati, which are comparable to the bounds obtained here.  Theorem 3.8  should be compared to these new findings. This comparison could also help in understanding its novelty. Even if we restrict to the results cited in the paper, while the authors report in the appendix the precise statements proven in concurring works, they don't really make a thorough comparison. For example, what's new in comparison with the paper of Pedrotti and Brigati? What is the role played by the bound on the second derivative of $h$, which they don't assume? If we use the Pedrotti and Brigati bounds in the proof of Theorem 3.15 do we get a complexity bound with poorer behavior with respect to the dimension? \n\n- Theorem 3.8 also features bounds on the time-derivative od $ V $. Are these bounds a consequence of the bounds on $ DV $ ? If not, what are the conceptual difficulties to be overcome to pass from a bound on $ DV $ to a bound on $ \\partial_t V $?\n\n- About Theorem 3.15: In the context of classical DDPMs $ O(\\sqrt{d} / \\epsilon) $ complexity bounds have been achieved in [2] under comparable assumptions, namely that the score is globally Lipschitz. Would your proof methods apply even in this case? The remark on page 8 tells, and I agree with this, that Prob ODE is a time-rescaling of the Follmer flow.  Thus, I am left wondering  why is the analysis of Follmer GMs different than the one carried out for classical DDPMs and why the methods of [2] could not yield comparable results to Theorem 3.15 \n\n\n[1] *Chaintron, L. P., Conforti, G., & Eichinger, K. (2025). Propagation of weak log-concavity along generalised heat flows via Hamilton-Jacobi equations. arXiv preprint arXiv:2508.07931.*\n\n[2] *Arsenyan, V., Vardanyan, E., & Dalalyan, A. (2025). Assessing the Quality of Denoising Diffusion Models in Wasserstein Distance: Noisy Score and Optimal Bounds. arXiv preprint arXiv:2506.09681.*"}, "questions": {"value": "- Can you make precise the sentence on page 6 where you say that weak semi log-concavity as in Bruno&Sabanis only achieves $O(d)$ sampling complexity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "I8nCJDMdX1", "forum": "HW2jd9vfCU", "replyto": "HW2jd9vfCU", "signatures": ["ICLR.cc/2026/Conference/Submission16282/Reviewer_Gq2n"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16282/Reviewer_Gq2n"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16282/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761144271743, "cdate": 1761144271743, "tmdate": 1762926430444, "mdate": 1762926430444, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper establishes a new convergence result for the probability flow model.\nUnder some regularity assumptions and a G-tail assumption for the decay of the data distribution, it is demonstrated the probability flow with constant step size has a Wasserstein discretization error that scales as $O(\\sqrt d)$, where $d$ is the dimension of the data space.\nThe analysis is based on regularity properties of the velocity fields which induces the Lipschitzness of the Föllmer flow."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "* The new bound get rid of undesirable log terms present in previous works (see Table 1).\n* The mathematical presentation is very rigorous.\n* All involved constants are explicit in the Tables given in appendix.\n* The analysis is general and does not require adapting the flow sampling scheme."}, "weaknesses": {"value": "The paper suffer for some presentation issues: \n* l. 190: The $L_2$ (unusual $\\mathbb{L}$ ?) loss still involves the unknown score. \n* Is it really useful to consider a Föllmer flow with a generic covariance matrix $C$? Is there machine learning applications with non-identity covariances?\n* The main results (eg Corollary 3.16) are stated with $M_0$ without precise mention to the dimension $d$, contrary to the abstract and the introduction (Table 1). I would suggest to highlight that $M_0$ is the order of $d$ for $C=I_d$ just after Assumption 3.1, and possibly provide bounds involving $d$\nfor Corollary 3.16 and Corollary 3.20.\n\n\nMinor remarks:\n* l. 037: with deterministic flow given initial\n* l. 041: While for structured data -> However?\n* l. 134: the the\n* l. 155: can be interpret as approximation\n* l. 215: later in see Theorem 3.8 for the regularity of the velocity field and Lemma 3.10 for the proof of well-posedness\n* l. 335 Specify that Table 3 is in Appendix"}, "questions": {"value": "line 110 : \"we achieve an optimal dependence of O √d on the data dimension d\" (also in abstract): Can you please clarify the sense of \"optimal\" here?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VShOSLDI4P", "forum": "HW2jd9vfCU", "replyto": "HW2jd9vfCU", "signatures": ["ICLR.cc/2026/Conference/Submission16282/Reviewer_oCNt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16282/Reviewer_oCNt"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16282/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761842500711, "cdate": 1761842500711, "tmdate": 1762926429935, "mdate": 1762926429935, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper conducts theoretical analysis on the Wasserstein based error of Follmer Process based on the discretization step of the Euler approximation and the dimension of the dataset. The bound is provided based on various regularity assumption on the flow as well as the accuracy of the arpproximation, as well as the smoothness assumption on the dataset distribution that generalizes the semi-log-concavity assumption."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well presented upto some point, and the problem itself is well stated and the assumed regularity assumptions on the flow are fair.  The paper presents the lower complexity bound than previous works for a Target with more general conditions than the previous works."}, "weaknesses": {"value": "The paper is hard to follow for many reasons. \n\n- The claimed statements are not directly referenced in the main results. For example, I believe that the main contribution of this paper is 3.15, and it is stated that this is the result that proves $\\sqrt{d}$ bound.  But there in no direct appearance of $d$ in the statement of itself. The author is most likely refering to $M_0$, which is defined as $max (Tr(C)), M_2)$, and  that for the isotropic $C$ in the assumption,  $Tr(C) \\sim d$ so that $M_0 \\in O(d)$.   Such reasonings are implicitly assumed and used throughout the statements, an the reader is required to go back and forth between the Constant Table4 and the stated theorems/corollaries to check the validity of the claim.  I strongly believe this is not a reader's job to disect the implicit statement on the results that is being claimed \"main\".  \n\n- The paper claims, in the abstract, that \" the error can be explicitly controlled by two parts: the Lipschitzness of the push-forward maps of the backward flow which scales independently of the dimension; and a local discretization error scales with $\\sqrt{d}$\".  But these (2) parts seems not be explicitly described in the work.  I can infer that the first part is corresponding to $\\exp$ part that rises naturally from the time-propagating discrepancy of the semigroup maps, and the latter part is corresponding to the part that is related to $M_0$, which is probably related to $d$ via the Assumption 3.1.  \nI believe that when such a statement is made in abstract, it must be referenced in the writing to clarify the author's intention.\n\n- The claim in 3.20 seems very ambiguous and possibly misleading. The same applies to 3.16 as well. It is being claimed that this oder of $N$ is a \"requirement\". I believe taht this bound is derived from 3.19, but if it is a \"requirement\", do we not need the tightness of the bound? $W_2(P, Q)^2  \\leq E [|X - Y|^2] $ is not tight as well in the case of this paper---the Follmer flow is not an Optimal Transport. \n\n- The paper ends abruptly without leaving any remarks for the main claims made in the paper,  is this really the final version of the submission?  I feel that this is a paper with the right idea but it is in a format not fit to the venue.  This paper's worth itself is noted, but major revision seems necessary."}, "questions": {"value": "Please see the Weakness section. \n\nAlso, what is the proof technique on this paper differ from the previous works that allows the tighter complexity bound? Is there any distinguishing regularity assumptions in the Follmer flow that is not used in the previous works?  ( G-tail seems like more general assumption, so it must be making the proof harder.)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "This is a theory paper."}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "04ayHBUrPG", "forum": "HW2jd9vfCU", "replyto": "HW2jd9vfCU", "signatures": ["ICLR.cc/2026/Conference/Submission16282/Reviewer_fxPs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16282/Reviewer_fxPs"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16282/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761877521718, "cdate": 1761877521718, "tmdate": 1762926429224, "mdate": 1762926429224, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work analyzes accumulated error for Euler step sampling using Follmer flows. The main contribution is a tighter bound in terms of data dimension $d$ along with the analytical tools."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "A tighter bound in terms of $d$ is provided."}, "weaknesses": {"value": "1. The entire paper seems rushed and incomplete. Section 3 seems to be a compilation of assumptions, corollaries and theorems. Interpretations and explanations for stated results are barely provided. There is no conclusion & future work section. Overall, I don't think the current presentation helps the audience to connect the assumptions and bounds to the machine learning context. I'd advise the authors to present a simplified set of assumptions and theorems in the main paper to have more space to convey the intuition and implications of these results while deferring the formal, rigorous presentation in the appendix. \n\n2. As a consequence of 1, I'm not able to understand the significance of this work.\n\n3. Follmer flows seems to be a special case of rectified flow [1] (see appendix A in [2]) by letting the noisy prior distribution to be $\\mathcal{N}(0, C)$. Mathematically, Follmer flow seems to be $X_t  = t X_1 + (1-t)X_0$ but restricting $X_0$ to be sampled from $\\mathcal{N}(0, C)$.  Can the authors confirm this observation? If so, I think it would be necessary to further discuss the connection between this work and rectified flows. \n\n\n4. I highly doubt that assumption 3.13 would hold in practice. It basically requires a neural network to be uniformly bounded on a non-compact support. \n\n\n5. Would it be easier to bound/spell out $Lip(T_j)$ and $Lip(\\tilde{T}_j)$ in terms of quantities related to the score function/ neural networks? It would help the audience to connect the assumptions back to properties of neural nets.\n\n[1] Liu, X., Gong, C., & Liu, Q. (2022). Flow straight and fast: Learning to generate and transfer data with rectified flow. arXiv. https://arxiv.org/abs/2209.03003\n\n[2] Rout, L., Chen, Y., Ruiz, N., Caramanis, C., Shakkottai, S., & Chu, W.-S. (2024). Semantic image inversion and editing using rectified stochastic differential equations. arXiv. https://arxiv.org/abs/2410.10792"}, "questions": {"value": "1. what is the significance to analyze a general $C$ instead of $C=I$? I've only seen the use of correlated noise in infinite dimensional flows like [1] and [2] only because white Gaussian noise is not trace-class in a general Hilbert space. But it's certainly not the case here.\n\n2. see weakness.\n\n\n[1] Kerrigan, G., Migliorini, G., & Smyth, P. (2023). Functional Flow Matching. arXiv. https://arxiv.org/abs/2305.17209\n\n[2]Franzese, G., Corallo, G., Rossi, S., Heinonen, M., Filippone, M., & Michiardi, P. (2023). Continuous-Time Functional Diffusion Processes. arXiv. https://arxiv.org/abs/2303.00800"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sP3hHAsFde", "forum": "HW2jd9vfCU", "replyto": "HW2jd9vfCU", "signatures": ["ICLR.cc/2026/Conference/Submission16282/Reviewer_Q1jr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16282/Reviewer_Q1jr"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16282/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761942972703, "cdate": 1761942972703, "tmdate": 1762926428845, "mdate": 1762926428845, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}