{"id": "os7OLubIMI", "number": 19820, "cdate": 1758299687938, "mdate": 1759897017377, "content": {"title": "On learning linear dynamical systems in context with attention layers", "abstract": "This paper studies the expressive power of linear attention layers for in-context learning (ICL) of linear dynamical systems (LDS). We consider training on sequences of inexact observations produced by noise-corrupted LDSs, with all perturbations being Gaussian; importantly, we study the non-i.i.d.\\ setting as it is closer to real-world scenarios. We provide the optimal weight construction for a single linear-attention layer and show its equivalence to one step of Gradient Descent relative to an autoregression objective of window size one. Guided by experiments, we posit an extension to larger window sizes. We back our findings with numerical evidence. These results add to the existing understanding of transformers' expressivity as in-context learners, and offer plausible hypotheses for experimental observations whereby they compete with Kalman filters --- the optimal model-dependent learners for this setting.", "tldr": "This paper studies how linear attention layers in-context learn linear dynamical systems and shows the optimal weight construction implements one step of Gradient Descent relative to an autoregression objective of window size one.", "keywords": ["in-context learning; linear attention; linear dynamical systems; kalman filter; time series"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d154a084db3f37f971f16fc70ec97bd08eb175fa.pdf", "supplementary_material": "/attachment/fff27e079363c4dd47739d11418fcd4388240a4f.zip"}, "replies": [{"content": {"summary": {"value": "The paper addresses the task of learning dynamical models in-context with a linear transformer. The authors show how the transformer can be optimised to fit a linear, size-one, autoregressive model in-context. Under certain assumptions, they compute the attention parameters that guarantee one in-context step of gradient descent of a Least Squares objective."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Learning a dynamical model in context is challenging and new. \n- The state-of-the-art is well-presented, in the introduction and throughout the presentation."}, "weaknesses": {"value": "- The performance of linear self-attention models does not match that of more expensive LLMs. \n- After the reduction to improper learning, the problem resembles linear regression. The authors should comment on the specific challenges coming from the non-i.i.d. setup.\n- The assumptions on the diagonality of the state transition matrix seem strong. The authors comment on the effects of relaxing it for the data-generating process. Is the assumption also crucial for Lemma and Theorem 4.1? \n- The authors write *\"However, a quick calculation of the forward pass reveals that weights trained to optimality with AR(s) tokens (7) for $s \\geq 2$ do not implement GD in the forward pass\"*. Does it mean the suggested procedure cannot be verified empirically? \n- The experimental results focus on the attention parameters. Except for the *quick calculation of the forward pas* mentioned above, the authors do not provide any evidence that the learned model performs gradient descent in context, which, to my understanding, is the paper's main claim.\n- The length of the sequences used in the experiments is 30. Is the same length used for in-context testing?"}, "questions": {"value": "- Why is the Gaussianity assumption necessary? Wouldn't requiring the noise to have a zero mean be enough?\n- Once data matrices are formed, the problem reduces to standard linear regression. Is the extra challenge the sum over $k$ in Equation 9? Aren't $Y_t|Y_{t-1}$, $t=1, \\dots, T$ i.i.d. when the model is stationary?\n- What do you mean by *\"temporal scaffold closer in nature to that of language-induced tokens, in stark contrast to the i.i.d.\"*?\n- What happens if the state-transition matrix is not diagonal? Would $W_{QK}$ and $W_V$ still have the structure shown in Lemma 4.1? \n- Does the idea generalise to i) multi-step GD and ii) larger sliding windows?\n- In the discussion, you say that the model does not implement GD for $s\\geq 2$. Does this falsify the theoretical equivalence claimed in the abstract? Is the *\"recursive pattern of the optimal weights that builds on top of the GD inducing parameters recovered for AR(1)*\" predicted by the theory?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "0FYO0EWoTt", "forum": "os7OLubIMI", "replyto": "os7OLubIMI", "signatures": ["ICLR.cc/2026/Conference/Submission19820/Reviewer_yeiD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19820/Reviewer_yeiD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19820/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761481703753, "cdate": 1761481703753, "tmdate": 1762931901459, "mdate": 1762931901459, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates how a single linear self-attention layer can perform in-context learning (ICL) on data generated by linear dynamical systems (LDS)—a non-i.i.d. setting relevant to time-series and control problems. The authors derive theoretical results showing that the optimal linear-attention weights correspond to a gradient descent (GD) step on an autoregressive loss for first-order systems, extending prior work on ICL beyond the i.i.d. regime. They also identify structural patterns in optimal parameters for higher-order autoregressive models and support their findings with numerical experiments."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- This paper povides one of the first formal analyses of transformers’ in-context learning behavior on non-i.i.d. time-dependent data (LDS), bridging ICL theory with system identification literature.\n\n- Experimental results confirm the theoretical findings and reveal recurring structural patterns in optimal weights for higher-order autoregressive tasks."}, "weaknesses": {"value": "- The assumptions in this paper suggest that the non-i.i.d setting seems to be overly simplified, each sample seems to be just a sum from previous ones after some scalings. This setting leads to a significant mismatch with real-life data. Addition to this, a single linear attention layer is studied. This model is also entirely far from a transformer often used in practice. Those facts lead to concern about the significance of their result to understand transformer's expressive power.\n- The optimality proof is limited to first-order systems; higher-order cases are only supported empirically without a full theoretical guarantee."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "MMczhzSK4V", "forum": "os7OLubIMI", "replyto": "os7OLubIMI", "signatures": ["ICLR.cc/2026/Conference/Submission19820/Reviewer_hQkJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19820/Reviewer_hQkJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19820/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761879510530, "cdate": 1761879510530, "tmdate": 1762931898402, "mdate": 1762931898402, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates the expressive power of a single linear attention layer for in-context learning of Linear Dynamical Systems (LDS) using non-i.i.d. data. The main result demonstrates that, for a first-order autoregressive approximation, the optimal linear attention layer effectively performs one step of gradient descent (GD) on the corresponding least-squares loss."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The main strength of the paper lies in its consideration of the challenging non-i.i.d. setting and its rigorous theoretical contribution. The authors formally prove that, for an order-one autoregressive approximation of a Linear Dynamical System, the optimal single linear attention layer corresponds to one step of gradient descent on the associated least-squares loss. Overall, the theoretical analysis is well-motivated and provides an interesting and valuable contribution to the understanding of the expressive power of linear attention mechanisms."}, "weaknesses": {"value": "One of the main weaknesses of the paper lies in its presentation, which is at times convoluted and difficult to follow. Furthermore, since the paper’s primary contribution is theoretical, placing the key proofs in the appendix somewhat weakens its overall clarity and impact. Regarding the theoretical results, an additional limitation that reduces the paper’s significance is that the optimality result (Theorem 4.1), which demonstrates that the transformer performs one step of Gradient Descent on the least-squares loss, is restricted to the order-one autoregressive approximation of the Linear Dynamical System. Another substantial limitation lies in Assumption 3.2, which imposes a highly simplified structure on the linear dynamical system by restricting the matrix A to be diagonal with distinct, nonzero entries. While this choice facilitates analytical tractability, it eliminates interactions between state variables and therefore limits the applicability of the results to realistic systems exhibiting coupled dynamics. Moreover, the assumption that both the process and observation noise are Gaussian and isotropic further simplifies the analysis but fails to capture the correlated or non-Gaussian noise commonly encountered in real-world scenarios. The authors should also consider citing and discussing related recent work, such as Zhang, Yedi, et al. “Training dynamics of in-context learning in linear attention.” arXiv preprint arXiv:2501.16265 (2025), which similarly analyzes the expressive power and mechanistic basis of ICL within minimal transformer architectures.\nRegarding the empirical study, the rationale behind the proposed experimental setup is not entirely convincing. It remains unclear how several hyperparameters (such as T, d, and the number of iterations) were selected and how their choice may have influenced the results. For instance, the noise margin, which appears to play a crucial role, is fixed, yet no explanation is provided for how its value was determined. The authors should clarify the sensitivity of the analysis and the observed recursive patterns to these parameter choices."}, "questions": {"value": "- The optimality result in Theorem 4.1 is restricted to the order-one autoregressive approximation of the Linear Dynamical System. Do the authors expect their findings to extend to higher-order cases, and if so, under what assumptions?\n\n- How sensitive are your results to relaxing Assumption 3.2, for example in systems with coupled (non-diagonal) dynamics or correlated, non-Gaussian noise?\n\n- Could the authors elaborate on how the key hyperparameters were selected and discuss how sensitive the empirical results are to changes in these parameters?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "miyrqFao7X", "forum": "os7OLubIMI", "replyto": "os7OLubIMI", "signatures": ["ICLR.cc/2026/Conference/Submission19820/Reviewer_jZgQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19820/Reviewer_jZgQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19820/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761950182250, "cdate": 1761950182250, "tmdate": 1762931896491, "mdate": 1762931896491, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the theoretical behavior of linear attention layers when provided sequences generated by linear dynamical systems (LDS), aiming to understand how transformers can perform in-context learning under temporally correlated data. It was shown that for first-order autoregressive processes, the optimal weights of a linear attention layer perform a single gradient descent step on the least-squares estimation objective, essentially mirroring Kalman filtering updates. It is further shown which structured pattern the learned weights exhibit for higher-order AR models. Experiments on synthetic LDS data support these claims, suggesting that transformers can emulate filtering-like inference dynamics without explicit supervision."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper presents a clear theoretical analysis linking linear attention updates to gradient descent steps in linear dynamical systems. The extension of the understanding of in-context learning ICL beyond i.i.d. data to temporally correlated, non-i.i.d. sequences is conceptually \nsignificant."}, "weaknesses": {"value": "The scope is somewhat narrow: the main result holds only for AR(1) processes, with higher-order cases supported empirically rather than analytically, and the experimental validation remains limited to small synthetic settings.\n\nAssumption 3.2 (lines 207-208) appears rather limiting -- diagonal A, combined with the assumptions on the noise covariance matrix stated as part of Assumption 3.1, implies that the dynamics of the components of the state vector in (1) are completely separable. The assumption c = 1_d (part of Assumption 3.2) is also limiting."}, "questions": {"value": "It is stated in the paper that Assumption 3.2 can be \"relaxed to symmetry at the expense of added complexity in the later data sampling step.\" This should be elaborated upon: what would be the path forward for more general A and c?\n\nThe core analytical result is for AR(1) / first-order LDS. Can you clarify precisely which parts of the argument fail for AR(p) with p > 1? Is it a technical difficulty (algebra gets intractable) or a fundamental obstacle (the correspondence to a single GD step is no longer true)? This matters for how general the claimed mechanism actually is.\n\nIs the linear attention update / Kalman-style filtering analogy exact (i.e., the attention layer implements the same update under the assumptions), or qualitative (as in \"both reduce prediction error using recent context\")? It would help if this is stated explicitly, i.e., if  exact equivalence under stated assumptions is precisely established... otherwise, one might get an impression that attention simply learns to mimic the effect of an adaptive linear predictor under LDS-generated data. Either way, precision would be beneficial.\n\nThe Discussion section makes several statements about prior work that appear overstated. For instance, lines 358–359 claim this is the only work addressing noisy LDSs apart from Cole et al. '25, yet Goel and Bartlett '24 (already cited) analyze a similar and more general LDS model without assuming Assumption 3.2. Likewise, the statement in lines 368–371 that prior KF-emulating transformers require complete knowledge of system parameters seems inconsistent with published claims of robustness to partial parameter availability in that approach.\n\nWhile the focus of the paper is on LDS + Gaussian inputs, an insight into what happens if the noise is not Gaussian but the system is still linear would be appreciated. Likewise, even a brief discussion on potential directions and/or expectation in non-linear + non-Gaussian case would be helpful."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dcygjrIkS2", "forum": "os7OLubIMI", "replyto": "os7OLubIMI", "signatures": ["ICLR.cc/2026/Conference/Submission19820/Reviewer_2rfD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19820/Reviewer_2rfD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19820/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972157686, "cdate": 1761972157686, "tmdate": 1762931891027, "mdate": 1762931891027, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates in-context learning (ICL) for non iid sequential data, addressing a critical gap in the theoretical understanding of transformers. This paper takes the first step toward sequential data by studying Linear Dynamical Systems (LDS). The authors prove that for order-one autoregressive (AR(1)) approximations, the optimal linear attention layer implements exactly one step of Gradient Descent on the context-dependent least-squares loss. The key insight is that AR(s) models can closely approximate Kalman Filter predictions when the window size s is sufficiently large. The authors identify structural patterns for higher-order cases and provide experimental validation. The connection to language modeling is still distant, but this result represents the first optimality result for ICL with non-i.i.d. data extending the optimization framework from independence to temporal dependence."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "* The paper is well written, well organized.I am far from being a theoretical specialist in the field, but the problem is very clearly understandable, as are the SOTA and the paper's positioning in the literature.\n* Extends ICL theory to noise-corrupted dynamical systems with non iid data, more realistic scenario.\n*  Provides Mechanistic Explanation for Transformer-Kalman Filter connection\n* Solid theoretical contribution for AR(1) with Noise (theorem 4.1)\n* structural insight for higher orders (banded structures etc).\n* limitations are well discussed."}, "weaknesses": {"value": "* in my opinion, some assumptions are highly restrictive (diagonal A for LDS, independance of the evolution of each dimension), with no clear insights how to generalize beyond the assumption.\n* The  proof is only for AR(1), the results for s>=1 are only empirical."}, "questions": {"value": "You state  that AR(s≥2) optimal weights do not \nimplement gradient descent. However, you observe an intriguing \nrecursive pattern  where AR(s+1) structure embeds \nforward-shifted AR(s) structure. Can you clarify your current undestanding ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "o7731fKa1J", "forum": "os7OLubIMI", "replyto": "os7OLubIMI", "signatures": ["ICLR.cc/2026/Conference/Submission19820/Reviewer_JMPY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19820/Reviewer_JMPY"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission19820/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762798862813, "cdate": 1762798862813, "tmdate": 1762931841216, "mdate": 1762931841216, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}