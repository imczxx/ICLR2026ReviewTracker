{"id": "gv8R88PVEG", "number": 13489, "cdate": 1758218547626, "mdate": 1759897433411, "content": {"title": "FlowCast: Trajectory Forecasting for Scalable Zero-Cost Speculative Flow Matching", "abstract": "Flow Matching (FM) has recently emerged as a powerful approach for high-quality visual generation. However, their prohibitively slow inference due to a large number of denoising steps limits their potential use in real-time or interactive applications. Existing acceleration methods, like distillation, truncation, or consistency training, either degrade quality, incur costly retraining, or lack generalization. We propose FlowCast, a training-free speculative generation framework that accelerates inference by exploiting  the fact that FM models are trained to preserve constant velocity. FlowCast speculates future velocity by extrapolating current velocity without incurring additional cost, and accepts it if it is within a mean-squared error threshold. This constant-velocity forecasting allows redundant steps in stable regions to be aggressively skipped while retaining precision in complex ones. FlowCast is a plug-and-play framework that integrates seamlessly with any FM model and requires no auxiliary networks. We also present a theoretical analysis and bound the worst-case deviation between speculative and full FM trajectories. Empirical evaluations demonstrate that FlowCast achieves $>2.5\\times$ speedup in image generation, video generation, and editing tasks, outperforming existing baselines with no quality loss as compared to standard full generation.", "tldr": "FlowCast accelerates Flow Matching inference via training-free speculative generation, using constant-velocity forecasting to skip redundant steps, achieving >2.5× speedup without quality loss.", "keywords": ["Flow Matching", "Speculative Decoding", "Inference Acceleration", "Training-Free", "Generative Models", "Zero-Cost Drafts", "Parallel Verification", "Adaptive Sampling"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/64958274201ffcf3b80d52ce7ce0c2371c36b01d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes FlowCast, a training-free speculative inference scheme for Flow Matching (FM) models. Observing that FM trajectories exhibit locally constant/slowly varying velocity, FlowCast linearly extrapolates future states using the current velocity (“zero-cost drafts”) and verifies them via a lightweight MSE check on predicted velocities. Accepted drafts allow aggressive step skipping in stable regions; rejections trigger fallback to standard updates. The authors provide a deviation bound relating the acceptance threshold to worst-case trajectory error. Experiments across image generation, image editing (incl. multi-turn), and video generation report >2.5× speedups with negligible quality loss versus full 50-step sampling, and improvements over TeaCache and other accelerators."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.Training-free & plug-and-play: No distillation or auxiliary networks; applicable to diverse FM backbones and tasks.\n\n2.Clear principle & theory: A simple constant-velocity extrapolation paired with an MSE-based verifier, plus a worst-case deviation bound.\n\n3.Broad empirical coverage: Image, editing, multi-turn editing, and video; consistent speedups with small fidelity drops and fair comparisons to truncation/TeaCache."}, "weaknesses": {"value": "1.Assumption sensitivity: Reliance on locally constant/slowly varying velocity may fail for sharp dynamics (e.g., complex edits, rapid motion), but stress tests are limited.\n\n2.Parallel verification cost: Speedups hinge on verifying many drafts in parallel; wall-clock gains on constrained hardware are unclear.\n\n3.Metric breadth: Quality is mostly CLIPIQA/GenEval/vBench/BRISQUE; limited human or task-specific fidelity/temporal metrics to substantiate “no quality loss.”"}, "questions": {"value": "1.How does FlowCast behave under deliberately adversarial schedules with rapid velocity changes ? Any failure analyses?\n\n2. What are end-to-end wall-clock gains on a single-GPU, limited-memory setting (no tensor-parallel drafts)? Please report FLOPs/latency breakdown for verification vs. baseline.\n\n3. Can the acceptance threshold ϵ be adapted online (e.g., via Lipschitz/variance estimates) to trade speed for quality automatically? Any guidance for setting ϵ per model/task?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "l7T4W05ZwQ", "forum": "gv8R88PVEG", "replyto": "gv8R88PVEG", "signatures": ["ICLR.cc/2026/Conference/Submission13489/Reviewer_2jF7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13489/Reviewer_2jF7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13489/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761947744473, "cdate": 1761947744473, "tmdate": 1762924106787, "mdate": 1762924106787, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes FlowCast, a training-free speculative generation framework that accelerates inference by exploiting the fact that FM models are trained to preserve constant velocity. \n\nFlowCast speculates future velocity by extrapolating current velocity without incurring additional cost, FlowCast is a plug-and-play framework that integrates seamlessly with any FM model and requires no auxiliary networks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- the paper is well-written and easy to follow\n- the method is training-free and plug-and-play"}, "weaknesses": {"value": "- the motivation to predict future velocity based on known ones is not fully justified. In few-step sampling the velocity actually varies a lot in adjacent steps. \n- experiments on text-to-image generation is not very comprehensive, only some cherry-picked simple cases is shown\n- the performance drop (e.g., from 0.78 to 0.57) is unacceptable. In image generation, we would prefer high-quality instead of fast-speed."}, "questions": {"value": "- How do different designs of verifier affect the performance?\n- Please compare the performance with training-based methodsl."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "vYkZUokJbs", "forum": "gv8R88PVEG", "replyto": "gv8R88PVEG", "signatures": ["ICLR.cc/2026/Conference/Submission13489/Reviewer_wbif"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13489/Reviewer_wbif"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13489/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761987566347, "cdate": 1761987566347, "tmdate": 1762924106503, "mdate": 1762924106503, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces FlowCast, a training-free speculative generation framework designed to accelerate the notoriously slow inference process in Flow Matching (FM) models. The core idea capitalizes on the observation that FM trajectories, particularly in well-trained models, are locally smooth and can be accurately modeled as having near-constant velocity. FlowCast creates \"zero-cost drafts\" by simply extrapolating future steps using the model's most recent velocity prediction, thus eliminating the overhead of auxiliary drafting networks or time-consuming retraining. These predicted steps are then verified in parallel using a swift mean-squared error check on the velocity field. This adaptive, dynamic mechanism enables the model to aggressively skip redundant computations in stable regions while ensuring full fidelity in complex, rapidly changing areas of the generation trajectory.\n\nFlowCast is a plug-and-play solution applicable to any FM model and task, demonstrating broad versatility. A key contribution is the theoretical derivation of an error bound that formally controls the maximum deviation between the speculative trajectory and the precise full-step integration. Extensive empirical evaluations across image generation, complex image editing, and video generation confirm its effectiveness. The results show that FlowCast consistently delivers substantial speedups, typically over $2.5\\times$, while successfully preserving output quality that is indistinguishable from the original, unaccelerated generation, positioning it as a preferred method for real-time and interactive generative applications."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "+ FlowCast's core mechanism uses the model's own previous velocity prediction as a draft, incurring zero additional training or computational overhead for the drafting phase.\n\n+ The framework integrates seamlessly with any existing FM model and is successfully demonstrated across image generation, image editing, multi-turn editing, and video generation tasks, showcasing its broad applicability.\n\n+ FlowCast dynamically adapts the number of steps skipped based on the local complexity of the generation trajectory (Figure 9), ensuring maximal speedup while preserving fidelity—a clear advantage over static reduction methods.\n\n+ The framework is supported by a theoretical error bound (Theorem $4.2$) which formalizes the maximum allowable deviation based on the threshold $\\epsilon$, ensuring reliability and rigor."}, "weaknesses": {"value": "The main practical limitation acknowledged in the conclusion is FlowCast's dependence on adequate compute for parallel verification of drafts, where cutting drafts reduces overhead but also limits speedup. While the verification step is performed in a single forward pass for parallel drafts, the overall efficiency gain is bounded by the available parallelism. While the paper provides empirical guidance for setting the threshold $\\epsilon$ for different tasks (e.g., $\\epsilon \\in [0.01, 0.02]$ for image generation), a generalized, non-empirical approach or model-dependent estimation of the Lipschitz constant $M$ and the second derivative bound $N$ in Lemma $4.1$ would enhance the theoretical contribution's utility for arbitrary FM models. The comparison against TeaCache, although demonstrating FlowCast's superiority, focuses on TeaCache's non-adaptive nature, but a more direct quantitative comparison of the maximum quality achieved by both methods at a fixed, competitive speedup could further clarify the trade-off space."}, "questions": {"value": "- The theoretical bound in Theorem $4.2$ requires the Lipschitz constant $M$ and the probability of acceptance $p$, both of which are challenging to determine analytically for a new FM model. Can the authors discuss approaches to estimate $M$ and $N$ for a given trained FM model without resorting to extensive validation steps, or how the empirically derived $\\epsilon$ relates back to the theoretical bounds? \n\n- Figure 6 and Table 5 show that FlowCast is complementary to TeaCache. Can the authors provide a more detailed analysis, possibly through an ablation, of the combined method (TeaCache $+$ FlowCast) to explain why the gains are not simply additive, and what type of redundancy each method primarily targets within the diffusion trajectory? \n\n- Given that FlowCast relies on the ODE being locally smooth (constant velocity assumption), how does the performance scale when applied to rectified flow variants (like the one used in the PeRFlow experiment), where the velocity field is explicitly straightened to be nearly constant over the entire path?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "iIKxRANQ6B", "forum": "gv8R88PVEG", "replyto": "gv8R88PVEG", "signatures": ["ICLR.cc/2026/Conference/Submission13489/Reviewer_jE6u"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13489/Reviewer_jE6u"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13489/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998156968, "cdate": 1761998156968, "tmdate": 1762924106232, "mdate": 1762924106232, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This manuscript proposes a FlowCast method, which is a training-free speculative generation framework accelerating inference. The proposed method is a plug-and-play framework and can be integrated into different FM models. Experimental results on different tasks demonstrate the efficiency of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "-\tThe proposed method is training-free and model-agnostic.\n-\tThe key insight is good. The method pinpoints and exploits a core property of FM—local smoothness and near-constant velocities—turning the model’s own current velocity into a “zero-cost” draft and verifying in velocity space. This aligns perfectly with FM’s dynamics, enabling aggressive step skipping in stable regions while preserving fidelity, and it explains both the simplicity and effectiveness of the approach.\n-\tSubstantial inference acceleration."}, "weaknesses": {"value": "-\tIn Table 1, provide profiling of memory footprint and latency of speculative vs. existing methods.\n-\tDiscuss the failure case or limitation of the proposed method.\n-\tThe manuscript organization can be improved. Such as the Eq.5 in L244.\n-\tA more comprehensive comparison of the proposed method in term of computation complexity, memory usage and so are expected."}, "questions": {"value": "-\tIs the SD method limited to the FM models? Can it be applied to other image/video generating methods such as diffusion models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cdY1sRqSPf", "forum": "gv8R88PVEG", "replyto": "gv8R88PVEG", "signatures": ["ICLR.cc/2026/Conference/Submission13489/Reviewer_1Hsg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13489/Reviewer_1Hsg"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13489/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762111012468, "cdate": 1762111012468, "tmdate": 1762924104446, "mdate": 1762924104446, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}