{"id": "SRn1MtMPRq", "number": 12455, "cdate": 1758207950469, "mdate": 1759897509034, "content": {"title": "Emergent Coordination in Multi-Agent Language Models", "abstract": "When are multi-agent LLM systems merely a collection of individual agents versus an integrated collective with higher-order structure? We introduce an information-theoretic framework to test---in a purely data-driven way---whether multi-agent systems show signs of higher-order structure. This information decomposition lets us measure whether dynamical emergence is present in multi-agent LLM systems, localize it, and distinguish spurious temporal coupling from task-relevant cross-agent synergy. We implement both a practical criterion and an emergence capacity criterion  operationalized as partial information decomposition of time-delayed mutual information (TDMI). We apply our framework to experiments using a simple guessing game without direct agent communication and only minimal group-level feedback with three randomized interventions. Groups in the control condition exhibit strong temporal synergy but only little coordinated alignment across agents. Assigning a persona to each agent introduces stable identity-linked differentiation. Combining personas with an instruction to ``think about what other agents might do'' shows identity-linked differentiation and goal-directed complementarity across agents. Taken together, our framework establishes that multi-agent LLM systems can be steered with prompt design from mere aggregates to higher-order collectives. Our results are robust across different indicators of emergence, alternative approaches to estimating entropy, and residualizing data of time trends. Without attributing human-like cognition to the agents, the patterns of interaction we observe mirror well-established principles of collective intelligence in human groups: effective performance requires both alignment on shared objectives and complementary contributions across members.", "tldr": "Information-theoretic framework reveals how prompt design steers multi-agent LLMs from simple aggregates to emergent collectives with higher-order structure", "keywords": ["multi-agent systems", "LLMs", "information decomposition", "emergence", "collective intelligence"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/01bb57d58da3a3c69e424d2dea2e615ddded2a9c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The recent advancements in large language models have showcased the effectiveness of multi-agent systems. However, the authors argue that the performance gains in these multi-agent systems are not well understood, beyond the emergent behavior due to from interacting specialist agents. The core motivation is then to determine the threshold when a population of LLM agents transfers from a collection of agents into a productive collective. The authors investigate a group guessing game where agents must propose integers such that all integers sum a hidden unknown target, where the only feedback is binary high/low of the group sum. For this task to be successful, members of the group must fulfill complementary roles in an emergent way. The authors formulate three heuristics to measure the group synergy and emergence with the goal of quantifiability: practical criterion (prediction of delayed-release macro signal from instantaneous agent states), emergence capacity (median synergy estimate across all agent pairs), and coalition test (difference in predictive ability of a triplet compared to its most predictive pair). Each heuristic covers some needed insight that may not be available by the other heuristics. \n\nThe heuristics are used across two tests alongside null distribution: shuffling row wise to break agent identities, and shuffling column-wise to break time alignment. The authors propose a separate series of hierarchical models to differentiate agents across rounds. The main intervention in the paper is changing the text prompt input of each LLM agent, using either plain prompts (treating LLMs as human subjects), persona prompts (instructing each agent to respond conditional on anthropomorphic attributes), and theory of mind prompts (instructing agents to act based on what they perceive other agents to think). Empirical experiments using GPT4.1 and Llama-3.1-8b first showed that practical criterion for emergence is satisfied regardless of intervention. Next the hierarchical model showed that the most differentiation among agents occurs for Persona and ToM prompting. The coalition test is used to show that ToM agents tend towards higher task mutual information while coalition signal was lower, suggesting that among pairs of agents in the ToM set, there is a reinforcement of established roles with respect to the group goal. This is in contrast to the Persona set, which has a similar total mutual information to Plain (Figure 3b). A subset of experiments were repeated on Llama-3.1-8b but had mixed results due to the reduced generalization ability."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The authors investigate the problem of emergent synergy in LLM-based agents, which is relevant to the NLP and multi-agent research communities, yet difficult to quantify. Tools from information theory and partial information decomposition are used to propose three heuristics.\n- The heuristics provide measurement tools to study task alignment among triads and pairs of agents, alongside the grounding of agent micro-states in the delayed system signal (practical criterion). These heuristics could have significance for the broader research community in studying emergent synergy of multi-agent systems.\n- The authors provide confidence values and error margin for each reported result. The plot rendering is generally high quality with only minor issues in some figures. The writing quality is high enough to convey the technical points.\n- The empirical analysis reveals some interesting insights about tuning LLM prompts to use ideas from ToM with GPT 4.1. These ideas do not necessarily transfer over to smaller models such as LLama-8b. An interesting takeaway from the analyses was that ToM prompts may reinforce pairwise identity assignments given to agents. The pairwise reinforcement, qualitatively speaking, may be reinforced first by the original system prompt of an agent, and again by the other agents projecting the identity onto the same agent during ToM reasoning.\n- For the group sum task, it is shown that triadic synergy may be spurious compared to strictly pair-wise synergy, in fact it may be detrimental as evidenced by Persona and ToM coalition measurements."}, "weaknesses": {"value": "- The writing in some sections could be clarified to help motivate heuristics and models. For example \"Test of Agent Differentiation\" mixed model is not well motivated as a heuristic until reaching the results in Section 4.2, some sign posting would help clarify the utility.\n- Some conceptual details are not clear or self contained, such as the author's use of PID (L157), it is not clear how unique information and redundant information are formulated for the group sum task.\n- The notation needs some clarification to make the proposed formulation self-contained: the variables $t$, $l$, $k$ (L138-L144) should be introduced more naturally, and choice of $devs$ for target deviations may be changed to a single bold-face letter.\n- Typos: L335-L344 Figure 3 is referenced as Figure 4, L480 emergency -> emergent\n- Vertical figure subtitles are difficult to read and tend to clash with the figure identifier."}, "questions": {"value": "- Considering the lower $G_3$ of ToM agents in Figure 3c, do the authors still see utility in the coalition test heuristic as a measure of the system's emergent synergy? It would seem that simply using the pairwise mutual information says more about the system capability than a triad approach in the group sum setting. In other words, for the specific task of group sum, triadic mutual information does not appear necessary for task success since Persona and Plain score higher, so it may be misleading to label triadic synergy as \"dynamical emergent synergy\" when pairwise synergy suffices."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3pWI5pMrUh", "forum": "SRn1MtMPRq", "replyto": "SRn1MtMPRq", "signatures": ["ICLR.cc/2026/Conference/Submission12455/Reviewer_st12"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12455/Reviewer_st12"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12455/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761700312783, "cdate": 1761700312783, "tmdate": 1762923335301, "mdate": 1762923335301, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates whether multi-agent LLM systems exhibit emergent collective properties beyond individual agents. The authors develop an information-theoretic framework using partial information decomposition and time-delayed mutual information to quantify synergy in multi-agent systems. They test this framework on a number guessing game under three conditions: plain instructions, assigned personas, and theory-of-mind prompting. Results show all conditions exhibit statistical synergy, with different coordination patterns across interventions. The ToM condition displays higher mutual information and lower emergent synergy compared to other conditions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1. The paper addresses the important and novel question of when multi-agent systems exhibit collective intelligence that transcends the sum of individual agents, which is crucial for exploring MAS capabilities and LLM potential.\n\nS2. The authors adapted an appropriate experimental paradigm from cognitive science work (the group guessing game), which inherently requires collective group interaction.\n\nS3. ToM prompting induces identity-locked differentiation and goal-directed complementarity, which to some extent distinguishes whether synergy is genuinely functional.\n\nS4. The experimental design incorporates robust validity checks and null hypotheses, such as employing multiple entropy estimators and redundancy measures in partial information decomposition (PID). Additionally, the sample size is sufficient to ensure statistical significance."}, "weaknesses": {"value": "W1. The experiments may have limitations in causal inference. For instance, the Persona and ToM interventions simultaneously alter multiple factors. Designing separate control groups to isolate these two factors could better explain the causal relationships in the experiments.\n\nW2. Figure 2(a) shows no statistically significant differences in success rates across different interventions, suggesting that ToM may not necessarily be optimal, and that the effectiveness of synergy requires stronger evidence. Under ToM intervention, I3 is higher than G3. High I3 indicates that agent behaviors contain substantial information about group goals, but it remains unclear whether this information is redundant or complementary. G3 indicates whether observations of agents can be decomposed into pairwise relationships. The paper explains these results as distinguishing effective from spurious synergy, with low G3 being a sign of alignment. However, this does not rule out the phenomenon of apparent alignment due to excessive agent homogenization rather than better coordination. Furthermore, high I3 does not lead to better task performance. I3 may only measure information quantity rather than quality, or the task itself may not require complex synergy to solve. Therefore, I believe ToM may indeed change the interaction patterns between agents, but further validation is needed regarding I3's predictive power and whether ToM can be claimed as a superior mode.\n\nW3. The term \"emergence\" may be overused in this paper. Synergy does not necessarily represent the emergence of collective intelligence; it merely indicates that the joint predictive ability of agents exceeds the sum of their individual predictive abilities, which does not imply any cooperation or specialized roles. The paper is potentially imprecise in claiming specialized roles, using hierarchical models showing significant agent-level random intercepts and G3>0 as evidence. However, this cannot necessarily be attributed to roles but may stem from temperature randomness or prompt differences in the persona condition. It is difficult to determine whether this represents emergent behavior or merely the result of prompt engineering."}, "questions": {"value": "C1. Quantile binning with K=2 may lose critical dynamic information by binarizing continuous guess values. Moreover, under K=3 bins, the ToM condition shows p=0.991 for emergence capacity, and the paper does not explain this problematic value."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8hScBJXCrR", "forum": "SRn1MtMPRq", "replyto": "SRn1MtMPRq", "signatures": ["ICLR.cc/2026/Conference/Submission12455/Reviewer_EcL2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12455/Reviewer_EcL2"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12455/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762016967274, "cdate": 1762016967274, "tmdate": 1762923334608, "mdate": 1762923334608, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework to test whether multi-agent LLM systems exhibit emergent coordination and higher-order structure (above and beyond mere collections of individuals). The authors apply partial information decomposition (PID) of time-delayed mutual information (TDMI) to measure dynamical emergence in multi-agent systems solving a group guessing game. Through experiments with GPT-4.1 and Llama-3.1-8B agents under three prompt conditions (control, persona assignment, and personas with theory of mind instructions), they demonstrate that multi-agent LLM systems can be steered from simple aggregates to integrated collectives exhibiting goal-directed synergy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "To my knowlege, this work is the first systematic application of information theoretical (PID/TDMI) framework to LLM multi-agent systems. I really like prompt manipulations to demonstrate that coordination patterns can be influenced by prompt engineering. Multiple permutation tests and bias correction methods have been leveraged."}, "weaknesses": {"value": "1. While the emergent properties of LLM collective groups are well-characterized through TDMI, it is less clear \"why\" they show these patterns of emergent coordination. Is it because they actually lead to performance gains? (i.e., they coordinate because that's actually helpful to find the solution) Or do they simply emerge from mimicking human behavioral patterns in their training data, regardless of performance benefits? Figure 2 shows no clear performance differences between Plain, Persona, and Persona + ToM conditions, and the paper does not directly show LLM performance with vs. without emergent coordination, so it's hard to assess whether their emergent coordination really drives the performance.\n\n2. The abstract claims LLM coordination patterns \"mirror well-established principles of collective intelligence in human groups,\" so I hoped to see more comparisons between human vs. LLMs. Without human baseline data (or cited literature) using the same TDMI measures, it was hard to assess whether LLM collectives are more, less, or equally emergent compared to humans.\n\n3. Single task, dramatic model-dependency (GPT-4.1 vs Llama-3.1 show opposite patterns)"}, "questions": {"value": "1. I hope to see several methodological details:\n- Were the same 20 personas reused across 200 experiments or regenerated by GPT?\n- How were N=10 personas selected for agents in each run? (randomly selected? fixed? or based on certain criteria?)\n- Could you provide full examples of actual personas provided? (full 20 persona)\n- These ambiguities affect interpretation: are effects (i.e., \"persona\" effects) due to having \"distinct identities\" or \"specific persona combinations\"? (i.e., is the effect driven by having \"any distinct persona\" or having \"certain set of persona\"?)\n\n2. The role of \"ToM prompt\" is a bit unclear to me. The task inherently requires considering others' contributions (summing to target). What does the ToM prompt add beyond this implicit requirement?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "M9tRqhbKmh", "forum": "SRn1MtMPRq", "replyto": "SRn1MtMPRq", "signatures": ["ICLR.cc/2026/Conference/Submission12455/Reviewer_Hc1h"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12455/Reviewer_Hc1h"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12455/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762175493620, "cdate": 1762175493620, "tmdate": 1762923334236, "mdate": 1762923334236, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper explores when multi-agent LLM systems exhibit genuine higher-order structure—that is, coordination dynamics that go beyond mere aggregation of individual behaviors. The authors introduce an information-theoretic framework to test for dynamical emergence and cross-agent synergy using partial information decomposition (PID) and time-delayed mutual information (TDMI). They formalize three complementary tests—practical, emergence capacity, and coalition tests—to detect and localize synergy among agents in data-driven experiments. The empirical analysis uses GPT-4.1 and LLaMA-3 agents playing a “group guessing” task without explicit communication, under various prompting conditions (Control, Persona, ToM). The results show that only the Theory-of-Mind (ToM) condition leads to consistent “goal-directed” synergy and identity-linked differentiation across agents. The findings connect principles of collective intelligence from human groups to emergent behavior in LLM collectives."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper tackles a timely and underexplored question—whether multi-agent LLM collectives can exhibit emergent higher-order coordination—through a rigorous, information-theoretic lens.\nThe proposed framework is conceptually elegant and connects human-group cognition with quantitative, falsifiable tests for emergence. The use of partial information decomposition and time-delayed mutual information is particularly novel in the context of LLM collectives, moving beyond superficial behavioral correlations. The three-layered test design (practical, emergence capacity, coalition) provides complementary diagnostics and robustness checks. The authors are careful to isolate emergent coordination from spurious synchronization or heterogeneity-induced artifacts via well-chosen surrogate null models.\n\nThe experimental setup is simple but powerful: a communication-free group guessing game allows the authors to observe spontaneous coordination. The finding that prompting agents to adopt Theory-of-Mind reasoning produces structured, goal-aligned differentiation is compelling and resonates with the literature on human collective cognition. Overall, the work offers a rigorous empirical entry point to the study of collective behavior in AI systems, a topic of growing significance for multi-agent AI safety and orchestration."}, "weaknesses": {"value": "While the empirical results are intriguing, the theoretical underpinnings of the framework could be deepened. The notion of “emergence” here is operationalized through information decomposition, but the connection between these information-theoretic quantities and game-theoretic or dynamical systems perspectives remains underdeveloped. For instance, one might ask:\n\t•\tCan the framework be linked to known fixed-point or equilibrium concepts (e.g., correlated equilibria, variational stability) to characterize steady-state synergy?\n\t•\tIs the “macro signal” in their tests analogous to a coarse-grained order parameter in dynamical systems theory, and could Lyapunov-like quantities be defined to formalize stability of emergent coordination?\n\t•\tHow does the introduced TDMI-based synergy relate to mutual predictability under stochastic gradient dynamics or belief-updating processes?\nDeveloping a mathematical bridge to these established theories could significantly increase the conceptual depth of the paper.\n\nIn addition, the paper’s experimental validation—while extensive—focuses on a single synthetic task. It would be valuable to test whether the same synergy measures predict performance or alignment quality in richer multi-agent environments (e.g., collaborative reasoning or negotiation tasks). The robustness of the results to changes in LLM temperature, prompt diversity, and task complexity could also be more systematically analyzed.\n\nFinally, while the authors emphasize “no communication,” there remains an implicit shared context via prompts and the task description, which could bias coordination outcomes. A discussion on how to distinguish true emergent coordination from shared prompt priors would improve the interpretability of results."}, "questions": {"value": "ΝΑ"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wFX6c2sINO", "forum": "SRn1MtMPRq", "replyto": "SRn1MtMPRq", "signatures": ["ICLR.cc/2026/Conference/Submission12455/Reviewer_A7pR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12455/Reviewer_A7pR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12455/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762313683934, "cdate": 1762313683934, "tmdate": 1762923333921, "mdate": 1762923333921, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}