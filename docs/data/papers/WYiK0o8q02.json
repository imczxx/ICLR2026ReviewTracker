{"id": "WYiK0o8q02", "number": 20588, "cdate": 1758307979303, "mdate": 1763737261194, "content": {"title": "TRACE: Theoretical Risk Attribution under Covariate-shift Effects", "abstract": "When a source-trained model $Q$ is replaced by a model $\\tilde{Q}$ trained on shifted data, its performance on the source domain can change unpredictably. To address this, we study the two-model risk change, $\\Delta R := R_P(Q) - R_P(\\tilde{Q})$, under covariate shift. We introduce TRACE (Theoretical Risk Attribution under Covariate-shift Effects), a framework that decomposes $|\\Delta R|$ into an interpretable upper bound. This decomposition disentangles the risk change into four actionable factors: two generalization gaps, a model change penalty, and a covariate shift penalty, transforming the bound into a powerful diagnostic tool for understanding why performance has changed. To make TRACE a fully computable diagnostic, we instantiate each term. The covariate shift penalty is estimated via a model sensitivity factor (from high-quantile input gradients) and a data-shift measure; we use feature-space Optimal Transport (OT) by default and provide a robust alternative using Maximum Mean Discrepancy (MMD). The model change penalty is controlled by the average output distance between the two models on the target sample. Generalization gaps are estimated on held-out data. We validate our framework in an idealized linear regression setting, showing the TRACE bound correctly captures the scaling of the true risk difference with the magnitude of the shift. Across synthetic and vision benchmarks, TRACE diagnostics are valid and maintain a strong monotonic relationship with the true performance degradation. Crucially, we derive a deployment gate score from the model change and covariate shift terms that strongly correlates with $|\\Delta R|$ and achieves exceptionally high AUROC/AUPRC for gating decisions, enabling safe, label-efficient model replacement.", "tldr": "We introduce TRACE, a framework to attribute the risk of model updates to data shift and model instability, providing both a practical diagnostic and a powerful automated deployment gate score.", "keywords": ["Distribution Shift", "Risk Attribution", "Optimal Transport", "Covariate Shift"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cf9181c15d5a48b61d53129de8d90252a23751a0.pdf", "supplementary_material": "/attachment/80f3e07538f51d99e343e8029a63ac1d9ea711ab.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose an interpretable analytic upper bound for a predictive model on the difference between the risk of the source model and the risk of the adapted model on the source domain. The authors identify four factors constructing the bound: generalization gap terms, empirical risk gap, and the population risk gap, and then provide a computable proxy version of the bound that replaces all population terms with empirically estimatable ones. Finally, they provide a conceptual diagnostic framework by utilizing the components of the bound to attribute model's failure."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* [`Exceptional Clarity`] The derivation of the proposed bound is easy to follow. No unnecessary complex tweak. The flow of paper is very straightforward.\n* [`Practical Bound`] The proposed bound captures multiple sources of the model's failure mode, and those sources are clearly decomposed. \n* [`User-friendly Theoretical Framework`] Not only providing just an analytic form of bound, but the authors explicitly instantiate all the individual components of the proposed bound, so that one can easily leverage it.\n* [`Appropriate Descriptions on Application and Example`] Besides, the authors give a diagnostic pipeline to attribute the model's failure and provide minimal working examples (Ridge Regression on a synthetic dataset and a computer vision model on a real image dataset)."}, "weaknesses": {"value": "* [`Realism of Assumptions`] The authors made some assumptions about the loss -- boundness and Lipschitz property, but did not discuss how it is in case in practice.\n* [`Discussion on the Bound Tightness`] Although I know that it is inevitable to introduce multiple inequalities to make the bound empirically computable, I believe that a discussion on how the tightness of the bound is affected by each empirical approximation and when it can achieve the tightest/loosest bound should be included.\n* [`Limited Coverage of Theoretical Framework`] The proposed framework was built on the C-way classification model. There is no discussion about how the proposed bound can be extended to a broader class of modern models.\n* [`Limited Effectiveness of Application`] As the scales of each component in the bound may differ, we don't actually know which part matters than the other parts relatively. How can we genuinely attribute the failure of the model, and how precise is it?"}, "questions": {"value": "> Minor suggestions\n* L107: I think you misuse the (\") in this sentence.\n* In the abstract L013, when you introduce $\\Delta R:= R_{P}(Q)-R_{P}(\\tilde{Q})$, how about denoting it $\\Delta R:= R_{P}(\\tilde{Q})-R_{P}(Q)$ to make it more intuitive (even though it does not matter because only the $|\\Delta R|$ will be used)? \n* Table 1 is hard to read. There are no clear descriptions of the meaning of each column.\n* Could you add an explanation of the Sinkhorn distance computation for further clarity?\n\n---\n\nIf there is any misunderstanding from me, please point it out."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tg81ONXgXn", "forum": "WYiK0o8q02", "replyto": "WYiK0o8q02", "signatures": ["ICLR.cc/2026/Conference/Submission20588/Reviewer_Tg6A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20588/Reviewer_Tg6A"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20588/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761850685062, "cdate": 1761850685062, "tmdate": 1762933996968, "mdate": 1762933996968, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose an interpretable analytic upper bound for a predictive model on the difference between the risk of the source model and the risk of the adapted model on the source domain. The authors identify four factors constructing the bound: generalization gap terms, empirical risk gap, and the population risk gap, and then provide a computable proxy version of the bound that replaces all population terms with empirically estimatable ones. Finally, they provide a conceptual diagnostic framework by utilizing the components of the bound to attribute model's failure."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* [`Exceptional Clarity`] The derivation of the proposed bound is easy to follow. No unnecessary complex tweak. The flow of paper is very straightforward.\n* [`Practical Bound`] The proposed bound captures multiple sources of the model's failure mode, and those sources are clearly decomposed. \n* [`User-friendly Theoretical Framework`] Not only providing just an analytic form of bound, but the authors explicitly instantiate all the individual components of the proposed bound, so that one can easily leverage it.\n* [`Appropriate Descriptions on Application and Example`] Besides, the authors give a diagnostic pipeline to attribute the model's failure and provide minimal working examples (Ridge Regression on a synthetic dataset and a computer vision model on a real image dataset)."}, "weaknesses": {"value": "* [`Realism of Assumptions`] The authors made some assumptions about the loss -- boundness and Lipschitz property, but did not discuss how it is in case in practice.\n* [`Discussion on the Bound Tightness`] Although I know that it is inevitable to introduce multiple inequalities to make the bound empirically computable, I believe that a discussion on how the tightness of the bound is affected by each empirical approximation and when it can achieve the tightest/loosest bound should be included.\n* [`Limited Coverage of Theoretical Framework`] The proposed framework was built on the C-way classification model. There is no discussion about how the proposed bound can be extended to a broader class of modern models.\n* [`Limited Effectiveness of Application`] As the scales of each component in the bound may differ, we don't actually know which part matters than the other parts relatively. How can we genuinely attribute the failure of the model, and how precise is it?"}, "questions": {"value": "> Minor suggestions\n* L107: I think you misuse the (\") in this sentence.\n* In the abstract L013, when you introduce $\\Delta R:= R_{P}(Q)-R_{P}(\\tilde{Q})$, how about denoting it $\\Delta R:= R_{P}(\\tilde{Q})-R_{P}(Q)$ to make it more intuitive (even though it does not matter because only the $|\\Delta R|$ will be used)? \n* Table 1 is hard to read. There are no clear descriptions of the meaning of each column.\n* Could you add an explanation of the Sinkhorn distance computation for further clarity?\n\n---\n\nIf there is any misunderstanding from me, please point it out."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tg81ONXgXn", "forum": "WYiK0o8q02", "replyto": "WYiK0o8q02", "signatures": ["ICLR.cc/2026/Conference/Submission20588/Reviewer_Tg6A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20588/Reviewer_Tg6A"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20588/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761850685062, "cdate": 1761850685062, "tmdate": 1763762722912, "mdate": 1763762722912, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces TRACE standing for Theoretical Risk Attribution under Covariate shift Effect. The key idea is to give a full diagnosis of the change in the risk when a model that was trained on a source distribution is deployed on a different target distribution. More precisely TRACE decomposes the error as the sum of 4 terms: the source generalisation gap, the target generalisation gap, the empirical discrepancy and equivalent shift penalty term under a set of hypothesis explicit expression for each of the term are given the paper then include some experiment on two dimensional synthetic dataset and DomainNet."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well written and addresses important question for transfer learning\n- The paper describes the entire pipeline to compute the estimate"}, "weaknesses": {"value": "- It is hard to compare this method with previous methods: the related work could be more explicit in this regard. \n- The discussion over the tightness of the estimated quantities is limited, in more difficult scenarios one could be afraid that bounds will be to loose to be helpful.\n- The experiment are limited to 2 dimensional data for most of it and is not detailed enough to provide a good evaluation of the method"}, "questions": {"value": "- Could you comment on assumption 3 similarly to what you have done for the other assumptions? It seems that this condition is particularly hard to achieve.\n- When using the Sinkhorn divergence, the regularisation terms make interpretation of Wasserstein distance hard is it an issue in practice? Would it be still possible to compute the trace estimate when the source dataset is large?\n- Could you detail more the experiment over DonainNet. As your method provide four different terms, would it be possible to modify each of this term to double check how precisely they are captured by your estimator?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "g3l8J56Vfa", "forum": "WYiK0o8q02", "replyto": "WYiK0o8q02", "signatures": ["ICLR.cc/2026/Conference/Submission20588/Reviewer_ns7s"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20588/Reviewer_ns7s"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20588/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761907180227, "cdate": 1761907180227, "tmdate": 1762933996565, "mdate": 1762933996565, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors studied the problem of explaining and bounding risk change when replacing a source-trained model with a new model trained on shifted data under covariate shift. They proposed TRACE (Theoretical Risk Attribution under Covariate-shift Effects), a framework that decomposes the absolute risk change $|\\Delta R|$ into four interpretable terms: two generalization gaps, a model-change penalty, and a covariate-shift penalty. The method instantiates each term with computable quantities, using Optimal Transport or MMD to estimate data shift, model sensitivity via input gradients, and the discrepancy between model outputs. They demonstrate TRACE theoretically, showing asymptotic sharpness of the bound in linear settings, and empirically validate it across synthetic and vision benchmarks. They show that TRACE's diagnostic score correlates strongly with true performance degradation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The idea of providing practical explanations and bounds for risk change under model replacing is interesting and novel.\n- The proposed framework is effective and practical, both in theory and in experiments."}, "weaknesses": {"value": "- The introduction is not well motivated. The authors should provide more explanation about why it is important to explain and bound risk change under covariate shift.\n- The setting is limited. The authors only consider covariate shift, which enforces a strong assumption on the two distributions."}, "questions": {"value": "- Questions\n  - In Case Study 1, does the result ($|\\Delta R|$) imply that w1min is a better objective than mmdmin? Are there any other metrics to empirically validate this conclusion?\n  - In Case Study 2, what is the definition of harmness?\n- Suggestions\n  - Figure 1 is too wide. I suggest the authors reduce the width of the figure to fit the column width."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "TQh6SIIr5H", "forum": "WYiK0o8q02", "replyto": "WYiK0o8q02", "signatures": ["ICLR.cc/2026/Conference/Submission20588/Reviewer_c25K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20588/Reviewer_c25K"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20588/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972163658, "cdate": 1761972163658, "tmdate": 1762933996171, "mdate": 1762933996171, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes the TRACE, which decomposes the upper-bound of the source risk of models updated on shifted data, enabling the analysis or explanation of the risks with factors. To this end, the authors provide the computable proxies that approximate the theoretical factors, giving practical actions that can give valid diagnosis for models showing performance degradations."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- TRACE provides the practical lens that ones can diagnose which factors the model performance degradations are attributed to. Such attributions can be fully computable for each factor, which leads to diagnosis in domain adaptations such as failures by model instability or harmful parameter updates. \n- Such diagnosis is theoretically sound and its performances seem effective when tested in real-world scenarios such as adaptations to DomainNet dataset."}, "weaknesses": {"value": "- The overall scope of this paper is limited to the covariate shifts, and it cannot be easily extended to other or more complicated distribution shifts. I'm still concerned how practical it is, even considering that the method is theoretically sound."}, "questions": {"value": "Please see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "4DakqO1ouD", "forum": "WYiK0o8q02", "replyto": "WYiK0o8q02", "signatures": ["ICLR.cc/2026/Conference/Submission20588/Reviewer_iCBh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20588/Reviewer_iCBh"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20588/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762153118613, "cdate": 1762153118613, "tmdate": 1762933995693, "mdate": 1762933995693, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Revised Manuscript Uploaded"}, "comment": {"value": "We sincerely thank all reviewers for their time and valuable feedback. We are encouraged that the reviewers found that our work addresses an **\"important question\"** (Reviewer ns7s), is **\"interesting and novel\"** (Reviewer c25K), provides a **\"practical lens\"** (Reviewer iCBh), and is presented with **\"Exceptional Clarity\"** (Reviewer Tg6A). The feedback provides a clear path to strengthen the paper. A central theme is the practicality and scope of TRACE. We will revise the paper to emphasize that TRACE's primary value is as a **practical, ranking-based diagnostic** for the critical MLOps problem of safe model replacement, rather than a tight certifier. Below, we address each reviewer's points in detail.\n\n**We have uploaded a revised manuscript incorporating your suggestions, with major changes highlighted in $\\textcolor{blue}{blue}$.**"}}, "id": "52CLEzU6wa", "forum": "WYiK0o8q02", "replyto": "WYiK0o8q02", "signatures": ["ICLR.cc/2026/Conference/Submission20588/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20588/Authors"], "number": 9, "invitations": ["ICLR.cc/2026/Conference/Submission20588/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763737327079, "cdate": 1763737327079, "tmdate": 1763738639558, "mdate": 1763738639558, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}