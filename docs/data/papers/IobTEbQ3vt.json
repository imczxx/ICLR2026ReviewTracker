{"id": "IobTEbQ3vt", "number": 9788, "cdate": 1758140503524, "mdate": 1759897696014, "content": {"title": "Bringing Stability to Diffusion: Decomposing and Reducing Variance of Training Masked Diffusion Models", "abstract": "Recently, masked diffusion models (MDMs) have emerged as a promising direction beyond auto-regressive models (ARMs). However, MDM training consistently exhibits high variance, leading to less stable optimization and lower final performance. Despite several attempts at mitigation, there has been no theoretical explanation or systematic solution to this instability. In this paper, we derive the first decomposition of MDM training variance into (A) masking pattern noise, (B) masking ratio noise, and (C) data noise, while ARMs are only affected by (C). Building on this foundation, we design six variance-reduction methods, including two core methods: 1) P-POTS, a Pareto-optimal t-distribution that samples harder t values more often with smaller update steps to reduce (A), (B) and (C) simultaneously, and 2) MIRROR, which constructs negatively correlated samples to reduce (A). Experiments show that, compared to standard MDM training, our methods improve accuracy by 7â€“8% on complex reasoning tasks (such as GSM8K and HiTab), while simultaneously reducing run-to-run variability from 5.07% to 1.35%, thereby substantially narrowing the gap with strong ARM baselines.", "tldr": "We stabilize MDM training by deriving a variance decomposition and introducing two core methods: P-POTS, which is Pareto-optimal among all unbiased t-samplers, and MIRROR, which complements it. Experiments yield clear gains on final performance.", "keywords": ["Masked Diffusion Models", "Training Variance", "Training Stability", "Mask Schedule", "Mask Sampling"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8cbf94ee51ed08099af20b8425a06daf6844755b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper tackles the critical problem of high training variance in Masked Diffusion Models (MDMs), which causes optimization instability and performance degradation compared to Auto-Regressive Models (ARMs). The paper derives the first systematic decomposition of MDM training variance, identifying three distinct sources: A) Masking Pattern Noise, B) Masking Ratio Noise, and C) Data Noise. Based on this decomposition, the authors propose six methods, including two core techniques: P-POTS and MIRROR.  Experiments on complex reasoning and multimodal tasks show that the proposed methods, particularly the combination \"P-POTS+MIRROR,\" dramatically improve performance (e.g., +7-8% accuracy on GSM8K) and, critically, reduce run-to-run performance variability."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. This paper provides a clean, intuitive, and theoretically sound framework for understanding why MDMs are unstable.\n2. The proposed core methods (P-POTS and MIRROR) are well-motivated and directly derived from the theoretical analysis. \n3. The significant improvement in the MDM's performance makes the proposed method not only theoretically sound but also practically effective."}, "weaknesses": {"value": "This is a strong paper without major weaknesses. One suggestion on the presentation is that although this paper proposes two core methods to reduce the instability, it introduces six methods in total. I think this may harm the readability of this paper and distract the reader from understanding the core contribution. Therefore, the author may reconsider the paper structure."}, "questions": {"value": "1. Based on my understanding, LLaDA and Dream seem to use slightly different formulations to train MDM. However, this paper only conducts experiments on LLaDA. Thus, are the proposed methods applicable to other baselines, such as Dream?\n2. This paper discusses two types of LM, MDM and ARM, where MDM is fully bidirectional. How about the combined version, such as BlockDiffusion[1]? Does the author have any insights on this case, such as the training variance or whether proposed methods are still applicable?\n3. Though experimental results are quite impressive, I still recommend that the author provide train-from-scratch results in the future since the training variance in pretraining might be more salient.\n\n\n[1] Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models, in ICLR 2025"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "tXs7tOmcn1", "forum": "IobTEbQ3vt", "replyto": "IobTEbQ3vt", "signatures": ["ICLR.cc/2026/Conference/Submission9788/Reviewer_J4Ut"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9788/Reviewer_J4Ut"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9788/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761789182801, "cdate": 1761789182801, "tmdate": 1762921276240, "mdate": 1762921276240, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper try to decompose the MDM's training noise. The noise is divided into three parts: data noise and two about masking.\nThe core analyses are about inter-group and inner-group decoupling by the law of the total variance. Based on the aforementioned analyses, two main approaches are proposed, P-POTS and MIRROR."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Intuitive and sharp derivation of the theorem provides a mathemetically elegant  and practical explanation.\n- Numerical pre-experiments seems robust and adheren to the expected Pareto frontier."}, "weaknesses": {"value": "- Limited experiments about generalization and comparison. The ablaition experiments are mixed in the table of comparison. The included MDM baselines are too limited.\n- Parts of the error bars are missing, and meanwhile, the error bars reported are too large to convince audience that the methods are consistently performing well as it's tested in the main table."}, "questions": {"value": "- Selected benchmarks are all about QA reasoning tasks. How about general QA tasks and knowledge-intensive benchmarks, e.g., Graph QA, OCR detection?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MDBz9VNjWQ", "forum": "IobTEbQ3vt", "replyto": "IobTEbQ3vt", "signatures": ["ICLR.cc/2026/Conference/Submission9788/Reviewer_WDaB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9788/Reviewer_WDaB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9788/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761848854610, "cdate": 1761848854610, "tmdate": 1762921275535, "mdate": 1762921275535, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper analyzes training instability in masked diffusion models by decomposing the loss variance into three parts: (A) randomness from the mask pattern, (B) randomness from the mask ratio/timestep, and (C) data variance. To reduce these sources, it introduces P-POTS (a timestep sampler), Mirror (a complementary mask), and various other techniques. Across multiple benchmarks, the proposed approaches stabilize training and improve final results."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Overall, I think the paper studies an important problem. The proposed fixes P-Pot and Mirror are clearly argued and have demonstrated practical usefulness in terms of accuracy and training stability."}, "weaknesses": {"value": "1. The loss-variance decomposition is insightful, but I believe for training stability it would be more insightful to analyze gradient variance. It would be nice to see how reductions in the proposed loss variances translate to reduced gradient variances and more stable optimization.\n2. MIRROR roughly doubles the cost on some benchmarks compared to the baselines, which is quite expensive. Would MIRROR still be the best choice under a fixed time budget, which is a more practical scenario?\n3. I am not familiar with MDMs and thus cannot comment on the commonly reported numbers. But for ARMs, the Qwen-2.5-7B-Instruct and Qwen-3-8B numbers appear below the commonly reported results. Could the authors clarify their evaluation approachs?"}, "questions": {"value": "The variance decomposition is not unique. It depends on the conditioning order when you iteratively apply the law of total variance. Could the authors discuss how your conclusions change under alternative decompositions, and whether those alternative decompositions could lead to other interesting approaches?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "51X5CVdK08", "forum": "IobTEbQ3vt", "replyto": "IobTEbQ3vt", "signatures": ["ICLR.cc/2026/Conference/Submission9788/Reviewer_ag9a"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9788/Reviewer_ag9a"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9788/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761893816647, "cdate": 1761893816647, "tmdate": 1762921274974, "mdate": 1762921274974, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a theoretical and practical framework to understand and address instability in masked diffusion model (MDM) training. The authors first derive a variance decomposition framework that attributes training variance to three distinct sources: (A) masking pattern noise, (B) masking ratio noise, and (C) data noise. Based on this decomposition, they propose six variance-reduction methods. Experiments on multiple text reasoning datasets (GSM8K, HiTab, OpenScience) and a text-to-image benchmark show consistent improvements in both performance and stability. Overall, the paper is technically strong, though somewhat dense and in need of a tiny bit of clearer writing."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Strong theoretical foundation. The paper provides a clear and principled variance decomposition for masked diffusion model (MDM) training, unifying prior ad-hoc stabilization methods under a single theoretical framework. It then builds directly on this foundation by proposing six targeted variance-reduction techniques to mitigate the identified sources of instability.\n2. Comprehensive empirical validation. The experiments cover both language and multimodal domains, demonstrating that the proposed methods are broadly effective and improve training stability across diverse settings."}, "weaknesses": {"value": "1. Narrow comparison to ARMs. The study includes only two autoregressive baselines from the same family. Incorporating additional ARM baselines, especially models with different architectures or training paradigms, would help clarify whether the observed variance gap is a general phenomenon or specific to the chosen comparison set.\n2. Limited model diversity and scaling analysis. While the empirical results are solid, they are restricted to a single MDM backbone (LLaDA-8B-Instruct). Evaluating the proposed methods across different model sizes and architectures would strengthen the claims of generality and potentially reveal whether the improvements follow any scaling trends within or across model families.\n3. Writing and presentation. The exposition could be tightened to improve readability; the current density of equations and notation can make the paper feel more complex than necessary. Additionally, some figures could benefit from more informative captions, for instance, Figure 3 presents image generation results but omits the corresponding prompts."}, "questions": {"value": "See Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pyjNQm1kcH", "forum": "IobTEbQ3vt", "replyto": "IobTEbQ3vt", "signatures": ["ICLR.cc/2026/Conference/Submission9788/Reviewer_oCXk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9788/Reviewer_oCXk"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9788/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997480685, "cdate": 1761997480685, "tmdate": 1762921272586, "mdate": 1762921272586, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}