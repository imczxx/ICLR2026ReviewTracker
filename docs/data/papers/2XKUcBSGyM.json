{"id": "2XKUcBSGyM", "number": 2626, "cdate": 1757168947004, "mdate": 1762956306864, "content": {"title": "Unveiling Hidden Details: A RAW Data-Enhanced Paradigm for Real-World Super-Resolution", "abstract": "Real-world image super-resolution (Real SR) aims to generate high-fidelity, detail-rich high-resolution (HR) images from low-resolution (LR) counterparts. Existing Real SR methods primarily focus on generating details from the LR RGB domain, often leading to a lack of richness or fidelity in fine details. In this paper, we pioneer the use of details hidden in RAW data to complement existing RGB-only methods, yielding superior outputs. We argue that key image processing steps in Image Signal Processing, such as denoising and demosaicing, inherently result in the loss of fine details in LR images, making LR RAW a valuable information source. To validate this, we present RealSR-RAW, a comprehensive dataset comprising over 10,000 pairs with LR and HR RGB images, along with corresponding LR RAW, captured across multiple smartphones under varying focal lengths and diverse scenes. Additionally, we propose a simple yet efficient and general RAW adapter to effectively integrate LR RAW data into existing CNNs, Transformers, and Diffusion-based Real SR models by extracting fine-grained details from RAW data to enhance performance. Extensive experiments demonstrate that incorporating RAW data significantly enhances detail recovery and improves Real SR performance across ten evaluation metrics, including both fidelity and perception-oriented metrics, under real-world and wild-captured scenarios. Our findings open a new direction for the Real SR task, with the dataset and code being made available to support future research.", "tldr": "This paper introduces RealSR-RAW, a dataset with over 10,000 paired LR and HR RGB images and corresponding LR RAW data, and pioneers a novel RAW adapter using RAW data to enhance Real SR model performance.", "keywords": ["Real-World Super-Resolution", "RAW Data", "Generalization"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/21da93769716d7f2517946155b313bf1a421e93c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses real-world image super-resolution (Real SR), which reconstructs high-quality, detailed high-resolution images from LR inputs. Unlike existing methods that rely solely on RGB data, the proposed approach leverages information from RAW data to recover lost fine details. Specifically, (i) the authors introduce RealSR-RAW, a large-scale dataset containing over 10,000 paired LR/HR RGB images with corresponding LR RAW data captured from various smartphones and scenes. (ii) They also present a lightweight RAW adapter that integrates RAW features into different model architectures, including CNNs, Transformers, and Diffusion models. Experimental results demonstrate the effectiveness of their proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "Quality: The argument is well-supported by a range of experiments and analysis.\n\nClarity: The paper is well-written and easy to follow.\n\nSignificance: The results show decent improvement over RGB-only approaches and the method proposed could be useful for mobile phone producers."}, "weaknesses": {"value": "Originality: Although the combination of RGB and Raw data sounds new, SR and image restoration of Raw data is not a new topic and there is even an NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution [1]. That is, the key motivation and observations (e.g., information loss) in this work are already known, and the analysis part of this paper makes little contribution.\n\nQuality: (i) Although combining RGB and Raw data is a straightforward idea, it would also be interesting to know how they complement each other exactly. However, the paper did not explain this clearly. For example, the paper argued, \"Considering that LR RAW is in Bayer format and contains an amount of noise, directly concatenating LR RAW and RGB images can lead to distribution mismatches and noise interference.\" However, there are no associated empirical results/analysis showing if this is true and whether the proposed RAW adapter module really resolves this issue. \n(ii) The discussion of \"Why not LR RAW → HR RGB?\" is lacking as there are no comparisons with relevant methods, e.g., those in [1]. Methods specifically designed for LR RAW → HR RGB should perform better than those designed for RGB images. \n\n[1] NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution, https://ieeexplore.ieee.org/document/11148038"}, "questions": {"value": "Please see my comments in Weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FlrAV3ImrR", "forum": "2XKUcBSGyM", "replyto": "2XKUcBSGyM", "signatures": ["ICLR.cc/2026/Conference/Submission2626/Reviewer_yURM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2626/Reviewer_yURM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2626/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761036354396, "cdate": 1761036354396, "tmdate": 1762916313228, "mdate": 1762916313228, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "Qyy3ZNoPdO", "forum": "2XKUcBSGyM", "replyto": "2XKUcBSGyM", "signatures": ["ICLR.cc/2026/Conference/Submission2626/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2626/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762956305729, "cdate": 1762956305729, "tmdate": 1762956305729, "mdate": 1762956305729, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes the first Real SR dataset containing over 10,000 high-quality paired LR and HR RGB images, along with corresponding LR RAW data. Besides, a RAW adapter is proposed to efficiently capture useful information and align the distribution of RAW features to the RGB domain, resulting in significant improvements across multiple real-world benchmarks and metrics."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper provides a good description of the evidence and experimental results. A large number of experimental results have verified the effectiveness of this method."}, "weaknesses": {"value": "The insufficient novelty of the proposed method. This paper only proposed a RealSR-RAW dataset and a RAW Adapter. The structure of RAW Adapter is similar to many SR methods. These novelties can not support a good publication.\n\nSome more comprehensive experimental results should be provided, i.e., complexity and other SR datasets.\n\nSome descriptions are inaccurate. Authors should check and provide details."}, "questions": {"value": "In this paper, only the RealSR-RAW dataset was proposed to verify the effectiveness of RAW. Can the author provide more results on different SR datasets for comprehensive comparison?\n\nHow to generate the RAW data of existing SR datasets, i.e., DIV2K, UHD4K, DRealSR. Why author verify the effectiveness of the RAW data in the Real SR task? Is RAW data effective for traditional SR tasks?\n\nWhy author only use the RealSR dataset to generate the RealSR-RAW dataset for the experiment?\nCan other datasets also generate the RAW dataset for this experiment and draw the same conclusion?\n\nIn Equation (2), the LR RAW image and the LR RGB image are concatenated and then fed into a Real SR model to generate the SR image. However, in Figure 4 (a), the LR RAW image is fed into the RAW Adapter and the output with the LR RGB image is fed into the SR model. What is the output of the RAW Adapter? Is Equation (2) correct? Please carefully check!\n\nThe structure of the RAW adapter is very simple, and similar structures are applied in many SR methods. The novelty of RAW adapters is insufficient.\n\nThe author only provided the SR performance of the RealSR model, and should also provide the complexity of these models for compression comparison."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6GX13crMvn", "forum": "2XKUcBSGyM", "replyto": "2XKUcBSGyM", "signatures": ["ICLR.cc/2026/Conference/Submission2626/Reviewer_xsMq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2626/Reviewer_xsMq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2626/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761722146639, "cdate": 1761722146639, "tmdate": 1762916312953, "mdate": 1762916312953, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, a RealSR-RAW dataset is captured with over 10K high-quality paired LR RGB, HR RGB, and corresponding LR RAW. The authors proposed a RAW adapter that can capture useful information of LR RAW as a detail supplement to boost SR performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Valuable dataset: RealSR-RAW is captured with different settings when compared with other datasets. \n2. The motivation of the proposed method is clearly stated."}, "weaknesses": {"value": "1. Capturing LR RGB and LR RAW with the HR RGB displayed on a UHD monitor may cause inconsistent illumination. For example, the lighting environment of the LR RGB and LR RAW could be entirely different from that of the HR RGB. Would this give rise to certain issues? \n2. The authors claimed that the moiré patterns are avoided by using professional high-resolution displays. However, I believe that it is impossible to completely eliminate the moiré patterns, as faint, even those imperceptible to the naked eye, may still exert some adverse effects.\n3. About experiments, only $\\times 2$ is considered. The RAW adapter is effective on the proposed RealSR-RAW dataset and benchmark, without validating the effectiveness on existing datasets.\n4. I am confused about the RGB Image (Non-Bypass) in Figure 2 (b). It contains very obvious noise.\n5. Leveraging RAW information in SR is not novel and has been explored before. Please refer to NTIRE 2024 Challenge on Deep RAW Image Super-Resolution."}, "questions": {"value": "Please refer to the weaknesses part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pJr9saY1Eb", "forum": "2XKUcBSGyM", "replyto": "2XKUcBSGyM", "signatures": ["ICLR.cc/2026/Conference/Submission2626/Reviewer_9zXy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2626/Reviewer_9zXy"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2626/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761933563858, "cdate": 1761933563858, "tmdate": 1762916312825, "mdate": 1762916312825, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces RealSR-RAW, a large-scale dataset containing paired LR RAW, LR RGB, and HR RGB images for real-world super-resolution. It further proposes a lightweight RAW adapter that can be plugged into CNN-, Transformer-, or Diffusion-based SR models to extract high-frequency details from RAW data. Experiments show consistent gains in PSNR, SSIM, and perceptual quality, suggesting that RAW data can effectively complement RGB-based restoration."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper tackles a practical gap in Real-SR by integrating sensor-level information. The dataset is valuable and carefully collected, covering multiple devices and lenses. The proposed RAW adapter is simple yet generalizable, improving several baseline architectures with minimal computation overhead."}, "weaknesses": {"value": "1. The work \"Zoom to Learn, Learn to Zoom\" appears to be closely related to this paper. I recommend the authors provide a thorough analysis and comparison between their approach and the Zoom-to-Learn method, clearly highlighting the differences in data acquisition, methodology, and overall contributions.\n2. The current manuscript lacks sufficient ablation studies on alternative feature fusion strategies within the RAW Adapter. To better demonstrate the value and effectiveness of the proposed module, I suggest including more comparisons with other feature fusion approaches.\n3.  There are several detail issues that need clarification:\n   - In Table 2, the meaning of \"M50-M\" and \"P70-T\" is not clearly explained in the main text. Please provide detailed definitions for these terms.\n   - In Table 5, the column header \"Time\" may be ambiguous; if it refers to multiple runs or counts, \"Times\" might be more appropriate.\n4. RAW images typically contain RGGB Bayer patterns, while RGB images represent single pixels, resulting in shape inconsistency. The authors should clarify how they address this shape alignment issue before feature fusion.\n5. The new dataset and proposed idea are highly valuable for the research community. I would like to ask whether the authors plan to release the dataset and code in the near future to facilitate community adoption and ensure reproducibility."}, "questions": {"value": "See weaknesses for details."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SDOOJYw5WX", "forum": "2XKUcBSGyM", "replyto": "2XKUcBSGyM", "signatures": ["ICLR.cc/2026/Conference/Submission2626/Reviewer_H5Y5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2626/Reviewer_H5Y5"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2626/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762009045489, "cdate": 1762009045489, "tmdate": 1762916312690, "mdate": 1762916312690, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}