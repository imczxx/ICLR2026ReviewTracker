{"id": "c4Nbn695Au", "number": 6387, "cdate": 1757977612520, "mdate": 1759897917871, "content": {"title": "Unsupervised Radar Point Cloud Enhancement via Arbitrary LiDAR Guided Diffusion Prior", "abstract": "The angular resolution of automotive radar is fundamentally limited by the Rayleigh criterion and the number of antennas, resulting in sparse radar point clouds that hinder high-precision perception. Recent approaches address this limitation by training discriminative or conditional generative models on paired radar-LiDAR data, learning an explicit mapping from radar measurements to LiDAR-like outputs. However, these methods are sensitive to calibration errors and fail when LiDAR data is unavailable. In this work, we propose the first *cross-modality, unsupervised* radar point cloud super-resolution method by formulating radar enhancement as a Bayesian inverse problem. We explicitly model the radar sensing process with a differentiable forward operator, defining the measurement likelihood, and combine it with a LiDAR-trained latent diffusion model that captures the distribution of physically plausible point clouds. During inference, we perform posterior sampling that integrates this generative prior with the radar likelihood, yielding reconstructions that are both geometrically rich and strictly measurement-consistent ‚Äî without requiring paired radar-LiDAR data. Experiments on the RADIal dataset show that our approach matches the performance of supervised mapping-based methods, while generalizing significantly better to unseen datasets such as K-Radar. These results demonstrate the effectiveness of combining physics-based modeling with distributional priors, offering a robust and practical solution for radar perception in real-world deployments. Our code is available at https://anonymous.4open.science/r/RadarINV2025.", "tldr": "", "keywords": ["Radar", "Point Cloud Enhancement", "Diffusion Model", "Inverse Problem", "Autonomous Driving"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f8ad6342e3e43a9ea732b695b3c92160ec549d17.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes an unsupervised radar point-cloud enhancement method framed as a Bayesian inverse problem. It combines a differentiable radar forward model (likelihood) with a LiDAR-trained diffusion prior to sample dense, geometrically plausible point clouds without paired radar‚ÄìLiDAR supervision. Claimed contributions include the formulation, a practical posterior sampling procedure, and experiments showing performance near supervised baselines on RADIal with improved cross-dataset generalization (e.g., to K-Radar)."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper frames radar enhancement as a Bayesian posterior sampling problem and leverages a LiDAR-trained diffusion prior to inject strong geometric priors without paired radar‚ÄìLiDAR supervision‚Äîa creative and non-obvious combination.\n2. This paper achieves near-supervised performance on benchmarks, indicating a sound design with practical impact by reducing reliance on costly paired data and calibration."}, "weaknesses": {"value": "Problem framing and positioning.\nThe method reads more like super-resolution on range‚Äìazimuth heatmaps than ‚Äúpoint-cloud enhancement.‚Äù Please clarify terminology, the signal domain where inference occurs, and the point-cloud generation step. In addition, lines 40‚Äì41 attribute sparsity mainly to limited angular resolution, whereas in practice sparsity largely stems from point cloud generation methods (e.g., CFAR) that retain only peak returns; the pre-CFAR range‚Äìazimuth‚ÄìDoppler tensor is much richer. Revise the discussion to reflect this and specify where your method interfaces with this pipeline. Finally, the title‚Äôs ‚Äúarbitrary‚Äù claim is not operationalised‚Äîeither remove it or define and support it rigorously.\n\nReadability and technical clarity.\nIt is unclear how the masking strategy enables end-to-end training and reduces computation. Provide a complexity analysis, comparisons to alternative schemes, and ablations. For a broad audience, add a concise Preliminaries section on radar sensing (range/angle/Doppler FFTs, data cubes, CFAR, notation). Derivations are also hard to follow: detail the steps from Eq. (4) ‚Üí (5) and the extension (5) ‚Üí (1) in the supplement, stating assumptions and approximations.\n\nApplicability and evidence.\nGenerated radar points differ noticeably from LiDAR ‚Äúground truth.‚Äù Please explain the physical plausibility of these differences and what application value they provide. Strengthen the paper with downstream experiments (e.g., detection, segmentation, occupancy) to test whether the ‚Äúenhanced‚Äù radar improves task performance."}, "questions": {"value": "1. The Chamfer Distance unit is unspecified (meters? normalized voxel units?)\n2. How about the efficiency of the current method?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PkfhNIL8e1", "forum": "c4Nbn695Au", "replyto": "c4Nbn695Au", "signatures": ["ICLR.cc/2026/Conference/Submission6387/Reviewer_8Ps7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6387/Reviewer_8Ps7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6387/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760462425661, "cdate": 1760462425661, "tmdate": 1762918671911, "mdate": 1762918671911, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an unsupervised radar point cloud enhancement method that leverages a LiDAR-trained latent diffusion model as a prior. The goal is to enhance radar point clouds without requiring paired radar‚ÄìLiDAR data. The authors formulate the task as a Bayesian inverse problem, combining a physics-based radar forward model with a generative diffusion prior to reconstruct dense, LiDAR-like radar point clouds. Experiments on the RADIal and K-Radar datasets demonstrate that the proposed method achieves performance comparable to supervised approaches and significantly outperforms traditional methods such as CFAR across multiple metrics."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The reviewer believe authors' motivation is strong ‚Äì unsupervised radar enhancement is indeed essential becuase paired radar‚ÄìLiDAR data is scarce and fragile. \n2. Novel formulation regarding basyesion inverse problem and unsuperived learning with diffusion for radar enhanment.\n3. Authors provide their code and showing that their performance outperfomnce CFAR in the cross dataset experiment, which is widely use in almost all radar systems."}, "weaknesses": {"value": "1. The paper relies on several strong modeling assumptions‚Äîparticularly the use of Gaussian noise and an idealized, linear radar sensing model and some are not clearly stated or justified. These assumptions may not accurately reflect the statistical or physical characteristics of real radar signals. In the reviewer‚Äôs opinion, assuming Gaussian noise before the FFT stage is reasonable and common practice, as it represents thermal receiver noise. However, for radar tensors from datasets such as RADIal and K-Radar, subsequent processing steps like FFT beamforming introduce additional structured artifacts, including deterministic sidelobes and spectral leakage. The omission effects limits the realism of the forward model and could partly account for the false alarms observed in the qualitative results‚Äîmost notably on K-Radar, which exhibits stronger sidelobe artifacts.\n2. Writing can be improved, for example the symbols $ùúñ_ùúÉ$  and $ùúñ_ùõø$ appear interchangeably without explicit definition, while $ùúá_t$ and $Œ£_t$ are referenced but not introduced. The update term $ùúá_t ‚àí z_t$ uses the hyperparameter $Œª$$diff$, which is not defined elsewhere. The parameters $Œ≥$ and $Œ∂$ are inconsistently described between Algorithm 1 and Table 1. The appendix extends the derivation of the Bayesian update but suffers from notation inconsistencies. Clarifying these definitions and ensuring consistent notation throughout would greatly improve readability\n3.  Authors target a 2D range‚Äìazimuth slice. Many automotive radars are now 3D/4D (with elevation, Doppler). 2D enhancement limit the potential usage to only in BEV space.\n4. Another concern is the lack of detail regarding the CFAR baseline. The paper does not specify which variant of CFAR (e.g., CA-CFAR, OS-CFAR, GO-CFAR, etc.) is used, nor how its parameters are selected. These parameters are typically carefully tuned in practical radar systems, and their performance can vary significantly depending on the setting. Without this information, the reported CFAR results may not represent a fair or optimized baseline, which makes the comparison potentially unreliable."}, "questions": {"value": "The authors propose a radar enhancement system based on a diffusion model and report quantitative improvements across several metrics against Lidar pc. Chamfer Distance and FID-BEV measure geometry but not physical consistency. There‚Äôs no analysis of false positives, detection precision/recall, or uncertainty ‚Äî all key for radar. Also, it remains unclear how these enhancements affect downstream perception tasks compared with using CFAR point clouds or raw radar data. Since the enhanced results still contain noticeable noise, conducting relevant downstream experiments (e.g., object detection or tracking) would substantially strengthen the paper. My main concern lies in the paper‚Äôs overall contribution. Introducing an unsupervised radar enhancement approach is interesting, it is still uncertain whether this direction is worthwhile without stronger evidence. More comprehensive experiments or deeper analysis are needed to convince the community of its significance. \n\nI believe this is an interesting research direction, and I am open to raising my score if the authors effectively address the concerns outlined above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sPbLFZOKS1", "forum": "c4Nbn695Au", "replyto": "c4Nbn695Au", "signatures": ["ICLR.cc/2026/Conference/Submission6387/Reviewer_ZmfZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6387/Reviewer_ZmfZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6387/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761576982834, "cdate": 1761576982834, "tmdate": 1762918671525, "mdate": 1762918671525, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper aims to mitigate the sparsity of radar points for autonomous vehicles, thereby enhancing high-precision perception. It addresses the limitations of existing works in terms of their sensitivity to calibration errors and reliance on LiDAR data. To this end, the authors proposed a model that leverages a LiDAR-based latent diffusion model to solve for radar enhancement as a Bayesian inverse problem. Highlighted results from their experiment are the generalizability of the proposed model when evaluated across different datasets. Despite some promising results, it comes with significant limitations in both **novelty** and **significance of benefits**, as I will discuss in the sections below. Therefore, it is not considered a paper good enough for acceptance from my perspective."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is overall concise and application-oriented, with a clear presentation of problem statement, motivations, methodology, and experiments. The following lists some key contributions based on my understanding:\n1. **Parallel Radar Forward Model**: Motivated by the limitations of the discrete process, the authors introduce a parallel radar forward model in Section 3.2 to apply the Fourier Filter Transformation on BEV grids for continualizations.\n2. **Consistency Model**: Authors apply the diffusion model to learn an intermediate representation bridging radar and lidar points $\\mathbf{z}_{0}$ and enforce consistency constraints during inference with respect to the range-azimuth function $\\mathcal{A}$.\n3. **Generalizability**: A significant benefit of the model, as suggested by the authors, is highlighted by the strong generalization capability given by the cross-dataset validation in Section 4.2.3. This fits the expectation with the additional Bayesian inference setting."}, "weaknesses": {"value": "For this application-oriented paper, limitations of the proposed model are evident in terms of its limited novelty and performance:\n1. **Limited Novelty.** To the best of my knowledge, neither the concept of formulating Radar enhancement as a Bayesian inverse problem nor the application of combining Diffusion models in bridging LiDAR and radar is a novel idea compared to existing works. Based on this standpoint, the work is considered an incremental contribution to the field, as it replaces prior models in a Bayesian inverse setting with a learned Diffusion model of LiDAR points. This raises the question about its significance.\n2. **Significance of Performance.** With the limited novelty above, I would expect authors to showcase an improved performance with the proposed design. However, as listed in Table 2, the proposed method has improved none of the five key metrics. In particular, it has a relatively worse FID in BEV and UCD. In this sense, I would argue that there are potential improvements to be made in the proposed method, given the increase in computational and memory costs associated with incorporating a Diffusion model.\n3. **Generalizability.** Despite the promising generalizability demonstrated in Table 3, I wonder if the model can be efficiently scaled up with additional parameters or new data."}, "questions": {"value": "1. Equation (6) posed an i.i.d. Gaussian noise for the emission distribution. Have you considered other distributions that may better fit the properties of the features, such as the log-normal or von Mises distribution? \n2. Instead of a Diffusion prior, I wonder if it would be more appropriate to directly learn a unified flow-based model from the distribution of lidar points to the distribution of radar features within a unified BEV perspective?\n3. What is the sensitivity of sampling quality with respect to the number of measurement update steps $K$ and sampling steps $T$? If the quality is indeed sensitive to these two hyperparameters, how can we balance the trade-off between performance and efficiency?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA."}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0fkGiBcun3", "forum": "c4Nbn695Au", "replyto": "c4Nbn695Au", "signatures": ["ICLR.cc/2026/Conference/Submission6387/Reviewer_BmY1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6387/Reviewer_BmY1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6387/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761907047097, "cdate": 1761907047097, "tmdate": 1762918670483, "mdate": 1762918670483, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an unsupervised, cross-modality method for radar point cloud enhancement (super-resolution) to address the sparsity issue caused by physical aperture limitations. Unlike conventional supervised methods that rely on paired radar-LiDAR data, this work formulates radar enhancement as a Bayesian inverse problem.  The core contribution: (1) A differentiable radar forward sensing model (as the measurement likelihood, $p(y|x)$); (2) A latent diffusion model trained only on arbitrary (unpaired) LiDAR data (as the prior, $p(x)$, capturing real-world geometric distributions). During inference, the method performs posterior sampling to generate high-resolution point clouds that are both consistent with the radar measurements and possess LiDAR-like dense geometric structure. Experiments on the RADIal dataset show the unsupervised method achieves performance comparable to supervised approaches, while demonstrating significantly superior generalization on the unseen K-Radar dataset."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Unsupervised Formulation: The use of an unsupervised method to improve point cloud reconstruction quality is clearly a promising research direction. I believe this approach is particularly valuable for rare and special scenarios where it is often difficult to find LiDAR point cloud data with a matching distribution for paired training.\n\n2. Generalization Ability: As a direct benefit of its unsupervised nature, the proposed method demonstrates strong generalization capabilities when tested on the unseen K-Radar dataset.\n\n3. Novel Formulation: The paper introduces a novel formulation by framing the task as a Bayesian inverse problem. It effectively combines a physics-based radar forward model (the likelihood $p(y|x)$) with a diffusion prior trained on LiDAR data (the distributional constraint $p(x)$)."}, "weaknesses": {"value": "My specific concerns are as follows:\n\n1. **Poor In-domain Performance:** The method's in-domain results are underwhelming. **Table 2** indicates that the proposed approach offers only a marginal improvement over the traditional CFAR baseline, particularly on the commonly used CD and UCD metrics. More critically, the qualitative results in **Figure 4** show that CFAR can produce significantly more accurate reconstructions in some scenes (e.g., the third row), whereas the proposed method introduces numerous artifacts. This discrepancy suggests the quantitative gains might be illusory, potentially stemming from merely generating a denser cloud of points rather than from successfully integrating a meaningful scene prior. Consequently, the method's performance does not demonstrate a clear and significant advantage, even over the CFAR baseline.\n\n2. Questionable Validity of the Prior: The poor results call the core premise into question: is using a LiDAR point cloud as a prior truly sound for this task? A key implementation detail is omitted: did the authors strictly filter the LiDAR training data to only include points within the radar's specific Field-of-View (FOV)? The paper mentions pre-processing LiDAR to a $512 \\times 768$ BEV image covering [-90¬∞, 90¬∞], but it is not explicitly stated if this range was chosen to match the radar's FOV. If out-of-FOV data was used to train the prior, this would introduce a strong, incorrect bias, forcing the model to hallucinate points in areas the radar *cannot* see, which could explain the artifacts and poor metrics.\n\nIf the authors can substantially address concern #1 (Poor In-domain Performance) and provide a clear, reasonable explanation for concern #2 (Validity of the Prior), I will consider improving my rating."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1jS6yAVe3n", "forum": "c4Nbn695Au", "replyto": "c4Nbn695Au", "signatures": ["ICLR.cc/2026/Conference/Submission6387/Reviewer_AEG4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6387/Reviewer_AEG4"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6387/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761907939745, "cdate": 1761907939745, "tmdate": 1762918669850, "mdate": 1762918669850, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}