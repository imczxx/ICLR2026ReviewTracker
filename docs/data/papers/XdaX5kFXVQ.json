{"id": "XdaX5kFXVQ", "number": 9873, "cdate": 1758145369564, "mdate": 1759897690316, "content": {"title": "Tree-of-Options: Temporally Extended World Modeling, Planning, and Execution with Large Language Models", "abstract": "With commonsense knowledge embedded, Large Language Models (LLMs) have been repurposed as world models that can be exploited by principled planning algorithms such as Monte Carlo Tree Search (MCTS).\nPrior works have been limited to exploiting LLMs for low-level world modeling, i.e., predicting immediate next world states and rewards upon primitive actions, which makes them unfit for long-horizon tasks where prediction errors compound quickly over time. \nThis work develops an alternative framework where LLMs perform world modeling on temporally extended actions (options), to overcome their limitations in precise world modeling at small temporal scales.\nAt this temporal abstraction level, LLMs will also be competent in suggesting reasonable options, enabling effective planning using MCTS.\nTo execute the planned options with the primitive actions, we again turn to LLMs by prompting them to synthesize code implementing option-conditioned policies, which LLMs are known to excel at.\nEmpirical results in Minecraft show that this approach substantially improves performance over prior LLM-based planners on long-horizon, compositional tasks for embodied agents.", "tldr": "", "keywords": ["LLM world model", "MCTS", "Minecraft"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/adb627ca250067d1908e449ba73ae62d6dfdb95b.pdf", "supplementary_material": "/attachment/ae4d4b29a3aa1c902ef4953e094a962489f495dd.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose Tree of Options (ToO), using temporally extended actions instead of primitive actions to improve large language models' performance in long-horizon, complex tasks. The authors choose Minecraft as the target environment and experiment ToO on four long-horizontal tasks against CoT and ToT+MCTS, showing promising results."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. For long-horizon tasks, using options as instead of actions is straightforward and convincing. Options can be viewed as a higher level action comparing to primitive actions. Building the tree of options shortens the length of trajectory and facilitates LLMs to make decisions on a higher level.\n2. Presentation of Figure 2 is straightforward, where ToO obtains a \"flatter\" distribution of lower-level attempts. Flatter distribution of lower-level attempts could potentially help LLMs jump out of local maxima and go to the ultimate goal faster."}, "weaknesses": {"value": "1. Contribution is limited. I would like to view ToO as a variant of Language Agent Tree Search (LATS) [1], where the actions are replaced by options, where LLM initially critics on options and then try implements with actual feedbacks with environments.\n\n2. The experiment results partially supports the argument, but not fully. The long-horizon tasks should be harder and longer, like some tasks where the Diamond tools are involved. Also, for all the tasks, the baselines (CoT and ToT + MCTS) are able to achieve successfully. Some results that the baselines cannot achieve within some reasonable extended budgets comparing to ToO would support the authors' argument much better, where options do help LLMs perform reliably in long-term, complex tasks.\n\n3. The implementation of options is also limited. The authors use a prebuilt Voyager [2] skill library to implement Minecraft, and a trial-error fashion style based on the semantic similarity between options and skill library function names. While those implementations are simple and straightforward, a more general or principled way to implement execution of options would be appreciated.\n\n4. The related work section needs to be better. For instance, this paper is not cited: \"Mastering Board Games by External and\nInternal Planning with Language Models\" [3].\n\n[1] Zhou, Andy, et al. \"Language agent tree search unifies reasoning acting and planning in language models.\" arXiv preprint arXiv:2310.04406 (2023).\n[2] Wang, Guanzhi, et al. \"Voyager: An open-ended embodied agent with large language models.\" arXiv preprint arXiv:2305.16291 (2023).\n[3] Schultz, John, et al. \"Mastering board games by external and internal planning with language models.\" arXiv preprint arXiv:2412.12119 (2024)."}, "questions": {"value": "1. Would you mind providing additional experiments results on longer horizontal tasks? (Connection to weakness 2)\n\n2. For the option, how many actor code generation attempts needed to fully implement the option? \n\n3. What's the difference between option and action? For me, it seems like the options would be slightly general queries to retrieve from Voyager [1] skill library for code implementations comparing to detailed verbal actions. This is a nice contribution with simple solutions but there's no fundamental differences between options and actions. \n\n4. What's the cost comparison among CoT, ToT + MCTS, ToO (iteration =5) and ToO (iteration = 10)? Dollar computation would be sufficient (including OpenAI embedding model costs for ToO).\n\n[1] Wang, Guanzhi, et al. \"Voyager: An open-ended embodied agent with large language models.\" arXiv preprint arXiv:2305.16291 (2023)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6E6PFbB1pb", "forum": "XdaX5kFXVQ", "replyto": "XdaX5kFXVQ", "signatures": ["ICLR.cc/2026/Conference/Submission9873/Reviewer_t5aT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9873/Reviewer_t5aT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9873/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761511975548, "cdate": 1761511975548, "tmdate": 1762921343012, "mdate": 1762921343012, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the Tree of Options (ToO) framework, a novel planning method designed to enhance the performance of Large Language Models (LLMs) on long-horizon embodied decision-making tasks. The framework integrates Monte Carlo Tree Search (MCTS) with a high-level, LLM-based world model to plan over an abstract space of temporally extended actions, or \"options.\" Experiments conducted in the Minecraft environment demonstrate that ToO achieves superior efficiency and reliability on complex tasks when compared to baseline methods."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- By planning at the \"option\" level, the framework astutely leverages the high-level reasoning strengths of LLMs while mitigating their known weaknesses in handling low-level control details. The integration of MCTS with an option-level world model is a well-motivated and insightful contribution.\n- The choice of Minecraft as a testbed for long-horizon tasks is highly appropriate. Furthermore, the comparison against the ToT-MCTS baseline effectively ablates and highlights the core contribution of the option-level world model."}, "weaknesses": {"value": "- The framework involves multiple nested LLM calls within a single MCTS iteration, which appears computationally expensive. The paper does not discuss the associated costs or the scalability of this approach.\n- The success of each component (e.g., dynamics model, feasibility check) is highly dependent on carefully engineered prompts. This approach can be brittle and may require significant re-engineering for new domains or even for slightly different tasks, raising questions about its generalizability.\n- While \"actor attempts in code generation\" is a useful proxy for efficiency, the evaluation would be more persuasive if it also prominently featured standard metrics such as overall task success rate, total wall-clock time, and the total number of LLM API calls, some of which are currently in the appendix."}, "questions": {"value": "- Given that ToO involves multiple nested LLM calls per MCTS iteration, could the authors provide a quantitative analysis of the planning costs (e.g., number of API calls, token consumption, latency) and discuss the framework's scalability as the number of MCTS iterations and the branching factor increase?\n- The current implementation relies on one-shot planning. How might the system adapt to significant discrepancies between the world model's prediction and the actual outcome of an action? A discussion of strategies for online replanning and the associated trade-offs with the high planning cost would be valuable for assessing the framework's practicality.\n- Could the evaluation be made more comprehensive by supplementing the primary metric (\"number of code generation attempts\") with standard metrics like task success rate and total execution time in the main text?\n- It would be interesting to hear the authors' perspective on the trade-offs of the iterative code generation approach—a form of trial-and-error learning—compared to traditional reinforcement learning methods for executing complex options."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Au2DYoxx1s", "forum": "XdaX5kFXVQ", "replyto": "XdaX5kFXVQ", "signatures": ["ICLR.cc/2026/Conference/Submission9873/Reviewer_HKvo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9873/Reviewer_HKvo"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9873/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761737072285, "cdate": 1761737072285, "tmdate": 1762921342427, "mdate": 1762921342427, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Tree of Options (ToO) — a framework that integrates Large Language Models (LLMs) into temporally abstract world modeling and planning via Monte Carlo Tree Search (MCTS). Unlike previous LLM-based planners that operate on primitive actions (leading to compounding prediction errors), ToO models temporally extended actions (“options”) in natural language form."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Introduces a language-level option framework—bridging classical hierarchical RL (options) and LLM reasoning.\n2. Integrates LLMs into MCTS for structured exploration and evaluation over temporally extended actions. The combination of option-driven dynamics and reward predictors gives a coherent planning architecture.\n3. Uses LLMs’ strength in program synthesis to translate abstract options into executable skills. Iterative refinement with feedback increases robustness against generation errors."}, "weaknesses": {"value": "1. The approach depends on carefully hand-engineered prompts (for option generation, feasibility checks, reward prediction, etc.).\n2. While qualitative trajectories are shown, there is limited quantitative analysis on computational cost, token usage, or LLM query efficiency compared to baselines.\n3. The paper lacks a formal discussion of convergence, optimality guarantees, or the relationship between option-level abstraction depth and search efficiency.\n4. Ablations isolate world modeling and feasibility checks but do not examine how MCTS hyperparameters, rollout length, or option vocabulary size affect performance"}, "questions": {"value": "More discussions about Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "dmJXB640gK", "forum": "XdaX5kFXVQ", "replyto": "XdaX5kFXVQ", "signatures": ["ICLR.cc/2026/Conference/Submission9873/Reviewer_yJ7s"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9873/Reviewer_yJ7s"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9873/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761844660131, "cdate": 1761844660131, "tmdate": 1762921342116, "mdate": 1762921342116, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents ToO, a framework that lets LLMs plan and act through temporally extended actions instead of step-by-step moves. It combines an LLM-based world model, which predicts how the environment changes when a high-level option is executed, with a MCTS  planner that selects the best option sequence. The system then prompts the LLM again to generate executable code for each option. Experiments in Minecraft show that it handles long, multi-step tasks more reliably than Chain-of-Thought or Tree-of-Thought baselines, producing steadier and more feasible plans."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The pape introduces the options concept from RL into the context of LLM-based planning.\n\n- The experiments provid qualitative analyses of the slow is fast, option dependency stability, and the role of feasibility validation, which make the behavioral insights richer."}, "weaknesses": {"value": "- The overall presentation of the paper could be improved. Figure 1 lacks clear annotations and does not clearly illustrate how the world modeling component is integrated into the framework. \n\n- The main results section relies heavily on visualizations (Figures 2–4). As these figures are not sufficiently explained, it takes some effort for me to understand their logic. Since they mainly show a few specific tasks, the results feel more like case studies. It would greatly strengthen the paper to include a summary table with clear metrics such as task success rate or average step length.\n\n- All experiments are conducted in the Minecraft environment with very similar task settings (mining, crafting, milking, etc.). The paper would benefit from validation in additional environments."}, "questions": {"value": "- When an option is judged infeasible, how exactly does the feasibility module generate the “alternative actions”? Is there a specific prompting strategy or rule to ensure these replacements remain consistent and task-relevant?\n\n- Could the authors clarify how the weights in Eq. (6) are determined?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wnyxntQvC5", "forum": "XdaX5kFXVQ", "replyto": "XdaX5kFXVQ", "signatures": ["ICLR.cc/2026/Conference/Submission9873/Reviewer_VxES"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9873/Reviewer_VxES"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9873/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762015103115, "cdate": 1762015103115, "tmdate": 1762921341873, "mdate": 1762921341873, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}