{"id": "ORcb9LUjLQ", "number": 9874, "cdate": 1758145380356, "mdate": 1759897690255, "content": {"title": "Adaptive Drug-Drug Interaction Prediction via Gauge-Aware Graph Representation and Distribution Alignment", "abstract": "We re-study drug-drug interaction (DDI) prediction under the conditions of data scarcity and distribution shift. In this paper, we propose a practical framework that links a compact gauge-aware graph encoder to light-weight distribution alignment objectives, which we refer to as GraphPharmNet. On the modeling side, GraphPharmNet is based on the message passing mechanism with the per-edge orthogonal transports that align the neighbor features before aggregation, offering a robust and stable mechanism that is especially implementation-friendly given local coordinate choices. (Contrary to the claim of the strict O(d)-equivariance with general nonlinearities being a theoretical ideal, it is important to note that the notion of gauge-aware is a device of stability, as opposed to being a theoretical identity.) Orthogonal transports are on-the-fly generated by a shared edge MLP, and not edge learnable parameters. Note that the memory estimates we report are an \\emph{upper bound} when you have to cache all the coefficients at each edge, in practice we materialize them per mini-batch and we do not perform caching. On the learning side, we develop so-called training-only domain alignment based on MMD and optionally entropic-OT between partitions induced inside the training data. In order to prevent target leakage at all, we use a so-called leakage-safe training protocol: for predicting a batch of training edges, the target edges are (temporarily) removed from the message passing adjacency and feature propagation pipeline (''drop-edge-by-target''). Thus, relation labels of the target edges never enter the encoder which is used to generate their embeddings. We, furthermore, guarantee feature parity across the train/validation/test phases by utilizing the same training-only adjacency across all phases, and maintaining the above target-edge exclusion at training time. Empirically, on a DrugBank-based DDI graph (merged with Hetionet; $33{,}765$ nodes and $1{,}690{,}693$ edges), GraphPharmNet shows very strong performance under $6{:}1{:}3$ split outperforming the competitive GNN baselines. Furthermore, we record leakage-safe evaluation, deterministic single-label mapping, handling directed edges, and training-only alignment so that one can reproduce our setup.", "tldr": "", "keywords": ["Graph Representation", "Domain Adaptation"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b7d22c451556d5eeaab6dcf8df4be058f1df75e1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper aims to revisit the DDI prediction problem under data scarcity and distribution shift. It introduces GraphPharmNet, a framework combining a gauge-aware graph encoder with lightweight distribution alignment strategies. The work claims novelty in using per-edge orthogonal transports (computed via a shared edge MLP) to align neighborhood features before aggregation, promoting stability without requiring strict O(d)-equivariance. On the training side, the authors aims to design a leakage-safe protocol with training-only domain alignment (using MMD and optional entropic-OT), ensuring fair evaluation and reproducibility. Experiments on a large merged DrugBank–Hetionet dataset show consistent gains over baseline GNNs (though many SOTA models are excluded from the comparison), though the approach’s scalability and computational trade-offs warrant closer scrutiny.\nOvwerall, I think, this paper presents an interesting idea and a commendable effort, but the clarity and coherence of presentation are weak, and the experiments do not sufficiently support the claims. Overall, it lacks sound motivation, depth, and analytical rigor. Strengthening the structure, related work, and experimental validation would greatly improve its suitability for ICLR."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. Introduces a gauge-aware graph encoder that integrates orthogonal transport mechanisms in message passing, offering a fresh perspective on stabilizing feature aggregation in molecular graphs.\n2. Their proposed leakage-safe training protocol and training-only distribution alignment demonstrate careful attention to experimental rigor and reproducibility, which are often overlooked in DDI prediction research.\n3. Aims to address practical challenges of distribution shift and data scarcity in biomedical graphs, an underexplored yet important direction for improving real-world drug–drug interaction prediction."}, "weaknesses": {"value": "1. The problem doesn't seem well-motivated or some related literature is missing. The discussion contains several problems in current DDI works, but their approch and modeling choices, doesn't seem to have any relation to these.\n2. Informaiton in lines 069-097 seems out of context without any references and problem formualtion; thus very hard to understand and relate.\n3. Several relevant DDI works are missing from the discussion. DOIs: 10.1145/3511808.3557648, 10.48550/arXiv.1905.00534, 10.1093/bib/bbab441, 10.48550/arXiv.2403.17210, 10.1093/bib/bbab133, 10.1093/bib/bbac597, 10.48550/arXiv.2209.09941, 10.1039/D2SC02023H, 10.48550/arXiv.2508.06576.\n4. In Figure 2 and 3, mention the exact values, increase font sizes as it is not mreadable in current format. Tables are preferred. \n5. In Section 5.3 : Baselines, it is not clear why you didn't compare it with existing GNN-based DDI models (DOIs: 10.1145/3511808.3557648, 10.48550/arXiv.1905.00534, 10.1093/bib/bbab441, 10.48550/arXiv.2403.17210, 10.1093/bib/bbab133, 10.1093/bib/bbac597, 10.48550/arXiv.2209.09941, 10.1039/D2SC02023H)? Also, connecting to Figure 2, exisitng DDI models is reported to gain 90-98% accuracy, 99% AUROC in 2023. So, a discussion is expected on how this work differencites from them in terms of application and provides new insights to DDI researchers.\n6. Results section is very narrow and do not justify a lot of claimed contributions. A lot of theoretical contributions are made, but the result section do not reflect how these things are actually making a real impact in the modeling; or, how these addresses a practical problem in DDI.\n6. Ablations are not clear. Also, more detailed ablaitons are expected, concerning the contribution of the paper. For example, study the impact of *gauge-aware*ness, the alignment objective (MMD/OT), and more. A lot of things are introduced, but their impact or necesity was not establsihed proeprly.\n7. Contributions state *an efficiency- and memory-conscious implementation with on-the-fly transport generation that scales to graphs with millions of edges without prohibitive memory requirements*, but there is not scaling studies presented.\n8. Presentation and writing quality is poor. Very hard to foillow along and understand. Paper structure, word choices and content flow should be improved."}, "questions": {"value": "1. The section in lines 044-060 seems disconnected to 060-064. Explain in details both motivators you mentioned, *(i) distribution shift robust against the heterogeneous nature of sources of integrated knowledge and (ii) representation choice safe*. I didn't find any prior discussion to *distribution shift*, what it is in the context of DDI? how and why it happens? and how and why it matters? Also, the second point is unclear too. What do you meant by \"*whichfollows a trial-safe policy of experimental practice preventing any unfair performance evaluation.*\"? As per current information, I don't see these methodological requirements being established properly.\n2. In Line 069, before discussing the technical terms like *edge*, maybe the graph and problem preliminaries should be introduced; so that the readers can understand the situation better.\n3. L70/71 says,*the heterogeneous graph integration problem is a fundamental problem* - any related works or references?\n4. What does it mean by *we achieve this by **providing an effective stability in stabilizers** when performing local reparameterizations*? Mention the alhgorithm/strategy directly.\n5. Lines 75/76 says, *\"Throughout, we take **gauge-aware** to mean stabilization under local changes of basis\"*. What is *gauge*? Why should we do *gauge-aware* modeling? What is the techincal or application-wise impactg of it? \n6. What is MMD in abstract (L026) and L79/80? It should be introduced before using.\n7. L80/81 says, *\"prevent mis-imbalance of the internal distributions of them often resulting from merging data sources\"*.  - any related works or references?\n8. Add sufficient references in lines 069-097. Also, clarify. Currently, it is very hard to understand.\n9. *\"It is possible to do exactly equivariant layers with orthogonal basis changes (e.g. with radial nonlinearities and scalar maps).\"* - OK, But, why do we need these?\n10. What is the size of $d_0$? In L193/194, it says, *\"Each drug $v$ has initial features\"*. Whjat about $u$? \n11. Line 196 says, *for single-label, multi-class DDI type prediction*. In DDI, interaction types ($y$ in this paper) has massive class imbalance (in DrugBank's 86 interaction types) (DOI: 10.48550/arXiv.2508.06576.). Only top 10-15 interaction type has good representation and takes around 70-80% of the data. How do you handle this issue?\n12. Improve abslations as stated in weakness.\n13. Add missing references and related discussion. Also, why you didn't compare it with existing GNN-based DDI models? Those models seem to outperform this work, so, in practical application, how does this work makes meaningful contribution? I meant, those DDI models are already performing at 98-99% accuracy. Why od we need another model and what problem does it solve that justifies the need of this work?\n14. Provide scaling studies to justify contribution iv.\n15. In justification of *leakage-safe*, provide relevant references that proves other SOTA DDI models do have this problem."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "KW1F2c2ATG", "forum": "ORcb9LUjLQ", "replyto": "ORcb9LUjLQ", "signatures": ["ICLR.cc/2026/Conference/Submission9874/Reviewer_naJm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9874/Reviewer_naJm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9874/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760785814679, "cdate": 1760785814679, "tmdate": 1762921344372, "mdate": 1762921344372, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes GraphPharmNet, a framework for drug-drug interaction (DDI) prediction addressing data scarcity and distribution shifts. Key contributions include:\nPer-edge orthogonal transports align neighbor features before aggregation, claimed to enhance stability under local basis changes.\nUses MMD and entropic optimal transport (OT) on deterministic partitions of training data to handle source heterogeneity.\nTemporarily removes target edges during training (\"drop-edge-by-target\") to prevent information leakage.\nOn-the-fly generation of orthogonal transports reduces memory by 60× vs. naive caching. Evaluated on a DrugBank-Hetionet graph, the method reportedly outperforms GNN baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The \"drop-edge-by-target\" protocol is a rigorous solution to edge-label leakage.\nEmphasis on deterministic splits and label mapping aids reproducibility."}, "weaknesses": {"value": "\"Gauge-awareness\" is ambiguously defined—is it a smoothing regularizer or an approximate symmetry? Formal guarantees are missing.\nComparisons are limited to generic GNNs, excluding recent DDI-specific models.\nOnly one dataset is tested. Cold-start/relation-biased shift experiments are mentioned but not shown.\nDistribution alignment is confined to training data, undermining its relevance to real-world shifts."}, "questions": {"value": "Ablate orthogonal transports: How does performance change on shifted data (e.g., new relation types) without R_uv? Provide metrics for \"stability\" (e.g., variance in embeddings under perturbations).\nWhy align only training partitions? Compare to aligning training with a synthetic target domain. Show if MMD/OT improves macro-F1 on cold-start tasks."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CVWvro44Bz", "forum": "ORcb9LUjLQ", "replyto": "ORcb9LUjLQ", "signatures": ["ICLR.cc/2026/Conference/Submission9874/Reviewer_8cN4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9874/Reviewer_8cN4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9874/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761385682140, "cdate": 1761385682140, "tmdate": 1762921343772, "mdate": 1762921343772, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed GraphPharmNet for the drug-drug interaction (DDI) prediction with limited data and unpredictable distribution shift. The core of GraphPharmNet is to link a compact gauge-aware graph encoder and light-weight distribution alignment objectives. The proposed GraphPharmNet method was compared with six state-of-the-art GNN-based methods on the DrugBank dataset."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "S1: The proposed GraphPharmNet is to combine gauge-aware graph encoder and light-weight distribution alignment for the drug-drug interaction (DDI) prediction under the conditions of limited data and distribution shift.\n\nS2: In reported experiments, the proposed GraphPharmNet outperforms existing GNN-based DDI prediction methods in terms of accuracy, micro-F1, and macro-F1."}, "weaknesses": {"value": "W1: The abstract is too obscure and difficult to understand. Too many irrelevant statements affect readability and make it difficult to understand the core ideas.\n\nW2: The core of the work is leakage-safe gauge-aware message passing with alignment. However, too many concepts and theorems are discussed but lack a reasonable explanation of the motivation for proposing them.\n\nW3: The paper could be strengthened from more advanced DDI prediction methods such as DMFDDI and further validation along different DDI datasets."}, "questions": {"value": "- How does the proposed gauge-aware graph encoder based on edge orthogonal transport and kernelized neighborhood weighting address the data scarcity problem in DDI prediction? How does lightweight distribution alignment handle unpredictable distribution shifts in DDI prediction?\n- What does MMD stand for? This abbreviation should be clearly defined before use.\n- The description in Figure 1 does not match the content of Figure 1. For example, the middle section: a gauge-aware encoder transports neighbor features via orthogonal transforms Ruv and weights contributions by Kuv before aggregation. However, the middle section of Figure 1 focuses on DDI subgraph generation and knowledge subgraph generation, rather than the so-called gauge-aware graph encoder.\n- The core of the work is leakage-safe gauge-aware message passing with alignment. However, too many concepts and theorems are discussed but lack a reasonable explanation of the motivation for proposing them.\n- The paper could be strengthened from more advanced DDI prediction methods such as DMFDDI and further validation along different DDI datasets such as TWOSIDES.\n- A comprehensive ablation study to dissect the contribution of each component (i.e., Gauge-Awareness, Leakage-Safe Protocol, and Distribution Alignment) is needed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DgCvpf7OGe", "forum": "ORcb9LUjLQ", "replyto": "ORcb9LUjLQ", "signatures": ["ICLR.cc/2026/Conference/Submission9874/Reviewer_Ja6w"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9874/Reviewer_Ja6w"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9874/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761787986396, "cdate": 1761787986396, "tmdate": 1762921343166, "mdate": 1762921343166, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors proposed a framework that combines gauge-aware message passing with training-only distribution alignment, enabling more stable and generalizable representation learning in drug knowledge graphs."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The authors proposed a framework that combines gauge-aware message passing with training-only distribution alignment, enabling more stable and generalizable representation learning in drug knowledge graphs."}, "weaknesses": {"value": "1.\tOn “a subtle but pervasive type of information leakage.”\nTo my knowledge, most KG-augmented DDI methods (e.g., using DRKG, Hetionet) explicitly remove all test-set DDI edges from the KG prior to training/evaluation. In that case, how does leakage still occur? Could you provide a concrete, reproducible example demonstrating the leakage pathway you have in mind, so readers can verify that leakage persists even after removing test DDI edges?\n2.\tOn “Inconsistent Evaluation Practices.”\nYou argue that prior work suffers from inconsistent evaluation; however, many recent papers report five-fold cross-validation, which appears consistent at first glance. Could you clarify what specific inconsistencies you refer to? In addition, for the two points on handling multi-type interactions and directed vs. undirected edges, do you have strong empirical evidence or practical case studies that illustrate clear failures under common setups? Concrete examples would make these claims much more convincing.\n3.\tThe font in Figures 2 and 3 is quite small on printouts and standard screens. I recommend enlarging axis labels, legends, and annotations to improve readability.\n4.\tOn baseline citations and recency.\nCould you double-check the citations for the compared baselines? To my understanding, KGNN was introduced at IJCAI 2020, DDKG in Briefings in Bioinformatics 2022, SumGNN in Bioinformatics 2021, and LaGAT in Bioinformatics 2022. In your manuscript these are cited with 2024–2025 references. Are you certain those attributions are correct? Also, given that these baselines are relatively older, it would be helpful to include or discuss more recent (2024–2025) methods to strengthen the comparison.\n5.\tLack of interpretability of the model"}, "questions": {"value": "1.\tOn “a subtle but pervasive type of information leakage.”\nTo my knowledge, most KG-augmented DDI methods (e.g., using DRKG, Hetionet) explicitly remove all test-set DDI edges from the KG prior to training/evaluation. In that case, how does leakage still occur? Could you provide a concrete, reproducible example demonstrating the leakage pathway you have in mind, so readers can verify that leakage persists even after removing test DDI edges?\n2.\tOn “Inconsistent Evaluation Practices.”\nYou argue that prior work suffers from inconsistent evaluation; however, many recent papers report five-fold cross-validation, which appears consistent at first glance. Could you clarify what specific inconsistencies you refer to? In addition, for the two points on handling multi-type interactions and directed vs. undirected edges, do you have strong empirical evidence or practical case studies that illustrate clear failures under common setups? Concrete examples would make these claims much more convincing.\n3.\tThe font in Figures 2 and 3 is quite small on printouts and standard screens. I recommend enlarging axis labels, legends, and annotations to improve readability.\n4.\tOn baseline citations and recency.\nCould you double-check the citations for the compared baselines? To my understanding, KGNN was introduced at IJCAI 2020, DDKG in Briefings in Bioinformatics 2022, SumGNN in Bioinformatics 2021, and LaGAT in Bioinformatics 2022. In your manuscript these are cited with 2024–2025 references. Are you certain those attributions are correct? Also, given that these baselines are relatively older, it would be helpful to include or discuss more recent (2024–2025) methods to strengthen the comparison.\n5.\tLack of interpretability of the model"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vZma56N6aP", "forum": "ORcb9LUjLQ", "replyto": "ORcb9LUjLQ", "signatures": ["ICLR.cc/2026/Conference/Submission9874/Reviewer_E42z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9874/Reviewer_E42z"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9874/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761833097462, "cdate": 1761833097462, "tmdate": 1762921342750, "mdate": 1762921342750, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}