{"id": "2GAIoYNlNv", "number": 16825, "cdate": 1758269140765, "mdate": 1759897217093, "content": {"title": "FSMLP: Modelling Channel Dependencies With Simplex Theory Based Multi-Layer Perceptions In Frequency Domain", "abstract": "Time series forecasting (TSF) plays a crucial role in various domains. While effective for temporal modeling, channel-wise MLPs suffer from overfitting in inter-channel dependency learning. In this paper, we analyze this via Rademacher complexity theory, identifying extreme values as key overfitting catalysts.\nTo mitigate this issue, we propose to constrains weights to a standard simplex (Simplex-MLP), enforcing simpler patterns and reducing extreme value overfitting. Theoretically, we demonstrate that Simplex-MLP exhibits reduced susceptibility to overfitting on extreme values and demonstrates enhanced generalization capabilities. Based on the Simplex-MLP layer, we propose a novel F requency S implex MLP (FSMLP) framework for time series forecasting, comprising of two kinds of modules: Simplex Channel-Wise MLP (SCWM) and FrequencyTemporal MLP (FTM). Experiments on seven benchmarks confirm FSMLP's accuracy/efficiency improvements and superior scalability. Additionally, simplex-MLP also enhances existing channel-wise MLP methods, reducing their overfitting and boosting performance. Code is available.", "tldr": "", "keywords": ["time series forecasting"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ba9d8196847b5be8c9dbb934f9339e02f3c3962d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes FSMLP, a novel MLP-based architecture for time series forecasting that operates in the frequency domain. The authors begin by providing a theoretical motivation using Rademacher complexity to argue that standard channel-wise MLPs are prone to overfitting, particularly in the presence of extreme values in time series data. To address this, they introduce the \"Simplex-MLP,\" a core component that constrains the weights of the MLP layer to lie within a standard n-simplex, thereby enforcing a form of regularization that encourages simpler patterns and bounds the weight norm.\n\nThe proposed FSMLP framework consists of two main modules: (1) a Simplex Channel-Wise MLP (SCWM) that models inter-channel dependencies in the frequency domain, and (2) a Frequency Temporal MLP (FTM) that models temporal dynamics. The authors conduct experiments on seven common time series forecasting benchmarks, demonstrating that FSMLP achieves state-of-the-art performance and is more computationally efficient than many Transformer-based models. They also show that their Simplex-MLP layer can be used to improve the performance of existing models like Autoformer and TSMixer."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The FSMLP architecture is fully based on MLPs, which makes it computationally efficient in terms of both training and inference time compared to more complex attention-based models. This is a significant practical advantage.\n2.  The authors' effort to motivate their approach using Rademacher complexity theory is appreciated. It provides a principled, if not entirely complete, basis for tackling the problem of overfitting in MLP-based models.\n3. On the seven benchmark datasets used, FSMLP demonstrates very competitive, often state-of-the-art, performance, showcasing the practical potential of the proposed method in these specific domains."}, "weaknesses": {"value": "1. The primary weakness is that the theoretical analysis does not adequately establish why the simplex constraint is superior to other regularization methods. The analysis shows that the simplex complexity bound is independent of the weight norm, which is interesting, but it doesn't offer a comparative analysis against L1 or L2 norms from a theoretical standpoint. Why is enforcing a sum-to-one and non-negativity constraint the best way to handle overfitting from extreme values, compared to simply penalizing the norm?\n2. The comparison could be made more robust by including other recent and strong MLP-based models[1] [2] [3] . The claims of outperforming \"existing state-of-the-art methods\" would be stronger with a more comprehensive set of contemporary baselines.\n3. The experiments are concentrated on datasets from the electricity (ETTh1/2, ETTm1/2, ECL), traffic, and weather domains. This narrow scope makes it difficult to assess the true generalizability of FSMLP. The model's effectiveness on other types of time series data, such as from finance, healthcare, or retail, which may have different characteristics (e.g., higher noise, non-stationarity, lack of strong periodicity), remains unverified.\n4. The paper states that the SCWM models inter-channel dependencies on the frequency representations of the series. The mechanism for this is applying an MLP across the channel dimension for each frequency component. The intuition for why this is an effective way to model channel dependencies is not well explained. For example, does this allow the model to learn that a high value in frequency k for channel A should correlate with a low value in frequency k for channel B? A more intuitive explanation would be helpful.\n\n[1] Shiyu Wang, Jiawei Li, Xiaoming Shi, Zhou Ye, Baichuan Mo, Wenze Lin, Shengtong Ju, Zhixuan Chu, Ming Jin: TimeMixer++: A General Time Series Pattern Machine for Universal Predictive Analysis. ICLR 2025\n[2] Shiyu Wang, Haixu Wu, Xiaoming Shi, Tengge Hu, Huakun Luo, Lintao Ma, James Y. Zhang, Jun Zhou: TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting. ICLR 2024\n[3] Lu Han, Xu-Yang Chen, Han-Jia Ye, De-Chuan Zhan: SOFTS: Efficient Multivariate Time Series Forecasting with Series-Core Fusion. NeurIPS 2024"}, "questions": {"value": "1. How does the softmax operation contribute? Can it be replaced by another normalization operation?\n2. Are there any other constraints that can achieve similar performance? like L2- ball constrain?\n3. Relationship to instance normalization or other normalization method?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rDkrgM2Fs4", "forum": "2GAIoYNlNv", "replyto": "2GAIoYNlNv", "signatures": ["ICLR.cc/2026/Conference/Submission16825/Reviewer_oDSf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16825/Reviewer_oDSf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16825/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761641813564, "cdate": 1761641813564, "tmdate": 1762926855649, "mdate": 1762926855649, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies overfitting in channel wise MLPs for multivariate time series forecasting and traces a key failure mode to extreme values (outliers). Building on Rademacher complexity arguments, the authors propose Simplex MLP, which constrains each channel mixing weight vector to the standard simplex. They embed this into a frequency–time pipeline dubbed FSMLP, comprising a Simplex Channel Wise MLP (SCWM) and a Frequency Temporal MLP (FTM). The loss combines time domain MSE and frequency domain MAE. On seven benchmarks , FSMLP shows strong accuracy and efficiency and also improves existing models when Simplex MLP is used as a drop in layer."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.A concise and general mechanism.The paper links outliers to weight-norm inflation and mitigates overfitting to data spikes by constraining channel-mixing weights within the simplex. This approach is easy to implement, interpretable as a convex combination across channels, and theoretically justified by showing that the simplex constraint yields a tighter Rademacher bound.\n\n2.Broad and scalable empirical evidence.FSMLP remains competitive or achieves state-of-the-art results on long-horizon forecasting tasks while maintaining high efficiency (overall complexity O(NL)). It also provides plug-and-play performance gains when integrated into existing models such as TSMixer and Autoformer."}, "weaknesses": {"value": "1.Weak geometric motivation and interpretation.Although the paper describes the weight constraint as a “geometric constraint” that restricts parameters to lie within a standard simplex, its discussion of geometry remains largely formal, focusing only on the non-negativity and sum-to-one convex-combination conditions. The authors do not further explore the meaning of this geometric structure for the overall method, nor do they provide visualization or geometric interpretation. For instance, in classical linear programming, the simplex has a clear geometric implication—optimal solutions often occur at the vertices—yet no similar insight is discussed here. As a result, the “simplex constraint” in its current form appears more like an algebraic normalization operation than a genuinely geometry-inspired modeling approach, giving the impression that geometry serves merely as an external shell. A deeper exploration of the simplex’s geometric significance in future work would make the constraint more theoretically grounded and interpretable.\n\n2.Simplistic constraint assumption.By restricting the channel-mixing weights to the standard simplex, the method effectively prevents weight inflation caused by extreme values, but it implicitly assumes that all inter-channel relationships are non-negative convex combinations—channels can only act in an additive, cooperative manner. The paper does not discuss the possibility of allowing negative weights, which in many multivariate time-series contexts play an inhibitory role: an increase in one channel may suppress signals in another, a phenomenon commonly observed in meteorological, economic, or sensor-network data. Completely excluding such signed interactions makes it difficult for the model to capture antagonistic or counteracting relationships explicitly. Consequently, the simplex constraint currently functions more as a numerical regularization to prevent overfitting rather than as a modeling hypothesis that fully reflects the nature of inter-channel interactions. Future work could consider introducing signed or zero-mean variants of the constraint to represent both positive and negative correlations—thereby capturing the inhibitory effects between channels while maintaining stability."}, "questions": {"value": "1.On the geometric motivation.Could the authors elaborate on the geometric interpretation of the simplex constraint beyond non-negativity and normalization? For instance, does the geometry of the simplex  have any implication for optimization dynamics or model behavior? A visualization or geometric analysis would help clarify whether the constraint brings benefits beyond simple normalization.\n\n2.On allowing signed or zero-mean weights.Have the authors considered extending the simplex constraint to allow signed or zero-mean weights? In many multivariate time-series settings, negative channel interactions represent inhibitory effects—an increase in one channel suppresses another. How would the proposed framework behave if such antagonistic relationships were permitted? Could a “centered simplex” or signed variant of the constraint preserve stability while improving modeling flexibility?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8qpist03YW", "forum": "2GAIoYNlNv", "replyto": "2GAIoYNlNv", "signatures": ["ICLR.cc/2026/Conference/Submission16825/Reviewer_VGLj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16825/Reviewer_VGLj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16825/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761985160832, "cdate": 1761985160832, "tmdate": 1762926853772, "mdate": 1762926853772, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces FSMLP, a novel model for time series forecasting that explicitly constrains MLP weights to a standard simplex (Simplex-MLP) to mitigate overfitting due to extreme values in multivariate time series data. The authors provide a theoretical justification using Rademacher complexity, showing that the proposed weight constraint reduces the model’s capacity to overfit noise. The approach is integrated into a frequency-domain framework (FSMLP) that includes Simplex Channel-Wise MLP (SCWM) and Frequency Temporal MLP (FTM) blocks. Extensive experiments on seven benchmark datasets and ablation studies demonstrate improved forecast accuracy, generalization, and computational efficiency over recent state-of-the-art baselines. The paper also shows that incorporating Simplex-MLP into existing models like TSMixer and Autoformer improves their performance."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- The paper gives a solid theoretical and empirical motivation for the overfitting problem associated with traditional channel-wise MLPs due to extreme values, as summarized in Table 1 and visually reinforced in Figure 1, which shows overfitting trend disparities among methods (FSMLP, TimesNet, TSMixer, Autoformer).\n- The simplex constraint is rigorously justified with Rademacher complexity bounds (Section 5, Theorem 2), and a detailed proof is given in the Appendix, explaining why the constraint reduces generalization risk compared to L1/L2 regularization.\n- The paper includes an exhaustive empirical comparison across diverse, standard benchmarks, demonstrating that FSMLP consistently outperforms prior models in both MSE and MAE for various input/output sequence lengths.\n- The ablation study isolates the contributions of the simplex constraint, frequency transformation, and loss design. Figure 3 and Table 10 show the model achieves lower memory usage and faster inference/training times compared to prior models, demonstrating practical efficiency.\n- The method is shown to generalize to and enhance other recent models, as evidenced in Table 9, where plugging Simplex-MLP into TSMixer/Autoformer yields notable performance gains across datasets.\n- Mathematical derivations (e.g., equations for simplex projection, proofs of norm inflation in Section B.1/B.2) augment the presentation, demonstrating a solid grasp of both theoretical and practical considerations."}, "weaknesses": {"value": "1. The math formulations and step-by-step derivations for projecting weights onto the simplex lack clarity around certain details, such as the computational complexity of each transformation and how they are implemented for large-scale matrices. The choices for $$f_\\mathrm{trans}$$ (absolute, log, square) are described, but a more precise algorithmic statement or pseudocode for the entire weight update procedure, particularly for batch settings, is missing. This may hinder reproducibility and understanding of the exact workflow, especially in the context of PyTorch/TensorFlow weight updates.\n2. The Rademacher complexity argument assumes bounded-norm, i.i.d. data. In real-world time series, substantial autocorrelation and non-stationarity violate these simplifications. The practical impact on generalization may be overestimated, and no sensitivity analysis explores cases of strongly autocorrelated or heavy-tailed sequences. A more thorough discussion or experiments on datasets with severe non-stationarity would solidify the contribution.\n3. At several points, the paper argues that FSMLP is “universally” effective, yet the benchmarks are all from canonical, academic datasets. No evidence is given for extreme industrial settings (e.g., financial or medical data with even more skewed distributions), nor is the method tested on irregularly sampled or missing data. Similarly, statements like in Section 7 (“demonstrating scalability and robustness in large-scale, long-term forecasting tasks”) are somewhat overreaching given the size and scope of the benchmarks."}, "questions": {"value": "1. Can the authors provide an explicit pseudocode or concrete algorithmic steps for the Simplex-MLP weight update (particularly the combination of $$f_{\\text{trans}}$$ and $$f_{\\text{norm}}$$ for batched tensors)? How efficient is this step computationally for high-dimensional weight matrices? Does it introduce runtime bottlenecks?\n2. How robust is the FSMLP approach to highly non-stationary or autocorrelated time series, given the theoretical claims depend on i.i.d./boundedness assumptions? Do the authors see consistent improvements on, for example, financial or clinical datasets with heavy tails or strong patterns? If not, what failure modes emerge?\n4. For scenarios requiring sparse or highly selective channel influence, does the simplex constraint risk underfitting? Would a convex-combination constraint (with temperature or sparsity control) provide a better regularization/expressivity tradeoff?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ZkDj5AQWMD", "forum": "2GAIoYNlNv", "replyto": "2GAIoYNlNv", "signatures": ["ICLR.cc/2026/Conference/Submission16825/Reviewer_iSan"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16825/Reviewer_iSan"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16825/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762008551745, "cdate": 1762008551745, "tmdate": 1762926852226, "mdate": 1762926852226, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Overall, the paper’s motivation is unclear and, in some parts, potentially questionable. \nThe design rationale behind the proposed model architecture is not sufficiently articulated.\nSeveral statements in the manuscript appear to be inaccurate or misleading, particularly in the Related Work section and the theoretical proofs.\nIn addition, the chosen baselines are outdated and do not include recent models from NeurIPS 2024, ICLR 2025, or ICML 2025. Given these issues, I believe the paper is not yet ready for publication and therefore recommend rejection."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea of introducing a simplex constraint on MLP weights is conceptually interesting.\n\n2. The experimental section covers multiple benchmark datasets, providing a broad empirical context for evaluation."}, "weaknesses": {"value": "1. In Table 1, it is unclear what type of “extreme values” the authors are referring to. The meaning of this term is ambiguous and requires clarification.\n\n2. The content in Section 2.1 Time Series Forecasting, is not closely connected to the main topic discussed in this paper.\n\n3. Regarding the description of the related work FreTS, the statements in lines 140–143 are incorrect. Furthermore, even on the authors’ own terms, the position expressed in lines 140–143 appears inconsistent with that in line 161.\n\n4. In Figure 2,\n\n    (i) The outer block is labeled “SCWM,” and the inner layer within the same block is also named “SCWM.” This creates ambiguity, as it is unclear whether “SCWM” refers to the entire module or a specific layer inside it.\n\n    (ii) The two dashed diagonal lines should originate from the position of the SCWM layer.\n\n    (iii) The *Simplex Constrain*, which is claimed as one of the main contributions of the paper, is not clearly illustrated or elaborated in the figure.\n\n5. Issues in the Proof of Theorem 1 (Weight Norm Growth with Extreme Values)\n\n    (i)  Incorrect use of spectral lower bound.   The proof employs $\\lambda_{\\min}(X^{\\top}X)$ to lower-bound terms involving $\\Delta X$, even though $\\Delta X$ is an independent perturbation matrix unrelated to $X$.\n   This substitution has no theoretical justification: one cannot assume that the smallest eigenvalue of $X^{\\top}X$ constrains the behavior of $\\Delta X$.\n   A valid bound should depend on $\\sigma_{\\min}(\\Delta X)$, the smallest singular value of the perturbation itself.\n\n    (ii) Invalid inequality for difference of norms. The argument that $||\\Delta XW - \\Delta Y||_F^2 \\ge \\tfrac12||\\Delta XW||_F^2 - ||\\Delta Y||_F^2$ is mathematically incorrect.\n   The standard triangle inequality only implies $||A-B||_F \\ge |\\ ||A||_F - ||B||_F|$;\n   squaring this relation does **not** yield the linear form used in the proof.\n   Consequently, the claimed lower bound on $||\\Delta XW - \\Delta Y||_F^2$ is unjustified.\n\n6. Moreover, the proof of Theorem 2 (Rademacher Complexity of Simplex-MLP) contains errors in the treatment of the maximization domain and omits the necessary dimensional factor(s).\n\n7. The numbering of the theorems is inconsistent: Theorem 1 (Weight Norm Growth with Extreme Values) in the main text becomes Theorem 3 in the appendix; similarly, Theorem 2 (Rademacher Complexity of Simplex-MLP) in the main text appears to correspond to another theorem also labeled Theorem 3 in the appendix.\n\n8. Regarding the experimental section:\n\n    (i) The selected baselines are relatively old and do not include more recent models published in ICLR 2025 or ICML 2025, which limits the competitiveness and relevance of the comparison.\n\n    (ii) It would be very informative to visualize the learned weight matrix of Simplex-MLP to show how the simplex constraint affects the weight distribution.\n\n    (iii)  Some tables repeat the same experimental results (for example, Table 3 vs. Table 9, and Table 5 vs. Table 8), which is unnecessary and could be consolidated.\n\n    (iv) The paper lacks visualizations comparing predicted and ground-truth curves."}, "questions": {"value": "1. Figure 1 presents experiments conducted on the ETTh1 dataset. The meanings of the horizontal and vertical axes are the same in both the left and right subfigures, but the curves differ. What causes this discrepancy? In addition, the figure’s intended message is unclear, as neither the caption nor the introduction provides a sufficiently detailed or insightful analysis.\n\n2. Line 097: “and each coordinate is greater than or equal to zero.” Is this constraint applicable to real-world datasets? My concern is that when coordinate values are negative, such cases are ignored, even though negative values may naturally occur, for example, when variables exhibit negative correlations.\n\n3. In Lines 235–247, the authors state that *“the operator $f_{\\text{trans}}$ can be realized with each of the three following functions.”* I would like to know how one should determine which function to choose in different scenarios. In addition to these three functions, are there any other possible implementations of the operator $f_{\\text{trans}}$ ? Furthermore, what do you consider to be the essential properties or constraints that $f_{\\text{trans}}$  must satisfy?\n\n4. In line 274, the phrase “N SCWM blocks and N FTM blocks” appears. Does *N* here refer to the number of series (as mentioned in “N series” in line 195)? It seems not."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tFjva4XYNL", "forum": "2GAIoYNlNv", "replyto": "2GAIoYNlNv", "signatures": ["ICLR.cc/2026/Conference/Submission16825/Reviewer_UooN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16825/Reviewer_UooN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16825/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762060539744, "cdate": 1762060539744, "tmdate": 1762926851538, "mdate": 1762926851538, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}