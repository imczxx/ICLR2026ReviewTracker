{"id": "nBta7psl5J", "number": 15817, "cdate": 1758255659379, "mdate": 1759897280010, "content": {"title": "Uncovering Competing Poisoning Attacks in Retrieval-Augmented Generation", "abstract": "Retrieval-Augmented Generation (RAG) systems improve the factual grounding of large language models (LLMs) but remain vulnerable to retrieval poisoning, where adversaries seed the corpus with manipulated content. Prior work largely evaluates this threat under a simplified single-attacker assumption. In practice, however, high-value or high-visibility queries attract multiple adversaries with conflicting objectives. Motivated by real cases, we introduce the setting of competing attacks, in which multiple attackers simultaneously attempt to steer the same (or closely related) query toward different targets. We formalize this threat model and propose competitive effectiveness, a metric that quantifies an attacker’s advantage under competition. Extensive experiments show that many strategies that succeed in the single-attacker regime degrade markedly under competition, revealing performance inversions and highlighting the limits of conventional metrics such as attack success rate and F1. Further more, we present PoisonArena, a standardized framework and benchmark for evaluating poisoning attacks and defenses under realistic, multi-adversary conditions. Our code is included in the supplementary materials.", "tldr": "We show that RAG poisoning attacks behave very differently when multiple attackers compete, and introduce PoisonArena to evaluate this.", "keywords": ["RAG Poison Attack", "Trustwrothy AI", "Retrieval System Poison Attack"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c17f518fa14a521cae577f5ab1bc4d25b9539e45.pdf", "supplementary_material": "/attachment/eafd20377cc64188372e760088ca3aba7312c1b7.zip"}, "replies": [{"content": {"summary": {"value": "The authors identify a novel and yet interesting research topic, which defines the competition among attackers of the same RAG system. A Bradley-Terry model is considered to formulate the success of attackers. Thorough experiments have been conducted, including single-attacker settings, competition settings, as well as their counterparts under the presence of recent defense methods. The results show interesting and unconventional results, where single attackers may not work well at the presence of other attackers. Furthermore, a new benchmark is proposed for future evaluations."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "A novel research question is identified. The experimental results are interesting. Thorough numerical studies are conducted, including those under recent defenses."}, "weaknesses": {"value": "However,  I identify several weakness:\n\n(1) Although the problem of having multiple attackers is truly realistic, it is hard to formulate the problem into a research setting. In other words, while I appreciate the authors' attempt and great effort, several practical problems may still exist (and can hardly be formulated or assumed away). For example, it is totally understandable that simulations have to require all attackers have the same level of capability. In practice, however, some attackers may have higher level of access to the corpus, or higher rates of injecting new information into the database, or the capability to access the retriever and hence inject more valuable and likely retrieved documents, or the algorithm to identify high-value queries dynamically and more accurately.\n\n(2) The novelty of the proposed method is rather weak. The novelty mainly lies in the novel research topic and the construction of the new benchmark. The execution of the idea, on the other hand, mainly relies on existing methods, including existing RAG attack algorithms and the Bradley-Terry method for attacker ability evaluation. If this is presented as a benchmark paper, it should be fine, though."}, "questions": {"value": "What does it mean high-value queries? Practically how do we identify them?\n\nIt might be helpful to introduce briefly what the two datasets are, and why and how they can be used to evaluate the proposed attacker competition problem.\n\nWhat's the baseline RAG system on which the attacks are compared? What's the retriever?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "R20FC8rgxC", "forum": "nBta7psl5J", "replyto": "nBta7psl5J", "signatures": ["ICLR.cc/2026/Conference/Submission15817/Reviewer_WSXS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15817/Reviewer_WSXS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15817/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761341895755, "cdate": 1761341895755, "tmdate": 1762926046358, "mdate": 1762926046358, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents the concept of competing attacks, a multi-adversary threat model for retrieval-augmented generation systems where multiple attackers attempt to influence the same query at the same time."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "A novel competing attack is proposed to target the RAG system."}, "weaknesses": {"value": "1. The threat model assumed in the paper is unrealistic.\n\n2. The runtime of the proposed attack and all baseline methods is not evaluated.\n\n3. Allowing five poisoned documents to be injected into the system per query is impractical.\n\n4. The paper overlooks several recent attack and defense approaches."}, "questions": {"value": "1. The paper assumes that the attacker either has access to a proxy retriever or can observe the retriever’s output, which is unrealistic. In real-world scenarios, it is nearly impossible for an attacker to obtain such information. Moreover, the authors’ statement that “the strength of the attack assumption is not the central focus of our study” is inappropriate. For an attack paper, the proposed method must demonstrate effectiveness under realistic threat models, as practicality and realistic assumptions are essential to evaluating attack feasibility.\n\n2. Some attack methods, such as GASLITE, benefit from more advanced optimization mechanisms, while simpler baselines are under-optimized. This imbalance compromises the fairness of the comparisons.\n\n3. Simulating pairwise competitions among all attackers across datasets is computationally expensive, yet the paper does not provide any runtime or efficiency analysis of the proposed framework.\n\n4. The experimental setup allows five poisoned documents per query to be injected into the RAG system. This configuration is unrealistic because, as shown in [a][b], the number of truly relevant texts among the top-5 retrieved documents per query is typically fewer than five (e.g., in the NQ dataset). As a result, the number of poisoned documents exceeds the number of relevant ones, which artificially inflates the attack success rate. A more practical setting would restrict the attacker to injecting only one poisoned document per query.\n\n5. Several recent and more advanced poisoning attacks on RAG systems, such as [a][c], are not included in the comparison. The authors should evaluate their method against these stronger and up-to-date baselines to demonstrate competitiveness.\n\n6. The range of defenses examined in the paper is narrow. Additional robust defenses, such as [d][e], should be incorporated.\n\n\n[a] Practical Poisoning Attacks against Retrieval-Augmented Generation.\n\n[b] Benchmarking Poisoning Attacks against Retrieval-Augmented Generation.\n\n[c] FlippedRAG Black-Box Opinion Manipulation Adversarial Attacks to Retrieval-Augmented Generation Models. \n\n[d] SafeRAG Benchmarking Security in Retrieval-Augmented Generation of Large Language Model.\n\n[e] Traceback of Poisoning Attacks to Retrieval-Augmented Generation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "4MjQFgyhYO", "forum": "nBta7psl5J", "replyto": "nBta7psl5J", "signatures": ["ICLR.cc/2026/Conference/Submission15817/Reviewer_cCQE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15817/Reviewer_cCQE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15817/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761882922696, "cdate": 1761882922696, "tmdate": 1762926045818, "mdate": 1762926045818, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies competing poisoning attacks on RAG systems, cases where multiple adversaries try to push conflicting misinformation into the same query. The authors show that methods strong in single-attacker settings often fail or flip rankings when attackers compete. They introduce PoisonArena, a benchmark with new metrics (m-ASR, m-F1, and a competitive coefficient) to measure attack strength under competition. Results show that real-world RAG security needs multi-attacker evaluation, not just single-attacker tests."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is the first to study competing poisoning attacks in RAG systems, moving beyond the oversimplified single-attacker assumption.\n2. It introduces PoisonArena, a well-structured evaluation framework for multi-attacker experiments.\n3. This paper provides code, simulation details, and convergence criteria for reliable replication."}, "weaknesses": {"value": "1.Although the paper presents the idea of competing attackers as a realistic scenario, likw political misinformation, product competition, the experiments remain entirely synthetic. All poisoned documents and queries are generated using LLMs rather than derived from real user-generated or adversarial data. This disconnect weakens the paper’s central claim that competing attacks mirror real-world threat. there is no evidence that such multi-party interference actually emerges in open systems.\n2. The proposed simulation framework requires repeated pairwise competitions among multiple attackers across large datasets. This design is computationally heavy, yet the authors provide no discussion or measurements of runtime, memory cost, or scaling behavior. Without efficiency evaluation, it is unclear whether PoisonArena can scale beyond small experimental settings or be adopted for large-scale security testing.\n3. One of the paper’s most interesting findings that \"weaker single-attacker methods outperform stronger ones under competition \"is treated descriptively, not analytically. The authors offer no clear theoretical reasoning or model of interaction that explains why this inversion occurs. Without such grounding, the finding risks being dataset or setup-specific rather than a general phenomenon.\n4. The setting allows up to five poisoned documents per query gives each attacker excessive influence. In most RAG pipelines, the retriever only surfaces one or two truly relevant passages among the top-k results. Granting five injected documents per query likely inflates attack success rates and makes competition dynamics less representative of real conditions. A more realistic setting should restrict attackers to one or at most two poisoned documents per query."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fQbutrGEie", "forum": "nBta7psl5J", "replyto": "nBta7psl5J", "signatures": ["ICLR.cc/2026/Conference/Submission15817/Reviewer_kQAJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15817/Reviewer_kQAJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15817/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762035447444, "cdate": 1762035447444, "tmdate": 1762926045396, "mdate": 1762926045396, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the concept of \"competing poisoning attacks\" in RAG systems, where multiple adversaries simultaneously attempt to mnipulate the same query toward different, mutually exclusive targets. Additionally, they propose PoisonArena, a benchmark framework that evaluates poisoning methods under both single- and multi-attacker settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1. There is a critical gap in existing RAG security research and this paper identifies it and fulfill this gap. The competing attacks is realisti and relevant forhigh-stakes queries in politics and public health.\n\nS2. The evaluation is comprehensive covering seven attack methods, six LLMs and multiple datasets including (NQ, MS MARCO, mMARCO).\n\nS3. The paper is well written and easy to follow."}, "weaknesses": {"value": "W1. The choice of 8 incorrect answers per query seems arbitrary and lacks justification\n\nW2. The convergence criterion based on ranking stability (Equation 7) could be sensitive to the choice of r (consecutive rounds)\n\nW3. The specific prompt templates for generating adversarial content may introduce biases"}, "questions": {"value": "Please refer to Weakness part"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "fzHoZ3KbQ6", "forum": "nBta7psl5J", "replyto": "nBta7psl5J", "signatures": ["ICLR.cc/2026/Conference/Submission15817/Reviewer_B74c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15817/Reviewer_B74c"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15817/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762802428625, "cdate": 1762802428625, "tmdate": 1762926045096, "mdate": 1762926045096, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}