{"id": "DjfRkr82jn", "number": 7215, "cdate": 1758011880992, "mdate": 1759897865922, "content": {"title": "PreciseCache: Precise Feature Caching for Efficient and High-fidelity Video Generation", "abstract": "High computational costs and slow inference hinder the practical application of video generation models. While prior works accelerate the generation process through feature caching, they often suffer from notable quality degradation. In this work, we reveal that this issue arises from their inability to distinguish truly redundant features, which leads to the unintended skipping of computations on important features. To address this, we propose \\textbf{PreciseCache}, a plug-and-play framework that precisely detects and skips truly redundant computations, thereby accelerating inference without sacrificing quality. Specifically, PreciseCache contains two components: LFCache for step-wise caching and BlockCache for block-wise caching. For LFCache, we compute the Low-Frequency Difference (LFD) between the prediction features of the current step and those from the previous cached step. Empirically, we observe that LFD serves as an effective measure of step-wise redundancy, accurately detecting highly redundant steps whose computation can be skipped through reusing cached features. To further accelerate generation within each non-skipped step, we propose BlockCache, which precisely detects and skips redundant computations at the block level within the network. Extensive experiments on various backbones demonstrate the effectiveness of our PreciseCache, which achieves an average of $2.6\\times$ speedup without noticeable quality loss. Source code will be released.", "tldr": "", "keywords": ["Diffusion Model"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1dce3cfb1a53f54eb4a938686d8fc5bf8bd278fb.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces **PreciseCache**, a training-free acceleration framework for video diffusion models that reuses redundant computations both across denoising steps (LFCache) and within transformer blocks (BlockCache). The method identifies truly redundant features based on low-frequency difference (LFD) analysis, achieving up to 2.6× speedup without noticeable quality degradation. The paper evaluates performance across several open-source video generation backbones."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper identifies redundancy in transformer-based video generation models, distinguishing between *pivotal* and *non-pivotal* blocks, which aligns with observations of over-parameterization in large diffusion models. Training-free and plug-and-play: The proposed method requires no fine-tuning or retraining, making it applicable to existing models with minimal integration cost."}, "weaknesses": {"value": "Limited generalization evidence. The proposed method relies on the redundancy of existing open-weight video generation models. Its effectiveness may diminish when applied to smaller or more efficient architectures with less redundancy. The paper does not test PreciseCache on small-scale, parameter-efficient video generation models, leaving uncertainty about its general applicability."}, "questions": {"value": "**Evaluation on compact video generation models:**\n\n Please evaluate PreciseCache on a smaller, efficient video generation model (e.g., with reduced transformer depth or parameter count) to demonstrate whether the proposed caching mechanism provides benefits beyond over-parameterized models. Please **specify the exact training datasets** and report **metric scores per model** (LPIPS, SSIM, PSNR, VBench) and training time for at least one video geneartion model.  I am willing to increase score if the authors can help reduce some concerns about the video generation models."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "K58jhiecJR", "forum": "DjfRkr82jn", "replyto": "DjfRkr82jn", "signatures": ["ICLR.cc/2026/Conference/Submission7215/Reviewer_j8AN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7215/Reviewer_j8AN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7215/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761611362860, "cdate": 1761611362860, "tmdate": 1762919362647, "mdate": 1762919362647, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "PreciseCache is a training-free, plug-and-play framework that accelerates video diffusion models by precisely detecting and skipping truly redundant computations through Low-Frequency Difference (LFD)-based step-wise caching (LFCache) and block-wise caching (BlockCache), achieving up to 2.6× speed-up without noticeable quality loss."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "+ The step-wise LFCache determines when to skip entire denoising steps, while the block-wise BlockCache further skips redundant network blocks within the key steps, forming a hierarchical strategy that compresses redundant computation in a simple yet effective manner.\n\n+ By performing a spatiotemporal downsampled “trial run” on the latent to estimate the LFD, the method greatly reduces the decision overhead compared to a full forward pass, which is an idea both interesting and effective.\n\n+ The experiments cover diverse backbones, resolutions, denoising steps, and multi-GPU settings, reporting metrics such as MACs, latency, VBench, and similarity scores (LPIPS, SSIM, PSNR) relative to non-caching baselines. Comparisons with PAB, TeaCache, and FasterCache demonstrate that the proposed method achieves higher acceleration while maintaining high fidelity, with LPIPS remaining below 0.1.\n\n+ The paper is clearly written and easy to follow."}, "weaknesses": {"value": "- The paper involves several hyperparameter settings, such as the low-frequency cutoff radius, the cache window size L, and the key-block selection ratio Top-c% in BlockCache. However, the current version lacks experiments or analyses demonstrating the robustness of these choices. It would strengthen the work to include additional studies or sensitivity analyses that show how variations in these hyperparameters affect performance and stability.\n\n- The method suffers from excessive memory consumption; however, as noted by the authors in the limitation section, this is a common issue among cache-based approaches and can be mitigated through sequence parallelism."}, "questions": {"value": "See Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None."}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "hgNKVtUqqz", "forum": "DjfRkr82jn", "replyto": "DjfRkr82jn", "signatures": ["ICLR.cc/2026/Conference/Submission7215/Reviewer_GzPo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7215/Reviewer_GzPo"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7215/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761822745256, "cdate": 1761822745256, "tmdate": 1762919362228, "mdate": 1762919362228, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper achieves adaptive skipping—dynamically determining whether to adopt a full computation strategy or a caching strategy at each step—with minimal computational overhead. This is accomplished by first correlating output differences with low-frequency differences and then integrating these correlations with lightweight subsampling. At a finer granularity, for steps where the full computation strategy is employed, a BlockCache method is proposed. This method evaluates block importance based on block differences: it performs full computation for critical blocks while accelerating the processing of non-critical blocks by caching their differences."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This paper proposes a novel novel adaptive-adaptive skipping strategy, which achieves adaptive skipping with minimal computation by correlating output differences with low-frequency differences and further associating them with lightweight subsampling."}, "weaknesses": {"value": "1. The LFD method proposed in this paper essentially implements adaptive skipping. How does this method perform compared to AdaptiveDiffusion(Training-Free Adaptive Diffusion with Bounded Difference Approximation Strategy)?\n\n2. The BlockCache method achieves acceleration by caching block differences. How does this method perform in comparison with ∆-DiT(∆-DiT: A Training-Free Acceleration Method Tailored for Diffusion Transformers)?\n\n3. Can the method in this paper be presented more clearly in the form of a network structure?\n\n4. Is this method equally effective in image generation?"}, "questions": {"value": "Please refer to weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "maXR41hXgp", "forum": "DjfRkr82jn", "replyto": "DjfRkr82jn", "signatures": ["ICLR.cc/2026/Conference/Submission7215/Reviewer_CSSt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7215/Reviewer_CSSt"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7215/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761897828414, "cdate": 1761897828414, "tmdate": 1762919361856, "mdate": 1762919361856, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents PreciseCache, a unified inference-acceleration framework for Diffusion Transformers (DiTs) that leverages the Low-Frequency Difference (LFD) between consecutive steps to identify redundant computations.\nTwo complementary caching schemes are proposed:\n - 1. LFCache, which adaptively skips diffusion steps based on LFD-estimated redundancy;\t\n - 2. BlockCache, which reuses spatial feature blocks within non-skipped steps to further reduce computation.\n\nExperiments on multiple DiT-based video diffusion models show up to 2.6 × speed-up with minimal quality degradation, suggesting that LFD is an effective redundancy proxy.\n\nOverall, the paper tackles a practical and timely question—how to accelerate DiT inference without retraining or architectural modification—and offers an empirically validated, conceptually simple solution."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "PreciseCache demonstrates outstanding performance in **redundancy detection precision** and **cross-model adaptability**, particularly excelling in video generation—a highly complex task—where it effectively balances the core trade-off between *acceleration ratio* and *quality preservation*.\n\n1. **Frequency-Domain-Based Precise Redundancy Detection, Overcoming Blind Caching**  \n   Existing caching methods (e.g., TeaCache, FasterCache) often rely on *uniform time intervals* or *global feature differences* to detect redundancy, overlooking the fact that *different frequency components have varying impacts on video quality*:\n   - **Key insight via frequency decomposition:** By applying FFT to decompose predicted features into low-frequency and high-frequency components, experiments show that low-frequency components determine structural and content consistency, while high-frequency components mainly affect minor details. For instance, reusing high-frequency features results in negligible MSE error, but reusing low-frequency ones causes severe degradation.  \n   - **Low-Frequency Difference (LFD)** serves as a quantitative measure of temporal redundancy, and its variation trend aligns closely with caching impact on final quality — large LFD in early noisy stages implies high caching risk, while small LFD in late denoising stages indicates safety.  \n   This design fundamentally addresses the traditional issue of *misidentifying critical timesteps*, explaining the near-lossless quality at high acceleration.\n\n2. **Two-Level Caching: Step-Level + Block-Level Synergy for Maximum Acceleration**  \n   PreciseCache achieves *compound acceleration* by combining **LFCache** (temporal redundancy filtering) and **BlockCache**:  \n   - **LFCache (Step-Level):** To avoid full inference for LFD computation, a *downsampled latent probing* strategy is proposed—performing temporal-spatial downsampling (e.g., T/2×H/4×W/4) on current-step latents and running lightweight inference to obtain low-frequency components. This introduces negligible overhead. Experiments show >95% consistency between downsampled and full-resolution LFD, ensuring accurate caching decisions.  \n   - **BlockCache (Module-Level):** Within *non-redundant timesteps* selected by LFCache, PreciseCache further analyzes Transformer module importance—computing input-output differences to identify *pivotal blocks* (top c%) and *non-pivotal blocks* (low-difference). Outputs of redundant modules are approximated using cached input–output deltas, skipping redundant computation (Fig. 6).  \n   This *“step filtering + module compression”* design boosts acceleration from 1.9× (TeaCache) to 2.6× (PreciseCache-Flash) with negligible quality loss.\n\n3. **Adaptable to Mainstream Video Generation Models and Multi-GPU Scaling**  \n   PreciseCache maintains consistent performance across architectures, resolutions, and GPU configurations, demonstrating strong engineering generality:  \n   - **Cross-model adaptability:** Tested on Open-Sora 1.2, HunyuanVideo, CogVideoX, and Wan2.1-14B, achieving an average 2.6× acceleration with only 0.1–0.6% VBench score drops.  \n   - **Multi-GPU scalability:** With Dynamic Sequence Parallelism (DSP), acceleration scales almost linearly.  \n   - **Resolution robustness:** At 1080P, a single GPU achieves 2.5× speed-up, effectively mitigating *latency explosion* in high-resolution video generation."}, "weaknesses": {"value": "1. **BlockCache Increases Memory Overhead, Limiting Single-GPU Deployment**  \n   BlockCache caches *input–output deltas* for each Transformer block, significantly increasing GPU memory usage—especially in large-scale or high-resolution setups:  \n   - Appendix A.2 states that for Wan2.1-14B (1080P), PreciseCache-Flash cannot run on a single 80 GB A800 GPU and requires multi-GPU execution.  \n   - The paper reports latency and MACs but omits explicit memory growth metrics (e.g., +20% or +50% vs baseline), leaving uncertainty for edge devices with limited VRAM.  \n   While this issue affects most module-level caching methods, the paper proposes no mitigation (e.g., delta compression or dynamic cache eviction), restricting its single-GPU applicability.\n\n2. **Untapped Acceleration Potential in High-Noise Phases**  \n   LFCache disables caching in early high-noise steps (≈ first 10–15 iterations) due to large LFD, yielding no acceleration during this phase.  \n   - However, module-wise redundancy may still exist even in high-noise phases. Yet BlockCache is only applied after LFCache filtering, missing these opportunities.  \n\n3. **Insufficient Analysis of Parameter Sensitivity in Frequency Decomposition and Downsampling**  \n   The paper defines a low-frequency radius of $1/5 × \\min(H,W)$ and a downsampling ratio of (2×4×4), but does not analyze their sensitivity:  \n   - **Low-frequency radius:** Would LFD accuracy degrade if set to 1/10 or 1/3? A too-small radius may miss important low-frequency content, while too-large introduces high-frequency noise, reducing discriminability.  \n   - **Downsampling ratio:** Table 3 tests 1×2×2 to 4×4×4 only, omitting extreme cases (e.g., 8×8×8) and ignoring interaction with model scale or resolution (e.g., smaller models may tolerate higher ratios).  \n   Lack of such analysis forces users to fine-tune these parameters per model, raising deployment costs.\n\n4. **Limited Theoretical Explanation for the Link Between LFD and Video Quality**  \n   While experiments empirically demonstrate the correlation between LFD and quality loss, the paper lacks theoretical grounding:  \n   - No mathematical derivation relating LFD magnitude to video quality degradation, thus the optimal α threshold is empirically chosen (0.5/0.7).  \n   - No analysis on how video type (e.g., dynamic action vs static landscape) affects LFD thresholds—dynamic videos likely require stricter criteria (smaller α), but this remains untested.  \n   Consequently, the method’s adaptability across diverse video generation scenarios is uncertain."}, "questions": {"value": "1. How stable are the gains under different LFD thresholds $\\delta$ or block sampling ratios"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7BEB2Sa40l", "forum": "DjfRkr82jn", "replyto": "DjfRkr82jn", "signatures": ["ICLR.cc/2026/Conference/Submission7215/Reviewer_KbQo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7215/Reviewer_KbQo"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7215/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761901201729, "cdate": 1761901201729, "tmdate": 1762919361494, "mdate": 1762919361494, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}