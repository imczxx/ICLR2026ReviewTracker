{"id": "zhqiPuLQHU", "number": 1037, "cdate": 1756829573739, "mdate": 1763613287444, "content": {"title": "Orion: Intervention-Validated Causal Discovery for Spatiotemporal Forecasting", "abstract": "While spatiotemporal forecasting plays a critical role in domains such as intelligent transportation and infectious disease prediction, existing methods still face fundamental challenges in modeling complex dependencies in graph-structured data and multi-scale temporal dynamics, primarily because they neglect the inherent causal mechanisms in spatiotemporal propagation processes. To address these limitations, we propose Orion, a framework that integrates trainable causal inference with attention mechanisms, optimized through progressive training. Our key contributions include: (1) the TE-CausGAT module, which jointly performs causal discovery and validates learned structures via do-interventions; (2) the Belt Block architecture, which processes hourly, daily, and weekly patterns in parallel; (3) intelligent data retrieval using a fine-tuned large language model; and (4) a progressive three-stage training strategy that progressively transitions from feature learning to causal discovery to end-to-end optimization. Orion achieves new state-of-the-art performance across multiple benchmarks: in traffic forecasting, it improves MAE by 6.60% on METR-LA, 8.65% on PEMS-08, and achieves optimal results across multiple prediction horizons on PEMS-04; in epidemic forecasting, it improves MAE by 22.70% on CA and 37.73% on TX. Furthermore, comprehensive ablation studies, Dream3 causal validation experiments, and METR-LA case studies collectively demonstrate Orion's effectiveness in both accurate prediction and reliable causal discovery.", "tldr": "We propose Orion, a spatiotemporal forecasting model that combines trainable causal inference with attention mechanisms, along with progressive curriculum learning and large language model-enhanced data retrieval.", "keywords": ["spatiotemporal forecasting", "causal discovery", "graph attention networks", "do-interventions", "multi-head attention"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/47e6fa6735acb10f99822530c09a1760c503ee5b.pdf", "supplementary_material": "/attachment/2c2a4d49dba0cf7d64f4686dd69b209f9179ff7b.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a spatiotemporal forecasting framework named Orion, which leverages causal theory and a progressive three-stage training strategy to discover causal relationships among nodes and enhance forecasting accuracy. Specifically, Orion employs an LLM-based retrieval mechanism to select semantically relevant historical periods, a TE-CausGAT module for autonomous causal discovery and intervention-based validation, and a three-stage training process that progressively transitions from feature learning to causal learning and to end-to-end optimization.Orion demonstrates strong performance across both traffic and epidemic forecasting tasks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper leverages causal structure learning with do-intervention validation to learn a dynamic causal graph, which is interesting.\n\n2. Comprehensive experiments on both traffic and epidemic forecasting tasks.\n\n3. Case studies demonstrate that the proposed method can discover meaningful causal relationships."}, "weaknesses": {"value": "1. The paper is hard to follow due to issues with clarity in writing. For example, it is unclear how the LLM-enhanced data retrieval module selects historical data based on semantic similarity: What is the input format to the LLM? How is the LLM fine-tuned to support this task? Are specific prompts required, and if so, how are they designed?\n\n2. Some key important technical details lack justification. For example, in the TE-CausGAT module, why is an eight-kernel convolution used? Is there any hyperparameter study to justify this choice, and why specifically eight kernels?\n\n3. Some figures are too small to read. For example, Figure 6.\n\n4. The proposed strategies may underperform at high target magnitudes. According to the ablation study, removing the multi-period fusion module results in higher MAE compared to Orion but substantially lower MAPE; removing TE-CausGAT shows the same trend. Since MAPE measures relative error, these reductions in MAPE suggest that the proposed strategy may potentially degrade performance in some critical cases."}, "questions": {"value": "1. What is the input format to the LLM? How is the LLM fine-tuned to support this task? Are specific prompts required, and if so, how are they designed?\n\n2. Why is an eight-kernel convolution used? Is there any hyperparameter study to justify this choice, and why specifically eight kernels?\n\n3. Is there any justification for the finding that removing the proposed strategies results in higher MAE but substantially lower MAPE compared to Orion?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "k1aQ7Sac3S", "forum": "zhqiPuLQHU", "replyto": "zhqiPuLQHU", "signatures": ["ICLR.cc/2026/Conference/Submission1037/Reviewer_VcAa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1037/Reviewer_VcAa"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1037/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761572352443, "cdate": 1761572352443, "tmdate": 1762915660293, "mdate": 1762915660293, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents Orion, a framework that integrates trainable causal inference with attention mechanisms, optimized through progressive training. Through Orion, the paper aims to address the modeling of complex dependencies in graph-structured\ndata and multi-scale temporal dynamics from a causal angle into the underlying forecasting model."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The underlying results and the comparison with a lot of different prior work is impressive and across the proposed datasets and benchmarks the paper does achieve significant improvements across a variety of metrics."}, "weaknesses": {"value": "The paper several fundamental assumptions in their causal discovery assumptions and the \"do-intervention\" analysis. In most of their scenarios, they are not doing an actual \"do-intervention\" but actually taking observational data with potential causal assumptions to derive the link weights of these causal links. The writing and analysis and the positioning of these arguments raises several fundamental questions on the correctness of their framing and the claims made in the paper."}, "questions": {"value": "Causal aware modeling is different from do-intervention calculus.\n\nIn a do-intervention calculus, there is an explicit notion of \"do-intervention\" and not.\n\nThis scenario does not happen in your context for both the traffic example and the COVID modeling example. You are using data from various sources to formulate a forecasting problem and then you are using a causal aware model to potentially pinpoint what could have happened and how it could impact the future spatiotemporal predictions.\n\nFor example, in the traffic scenario, you talk about an accident example in the introduction. Now, in the real datasets, you do not know this information all the time. Even if you do, did your model truly formulate it as a do-intervention and not do-intervention with the right underlying causal models taking careful care of the co-founders in your assumptions.\n\nYour approach takes a data-driven parameter estimation approach in your three-stage scenario. There is nothing wrong in that approach from a spatiotemporal forecasting approach but claiming that it actually captures do-interventions is not correct.\n\nIn short, the paper analysis and results and comparitive metrics are very strong from a forecasting perspective but the formulation from a causal argument perspective seems flawed.\n\nThe DREAM3 dataset is the only data in your model where the dointerventions can be synthetically controlled in a simulation.\n\nIf you are doing a physics-driven simulation of traffic and disease forecasting and then claiming that your model can retrieve the simulation parameters, that is more believable."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "p1NyLB99Po", "forum": "zhqiPuLQHU", "replyto": "zhqiPuLQHU", "signatures": ["ICLR.cc/2026/Conference/Submission1037/Reviewer_bhkv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1037/Reviewer_bhkv"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1037/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761921440767, "cdate": 1761921440767, "tmdate": 1762915660167, "mdate": 1762915660167, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ORION, a spatiotemporal forecasting framework that aims to learn and exploit causal structure while predicting. Core ideas are: (i) TE-CausGAT, which learns a time-segmented, directed adjacency via parameterized source/target transforms, fuses segments (plus a prior graph), imposes an acyclicity surrogate penalty, and then validates edges by training-time do-style perturbations whose effects are propagated by a GRU; edges whose predicted strengths align with observed perturbation effects get higher â€œvalidityâ€ scores and are emphasized in attention; (ii) a Belt Block with parallel Hour/Day/Week branches plus a fusion block; (iii) an optional LLM-enhanced retrieval (TinyLlama fine-tuned) that selects semantically similar historical periods; and (iv) three-stage training (feature learning â†’ causal discovery â†’ end-to-end finetuning). On traffic (METR-LA, PEMS-04/-08) and epidemic datasets (CA/TX COVID), ORION reports new SOTA MAE/ RMSE/ MAPE in several regimes; ablations indicate sizable drops without multi-period fusion or the staged training; and on DREAM-3 causal discovery ORION beats several time-series CD baselines (AUC 0.6295 vs 0.592 CUTS)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The idea of validating discovered edges by an internal do-intervention mechanism, then routing attention through the validated graph, is clear and well-engineered.\n2. Multi-scale temporal design: The Hour/Day/Week â€œBelt Blockâ€ plus fusion is a simple, effective way to encode periodic structure; the staged training helps stabilize end-to-end optimization.\n3. Strong traffic and epidemic results, per-component ablations (single-stage training, removing TE-CausGAT, removing fusion, turning off intervention validation), and a causal-discovery check on DREAM-3."}, "weaknesses": {"value": "1. The intervention test is simulated within the model, and validity compares effect magnitudes to the learned ð¶. This can create confirmation bias: the same machinery that produced the graph is used to â€œvalidateâ€ it. There is no external interventional/perturbational source or counterfactual oracle. Please clarify safeguards (e.g., freeze parts during validation, use held-out time windows, or randomized response) and provide stress tests showing the module rejects spurious edges when the simulator is mis-specified.\n2. The DAG constraint uses a polynomial surrogate instead of the full NOTEARS regularization; no guarantee is given that cycles are eliminated, especially after segment fusion with a prior. Report cycle rates and orientation accuracy (not just adjacency AUROC).\n3. LLM retrieval is evaluated on small node subsets and excluded from the main SOTA tables for fairness. The added module (tokenization of time series, similarity via TinyLlama embeddings) raises reproducibility and cost questions; its contribution to headline results remains modest and localized.\n4. Forecasting comparisons are extensive, but statistical significance/CI and calibration are missing. For causal discovery, DREAM-3 is static gene regulation with very different noise/lag structures; explain how TE-CausGAT (designed for dynamic graphs) was specialized there. \n5. The paper sometimes equates improved MAE with â€œvalidated causality.â€ Given that validation is internal and priors include geographical adjacency, careful language would separate forecasting gains from causal identification."}, "questions": {"value": "1. How many nodes ð¾ are intervened per batch? Are interventions drawn independently over segments? Do you freeze \nC_fused while computing validity (to avoid trivial alignment)? What happens if you shuffle the intervention effects before computing \nVð‘–â†’ð‘—?\n2. Generalization of the learned graph. If you learn C_fused on one period (e.g., a month) and freeze it, how does performance transfer to a later month (distribution shift, holidays)? \n3. DREAM-3 setup: Are you learning a single static graph there, or segments? How are lags handled, and is the intervention validator used (with what simulator)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Sd5NWHw3Sz", "forum": "zhqiPuLQHU", "replyto": "zhqiPuLQHU", "signatures": ["ICLR.cc/2026/Conference/Submission1037/Reviewer_JAFJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1037/Reviewer_JAFJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1037/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761933293963, "cdate": 1761933293963, "tmdate": 1762915660025, "mdate": 1762915660025, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Building on CaST, the paper introduces a novel spatiotemporal forecasting model that builds causal graphs at different time points to account for changing spatial dynamics. This model is then evaluated on traffic and epimdeic datasets. The authors also conducted ablation studies and visualized the causal graphs at different time points on METR-LA."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "- Originality: The paper extends on CaST and proposes to construct causal structural matrices for each time step. This is intuitively sound as the traffic conditions change depending on the time of day and day of week, causing distribution shifts. This is partially validated with further analysis in section 5.3.\n- Quality: The model is benchmarked against many baselines.\n- Clarity: The figures help the reader conceptualize the information flow."}, "weaknesses": {"value": "- Literature Review\n  -  The following cited works are general Graph/NLP architectures, not involved in spatiotemporal forecasting.\n      > Existing spatiotemporal forecasting methods fall into three paradigms. The first category includes convolutional architectures such as GCN (Li et al., 2018) and TCN (Lea et al., 2016), alongside attention-based models like Transformer (Vaswani et al., 2017) and GAT (Velickovic et al., 2017).\n  - The subsection **Causal Inference in Spatiotemporal Modeling** needs more information to put this work in the context of existing literature. For instance, this is not informative to the reader for understanding the limitations of previous work.\n      > However, fixed causal graphs and incomplete validation limit their effectiveness. \n- Movitation\n  - The motivation behind using LLM-enhanced data retrieval is not clear, and the empirical improvement is marginal.\n- Clarity\n  - Figures 1, 3, 4, 5, 6, 7, 8, 9 are very hard to read.\n  - Section 5.3 shows important causal graph structure analysis that needs more details.\n  - Overall, the paper was hard to follow without reading the appendix for more information. The authors summarized the technical contributions, but failed to guide the reader in understanding how it fills a gap in the existing work. This can be fixed with a more elaborate related work section that shows the reader why dynamic causal inference is important."}, "questions": {"value": "- What is the node embedding without LLM-enhanced data retrieval, is it a fully connected layer or the raw data?\n- Do the causal graph connectivity correspond to real-world behaviour? The connections are further in the morning and evening than during off-peak, why is that?\n- Are the benchmark results directly copied from the papers? If so, are the data preprocessing steps and data pipeline identical?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0ytSQGrmpx", "forum": "zhqiPuLQHU", "replyto": "zhqiPuLQHU", "signatures": ["ICLR.cc/2026/Conference/Submission1037/Reviewer_ow75"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1037/Reviewer_ow75"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1037/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762027110899, "cdate": 1762027110899, "tmdate": 1762915659861, "mdate": 1762915659861, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Overall Response (1/2)"}, "comment": {"value": "# **In this post:**\n\n1. **Reviewer-acknowledged strengths** that validate our approach.\n2. **Major updates to the revised PDF** (main text and appendix).\n\n**Individual responses** with detailed answers, experimental verification, and improvements.\n\n---\n\n# **Strengths of Our Paper:**\n\n**Novelty and soundness of the core methodology**\n\n* **Reviewer ow75:**\n\n  * \"The paper extends on CaST and proposes to construct causal structural matrices for each time step. This is intuitively sound as the traffic conditions change depending on the time of day and day of week, causing distribution shifts.\"\n\n* **Reviewer JAFJ:**\n\n  * \"The idea of validating discovered edges by an internal do-intervention mechanism, then routing attention through the validated graph, is clear and well-engineered.\"\n\n* **Reviewer VcAa:**\n\n  * \"The paper leverages causal structure learning with do-intervention validation to learn a dynamic causal graph, which is interesting.\"\n\n**Multi-scale temporal modeling design**\n\n* **Reviewer JAFJ:**\n\n  * \"Multi-scale temporal design: The Hour/Day/Week 'Belt Block' plus fusion is a simple, effective way to encode periodic structure; the staged training helps stabilize end-to-end optimization.\"\n\n**Significant improvements in forecasting performance**\n\n* **Reviewer JAFJ:**\n\n  * \"Strong traffic and epidemic results\"\n  * \"ORION reports new SOTA MAE/ RMSE/ MAPE in several regimes\"\n\n* **Reviewer bhkv:**\n\n  * \"The underlying results and the comparison with a lot of different prior work is impressive and across the proposed datasets and benchmarks the paper does achieve significant improvements across a variety of metrics.\"\n  * \"The paper analysis and results and comparative metrics are very strong from a forecasting perspective.\"\n\n**Comprehensiveness and rigor of experimental design**\n\n* **Reviewer ow75:**\n\n  * \"The model is benchmarked against many baselines.\"\n\n* **Reviewer JAFJ:**\n\n  * \"Strong traffic and epidemic results, per-component ablations (single-stage training, removing TE-CausGAT, removing fusion, turning off intervention validation), and a causal-discovery check on DREAM-3.\"\n  * \"Ablations indicate sizable drops without multi-period fusion or the staged training.\"\n\n* **Reviewer VcAa:**\n\n  * \"Comprehensive experiments on both traffic and epidemic forecasting tasks.\"\n\n**Causal discovery and interpretability capabilities**\n\n* **Reviewer JAFJ:**\n\n  * \"On DREAM-3 causal discovery ORION beats several time-series CD baselines (AUC 0.6295 vs 0.592 CUTS).\"\n\n* **Reviewer VcAa:**\n\n  * \"Case studies demonstrate that the proposed method can discover meaningful causal relationships.\"\n\n* **Reviewer ow75:**\n\n  * \"This is partially validated with further analysis in section 5.3.\"\n\n**Presentation quality and clarity**\n\n* **Reviewer ow75:**\n\n  * \"The figures help the reader conceptualize the information flow.\""}}, "id": "Ln3efFtIZG", "forum": "zhqiPuLQHU", "replyto": "zhqiPuLQHU", "signatures": ["ICLR.cc/2026/Conference/Submission1037/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1037/Authors"], "number": 13, "invitations": ["ICLR.cc/2026/Conference/Submission1037/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763611132152, "cdate": 1763611132152, "tmdate": 1763611167457, "mdate": 1763611167457, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}