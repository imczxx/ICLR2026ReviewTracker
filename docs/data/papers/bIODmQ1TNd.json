{"id": "bIODmQ1TNd", "number": 11748, "cdate": 1758203505874, "mdate": 1763626339529, "content": {"title": "LiveWeb-IE: A Benchmark For Online Web Information Extraction", "abstract": "Web information extraction (WIE) is the task of automatically extracting data from web pages, offering high utility for various applications.\nThe evaluation of WIE systems has traditionally relied on benchmarks built from HTML snapshots captured at a single point in time.\nHowever, this offline evaluation paradigm fails to account for the temporally evolving nature of the web; consequently, performance on these static benchmarks often fails to generalize to dynamic real-world scenarios.\nTo bridge this gap, we introduce LiveWeb-IE, a new benchmark designed for evaluating WIE systems directly against live websites.\nBased on trusted and permission-granted websites, we curate natural language queries that require information extraction of various data categories, such as text, images, and hyperlinks.\nWe further design these queries to represent four levels of complexity, based on the number and cardinality of attributes to be extracted, enabling a granular assessment of WIE systems.\nIn addition, we propose Visual Grounding Scraper (VGS), a novel multi-stage agentic framework that mimics human cognitive processes by visually narrowing down web page content to extract desired information. \nExtensive experiments across diverse backbone models demonstrate the effectiveness and robustness of VGS.\nWe believe that this study lays the foundation for developing practical and robust WIE systems.", "tldr": "We introduce a benchmark for evaluating information extraction on live websites and a visual grounding scraper method.", "keywords": ["web information extraction", "web scraping"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c8af7178274eedffb4178e5abb0988fd8693f178.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents LIVEWEB‑IE, a benchmark for evaluating web information extraction systems on so‑called live websites, and introduces a baseline model, Visual Grounding Scraper (VGS). The benchmark is constructed through website selection, annotation, and verification, emphasizing content stability for reproducibility. However, since it deliberately focuses on static webpages and stable answers, the setting does not clearly demonstrate advantages over conventional snapshot‑based benchmarks in reflecting real temporal dynamics."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The benchmark clearly defines four task types covering single/multi‑attribute and single/multi‑value extraction, providing a systematic and comprehensive framing of the web information extraction problem.\n\nThe paper presents a coherent pipeline for website selection, annotation, and verification, showing solid engineering effort.\n\nThe introduction of the baseline model (Visual Grounding Scraper – VGS) illustrates the benchmark’s intended use and offers an initial reference for comparison."}, "weaknesses": {"value": "Although the paper highlights the live nature of the benchmark, most of the evaluated webpages are essentially static and rarely updated. As a result, the work does not clearly demonstrate any advantage of using “live” data over conventional snapshot‑based settings that are already stable and reproducible. Even HotpotQA, which is built on fixed Wikipedia content and unchanging commonsense facts, offers a comparable level of variability.\n\nThe benchmark explicitly filters for stable pages and attributes “unlikely to change,” ensuring reproducibility but sidestepping what genuinely makes web extraction live—coping with temporal and structural drift. A truly live evaluation should treat the target as a function responsive to time and environment rather than a fixed, time‑agnostic value.\n\nIncorporating multiple modalities in web information extraction is intuitively reasonable, but the paper does not clearly explain how these modalities are functionally integrated or why they are critical to the benchmark’s objectives. The description and experiments leave it unclear whether multimodality influences task formulation, model behavior, or evaluation outcomes, making this aspect feel under‑motivated despite being prominently emphasized."}, "questions": {"value": "Could the authors clarify what specific phenomena of “liveness” are actually captured in the current setup, beyond what a static snapshot benchmark would provide?\n\nGiven that the dataset construction deliberately filters for stable content, how does the current benchmark evaluate a system’s robustness to temporal or structural changes—if at all?\n\nMultimodality is highlighted as a major aspect of the work, but its functional role is unclear. Can the authors specify which tasks or results concretely rely on non‑textual modalities, and what insights would be lost if these were removed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "w3xMtnrint", "forum": "bIODmQ1TNd", "replyto": "bIODmQ1TNd", "signatures": ["ICLR.cc/2026/Conference/Submission11748/Reviewer_D9Lx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11748/Reviewer_D9Lx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11748/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760953895661, "cdate": 1760953895661, "tmdate": 1762922777767, "mdate": 1762922777767, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces LIVEWEB-IE, an online Web Information Extraction (WIE) benchmark, and proposes a multi-stage agentic framework called VGS (Visual Grounding Scraper). By mimicking human cognitive processes, VGS accurately identifies the information that needs to be extracted. Experiments demonstrate that VGS outperforms existing methods on both LIVEWEB-IE and several established WIE benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The proposed Visual Grounding Scraper (VGS) framework that mimics human information-seeking behavior on web pages is novel and practical. Multi-stage visual grounding (region → element → XPath) effectively reduces HTML noise, achieving great performance on both LIVEWEB-IE and other offline benchmarks."}, "weaknesses": {"value": "1. Weak Motivation. While the paper argues that performance on offline benchmarks fails to generalize to live websites due to temporal changes in web structures, this claim lacks sufficient empirical evidence. For instance, there is no direct comparison showing how existing methods degrade over time on the same websites, nor quantitative data on the frequency or impact of such changes. This undermines the core motivation, as it's unclear whether the offline-to-online gap is as significant as asserted, potentially overstating the need for LIVEWEB-IE.\n2. Reproducibility Undermined. Live evaluation causes inconsistent results across runs/time windows, breaking fair comparison and replicability. Website states can vary at each evaluation (e.g., due to updates in layout or content), leading to inconsistent results across runs. Different systems or papers might be tested in non-overlapping time windows, making it impossible to ensure fair comparisons.\n3. Expenditure and efficiency in VGS. The multi-stage VGS framework relies heavily on VLMs for visual grounding and pinpointing, which could incur significant computational costs and latency, especially for large-scale scraping. The paper does not discuss efficiency metrics (e.g., inference time or resource usage) or optimizations, making it less practical for real-world deployment compared to simpler HTML-based methods."}, "questions": {"value": "No specific questions. Please refer to the weakness section for detailed concerns."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nSVO1gJSW9", "forum": "bIODmQ1TNd", "replyto": "bIODmQ1TNd", "signatures": ["ICLR.cc/2026/Conference/Submission11748/Reviewer_uvkz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11748/Reviewer_uvkz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11748/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761833754675, "cdate": 1761833754675, "tmdate": 1762922777361, "mdate": 1762922777361, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a new benchmark, LiveWeb IE, which focuses on addressing the limitations of previous offline benchmarks that capture only a fixed snapshot in time. LiveWeb IE is claimed to evaluate models directly on live websites, thereby reflecting their performance on temporally evolving web content. The paper further proposes a Web IE framework, Visual Grounding Scraper, which leverages visual cues as guidance rather than directly locating the target element."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "-Empirical results show that the newly proposed benchmark is more challenging, and the performance on state-of-the-art LLM/LMMs are less saturated; showing a gap between WIE systems and humans on more up-to-date live websites.\n-The proposed VGS framework is effective on both closed-source and open-source models\n-The paper writing is clear and contains sufficient ablations on the VGS components"}, "weaknesses": {"value": "-While the LiveWeb-IE benchmark is claimed to be “evaluating directly against live websites”, it is not clear how the benchmark automatically evolves as the website updates over time. The dataset construction pipeline is still based on a snapshot of a certain time and requires human verification to curate the data. It is potentially an overclaim that the benchmark is “Live”.\n-It is also not clear how to handle layout changes through time while still keeping the evaluation/annotation valid; and how much human efforts are required to keep the benchmark up-to-date\n-The WIE task is very related to GUI and Computer Use tasks (especially in the settings where the html/a11y tree is available for the perception step); there is a lack of discussion and comparison with the widely studied GUI agent models and literature."}, "questions": {"value": "What is the key difference between the WIE task and a subset of GUI tasks (where the agent do not need to perform action but simply perform the perception)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DuuEMDcwBq", "forum": "bIODmQ1TNd", "replyto": "bIODmQ1TNd", "signatures": ["ICLR.cc/2026/Conference/Submission11748/Reviewer_RXSR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11748/Reviewer_RXSR"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11748/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761921408866, "cdate": 1761921408866, "tmdate": 1762922777013, "mdate": 1762922777013, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles the task of Web Information Extraction (WIE) directly on live websites, while prior work has mainly considered static websites.  For this, they introduce a new benchmark LiveWeb-IE which existing Web IE approaches seem to struggle on. The paper also introduces Visual Grounding Scraper (VGS) that leverages VLMs to narrow down the relevant web element to extract desired information. Experiments show that VGS outperforms current WebIE approaches on LiveWeb-IE while also demonstrating improvements on existing WebIE benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The methodology is described well and the paper is easy to read. \n2. The experimental results are pretty comprehensive, with a variety of backbone LLMs used. \n3. The LiveWeb-IE benchmark can be a very valuable resource to the research community."}, "weaknesses": {"value": "1. The novelty of the VGS approach is limited. The method mainly incorporates VLMs for prompting to narrow down relevant web elements, with the XPath generation part already being done in prior work [1]. \n2. The related work section is pretty lacking, with no discussion of distinctions/comparisons of VGS with prior WebIE methodologies.\n3. While VGS is relatively performant, the authors should also show a cost comparison with prior baselines. The approach of iteratively pass all regions of the webpage to VLM can be cost intensive. The paper does not have any discussion of the additional cost of the proposed approach. \n\n[1] Automating xpath query generation using nlp for streamlined web crawling and gui testing; Kaur et al 2025"}, "questions": {"value": "1. Given that the use of live websites within this benchmark creates the problem of information on these websites changing over time, how do the authors  plan to address this? Will the answers regularly be refreshed, similar to FreshQA [2]?\n\n[2] FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation; Vu et al 2023"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vaGboF8IPm", "forum": "bIODmQ1TNd", "replyto": "bIODmQ1TNd", "signatures": ["ICLR.cc/2026/Conference/Submission11748/Reviewer_v3S5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11748/Reviewer_v3S5"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11748/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762146075059, "cdate": 1762146075059, "tmdate": 1762922776625, "mdate": 1762922776625, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Responses to all reviewers"}, "comment": {"value": "*We sincerely thank all four reviewers for careful reading, constructive feedback, and valuable suggestions.*\n\nIn response, we revised the manuscript to address the points raised and enhance its clarity, highlighting all changes in blue. We also provide detailed responses to each point below. We hope the reviewers find the revisions and our accompanying responses helpful.\n\n**We are pleased that the reviewers recognized the key strengths of our work:**\n\n- **Clarity and Comprehensive Evaluation:** Reviewers commended the paper's clarity, readability, comprehensive experimental results, and sufficient ablation studies. [v3S5, RXSR]\n\n- **Contribution of Benchmark:** Reviewers highlighted that the benchmark is a valuable, challenging, and less-saturated resource, noting its solid engineering pipeline and systematic four-type task definition. [v3S5, RXSR, D9Lx]\n\n- **Novelty of Methodology:** Reviewers recognized the VGS framework as novel and practical, noting its multi-stage visual grounding effectively reduces noise and demonstrates strong performance across diverse models. Its role as a baseline was also valued for illustrating the benchmark's intended use and providing an initial reference for comparison. [RXSR, uvkz, D9Lx]\n\n\n**Our responses to the key concerns, along with the corresponding manuscript revisions, are as follows:**\n\n- **Novelty and Positioning of Methodology:** We clarified that the core novelty of VGS is not the final XPath synthesis, but the vision-based identification paradigm used to find the target elements. **We updated the Related Work (§ 2)** to explicitly differentiate this vision-based approach from prior HTML-based methods and to clarify the distinct goals of WIE versus GUI agents. [v3S5-W1&W2, RXSR-W3&Q1]\n\n- **Cost and Efficiency of Methodology:** To address concerns regarding computational cost and efficiency, **we performed a efficiency analysis (Appendix G, Fig.10).** While VGS is a wrapper generator, making it highly efficient for large-scale scraping, we analyzed the generation cost itself (Appendix E). The results show that for complex web pages, VGS is more efficient than HTML-only LLM baselines, as its visual filtering scales better than parsing token-heavy HTML. [v3S5-W3, uvkz-W3]\n\n- **Motivation for the Benchmark:** To provide empirical evidence for our benchmark motivation, **we conducted a new experiment (Appendix F, Tab.4).** We evaluated methods on original SWDE snapshots from the early 2010s and then on their corresponding live 2025 URLs. The results show a performance degradation on the live URLs, which validates our claim that performance on outdated snapshots fails to generalize. [uvkz-W1]\n\n- **Benchmark Design - \"Live\" Evaluation and Stability:** We clarified a critical distinction in our benchmark's design: we decoupled the stability of values from the stability of web page structures. LiveWeb-IE forces systems to process the current web structure—allowing for an accurate evaluation of their performance on the web page as it exists at that moment—while the stable values ensure the evaluation task itself remains valid. **We updated the Introduction (§ 1) and Dataset (§ 3), and added figures (Fig. 30, 31)** to make this critical point explicit. [v3S5-Q1, RXSR-W1&W2, uvkz-W2, D9Lx-W1&W2&Q1&Q2]\n\n- **Motivation for Multimodality:** We clarified that multimodality (text, images, hyperlinks) is critical for a benchmark aimed at real-world scenarios, where user queries are not limited to text. Our analysis (§ 6.2) confirms that non-textual extraction remains a key challenge where models struggle, justifying its inclusion as a core evaluation component. **We added clarifications on this point to the Introduction (§ 1), Dataset (§ 3.2), and Discussion (§ 6.2) sections.** [D9Lx-W3&Q3]\n\nIf there are remaining questions or any additional comments, we are happy to address them within the remaining discussion time.   \nThank you again for your thoughtful reviews.\n\nBest regards,    \nPaper 11748 Authors"}}, "id": "UyI7FyLlzh", "forum": "bIODmQ1TNd", "replyto": "bIODmQ1TNd", "signatures": ["ICLR.cc/2026/Conference/Submission11748/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11748/Authors"], "number": 12, "invitations": ["ICLR.cc/2026/Conference/Submission11748/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763629034210, "cdate": 1763629034210, "tmdate": 1763629034210, "mdate": 1763629034210, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}