{"id": "lE2UP2pZ1g", "number": 20601, "cdate": 1758308149635, "mdate": 1758806395980, "content": {"title": "Reflective Causal Agents", "abstract": "We present the first empirical evaluation of Causal Reflection, a framework that equips agents with causal reasoning, structured self-correction, and explainable decision-making in dynamic environments. Standard reinforcement learning and large language model agents often fail under non-stationary conditions, relying on spurious correlations rather than robust causal models. Building on the theoretical foundations of Causal Reflection which formalizes causality as a temporal function and introduces a Reflect mechanism for hypothesis-driven model revision. We implement Reflective Causal Agents. Across a dynamic benchmark environment, these agents outperform ablated and associative baselines in adaptability, predictive accuracy, causal graph recovery, and hypothesis generation. Our results establish Causal Reflection as a practical approach toward robust, interpretable, and generalizable AI systems.", "tldr": "Teaching Agents to Reflect and Causally Explain their decisions", "keywords": ["Causal Inference", "LLMs", "Explainability", "Reinforcement Learning", "Agentic Systems"], "primary_area": "causal reasoning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/aa8705eed1236b0222aa3dc0d4fdd178a43f14b7.pdf", "supplementary_material": ""}, "replies": [], "withdrawn": true}