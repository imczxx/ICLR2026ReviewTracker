{"id": "lro42pRwOl", "number": 16556, "cdate": 1758266002193, "mdate": 1759897232983, "content": {"title": "Subgraph Generation for Generalizing on Out-of-Distribution Links", "abstract": "Graphs Neural Networks (GNNs) demonstrate high-performance on link prediction\n(LP) datasets, especially when the distribution of testing samples falls within the\ndataset’s training distribution. However, GNNs suffer decreased performance\nwhen evaluated on samples from outside their training distribution. In addition,\ngraph generative models (GGMs) show a pronounced ability to generate novel\noutput graphs. Despite this, the application of GGMs remains largely limited to\ndomain-specific tasks. To bridge this gap, we propose leveraging GGMs to produce\nsynthetic samples which extrapolate between training and testing distributions.\nThese synthetic samples are then used for fine-tuning GNNs to improve link\nprediction performance in out-of-distribution (OOD) scenarios. We introduce a\ntheoretical perspective on this phenomena which is further verified empirically via\nincreased performance across synthetic and real-world OOD settings. We conduct\nfurther analysis to investigate how inducing structural change within training\nsamples improves OOD performance, indicating promising new developments in\ngraph data augmentation on link structures.", "tldr": "synthetic graph samples augment training dataset to improve LP performance in OOD scenarios", "keywords": ["subgraphs", "graph generation", "out of distribution", "distribution shift", "link prediction", "graph neural networks"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3b72eb9be1c12209dd4461f785649bcdb45c5e79.pdf", "supplementary_material": "/attachment/63eaab63ae113e03fbd69ff843dbb617e2e576ad.zip"}, "replies": [{"content": {"summary": {"value": "The paper tackles OOD generalization for link prediction. The core idea is to augment training with counterfactual subgraphs synthesized by a generative model so that a pre‑trained link predictor becomes robust to structural shifts. The proposed framework, FLEX, first pretrains a GNN and a semi‑implicit variational autoencoder on k‑hop subgraphs extracted with the labeling trick, then co‑trains them in an adversarial way (much like GAN). Counterfactuality is encouraged by maximizing KL divergence between the posterior and prior. On the LPShift benchmark, the method improves over baselines in most cases. Efficiency analyses show FLEX training/inference overheads are modest compared to a non‑parametric counterfactual baseline like CFLP."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. It has a well‑motivated problem and clear intuition.\n\n2. FLEX has simple, modular setup. It can be used with any pre‑trained GNN. and the $$/gamma$$ threshold tackle the tendency of generators to over‑densify.\n\n3. The empirical results over LPShift show the effectiveness of the FLEX."}, "weaknesses": {"value": "1. Limited backbone and generator diversity. Results are only on GCN and NCN. Modern link‑predictors (e.g., NBFNet, Neo‑GNN, LPFormer) are referenced but not evaluated; likewise, the framework is described as agnostic to the generator, but only SIG‑VAE is used. A “FLEX‑with‑VGAE/diffusion” variant or at least a plug‑in ablation would isolate how much the semi‑implicit choice matters.\n\n2. I am concerned about the efficiency. The recent trend of modern LP models has been shifted from subgraph-level prediction (SEAL) to more efficient node-level encoding (BUDDY, NCN). This shift makes the method efficient and applicable to the real-world use case with large-scale graphs. However, FLEX still operates at subgraph-level, meaning that it will struggle to scale to large graphs. For example, OGBL-Citation2 can be a good test bed to evaluate FLEX on large-scale dataset."}, "questions": {"value": "1. During inference time, is the cotrained GNN predictor being used for prediction or a new GNN being trained from scratch on the original graph+FLEX-generated graphs? If the former, will FLEX, as a data augmentation method, generalize across different GNN backbones? In other words, if the FLEX-generated graphs can improve performance of any LP methods (including both train-from-scratch GNN or even just heuristics like Common Neighbor), it will have much broader use case.\n\n\n2. Can FLEX improve the model performance not only on the distribution shift dataset but also general ones (which already has some degree of distribution shift)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YTxEZzLAr2", "forum": "lro42pRwOl", "replyto": "lro42pRwOl", "signatures": ["ICLR.cc/2026/Conference/Submission16556/Reviewer_Xvsx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16556/Reviewer_Xvsx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16556/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761776520678, "cdate": 1761776520678, "tmdate": 1762926637097, "mdate": 1762926637097, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces FLEX, a framework designed to improve OOD generalization in GNNs for the link prediction task. The core idea is to jointly train a GGM and a GNN to generate counterfactual subgraphs that expand the structural support of the training distribution. The framework demonstrates considerable innovation and empirical effectiveness, achieving efficient subgraph-level generation through a well-designed training mechanism. By reformulating link prediction in terms of structural feature distributions (e.g., Common Neighbors), the paper provides a principled theoretical foundation for understanding the limitations of traditional link predictors under distribution shift. Extensive experiments on multiple benchmark datasets demonstrate that FLEX outperforms both traditional OOD baselines and graph-specific methods in robustness and generalization performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "By reformulating the task in terms of structural feature distributions (e.g., Common Neighbors), the paper provides a principled explanation for why traditional link predictors underperform under distribution shifts. The proposed set-theoretic and ELBO-based analysis forms the unified theoretical perspectives on OOD generalization for link prediction.\n\nThe empirical evaluation spans multiple benchmark datasets and diverse graph structures, consistently demonstrating the robustness and OOD generalization ability of FLEX on link prediction tasks.\n\nFLEX performs counterfactual generation at the subgraph level, which is an efficient and scalable design choice. This approach reduces unnecessary graph-wide computation and provides a practical path toward efficient OOD generalization."}, "weaknesses": {"value": "Although the appendix provides a set-theoretic argument that counterfactual subgraph generation can enlarge the overlap between training and testing distributions, the analysis remains qualitative. It lacks a quantitative derivation of generalization bounds, risk functions, or error guarantees. The theoretical foundation that KL divergence regularization and structural diversity objectives necessarily improve OOD generalization remains insufficient.\n\nThe paper emphasizes generating “structurally different” counterfactual subgraphs, yet it does not explain how these generated subgraphs maintain semantic or structural validity. Furthermore, no visualization or statistical characterization of the generated samples is provided.\n\nAll experiments are conducted on homogeneous graphs for the link prediction task, its applicability to heterogeneous or more complex graph structures remains unverified.\n\nThe paper does not sufficiently isolate the contribution of each component within FLEX, as it lacks sensitivity analysis on the number and perturbation strength of generated subgraphs, ablation results for removing the KL constraint, and comparison between joint training with GNNs and independent optimization, making it difficult to determine whether the observed improvements truly originate from the proposed mechanism rather than from generic data augmentation or increased model capacity.\n\nThe paper claims efficiency through subgraph-level generation, yet several experiments report OOM or training exceeding 24 hours. There is no analysis of computational complexity, runtime, or hardware requirements.\n\nKey implementation details such as generator architecture, sampling strategy, and loss coefficients are missing. \n\nThe presentation is weak, with numerous grammatical, stylistic, and typographical errors throughout the manuscript. For example, line 178 “it’s”; line 240 “said features”; and line 340 “we an input links…”."}, "questions": {"value": "This paper provides a set-theoretic argument that counterfactual subgraph generation can enlarge the overlap between training and testing distributions. However, this analysis is mostly qualitative and lacks quantitative characterization of the generalization error or risk bounds. Could the authors provide a more rigorous theoretical or empirical analysis to substantiate the claimed generalization improvement?\n\nCould the authors provide visualization or statistical characterization of the generated subgraphs to demonstrate their structural diversity and semantic consistency?\n\nAll experiments are conducted on homogeneous, static graphs for the link prediction task. Have the authors evaluated FLEX on more complex graph settings such as heterogeneous graphs (e.g., MAG [1], DBLP [2])? If not, could they discuss the applicability or potential limitations of the proposed framework under such conditions?\n\nThe paper lacks a thorough ablation study to isolate the contribution of each FLEX component. Could the authors supplement experiments that (1) analyze the sensitivity to the number and perturbation strength of generated subgraphs, (2) evaluate performance without the KL-divergence constraint, and (3) compare joint versus independent training of FLEX and GNNs?\n\nSeveral experiments are marked as “OOM” or “>24h,” but no analysis of runtime, complexity, or hardware requirements is provided. Could the authors include a detailed analysis of computational complexity, training time, memory consumption, and hardware setup to clarify FLEX’s scalability and practical feasibility?\n\nThe paper omits important implementation details such as the generator architecture, sampling strategy, and loss coefficients. To enhance reproducibility, could the authors release the implementation and provide detailed hyperparameter settings and training configurations?\n\n[1] Hu, et al. OGB-LSC: A Large-Scale Challenge for Machine Learning on Graphs. NeurIPS 2021.\n[2] Zhang, et al. Oag-bench: a human-curated benchmark for academic graph mining. KDD 2024."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "1aN1AS25Gq", "forum": "lro42pRwOl", "replyto": "lro42pRwOl", "signatures": ["ICLR.cc/2026/Conference/Submission16556/Reviewer_NgWx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16556/Reviewer_NgWx"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16556/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761804000515, "cdate": 1761804000515, "tmdate": 1762926636527, "mdate": 1762926636527, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces FLEX, a subgraph generation framework designed to enhance the generalization capability of graph neural networks in out-of-distribution link prediction tasks. Its core idea is to utilize a graph generation model trained collaboratively with the GNN to generate counterfactual subgraphs that differ structurally from training samples but share consistent node features, thereby enabling GNN fine-tuning. The method encourages structural diversity by maximizing the KL divergence between the posterior and prior distributions (with quadratic penalty), while preserving semantic relevance. The authors validate FLEX's effectiveness across multiple synthetic (LPShift) and real-world (ogbl-collab, Amazon Cross-Domain) OOD settings, conducting ablation studies, hyperparameter sensitivity analyses, and structural alignment evaluations."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. OOD link prediction is a critical bottleneck for GNN deployment, yet existing work predominantly focuses on node/graph classification. This paper explicitly demonstrates that standard OOD generalization methods (e.g., IRM, CORAL) exhibit limited effectiveness in LP tasks (from Table 1), providing empirical evidence and establishing a robust problem motivation.\n\n\n2. The paper employs k-hop subgraph generation instead of full-graph generation, introduces a labeling trick to enable GNNs to perceive target edges, and utilizes a semi-implicit VAE to balance generation quality and scalability.\n\n3. Formally define meaningful structural differences through counterfactuals and feature condition equivalence, and prove in Appendix B that generated samples can scale training support sets to cover the test distribution from a set-theoretic perspective.\n\n4. The experimental results showed improvement."}, "weaknesses": {"value": "1. The paper repeatedly cites Pearl's causal framework, yet the FLEX generation process does not model structural equation models or interventions. Instead, it achieves structural differences solely through KL divergence maximization. This approach aligns more closely with diversity sampling in data augmentation than with counterfactuals in a strict causal sense.\n2. Gamma significantly impacts performance, but selection relies on grid search. In real-world out-of-distribution scenarios where the test distribution is unseen, how can gamma be adaptively set. If gamma is set too high, resulting in overly sparse graphs, critical structural information may be lost.\n3. FLEX has not been directly compared with recent OOD learning methods on LP tasks. While it is noted that these methods do not directly optimize LP generalization, experimental evidence is required to demonstrate that FLEX outperforms these generative OOD approaches.\n4. Appendix B's Theorem 1 assumes that the generated sample set S satisfies  \\mu(S\\cap(U\\T))>0. However, in practice, the Lebesgue measure of discrete graph spaces is zero. This assumption holds under continuous approximation but does not address discretization error."}, "questions": {"value": "please see weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6XuS53SwT8", "forum": "lro42pRwOl", "replyto": "lro42pRwOl", "signatures": ["ICLR.cc/2026/Conference/Submission16556/Reviewer_JXn7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16556/Reviewer_JXn7"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16556/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761888721773, "cdate": 1761888721773, "tmdate": 1762926636013, "mdate": 1762926636013, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes FLEX, a framework for improving out-of-distribution (OOD) link prediction in graphs. It co-trains a graph neural network with a semi-implicit variational autoencoder (SIG-VAE) that generates link-conditioned subgraphs—synthetic, counterfactual examples meant to expand the structural diversity of training data. By training on both real and generated subgraphs, the model aims to generalize better to unseen graph structures. Experiments on LPShift and real datasets are conducted to validate the proposed method."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation is clear and intuitive.\n\n2. The evaluation is conducted on four datasets with diverse shift schemes, and an ablation study is also provided."}, "weaknesses": {"value": "1. I’m not fully convinced by the performance improvements shown in Tables 1 and 3. AUC scores below 0.5–0.6 are essentially trivial, indicating near-random predictions. Although FLEX often yields statistically significant gains, improvements such as 50% → 52% provide limited practical utility. The per-dataset breakdown in Table 3 further shows that GCN+FLEX frequently increases AUC while remaining in the trivial range. In some cases (e.g., Backward–PA), FLEX even degrades GCN’s AUC from 73% to 59%, effectively turning a non-trivial score into a trivial one. In addition, the “average gain” reported for NCN+FLEX is somewhat misleading—it should be compared against its backbone (NCN), not against GCN.\n\n2. Table 5 reveals a substantial computational burden introduced by FLEX. The preprocessing and co-training steps are notably expensive, raising concerns about scalability to larger graphs or real-time applications. It is surprising that preprocessing even a small dataset like CiteSeer takes more than six hours.\n\n3. It would strengthen the empirical validation to include results on a more diverse set of GNN backbones, such as GAT or GIN, to test the general applicability of FLEX.\n\n4. It is not obvious how standard OOD generalization methods (e.g., IRM, VREx, GroupDRO) are adapted for link prediction tasks in this work. Providing implementation details or specific design choices for these adaptations would help the reader better assess fairness and reproducibility.\n\nMinor issue:\nAll parentheses are printed incorrectly."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wBFNMtAFEQ", "forum": "lro42pRwOl", "replyto": "lro42pRwOl", "signatures": ["ICLR.cc/2026/Conference/Submission16556/Reviewer_EKCx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16556/Reviewer_EKCx"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16556/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968773109, "cdate": 1761968773109, "tmdate": 1762926635615, "mdate": 1762926635615, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}