{"id": "ogKDAjoyy8", "number": 25570, "cdate": 1758369166876, "mdate": 1763729033445, "content": {"title": "Unsupervised Dynamic Graph Multi-Model Representation Learning for Temporal Patterns Discovery: Uncovering Parkinson’s Disease Stages Using Cerebrospinal Fluid Longitudinal Profiles", "abstract": "Dynamic graph learning methods typically capture local structural information\nand short-range temporal dependencies at each time step. In this work, we introduce a dynamic graph learning architecture that generates time-step embeddings capturing both local structural context and progression-trajectory patterns for each node across an entire longitudinal sequence. Unlike existing approaches, our framework clusters fused embeddings that integrate (i) the global temporal trajectory of each node and (ii) its local spatial context at every graph snapshot to discover meaningful temporal patterns in longitudinal datasets. We\nevaluate the proposed model in the context of Parkinson’s disease (PD) progression using six years of longitudinal cerebrospinal fluid (CSF) profiles from 24 patients. Visit-based graphs were constructed by representing patients as nodes enriched with peptide-abundance features, and by connecting patients with similar features profiles. A Graph Convolutional Network (GCN) captures visit-specific spatial relationships, while a sequential model learns global temporal representations. A fusion module integrates both sources of information to produce enriched node embeddings that reflect inter- and intra-patient molecular dynamics.\nClustering the learned embeddings reveals four distinct PD progression stages, supported by strong validity indices (Davies–Bouldin: 0.169; Calinski–Harabasz: 1264.24). Significant differences in motor severity (UPDRS 2 and UPDRS 3; p < 0.05) were observed across clusters, whereas non-motor scores showed a more diffuse pattern (p = 0.11). Compared with PCA, autoencoders, GCN, T-GCN, and GC-LSTM, the proposed architecture yields more clinically discriminative representations of disease severity. These findings demonstrate the potential of the proposed dynamic graph learning for data-driven disease staging and offer a generalizable framework for uncovering latent temporal patterns in longitudinal datasets.", "tldr": "We created a multi-model graph learning method that integrates node representations across graph snapshots, capturing temporal trajectories and spatial context.", "keywords": ["Learning Representation", "Dynamic Graphs", "Parkinson’s Disease", "deep learning", "unsupervised learning"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/191a2f52c796960b87d23a0f4222cf70110fe1f7.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents a novel unsupervised dynamic graph multi-model framework for discovering temporal disease patterns from longitudinal biomedical data, with application to Parkinson’s disease (PD). The authors integrate a Graph Convolutional Network (GCN) for learning spatial dependencies among patients at each clinical visit with a Gated Recurrent Unit (GRU) for modeling temporal progression across visits. The model fuses spatial and temporal embeddings to produce comprehensive node representations, which are then clustered to reveal disease stages. Evaluation on a longitudinal cerebrospinal fluid (CSF) dataset of 24 PD patients demonstrates that the proposed model identifies four distinct disease stages, with significant correspondence to clinical UPDRS motor scores."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. The combination of GCN (for intra-timepoint spatial modeling) and GRU (for temporal modeling) is well-motivated and implemented in a consistent framework.\n\n2. The linkage between discovered clusters and clinically meaningful UPDRS scores provides valuable interpretability and supports the validity of the results."}, "weaknesses": {"value": "- The manuscript is lengthy and sometimes reads as a descriptive technical report rather than a concise scientific contribution; key design motivations and insights are not emphasized. For instance, the abstract focuses too much on procedural details rather than emphasizing the core contributions, **resulting in an overly lengthy summary that obscures the main point.**\n- Only 24 patients were included in the final analysis, which significantly limits the generalizability and robustness of the conclusions.\n- The proposed architecture largely combines established modules (GCN and GRU) with standard fusion operations; no novel learning mechanism or theoretical contribution is introduced.\n- The impact of each model component (GCN, GRU, fusion layers) is not quantitatively assessed. **The ablation analysis is necessary.**\n- The paper does not provide a clear theoretical justification or complexity analysis explaining why the fusion of spatial and temporal embeddings improves representation quality.\n- While ICLR permits supplementary material for code submission, the authors provided a GitHub link (seems not fully anonymized) pointing to their repository, yet no implementation code could be found there."}, "questions": {"value": "Please refer to the above **Weaknesses**."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "y6O8Gx9U0x", "forum": "ogKDAjoyy8", "replyto": "ogKDAjoyy8", "signatures": ["ICLR.cc/2026/Conference/Submission25570/Reviewer_ZZtF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25570/Reviewer_ZZtF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25570/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761332338482, "cdate": 1761332338482, "tmdate": 1762943479974, "mdate": 1762943479974, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents an unsupervised dynamic graph learning framework designed to discover temporal disease stages from longitudinal biomedical data. The authors propose a multi-model architecture that integrates a single-layer GCN, to capture spatial inter-patient similarity at each time step with a GRU to capture temporal dependencies across visits. The fused embeddings are clustered to identify Parkinson’s Disease stages using longitudinal cerebrospinal fluid peptide profiles. The method is evaluated against standard baselines using clustering validity metrics and non-parametric statistical tests. Results show that the model identifies four interpretable PD stages that correlate with UPDRS motor scores."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Using dynamic graph learning for unsupervised disease stage discovery is original, particularly in modeling temporal patient trajectories via age-based graphs.\n\n2. The combination of GCN and GRU with a fusion module is conceptually coherent and technically straightforward. The reasoning behind using shallow layers to avoid over-smoothing is well-motivated.\n\n3. The use of clustering validity indices and statistical significance testing (Kruskal–Wallis, Dunn) to validate discovered disease stages adds credibility to the biological interpretation."}, "weaknesses": {"value": "1. The “multi-model” framework is effectively a shallow GCN + GRU fusion, a design already seen in many T-GCN and GC-LSTM variants. The contribution lies more in the application and evaluation context than in model innovation.\n2. Only 24 patients are used after filtering, which raises concerns about overfitting and the reliability of clustering outcomes. The reported high Calinski–Harabasz and low Davies–Bouldin scores may not generalize.\n3. The significance tests (e.g., Kruskal–Wallis, Dunn) are performed on very small sample sizes (some clusters appear to have few patients). The power of these tests and their reliability for clinical interpretation are questionable.\n4. Presentation issues and overclaiming. \n(a) The text occasionally conflates Parkinson’s and Huntington’s disease (see Section 2–3 confusion line 210–213), which undermines clarity. (b) Figures are referenced but not well-integrated in the discussion (e.g., Figure 2 architecture schematic is described verbosely but visually contributes little). (c) Claims of “first dynamic graph model for neural disorder diseases” seem overstated, given existing work in dynamic GNNs for biomedical longitudinal analysis."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "n1xON24u5S", "forum": "ogKDAjoyy8", "replyto": "ogKDAjoyy8", "signatures": ["ICLR.cc/2026/Conference/Submission25570/Reviewer_dDiY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25570/Reviewer_dDiY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25570/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761545551464, "cdate": 1761545551464, "tmdate": 1762943479291, "mdate": 1762943479291, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an unsupervised graph-based learning framework for longitudinal disease data analysis. Each node represents a single patient, and edges encode pairwise similarity between nodes. A single graph is constructed based on the same aged patients, and a set of such graphs represents the temporal evolution of the cohort. The model integrates GCN and GRU to capture spatio-temporal dependencies across these age-based graphs, and a downstream clustering algorithm is applied to identify disease stages. The clustering quality is evaluated using three metrics, demonstrating that the proposed framework generally outperforms the baseline GCN."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1)\tThe motivation of the study, i.e., learning longitudinal patterns of neurodegenerative diseases, is clear and intuitive. \n2)\tThe research includes statistical analyses of results."}, "weaknesses": {"value": "1)\tThere are lack of technical novelty and significant lack of comparisons with existing works. The proposed method does not introduce a fundamentally new learning mechanism. The model is simply built upon a simple GCN with an additional GRU layer and a downstream clustering phase, offering incremental changes. Moreover, existing spatio-temporal graph models were not sufficiently examined; among the adopted baselines, only T-GCN is a spatio-temporal graph model. Additional recent baselines [1-4] are encouraged to be added. Given the growing number of graph studies, I believe that the authors could find more spatio-temporal graph learning methods with open source codes to strengthen the contribution of the proposed method.\n\n[1] Cini et al., “Scalable Spatiotemporal Graph Neural Networks”, AAAI 2023\n\n[2] Tang et al., “Predicting 30-Day All-Cause Hospital Readmission Using Multimodal Spatiotemporal Graph Neural Networks”, IEEE Journal of Biomedical and Health Informatics, 2023\n\n[3] Cho et al., “Mixing Temporal Graphs with MLP for Longitudinal Brain Connectome Analysis”, MICCAI 2023\n\n[4] Pareja et al., “EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs”, AAAI 2020\n\n2)\tAblation studies of the model components and ranges of hyperparameter tuning (for both the proposed method and the baselines) are not provided. Including these details would improve the transparency and reproducibility of the experiments.\n3)\tOverall, the presentation of the paper has lots of room for improvement, including the writing, figures, and formulas. For example, the abstract contains too much details of experimental settings. The flow of the Introduction section is disorganized and mixed with background, motivation, and methodological contributions without a clear transition. In the method section, no loss function is given; instead, dataset description and model training configurations are presented, which would be more appropriately placed in the experiment section. Figure 2 is overly complex and difficult to interpret; it would benefit from a clearer depiction of the model architecture that highlights the key components and their interactions, rather than presenting every detail from all $G_t$. Furthermore, Fig. 3 does not provide exact numerical values of the performance metrics, making it difficult to compare the models quantitatively. Presenting these results in a table format would make the comparison clearer and more informative. The paper lacks an introduction of the evaluation metrics (e.g., UPDRS), which makes it difficult for readers outside the clinical domain to interpret the reported results."}, "questions": {"value": "1)\tWhy is the method described as a multi-‘MODEL’ framework? The proposed method combines a GCN and a GRU, but GRU (Gated Recurrent Unit) itself is a unit/layer, rather than an independent model architecture. Moreover, although the loss function of the proposed method is not explicitly stated in the paper, it appears that the method only utilizes a single loss function, which makes it difficult to call it ‘multi-model’ framework.\n\n2)\tWhy were edges constructed based on small nodal similarities rather than high similarities? I think the term ‘similarity’ might have been misused and should be replaced with ‘distance’, since Euclidean distance was employed as the measurement.\n\n3)\tCompared to recent spatio-temporal graph studies, what is the concrete technical advantage of the proposed method, and how do each model component meaningfully contribute to model performance or interpretability?\n\n4)\tIn line 127, it is stated that T-GCN and GC-LSTM are limited to capturing only short-term temporal graph features. However, the rationale behind this claim is not clearly supported. It would be helpful if the authors could provide either a theoretical justification or quantitative comparison results demonstrating how the proposed method captures longer temporal dependencies compared to existing approaches."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XBnqrKedJF", "forum": "ogKDAjoyy8", "replyto": "ogKDAjoyy8", "signatures": ["ICLR.cc/2026/Conference/Submission25570/Reviewer_9Jj8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25570/Reviewer_9Jj8"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25570/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761809874367, "cdate": 1761809874367, "tmdate": 1762943478963, "mdate": 1762943478963, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes a new unsupervised dynamic graph representation learning framework for longitudinal biomedical data applied to a Parkinson's disease progression dataset. It combines per-visit graph neural network embeddings based on patient similarity edges, yielding integrated patient representations that capture both within-visit context and the entire across-visits temporal trajectory. It is claimed that this method outperforms methods like PCA and autoencoders, among others, while also claiming that the clusters discovered are meaningful."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. It tackles the unsupervised representation learning problem for temporal graph-structured data in healthcare, an area that has been underexplored.\n2. The architecture seems to be a clever/innovative way to put together previous well-established GNN methods for the specific challenge at hand.\n3. The model naturally handles missing visits by simply omitting nodes for those missing visits (i.e. if a patient has no record at a given timepoint, they are not included in that snapshot graph). This approach to incomplete longitudinal data is practical and avoids complex imputation, while I also think it's a clever way to handle missing visits that I have not seen before.\n4. The resulting clusters appear reasonable. \n5. The method seems to achieve the highest clustering scores across many different baselines\n6. The paper reports that the clusters identified by the so-called Multi-Model are more stable than the GCN baseline, which is important."}, "weaknesses": {"value": "1. The experiments are run on a dataset with only 24 patients which is quite limited and thus raises concerns about robustness. The cluster findings might not generalise well for broader PD populations.\n2. It's unclear if this model would scale to larger patient cohorts, as training multiple GCNs with so many nodes and a sequence model could be computationally heavy and not handle hundred of patients as seen in other datasets without significant modification or risks of overfitting.\n3. Some aspects of the writing are confusing or inconsistent, which impacts clarity. For example, the authors describe constructing “age-based” graphs, when in fact each graph corresponds instead to a specific visit time (a better -and correct- term in my opinion would be visit-based graphs). The term “multi-model” is overused without a clear definition, and in my perspective only one model is actually being presented in this work, rather than many. Additionally, section 3.1 wrongly refers to \"both datasets\" even though only one dataset is used, suggesting a leftover from a previous draft. Finally, I believe \"Huntington's disease\" at the end of Related Work is a typo.\n4. The inclusion of t-SNE as a baseline for the embedding/clustering comparison is questionable. t-SNE is a stochastic visualisation algorithm, not a fixed representation learning method, so its results can vary run to run and it's not typically used for clustering performance benchmarks.\n5. The work lacks any evaluation on external datasets or discussion of generalisability. All results are on a single small PD cohort, and there's no evidence the learned representations would transfer to a different patient population or data source. This absence is a major concern for real-world application, since clinical tools typically require validation on independent cohorts.\n6. The paper does not clearly explain how the model was trained and tuned, which affects reproducibility. It's unclear how the train/validation split was handled given the unsupervised nature of the model. It is mentioned that hyperparameters were adjusted, but I don't know how (ie, was there a held-out validation set, or was the entire dataset used for training/clustering?). I'm left unsure whether the reported performance might be inflated by overfitting or trial-and-error hyperparameter tuning on the test set\n7. The authors do not provide any error analysis of potential misclustered cases. For a clinical application, understanding whether certain patients were borderline or inconsistently clustered (and why) would be not only important but also interesting. The absence of such analysis means we don't know how robust each assignment is, especially given the small sample size."}, "questions": {"value": "1. What exactly does \"multi-\" in \"multi-model\" mean? The term is used repeatedly (and even marked with a special icon in Figure 2), but it isn't explicitly defined.\n2. How were hyperparameters tuned and what was the training/validation splits used for model selection? Since this is an unsupervised task, did the authors use a portion of data to validate the representation quality when tuning parameters, or was the entire dataset used for both training and evaluation?\n3. What was the rationale for using t-SNE as one of the baseline embedding methods for clustering? t-SNE is stochastic and typically intended for visualization rather than as a fixed embedding for clustering as absolute Euclidean distances could vary across runs, so this was a bit unexpected to me.\n4. Given the unsupervised framework and how the graphs are created, it seems to me that this model cannot be directly applied to new patients. So, how were the authors thinking about using this in a clinical setting when applied to new people?\n5. Did the authors examine any cases of misclustered or borderline patients, or otherwise measure uncertainty in the cluster assignments? For example, were there patients who repeatedly switched clusters across different runs, or whose embeddings were near cluster boundaries?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "By15kaSWjB", "forum": "ogKDAjoyy8", "replyto": "ogKDAjoyy8", "signatures": ["ICLR.cc/2026/Conference/Submission25570/Reviewer_QbpR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25570/Reviewer_QbpR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25570/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761957938334, "cdate": 1761957938334, "tmdate": 1762943478756, "mdate": 1762943478756, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}