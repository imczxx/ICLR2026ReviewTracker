{"id": "4IPIhOgVqz", "number": 9726, "cdate": 1758136720829, "mdate": 1759897701997, "content": {"title": "DoFlow: Flow-based Generative Models for Interventional and Counterfactual Forecasting on Time Series", "abstract": "Time-series forecasting increasingly demands not only accurate observational predictions but also causal forecasting under interventional and counterfactual queries in multivariate systems. We present DoFlow, a flow-based generative model defined over a causal DAG that delivers coherent observational and interventional forecasts, as well as counterfactuals through the natural encoding–decoding mechanism of continuous normalizing flows (CNFs). We also provide a supporting recovery result under certain assumptions.  Beyond forecasting, DoFlow provides explicit likelihoods of future trajectories, enabling principled change-point and anomaly detection. Experiments on synthetic datasets with various causal DAG structures and real-world hydropower time series show that DoFlow achieves accurate system-wide observational forecasting, enables causal forecasting over interventional and counterfactual queries, and effectively detects anomalies.", "tldr": "", "keywords": ["Time Series", "Causal Inference", "Generative Models", "Flow Matching"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/47c5cb90e0d1e11d3428c9630d3cafaba597a0cf.pdf", "supplementary_material": "/attachment/984d1eba37087f16f24a0b064a329641c23ac88a.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel architecture based on Normalizing Flows for time-series forecasting. The model is designed to handle three types of forecasting queries: observational (standard prediction), interventional (predicting the effect of an action), and counterfactual (predicting what would have happened under a different action, given a specific observed outcome).\nWhile the idea is interesting and the authors provide an appropriate theoretical analysis of the method, I have some concerns about specifically the presentation, the empirical evaluation, and the motivation for counterfactual simulations that I would like to be addressed before recommending the paper for acceptance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.  **Novelty:** The core idea of using a unified Normalizing Flow-based framework to tackle observational, interventional, and counterfactual time-series forecasting is interesting and novel.\n2.  **Theoretical Grounding:** The paper provides a theoretical analysis of the proposed method, which adds rigor to the contribution."}, "weaknesses": {"value": "1. **Motivation and Practical Utility of Counterfactual Forecasting:** My most fundamental concern is the practical relevance of the counterfactual simulations as defined in the paper. The method hinges on conditioning on the exogenous noise `z` from an observed trajectory to ask \"what if?\" questions. However, the motivation for why a practitioner or decision-maker would need to perform a simulation conditioned on this specific noise instance is unclear.\n    - Could the authors provide a concrete, practical decision-making scenario where this type of counterfactual simulation provides unique, actionable information that cannot be obtained from simpler interventional forecasts?\n    - How does this concept translate to models that are not probabilistic (e.g., deterministic models)? Is intervening on a variable `X` sufficient for counterfactual reasoning if there are no further noise components?\n\n\n2. **Insufficient Experimental Details and Reproducibility:** The empirical evaluation is missing critical information, making it difficult to assess the validity of the results.\n    - **Hyperparameters and Model Specifications:** There are no details on the hyperparameters for the proposed model or for any of the baselines. Information on architecture, training duration, learning rates, etc., is essential. E.g. 908-910 is extremely vague and should be further specified.\n    - **Dataset Details:** The paper lacks information on the amount of data used for training, validation, and testing for each experiment, nor does it provide information on whether such a split was actually used. For the real-world power outage data, it is unclear how the model was trained, as there is presumably only one historical trajectory. Was the power outage event included in the training data, or was the time series split? This needs further clarification.\n    - **Intervention Details:** The nature of the interventions is not specified. Were the interventions in-distribution or out-of-distribution? How many variables were affected simultaneously? This context is crucial, especially given that the baselines appear to perform strikingly worse than the proposed method, even when trained on only the correct Parent set. A detailed description of the experimental setup is needed to understand this performance gap.\n\n3. **Unclear Explanation of Anomaly Detection Results:** The application to preemptive anomaly detection is highlighted as a key result, but is not sufficiently explained.\n    - How exactly is the detection performed? What quantity is measured, and what threshold defines an \"abnormal\" reading?\n    - The claim of *preemptive* detection is extraordinary. Why can the model detect an anomaly before it occurs? Is this consistent with the physical reality of the system, or is it an artifact of the experimental setup (e.g., information leakage)? A more detailed explanation of the underlying mechanism is necessary to properly assess this result.\n\n4. **Clarity and Connection of Paper Sections:** Certain parts of the paper seem disconnected or lack support.\n    - **L60 (Causal Discovery):** The discussion of the causal discovery literature feels vague and disconnected from the paper's core contribution, as the method fundamentally assumes a known and fixed causal graph (DAG). The authors should either better integrate this discussion or remove it.\n    - **Section 4.4:** This section appears unsupported and feels out of place, as it is not explained how exactly the anomaly detection can be performed.\n    - **Methodological Limitations:** It should be explicitly noted and discussed that the proposed model does not account for instantaneous causal effects within a single time step, which is a significant assumption in many real-world systems.\n    - **Table 1:** The table is overflowing and quite small. Please consider updating the formatting"}, "questions": {"value": "- As noted in the specified weaknesses. \n\n- What happens if the causal graph is not fully known or partly wrongly specified? Is DoFlow able to recover from such misspecifications?\n\n- How would you position your method against works such as [1] ?\n\n- Could you imagine under which conditions (or data distributions) DoFlow is struggling? A discussion on this could help the reader assess the applicability of your method to their problem. \n\n¹ https://arxiv.org/abs/2402.09891"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "XUZ5ALCRWC", "forum": "4IPIhOgVqz", "replyto": "4IPIhOgVqz", "signatures": ["ICLR.cc/2026/Conference/Submission9726/Reviewer_Pjb9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9726/Reviewer_Pjb9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9726/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760636292733, "cdate": 1760636292733, "tmdate": 1762921227701, "mdate": 1762921227701, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes _DoFlow_ a framework based in NeuralODEs and Recurrent Neural Networks (RNN), to estimate not only observational forecasting distributions, but also interventional distributions and counterfactuals, opening the door to reliable decision making in decision making with time-series.\n\nDoFlow models each variable in a known causal graph with its own NeuralODE, and conditions generation on a recurrent state that summarizes the past of that variable and its parents. This lets the model similate future trajectories in topological order. This allows to forecast observational series, interventional distributions and individual counterfactual outcomes. Because the model is a continuous normalizing flow, it also assigns likelihoods to predicted trajectories, which they use for anomaly and change-point detection. The authors provide a recovery result guaranteeing correct counterfactual reconstruction under certain assumptions, and they report experiments on synthetic causal time series and a real hydropower system. DoFlow matches or improves standard forecasting error compared to strong baselines, and uniquely supports interventional simulation, counterfactual rollout for each individual sequence, and early anomaly warnings before system failures."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Preliminaries about NeuralODE  and Flow matching are clear. Additionally, the method section: 'Time conditioned flow on a causal DAG'  is very well written and the method is easy to understand. The method is based on state of the art deep learning techniques, and all the proposed strategy is sound and practical. I find the model useful for future reseach. However, I would like to see a complete scheme of the implementation of the framework: how many NeuralODEs are needed, how the RNN is trained and combined with the Flow, etc.\n\n- The paper presents theoretical guarantees about the recoverability of counterfactuals, which are sound and mostly (see weaknesses) clear, although I have not checked the proofs of the Appendix in detail.\n\n- The results on synthetic data support the theoretical insights in interventional forecasting and in counterfactual estimation. Also, experiments on real-world data demonstrate an impresive performance, not only in estimating interventions, but also in estimating anomaly detection via likelihoods. Experiments are systematic, extensive and complex enough."}, "weaknesses": {"value": "- Neither the problem or the solution proposed are well specified in the introduction. There are many unconected paragraphs that do not provide a connected story line about the motivation, the **limitations of existing work** or the strategy that this paper proposes. For example, `line 96`says: ''motivated by these gaps...'', which gaps? Also, more information about the interventions that the model is suposed to handle has to be provided. What does '...counterfactual queries across the entire system'(`line 97-98`) mean?\n\n- I have a minor concern about the theory section, although I probably miss something. First of all, I do not see a condition of invertibility between X and U. Assumption A2 requires monotone $f(\\cdot, U_t)$. However, that is invertible only if the function is continuous and also if X is continous. How can we recover the value of the exogenous variable if the function is not bijective? I think that bijectivity should be required explicitly.\n\n- There are implicit assumptions that have not being discussed in the paper:\n1) Unconfoundedness / causal sufficiency. I.e., that all confounders are observed. If there exist time-varying confounders that are not observed, I do not see how the model can recover interventional distributions and counterfactuals.\n2) Positivity. If the observational data is not rich enough, that is, if the intervention is done in a point in which the density of the observational distribution is not zero, the model would extrapolate the causal effects.\n3) no interference and consistency: the classical SUTVA assumptions.\n4) Regularity conditions: I think that the functions of the SCM have to meet some regularity conditions in order this theory to hold.\n\n\n> Summary\n\nAlthough I have some concerns---specially with the introduction and the related work section---and many questions, I find the paper a good contribution to causal inference in time series. I think the employment of neuralODEs to causal time series forecasting, with the inclusion of DAGs, which allows for interventional and counterfactual inference, is great step forward in causal forecasting. For all the previous reasons, I will recommend to accept the paper, and I will be happy to raise my score if my concerns are covered."}, "questions": {"value": "- I do not really understand the implication that _counterfactual explanations_ in this work. Although the term _counterfactual_ is a common term in causal literature, counterfactual explanations are non-causal concepts that look for perturbations in the input to get the desired output. Is it necessary to include that in the introduction? I think those papers only introduce noise to the reader.\n\n- Related with the previous point, I have the same question with causal discovery literature. Although causal discovery is a much more related topic, why do you include that in the introduction, if you assume a known causal graph? I think the introduction is scarce, in general very noisy, and the objective of the work is not clear.\n\n- I am surprised because in the related work the authors name some models that solve interventional and counterfactual queries, but they do not name two models that are the state-of-the-art in this field and are based in normalizing flows, thus being very connected with the technologies of this paper: [1, 2]. Is there any reason for not including them?\n\n- In general, some related works are missing or they lack discussion. For example, haven't authors considered to include [3]? Or can authors discuss the limitations of [4]? Those are only some examples, but more discussion have to be added in the introduction/ related work.\n\n- Should the paper of continuous normalizing flows not be cited in line 115?\n\n- Although section 4 is well written in general, $\\Phi_\\theta$ should be defined before introducing them in the algorithms. Otherwise, the reading is more difficult. Instead, it is defined in section 5 (`line 322`).\n\n- Assumption A3 requires $Z\\sim N(0,1)$, but is that distribution necessary? Is not enough with having Z independent from $H_{t-1}$, independently of the base distribution of $Z$?\n\n- Everything that the DAG is assumed to be true, there is a question that arises: what if the DAG is not well specified? I think that some discussion about this fact would help.\n\n- Have the authors thought of exploring the violation of 'all confounders observed'? Some work on this have been explored in causal generative models: [5, 6]\n\n> References\n\n[1] Javaloy, A., Sánchez-Martín, P., & Valera, I. (2023). Causal normalizing flows: from theory to practice. Advances in Neural Information Processing Systems, 36, 58833-58864.\n\n[2] Khemakhem, I., Monti, R., Leech, R., & Hyvarinen, A. (2021, March). Causal autoregressive flows. In International conference on artificial intelligence and statistics (pp. 3520-3528). PMLR.\n\n[3] Liu, Y., Sun, Y., & Lim, J. H. (2023, June). Counterfactual Dynamics Forecasting–a New Setting of Quantitative Reasoning. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 37, No. 2, pp. 1764-1771).\n\n\n[4] Shenghao Wu, Wenbin Zhou, Minshuo Chen, and Shixiang Zhu. Counterfactual generative models\nfor time-varying treatments. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge\nDiscovery and Data Mining, pages 3402–3413, 2024\n\n[5] Almodóvar, A., Javaloy, A., Parras, J., Zazo, S., & Valera, I. (2025). DeCaFlow: A Deconfounding Causal Generative Model. arXiv preprint arXiv:2503.15114.\n\n[6] Kevin Muyuan Xia, Yushu Pan, and Elias Bareinboim. Neural Causal Models for Counterfactual Identification and Estimation. In The Eleventh International Conference on Learning Representations, ICLR 2023"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "dZ7amIcGQG", "forum": "4IPIhOgVqz", "replyto": "4IPIhOgVqz", "signatures": ["ICLR.cc/2026/Conference/Submission9726/Reviewer_jniY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9726/Reviewer_jniY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9726/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761839253821, "cdate": 1761839253821, "tmdate": 1762921227267, "mdate": 1762921227267, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The objective of this work, as expressed in Equation (9), is to obtain the counterfactual forecast $X_{\\tau+1:T}^{\\mathrm{CF}}$, given the interventions $\\mathrm{do}(X_I := \\gamma_I)$ applied to the predictor $X_{1:\\tau}$ and the corresponding factual forecast $X_{\\tau+1:T}^{\\mathrm{F}}$, along with optional conditional variabels.  The authors trained a mapping that connects the current state to its past states and parent variables, based on a directed acyclic graph (DAG), while optionally incorporating conditional variables.  Using these factors as inputs, the authors employed flow matching to generate the current state as a probability distribution over possible outcomes. This process is autoregressive. To support the training of the entire pipeline, the authors used simulated data generated from four causal patterns, encompassing both linear and nonlinear additive models. After the entire framework is trained, given the essential inputs and specified interventions,  it can generate the corresponding counterfactual forecast distribution."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper introduces an unexplored research direction, as claimed by the authors, which could be of potential value. \n\n2. The technical pipeline presented in this work appears to be complete. \n\n3. Producing the probability density function (PDF) instead of a single counterfactual forecast is an insightful approach."}, "weaknesses": {"value": "1. Several key concepts are not clearly introduced at the beginning. For example, in the Introduction section, it is unclear what is meant by “interventional question.” How are “binary or discrete, fixed-time actions, treatment focus …” defined? What does “extrapolating a counterfactual path and contrasting it” mean? Most importantly, the key concept of “counterfactual” should be clearly illustrated from the beginning. What does “these works do not encode causal DAGs or simulate system-wide trajectories under interventions” mean?\n\n2. In the Introduction, I would prefer the authors to directly explain why the research problem is important, rather than simply stating that it has not been studied and is important in many fields without sufficient evidence or support. The authors are also advised to briefly outline the key challenges of the problem and how this paper addresses them, instead of letting the related work take up a large portion of the Introduction.\n\n3. Why are the contributions placed in the Related Work section instead of the Introduction? Why does the Related Work section repeat content that has already been mentioned in the Introduction? In addition, the authors have not conducted a sufficiently thorough review of related work. Does the proposed method fall under an existing category of related work? How does it differ from similar studies?\n\n4. It is recommended that the authors introduce the concept of a causal DAG in the Preliminary section. It should explain more on how a multivariate time series can be represented as a directed graph. It sounds like paths in a graph, but can we still name them as time series?\n\n5. For the technical representation, the authors did not explain the meaning of the notation $\\gamma$ in equation (8), and did not explain the difference between notations X and x. The meaning of h should be explained early for equation (10), where it first appeared. Equation (11) is not clear. Is it a concatenation of vectors of scales or a mapping? What is the specific use of the conditions? In equation (11), I suggest the authors to remind the readers the meaning of s clearly: the time step of flow matching or the time series. The authors also did not explain the meaning of K nodes. How do we construct the nodes? What are they representing?"}, "questions": {"value": "1. Please address the presentation issues mentioned above.\n\n2. According to the mechanism of generative AI, particularly the flow-matching approach adopted in this work, the output represents only a sample from a potential distribution. Would this introduce additional uncertainty that complicates interpretability? Even if the analysis relies solely on the probability density function (PDF) to quantify significance, there remains a potential limitation regarding practical applicability: during training, small perturbations in past states may lead to extreme events in the future, and vice versa. Since such cases are statistical outliers, how can the authors justify that the trained flow-matching model is capable of capturing these rare patterns? If not, there is a risk that the forecasted extremes may be erroneously dismissed when relying exclusively on the PDF. \n\n3. This work appears to focus on utilizing past information, possibly generated by applying interventions to an existing dataset. However, what is the advantage of introducing an additional corresponding past state (perhaps the original one before intervention)? Why not treat this simply as a standard forecasting problem? Although the authors claim that causality plays a role, this assertion is not sufficiently justified. Moreover, since one past state could result from different interventions applied to various factual cases, would incorporating such additional causal structures introduce greater complexity or instability compared to a conventional forecasting framework?\n\n4. In Appendix B.5, the details on how the interventions were constructed are still missing. To demonstrate the practical value of this work, especially in real-world scenarios involving complex patterns, it is essential to justify that both the model design and the simulated data can effectively support training for complex pattern recognition. Unfortunately, the current version of the paper does not provide sufficient evidence to substantiate this key point.\n\n5. The reproducibility of this work is another major concern. The paper lacks essential records of hyperparameter settings, which is particularly important given the inherent outcome uncertainty of the generative AI model employed. Furthermore, the details of how the simulation data were constructed and how the model was trained to adequately capture complex real-world patterns, so as to perform as claimed in the case study, are not clearly documented. These omissions make the reproducibility and reliability of the reported results questionable.\n\nI would consider raising my scores if the above concerns are adequately addressed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "pIayABdJsA", "forum": "4IPIhOgVqz", "replyto": "4IPIhOgVqz", "signatures": ["ICLR.cc/2026/Conference/Submission9726/Reviewer_dDVY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9726/Reviewer_dDVY"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9726/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761856695361, "cdate": 1761856695361, "tmdate": 1762921226521, "mdate": 1762921226521, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes **DoFlow**, a time-conditioned continuous normalizing flow (CNF) defined over a causal DAG for multivariate time series. Each node’s flow is conditioned on recurrent states of the node and its parents, enabling an encode–decode procedure that supports observational, interventional, and counterfactual forecasting via abduct–action–predict. The training uses a conditional flow-matching loss; the model also exposes trajectory log-likelihoods used for automatic change-point/anomaly detection. On the theory side, under assumptions (independent noise, monotonicity in the noise, and a base-law condition on the encoded latent), the authors show that the encoded latent is a bijective function of the exogenous noise and derive a counterfactual recovery result for the encode–decode scheme; they relate this to BGM, noting their result does not require observational distribution matching. Empirically, they evaluate on synthetic DAGs (tree/diamond/chain/FC-layer) for interventional and counterfactual rollouts, and on a real hydropower system, reporting interventional/observational RMSEs and demonstrating early outage detection from log-densities (often 10–20 minutes in advance)."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Encoder–decoder CNF over a causal DAG neatly instantiates **abduction–action–prediction**, so observational, interventional, and counterfactual forecasts all come from one coherent mechanism.\n* **Impressive empirical results**: strong observational/interventional accuracy and compelling real-world demos (incl. early anomaly/outage detection), plus robustness across diverse synthetic DAGs.\n* **Theory that matches the use case**: clear assumptions lead to bijectivity-in-noise and a **counterfactual recovery** result that directly supports the encoder–decoder design.\n* **Clear, well-structured presentation** that makes the model easy to follow and reproduce."}, "weaknesses": {"value": "* **Positioning vs prior causal–flow work could be clearer.** The paper does a good job situating the CNF side (Neural ODEs, flow matching, encode–decode) but is lighter on contrasting with prior *causal* modeling using flows (e.g., works like *Causal Normalizing Flows: From Theory to Practice*, Javaloy et al.). A short subsection disentangling what comes from causal literature, what from flows, and what’s **novel here** would help readers map contributions more precisely.  \n* **Prediction intervals lack calibration evidence.** Interventional figures show 50%/90% bands, but I couldn’t find quantitative **coverage** or calibration metrics (e.g., empirical coverage, interval width/ACE, Winkler score, CRPS) to support the claim. Consider reporting coverage on synthetic data (where ground truth is known).\n* **Discussion section is a bit too sparse in my opinion** Even though the results seem good, I think a small discussion on particular on the limitations of this work would be interesting."}, "questions": {"value": "* Following weakness 2, do you have any results for the calibration of the output intervals?\n* Did you consider to replacing the RNN by a small transformer or just an attention layer? It would be more costly at prediction time, but would be interesting to see if it improves performance, and there could maybe even have some speed-ups in the case of a large past time series with a small forecast, due to parallelization."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JrvEub88Jd", "forum": "4IPIhOgVqz", "replyto": "4IPIhOgVqz", "signatures": ["ICLR.cc/2026/Conference/Submission9726/Reviewer_sw48"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9726/Reviewer_sw48"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9726/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927739168, "cdate": 1761927739168, "tmdate": 1762921225664, "mdate": 1762921225664, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}