{"id": "r4TvgVFo9L", "number": 6254, "cdate": 1757962407727, "mdate": 1759897926537, "content": {"title": "InvarGC: Invariant Granger Causality for Heterogeneous Interventional Time Series under Latent Confounding", "abstract": "Granger causality is widely used for causal structure discovery in complex systems from multivariate time series data. Traditional Granger causality tests based on linear models often fail to detect even mild non-linear causal relationships. Therefore, numerous recent studies have investigated non-linear Granger causality methods, achieving improved performance. However, these methods often rely on two key assumptions: causal sufficiency and known interventional targets. Causal sufficiency assumes the absence of latent confounders, yet their presence can introduce spurious correlations. Moreover, real-world data typically comprise only time series from multiple environments, without prior knowledge of interventions. It is difficult to distinguish intervened environments from non-intervened ones, and even harder to identify which variables or timesteps are affected. To address these challenges, we propose Invariant Granger Causality (InvarGC), which leverages cross-environment heterogeneity to mitigate the effects of latent confounding and to distinguish intervened from non-intervened environments with edge-level granularity, thereby recovering invariant causal relations. In addition, we establish the identifiability under these conditions. Extensive experiments on both synthetic and real-world datasets demonstrate the competitive performance of our approach compared to state-of-the-art methods.", "tldr": "", "keywords": ["Granger causality", "time series", "interventions", "latent confounders"], "primary_area": "causal reasoning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c36378904e9e37f74c08197fd61ca747c983ac5d.pdf", "supplementary_material": "/attachment/46f643f9c7b7eae3554009cd449cb306b4198d89.zip"}, "replies": [{"content": {"summary": {"value": "This paper develops a model that generalizes nonlinear granger causality to a setup where there are unobserved latent confounders and unknown interventions. The current methods in the field of nonlinear granger causality relies on the assumption of causal sufficiency, and the current methods of causal discovery including latent confounders do not handle unknown interventions. \nThe paper introduces the invarGC algorithm along with identifiability theorems, and then test it on synthetic and real world datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* As far as I know this paper is the first to extend Granger Causality to the case where there are nonlinear relations, unobserved latent confounders, and unknown interventions\n\n* This paper gives an algorithm along with an identifiability theorem, an experiment on a toy dataset, and an experiment on an almost real world dataset\n\n* At least equivalent to the tested models for the given task, and better when there are hidden confounders and interventions"}, "weaknesses": {"value": "* Some assumptions seem to be stronger than needed and others weaker than needed.\n\n* Many relevant state of the art methods are excluded from the experimental setup\n\n* In the real world dataset for benchmarking, the confounding factors are artificially introduced. The confounding factors are therefore not natural ones."}, "questions": {"value": "* Several state-of-the-art methods which are highly relevant in this setting have not been compared to, such as CD-NOD (Huang et al, 20), RegimePCMCI (Saggioro et al, 2020), JPCMCI (Günther et al, 2023) (these methods assume causal sufficiency similarly to GC, Dynotears, ... but unlike them  they can handle multiple regimes). There is also FCI-JCI (Mooij) which can handle multiple regimes as well as hidden confounding. It is true that FCI-JCI was not introduced  directly for time series but can be easily adapted (using the same strategy as varFCI (Malinsky)) to time series while taking into account instantaneous relations. Is there a reason for not including them?\n\n* Assumptions (1-4) are not explicitly introduced as Assumptions but rather as conditions A1,...,A4 within a Theorem, which is confusing. Later in the text they were refer to as Assumption 1, ..., Assumption 4.\n\n* Don’t you also need the faithfulness assumption to rule out deterministic relationships, not just to exclude path cancellations? (In other words, shouldn't you use the formal definition of Faithfulness which exclude both)\n\n* Since you assume no instantaneous relations and all edges are oriented using time, can't you replace faithfulness with adjacency faithfulness? \n\nMinor:\nI’ve always thought of Granger causality as a weaker notion of causality, more about prediction than true causal influence. However, under certain assumptions, doesn’t Granger causality actually correspond to genuine causality? If that’s the case, why do we still use the term Granger causality rather than simply referring to it as causality, given that it is traditionally considered useful mainly for predictive purposes ?\n\nReferences:\n\nBiwei Huang, Kun Zhang, Jiji Zhang, Joseph Ramsey, Ruben Sanchez-Romero, Clark Glymour, Bernhard Scholkopf.\nCausal Discovery from Heterogeneous/Nonstationary Data. JMLR, 2020\n\nElena Saggioro, Jana de Wiljes, Marlene Kretschmer, Jakob Runge\nReconstructing regime-dependent causal relationships from observational time series. Chaos, 2020\n\n\nWiebke Günther, Urmi Ninad, Jakob Runge. Causal Discovery for time series from multiple datasets with latent contexts\nUAI, 2023.\n\nJoris M. Mooij, Sara Magliacane, Tom Claassen.\nJoint Causal Inference from Multiple Contexts. JMLR, 2020.\n\nDaniel Malinsky, Peter Spirtes.\nCausal Structure Learning from Multivariate Time Series in\nSettings with Unmeasured Confounding. KDD workshop on causal discovery, 2018."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZpucIWPBfn", "forum": "r4TvgVFo9L", "replyto": "r4TvgVFo9L", "signatures": ["ICLR.cc/2026/Conference/Submission6254/Reviewer_B3Nt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6254/Reviewer_B3Nt"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761930618314, "cdate": 1761930618314, "tmdate": 1762918574505, "mdate": 1762918574505, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an algorithm to recover an invariant Granger causal graph from heterogeneous interventional time-series in the presence of latent confounding and unknown intervention targets. Under specific assumptions, the authors establish identifiability of the Granger causal graph, the subspaces spanned by latent confounders, and edge-level interventions.\n\nMethodologically, the approach combines networks for latent-confounder modeling, intervention identification, and invariant predictor learning, and recovers the graph via next-step prediction augmented with some regularizations to enforce invariance and identifiability.\n\nEmpirically, on both synthetic and real-world datasets, the method has performance that is competitive with or superior to strong baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper tackles an important gap in the literature by proposing an algorithm that recovers an invariant Granger causal graph under latent confounders and unknown interventions.\n\n2. The paper is well written and logically organized.\n\n3. The work provides both theoretical guarantees and empirical validation.\n\n4. The experimental results show impressive performance, often matching or outperforming the baselines."}, "weaknesses": {"value": "1. The theoretical guarantees are not solid.\n\n1.1 Assumption A4 is vague. Combining the main paper and the appendix, “...interventions are sufficiently diverse to distinguish true causal parents from non-parents.” means that, for $X^j_t\\in PA(X^i_{t+1})$, that \"there exists at least one environment in which the mechanism of the edge $ j \\rightarrow i$ differs from its invariant form.\", it also means that for any latent variables connected with the target variable, \"there exists an environment in which the mechanism along that direction differs from the invariant one. \".That is, by saying “...interventions are sufficiently diverse to distinguish true causal parents from non-parents,” although the intervention targets are unknown, they must intervene on enough edges so that every parent and latent variable for the target variable is identifiable. This is a very strict assumption.\n\n1.2 With Assumption A3, the latent-to-observed mechanism is invariant. Variables $X^j_t\\notin PA(X^i_{t+1})$ induced by such invariant spurious edges could be identified as parents, as there is no edge between $X^j_t$ and $X^i_{t+1}$ and hence such an edge cannot be intervened on, resulting in an invariant spurious edge between $X^j_t$ and $X^i_{t+1}$. I wonder, “by Assumption 4 there exists an environment in which the mechanism along that direction differs from the invariant one,” how this is true for latent variables, as interventions are only for observed variables.\n\n2. Important details about the algorithm are missing.\n\nWith finite samples, the hyperparameter $\\lambda$, $\\alpha$ in equation 12 are important. As claimed in the paper, \"For regularization parameters in a standard non-degenerate range, the increase ∆ dominates any penalty saving\", what is the practical choice of these hyperparameters? Will the performance be sensitive to these parameters?\n\n3. Scalability and running time are not reported.\n\nIt would also be beneficial to clearly list the number of nodes and confounders for each experiment. For instance, what is the number of nodes used for different types of the Causal-Rivers dataset?\n \n4. Ablation results need quantitative clarity.\n\nIt would be clearer to include quantitative results demonstrating the decrease in, for instance, AUROC and AUPRC without LCMCI or under other misspecifications. The current visualization is not straightforward, and it is not clear whether it reports a single trial or an average performance. For example, in Figures 3 and 4, what is the ground truth, what is the value in each cell, and why are some cells dark blue even though they are not extremely large or small compared with other cells?"}, "questions": {"value": "1. Could you please clarify the meaning of Assumption A4 with a toy example? More generally, what does this assumption require in terms of the number of interventions and the corresponding intervention targets?\n2. Are the other baselines also applicable to edge-level interventions? If the setting does not match their assumptions, how does that affect their performance?\n3. Is the connection restricted to $Z_t \\rightarrow X_{t+1}$ with lag 1? By default, does the confounder connect two variables both at time  $t+1$?\n4. Should there be a noise term in equation 1?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "iTStuPjtng", "forum": "r4TvgVFo9L", "replyto": "r4TvgVFo9L", "signatures": ["ICLR.cc/2026/Conference/Submission6254/Reviewer_2Sop"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6254/Reviewer_2Sop"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761935076716, "cdate": 1761935076716, "tmdate": 1762918574067, "mdate": 1762918574067, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper considers the problem of Granger causal discovery from time series data. Specifically, the authors address the presence of both latent confounding and multi-domain heterogeneity, where the causal relations among variables (i.e., the causal graph) are the same across all environments, but the causal mechanisms (functional relations) among observed variables may vary. The authors show that when the model is linear and the lag size is one (i.e., $X_{t+1}$ does not depend on $X_{1:t-1}$ or $Z_{1:t-1}$ conditioned on $X_t$ and $Z_t$), the true causal graph can be uniquely identified, which can be recovered by minimizing the loss function in the proposed recovery algorithm. Lastly, the authors evaluate the performance of the algorithm on both synthetic and real datasets."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The problem is well-formulated and addresses a realistic yet under-explored research setting.\n2. The authors conduct extensive simulations to demonstrate the effectiveness of the proposed algorithm, including evaluations on real-world datasets."}, "weaknesses": {"value": "1. The notation is a little confusing and difficult to follow. For example, the subscript of $W$ includes both numbers and variables. It would be better if the notation were unified, for instance, by using use $W_{0, 1:d}$ instead of $X_{0,X_{t+1}X_t}$.\n2. Some of the technical details are not clearly explained, such as the mathematical formulation of certain assumptions and related implementation details (see Q1 and Q4 below). \n3. It seems to me that the identification results consider a much simpler setting than the model described in Section 3.2 (see Q5 and Q6 below)."}, "questions": {"value": "1. Is there a mathematical formulation of \"sufficiently diverse\" in assumption (A4)?\n2. Are there any restrictions on the \"minimality\" of interventions in Theorem 3? For example, suppose there are three environments and two observed variables, where environment 1 is invariant and node $x_2$ is intervened upon in environments 2 and 3. Then there exists another model in which environment 2 is invariant and the node $x_2$ is intervened upon in environment 1 and 3.\n3. In line 359, does \"two environments remain purely observational\" imply that these two environments share exactly the same causal mechanisms?\n4. In Equation (7), is LCIM implemented as a neural network? If so, how are the parameters optimized?\n5. How do the causal effects among latent variables (i.e., W_{Z_{t+1}Z_t}) affect the performance of the recovery algorithm?\n6. Do the theoretical results presented in Section 4.3 only hold in the linear setting?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "90Vce907bn", "forum": "r4TvgVFo9L", "replyto": "r4TvgVFo9L", "signatures": ["ICLR.cc/2026/Conference/Submission6254/Reviewer_xZVy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6254/Reviewer_xZVy"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991016675, "cdate": 1761991016675, "tmdate": 1762929464383, "mdate": 1762929464383, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes InvarGC, a framework for Granger causality discovery in heterogeneous interventional time series subject to latent confounding. InvarGC identifies invariant causal relations by using data heterogeneity across environments, infers latent confounders through a dedicated inference module, and distinguishes intervened from non-intervened environments at the edge level. The authors offer formal identifiability guarantees of the recovered causal graph. The authors also conduct comprehensive experiments with synthetic and real-world datasets to support their claims."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Tackles a relevant setting: unknown interventions + latent confounding, and the problem setup is clear.\n- Identifiability results (graph, latent subspace, edge-level interventions) with explicit assumptions.\n- Good experimental results vs. strong baselines across synthetic and real data; sensible ablations on $L$."}, "weaknesses": {"value": "1. The largest real-world example (TEP) uses 33 variables, and Causal-Rivers uses node subsets. While nontrivial, this leaves open whether InvarGC scales effectively to higher-dimensional (>100 variables), longer sequences, or truly networked time series encountered in domains such as neuroscience, genomics, or industrial process control. No runtime or computational complexity results are reported either.\n2. Although the ablation study in Figure 3 analyzes the effect of the number of latent confounders ($L$) and regularization weights, the empirical analysis is somewhat superficial. There is insufficient exploration of how robust the method is to hyperparameter misspecification in practice, especially under lackluster prior knowledge of the true confounder count. It is unclear how challenging tuning becomes as the dataset grows, or whether the method is stable across a realistic hyperparameter grid.\n3. Edge-level detection uses an ad-hoc threshold; no uncertainty or sensitivity analysis."}, "questions": {"value": "1. What are training/runtime and memory costs as $d$ and $T$ grow?\n2. Can you provide more details on the choice and parameterization of the non-linear functions $f_i(\\cdot)$, $g_{k,i}(\\cdot)$, and $h_{k,i}(\\cdot)$? Are these always neural networks, and how sensitive are your results to their depth/width or activation choices?\n3. Is edge-level intervention detection always threshold-based? Would a probabilistic approach or inclusion of uncertainty quantification improve detection stability, particularly for weak interventions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ldmZZzZ8x4", "forum": "r4TvgVFo9L", "replyto": "r4TvgVFo9L", "signatures": ["ICLR.cc/2026/Conference/Submission6254/Reviewer_64gK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6254/Reviewer_64gK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6254/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991719195, "cdate": 1761991719195, "tmdate": 1762918573323, "mdate": 1762918573323, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}