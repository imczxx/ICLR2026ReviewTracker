{"id": "znuYrkEWmZ", "number": 11623, "cdate": 1758202601949, "mdate": 1759897564167, "content": {"title": "Unpacking In-Context Learning: Underlying Mechanism and Out-of-Distribution Generalization via Blended Training on Function Mixture", "abstract": "Transformer-based language models have achieved remarkable success across a wide range of real-world tasks, yet the internal mechanisms that govern their behavior remain only partially understood. Recent research has increasingly focused on the phenomenon of in-context learning (ICL) and its ability to generalize beyond the training distribution. However, many of these studies are conducted under simplified conditions, where both training and evaluation use prompts derived from a single, clearly defined function. As a result, it remains unclear how models behave in more structurally diverse or ambiguous settings.\nIn this study, we examine ICL under a blended training paradigm, in which each training prompt contains examples sampled from multiple function classes, without any explicit task identifiers or structural signals. Using standard ICL benchmarks such as linear and quadratic classification, we assess how this training approach influences model behavior, robustness, and generalization.\nOur findings indicate that under blended training, the commonly observed function selection behavior, where the model implicitly identifies and applies a single underlying function, plays a less central role. Instead, the model demonstrates more flexible pattern recognition, improved resilience to input noise, and stronger generalization to out-of-distribution tasks. These results suggest that training on structurally mixed prompts can enhance a model’s adaptability in unfamiliar scenarios.", "tldr": "Training transformers on blended prompts from multiple function classes fosters flexible pattern recognition, enhanced noise robustness, and improved out-of-distribution generalization, reducing reliance on single-function selection.", "keywords": ["In-Context Learning", "Blended Learning", "Function Mixture", "Function Selection", "OOD Generalization"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f49b7581537104622228a156f118213aa72b0681.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper makes a valuable contribution to the growing literature in-context learning (ICL) in Transformers. It introduces a \"blended training\" paradigm for ICL. In this paradigm, models are trained on prompts containing examples sampled from multiple function classes without any explicit task identifiers, thereby creating a more structurally complex and ambiguous learning environment. It provides crucial empirical evidence that the prevalent \"function selection\" behavior—a cornerstone of many current theoretical explanations for ICL—becomes less dominant under blended training. Empirical work demonstrates that this blended training approach leads to tangible performance improvements, including: model robustness to input noise, stronger generalization to out-of-distribution (OOD) tasks."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper identifies and tackles a significant limitation in the current In-Context Learning (ICL) literature. This work investigates the more complex and ambiguous scenario of \"blended training,\" which is a crucial step towards understanding ICL in more complex real-world applications.\n\n2. The experimental design allows for a controlled and interpretable investigation of a complex phenomenon, enabling the authors to draw clear comparisons to prior work.\n\n3. The key finding—that the dominant \"function selection\" mechanism diminishes in importance under blended training—is both surprising and insightful."}, "weaknesses": {"value": "1. The presentation of this paper is poor. Many descriptions is confusing and hard to understand. The details can be found in the part of Questions.\n\n2. The designed function type is kind of simple. I suggest to supplement more complex function class, such as MLP-based functions."}, "questions": {"value": "1. In this paper, the word \"structure\" is mentioned many times. For example, \"These works suggest that ICL involves structured, algorithmic behavior within the model.\" What's the meaning of structured behavior?\n\n2. In line 253, the label $\\hat{y}_{1,2,3...}$ are all computed. However, in the previous paragraph, only the value of y_100 is calculated.\n\n3. In section 4.2, the evaluation protocal is vague. Why \"the 100-th point was appended 2000 times\"?\n\n4. In Table 4, the meaning of each column is confusing. The author mentioned \"Specifically, we compare vanilla-trained and blendedtrained models to a baseline formed by individually trained models\". It seems that \"baseline formed by individually trained models\" are exactly vanilla-trained models."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GHYDNuZXwL", "forum": "znuYrkEWmZ", "replyto": "znuYrkEWmZ", "signatures": ["ICLR.cc/2026/Conference/Submission11623/Reviewer_K6Ru"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11623/Reviewer_K6Ru"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11623/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761623500574, "cdate": 1761623500574, "tmdate": 1762922695061, "mdate": 1762922695061, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors investigate blended training for in-context learning, a training paradigm introduced by [1]. Specifically, they analyze how models trained with a blended training strategy generalize to OOD tasks and how they perform function selection.\n\n[1] Yingcong Li, Xupeng Wei, Haonan Zhao, Taigao Ma. Can Mamba In-Context Learn Task Mixtures? ICML 2024 Workshop on In-Context Learning."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The questions asked are important and relevant -- In particular, how and when models generalize to OOD ICL tasks remains a relevant question for the field\n- The experiments testing the blended training setup are well-designed, and pair function classes in the blended training paradigm that are misaligned (e.g. Section 3.1)\n- The authors take steps to investigate what circuits in the model are important for OOD generalization, an interesting question with far-reaching implications"}, "weaknesses": {"value": "- The paper is confusing in places, making it hard to figure out what was done:\n    - The authors do not adequately describe the blended training setup. It is not clear from section 4.1 that in the blended training setup, the model (I think, from reading [1]) is also given information about which task $f_j$ is being presented to the model at the current sequence position. \n- The experiments testing OOD generalization could be improved:\n    - The authors choose the 'out-of-distribution' function class seemingly arbitrarily. When pretraining on some set of in-distribution functions, the out of distribution performance should depend on the interplay between the pretraining tasks and the OOD tasks, as in [2]. The authors argue that blended training improves OOD performance, but the OOD tasks considered here are too limited to make this claim. \n    - It is not clear how the 'task parameters' are chosen (e.g. $w, w_1, w_2, A, \\ldots$ in Table 1). Could the authors clarify this?\n    - In the comparison with the noise-augmented model (Section 5.3.1), the authors pick a fixed noise level ($p=0.3$) and assert that blended training outperforms the noise-augmented model. However, it is not clear whether this is just a result of the noise level selected. Perhaps a higher/lower value of $p$ would achieve comparable performance to blended training. \n- Attention head analysis: It is not clear to me from the authors' experiments that the function selection hypothesis is refuted. The authors show that there are attention heads whose presence is important to multiple function classes. \n    - It is possible that the 'top-performing' heads that the authors refer to perform the function of either i) embedding or generic, task agnostic manipulation of input data to fit the model's preferred internal representation or ii) consolidation of task-specific information via some generic prediction mechanism\n        - The heads the authors identify appear at early layers in the model, suggesting that i) is more likely\n    - The authors' ideas are based on the observation that ablation of one head shows a large change in model accuracy, ignoring the possibility of 'delocalized' circuits\n\n\n[1] Yingcong Li, Xupeng Wei, Haonan Zhao, Taigao Ma. Can Mamba In-Context Learn Task Mixtures? ICML 2024 Workshop on In-Context Learning.\n\n[2] Chase Goddard, Lindsay M. Smith, Vudtiwat Ngampruetikorn, David J. Schwab. When can in-context learning generalize out of task distribution? ICML 2025."}, "questions": {"value": "- How do models perform on OOD tasks as a function of how similar the OOD task is to the pretraining tasks?\n- Is $p=0.3$ the best-performing choice of noise level?\n- Is there a mechanistic explanation for what the heads are doing that would alleviate my concerns above?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IEzeqLLipM", "forum": "znuYrkEWmZ", "replyto": "znuYrkEWmZ", "signatures": ["ICLR.cc/2026/Conference/Submission11623/Reviewer_ThSc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11623/Reviewer_ThSc"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11623/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761662757479, "cdate": 1761662757479, "tmdate": 1762922694654, "mdate": 1762922694654, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "ICL is a key capability of large language models, yet its underlying mechanism remains unclear. Prior work has primarily focused on contexts drawn from a single function class, overlooking the structural diversity and ambiguity that real-world tasks often exhibit. This paper introduces mixed training, where each training prompt contains samples from multiple function classes, without any task labels or structural cues."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper proposes and systematically evaluates a mixed training paradigm, challenging the conventional single-function selection assumption. It extends ICL research from single-function settings to multi-function mixed scenarios, better aligning with real-world tasks.\n\n- Synthetic tasks are used to control variables, facilitating mechanistic analysis. Multiple experiments are designed to test the hypotheses from different perspectives. Through attention-head ablation analysis, the paper shows that the model does not modularly select functions; instead, it shares computational resources and performs dynamic fitting."}, "weaknesses": {"value": "- Limited task complexity: The function classes used in the study are relatively simple, which raises concerns about the generalizability of the conclusions.\n- Small model scale: The experiments rely on GPT-2–sized models, limiting the universality of the findings.\n- OOD tasks remain structurally aligned with training tasks: Although the paper evaluates out-of-distribution scenarios (e.g., transferring from LC/CC to R), the OOD tasks still share structural similarities with the training distribution. Fully novel task types are not explored.\n- Unaddressed training efficiency: The paper does not discuss whether mixed training requires more data or longer training time.\n- Readability issues in experimental results: Some results are difficult to interpret; for example, the results in Table 4 are quite confusing for the reader."}, "questions": {"value": "- How are the points (pts) chosen in Experiment 5.2.2?\n- The experiments show that attention heads are shared across tasks. Does this imply that these heads learn more fundamental primitive operations?\n- Could the paper report training efficiency results? (e.g., training time, convergence behavior, or computational cost)\n- How is the context length determined in the experiments? Are results available for other context lengths?\n- During training, for instance in the vanilla setting, how is the ordering of mixed function-class samples within the context determined?\n- How does the dimensionality of the data affect the results? What is the dimensionality of $x$ in your experimental setup? Considering that embedding dimensions in real-world scenarios are typically much higher, how does your work strengthen its claims in terms of empirical validity and generalizability under higher-dimensional settings?\n- Although the experiments suggest that the “function selection” assumption does not hold, is there a new theoretical framework proposed to explain how the model achieves dynamic adaptation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "USPs9ZbXMZ", "forum": "znuYrkEWmZ", "replyto": "znuYrkEWmZ", "signatures": ["ICLR.cc/2026/Conference/Submission11623/Reviewer_M4J5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11623/Reviewer_M4J5"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11623/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761925514457, "cdate": 1761925514457, "tmdate": 1762922694254, "mdate": 1762922694254, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper compares on various common ICL tasks to demonstrate that hybrid training does not degrade the model's predictive performance, in some cases it even outperforms the traditional training. It also conduct a mechanism analysis on the model's internal mechanisms under different training strategies, which reveals that hybrid-trained models are more flexible in dealing with task diversity and noise. Experiments show that hybrid training improves the model's noise robustness and OOD generalization ability, especially when training data is incomplete or tasks are diverse."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper breaks through the limitations of traditional ICL research, which only trains and evaluates on a single function or task distribution. \n\n2. It adapts the concept of Blended Training, where each training cue consists of a mixture of samples from multiple function categories, without explicit task labels. This setting more closely resembles the real-world scenarios of ambiguous and structurally diverse tasks, thus possessing strong practical significance and theoretical values."}, "weaknesses": {"value": "The paper almost does not propose any method, the proposed masking-based diagnostic is too naive. It indeed has a mechanism analysis through controlled experiments, but there's no any theoretical analysis about it, and I don't think this mechanism analysis alone is enough for a conference like ICLR."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GdO172kf89", "forum": "znuYrkEWmZ", "replyto": "znuYrkEWmZ", "signatures": ["ICLR.cc/2026/Conference/Submission11623/Reviewer_NRwE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11623/Reviewer_NRwE"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11623/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984086016, "cdate": 1761984086016, "tmdate": 1762922693942, "mdate": 1762922693942, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies in-context learning (ICL) under a new blended training paradigm where each prompt mixes examples from multiple function classes without task identifiers.\n\nThe goal is to test whether models trained this way can go beyond “function selection”—the hypothesis that Transformers identify and apply one underlying function per context—and instead demonstrate more flexible adaptation and better out-of-distribution (OOD) generalization.\n\nUsing small GPT-2–style Transformers on synthetic datasets (linear, quadratic, checkerboard, and residual classification), the authors compare vanilla (single-function prompts) vs blended (multi-function prompts) training.\n\nThey report that blended training:\n1. matches vanilla performance on seen tasks,\n2. generalizes better to unseen function mixtures,\n3. exhibits more robust behavior under input noise,\n4. and uses overlapping attention heads across tasks—suggesting shared, rather than function-specific, representations."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper targets an important and underexplored question: how ICL mechanisms change when the context combines heterogeneous task structures.\n2. Multiple diagnostics are considered—accuracy, OOD generalization, attention ablation, and noise robustness—offering a multi-angle empirical view."}, "weaknesses": {"value": "1. The paper is difficult to read and often imprecise. Key issues include: Long, unfocused paragraphs that mix motivation, results, and speculation. Undefined or vague terms (e.g., “lowest-error preference” in \"Mechanism analysis\" contribution). Ambiguous phrasing like “the model demonstrates more flexible pattern recognition” without quantitative evidence. Overall, the text reads like a draft in progress, not a polished ICLR paper.\n\n2. The Related Work section misses major lines on ICL mechanism as function learning such as: Function vectors (Todd et al., 2024; Hu et al., 2025), In-context gradient descent (von Oswald et al., 2023; Ahn et al., 2023).\n\n3. In table 2-3, no baseline for training on explicit mixtures or multi-task pretraining is provided, making it unclear whether improvements come from blending or merely data diversity."}, "questions": {"value": "1. What does this paper add beyond Li et al. (2024b)? Is it a new mechanism, a stronger empirical validation, or a diagnostic framework?\n\n2. Each subsection introduces H1/H2 vaguely. Can you provide mathematical or schematic definitions of what “function selection” vs “context adaptation” means?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PnR1hY1jMR", "forum": "znuYrkEWmZ", "replyto": "znuYrkEWmZ", "signatures": ["ICLR.cc/2026/Conference/Submission11623/Reviewer_Z35Y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11623/Reviewer_Z35Y"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission11623/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762241344360, "cdate": 1762241344360, "tmdate": 1762922693519, "mdate": 1762922693519, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}