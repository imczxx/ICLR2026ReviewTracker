{"id": "PO2iULmu5e", "number": 18334, "cdate": 1758286524588, "mdate": 1763743538760, "content": {"title": "RAIN-Merging: A Gradient-Free Method to Enhance Instruction Following in Large Reasoning Models with Preserved Thinking Format", "abstract": "Large reasoning models (LRMs) excel at a long chain of reasoning but often fail to faithfully follow instructions regarding output format, constraints, or specific requirements. We investigate whether this gap can be closed by integrating an instruction-tuned model (ITM) into an LRM. Analyzing their differences in parameter space, namely task vectors, we find that their principal subspaces are nearly orthogonal across key modules, suggesting a lightweight merging with minimal interference. However, we also demonstrate that naïve merges are fragile because they overlook the output format mismatch between LRMs (with explicit *thinking* and *response* segments) and ITMs (answers-only). We introduce **RAIN-Merging** (Reasoning-Aware Instruction-attention guided Null-space projection Merging), a gradient-free method that integrates instruction following while preserving thinking format and reasoning performance. First, with a small reasoning calibration set, we project the ITM task vector onto the null space of forward features at thinking special tokens, which preserves the LRM's structured reasoning mechanisms. Second, using a small instruction calibration set, we estimate instruction attention to derive module-specific scaling that amplifies instruction-relevant components and suppresses leakage. Across four instruction-following benchmarks and nine reasoning & general capability benchmarks, RAIN-Merging substantially improves instruction adherence while maintaining reasoning quality. The gains are consistent across model scales and architectures, translating to improved performance in agent settings.", "tldr": "", "keywords": ["Large Reasoning Model", "Instruction Following", "Model Merging", "Null-Space"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f483458657434d73b7cf5b19f7d7472efe97da3c.pdf", "supplementary_material": "/attachment/4dd9b68dcff0773dbb2e53edbc4e8c8507074406.zip"}, "replies": [{"content": {"summary": {"value": "This paper uses task vectors to alleviate the issue of reasoning models where they are struggling with instruction following. Authors proposed a gradient-free method to address this problem, called Reasoning-Aware Instruction-attention guided Null-space projection Merging (RAIN-Merging). At the first stage, ITM task vector is projected on the null space of forward features at thinking tokens, and at the next stage, an instruction attention is estimated to further amplify instruction-relevant components."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-written, and figures and tables help better understand the complicated method that authors proposed.  \n2. Reasoning models are bad at instruction-following is a well-known phenomenon, and the proposed method uses simple task vectors to boost the instruction-following ability while maintaining the original reasoning performance.  \n3. The results are reported in multi-dimensions according to the research questions in Section 4. Specifically, reporting a performance in agentic scenarios is a very good experimental evidence that the proposed method works well in the real world.  \n4. The proposed method is theoretically well-grounded."}, "weaknesses": {"value": "1. In Table 1, there are some cases where RAIN-Merging outperforms the performance of the original LRM. Authors hypothesize that stronger instruction adherence improves CoT quality. -- I suggest to prove this hypothesis (by manually checking randomly sampled predictions). This phenomenon seems very interesting to me since my intuition says the opposite. Specifically, the performance is increased by ~10% in GPQA. How is it possible?  \n2. In the ablation study, only stage 2 is ablated. Therefore, the paragraph's name should be scoped down. Also, could you ablate stage 1 as well to prove its effectiveness?\n\nDespite some of these questions, I believe this paper would contribute to the community significantly."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dwNwWZLWeV", "forum": "PO2iULmu5e", "replyto": "PO2iULmu5e", "signatures": ["ICLR.cc/2026/Conference/Submission18334/Reviewer_2pjo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18334/Reviewer_2pjo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18334/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761602479394, "cdate": 1761602479394, "tmdate": 1762928046873, "mdate": 1762928046873, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces RAIN-Merging, a gradient-free method for enhancing instruction following in Large Reasoning Models while preserving their structured thinking format. The approach projects instruction task vectors onto the null space of thinking token features, then applies instruction-attention guided scaling coefficients. The method demonstrates improvements across instruction-following and reasoning benchmarks without requiring gradient-based training."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Merging ITM and LRM is an interesting and practical problem.\n2. The finding that task vectors' principal subspaces are nearly orthogonal across key modules provides an interesting understanding about the parameter space structure of these capabilities.\n3. The evaluation spans multiple model families and sizes.\n4. The gradient-free nature makes this a practical, accessible alternative to SFT.\n5. Using four instruction-following benchmarks and multiple reasoning datasets provides reasonable empirical breadth."}, "weaknesses": {"value": "### 1. Data Contamination / Generalization Concerns\nFor example, Qwen2.5-7B-Instruct is trained on IFEval, InfoBench, and ComplexBench as calibration data, and this paper evaluates RAIN-Merging on the same benchmarks. Results may not generalize to unseen instruction-following or reasoning scenarios. Maybe the null-space projection and coefficients are optimized on the same distribution they're tested on.\n\n### 2. Data\nThe paper evaluates instruction-following and reasoning on separate benchmark datasets. While the paper attempts to evaluate integrated capabilities using agentic scenarios in Table 3, these tasks may not simultaneously stress complex reasoning and strict, arbitrary instruction-following to the same degree as the benchmarks. The main evaluation in Table 1 still separates these two skills, leaving a gap in the core claim.\n\n### 3. Metric\nThe paper relies primarily on accuracy metrics across all benchmarks. More metrics would be valuable to answer such questions: Is the thinking process coherent, or just structurally preserved (only thinking tokens)? Which types of instructions improve most/least? Are outputs semantically following instructions, or just superficially (evaluation on phrased instructions)?\n \n### 4. Method\nIn stage 1, how do we know null-space projection preserves reasoning ability rather than just token usage? Does the model still perform meaningful reasoning in <think> blocks, or just maintain the format while reasoning quality degrades? If the reasoning benchmark results show preservation, but is this because the reasoning content is truly preserved, or the model learned to use thinking tokens without meaningful reasoning?\n\nIn stage 2, what happens when reasoning and instruction-following are highly entangled? How are attention-guided coefficients computed when both reasoning and instruction-following are active in the same tokens?"}, "questions": {"value": "* What is your hypothesis for why reasoning ability and instruction-following have low coupling in parameter space? Is this due to structural differences (thinking tokens vs. output format) rather than semantic content differences?\n* How can you verify that Stage 1 preserves actual reasoning ability (content) and not just the habit of using thinking tokens? What metrics or analyses distinguish these scenarios?\n* In Stage 2, how do attention-guided coefficients handle tokens where reasoning and instruction-following are deeply entangled (e.g., instructions about reasoning strategy, logical constraints, or structured argumentation)? Can you provide examples and analysis?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Tlb8bqsR5Z", "forum": "PO2iULmu5e", "replyto": "PO2iULmu5e", "signatures": ["ICLR.cc/2026/Conference/Submission18334/Reviewer_i2ye"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18334/Reviewer_i2ye"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18334/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761909586769, "cdate": 1761909586769, "tmdate": 1762928046464, "mdate": 1762928046464, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents RAIN-Merging, a novel two-stage, gradient-free method for merging Large Reasoning Models (LRMs) with Instruction-Tuned Models (ITMs) to enhance instruction-following capability while preserving structured reasoning outputs. The approach leverages task-vector orthogonality and introduces a reasoning-aware null-space projection to maintain thinking formats, combined with instruction-attention guided coefficients to improve instruction adherence. Extensive experiments across multiple benchmarks and model scales demonstrate that RAIN-Merging significantly improves instruction-following performance without compromising reasoning or general capabilities. The method offers a computationally efficient and interpretable alternative to supervised fine-tuning, making it highly relevant for real-world applications of LRMs."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1.   Novel Research Problem: The work addresses an important and underexplored challenge—balancing instruction-following and reasoning capabilities in LRMs—through model merging, a lightweight and training-free approach.\n2.  Effective Methodology: The two-stage RAIN-Merging framework is well-motivated, combining null-space projection to preserve reasoning structure with attention-guided scaling to enhance instruction alignment, all without gradient updates.\n3.   Comprehensive Experiments: The paper provides extensive evaluations across multiple instruction-following, reasoning, and agentic benchmarks, with consistent improvements shown across different model sizes and architectures.\n4.  Clear and Well-Structured Writing: The paper is clearly written, with a logical flow, detailed derivations, and accessible explanations of both the motivation and technical contributions."}, "weaknesses": {"value": "While the method is evaluated on several model families (Qwen, Llama), further validation on a wider range of architectures and modalities (e.g., multimodal or multilingual models) would strengthen the generalizability claims."}, "questions": {"value": "1.  Overall, I think you have done very meaningful work. My question is: Will your work be open-sourced as a toolkit in the future? I am very much looking forward to using the methods proposed in your paper.\n2.  Have you considered validating your method on larger model sizes (e.g., above 30B parameters) to further verify its effectiveness?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "fJp4UTRKW0", "forum": "PO2iULmu5e", "replyto": "PO2iULmu5e", "signatures": ["ICLR.cc/2026/Conference/Submission18334/Reviewer_snDt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18334/Reviewer_snDt"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18334/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761985945624, "cdate": 1761985945624, "tmdate": 1762928046031, "mdate": 1762928046031, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes RAIN-Merging, a training-free (gradient-free) technique to improve instruction following in Large Reasoning Models (LRMs) without degrading their explicit “thinking→answer” format. The method has two stages: (1) Reasoning-aware null-space projection that projects the instruction-tuned model’s task vector into the null space of forward features at special thinking tokens (e.g., <think> … </think>), thereby preserving the LRM’s thinking distribution (formalized via a KL constraint). (2) Instruction-attention guided scaling, which uses forward attention statistics from a small instruction calibration set to compute per-module coefficients that increase attention alignment to instruction spans while penalizing leakage to unrelated spans. Experiments across Qwen/Llama backbones and sizes show instruction-following gains with maintained or improved reasoning and lower compute than SFT; ablations support both stages’ roles and show the method keeps the <think> format intact (no missing terminator)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Clear problem & neat insight. The paper pinpoints a real pain point: LRMs reason well, but violate format/constraints. The idea to protect the thinking segment explicitly while injecting instruction-following behavior is crisp and well-motivated.\n\nStrong empirical results. On the headline 7B setting, RAIN-Merging improves instruction-following average (48.11 vs. 44.12 LRM; +4 points absolute) while also improving reasoning/general (55.59 vs. 51.03) and beating task-arithmetic, SLERP, Karcher, TIES, DARE-TIES, and activation-based methods (AIM/ACM/LEWIS combined with TIES) \n\nEfficiency. Minutes to merge (20.96 min reported) vs. SFT’s 120+ min; GPU memory also far below SFT (22.1 GB vs. 112.6 GB in their config)"}, "weaknesses": {"value": "Calibration-set specificity. The instruction calibration set is distilled from IFEval-style instructions (365 samples). This may bias the proxy to rule-verifiable patterns and possibly underrepresent open-ended or tool-use instructions.\n\nReliance on explicit thinking markers. Stage 1 presumes accessible special tokens and feature extraction around them. It is unclear how well this transfers to LRMs with different templates (or hidden/implicit thinking) or to models without consistent <think> tags, using ReAct format for thinking tool use."}, "questions": {"value": "How does Stage 1 handle LRMs whose “thinking” is not demarcated by explicit tokens, or that interleave tool calls and thoughts (e.g., ReAct-style)? \n\nGeneralization of the proxy. If the calibration set used open-ended instructions (no machine-checkable rules), would Stage 2 still pick effective heads? Any results using other instruction corpora?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9jMlLvFdm7", "forum": "PO2iULmu5e", "replyto": "PO2iULmu5e", "signatures": ["ICLR.cc/2026/Conference/Submission18334/Reviewer_Yy8R"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18334/Reviewer_Yy8R"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18334/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762061140520, "cdate": 1762061140520, "tmdate": 1762928045483, "mdate": 1762928045483, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response"}, "comment": {"value": "Dear Program Chairs, Senior Area Chairs, Area Chairs, and Reviewers,\n\nWe sincerely appreciate your time, constructive critiques, and insightful suggestions, which have substantially strengthened our work. We are particularly grateful for the reviewers' recognition of our method's effectiveness and their positive assessment of our motivation.\n\nIn response to the comments, we have addressed each point carefully and conducted extensive additional experiments to further validate the scalability, generalization, robustness, and internal mechanisms of RAIN-Merging. All modifications in the revised PDF have been highlighted in blue for ease of reference.\n\n**Additional Experiments: (Weakness or Question, Table in Rebuttal, *Table or Figure, Revision in Revised PDF*)**\n\n1. Generalization and Scalability\n    * Generalization of Instruction Calibration Sets (Reviewer Yy8R W1&Q2, Tab.R1, *Tab.A8, Appendix J.5*)\n    * Validation on Larger Models (Reviewer snDt Q2, Tab.R2, *Tab.A9, Appendix J.6*)\n    * Generalization to Unseen Benchmarks (Reviewer i2ye W1, Tab.R3, *Tab.A10, Appendix J.7*)\n2. In-depth Analysis of Instruction-Following and Reasoning \n    * Joint Capability Evaluation (Reviewer i2ye W2, Tab.R4, *Tab.A11, Appendix J.8*)\n    * CoT Quality Analysis (Reviewer i2ye W3.1&W4.1&Q2, Reviewer 2pjo W1, Tab.R5 & R7, *Tab.A12, Appendix J.9*)\n    * Fine-grained Instruction Analysis (Reviewer i2ye W3.2, *Fig.A7, Appendix J.10*)\n    * Case Studies (Reviewer 2pjo W1, *Page 37-40, Appendix J.13*)\n3. Robustness and Ablation\n    * Semantic Robustness to Instructions (Reviewer i2ye W3.3, Tab.R6, *Tab.A13, Appendix J.11*)\n    * Complete Ablation Study (Reviewer 2pjo W2, Tab.R8, *Tab.4, Sec.4.2 RQ3*)\n\n**Clarification: (Weakness or Question)**\n\n1. Beyond Explicit Thinking Tokens (Reviewer Yy8R W2&Q1)\n2. More Modalities and Open-Sourcing (Reviewer snDt W1&Q1)\n3. Highly Entangled Instruction and Reasoning (Reviewer i2ye W4.2&Q3)\n4. Hypothesis on Weakly Coupled Parameter Space (Reviewer i2ye Q1)\n\nWe welcome any further questions or suggestions from the reviewers and look forward to continued discussion."}}, "id": "ij3XxXh5uq", "forum": "PO2iULmu5e", "replyto": "PO2iULmu5e", "signatures": ["ICLR.cc/2026/Conference/Submission18334/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18334/Authors"], "number": 8, "invitations": ["ICLR.cc/2026/Conference/Submission18334/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763743511022, "cdate": 1763743511022, "tmdate": 1763743511022, "mdate": 1763743511022, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}