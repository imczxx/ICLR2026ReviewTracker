{"id": "fHYzKTywr8", "number": 10311, "cdate": 1758166696841, "mdate": 1759897659456, "content": {"title": "HomM: Homogeneous Momentum Optimizer with Finite-Time Convergence", "abstract": "We introduce HomM, a homogeneous momentum optimizer derived from a perspective of continuous-time dynamical systems. HomM integrates homogeneity (scaling) and momentum, achieving finite-time convergence to an optimal solution under standard assumptions for both convex and non-convex objectives. To bridge theory and practice, we propose a semi-implicit discretization of the continuous-time HomM. Additionally, we present a unified framework for understanding adaptive optimizers through the lens of homogeneity, highlighting comparisons with HomM. Empirical evaluations on deep learning benchmarks show that HomM outperforms widely used momentum-based baselines, including SGD with momentum and Nesterov acceleration, as well as adaptive methods such as Adam and Lion.", "tldr": "We developed a new optimizer, HomM, that achieves finite-time convergence by  blending momentum and scaling.", "keywords": ["optimization", "homogeneity", "finite-time", "scaling"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/89bb8b8e3c2cad5e96eb72cf523476a2889c5425.pdf", "supplementary_material": "/attachment/2052d12d2b808ee10b0f3f533d2a7392657dd3e2.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose a momentum-based optimizer that exhibits a degree of a scale invariance (\"homogeneity\") that is parameterized by a constant $\\alpha\\in(-1,0]$. The paper provides theoretical results, demonstrating finite-time convergence of the continuous-time dynamics in both the well-conditioned and smooth+PL regimes. Additionally, the authors propose a discretization scheme for the continuous-time dynamics and empirically evaluate the method on deep learning tasks. The results suggest that homogeneity may lead to better generalization than adaptive gradient methods, possibly due to the avoidance of sharp minima."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. To my knowledge, finite-time gradient flows have not been well explored in machine learning. The idea is novel and certainly could be of interest to the theoretical ML community.\n2. The authors also generalize the homogeneity property of common optimizers, which is another theoretical contribution.\n3. For the most part, the paper is well-written and clear to read."}, "weaknesses": {"value": "Unfortunately, I believe that the potential impact of the contributions is limited, and there are several claims by the authors that are not well supported or motivated. For example,\n1. The theoretical results rely on (1) continuous-time dynamics; (2) smoothness assumptions; (3) strong convexity/PL assumptions (the authors claim \"both convex and non-convex objectives\" throughout the paper, but the PL condition is assumed in the non-convex setting). These assumptions are extremely strong, and little discussion is provided regarding their practicality outside of a theoretical setting.\n2. A discretized algorithm is provided, but no theoretical results (convergent hyperparameter regimes, convergence rates, etc.) are shown.\n3. I don't understand the claim that scale invariance is an undesirable property when it comes to \"over-sensitivity around flat minima\". The cited works in lines 300-308 do not support the claim that adaptive optimizers fail to generalize well *because* of scale invariance.\n4. The experiments sizes are far too small, featuring results on only toy example, e.g. CIFAR. There is little evidence to suggest that the proposed method scales to larger models and tasks, and the results presented in the paper are not convincing.\n5. Comparison to state-of-the-art optimizers (in particular, optimizers with weight decay) are brushed off as future work. I don't see why adding weight decay (or other regularization mechanisms) would be an unfair comparison, especially if the method is being proposed as an empirically effective optimizer.\n6. The proposed method introduces a new hyperparameter, $\\alpha$, that seems to require extensive tuning.\n6. (minor) typos:\n- Use `\\citep` for citations that should be parenthetical.\n- Line 111: \"stardand homogeneous\"\n- Line 632: the correct inequality is $f^*\\geq f_\\theta-\\frac{1}{2\\mu}\\nabla f_\\theta^\\top\\nabla f_\\theta$. The rest of the proof should be adjusted accordingly.\n- Line 664: \"Lyapunoc\"\nI have not checked the proofs in the detail, but even assuming that the theoretical results are correct, the mentioned weaknesses are already substantial."}, "questions": {"value": "1. To my understanding, Figure 1a does not appear to demonstrate the finite-time convergence of the proposed method?\n2. If 1. is due to discretization, how does the finite-time convergence result transfer from continuous time to discrete time? If finite-time convergence in continuous time does not imply finite-time convergence in discrete time, what is the benefit of having a continuous finite-time result?\n3. See also Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aKKRPEpg6b", "forum": "fHYzKTywr8", "replyto": "fHYzKTywr8", "signatures": ["ICLR.cc/2026/Conference/Submission10311/Reviewer_wG9t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10311/Reviewer_wG9t"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10311/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761440007483, "cdate": 1761440007483, "tmdate": 1762921654538, "mdate": 1762921654538, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Intuition for Using Homogeneous Gradient Scaling"}, "comment": {"value": "Overall, the high-level idea is to regulate the update magnitude and also introduce an implicit smoothing effect. A detailed example is provided below.\n\nIn ML optimizer design, the process can be separated into two stages: normalization and smoothing (or denoising). Here, we outline a roadmap for designing an adaptive optimizer. We start with plain gradient descent:\n$$\n\\theta_{k+1} = \\theta_k - h \\nabla \\mathcal{L}\n$$\n\n1. Since the gradient in ML can be extremely large (gradient explosion) or very small (gradient vanishing), to guarantee stable descent, we need to normalize the gradient:\n$$\n\\theta_{k+1} = \\theta_k - h \\frac{\\nabla \\mathcal{L}}{|\\nabla \\mathcal{L}|}.\n$$\nThis uses only the direction of the gradient, while the step size is determined by the learning rate $h$.\n\n2. Another consideration is that the gradient we use is actually noisy, and normalization is sensitive to noise. For example, in 1-D, let the true gradient be $$\\nabla \\mathcal{L} = 0.01$$ and the noisy gradient be $$\\tilde{\\nabla \\mathcal{L}} = \\nabla \\mathcal{L} + \\eta,$$ where $\\eta$ is a small random noise, e.g., $\\eta \\sim \\mathcal{N}(0,0.01)$. After normalization:\n$$\n\\hat{\\nabla \\mathcal{L}} = \\operatorname{sign}(\\tilde{\\nabla \\mathcal{L}}),\n$$\neven a small negative noise, e.g., $\\eta = -0.015$, flips the update direction from $+1$ to $-1$. This illustrates that normalization amplifies noise effects, motivating the need for smoothing.\n\nTo reduce sensitivity to noise, we can adopt filters for the gradient and its magnitude:\n$$\n\\theta_{k+1} = \\theta_k - h \\frac{g_1(\\nabla \\mathcal{L})}{\\sqrt{g_2(|\\nabla \\mathcal{L}|^2)}}.\n$$\nIf we apply a filter only to the magnitude $|\\nabla \\mathcal{L}|^2$, it becomes the well-known RMSprop algorithm. When both $g_1$ and $g_2$ are exponential moving averages, it corresponds to Adam.\n\n3. Rewriting normalized gradient descent as \n$$\n\\theta_{k+1} = \\theta_k - h \\operatorname{sign}(\\nabla \\mathcal{L}),\n$$\nwe see that noise sensitivity comes from the discontinuity of $\\operatorname{sign}(\\cdot)$. A widely used approach is to introduce homogeneity:\n$$\n\\theta_{k+1} = \\theta_k - h |\\nabla \\mathcal{L}|^{1+\\alpha} \\operatorname{sign}(\\nabla \\mathcal{L}).\n$$\nThe function $|x|^{1+\\alpha} \\operatorname{sign}(x)$ is continuous at zero, which greatly reduces the effect of noise. For example, in 1-D, suppose the true gradient is $$\\nabla \\mathcal{L} = 0.01$$ and the noisy gradient is $$\\tilde{\\nabla \\mathcal{L}} = \\nabla \\mathcal{L} + \\eta,$$ with $\\eta \\sim \\mathcal{N}(0,0.01)$. Using homogeneous normalization,\n$$\n\\hat{\\nabla \\mathcal{L}}_\\text{hom} = |\\tilde{\\nabla \\mathcal{L}}|^{1+\\alpha} \\operatorname{sign}(\\tilde{\\nabla \\mathcal{L}}),\n$$\nwith, for example, $\\alpha = 0.5$, the update magnitude becomes\n$$\n|\\tilde{\\nabla \\mathcal{L}}|^{1.5} \\approx 0.005^{1.5} = 3.5 \\times 10^{-4}.\n$$\nThis is very small, so the effect of noise is greatly reduced, and the update direction is less likely to flip unexpectedly. This 1-D example demonstrates how homogeneous gradient scaling smooths the sensitivity to noise while retaining the stability benefits of normalized gradients.\n\nTo illustrate the effect of gradient magnitude regulation and implicit smoothing, consider another 1-D gradient descent example with learning rate $h = 0.1$.\n\n1. Plain gradient descent: For a large gradient, e.g., $\\nabla \\mathcal{L} = 5$, the update is\n$$\n\\theta_{k+1} = \\theta_k - h \\nabla \\mathcal{L} = \\theta_k - 0.1 \\times 5 = \\theta_k - 0.5,\n$$\nwhich is a very large step and may cause instability. For a small gradient, e.g., $\\nabla \\mathcal{L} = 0.01$, the update is\n$$\n\\theta_{k+1} = \\theta_k - 0.1 \\times 0.01 = \\theta_k - 0.001,\n$$\nwhich is very slow.\n\n2. Normalized gradient descent: For both $\\nabla \\mathcal{L} = 5$ and $\\nabla \\mathcal{L} = 0.01$, the normalized update is\n$$\n\\theta_{k+1} = \\theta_k - h \\operatorname{sign}(\\nabla \\mathcal{L}) = \\theta_k - 0.1,\n$$\nso the step size is constant. Large gradients are controlled, but small gradients are overemphasized, and the method is sensitive to noise.\n\n3. Homogeneous normalization: With exponent $\\alpha = 0.5$,\n$$\n\\theta_{k+1} = \\theta_k - h |\\nabla \\mathcal{L}|^{1+\\alpha} \\operatorname{sign}(\\nabla \\mathcal{L}) = \\theta_k - 0.1 |\\nabla \\mathcal{L}|^{1.5} \\operatorname{sign}(\\nabla \\mathcal{L}).\n$$\nFor $\\nabla \\mathcal{L} = 5$, the update is $0.1 \\times 5^{1.5} \\approx 1.12$. For $\\nabla \\mathcal{L} = 0.01$, the update is $0.1 \\times 0.01^{1.5} \\approx 3.2 \\times 10^{-5}$, much smaller than the normalized step $0.1$.  \n\nThis shows that homogeneous normalization rescales the step according to gradient magnitude, preventing large updates from exploding while reducing noise amplification for small gradients.\n\nThe above illustrates the advantages of homogeneity. In this paper, we adopt these advantages together with filtered gradients, which motivates the name \"homogeneous momentum\" for our approach."}}, "id": "KPAr5fz9Bh", "forum": "fHYzKTywr8", "replyto": "fHYzKTywr8", "signatures": ["ICLR.cc/2026/Conference/Submission10311/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10311/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10311/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762959433906, "cdate": 1762959433906, "tmdate": 1762959433906, "mdate": 1762959433906, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes the HomM algorithm, which adaptively scales both the parameters and momentum in the optimization process. The main results include:  \n* Proof of the finite-time convergence of the continuous-time differential equation under the convexity and PL assumptions.  \n* Proposal of semi-implicit update rules for the continuous-time equations, and numerical demonstration that the discrete-time algorithms can well approximate the continuous-time equations.  \n* Experiments comparing the performance of HomM with other algorithms, including Adam, SGD, and Lion."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The idea of incorporating homogeneity into optimizer design is interesting.\n* The result of finite-time convergence of HomM differential eqaution provides theoretical guarantee on the performance of the purposed algorithms."}, "weaknesses": {"value": "* In general, I find the paper not well-organized. In particular, it lacks a section discussing related work, which makes it unclear how the current paper is positioned within the existing literature.\n\n* The idea of using homogeneity in algorithm design is not sufficiently motivated. Specifically, in the introduction, the authors mention that current adaptive optimization methods fail to fully explore the flat regions of the loss landscape. However, the motivation for how incorporating homogeneity can address this issue is not clearly stated.\n\n* I also find the conclusion that HomM can outperform commonly used algorithms such as SGD and Adam somewhat premature, given the experimental evidence presented. In particular, in the CIFAR-100 experiments (Table 3), the reported test accuracy of Adam is 72.08%, which appears lower than commonly reported in the literature. For example, in Table 3 of Li et al. (2022), SGD achieves 78.10% accuracy on CIFAR-100 using a ResNet-18 architecture, which is higher than the accuracy of HomM reported in this work. \n**I strongly encourage the authors to include comparisons with recent benchmarks reported in the literature, in order to provide a more comprehensive and convincing evaluation of HomM against existing algorithms.**\n\n* In line 29, ‚ÄúNeursnov‚Äù should be corrected to ‚ÄúNesterov.‚Äù\n\nReference:\n\nLi et al., Efficient Generalization Improvement Guided by Random Weight Perturbation."}, "questions": {"value": "What is the high-level reason that homogeneity can improve the ability of optimization trajectories to explore the flatter regions of the loss landscape?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jm3kSmShjh", "forum": "fHYzKTywr8", "replyto": "fHYzKTywr8", "signatures": ["ICLR.cc/2026/Conference/Submission10311/Reviewer_C6PA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10311/Reviewer_C6PA"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10311/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761563139181, "cdate": 1761563139181, "tmdate": 1762921654019, "mdate": 1762921654019, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces HOMM, a homogeneous momentum optimizer derived from a perspective of continuous-time dynamical systems. \nThe author(s) of the paper derives convergence guarantees under the standard assumption that the objective is strongly-convex and smooth (gradient Lipschitz), as well as under the non-convex case when PL inequality is assumed. A discretization scheme of the continuous-time dynamical systems is provided. Numerical experiments are conducted that shows that promising results compared to the classical methods such as SGD with momentum and Nesterov's accelerated method, as well as adaptive methods such as ADAM and LION."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "(1) The continuous-time dynamics and hence the discretization are novel. \n\n(2) Convergence guarantees are provided for the continuous-time dynamics under the strongly-convex plus smoothness assumption, or assuming PL inequality holds. The proof is based on constructing some non-trivial Lyapunov function. The Lyapunov function involves both quadratic terms and the objective."}, "weaknesses": {"value": "(1) Currently, there are not any non-asymptotic convergence guarantees for the discrete-time algorithm. Since the author(s) mention in the experiments that HomM can sometimes outperform Nesterov's accelerated method and SGD with momentum, it would be interesting to see if HomM enjoys the same or even better dependence on the condition number compared to Nesterov's accelerated method. Without such theoretical results, it is not easy to convince that one should use HomM other than more classical methods in the literature.\n\n(2) Numerical results are mixed. For example, in Figure 3, HomM enjoys better test accuracy, and hence generalization performance, but it seems it has worse training accuracy and training loss compared to existing methods in the literature."}, "questions": {"value": "(1) Theorem 2 and Theorem 3 are both asymptotic in nature. I am wondering if you can provide some theoretical bounds on $T_{s}$. That seems to be possible from Theorem 1 that you quoted from the literature. It will be interesting to see how $T_{s}$ depends on the condition number in the strongly-convex case, and how it behaves when you assume PL inequality, which might shed some insights how HomM performs according to the theory.\n\n(2) The title of Section A.3 should be Proof of Theorem 3. There is a typo."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Cerl41Xnt2", "forum": "fHYzKTywr8", "replyto": "fHYzKTywr8", "signatures": ["ICLR.cc/2026/Conference/Submission10311/Reviewer_mPdM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10311/Reviewer_mPdM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10311/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761740049258, "cdate": 1761740049258, "tmdate": 1762921653649, "mdate": 1762921653649, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this work, the authors introduce a novel optimization mechanism named Homogeneous Momentum (HOMM), designed for optimizing continuous-time dynamical systems. The proposed approach integrates homogeneity (scaling) and momentum principles to accelerate convergence. The key idea is to achieve finite-time convergence to an optimal solution under standard assumptions applicable to both convex and non-convex objective functions."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. Novelty\n\nThe proposed Homogeneous Momentum (HOMM) mechanism presents an innovative contribution to the field of optimization. By integrating homogeneity (scaling) and momentum, the authors introduce a fresh perspective on accelerating convergence within continuous-time dynamical systems. This integration is conceptually appealing because it unifies two distinct acceleration principles under a single framework, potentially offering both theoretical elegance and practical performance improvements. The idea of embedding homogeneity into a momentum-based optimizer appears novel and could inspire further developments in optimization dynamics and algorithmic design.\n\n2. Experimental Strength\n\nThe experimental section provides solid empirical evidence supporting the effectiveness of the proposed HOMM. The authors compared HOMM against several widely used gradient-based optimizers, including SGD, ADMM, and other peer methods, across multiple benchmark tasks. The reported results demonstrate consistent performance gains in terms of convergence speed and solution quality. The empirical validation is well executed and suggests that HOMM generalizes effectively across different optimization landscapes. Additional ablation studies or sensitivity analyses (if included) further strengthen the experimental credibility. Overall, the experiments convincingly substantiate the claimed advantages of the proposed approach.\n\n3. Theoretical Analysis\n\nThe paper also provides a rigorous theoretical foundation. The authors establish finite-time convergence results under standard assumptions for both convex and non-convex objectives. The derivations appear mathematically sound and align with the framework‚Äôs design principles. The theoretical analysis contributes meaningful insight into why the proposed mechanism achieves improved convergence behavior and differentiates it from existing momentum-based methods. This analytical strength enhances the paper‚Äôs overall impact, bridging conceptual innovation with provable guarantees."}, "weaknesses": {"value": "1. Limited Novelty\n\nThe conceptual contribution of Homogeneous Momentum (HOMM) appears incremental rather than groundbreaking. While the authors describe HOMM as a novel integration of homogeneity and momentum, the underlying formulation‚Äîparticularly as presented in Equation (1)‚Äîrelies heavily on the canonical momentum structure that has been well established in prior optimization frameworks, including ADMM and other momentum-based methods. The use of homogeneity as a scaling mechanism is not new, and the paper does not provide sufficient justification for how this particular combination represents a substantive theoretical advancement. Consequently, the proposed method lacks a clear differentiating factor that would establish it as a conceptual breakthrough within the optimization literature.\n\n2. Weak Experimental Design and Limited Scope\n\nThe experimental evaluation is relatively narrow in scope. The authors primarily benchmark HOMM against a small set of peer optimizers using limited datasets, such as CIFAR-100, which restricts the generalizability of the findings. To convincingly demonstrate the practical utility of the proposed method, the evaluation should be extended to a broader range of benchmarks, including more challenging or domain-diverse datasets. For example, applying HOMM to medical imaging tasks (e.g., the ADNI dataset) or large-scale vision benchmarks would provide stronger empirical evidence of its robustness and adaptability. The current experimental setup, while adequate for preliminary validation, does not substantiate the claimed superiority of HOMM across different application domains.\n\n3. Outdated Evaluation Framework\n\nThe choice of model architecture further limits the strength of the experimental validation. The authors rely on an older deep neural network, ResNet-34, to evaluate performance. Given the rapid evolution of deep learning, such a model may no longer be representative of the current state of the field. To demonstrate the scalability and modern relevance of HOMM, the authors are encouraged to evaluate their approach on contemporary architectures and openly released large-scale models, such as recent Large Language Models (e.g., LLaMA 4). This would provide a more compelling test of the optimizer‚Äôs generalizability and efficacy in modern AI contexts.\n\n4. Incomplete Theoretical Analysis\n\nThe theoretical discussion in the paper is not comprehensive enough to support the claimed analytical rigor. Although the authors cite several works related to finite-time convergence, the provided proofs are high-level and omit essential details regarding convergence bounds and rate guarantees. In particular, the absence of discussion on key comparative results, such as the convergence bound of ADMM, typically \n$ùëÇ(\\frac{1}{\\sqrt{T}})$, makes it difficult to assess the theoretical strength of HOMM. A deeper analysis connecting the proposed framework to established convergence theory, including explicit upper bounds or stability guarantees, would substantially strengthen the theoretical contribution.\n\n5. Limited Practical Applicability\n\nThe potential applications of HOMM appear constrained by the simplicity of the experimental design. The reported improvements are confined to standard image classification tasks using conventional architectures, which limits the relevance of the findings to more complex or real-world scenarios. To demonstrate broader impact, the authors should evaluate HOMM on more demanding tasks and models, such as transformer-based networks or multimodal large language models. Without such validation, the current results provide only limited evidence of HOMM‚Äôs scalability or applicability beyond simple benchmark problems."}, "questions": {"value": "Reviewer Questions and Suggestions\n\n1. Convergence Bound Analysis\nThe paper would benefit from a more detailed discussion and formal proof of the convergence bound of the proposed HOMM. Currently, the analysis focuses primarily on finite-time convergence, but it remains unclear how HOMM compares asymptotically with other state-of-the-art optimizers. For instance, if HOMM can achieve or surpass convergence rates such as $ùëÇ(\\frac{1}{\\sqrt{T}})$ (typical of ADMM) or $O(\\frac{1}{T^{\\frac{1}{3}}$) (as in STORM), this would provide a compelling argument for its superior efficiency. Establishing such bounds, or at least providing a theoretical comparison, would substantially strengthen the theoretical contribution and position HOMM more clearly within the broader optimization landscape.\n\n2. Comparison with Advanced Optimizers (e.g., STORM)\nThe current experimental evaluation omits a comparison with recent ‚Äúsuper-optimizers‚Äù, such as STORM and related adaptive momentum-based methods. Since these approaches are well recognized for their robustness and accelerated convergence in stochastic optimization, including them as baselines is essential. A direct comparison between HOMM and STORM would provide valuable empirical evidence of HOMM‚Äôs claimed advantages and help clarify its relative strengths and limitations. This would also enhance the paper‚Äôs credibility by situating the proposed method within the context of contemporary state-of-the-art optimizers.\n\n3. Expansion to Broader Datasets\nThe empirical validation is currently restricted to a limited set of natural image classification benchmarks. To demonstrate generalizability and broader applicability, it would be valuable to extend the experiments to diverse datasets or domains, such as medical imaging, text-based tasks, or multimodal benchmarks. Evaluating HOMM on datasets beyond standard image classification (e.g., ADNI or other high-dimensional biomedical datasets) would strengthen the experimental section and provide stronger evidence of the optimizer‚Äôs versatility across application domains.\n\n4. Discussion of Non-Smooth, Non-Convex Optimization\nIt would be valuable for the authors to discuss how HOMM performs in the context of non-smooth, non-convex optimization problems, which are increasingly common in modern deep learning architectures. As AI models become more complex, their associated loss landscapes often exhibit irregular, non-convex structures that challenge traditional optimization methods. A theoretical or empirical discussion of HOMM‚Äôs potential advantages‚Äîor limitations‚Äîin such settings would significantly enhance the paper‚Äôs impact and forward-looking relevance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "gHIAJbUu14", "forum": "fHYzKTywr8", "replyto": "fHYzKTywr8", "signatures": ["ICLR.cc/2026/Conference/Submission10311/Reviewer_Ex2E"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10311/Reviewer_Ex2E"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10311/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761930484052, "cdate": 1761930484052, "tmdate": 1762921653266, "mdate": 1762921653266, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}