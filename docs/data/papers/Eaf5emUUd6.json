{"id": "Eaf5emUUd6", "number": 25039, "cdate": 1758363422327, "mdate": 1763539517368, "content": {"title": "Towards Understanding Feature Learning in Parameter Transfer", "abstract": "Parameter transfer is a central paradigm in transfer learning, enabling knowledge reuse across tasks and domains by sharing model parameters between upstream and downstream models. However, when only a subset of parameters from the upstream model is transferred to the downstream model, there remains a lack of theoretical understanding of the conditions under which such partial parameter reuse is beneficial and of the factors that govern its effectiveness. To address this gap, we analyze a setting in which both the upstream and downstream models are ReLU convolutional neural networks (CNNs). Within this theoretical framework, we characterize how the inherited parameters act as carriers of universal knowledge and identify key factors that amplify their beneficial impact on the target task. Furthermore, our analysis provides insight into why, in certain cases, transferring parameters can lead to lower test accuracy on the target task than training a new model from scratch. Numerical experiments and real-world data experiments are conducted to empirically validate our theoretical findings.", "tldr": "", "keywords": ["Parameter transfer", "feature learning theory", "transfer learning", "negative transfer"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6539c8ead008172a350a53ea79c871a34f17ad43.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper develops a dynamic-theory framework for parameter transfer in which an $\\alpha$-proportion of weights from an upstream two-layer ReLU CNN are inherited by a downstream model, formalizing how inherited parameters convey universal knowledge and when transfer improves over training from scratch. It identifies key factors—shared-signal strength, source sample size, noise levels, and dimension—and derives sharp conditions (captured by an interpretable scalar $\\Gamma$) that delineate beneficial transfer from negative transfer, offering mechanistic explanations for both outcomes. Controlled simulations and CIFAR-10/100 experiments with ResNet, VGG, and DeiT corroborate these predictions."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. **Rigorous analysis of feature learning under partial parameter transfer.** The paper builds a concrete, analyzable setup that tracks training dynamics beyond purely lazy/NTK views, explicitly decomposing shared signal versus task-specific noise and characterizing how these components evolve during pretraining and downstream fine-tuning.\n    \n2. **Testable predictions via an interpretable scalar criterion.** The analysis aggregates key factors—inheritance ratio $\\alpha$, source data size $N_1$, shared-signal strength $|u|$, noise levels, and dimension $d$—into a compact indicator that predicts phase-like behavior between beneficial transfer and negative transfer; notably, these qualitative predictions align with controlled synthetic studies and with trends observed on standard vision benchmarks using canonical architectures.\n    \n3. **Mechanistic explanation of negative transfer with qualitative guidance for mitigation.** By identifying how weak shared signal coupled with inherited filters can inadvertently amplify non-shared noise, the work clarifies why negative transfer arises and suggests levers—such as moderating $\\alpha$ or strengthening regularization during fine-tuning—that can reduce risk; while not a full recipe, this mechanism-level understanding usefully narrows the space of practical interventions."}, "weaknesses": {"value": "1. **The core assumptions, especially $\\alpha$-proportion random parameter sampling, appear misaligned with practical deployment.** From an application standpoint, it is uncommon that “some arbitrary subset of weights” is available while others are not; more realistic constraints expose only certain layers or interfaces (e.g., a subset of layers or layer outputs). The motivation provided for adopting random sampling does not convincingly reflect these scenarios, and the paper does not clearly justify why random sampling is the right abstraction. Please clarify whether this choice is primarily for analytical tractability, and explicitly discuss how the conclusions would change under more realistic constraints such as layer-wise availability or fixed adapter interfaces.\n    \n2. **The claimed practical guidance remains vague and lacks actionable procedures.** While the paper states that its analysis can guide practice, it does not articulate how one would operationalize the findings in a real pipeline. The qualitative dependence of transfer effectiveness on data scale and source–target relatedness is well known and intuitive; the hard part is how to _measure_ a model’s potential transferability and how to _attain_ the best transfer in situ. As presented, the theory does not specify a concrete, data-driven procedure for estimating transferability on a new target (e.g., from a small validation split) nor a clear decision rule for when to prefer partial transfer over full fine-tuning. Please make explicit what operational steps a practitioner should follow—what to compute, how to select $\\alpha$, and how to decide between full fine-tuning, partial initialization, or alternative adaptation mechanisms.\n    \n3. **The positioning with respect to prior theory on transfer learning is incomplete and the exposition obscures the contribution.** I am not a theory specialist, but a cursory read of the transfer-learning portion of the related work did not surface theoretical analyses directly comparable to this study, which is unexpected for a paper centered on transfer-learning theory. The omission makes it difficult to assess novelty and significance, and the writing in other sections compounds the issue: from the abstract and introduction alone, it is hard to quickly grasp the precise value and scope of the contribution. Please expand and structure the related work to situate this analysis among prior theoretical efforts on transfer, and revise the abstract/introduction to foreground the problem setup, key assumptions (including $\\alpha$-sampling), and the main takeaways in a way that is immediately accessible."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "pR0apiHJDM", "forum": "Eaf5emUUd6", "replyto": "Eaf5emUUd6", "signatures": ["ICLR.cc/2026/Conference/Submission25039/Reviewer_6DBg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25039/Reviewer_6DBg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25039/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761487720631, "cdate": 1761487720631, "tmdate": 1762943293792, "mdate": 1762943293792, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a theoretical analysis of partial parameter transfer, a setting where a downstream model inherits only a subset of parameters from a pre-trained upstream model. The study is performed within a specific theoretical framework: both upstream and downstream models are two-layer ReLU convolutional neural networks (CNNs), and the data for both tasks is generated with a shared \"universal\" signal component and task-specific signal components. The major contribution is the theoretical framework and link to negative transfer."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* The paper provides an important theoretical contribution of partial parameter transfer as well as links to negative transfer which i find really interesting. This work is highly relevant, as architectural mismatches (e.g., different model sizes, new input/output heads) are the norm in practical transfer learning, yet most theory assumes a full-model transfer.\n\n* The paper claims to be one of the first to analyze the training dynamics of this process, moving beyond static generalization bounds.\n\n* well-designed experiments on classical ResNets and Transformer models."}, "weaknesses": {"value": "W1: **Writing**: The paper provides important theoretical contributions but i found the paper to not be very readable,  finding sare presented as large, dense, and complex mathematical conditions that are extremely difficult to parse for a non-expert in this specific theoretical subfield\n\nL:132: $\\Omega$ $\\Theta$ definition is confusing at first they seem like variable but are conditions. \n\nSpecific Instances: L282, cannot really understand what is the condition for negative transfer\n\nW2: Missing Citations, Highly relevant papers which were not cited:\n\n[1]Characterizing and Avoiding Negative Transfer, wang et al CVPR 2019.\n\n[2] Representation Alignment in Neural Networks, Imani et al. TMLR 2024\n\n[3] Identification of Negative Transfers in Multitask Learning Using Surrogate Models, Li et al. TMLR 2023\n\n W3: **Problematic and wrong Citations:**\n\nCorrect citation for  Vershynin R. et al is:  High-Dimensional Probability: An Introduction with Applications in Data Science. Cambridge University Press; 2018. The Authors did not include the book title in the citations. Url: https://www.cambridge.org/core/books/highdimensional-probability/797C466DA29743D2C8213493BD2D2102\n\n\nMade up citation!!: **JIANG, Z. ET AL. (2022). Transfer learning with pre-trained models: A survey. arXiv preprint arXiv:2209.01791**, I cannot find it. Is this a hallucinated citation?\n\n\nMinor: Typo in Section G of the appendix title, Discusstion -> Discussion. \n\nOverall, i believe that the paper should go through another rewriting to avoid these mistakes and make the paper more readable for a non-expert audience as well."}, "questions": {"value": "Q1: Proposition 4.4 (part 2)  seems to imply that negative transfer is most likely when one transfers from a very large but poorly-aligned task. Is this a correct interpretation?\n\nQ2 Generally, transfer is not random but based on first $m$ layer or $n-1$ layer,s where $n$ is the total number of layers, how does the current work take that into account? \n\nQ3 Can a connection to [1] and [2] be established?\n\nS1 Suggestion: Have a uniform citation format. Sometimes, the page number is included in NeurIPS; sometimes it's not, sometimes conference names are abbreviated, and sometimes written in full.\n\nQ4 Is this theory only valid for classification, or canit  be generalized to regression and other tasks somehow?\n\n\n[1]Characterizing and Avoiding Negative Transfer, wang et al CVPR 2019.\n\n[2] Representation Alignment in Neural Networks, Imani et al. TMLR 2024"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "dzK6YvCHEW", "forum": "Eaf5emUUd6", "replyto": "Eaf5emUUd6", "signatures": ["ICLR.cc/2026/Conference/Submission25039/Reviewer_ymzu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25039/Reviewer_ymzu"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25039/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761954109486, "cdate": 1761954109486, "tmdate": 1762943293202, "mdate": 1762943293202, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper provides a theoretical analysis of feature learning in parameter transfer, a core mechanism in transfer learning where parts of a pretrained model are reused for downstream tasks. Focusing on ReLU convolutional neural networks, the authors study when and why partial parameter reuse is beneficial. Their framework reveals how transferred parameters encode universal knowledge that can enhance learning efficiency under certain conditions, while also explaining cases where parameter transfer may hurt downstream performance compared to training from scratch. Theoretical insights are supported by both numerical simulations and real-world experiments, offering a clearer understanding of the mechanisms governing successful parameter transfer."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The theoretical derivations appear rigorous, and the topic—providing a theoretical explanation for transfer learning—is both timely and important. The use of feature learning analysis to study parameter transfer offers a novel and interesting perspective."}, "weaknesses": {"value": "Some assumptions are a bit restrictive, such as assuming $u$ is orthogonal to both $v_1$ and $v_2$. In addition, certain terminologies, including \"Bayesian optimal\" and \"sub-Bayesian optimal\" as used in Theorems 4.2 and 4.3, require clearer definitions or explanations to ensure accessibility for a broader audience."}, "questions": {"value": "1. In Definitions 3.1 and 3.2, the covariance matrices of the noise are given as $\\sigma_{p,1}(I - uu^\\top / \\|u\\|^2 - v_1v_1^\\top / \\|v_1\\|^2)$ and $\\sigma_{p,2}(I - uu^\\top / \\|u\\|^2 - v_2v_2^\\top / \\|v_2\\|^2)$, respectively. However, the last paragraph of Page 3 states that \"the noise variances in Task 1 and Task 2 are $\\sigma_{p,1}$ and $\\sigma_{p,2}$.\" These descriptions seem inconsistent—please clarify the relationship between them.  \n2. Still in Definitions 3.1 and 3.2, the covariance matrices imply that different elements of the one noise vector may be correlated, with correlations depending on $u$ and $v$. This modeling choice requires justification. Moreover, it should be verified (or stated) that the covariance matrices are always positive semidefinite, as required for valid covariance definitions.  \n3. When $d = 1$, it is impossible to have $u \\perp v_1$ and $u \\perp v_2$. It should therefore be noted somewhere that $d \\geq 2$ is assumed throughout the analysis."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "BOub9HGxOY", "forum": "Eaf5emUUd6", "replyto": "Eaf5emUUd6", "signatures": ["ICLR.cc/2026/Conference/Submission25039/Reviewer_ZDxq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25039/Reviewer_ZDxq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25039/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978480335, "cdate": 1761978480335, "tmdate": 1762943292820, "mdate": 1762943292820, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates the role of parameters shared between upstream and downstream models. Inheriting parameters can serve as a carrier of general knowledge and is sometimes beneficial for the target task; however, in certain cases, transferring parameters leads to lower accuracy on the target task than training from scratch."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.The paper is highly readable.\n2.The theoretical derivations are complete, lending strong credibility.\n3.It substantiates a key conclusion: inheriting more parameters, using larger upstream training datasets, and having less noise in upstream tasks can improve downstream model performance. The conclusions in the contributions section are insightful."}, "weaknesses": {"value": "Please refer to the Questions section below."}, "questions": {"value": "1.The case would be stronger with experiments on ViT-based models or VLMs.\n2.There is a lack of cross-dataset experiments across different tasks.\n3.The paper does not provide sufficient comparisons with existing parameter-transfer or transfer-learning methods."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "AYps3VKwGj", "forum": "Eaf5emUUd6", "replyto": "Eaf5emUUd6", "signatures": ["ICLR.cc/2026/Conference/Submission25039/Reviewer_SXqG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25039/Reviewer_SXqG"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25039/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762328906298, "cdate": 1762328906298, "tmdate": 1762943292635, "mdate": 1762943292635, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}