{"id": "2uIhLUgepi", "number": 23883, "cdate": 1758349783933, "mdate": 1759896792537, "content": {"title": "OpaqueToolsBench: Learning Nuances of Tool Behavior Through Interaction", "abstract": "Tool-calling is essential for Large Language Model (LLM) agents to complete real-world tasks. While most existing benchmarks assume simple, perfectly documented tools, real-world tools (e.g., general “search” APIs) are often opaque, lacking clear best practices or failure modes. Can LLM agents improve their performance in environments with opaque tools by interacting and subsequently improving documentation? To study this, we create OpaqueToolsBench, a benchmark consisting of three distinct task-oriented environments: general function calling, interactive chess playing, and long-trajectory agentic search. Each environment provides underspecified tools that models must learn to use effectively to complete the task. Results on OpaqueToolsBench suggest existing methods for automatically documenting tools are expensive and unreliable when tools are opaque. To address this, we propose a simple framework, ToolObserver, that iteratively refines tool documentation by observing execution feedback from tool-calling trajectories. Our approach outperforms existing methods on OpaqueToolsBench across datasets, even in relatively hard settings. Furthermore, for test-time tool exploration settings, our method is also efficient, consuming 3.5-7.5× fewer total tokens than the best baseline.", "tldr": "", "keywords": ["tool use", "tool calling", "language agents", "llm agents"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0b2ae599be284de22622340f614e7d69c7b06c86.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces OPAQUETOOLSBENCH, a benchmark designed to evaluate LLM agents’ ability to learn and adapt to opaque tools, i.e., tools that are underspecified, lack proper documentation, or exhibit non-transparent behaviors. To address the challenge, the authors propose TOOLOBSERVER, a framework that iteratively improves tool documentation through execution feedback (exploration and reflection). Results across all tasks demonstrate the feasibility of learning from execution trajectories to handle real-world, poorly documented tool APIs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper targets a realistic and underexplored aspect of tool-augmented LLMs: using and improving opaque tools where documentation is minimal or unreliable. This is a valuable shift from previous works that assume perfectly specified APIs.\n\n2. OPAQUETOOLSBENCH is conceptually clean yet diverse, covering structured, unstructured, and sequential tool-use scenarios (function calling, game-playing, and search composition)."}, "weaknesses": {"value": "1. TOOLOBSERVER largely reuses ideas from self-reflection and execution-based revision (e.g., Play2Prompt, Reflexion), differing mainly in when reflection occurs (interleaved rather than pre-task). \n\n2. Previous work like [1] has demonstrate the effectiveness of document refinement. What the main difference between this work and [1]? Could the author provide more explanation or comparison in terms of core technique contributions?\n\n\n3. As for experiment evaluation, other metrics such as the number of reflection iterations, or fine-grained alignment between learned and ground-truth documentation, could be considered for a further validation. \n\n---\n\n### Reference\n\n[1] From Exploration to Mastery: Enabling LLMs to Master Tools via Self-Driven Interactions"}, "questions": {"value": "See weakness above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UF2Fp2LNHk", "forum": "2uIhLUgepi", "replyto": "2uIhLUgepi", "signatures": ["ICLR.cc/2026/Conference/Submission23883/Reviewer_9Zwe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23883/Reviewer_9Zwe"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23883/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761813995723, "cdate": 1761813995723, "tmdate": 1762942839451, "mdate": 1762942839451, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work investigates how LLM agents can improve tool use in opaque tool settings by interacting with the tools and iteratively refining their documentation based on execution feedback. The authors propose TOOLOBSERVER, a reflection-based framework that continuously refines tool documentation by observing execution feedback from tool-calling trajectories. In addition, the authors introduce OPAQUETOOLSBENCH, a benchmark for learning in opaque tool settings where tool documentation is underspecified. It consists of three environments: general function calling, interactive chess playing, and long-trajectory agentic search.\n\nExperimental results show that TOOLOBSERVER consistently outperforms all baselines on OPAQUETOOLSBENCH, achieving an average improvement of 18.6% in task success rate while maintaining strong token efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is well-organized and easy to follow, with clear presentation of benchmark statistics and evaluation metrics. \n\n- The data generation pipeline is simple, scalable, and comprehensively described. \n\n- The simplicity and token efficiency of TOOLOBSERVER make it directly applicable to real-world tool-use scenarios."}, "weaknesses": {"value": "While three domains are tested, the evaluation metrics are somewhat limited. For example, Tables 2 and 3 only report overall accuracy. It would be informative to include additional metrics such as parameter accuracy or Abstract Syntax Tree (measures the generated function call format) etc."}, "questions": {"value": "- In Section 4.3, the authors claim that TOOLOBSERVER is more token-efficient than Play2Prompt. However, this is not fully convincing. Since discovering correct tool usage requires trial and error, calling multiple tools at once may not necessarily reduce overall exploration cost and improve the final accuracy. that is, exploring all tools at once does not sound like a experience-efficiency way to me. \n\n- The opaque tool setting is indeed an underexplored and interesting problem. I wonder whether TOOLOBSERVER could also be applied to refine existing but suboptimal documentation—for instance, improving clarity or usability rather than fixing errors. Similarly, could OPAQUETOOLSBENCH include such cases where the tool documentation is mostly correct but not good enough? \n\n- TOOLOBSERVER explores multiple tools at once, but it remains unclear how the editor generalizes when the number of tools grows substantially. How does performance scale with hundreds or thousands of tools? \n\n- It would be insightful to compare TOOLOBSERVER with human annotators on these tasks. Including a “human oracle” baseline could help quantify how close the model is to human-level understanding of opaque tools."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vkrhBZro9A", "forum": "2uIhLUgepi", "replyto": "2uIhLUgepi", "signatures": ["ICLR.cc/2026/Conference/Submission23883/Reviewer_Dj3K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23883/Reviewer_Dj3K"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23883/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761899560102, "cdate": 1761899560102, "tmdate": 1762942839171, "mdate": 1762942839171, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This study designed a situation for tool calling agents when the tool specs are opaque. Under this setting, calling correct tools will be challenging because language models do not have enough information to decide what's the best tool to use or an appropriate parameters to send to the tool.\n\nTo evaluate and solve this problem, this study proposed the ToolObserver method that iteratively observe tool behavior and provide incremental improvements to the tool documentations. Experiment shows that the proposed method performs better than selective baselines on tool use benchmarks with opaque tool specs."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The experiment results are encouraging, proving the the proposed method can generate good tool documentations that help improve the performance of models.\n- Compared to the baseline method, the proposed strategy does not have to process all tools. as a result, they end up significantly save generation tokens for tool documents."}, "weaknesses": {"value": "I feel the given situation is over-complicated / not well motivated. There are several reasons that tools won't be opaque in most applications:\n1. agent developers are trying their best to improve the performance. giving the agent good tool documentation is among the easiest improvement they can do.\n2. tool developers would maximize the chance that their tool gets called. as a result, they will work on improving the tool documentation so they are easy for the models to understand.\n3. the best use case of the proposed situation might be the agent developers do not know what models they are giving the agent, and the tools developers does not want to tell models what are the tools designed for. this is a very rare case.\n\nSecondly, I think the difference of the proposed strategy of the method and P2P is not strong enough for two reasons:\n1. ToolObserve does not need initial documentation, but it does need the schema of tool inputs. as a result, the difference of not needing initial docs is just an incremental steps that tells an LLM to predict tool functionality based on inputs and tool outputs.\n2. the token saving mainly comes from that ToolObserver does not have to explore all tools. However, when the number of requests are enough to cover all tools, this claim is no longer valid. ToolObserver and P2P both explore all tools and generates roughly same amount of tokens."}, "questions": {"value": "n/a"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JmPDITOoZw", "forum": "2uIhLUgepi", "replyto": "2uIhLUgepi", "signatures": ["ICLR.cc/2026/Conference/Submission23883/Reviewer_mFT3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23883/Reviewer_mFT3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23883/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968188743, "cdate": 1761968188743, "tmdate": 1762942838803, "mdate": 1762942838803, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates whether LLM agents can improve their performance when using opaque tools by interacting with them and refining their understanding through feedback. To study this, the authors introduce OPAQUETOOLSBENCH, a benchmark covering three domains: general function calling, interactive chess playing, and long-horizon agentic search. The study finds that existing automatic tool documentation methods are unreliable and costly under opaque conditions. To address this, the authors propose TOOLOBSERVER, a framework that iteratively refines tool documentation based on execution feedback from tool-calling trajectories."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The concept of opaque tool invocation is novel and opens an interesting direction for further research.\n2. The experiments are extensive and well-aligned with the proposed idea.\n3. The paper presents a clear analysis, demonstrating how performance evolves across iterations and documentation levels."}, "weaknesses": {"value": "1. The exploration and reflection phases in offline mode lack sufficient detail. The paper provides only a high-level description of these phases without sufficient algorithmic or implementation details.\n2. ToolObserver offers limited novelty and resembles prior reflection-based methods.\n3. The three benchmark scenarios may not fully represent real-world tool use.\n4. Benchmark performance remains low. Even with optimization, the best reported results are still modest, which raises concerns about the practical usefulness and scalability of the proposed method."}, "questions": {"value": "1. The definition of \"opague\" is relatively obscure. Can you explain it further?\n2. If the tasks are not opqgue, how well the models performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HIPfMwyvjj", "forum": "2uIhLUgepi", "replyto": "2uIhLUgepi", "signatures": ["ICLR.cc/2026/Conference/Submission23883/Reviewer_WVQD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23883/Reviewer_WVQD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23883/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992350004, "cdate": 1761992350004, "tmdate": 1762942838445, "mdate": 1762942838445, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}