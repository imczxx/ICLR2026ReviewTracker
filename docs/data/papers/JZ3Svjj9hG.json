{"id": "JZ3Svjj9hG", "number": 13851, "cdate": 1758223706909, "mdate": 1759897408670, "content": {"title": "Generative Counterfactual Manifold Perturbation: A Robust Framework for Treatment Effect Estimation with Unobserved Confounders", "abstract": "Estimating treatment effects from observational data is difficult when unobserved confounders create spurious associations that bias simple estimators. Recent generative approaches learn outcome distributions with conditional diffusion models, and some robust representation methods introduce sensitivity analysis or structural priors. These advances work well when identification assumptions hold exactly, but they become fragile when those assumptions are only approximate and offer few practical diagnostics. We introduce Generative Counterfactual Manifold Perturbation (GCMP), a unified framework that combines causal-aware self supervised learning, conditional diffusion counterfactual proxy generation, and adaptive variational inference. GCMP makes three main contributions: (i) a self supervised objective that preserves confounding signals during representation learning; (ii) a conditional diffusion model that reframes proxy construction as a generative task over rich perturbation manifolds; and (iii) an adaptive regularization scheme that yields graceful degradation and calibrated uncertainty when identification assumptions are violated. We also present new identifiability conditions, finite sample error bounds, and diagnostic tests to quantify manifold quality and effective orthogonality. Extensive experiments on synthetic and semi-synthetic benchmarks show that GCMP consistently outperforms the state-of-the-art.", "tldr": "Our method proposes a framework for multiâ€‘treatment effect estimation that can mitigate unobserved confounder and boost accuracy.", "keywords": ["ML: Causal Learning"], "primary_area": "causal reasoning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/feff6f5f6d7151ee5123c94a084359094ae645da.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses the challenge of hidden confounding in causal inference by proposing a novel framework: Generative Counterfactual Manifold Perturbation (GCMP). GCMP unifies causal-aware self-supervised learning, conditional diffusion-based counterfactual proxy generation, and adaptive variational inference. The authors conduct a series of experiments to empirically validate the effectiveness of their approach."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The theoretical derivations are solid and provide strong support for the proposed method.\n2. The focus on causal inference aligns well with the interests of the ICLR community.\n3. The experimental results are clearly presented and substantiate the claims made in the paper."}, "weaknesses": {"value": "1. The overall workflow of the proposed approach is not clearly described, making it challenging to fully understand the method. Including a schematic diagram or pseudo-code would enhance clarity.\n\n2. The related works section lacks coverage of classical causal inference methods, particularly recent developments within the last three years.\n\n3. The definition and details of the manifolds used (e.g., simplex manifold, Stiefel manifold) are unclear. \n\n4. The motivation for introducing local PCA is unclear. Is it intended to serve as a retraction operator or for some other specific purpose? Please clarify the rationale and theoretical justification.\n\n5. Why is the DDPM framework specifically chosen for the generative model? What would be the effect of using a variance explosion SDE framework instead [1]? A comparison or justification would strengthen the paper.\n\n6. The explicit form of the similarity function $\\text{Sim}$ in Equation (10) is not provided. Please clarify its definition.\n\n7. While variational inference can approximate the posterior, the approach appears to be a form of amortized variational inference, which may introduce an amortization gap. What would be the impact of using Monte Carlo-based approaches instead?\n\n---\nReferences:  \n[1]. Score-Based Generative Modeling through Stochastic Differential Equations"}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hgzymGJuyF", "forum": "JZ3Svjj9hG", "replyto": "JZ3Svjj9hG", "signatures": ["ICLR.cc/2026/Conference/Submission13851/Reviewer_PxTe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13851/Reviewer_PxTe"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13851/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761679278185, "cdate": 1761679278185, "tmdate": 1762924373095, "mdate": 1762924373095, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "To address the challenge of unobserved confounders that induce spurious associations, the authors propose a framework named Generative Counterfactual Manifold Perturbation (GCMP), which integrates causal-aware self-supervised learning, conditional diffusion-based counterfactual proxy generation, and adaptive variational inference. Experimental results demonstrate that GCMP consistently outperforms state-of-the-art methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Capable of handling diverse treatment types within a unified framework, including continuous, binary, and multi-dimensional treatments.\nThe experiments cover multi-dataset comparison and ablation studies, which effectively verifies the effectiveness and robustness of the method."}, "weaknesses": {"value": "1. The paper shows limited novelty, as the methodology combines three existing modules without sufficiently clarifying the specific challenges each addresses and how they interconnect functionally. \n\n2. It is strongly recommended that the authors include an overall framework diagram.\n\n3. The authors extensively cite prior work but does not discuss alternatives to normalizing flows for counterfactual, such as energy-based models or manifold-based generative approaches.\n\n4. The authors report experimental results, but the evaluation misses several strong baselines (e.g., TarNet, CFRNet, DragonNet, CEVAE and GANITE), which are essential.\n\n5. The code link provided appears to be incorrect and I could not access the related code."}, "questions": {"value": "As noted in the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xPI5yMnsbW", "forum": "JZ3Svjj9hG", "replyto": "JZ3Svjj9hG", "signatures": ["ICLR.cc/2026/Conference/Submission13851/Reviewer_37Rv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13851/Reviewer_37Rv"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13851/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761814190184, "cdate": 1761814190184, "tmdate": 1762924372597, "mdate": 1762924372597, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new framework for estimating CATE, where a new loss was proposed and several existing architectures were combined. Theoretical analysis and empirical validation were presented."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses causal inference with unobserved confounders, which is a critical field of study.\n\nThe codebase is well-maintained."}, "weaknesses": {"value": "Unverified assumption: this paper does not seem to rely on the standard causal inference assumptions (e.g., consistency, exchangeability, etc.) and requires three new assumptions that the authors have introduced. While the authors claimed that the assumptions are easier to verify empirically, no experimental results were shown to validate these assumptions, and no verbal explanations were provided to help the audience interpret the assumptions.\n\nPresentation clarity: The proposed method contains many modules. However, no summarizing statement of how the three modules interact with each other and are integrated into the framework. Therefore, the overall arrangement of the paper is chaotic and hard to understand, and it is difficult for me to appreciate the novelty of its architectural design.\n\nThis also applies to the theory section of the paper: the proved theoretical results are not explained for their role in the framework and contribution to the overall literature. Therefore, it is also unclear to me the significance of these results to the overall quality of the paper.\n\nRedundant information in the main paper: some details in the paper are redundant and can be moved to the appendix. For example, the definition of PHEH is relatively standard, and its expression does not need to be shown in the main paper. After saving these spaces, the omitted experiment results could be moved to the main paper.\n\nWeak experiments: there are a lot of aspects of the proposed method unverified, which could benefit from further ablation studies.\n\nMisleading wording: Line 232, the use of \"introduce\" is misleading, as it typically represents that what is about to be discussed is novel, while what is shown in the paper is generic, so it seems like a potential overclaim. I suggest replacing \"introduce\" with \"construct\"."}, "questions": {"value": "Could the authors please provide illustrations or provide an overview of how the components in the framework are assembled?\n\nCould the authors present ablation studies on how each component in the proposed method contributes to the final performance? \n\nCould the authors provide comparison results between your proposed method and proximal causal inference baselines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XclfWRdb50", "forum": "JZ3Svjj9hG", "replyto": "JZ3Svjj9hG", "signatures": ["ICLR.cc/2026/Conference/Submission13851/Reviewer_nusj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13851/Reviewer_nusj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13851/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761864064404, "cdate": 1761864064404, "tmdate": 1762924372162, "mdate": 1762924372162, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}