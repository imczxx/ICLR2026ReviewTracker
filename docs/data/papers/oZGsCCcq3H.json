{"id": "oZGsCCcq3H", "number": 10184, "cdate": 1758163316987, "mdate": 1763662105725, "content": {"title": "Adapting Actively on the Fly: Relevance-Guided Online Meta-Learning with Latent Concepts for Geospatial Discovery", "abstract": "In many real-world settings, such as environmental monitoring, disaster response, or public health, where data is costly and difficult to collect, strategically sampling from unobserved regions is essential for uncovering hidden risks or targets under tight resource constraints. Moreover, real-world geospatial data is often sparse, noisy, and geographically skewed, rendering most existing learning-based methods\nimpractical. To address this, we propose a unified geospatial discovery framework that integrates active learning, online meta-learning, and concept-guided reasoning to support efficient, real-time decision-making under extreme data scarcity. Our approach introduces two key innovations: a relevance-uncertainty guided sampling strategy that uses structured relevance vectors based on domain-specific concepts (e.g., spectral channels, industrial proximity), enabling interpretable and adaptive sample selection; and a relevance-aware meta-batch formation strategy that promotes semantic diversity during online-meta updates, improving generalization in dynamic environments. Our experiments include actively searching for a specific land cover type under sparse training conditions and a strict sampling budget, as well as identifying cancer-causing PFAS (Per- and polyfluoroalkyl substances) contamination hotspots in U.S. surface water bodies, a critical, real-world public health and environmental problem. Despite limited observations and significant landscape shifts, our method reliably uncovers target land covers and contamination zones and adapts across space and time, showcasing its scalability, robustness, and potential to accelerate discovery in data-limited, high-stakes environments.", "tldr": "", "keywords": ["Geospatial Modeling", "Active Learning"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b75e9566c95f0bc2d8df7bb83241c0a3fce34e41.pdf", "supplementary_material": "/attachment/ee33b4d3de62b0ba13fdf185654e7fd8276bb578.pdf"}, "replies": [{"content": {"summary": {"value": "The paper introduces an online active learning framework for geospatial discovery, combining concept-driven representations, uncertainty-based sampling, and online meta-learning to adapt under strict sampling budgets. The proposed system targets open-world settings where new data continuously arrive and cannot be revisited, addressing challenges of non-stationarity and limited supervision."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper tackles a timely and challenging problem of online adaptation for geospatial tasks, proposing a unified framework that integrates concept encoding and meta-learning."}, "weaknesses": {"value": "- Regarding interpretability, the study would benefit from visualizing which concepts or POI dimensions are most influential, along with strategy heatmaps or trajectory plots explaining the model’s sampling behavior. Qualitative analysis of failure cases could clarify which factors or uncertainty scores led to misdetections.\n- Regarding experiments, significance testing is missing; an ablation that removes the Gram–Schmidt orthogonalization step is needed to validate the contribution of concept diversity and de-correlation.\n- Regarding complexity, theoretical and empirical analysis of time and memory costs is lacking.\n- Regarding some minor issues:\n    - line 222: “Derivation of 1 in the Appendix.” should reference Proposition 1 or Eq. (1).\n    - Terminology consistency: unify “Open-World” vs. “Open World.”\n    - line 213: `[αc1, αc1, …, αcK]` should be `[αc1, αc2, …, αcK]`."}, "questions": {"value": "- Given that active learning relies on accurate uncertainty estimation, the framework employs a CVAE to model latent relevance r(x) but does not exploit its probabilistic properties. Why explicitly incorporate the posterior variance of r(x) into the sampling utility function? Has any uncertainty calibration been performed?\n- Considering that the proposed task involves sequential decision-making, adaptation, and long-term reward maximization, could the active sampling strategy be theoretically formulated within a Meta-RL framework?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "5zCZlcnYKG", "forum": "oZGsCCcq3H", "replyto": "oZGsCCcq3H", "signatures": ["ICLR.cc/2026/Conference/Submission10184/Reviewer_A8mn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10184/Reviewer_A8mn"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10184/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760695731636, "cdate": 1760695731636, "tmdate": 1762921551678, "mdate": 1762921551678, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Summary: This paper considers a challenge in geospatial machine learning for target indification -- there is often a sparsity of labels to learn from, so on-thy-fly learning is important for algorithmic approaches to adapt to new spatial or temporal domains. At the same time, the number of samples that can be collected is often small, necessitating an explore-exploit tradeoff for continual learning. To model these challenges, the authors present a novel problem formulation, Open-World Learning for Geospatial Prediction and Sampling (OWL-GPS), as well as a meta-learning based approach to solving this problem. They focus on applications in rare-class landcover detection, and PFAS hotspot identification. Overall, the scope of this paper is quite ambitious, contributing to both strengths and weaknesses that I outline below. \n\nNOTE: because many formal statements/proofs are in the appendix I did not have time to check them -- content in the appendix did not factor into my review or score."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. To the best of my knowledge, the problem formulation is novel. Also to the best of my knowledge, the problem formulation captures real-world challenges for online data collection with limited budgets, seen in many environmental monitoring settings.\n2. This paper has several contributions: a novel problem formulation, a novel method to address the problem, and a new benchmark for this problem. \n3. The proposed method performs better on average than the baselines (none of which are designed for this problem since it's a new problem formulation), some ablation studies are run to test the importance of the main components of the method (meta-training set and relevance-guided sampling). Overall, this gives evidence that the problem formulation is a challenging one needing new methods. It also shows that the proposed approach is working on this problem setting."}, "weaknesses": {"value": "1. There are so many design choices in the proposed methods, but not enough space to explain them, and not enough explain experiments to undertsand what matters. There are ablations on the relecance encoder and meta-training set, but only for one dataset (2019) - why not all three datasets? Does the GS orthogonalization matter? Forgive me if I missed it but I don't think that's tested.\n2. Related work is sparse: the part on geospatial foundation models only cites 2 papers? There are a ton. Either do a thorough related work here or specify what scope you're looking at for this part of the related work. Honeslty I'm not sure this part of your related work needs to be there, but maybe I'm missing something. For the active geopsatial search, is Sarkar et al. really the only team that has tackled this? Maybe the other work out there is less directly realted to what this paper tackles, but the readers need to understand what types of similar problems have been studied before in the geo/environemntal montiroing space, and this is too sparse to get that across.\n3. No standard deviations or standard errors on any of the results makes it impossible to intepret the statistical significance of the performance benefits.\n\nFormatting/figures/typos\n\n1. What is \"a)\" in the block diagram figure? This should be clear from the figure and/or legend alone.\n2. The font in figure 3 is way too small.\n3. Line 333: I think you mean K(C) *decreases* over time\n4. equation 10 seems unfinished.\n5. Table 4 appears before table 3. Fix the reference numbers so they appear in order\n6. The buffer around inset table and figure captions is too small. it's clear the authors are aggressively using \\vspace{-something} and it inhibits readability. There are alternatives, for example float table 5 and 6 together at the top or bottom of the page to span both columns."}, "questions": {"value": "1. I have some uncertainty as to what is going on in equation 1 with the notation that uses both q and i to index sampled regions. I think answering the following would help: Why is the problem formuluation done at a pixel level? I might be missing something, but I would think that people annotating satellite images can easily annotate major swatches of an image at a time. At the same time, does the objective in eq. (1) penalize asking for a large swatch of say, n xm  pixels to be labeled, if the target of interest is in that swatch but is small compared to the n x m dimension? If so, that seems a bit odd to me, because you've still found the target of interest. Would this then bias the algorithm toward big targets and away form small ones?\n2. The conclusion states that this method is interpreatable. What aspects of the method aid interpretability?\n3. could you please correct the formula in eq. 10 and kindly let me know what it should be?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vMaJ0zGvkw", "forum": "oZGsCCcq3H", "replyto": "oZGsCCcq3H", "signatures": ["ICLR.cc/2026/Conference/Submission10184/Reviewer_wCqr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10184/Reviewer_wCqr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10184/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761667299656, "cdate": 1761667299656, "tmdate": 1762921551225, "mdate": 1762921551225, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method for geospatial target discovery under tight resource constraints. The method combines multiple strategies such as relevance-uncertainty guided sampling and relevance-aware meta-batch formation for efficient decision-making. The experiments on searching for specific land cover types and contamination areas show that the method can generalize better than baselines to real-world scenarios under data constraints."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The problem of Open-World Learning for Geospatial Prediction and Sampling (OWL-GPS) is important and relevant to many real-world applications.\n2. The method design addresses important challenges in the OWL-GPS problem, including strict sampling budgets and evolving data distributions, and non-revisitable inputs.\n3. The experimental results show the improvements over the baselines."}, "weaknesses": {"value": "1.  The contribution of the components are not well explained. Is the relevance uncertainty from domain-specific concepts like spectral channels trying to use selected features based on domain knowledge to do the sampling? This feels like a reasonable domain application choice but the novelty is not apparent.\n\n2. Although the paper provides additional details on the datasets in the supplementary, it would be helpful to clarify how the characteristics of each dataset correspond to the OWL-GPS problem. For instance, Sentinel imagery is, in principle, abundantly available—so in what sense does it become “costly,” “non-replayable,” or “resource-constrained” in this work? Making this explicit for each dataset would also help readers understand how the baseline models are configured under the same setting. How difficult is it to get the labels?\n\n3. The experimental setup lacks sufficient detail and makes it difficult to understand how the models were trained."}, "questions": {"value": "Please explain the key technical contribution on uncertainty and sampling diversity compared with existing studies."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wWC5gAUrBZ", "forum": "oZGsCCcq3H", "replyto": "oZGsCCcq3H", "signatures": ["ICLR.cc/2026/Conference/Submission10184/Reviewer_j5o6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10184/Reviewer_j5o6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10184/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969271528, "cdate": 1761969271528, "tmdate": 1762921550515, "mdate": 1762921550515, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework for policy-driven, online meta-learning under constrained sampling and memory settings in geospatial environments. It formalizes the OWL-GPS problem, which introduces strict assumptions: non-revisitable inputs, dynamically shifting distributions, and hard query budgets. To address this, the authors propose:\n* A relevance-guided Conditional Variational Autoencoder (CVAE) to encode latent concept relevance.\n* A relevance-aware sampling strategy that balances exploration and exploitation.\n* A meta-training mechanism using core and reservoir buffers formed through Greedy Intersection Clustering (GIA) over relevance vectors.\n* A theoretical justification of sampling criteria via entropy-based exploration (Theorem 1 and 2).\n* Experiments on PFAS contamination and land cover tasks from satellite imagery data (years 2019 and 2021), showing superiority over baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The Greedy Intersection Algorithm for meta-batch diversity is clever and attempts to maintain semantic coverage without task boundaries.\n\n* Ablation studies cover a range of hyperparameters and show some resilience of the method.\n\n* The integration of domain-specific concepts into relevance encoding via CVAE is a principled and interpretable modeling choice."}, "weaknesses": {"value": "* The experiments use only two datasets. Only one run per configuration is reported with no variance bars. SR  gains over some baselines are margin.\n\n* Equation (6) uses a handcrafted combination of latent relevance distance and decoder uncertainty. The sampling objective is ad-hoc and insufficiently validated.\n\n* The framework assumes domain experts can predefine concept variables that are always available. This is rarely feasible in real domains or multi-modal geospatial datasets.\n\n* The SR formula includes a denominator term Ut defined as the maximum number of target pixels in the queried image. However, this is part of the ground truth and should not be used in evaluation."}, "questions": {"value": "* All reported results appear to come from a single run. Did you evaluate across multiple random seeds? Can you report mean and standard deviation?\n* Why was this form chosen in Equation (6)? Did you try simpler or standard acquisition functions like entropy or margin?\n* How would your method adapt to domains without explicit concept metadata? Have you tested robustness to missing, noisy, or misaligned concepts? Can the concept encoder be replaced with a learned representation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cqfXt8qGoO", "forum": "oZGsCCcq3H", "replyto": "oZGsCCcq3H", "signatures": ["ICLR.cc/2026/Conference/Submission10184/Reviewer_Hb3E"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10184/Reviewer_Hb3E"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10184/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761981918250, "cdate": 1761981918250, "tmdate": 1762921550019, "mdate": 1762921550019, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}