{"id": "d0P96cRFWX", "number": 10331, "cdate": 1758167269380, "mdate": 1763087039289, "content": {"title": "LLM-STAR: Sequence-Teacher-Anchored LLM Recommender with Adaptive Regularization", "abstract": "Large Language Models (LLMs) have been increasingly adopted for recommendation tasks, yet their ability to leverage the sequential nature of user item interaction data remains underexplored. In this work, we conduct a comprehensive investigation into how LLMs process item sequences and uncover a critical limitation: LLMs often exhibit a set-like prediction behavior, focusing on the unordered collection of items rather than their order. Through experiments where item textual content is removed and only item IDs are provided, we demonstrate that LLMs fail to fully exploit sequential dependencies, leading to degraded sequential recommendation. Motivated by the principle of entropy, we further provide a representation-space perspective: the region occupied by embeddings of ordered item sequences is a compact subspace of that formed by unordered item collections, as sequence information reduces entropy and enforces tighter structure. Building on this insight, we introduce a contrastive learning framework that explicitly guides LLMs to capture sequential patterns by encouraging compact representation of ordered item sequences. Extensive experiments across multiple benchmarks show that our method achieves state-of-the-art performance, surpassing prior LLM-based recommendation approaches.", "tldr": "", "keywords": ["LLM; recommendation system;"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/608b0821a3d2b4891b33fb8ca57b9fd9df5a3a1f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper investigates why LLM-based sequential recommenders often appear weakly sensitive to interaction order, diagnosing a set-like treatment of histories on Amazon Reviews via targeted probes (e.g., shuffling and ID-only inputs). It proposes LLM-STAR—a lightweight, sequence-teacher–anchored and adaptively weighted regularization that plugs into standard retrieval training—to encourage order-aware representations, with analyses and ablations indicating practical improvements without architectural changes."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. **Clear and useful conceptual diagnosis of LLM behavior in sequential recommendation.** The paper articulates a coherent perspective that LLMs tend to treat user histories in a set-like manner, and it frames “order-aware” representations as a compact subspace within the broader unordered semantic space; this organizing view, supported by targeted probes (e.g., shuffling analyses, attention inspections, and ID-only inputs), offers a productive lens for reasoning about when and why order may or may not emerge in LLM-based recommenders without overclaiming beyond the examined setting.\n    \n2. **Methodologically novel yet lightweight regularization via a sequence teacher.** The sequence-teacher–anchored objective steers LLM user representations toward order-aware anchors while pushing against carefully designed order-corrupted negatives, and the adaptive weighting mitigates the risk of over-enforcing noisy sequential cues; importantly, the loss integrates seamlessly with standard retrieval training, making the approach modular, orthogonal to backbone choices, and easy to adopt in existing LLM-for-recs pipelines.\n    \n3. **Practical training recipe with informative internal analyses.** The approach is compatible with parameter-efficient fine-tuning and does not require architectural changes or specialized pretraining, which enhances practical deployability; moreover, the accompanying ablation-style studies and probing experiments are thoughtfully designed to isolate the contribution of each component within the proposed framework, and preliminary cross-domain observations suggest the method has potential to transfer sequential inductive bias without asserting claims that depend on strongly order-centric benchmarks."}, "weaknesses": {"value": "1. **Baselines against modern sequential recommenders are insufficient.** The paper compares primarily to a single non-LLM method from 2018, which is not representative of the substantial progress made in sequential recommendation over the last several years; a fair assessment requires methodological discussion and empirical comparisons to more recent non-LLM sequential models (e.g., stronger transformer-based and contrastive variants), along with updated training protocols and evaluation practices so that the claimed advantages are credible and contextually grounded.\n    \n2. **Dataset choice weakly reflects order-dependent behavior.** The Amazon Reviews setting does not emphasize fine-grained sequence dynamics to the same degree as short-video or music recommendation, where immediate temporal context and session-level dependencies are stronger; consequently, it is unsurprising that a model appears less sensitive to order on this dataset, and performance there may correlate only weakly with true sequence-modeling capability, suggesting that additional experiments on datasets with clearer temporal signals would better validate the central claims.\n    \n3. **Shuffling-based evidence does not substantiate that order sensitivity is beneficial.** Table 1 is interpreted as showing that LLMs are not particularly sensitive to order, yet language order often has limited impact on overall meaning and robustness to small permutations is a known property; moreover, observing a larger degradation under shuffled inputs does not in itself imply a better model, as it can equally indicate reduced robustness to the specific transformation, and the paper does not persuasively justify why order should be expected to matter for this dataset, leaving the causal link between order information and recommendation quality underexplored.\n    \n4. **LLMs should be capable of learning order; observed insensitivity likely stems from limited fine-tuning.** Given strong positional encodings and modeling capacity (e.g., rotary position embeddings), an end-to-end optimization regime would reasonably allow an LLM to capture sequential dependencies at least as well as dedicated recommenders; the reported phenomenon more plausibly reflects the partial adaptation of the LLM—where fine-tuning preserves its robustness to natural-language order variations—so the behavior highlighted is arguably an advantage rather than a deficiency, and a deeper analysis contrasting full end-to-end training with the current adaptation setup would clarify this point."}, "questions": {"value": "see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hn3ap4mhvu", "forum": "d0P96cRFWX", "replyto": "d0P96cRFWX", "signatures": ["ICLR.cc/2026/Conference/Submission10331/Reviewer_fwnq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10331/Reviewer_fwnq"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761492498063, "cdate": 1761492498063, "tmdate": 1762921668323, "mdate": 1762921668323, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "pbNzbfyYoX", "forum": "d0P96cRFWX", "replyto": "d0P96cRFWX", "signatures": ["ICLR.cc/2026/Conference/Submission10331/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10331/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763087038588, "cdate": 1763087038588, "tmdate": 1763087038588, "mdate": 1763087038588, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes LLM-STAR, a sequentially aware LLM-based recommender model that reinforces sequential knowledge from a representation-space perspective. The approach is motivated by the observation that existing LLM-based recommenders tend to ignore item order and conduct set-like behavior. Extensive experiments on multiple Amazon datasets—including ablation analyses, baseline comparisons, and hyperparameter sensitivity tests—verify the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The authors tackle a key limitation of existing LLM-based recommender systems — their inability to effectively capture the sequential order of user–item interactions.  \n2. The authors introduce a novel approach, LLM-STAR, which enables LLM-based models to become sequence-aware by incorporating sequential information through a representation-space framework.   \n3. Experimental results show that LLM-STAR achieves substantial performance gains over prior LLM-based recommender methods."}, "weaknesses": {"value": "1. The observation regarding the set-like behavior of LLM-based recommender models is not novel. Prior work [1] has already demonstrated that these models struggle to capture the sequential order of items, which reflects the same phenomenon. Thus, the term “set-like behavior” appears to be a rephrasing of an existing finding.  \n* Additionally, the analysis associated with Table 2 and Figure 1 requires further clarification. For Table 2, to substantiate the claim that LLMs primarily rely on complete text content rather than order, the authors should include an additional experiment using only textual descriptions (without item IDs) and compare performance differences between original and shuffled sequences. For Figure 1, the purpose and interpretation are ambiguous—the paper does not clearly explain what the experiments on different layers indicate, what the red-highlighted text signifies, or what top tokens attended by the LLM are.  \n\n2. The motivation for incorporating sequence awareness in ordered item sets is not clearly addressed. The authors simply shows performance improvements but do not provide deeper analytical evidence showing that the proposed model truly captures or understands item order. \n\n3. Further analysis is needed to clarify whether LLM-STAR indeed learns sequential information. Since the model uses both item embeddings and text descriptions while keeping the LLM frozen, it remains uncertain whether performance gains stem from the LLM’s comprehension of sequence or from external representations. Additional ablation studies—such as removing item embeddings or text descriptions—should be performed to explicitly examine how the LLM interprets sequential user interactions.  \n\n4. Although adherence to the Code of Ethics is required, the paper does not include an explicit statement confirming compliance. This omission raises concerns about whether the authors have fully met ethical publication requirements.\n\n[1] Lost in Sequence: Do Large Language Models Understand Sequential Recommendation? Kim et al., KDD'25"}, "questions": {"value": "Question. \n\n1. Why is sequential knowledge beneficial for cross-domain recommendation? Please provide specific reasoning or analysis explaining the source of the observed performance improvements.\n\n2. Why do the dataset statistics differ from those reported in the previous work [1], despite the claim in Line 323 that this study follows the same data preprocessing procedure?  \n\n3. Could the authors clarify the main differences between this work and the previous study [1]? It appears that the proposed method heavily relies on the earlier findings and offers the simple method\n\nGiven that the primary finding is not new and the proposed approach is relatively simple, the paper’s overall contribution to the LLM-based recommender systems community seems marginal. Therefore, I recommend rejection.\n\n[1] Lost in Sequence: Do Large Language Models Understand Sequential Recommendation? Kim et al., KDD'25"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aHyVgzVprE", "forum": "d0P96cRFWX", "replyto": "d0P96cRFWX", "signatures": ["ICLR.cc/2026/Conference/Submission10331/Reviewer_heJn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10331/Reviewer_heJn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761784747736, "cdate": 1761784747736, "tmdate": 1762921667866, "mdate": 1762921667866, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper explores the challenge of large language models (LLMs) being insensitive to sequence information in sequence recommendation tasks. It proposes a contrastive learning-based approach to improve LLMs' ability to capture and model sequence information, supported by extensive experimental validation. However, the paper has notable shortcomings in writing quality, novelty articulation, technical contributions, and clarity of argumentation, making it unsuitable for acceptance at ICLR 2026."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The paper offers an interesting perspective, suggesting that the predictive behavior of LLMs is ensemble-oriented, with a stronger focus on unordered sets of items.\n  \n- It presents a comprehensive survey of sequence recommendation methods, covering both traditional approaches and LLM-based techniques."}, "weaknesses": {"value": "- Writing quality: The paper lacks clarity, making it challenging to discern key insights and the research motivation.\n- Limited novelty: The proposed approach is not innovative, as adapter-based representation mapping with contrastive learning has been widely explored in prior studies for guiding LLMs in capturing sequential and cooperative information.\n- Empirical limitations: The explanation in Table 1 regarding LLMs' insensitivity to observed order is unclear and insufficiently justified.\n- Reproducibility: The absence of provided code raises concerns about reproducibility."}, "questions": {"value": "- What are the specific settings for the \"original\" and \"shuffle\" options in Table 1? Section 4.1 does not clearly explain whether these settings are based on a traditional baseline or a LLM-based baseline. Additionally, the empirical results in Table 1 lack detailed discussion—how do they explain the insensitivity of LLMs to observed sequences?\n\n- The paper claims that existing work has not deeply analyzed the reasons for LLMs' insensitivity to sequence order. Where is the convincing reasoning or analysis provided in this paper?\n\n- What advantages do LLMs offer in understanding sequence knowledge compared to traditional sequence modeling methods?\n\n- Why does the proposed method rely on contrastive learning, as seen in mainstream LLM-enhanced recommendation methods? Can your framework effectively enable LLMs to understand the order information in interactive sequences? What are the key differences between your approach and others?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CKeDrrkw5R", "forum": "d0P96cRFWX", "replyto": "d0P96cRFWX", "signatures": ["ICLR.cc/2026/Conference/Submission10331/Reviewer_nHEf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10331/Reviewer_nHEf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761841279560, "cdate": 1761841279560, "tmdate": 1762921667439, "mdate": 1762921667439, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a critical limitation of Large Language Models (LLMs) in sequential recommendation: LLMs exhibit set-like prediction behavior, focusing on unordered item collections rather than the order of user interactions. Through systematic experiments (e.g., removing item textual content and analyzing attention patterns), the authors verify this order insensitivity and provide a representation-space perspective inspired by entropy—ordered sequence embeddings form a compact subspace of unordered collection embeddings. To mitigate this issue, they propose LLM-STAR, a framework integrating two core modules: (1) Sequence-Teacher-Anchored (STA) loss, which uses a pre-trained sequential model (SASRec) as a teacher to generate positive anchors and multi-scale negative anchors (random shuffle, window shuffle, last-N shuffle) for contrastive learning; (2) Adaptive Regularization (AR), which weights the STA loss by the teacher’s confidence in sequential patterns to avoid overfitting to noisy data. Extensive experiments on four Amazon datasets demonstrate that LLM-STAR achieves state-of-the-art performance, outperforming baseline LLM-based and traditional sequential recommendation models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "## 1. Originality.\n- The paper reveals the set-like prediction behavior of LLMs in sequential recommendation through rigorous experiments, which is a deeper and more fundamental insight than prior works (e.g., Hou et al., 2024b; Kim et al., 2025) that only observed order insensitivity without exploring the underlying mechanism.\n- The entropy-inspired representation-space perspective provides a novel theoretical explanation for LLM’s order insensitivity, linking sequential information to embedding compactness.\n- mThe combination of teacher-guided contrastive learning with multi-scale negative anchors and adaptive regularization is a creative design, addressing the limitations of prior distillation-based methods (e.g., LLM-SRec) that over-rely on positive teacher signals."}, "weaknesses": {"value": "## 1. Limited analysis of textual information’s role\nThe paper shows that removing textual content increases LLM’s order sensitivity (Table 2), but it does not further explore why textual information dominates LLM’s prediction. In fact, I believe that the text dominance may be due to the author using LLM as the base for training, with the amount of training data being far less than that of Pretrain. A data volume at the tens of millions level or even the industrial level might directly solve this problem, but the author did not make a comparison in this regard. Therefore, this directly leads to my doubt about the author's motivation and their proposition.\n\n\n## 2. Lack of efficiency analysis.\n- Given that LLM-STAR introduces additional modules, it is critical to demonstrate that the performance gain is not at the cost of excessive computational overhead, especially for industrial applications.\n\n## 3. Limited exploration of negative anchor design.\n- The paper uses three types of negative anchors but does not analyze the contribution of each type individually (e.g., which shuffle strategy is most effective for capturing sequential patterns).\n- There is no comparison with other negative sampling strategies (e.g., hard negative sampling based on item similarity) to verify if multi-scale shuffle-based negatives are optimal."}, "questions": {"value": "- Conduct an ablation study on individual negative anchor types to clarify their respective contributions and optimize the negative sampling strategy.\n- Add a case study to visualize how LLM-STAR’s embeddings of ordered sequences become more compact compared to baseline LLMs, verifying the representation-space perspective.\n- Conduct additional validation experiments with an extremely large data scale and re-explore the proposed set-like prediction behavior based on these experiments."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No concern"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sDMgcvhSn7", "forum": "d0P96cRFWX", "replyto": "d0P96cRFWX", "signatures": ["ICLR.cc/2026/Conference/Submission10331/Reviewer_pjMy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10331/Reviewer_pjMy"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991734829, "cdate": 1761991734829, "tmdate": 1762921666930, "mdate": 1762921666930, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}