{"id": "KIUOtEKzzN", "number": 5835, "cdate": 1757938914822, "mdate": 1759897950493, "content": {"title": "NoLLMRAG: LLM-Free Makes Graph-Based RAG Highly Efficient, Effective and Generalizable", "abstract": "Graph-based Retrieval-Augmented Generation (graph-based RAG) improves retrieval relevance and multi-hop reasoning compared to traditional RAG by constructing a graph that models relationships among text chunks. However, existing methods heavily rely on LLMs during indexing, resulting in inefficiency and unstable performance across LLM scales. Moreover, during retrieval, the lack of effective mechanisms for extracting query keywords and filtering irrelevant chunks further leads to redundant retrieval, introducing noise and degrading answer quality. To address these limitations, we propose NoLLMRAG, a novel graph-based RAG framework which is LLM-free during indexing and retrieval. It builds a three-layer heterogeneous graph index without LLMs, leverages a graph-statistics-driven keyword extraction to select keywords from queries that are aligned with the corpus, and applies a clustering-based retrieval on co-occurrence subgraphs to select more relevant chunks for generation. Experiments on three datasets and three LLMs demonstrate that NoLLMRAG achieves an average improvement of 41.27\\% over the strongest baseline, with indexing speedup of up to 300$\\times$ and QA speedup of up to 15$\\times$, and maintains robust adaptability for real-time corpus expansion, highlighting its superior performance, efficiency, and generalization across LLMs and domains.", "tldr": "We propose NoLLMRAG, a novel graph-based RAG framework which is LLM-free during indexing and retrieval, enabling strong performance, exceptional efficiency, and robust generalization", "keywords": ["Retrieval-Augmented Generation", "Large Language Model", "Graph"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ac0fa85bf50a7aac522063e70217e6940e5d80c5.pdf", "supplementary_material": "/attachment/955aac97606b3085b8f4ad987a5f95e70b97d3af.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes NoLLMRAG, a GraphRAG framework that eliminates LLM dependence by leveraging NLP tools to build a three-layer heterogeneous graph and extract query keywords. A clustering-based retrieval algorithm is proposed to retrieve relevant text chunks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. This paper demonstrate that leverging the NLP tools instead of LLMs can also achieve good results for GraphRAG.\n2. The proposed method demonstrates effiency gains compared with LLM-based methods.\n3. The paper is well-written and easy to follow."}, "weaknesses": {"value": "1. The novelty is limited. It is a common practice to extract keywords using NLP tools such as Named Entity Recognition (NER) [1]. The proposed Three-Layer Heterogeneous Graph is also quite common.\n2. The motivation is not clear. The authors claim that clustering-based retrieval algorithm can reduce redundancy and improve retrieval quality and introduce several steps. However, what is the motivation behind these steps?\n3. Lacks of baselines and evaluation datasets. The authors only use 3 baselines and 3 datasets. More baselines and datasets should be used to make a comprehensive evaluation.\n\n\n[1] Named Entity Extraction for Knowledge Graphs: A Literature Overview."}, "questions": {"value": "1. Why does HippoRAG 2 fails when applying the Qwen2.5-3B model?\n2. What is the retrieval performance of the proposed method?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "qfaBhIrH0J", "forum": "KIUOtEKzzN", "replyto": "KIUOtEKzzN", "signatures": ["ICLR.cc/2026/Conference/Submission5835/Reviewer_yRCx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5835/Reviewer_yRCx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5835/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761592375086, "cdate": 1761592375086, "tmdate": 1762918293707, "mdate": 1762918293707, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces NoLLMRAG, a graph-based RAG framework that removes LLMs from the indexing pipeline. It leverages graph-statistics-driven keyword extraction and clustering via keyword co-occurrence to better align queries with the corpus. Experiments across diverse QA datasets and LLMs of varying sizes show consistent gains over state-of-the-art graph RAG in accuracy, efficiency, and generalization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1: Tackles a timely and important problem for both industry and academia.\nS2: Achieves high computational efficiency and low cost by using tokenizer-based token extraction instead of LLM-based entity extraction.\nS3: Delivers competitive performance, validated with LLM-as-a-judge evaluations."}, "weaknesses": {"value": "W1: The effectiveness of the proposed importance score is not compared against established graph ranking methods (e.g., PageRank, SALSA, HITS).\nW2: The mechanism of cluster-based chunk retrieval are insufficiently explained.\nW3: The construction details of the three-layer heterogeneous graph are missing (node/edge types, counts, and connectivity)."}, "questions": {"value": "1.\tTokenizer choice: Is the tokenizer tied to a specific LLM, or can users select any tokenizer independent of the LLM used for embeddings? Please clarify compatibility, token normalization, and handling of subword units.\n2.\tImportance score validation: The design resembles TF-IDF but lacks evidence of correlation with node “importance.” If ground-truth importance is unavailable, compare against baselines such as PageRank and SALSA (e.g., overlap percentage of top-k nodes, Kendall tau/Spearman correlation, precision@k).\n3.\tGraph statistics: Given fine-grained tokenization, the graph likely contains many token nodes. Please report node and edge counts by type (token/chunk/document; token–token, token–chunk, chunk–document), average degrees, sparsity, and memory footprint.\n4.\tCluster-based retrieval: Elaborate the procedure (objective, stopping criteria, hyperparameters) and include a step-by-step example on a small corpus to illustrate iterations, cluster formation, and chunk selection, along with complexity analysis."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "88AfZfkl0I", "forum": "KIUOtEKzzN", "replyto": "KIUOtEKzzN", "signatures": ["ICLR.cc/2026/Conference/Submission5835/Reviewer_xwLn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5835/Reviewer_xwLn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5835/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761651265319, "cdate": 1761651265319, "tmdate": 1762918293341, "mdate": 1762918293341, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The method builds a three-layer heterogeneous graph using traditional NLP tools instead of expensive LLM calls. It extracts keywords from queries using graph statistics rather than LLM understanding. The system also uses clustering-based retrieval to reduce redundant information and improve answer quality."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "NoLLMRAG cuts out LLMs during indexing and retrieval, which makes things way faster. It's up to 300× quicker at indexing and 15× faster for answering questions compared to other graph-based RAG methods. Instead of expensive LLM calls, it just uses basic NLP tools like spaCy to build the graph. The system stays fast even when you keep adding new documents, so it actually works for real applications.\n\nThe retrieval part groups related keywords together to avoid grabbing irrelevant stuff. All these pieces work together to create a system that doesn't rely on LLMs at all, which is different from existing methods.\n\nNoLLMRAG handles complex multi-step questions better while still doing fine on simple ones."}, "weaknesses": {"value": "The three-layer graph idea is clever, but it would be helpful to understand how it captures relationships without LLMs. Right now the Token-Token edges just connect words that are next to each other in documents. This works okay but might miss connections between related ideas that aren't neighbors.\n\nIt could be interesting to try other ways of connecting tokens. Maybe connecting similar tokens across different chunks. These approaches might catch more meaningful relationships than just word order.\n\nThe paper doesn't really explain how the system weighs different edge types. Document-Chunk edges show hierarchy while Token-Token edges show sequence. How does retrieval balance these different relationship types? Some discussion of this would help readers understand the design better.\n\nThe importance scoring approach is neat, but some choices seem worth exploring more. Why multiply the three frequency measures and then take the log? What about adding them together or picking the maximum? The multiplication could get tricky when any frequency gets really small.\n\nThe log transformation makes sense intuitively, but testing other combinations might show if this is really the best approach. The threshold τ = 0.5 also seems like it was picked somewhat arbitrarily. Maybe trying different values or making it adapt to different queries could work better."}, "questions": {"value": "See my analysis above for specific details on these questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bvdpI7Hxsz", "forum": "KIUOtEKzzN", "replyto": "KIUOtEKzzN", "signatures": ["ICLR.cc/2026/Conference/Submission5835/Reviewer_UDXU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5835/Reviewer_UDXU"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5835/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762081935014, "cdate": 1762081935014, "tmdate": 1762918292979, "mdate": 1762918292979, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes NoLLMRAG, an LLM-free graph-based RAG framework to address efficiency bottlenecks in existing methods. The approach constructs a three-layer heterogeneous graph using traditional NLP tools, employs graph-statistics-driven keyword extraction, and implements clustering-based retrieval. Experiments show 41.27% average accuracy improvement with up to 300× indexing speedup and 15× QA speedup."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. **Significant efficiency improvements.** The LLM-free design achieves dramatic speedups (16-300× indexing, up to 15× QA) while maintaining competitive accuracy, addressing an important practical problem in RAG systems.\n\n2. **Good robustness and noise reduction.** Shows strong performance across different LLM scales, especially on small models where baselines fail. The graph-statistics approach effectively reduces retrieval redundancy as validated by ablation studies.\n\n3. **Comprehensive experiments.** Evaluation covers three QA task types, multiple LLM scales, and various metrics including real-time corpus expansion scenarios.\n\n4. **Clear presentation.** Well-structured paper with logical flow and comprehensive experimental results."}, "weaknesses": {"value": "1. **Essentially a pre-LLM approach.** While advantages over LLM-based methods are discussed, comparison with traditional non-LLM RAG methods (BM25, TF-IDF, hybrid retrieval) is missing, making it unclear whether improvements come from novel contributions or just avoiding LLM overhead.\n\n2. **Limited baseline comparison.** Only three graph-based RAG baselines are compared. Missing comparisons with classical IR methods and traditional graph algorithms weakens the evaluation.\n\n3. **Limited semantic understanding.** The statistical approach cannot handle cross-document concept alignment or synonyms (e.g., \"ML\" vs \"machine learning\"), which may hurt performance on complex reasoning tasks. The authors should provide more evidence on whether it hurts cross-document concept alignment to not use LLMs.\n\n4. **Small LLM evaluation only.** Testing limited to small models (3B-7B, GPT-4o-mini). Should evaluate on larger models to better assess generalizability claims."}, "questions": {"value": "1. **How does your method compare to traditional non-LLM RAG approaches?** It would be valuable to see comparisons with classical methods like BM25-based retrieval, TF-IDF, and hybrid retrieval systems to better understand whether the improvements come from your novel graph construction or from avoiding LLM overhead.\n\n2. **Could you provide broader baseline comparisons?** The current evaluation against three graph-based methods is somewhat limited. Comparisons with additional sophisticated graph indexing methods and classical information retrieval algorithms would strengthen the evaluation.\n\n3. **How does your method handle semantic variations and synonyms?** The statistical approach may struggle with cases where the same concept is expressed differently (e.g., \"ML\" vs \"machine learning\"). Could you discuss this limitation and its potential impact on performance?\n\n4. **How does performance scale with larger, more capable LLMs?** The evaluation focuses on smaller models. Testing on larger LLMs like GPT-4o or Claude Sonnet would help validate whether the observed advantages persist when baselines have access to stronger semantic understanding capabilities."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "uBaiyxUGno", "forum": "KIUOtEKzzN", "replyto": "KIUOtEKzzN", "signatures": ["ICLR.cc/2026/Conference/Submission5835/Reviewer_CDD7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5835/Reviewer_CDD7"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5835/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762140652686, "cdate": 1762140652686, "tmdate": 1762918292147, "mdate": 1762918292147, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}