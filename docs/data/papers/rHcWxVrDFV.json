{"id": "rHcWxVrDFV", "number": 23338, "cdate": 1758342403576, "mdate": 1759896820193, "content": {"title": "Deliberation Meets Reaction: A Dual-Expert VLA framework for Autonomous Driving", "abstract": "Vision-Language-Action (VLA) models have emerged as a promising paradigm for end-to-end autonomous driving due to their remarkable interpretability and generalization. However, their practical deployment is severely hindered by substantial computational costs and high inference latency. This challenge stems from (1) a large number of model parameters for maintaining world knowledge and (2) intensive Chain-of-Thought (CoT) reasoning for improving driving performance. Inspired by the observation that experienced drivers usually only engage in intensive deliberation in unfamiliar or complex situations, we propose an adaptive dual-expert VLA model, termed DE-Driver, to adaptively select activated experts and reduce unnecessary reasoning. Specifically, DE-Driver integrates a lightweight reactive expert for swift responses and a powerful deliberative expert for complex reasoning. Depending on the scenario, a scene-aware router dynamically directs layer-wise features to the appropriate expert. Then, these selected experts determine whether to generate CoT reasoning, ensuring a balance between inference efficiency and driving performance. Experimental results on the closed-loop Bench2Drive benchmark show that DE-Driver achieves driving performance on par with state-of-the-art methods while significantly improving inference efficiency.", "tldr": "", "keywords": ["autonomous driving", "VLM"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6c22e17632aef2be2fd043dbbbadf6b55e1ba8df.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes DE-Driver, a novel vision-language-action (VLA) model featuring a dual-expert architecture that adaptively switches between specialized experts and prunes unnecessary reasoning chains to achieve high-efficiency autonomous driving. DE-Driver demonstrates competitive performance across multiple efficiency metrics and significantly reduces inference time."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1/ The paper introduces a Dual-Expert (DE) module that dynamically switches between a lightweight reactive expert and a more powerful deliberative expert, enabling context-aware computation.\n\n2/ A Progressive Expert Specialization (PES) strategy is proposed to enforce distinct expert roles and stabilize router training, selectively skipping the generation of unnecessary chains of thought (CoT).\n\n3/ DE-Driver gets a new state-of-the-art on the Bench2Drive benchmark."}, "weaknesses": {"value": "1/ The dual-expert design—comprising a lightweight reactive expert and a powerful deliberative expert—resembles a classic teacher-student framework, which is not uncommon in model compression or scenario-adaptive systems. \n\n2/ The reliability of the Scene-Aware Router remains a concern: misjudgments by the router could lead to the omission of essential CoT reasoning in complex scenarios, potentially compromising decision quality and safety.\n\n3/ While the DE module reduces latency, it increases overall system complexity. The overall number of parameters is more than before."}, "questions": {"value": "1/ Beyond improving inference efficiency, does skipping unnecessary CoT generation have any adverse effects on model training stability or final performance?  \n\n2/ Since the experiments rely on data collected from the CARLA simulator, which may not fully capture the complexity of real-world driving. How likely is it to skip CoT reasoning would diminish significantly in more diverse and challenging real-world scenarios?  \n\n3/ Could the authors provide statistics on the proportion of decisions handled by each expert? Moreover, is this allocation ratio stable across different traffic conditions or scene types, or does it vary significantly?  \n\n4/ Does the Scene-Aware Router incorporate mechanisms such as a cooldown period (i.e., minimum dwell time per expert) or hysteresis to prevent rapid switching that might destabilize vehicle control and degrade ride comfort—as alluded to in the paper’s discussion of comfort-aware improvements?  \n\n5/ The Structured Pruning strategy is mentioned but not described in detail. Could the authors provide a quantitative analysis linking the reduction in model parameters to concrete gains in latency and performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CMijDrFeuv", "forum": "rHcWxVrDFV", "replyto": "rHcWxVrDFV", "signatures": ["ICLR.cc/2026/Conference/Submission23338/Reviewer_JnUT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23338/Reviewer_JnUT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23338/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761044452373, "cdate": 1761044452373, "tmdate": 1762942612752, "mdate": 1762942612752, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work identifies latency as a key bottleneck for applying VLA models in autonomous driving. To mitigate this, a novel approach is proposed, which combines structured pruning, knowledge distillation, and an adaptive expert router. The core idea is to enable the model to automatically alternate between experts in response to different scenarios. This strategy is designed to decrease inference latency to near real-time levels, without a significant loss in decision-making performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper attempts to address a critical challenge in applying VLA (Vision-Language-Action) models to autonomous driving inference tasks: enabling real-time and accurate inference. Furthermore, the authors conduct their experiments in a closed-loop policy environment, which enhances the practical significance of the findings."}, "weaknesses": {"value": "The experimental evaluation does not sufficiently address the core problem outlined in the paper. The experiments are primarily focused on driving performance, failing to adequately demonstrate the proposed method's improvements in terms of latency. The paper would be significantly strengthened by presenting an analysis of the trade-off between inference performance (e.g., accuracy) and inference latency, which would provide a more comprehensive and convincing evaluation."}, "questions": {"value": "- In the caption of Figure 1, the subfigure indicator `(a)` appears to be incorrectly written as `(1)`. Please correct this typo.\n- There seems to be an inconsistency regarding the model size of DE-Driver reported in Table 3. The table shows that DE-Driver has fewer parameters than SimLingo. However, the description accompanying Figure 3 suggests that DE-Driver utilizes two experts for inference, with the larger expert being architecturally equivalent to SimLingo in terms of parameter count. Logically, the total parameters of DE-Driver (the sum of both experts) should be greater than, or at the very least equal to, that of SimLingo. The authors should clarify this discrepancy.\n- The analysis of inference latency could be significantly strengthened with the following additions: a) It would be more informative to report the total end-to-end inference latency of the model, rather than only providing a breakdown of latency for each module. b) To better illustrate the overall latency distribution, the authors could present the per-frame latency data using a box plot or a violin plot. This would offer readers clearer insights into the model's performance consistency and variance. c) A crucial experiment would be to investigate the relationship between scene complexity and inference latency. Does the latency of DE-Driver converge towards that of SimLingo as scene complexity increases, or does it remain slightly lower? Including such targeted experiments on inference latency would substantially enrich the paper's contributions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0IirqIl0np", "forum": "rHcWxVrDFV", "replyto": "rHcWxVrDFV", "signatures": ["ICLR.cc/2026/Conference/Submission23338/Reviewer_UYDC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23338/Reviewer_UYDC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23338/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761728632012, "cdate": 1761728632012, "tmdate": 1762942612339, "mdate": 1762942612339, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces DE-Driver, a Vision-Language-Action (VLA) model that aims to improve the efficiency of autonomous driving systems while maintaining high performance. DE-Driver incorporates a dual-expert system with two specialized experts: a reactive expert for handling simple scenarios and a deliberative expert for more complex situations requiring detailed reasoning. The system dynamically switches between these experts using a scene-aware router based on the difficulty of the driving task. Additionally, the authors introduce a Progressive Expert Specialization (PES) strategy for training these experts and improving their performance. DE-Driver achieves state-of-the-art performance on the Bench2Drive benchmark, demonstrating both high driving performance and reduced inference latency. The model outperforms existing methods in terms of computational efficiency without sacrificing decision-making quality."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. A dual-expert system with adaptive switching between reactive and deliberative experts is a novel contribution to the field of autonomous driving. This approach addresses the significant trade-off between computational cost and performance by selectively activating the necessary expertise based on scenario complexity.\n2. The Progressive Expert Specialization (PES) strategy for training the reactive and deliberative experts is a clever method for balancing efficiency and performance. It enhances the model’s ability to perform under diverse conditions and allows for both specialized pruning and knowledge distillation to create a highly efficient model.\n3. DE-Driver outperforms several baselines on the Bench2Drive benchmark, achieving state-of-the-art driving scores while reducing computational costs. Its strong performance in complex scenarios (e.g., merging, overtaking) further demonstrates its robustness."}, "weaknesses": {"value": "1. While the paper compares DE-Driver to a number of other methods, the comparison with models using Mixture of Experts (MoE) or similar adaptive reasoning models is limited. A more comprehensive comparison with models that dynamically adjust computation based on task complexity (e.g., DriveMoE) would provide a clearer picture of the model's relative strengths.\n2. The reactive expert, while lightweight and efficient, may struggle with more complex reasoning tasks, as evidenced by some performance degradation when it is used alone. The pruning process, while effective, still introduces some limitations in generalization to more challenging scenarios.\n3. The evaluation is based on closed-loop benchmarks, which are useful but may not fully reflect real-world variability. Testing on more diverse or real-world datasets could further validate the model's robustness and generalizability across a wider range of driving environments."}, "questions": {"value": "1. Have you considered testing DE-Driver in real-world driving environments? How does it perform in terms of both safety and latency in these environments?\n2. You mention that expert switching sometimes leads to discontinuous decision-making, affecting comfort. Have you considered implementing a temporal processing mechanism that smooths out transitions between experts, such as incorporating memory-based methods or using a sliding window to consider past actions?\n3. The paper shows DE-Driver's strong performance in complex tasks like overtaking and merging. How does the model generalize to long-tail tasks or situations not seen during training (e.g., rare road events, unusual pedestrian behavior)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "RyoO5C5mSY", "forum": "rHcWxVrDFV", "replyto": "rHcWxVrDFV", "signatures": ["ICLR.cc/2026/Conference/Submission23338/Reviewer_2qVr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23338/Reviewer_2qVr"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23338/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761866157744, "cdate": 1761866157744, "tmdate": 1762942612136, "mdate": 1762942612136, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "DE-Driver targets a critical, practical challenge in VLA-based autonomous driving—balancing performance and inference efficiency—and offers an innovative dual-expert solution aligned with human driving intuition. The paper’s strengths lie in its well-motivated adaptive framework, structured PES training strategy, and comprehensive closed-loop evaluation on Bench2Drive, which validates both SOTA driving performance and significant latency reductions. However, several limitations undermine the work’s depth and generalizability: the scene-aware router’s complexity assessment lacks dynamic interaction modeling (e.g., unpredictable pedestrian behavior), the CoT generation logic for the deliberative expert is underspecified, long-tail scenario robustness is not explicitly evaluated, and comparisons to recent efficiency-focused VLA models (e.g., FastDriveVLA) are missing. Additionally, the trade-off between expert switching and driving comfort (acknowledged as low comfortness scores) lacks actionable mitigation details. Addressing these gaps, via expanded evaluations, clarified technical mechanisms, and more inclusive baselines, would strengthen DE-Driver’s contribution to efficient, deployable VLA systems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper directly addresses a critical pain point of existing VLA models: their prohibitive computational cost (due to billions of parameters and mandatory CoT reasoning) makes them incompatible with resource-constrained onboard hardware. DE-Driver’s dual-expert design, leveraging a lightweight reactive expert for ~80% of simple scenarios (per human driving analogies) and a deliberative expert only when necessary, resolves this by adapting computation to scenario complexity rather than using a one-size-fits-all VLA backbone. This focus on efficiency without performance loss aligns with real-world autonomous driving deployment needs, distinguishing it from works that prioritize performance alone."}, "weaknesses": {"value": "CoT generation logic for the deliberative expert is underspecified. While the paper claims the deliberative expert generates CoT only when necessary, it provides no details.\n\nMissing comparisons to recent efficiency-focused VLA baselines, DE-Driver claims to advance “efficient VLA design,” but it does not compare to recent works with similar goals.\n\nThe paper frames VLA models’ strength as handling long-tail scenarios, but DE-Driver’s performance on these is untested. \n\nThe paper acknowledges that DE-Driver has lower comfort scores (17.61) than baselines like SimLingo (33.67) and attributes this to expert switching. However, no details are provided on why switching causes discomfort (e.g., abrupt changes in acceleration, conflicting trajectory suggestions from adjacent layers). No mitigation strategies are proposed beyond a vague future temporal processing mechanism. For example, a simple smoothing layer between expert outputs or a switching hysteresis (avoiding frequent toggles between experts) could reduce oscillations, but these are not discussed."}, "questions": {"value": "CoT generation logic for the deliberative expert is underspecified. While the paper claims the deliberative expert generates CoT only when necessary, it provides no details.\n\nMissing comparisons to recent efficiency-focused VLA baselines, DE-Driver claims to advance “efficient VLA design,” but it does not compare to recent works with similar goals.\n\nThe paper frames VLA models’ strength as handling long-tail scenarios, but DE-Driver’s performance on these is untested. \n\nThe paper acknowledges that DE-Driver has lower comfort scores (17.61) than baselines like SimLingo (33.67) and attributes this to expert switching. However, no details are provided on why switching causes discomfort (e.g., abrupt changes in acceleration, conflicting trajectory suggestions from adjacent layers). No mitigation strategies are proposed beyond a vague future temporal processing mechanism. For example, a simple smoothing layer between expert outputs or a switching hysteresis (avoiding frequent toggles between experts) could reduce oscillations, but these are not discussed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4yuVkZuoO2", "forum": "rHcWxVrDFV", "replyto": "rHcWxVrDFV", "signatures": ["ICLR.cc/2026/Conference/Submission23338/Reviewer_cnJ7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23338/Reviewer_cnJ7"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23338/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990495858, "cdate": 1761990495858, "tmdate": 1762942610831, "mdate": 1762942610831, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}