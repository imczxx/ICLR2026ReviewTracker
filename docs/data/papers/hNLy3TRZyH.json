{"id": "hNLy3TRZyH", "number": 23295, "cdate": 1758341887025, "mdate": 1763630456308, "content": {"title": "Geometry-Aware Generative Modeling for Graph Clustering via Hyperspherical Diffusion", "abstract": "Unsupervised graph clustering is fundamental for uncovering latent structures in graph-structured data, particularly in scenarios where labeled data is limited or unavailable. However, existing approaches often struggle to simultaneously achieve cluster-discriminative representations and geometric consistency. Conventional variational graph autoencoders rely on unimodal Gaussian priors in Euclidean space, often leading to overlapping latent clusters, while contrastive approaches depend on heuristic augmentations that may disrupt essential structural information. To overcome these limitations, we propose Hyperspherical Contrastive Diffusion (HCD), a novel unsupervised graph clustering framework that jointly leverages hyperspherical geometry and diffusion-based generative modeling. HCD constrains node embeddings to lie on a unit hypersphere and refines them via a multi-step temporal denoising diffusion process. It integrates a Product-of-Experts aggregation strategy, a von Mises–Fisher KL divergence to regularize angular latent distributions, a spherical contrastive loss to enforce discriminative alignment, and a cluster compactness-separation regularizer based on Student-t assignments and entropy minimization. These objectives collectively shape a latent space that preserves graph structure while promoting tight intra-cluster cohesion and clear inter-cluster separation. Comprehensive experiments across diverse benchmarks and multiple clinically and biologically significant real-world tissue clustering scenarios (ranging from complex neuroanatomical region identification to cancer tissue segmentation under varied conditions) demonstrate that HCD consistently achieves state-of-the-art performance in clustering accuracy, robustness, and stability.", "tldr": "", "keywords": ["Graph Representation Learning", "Graph Clustering", "Generative Modeling"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c83a431f11856e0f79aa55e839d55ac86971ffb6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Hyperspherical Contrastive Diffusion (HCD), a novel framework for unsupervised graph clustering. HCD refines node embeddings through a multi-step diffusion process, aggregates them via a Product-of-Experts mechanism, and projects them onto a hypersphere. To encourage cluster-friendly representations, it integrates a vMF prior, a spherical contrastive loss, and a compactness–separation regularizer, explicitly shaping the latent space for both structural coherence and discriminative clustering.\nExtensive experiments on diverse datasets, including large-scale and medium-scale benchmark graphs as well as multiple spatial transcriptomics datasets, demonstrate that HCD consistently outperforms state-of-the-art baselines, showing strong ability to capture meaningful community structures and biologically relevant patterns across different domains."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1、The paper introduces a novel combination of hyperspherical geometry and diffusion modeling for unsupervised graph clustering, which has not been explored in prior work.\n2、The proposed framework is well designed, with multiple complementary objectives (reconstruction, uniformity, contrastive alignment, and clustering regularization) that together encourage discriminative and robust representations.\n3、The experimental evaluation is extensive, covering both large-scale and medium-scale benchmark graphs as well as real-world spatial transcriptomics datasets, demonstrating consistent and significant improvements over strong baselines."}, "weaknesses": {"value": "1、While the proposed framework is novel, the paper does not provide sufficient theoretical justification for why hyperspherical embeddings and the Product-of-Experts aggregation should consistently yield superior clustering performance across diverse graph settings.\n2、The complexity analysis is brief and does not adequately address potential computational bottlenecks when applying the method to very large-scale graphs, leaving uncertainty about its practicality in real-world scenarios.\n3、The evaluation focuses primarily on standard benchmarks and transcriptomics datasets, but does not include heterogeneous or dynamic graphs. This limits the evidence for the general applicability of the approach."}, "questions": {"value": "1、Why does multi-step diffusion with PoE consistently outperform a single-step encoder? Can the authors provide a principled explanation beyond empirical results?\n2、Could the authors provide a stronger justification for why hyperspherical representations consistently outperform Euclidean ones? Under what conditions might this assumption break down?\n3、Has the method been evaluated on heterogeneous or dynamic graphs? If not, could the authors discuss how well the approach might generalize to such settings and what limitations or adaptations would be expected?\n4、See more on Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "WKiDI2M4uF", "forum": "hNLy3TRZyH", "replyto": "hNLy3TRZyH", "signatures": ["ICLR.cc/2026/Conference/Submission23295/Reviewer_Mrrs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23295/Reviewer_Mrrs"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23295/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761636326800, "cdate": 1761636326800, "tmdate": 1762942593977, "mdate": 1762942593977, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces **Hyperspherical Contrastive Diffusion (HCD)**, a new framework for *unsupervised graph clustering* that integrates hyperspherical geometry with diffusion-based generative modeling. HCD couples a diffusion-like multi-step encoder with hyperspherical geometry: Gaussian latents are temporally fused via PoE, projected to the unit sphere, and regularized with a vMF KL. A spherical contrastive loss plus a cluster compactness–separation term (with entropy) promotes discriminative, non-collapsed embeddings. Across benchmarks and tissue/neuroanatomical datasets, HCD attains state-of-the-art or competitive clustering performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper presents a novel and well-motivated approach that combines diffusion-based modeling with hyperspherical geometry for unsupervised graph clustering, with a clear objective integrating reconstruction, contrastive, and clustering terms in a unified framework.\n\n\n2. The work also contributes conceptually by bridging geometric representation learning and diffusion generative models, potentially inspiring future extensions."}, "weaknesses": {"value": "1. This work exhibits ambiguity in “temporal diffusion” and unclear inter-step dependency. The encoder defines \\(H^{(t)} = \\phi^{(t)}(X, A)\\), suggesting that each timestep processes the same input independently rather than evolving from \\(H^{(t-1)}\\). Without an explicit forward–reverse relation or recurrent dependency, the notion of “temporally-aware diffusion” appears conceptual rather than algorithmic, and it seems like a multi-step VAE instead of a diffusion model.\n\n2. The transition from Gaussian latent encoding to spherical regularization is theoretically inconsistent. Eq. (2) uses the Gaussian reparameterization trick to sample latent variables that are later projected onto the unit hypersphere and regularized with a von Mises–Fisher (vMF) prior, and this transition lacks explanation and may introduce inconsistencies between the assumed likelihood and the geometric constraint. In fact, the Gaussian distribution in Euclidean space is different from distributions on the hypersphere; the authors should address this confusion.\n\n3. The theoretical basis of the Product-of-Experts (PoE) aggregation assumes that each expert provides an independent observation of the latent variable. However, in this model, the timestep-wise latent variables \\(z^{(t)}\\) are clearly correlated, since they originate from the same graph and represent successive states of the same encoding trajectory. This violates the independence assumption and can cause the aggregated posterior variance to be underestimated, resulting in an **overconfident** or overly sharp fused distribution.\n\n4. The spherical KL uniformity objective is reasonable in spirit but may conflict with clustering and requires numerically stable implementation. In fact, for graph clustering with latent community structure and implicit hierarchies, **hyperbolic geometry** can be a more natural fit than the hypersphere, where negative curvature offers exponential volume growth and low-distortion embeddings of trees and hierarchies, often yielding tighter intra-cluster contraction and larger inter-cluster margins at the same dimensionality."}, "questions": {"value": "1. If this design differs from DDPM-style diffusion, could the authors clarify its theoretical formulation, training objective, and convergence behavior? Specifically, what probabilistic or generative interpretation justifies the multi-step encoder, and how does it relate to the linear \\(\\beta\\)-schedule introduced later in the reconstruction loss?\n\n2. What is the rationale for applying Gaussian reparameterization before spherical projection rather than directly learning vMF-distributed embeddings on the hypersphere? Does this projection affect the statistical validity of the Product-of-Experts aggregation, or introduce bias in the latent density estimation?\n\n3. Would an alternative that keeps the entire latent process on the hypersphere (e.g., sampling on \\(S^{d-1}\\) with geodesic or Riemannian noise) yield a cleaner theoretical foundation and comparable empirical results? If so, how might this change the training dynamics or stability?\n\n4. Regarding the spherical uniformity loss, could the authors discuss its interaction with the clustering objective? Does the uniform prior discourage the formation of compact clusters, and have the authors explored hyperbolic or mixed-curvature variants to better capture hierarchical community structures?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "vNWAiJzQS2", "forum": "hNLy3TRZyH", "replyto": "hNLy3TRZyH", "signatures": ["ICLR.cc/2026/Conference/Submission23295/Reviewer_ZYX9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23295/Reviewer_ZYX9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23295/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761755234437, "cdate": 1761755234437, "tmdate": 1762942593803, "mdate": 1762942593803, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the unsupervised graph clustering problem, a fundamental task in the machine learning community. It proposes a novel framework called Hyperspherical Contrastive Diffusion (HCD), which jointly leverages hyperspherical geometry and diffusion-based generative modeling for unsupervised graph clustering. The method introduces a multi-step temporal denoising diffusion process and a Product-of-Experts (PoE) aggregation strategy, trained via a multi-objective loss function encompassing diffusion reconstruction loss, uniformity loss, spherical contrastive alignment loss, and cluster regularization loss. Experimental results on multiple canonical graph benchmarks (e.g., OGB datasets, ACM) and clinically realistic spatial-omics datasets (e.g., STARmap, BRCA) demonstrate state-of-the-art performance across key metrics. Overall, the paper presents an interesting approach with compelling empirical results."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper introduces a novel graph clustering method leveraging hyperspherical diffusion, effectively addressing the limitations of Euclidean-space latent representations and the reliance on heuristic graph augmentations in existing approaches. \n\n2. The paper presents extensive experimental evaluations across diverse datasets, covering large-scale OGB graphs, canonical benchmarks, and clinical spatial transcriptomics datasets. It compares against over 15 state-of-the-art baselines and incorporates detailed ablation studies, showing the method’s effectiveness.\n\n3. The paper is well-structured and clearly presented. It attempts to mathematically formalize key mechanisms, including the Angular Separation Lower Bound and the PoE aggregation principle."}, "weaknesses": {"value": "1. The paper does not elaborate on the fundamental rationale behind the effectiveness of latent-space diffusion for graph clustering. While it describes the technical implementation (noise scheduling, sampling, and aggregation), it lacks a clear analysis of why diffusing in the latent space—rather than on raw graph data (adjacency/features)—better preserves structural information and enhances clustering discriminability. Key questions remain unaddressed: How does latent diffusion mitigate over-smoothing compared to diffusion on raw data? What properties of graph-structured data make latent-space diffusion more suitable for capturing community structures? Without this theoretical grounding, the design choice feels underjustified.\n\n2. The paper focuses exclusively on graph clustering but provides no insight into whether its proposed diffusion fusion mechanism can be extended to non-graph data (e.g., images, tabular data). Given that diffusion models are widely applied across data modalities, a brief discussion of potential adaptations or inherent limitations would enhance the work’s broader significance. \n\n3. While the paper mentions computational complexity in the appendix, it lacks a systematic comparison of runtime and memory overhead against SOTA baselines, which is critical for large-scale graph applications. For example, HCD’s T-step diffusion and PoE aggregation introduce non-trivial overhead, but the paper does not quantify how this scales with increasing graph size or latent dimension. Additionally, there is no discussion of optimization strategies (e.g., sparse diffusion, early stopping for T) to mitigate this overhead, which limits practical adoption for resource-constrained scenarios.\n\n4. The paper ablates core components (vMF, contrastive loss), it does not isolate the contribution of learnable temporal weights ($γ_t$) in PoE aggregation. The current analysis conflates PoE’s inverse-variance fusion with $γ_t$’s temporal attention, making it unclear whether $γ_t$  adds meaningful value beyond fixed-weight precision fusion. A targeted ablation, e.g., comparing PoE with fixed $w_t=1/T$ vs. learnable $γ_t$) would strengthen the justification for this design choice.\n\n5. While the paper briefly touches on edge sparsification and feature noise, the noise robustness evaluation is narrow and underdeveloped. It fails to test against realistic, complex noise types common in graph data, such as structural noise and heterogeneous feature noise."}, "questions": {"value": "1. How does the proposed method generalize to non-graph data?\n\n2. How to estimate the number of clusters in practice?\n\n3. The method involves many hyperparameters，how are the multiple loss terms balanced?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "47GFbEBdpo", "forum": "hNLy3TRZyH", "replyto": "hNLy3TRZyH", "signatures": ["ICLR.cc/2026/Conference/Submission23295/Reviewer_s9Ky"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23295/Reviewer_s9Ky"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23295/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931219386, "cdate": 1761931219386, "tmdate": 1762942593620, "mdate": 1762942593620, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Hyperspherical Contrastive Diffusion (HCD) — an unsupervised graph-clustering framework that (i) constrains node embeddings to the unit hypersphere, (ii) encodes nodes via a multi-step temporal variational diffusion encoder whose timestep Gaussians are fused by a Product-of-Experts (PoE) inverse-variance aggregation, and (iii) sculpts the hyperspherical latent space via a combination of losses: a diffusion reconstruction loss, a von Mises–Fisher (vMF) KL “uniformity” regularizer, a spherical contrastive alignment loss (angular margin), and a Student-t based compactness/separation regularizer with entropy penalty. The learned hyperspherical embeddings are clustered by fitting a vMF mixture model. The paper evaluates HCD on large OGB graphs, medium benchmarks (ACM/DBLP/Wiki), and spatial-transcriptomics tissue datasets (STARmap, DLPFC, BRCA), reporting consistent improvements and an extensive ablation study."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1) Clear, well-motivated design that mixes geometry and generative modeling.\n\n2) Strong empirical gains across diverse datasets. HCD reports consistent wins on large OGB graphs (ogbn-arxiv, ogbn-products), medium benchmarks (ACM/DBLP/Wiki), and biologically meaningful spatial transcriptomics datasets (STARmap, DLPFC, BRCA), with quantitative tables and qualitative visualizations showing improved ARI/AMI/ACC.\n\n3) Reproducibility-oriented appendix and source code\n\n4) Thorough ablation and sensitivity analysis. The authors performed component ablations (removing vMF uniformity, spherical contrast, cluster regularizer, entropy term), diffusion depth/aggregation sweeps, hyperparameter sensitivity for contrastive terms, robustness tests under edge/feature corruption, and cluster-count stability. These ablations support the assertion that each component contributes to final performance"}, "weaknesses": {"value": "1) Compute vs. accuracy tradeoffs need more prominence. Appendix Table A7 shows per-epoch runtimes (HCD is slower per epoch than some baselines, e.g., HCD 47s vs CVGAE 36s on ogbn-arxiv; HCD 145s vs CVGAE 117s on ogbn-products). The manuscript claims an accuracy/efficiency tradeoff but does not show end-to-end wall-clock to target-metric comparisons (e.g., time-to-converged-ACC or GPU hours to reach a given ARI).\n\n2) For the spatial transcriptomics datasets, results are convincing visually and by ARI/AMI. However, domain experts often value biological markers or downstream validation (marker-gene enrichment, spatial continuity measures)."}, "questions": {"value": "1) Are there graphs or regimes where HCD performs worse than a simple GAE or contrastive method?\n\n2) Which single (or several) hyperparameter (if any) most strongly influences final ARI on OGBN-ARXIV?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "7yrA7W1CQC", "forum": "hNLy3TRZyH", "replyto": "hNLy3TRZyH", "signatures": ["ICLR.cc/2026/Conference/Submission23295/Reviewer_ttty"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23295/Reviewer_ttty"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23295/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978050810, "cdate": 1761978050810, "tmdate": 1762942593452, "mdate": 1762942593452, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}