{"id": "TPXVdBjrvU", "number": 8738, "cdate": 1758096603426, "mdate": 1759897766407, "content": {"title": "Efficient On-Device Agents via Adaptive Context Management", "abstract": "On-device AI agents offer the potential for personalized, low-latency assistance, but their deployment is fundamentally constrained by limited memory capacity, which restricts usable context. This reduced practical context window creates a trade-off between supporting rich, stateful interactions with complex tool capabilities and maintaining on-device feasibility. We break this trade-off with a framework for context-efficient on-device agents, driven by three synergistic optimizations (1) a dynamic memory system using specialized LoRA adapters to distill conversational history into a compressed, and structured Context State Object; (2) a minimalist serialization format for tool schemas to minimize token overhead per tool; and (3) a just-in-time schema-passing mechanism that loads full tool definitions only upon tool selection. We realize this framework by adapting a 3B parameter SLM to context-efficient trajectories and rigorously evaluate it against a conventional baseline on complex user tasks. Our agent matches, or exceeds, the performance of a conventional baseline while dramatically compressing context, achieving more than a 6-fold reduction in initial system prompt context and a 10- to 25-fold reduction in context growth rate based on the interaction verbosity, demonstrating that strategic context management is key to unlocking capable and persistent on-device AI.", "tldr": "We present a framework for on-device, resource-constrained agent deployments that mitigates context bloat from both tool schemas and agent–environment interactions, yielding lower token costs and improved task performance.", "keywords": ["Context management", "On-device ML", "Agents", "Key–value (KV) cache", "Token efficiency"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/79d13e5b1f25fe7172b32745ea465ff5abe702e7.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel framework for on-device agents, focusing on the scalability issue regarding tool usage. Within the framework, the agent handles the requests from the users in two stages: orchestration and context management, which is backed up by a specially fine-tuned LoRA adapter. Benefiting from the design and fine-tuning, the agents exhibit effectiveness in the evaluation tasks and demonstrate desired traits, such as reduced history log, often functioning as a bottleneck in the long term. The authors also present a detailed analysis of the architectural designs."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The strengths of this paper are as follows:\n1. Framework design: The proposed framework is well-thought-out. Each choice of the framework is well supported with reasonable observations/insights. Especially, the choices are highly technically detailed at the low level, while the appropriateness remains clear at the high level. \n2. Balanced metric: The authors combine various metrics to examine the efficacy of the proposed method. The combination of precision (i.e., rule-based) and LLM-as-judge (i.e., model-based) provides a synergy for examining the agents more rigorously.\n3. Analysis: The experiments are studied extensively. The authors provide detailed explanations of the results with rationalizations of such results in the view of agents’ behaviors. The detailed study on the architectural trade-off is also noticeable."}, "weaknesses": {"value": "The weaknesses/questions/suggestions of this paper are as follows:\n1. Reference: There are missing parts of the Appendix that are referenced in the main text (e.g., Appendix A.5 & A.6).\n2. Tasks:\n\t- In the line 827-828 (Appendix A.2.6): does this mean that prior benchmarks are ill-posed, or the framework is designed in a wrong manner? The “our models will not work” part sounds very unconvincing. Would there be any method to adapt the existing framework (e.g., changing the context part with some special module with a subset of problems of the existing benchmark)? \n\t- While the authors claim that simulated users present reality, the claim is not supported enough. I request the authors to elaborate on the simulated \nusers.\n\t- (Minor) Why do the authors restrict the use of tools in conversational tasks? My interpretation is that the agents might use the tool for more natural conversation (e.g., exploring notes to understand users better).\n3. Baselines: I believe that more baselines using other methods are in demand. (If more baselines are not applicable, please justify why.) The presented baselines are mostly ablation studies, rather than comparisons with other methods, hindering judgment on the superiority of the proposed methods over other approaches. Especially, because there is a large gap between xLAM-2 3B and Baseline, but marginal differences between from Baselines to Combined, judging the effectiveness of the proposed method is highly difficult.\n\nOverall, I believe that the paper has a strong framework design, while the results are relatively weak to support its superiority. I believe that this can also be resolved by adding more tasks, which is less appealing compared to adding more baselines."}, "questions": {"value": "(See above)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "RGgqWywnmz", "forum": "TPXVdBjrvU", "replyto": "TPXVdBjrvU", "signatures": ["ICLR.cc/2026/Conference/Submission8738/Reviewer_CQ3w"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8738/Reviewer_CQ3w"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8738/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761879521656, "cdate": 1761879521656, "tmdate": 1762920532220, "mdate": 1762920532220, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of limited memory in device-based systems with context-efficient on-device agents. It not only reduces context overhead but also maintains performance on complex tasks. The framework introduced dual LoRA adapters tos compress conversational history into a structured, append-only logs thus significantly reduces context growth. Further improvements minimizes initial prompt size by using a minimalist schema format and a just-in-time mechanism to load full tool definitions only when needed."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Novel Context Management: The CSO system effectively balances memory efficiency and task fidelity by leveraging structured logging and semantic compression. This addresses the critical bottleneck of long-context degradation in on-device settings.\n- Practical Tool Optimization: The minimalist schema format and JIT mechanism drastically reduce initial token overhead, enabling agents to handle more tools within constrained memory budgets.\n- Strong Empirical Results: The experiments show significant improvements in context efficiency without sacrificing performance on complex tasks like multi-tool orchestration and cloud delegation."}, "weaknesses": {"value": "- The experiment is conducted on a 3B-parameter xLAM 2. While a brief test on Qwen-3 4B suggests scalability, the results may not extend to other architectures or larger models without retraining.\n- The JIT schema-passing mechanism introduces 500ms latency per turn for the CSO update cycle on a Galaxy S25 CPU, which would  increase latency in time-sensitive applications.\n- While the paper provides detailed methodology, it is still difficult for researchers to reproduce it and it would be better for authors to add an additional code repository."}, "questions": {"value": "Please see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "IDI1UcFxQO", "forum": "TPXVdBjrvU", "replyto": "TPXVdBjrvU", "signatures": ["ICLR.cc/2026/Conference/Submission8738/Reviewer_FUyE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8738/Reviewer_FUyE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8738/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761891299077, "cdate": 1761891299077, "tmdate": 1762920531832, "mdate": 1762920531832, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the context compression for on-device AI agents by proposing a framework with three components: (1) a dual-adapter memory system where one LoRA adapter handles tasks while another compresses conversation history into an append-only CSO in key-value format, (2) a token-efficient tool schema format, and (3) a JIT tool loading mechanism that initially presents only tool names/descriptions and loads full schemas only after selection. Experiment results show the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Context constraints on resource-limited devices are a genuine deployment bottleneck overlooked by long-context research.\n2. The paper is well written and easy to follow.\n3. Empirical results show the proposed method achieves 10-25× context reduction with maintained or improved performance."}, "weaknesses": {"value": "1. **Limited Novelty in Context Compression**: Context compression is a mature field with extensive prior work. The proposed Context State Object is essentially task-specific summarization in key-value format, not a fundamentally new compression paradigm. The dual-adapter architecture uses standard techniques. The paper needs to better clarify what makes this approach fundamentally different from applying existing summarization methods to agent conversations, as the primary contribution appears to be system-level engineering rather than methodological innovation.\n2. **Insufficient Baseline Comparisons**: The paper lacks comparisons with established context management methods. Without these baselines, it's unclear whether efficiency gains stem from CSO's specific design or simply from having any compression mechanism. The custom evaluation protocol further limits comparability with prior work.\n3. **Unvalidated LLM-as-Judge**: The qualitative evaluation relies on Gemini 2.0 Flash without reliability validation. The paper provides no human agreement analysis, calibration study, or bias assessment. Given significant score variations across models, it remains unclear whether these differences reflect actual quality gaps or judgment artifacts."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cxCNNWtGcM", "forum": "TPXVdBjrvU", "replyto": "TPXVdBjrvU", "signatures": ["ICLR.cc/2026/Conference/Submission8738/Reviewer_fuCP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8738/Reviewer_fuCP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8738/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923115887, "cdate": 1761923115887, "tmdate": 1762920531510, "mdate": 1762920531510, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper present an engineering solution for managing the context of on-device agents, which is a critical challenge given the limited memory to hold the context on device. The proposed method mainly focus on summarizing tool execution context and tracing the dialog state. Results verify the methods’ effectiveness and efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper studies a practical scenarios and can be helpful for the deployment of llm. \n2. The proposed method is simple and easy to understanding while being effective."}, "weaknesses": {"value": "1. The technical contribution might be minor. The author lacks a comprehensive discussion on existing method and their limitations. Therefore, It is hard to justify the novelty of the proposed method.\n2. The author only compares their method to few baselines on a self-curated datasets, which is a weak evaluation.\n3. Although the author study on-device memory management, no specific memory parameters and computation resources available for a number of representative devices are provided. Therefore, it is hard to understand whether the proposed method satisfy the practical needs."}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2Dq82qvpDE", "forum": "TPXVdBjrvU", "replyto": "TPXVdBjrvU", "signatures": ["ICLR.cc/2026/Conference/Submission8738/Reviewer_dzNG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8738/Reviewer_dzNG"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8738/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761985052653, "cdate": 1761985052653, "tmdate": 1762920531164, "mdate": 1762920531164, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}