{"id": "ghcnO9J9PI", "number": 1483, "cdate": 1756886360227, "mdate": 1759898206761, "content": {"title": "QuantDemoire: Quantization with Outlier Aware for Image Demoiréing", "abstract": "Demoiréing aims to remove moiré artifacts that often occur in images. While recent deep learning–based methods have achieved promising results, they typically require substantial computational resources, limiting their deployment on edge devices. Model quantization offers a compelling solution with its advantages of compactness and efficiency. However, directly applying existing quantization methods to demoiréing models introduces severe performance degradation. The main reasons are distribution outliers and weakened representations in smooth regions. To address these issues, we propose QuantDemoire, a post-training quantization framework tailored to demoiréing. It contains two key components. **First**, we introduce an outlier-aware quantizer to reduce errors from outliers. It uses sampling-based range estimation to reduce activation outliers, and keeps a few extreme weights in FP16 with negligible cost. **Second**, we design a frequency-aware calibration strategy. It emphasizes low- and mid-frequency components during fine-tuning, which mitigates banding artifacts caused by low-bit quantization. Extensive experiments validate that our QuantDemoire achieves large reductions in parameters and computation while maintaining quality. Meanwhile, it outperforms existing quantization methods by over **4 dB** on W4A4. Code will be released.", "tldr": "", "keywords": ["Quantization", "Image-Demoir\\backslash’eing"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0da9bbc8cd17ea37d6d0c553c8763d341aeba6d9.pdf", "supplementary_material": "/attachment/0642953bb8f60401562c3b808bc2deaa08e30b2d.zip"}, "replies": [{"content": {"summary": {"value": "The authors aim to improve quantization for ML-based demoireing methods on the edge. Their method consists of three components:\n1. setting the activation quantizer grid through a minmax of a *sample* of the activations (thereby reducing the quantization range, as some outliers may not be sampled),\n2. keeping the worst outlier entries of the weights in Float16,\n3. calibrating the activation quantization boundaries (i.e. clipping) based on some \"frequency-aware\" reconstruction loss"}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The authors address a real-world application, demoireing on the edge.\n2. The ablations are quite extensive (but see my questions)\n3. The results suggest the method performs favorably compared to existing works."}, "weaknesses": {"value": "**1. Method**\n\nUnfortunately, at this point I do not recommend acceptance. I believe there are a few issues with the method that I urge the authors to seriously consider:\n\n**a. Activation Quantization**. The idea behind Eq. 6, randomly sampling activation entries to avoid outliers, is not effective---despite the authors' claim \"the proposed method effectively captures the typical distribution of activations\" and \"[this means we] naturally discard extreme outliers\". Just subsampling the entries does not change the distribution that is sampled from, it only changes the number of samples that is used for estimating the max value. Moreover, there is a large variance in this procedure---sometimes bad outliers may be sampled, and sometimes not. For example, it is not clear why Figure 3 right should be preferred---the real outliers are actually worse here. It would be much better in my opinion to compute e.g. the 95% quantiles for setting the range---this is not cheap, but even an approximation would suffice (e.g. `x>mean+std*some_constant`). It would be even better to learn how much to clip on some calibration data, which doesn't need to be expensive.\n\n**b. Weight quantization**. The mixed-precision scheme makes sense, but because the mixed-precision is completely unstructured, the matmul would not be parallelizable (e.g. not run on GPU/TPU/NPU). The authors do not address this. Using mixed-precision for weights is also not new, so in any case this cannot really be claimed as a contribution. \n\n**c. Calibration stage**. The authors' use of \"quantization boundary optimization\" (Section 3.3) is not clear to me. In 3.2, they propose the sampled activation quantizer approach, but now they say they optimize the boundary anyway.\n\n\n**2. Results**\n\n**a. stds**. The ablations do not have standard deviations. I assume these experiments are quite cheap, and hence std's would be feasible. They are valuable, because the sampling strategy of the activation quantization clearly has a high variance. The calibration approach also has some non-ignorable noise.\n\n**b. Compression Ratio**. What do you mean with OPS? I assume the number of ops is the same (or slightly higher), but that the ops are cheaper in low-bit. In any case, these results should in my opinion be compared to Bfloat16, not Float32. Additionally, the effect of switching from INT to Float for some weight indices should not be underestimated and is not addressed by these results.\n\n**c. Experimental details**. More experimental details would be desirable, see my two questions below.\n\n\n## Minor\n\n> [L.136] Although QAT achieves competitive performance (Nagel et al., 2021), its high training cost makes\nit less suitable for deployment on edge devices.\n\nSince training does not happen on the edge, this argument does not hold.\n\n> [L. 213] Some existing post-training quantization methods (such as percentile (Li et al., 2019)) are specifically\ndesigned to address the problems caused by outliers. However, these methods could lead to some\nadditional time overhead during the calibration stage. At the same time, because of their inflexible\ndesign, these methods may lack robustness facing outliers in different distributions.\n\nThis could be explained better. Again it seems to me that calibration can happen not on the edge, so this is no issue. It is also not clear what is meant by the last sentence, \"may lack robustness [due to their \"inflexible design\"]\""}, "questions": {"value": "1. Do all ablations use calibration of activation boundaries? E.g. also the \"Original\" and \"Smooth (Raw)\" baselines?\n\n2. Can you explain why the percentile approach performs worse than your sampled approach?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YbmKB7npIk", "forum": "ghcnO9J9PI", "replyto": "ghcnO9J9PI", "signatures": ["ICLR.cc/2026/Conference/Submission1483/Reviewer_H9oE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1483/Reviewer_H9oE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1483/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760456012193, "cdate": 1760456012193, "tmdate": 1762915782684, "mdate": 1762915782684, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces QuantDemoire: a post training quantization methodology designed specifically for the quantization of Image Demoiréing models. The methodology consist of an alternative sample-base range-setting methodology, which preserves a small percentage of weights in high precision, and a calibration method focused on preserving low and medium frequencies of the model output. An empirical evaluation demonstrates the effectiveness of the proposed methodology in extreme quantization settings, by comparing QuantDemoire against recent approaches developed in the context of image generation quantization literature."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The paper introduces a novel method for effectively quantizing demoreing models, which is a novel application. The paper compares the demoreing performance against strong baselines used in Diffusion Transformer quantization. \n\n* Overall, the paper does a good job in describing all the components. The methodology section is overall quite simple and clear."}, "weaknesses": {"value": "* Recent edge devices can handle models of up to a few billion parameters (fp16/bf16) hence it should be possible to deploy models consisting of million of parameters without aggressive quantization. The motivation is not entirely obvious from reading sections 1 and 2. \n\n* The sampling procedure described in section 3.2 seems like a high-variance estimate of the k-th percentile. However, the two methods are not compared theoretically, and the setting used for the empirical comparison are unclear. The computational cost of estimating distribution statistics is usually negligible since the calibration phase needs to be performed only once and yields lower variance estimate than the proposed sampling approach. Variance estimations are not reported in the experimental results in Table 1a. \n\n* Figure 4 is difficult to read because of the low density of the distribution tails. Please consider using a logarithmic scale."}, "questions": {"value": "1. Can the authors elaborate on the statement “[edge devices] are also the most important application scenarios [for image demoiréing]” ? Although the relevance of the task is clear, this statement does not seem entirely obvious. Deploying models consisting of millions of parameters on the edge with recent hardware should also be possible without aggressive quantization. What is the ideal use case of QuantDemoire? \n\n2. What hyper-parameter ranges are compared to produce the results reported in Table 1a? What is the variance on the proposed sampling methodology when compared to the baseline? Can the authors further comment on the advantages of sampling vs percentile-based range-setting?\n\n3. The paper proposes to keep the weight outliers in full precision instead of clipping them. Can the authors quantify the overhead introduced by $W_{outlier}$ matmul in terms of memory and latency? Is the bit width substantially lower than a less-aggressive quantization scheme (e.g. 5 bits) ? How is the sparse matmul performed efficiently? \n\n4. What is the effect of the two terms $\\mathcal{L}_1$ and $\\mathcal{L}_p$ on the loss? Is there a tunable weighting factor? I suspect that, due to the different number of dimensions the two terms might have a different scale."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Ayo6RBh0RO", "forum": "ghcnO9J9PI", "replyto": "ghcnO9J9PI", "signatures": ["ICLR.cc/2026/Conference/Submission1483/Reviewer_FcUX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1483/Reviewer_FcUX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1483/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761320073971, "cdate": 1761320073971, "tmdate": 1762915782316, "mdate": 1762915782316, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Image demoireing is an important vision task especially for edge devices such as smartphones, drones, and portable cameras.\nThus, model quantization is necessary to utilize high performance demoireing models in practical applications.\nExisting quantization methods are not focused on demoireing so that they 1) overlook outliers in weights and activations, and 2) weaken representations in smooth regions, resulting in a huge performance loss.\nQuantDemoire removes activation outliers through random sampling and keeps extreme weights in FP to mitigate the impact of outliers.\nIt also extracts mid- and low-frequency information by a recursive kernel to train the quantized model to preserve low-frequency features well.\nExtensive experiments show that QuantDemoire outperforms existing methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The work successfully identifies and addresses the frequency-related issue that is unique to the demoireing task.\n* Effectively extracting low-frequency features through a simple convolution kernel.\n* QuantDemoire achieves the state-of-the-art performance."}, "weaknesses": {"value": "* Smoothing and clipping approach of outlier-aware quantizer strongly resembles existing methods such as OmniQuant [1].\n* Preserving outliers in full-precision also resembles existing methods such as LLMint8 [2].\n* Preserving arbitrary weight parameters in FP would induce computation inefficiencies because of hardware-unfriendly structure [3].\n* From the ablation results in Table 3, the effect of frequency-aware calibration appears to be marginal.\n\n[1] Shao, Wenqi, et al. \"OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models.\" The Twelfth International Conference on Learning Representations.\n\n[2] Dettmers, Tim, et al. \"Gpt3. int8 (): 8-bit matrix multiplication for transformers at scale.\" Advances in neural information processing systems 35 (2022): 30318-30332.\n\n[3] Lin, Ji, et al. \"Awq: Activation-aware weight quantization for on-device llm compression and acceleration.\" Proceedings of machine learning and systems 6 (2024): 87-100."}, "questions": {"value": "* Does sampling-based quantization occur online during inference or are scaling factors pre-computed during calibration?\n* If it occurs online, how does it affect on throughput?\nIn my understanding, strength of smoothing based approach is that the smoothing factor is fused into weight so that the inference cost remains the same.\nIs outlier-aware quantizer better than other online outlier-handling approaches such as OCS even without fusing?\n* Could you further review related work and clarify how the proposed outlier-aware quantizer differs from existing methods?\n* Could you provide additional ablation results under more diverse settings, such as different datasets or bit-widths?\n* Does applying and training multiple kernels not lead to higher training cost or longer training time?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "swuwHTLIVc", "forum": "ghcnO9J9PI", "replyto": "ghcnO9J9PI", "signatures": ["ICLR.cc/2026/Conference/Submission1483/Reviewer_piwj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1483/Reviewer_piwj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1483/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761817458942, "cdate": 1761817458942, "tmdate": 1762915781664, "mdate": 1762915781664, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}