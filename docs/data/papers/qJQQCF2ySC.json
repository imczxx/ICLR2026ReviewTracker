{"id": "qJQQCF2ySC", "number": 22408, "cdate": 1758330662322, "mdate": 1763622071363, "content": {"title": "LAMP: Data-Efficient Linear Affine Weight-Space Models for Parameter-Controlled 3D Shape Generation and Extrapolation", "abstract": "Generating high-fidelity 3D geometries that satisfy specific parameter constraints has broad applications in design and engineering. However, current methods typically rely on large training datasets and struggle with controllability and generalization beyond the training distributions. To overcome these limitations, we introduce LAMP (Linear Affine Mixing of Parametric shapes), a data-efficient framework for controllable and interpretable 3D generation. LAMP first aligns signed distance function (SDF) decoders by overfitting each exemplar from a shared initialization, then synthesizes new geometries by solving a parameter-constrained mixing problem in the aligned weight space. To ensure robustness, we further propose a safety metric that detects geometry validity via linearity mismatch. We evaluate LAMP on two 3D parametric benchmarks: DrivAerNet++ and BlendedNet. We found that LAMP enables (i) controlled interpolation within bounds with as few as 100 samples, (ii) safe extrapolation by up to 100\\% parameter difference beyond training ranges, (iii) physics performance-guided optimization under fixed parameters. LAMP significantly outperforms conditional autoencoder and Deep Network Interpolation (DNI) baselines in both extrapolation and data efficiency. Our results demonstrate that LAMP advances controllable, data-efficient, and safe 3D generation for design exploration, dataset generation, and performance-driven optimization.", "tldr": "", "keywords": ["3D Shape Generation", "Parametric Control", "Data Efficient Learning", "Engineering Design"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/81cb23ff985e1ad5d7c5c3b04e3b91c6eaa743af.pdf", "supplementary_material": "/attachment/10950a212a8ef34f032602d0ac65c6a9dfd3210d.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a 3D shape generation method that aims to produce shapes that respect certain parameter constraints.\nThis is implemented by computing an affine combination of parameter vectors of known shapes under the given constraints.\nThe shape is then generated by using the same weights to combine the weights of neural SDF representations of the corresponding known shapes.\nTo check the validity of the generated shape, a linearity-mismatch metric is proposed.\n\nThus, the contribution of this paper is a new method for controlled interpolation and extrapolation of a limited set of shapes.\nExperiments show that the proposed method can generate shapes that respect the given constraints, and that the linearity-mismatch metric correlates well with the quality of the generated shapes."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The strength of this paper lies in the novel idea of combining parameter vectors and neural SDF weights to generate new shapes under given constraints.\n\nThe method offers some much-needed fine-grained control over the generated shapes.\nFurthermore, the proposed method does not rely on large datasets or compute for training.\n\nThe method is conceptually simple and easy to implement, and the experiments demonstrate that the affine combination weights derived from the parameter vectors can (perhaps somewhat surprisingly) be effectively used to generate new shapes that respect the constraints.\n\nOverall the paper is well-written and clearly presents the proposed method and experimental results."}, "weaknesses": {"value": "One weakness of the paper is that the linearity of the SDF weights is only reasonable for very similar weights.\nThis limits the variability of the generated shapes.\n\nFurthermore, it is not clear to me how sensitive the method is to the choice and number of known shapes.\nIf the known shapes do not cover the parameter space well, it is unclear how well the method performs.\n\nOn a more minor note Table 1 does not seem to be referenced in the text."}, "questions": {"value": "* How are the set of known shapes selected for a given set of parameter constraints?\n* How sensitive is the method to the choice and number of known shapes?\n* Does the method require the SDF networks to be trained in a specific way?\n* Would incorporating the linearity-mismatch metric into equation (1) as a regularization term improve the quality of the generated shapes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Mp0ipBeVqE", "forum": "qJQQCF2ySC", "replyto": "qJQQCF2ySC", "signatures": ["ICLR.cc/2026/Conference/Submission22408/Reviewer_CbJm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22408/Reviewer_CbJm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22408/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761223328238, "cdate": 1761223328238, "tmdate": 1762942207534, "mdate": 1762942207534, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes a framework for generating new 3D shapes given a set of physical parameters. The key idea is to first fit an SDF-based decoder (similar to DeepSDF) for each training shape, using a dataset of shapes with annotated physical parameters. To generate a shape with target parameters, the method creates an affine combination of decoder network weights, mixed according to the parameters of the training set. The resulting network weight is then used to decode the mesh. Experimental results on DrivAerNet++ and BlendedNet show that the framework achieves better prediction accuracy for interpolation and better generalization for extrapolation. Additionally, a safety metric is proposed to avoid invalid generation results, and an application for drag reduction demonstrates effectiveness for aerodynamic optimization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- To my knowledge, existing work mainly focuses on generating network weights or latents, such as HyperDiffusion. The idea of interpolating network weights with shared initialization to obtain new generation results is both interesting and novel.\n- Despite its simplicity, the experimental results demonstrate that the framework achieves better performance on both DrivAerNet++ and BlendedNet datasets for interpolation and extrapolation. The framework also enables aerodynamic optimization and achieves better optimization results than the baseline.\n- The proposed safety metric is shown to be effective both quantitatively and qualitatively in Figures 5 and 17–18."}, "weaknesses": {"value": "The current manuscript has some minor concerns:\n\n- This work assumes generated 3D shapes are produced from an affine transformation of the input shapes (Theorem A(1)). The proposed framework is unlikely to work on datasets with heterogeneous topologies. It is recommended to discuss this assumption and limitation.\n- Theorem A(2) assumes that if the weight difference from initialization is small enough, the obtained mixed SDFs will be close to a linear combination of the original SDFs. While this sounds reasonable theoretically, an ablation study would help justify the necessity of using a shared initialization."}, "questions": {"value": "- Could the proposed framework work on datasets with heterogeneous topologies (e.g., shapes with varying numbers of holes or disconnected components)? If not, could you expand the discussion on this limitation and clarify the scope of applicability?\n- Could you provide an ablation study comparing the performance of LAMP with and without shared initialization? This would help justify the necessity of the shared initialization assumption stated in Theorem A(2)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6RlOzc4CdZ", "forum": "qJQQCF2ySC", "replyto": "qJQQCF2ySC", "signatures": ["ICLR.cc/2026/Conference/Submission22408/Reviewer_BDet"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22408/Reviewer_BDet"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22408/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761877549383, "cdate": 1761877549383, "tmdate": 1762942207290, "mdate": 1762942207290, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes LAMP, a data efficient linear affine weight space model for 3D shape generation and interpolation/extrapolation that supports parameter control. Data scarcity is a major practical challenge, especially for engineering designs. The method is overall plausible and the paper shows extensive evaluation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The proposed method provides a data-efficient framework for parameter-controlled 3D mesh generation.\n\nThe paper demonstrates the effectiveness of the method on some benchmark datasets."}, "weaknesses": {"value": "Although the safety metric is shown to be effective for the test case (when compared with human judgement), it lacks theoretical guarantee why a simple threshold is sufficient.\n\nThe paper should discuss limitations/failure cases more clearly.\n\nThe process from SDF to mesh may lead to changing mesh connectivity even when the parameters only change by a small amount."}, "questions": {"value": "How do the parameter constraints work in practice, especially when some constraints may have conflict to be satisfied at the same time?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "969V0t3SJc", "forum": "qJQQCF2ySC", "replyto": "qJQQCF2ySC", "signatures": ["ICLR.cc/2026/Conference/Submission22408/Reviewer_GHuJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22408/Reviewer_GHuJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22408/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762305196718, "cdate": 1762305196718, "tmdate": 1762942206892, "mdate": 1762942206892, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes LAMP, a data-efficient framework for parameter-controlled 3D mesh generation. The method employs affine mixing in the weight space of neural signed distance function (SDF) decoders to construct a generative model. Each exemplar shape in a small-scale dataset is fitted with an individually overfitted SDF decoder. For novel shape synthesis, mixing coefficients satisfying target parameter constraints are solved and then applied to linearly combine the exemplar decoders' weights. A linearity mismatch metric is introduced to detect and filter invalid geometries."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-written, with clear and coherent presentation.\n2. LAMP enables precise parameter-controlled generation with limited training data."}, "weaknesses": {"value": "1. For each example, is the weight w the flattened vector of all parameters of its trained SDF network? What is the dimensionality D of w? Storing such large vectors per example may impose substantial storage costs—how does the method scale as the dataset grows?\n2. Training a separate SDF network per example could be time-consuming. Could you report the overall training cost and per-example training time, and compare both training and inference time against the baseline methods.\n3. The selection of baseline methods appears limited, with only two relatively early works (from 2019 and 2021). Could the authors clarify why these particular baselines were chosen instead of more recent ones? Would it be possible to include comparisons with newer approaches, such as modern conditional diffusion models fine-tuned on similarly small datasets?\n4. Can the proposed method be integrated with recent SOTA 3D generative models? If not, does this limit its practical applicability or generalization potential?\n5. Can the two linear assumptions proposed in the paper be supported by concrete feature data?\n6. The provided code lacks the filtered_drivaernet_small.csv file and possibly the required mesh files, making it currently impossible to run. Why were these not included in the supplementary materials? Their absence may affect the transparency and reproducibility of the work."}, "questions": {"value": "Please refer to weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uzVgtjAmk2", "forum": "qJQQCF2ySC", "replyto": "qJQQCF2ySC", "signatures": ["ICLR.cc/2026/Conference/Submission22408/Reviewer_MKVD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22408/Reviewer_MKVD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22408/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762335707538, "cdate": 1762335707538, "tmdate": 1762942206676, "mdate": 1762942206676, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes LAMP (Linear Affine Mixing of Parametric shapes), a framework for data-efficient and controllable 3D mesh generation. Instead of training a single large model, LAMP aligns a small number of SDF (Signed Distance Function) decoders—each overfitted to one exemplar—into a shared weight space, and generates new geometries by solving a parameter-constrained affine mixing problem over these aligned weights. The paper introduces a linearity-mismatch safety metric to detect invalid extrapolations and demonstrates applications on two 3D design benchmarks (DrivAerNet++ and BlendedNet). Experimental results show improved interpolation, safe extrapolation, and physics-guided optimization with limited data compared to AE-LPA and Deep Network Interpolation (DNI)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Data-efficient and interpretable approach for parameter-controlled 3D generation. Clear problem motivation in engineering design, emphasizing low-data and extrapolation regimes. Practical safety check (linearity mismatch) that can identify unstable generations without ground truth. Demonstrates reasonable quantitative and visual improvements over strong baselines (DNI, AE-LPA). Readable and systematic experimental section, showing controlled interpolation, extrapolation, and performance optimization."}, "weaknesses": {"value": "The main weakness of this paper lies in its limited conceptual novelty. The core idea of affine weight mixing closely follows earlier works like Deep Network Interpolation (DNI) and model interpolation methods, without introducing much theoretical advancement. The key assumptions behind the approach, especially (A1) and (A2), feel heuristic and are never really tested beyond small, local cases—there’s no solid evidence that SDF weights behave linearly when pushed far beyond the training range. The proposed safety metric is interesting but remains entirely empirical, with no proof or deeper justification linking linearity mismatch to actual geometric validity. Overall, the paper leans heavily on engineering experiments rather than theoretical grounding or broader applicability. It doesn’t discuss failure cases, scalability to more complex architectures, or how the method might fit into real-world design systems. Finally, the comparison set feels a bit dated—modern 3D diffusion or generative models like SDFusion, GET3D, or LION aren’t seriously considered, which weakens the broader relevance of the results."}, "questions": {"value": "How sensitive is the method to the choice of initialization during SDF overfitting? Would random seeds break alignment?\nCould the authors quantitatively evaluate the linearity assumption (A2) by plotting true vs. predicted SDF outputs under linear weight interpolation?\nCould this framework be extended to diffusion-based decoders or non-implicit representations (e.g., mesh-based networks)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sC7dCShDDr", "forum": "qJQQCF2ySC", "replyto": "qJQQCF2ySC", "signatures": ["ICLR.cc/2026/Conference/Submission22408/Reviewer_peNY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22408/Reviewer_peNY"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission22408/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762897017917, "cdate": 1762897017917, "tmdate": 1762942206497, "mdate": 1762942206497, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}