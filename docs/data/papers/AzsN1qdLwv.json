{"id": "AzsN1qdLwv", "number": 6429, "cdate": 1757983338854, "mdate": 1759897915024, "content": {"title": "Neural Compression of 3D Meshes using Sparse Implicit Representation", "abstract": "The growing demand for high-quality 3D models has fueled the need for efficient 3D mesh compression techniques. However, existing methods suffer from suboptimal compression performance due to inefficient data representation of meshes. To address this issue, we propose a novel neural mesh compression method based on Sparse Implicit Representation (SIR). Specifically, SIR only records values of the signed distance field on regular grids near the surface, enabling high-resolution structured representation of arbitrary geometric data with much less memory cost while supporting precise surface recovery. Subsequently, a lightweight Sparse Neural Compression (SNC) network is constructed to extract compact embedded features from the SIR and encode them into a bitstream. Extensive experiments and ablation studies demonstrate that our method outperforms state-of-the-art mesh and point cloud compression approaches in both compression performance and computational efficiency across diverse mesh models. The code is included in the Supplementary Material.", "tldr": "", "keywords": ["compression", "3D mesh"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0a0ea31eefd5b1631633dc80bdf8e53c7b88ab83.pdf", "supplementary_material": "/attachment/50f04e9a4a21b6f5e8f3c63e77b9039f45a23f26.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents a novel neural mesh compression framework named SIR-SNC, which addresses the inefficiencies of existing 3D mesh compression methods. It introduces: 1) Sparse Implicit Representation (SIR): Efficiently encodes surface geometry by storing SDF values only near the surface; 2)Sparse Neural Compression (SNC): A lightweight autoencoder based on sparse convolutions that compresses the SIR representation into compact latent features and encodes them into a bitstream. Experiments on multiple datasets show that SIR-SNC significantly outperforms prior methods, including Draco, G-PCC, SparsePCGC, NeCGS, and V-DMC, both in rate-distortion performance and computational efficiency. Notably, it generalizes well to non-watertight and dynamic mesh scenarios."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1)\tTechnical novelty: The SIR design is a well-motivated innovation that combines the best of sparse geometry and implicit fields.\n2)\tStrong empirical performance and efficiency: The proposed method achieves significant BD-BR reductions across diverse benchmarks, while maintaining a lightweight model size and fast decoding speed, demonstrating both superior compression effectiveness and practical efficiency.\n3)\tRobust generalization: The method generalizes well to diverse and challenging meshes without any fine-tuning. It was validated on unseen datasets such as ShapeNet , ScanNet, and MGN, including non-watertight and open-surface cases, demonstrating strong robustness across domains and geometry types."}, "weaknesses": {"value": "There is no ablation study on the predefined distance threshold."}, "questions": {"value": "1. What are the relations between the initial grids and the target grids?\n2. How sensitive is SIR to the threshold \\tau?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "k5t7a8xn8L", "forum": "AzsN1qdLwv", "replyto": "AzsN1qdLwv", "signatures": ["ICLR.cc/2026/Conference/Submission6429/Reviewer_b2HU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6429/Reviewer_b2HU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6429/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761665837623, "cdate": 1761665837623, "tmdate": 1762918822399, "mdate": 1762918822399, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a combination of Sparse Implicit Representation (SIR) and Sparse Neural Compression (SNC) through a two-stage approach to achieve significant file size reduction while maintaining reconstruction precision. The key insight is that by storing explicit coordinates with distance values for near-surface points only, SIR achieves high-fidelity representation with reduced file sizes compared to established methods. Results demonstrate impressive compression gains over prior methods across multiple datasets, with effective generalization to unseen meshes, support for non-watertight surfaces, and practical efficiency through sub-second decoding times."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Originality: The paper demonstrates strong originality through simple but powerful insight that only near-surface voxels matter for reconstruction, thus introducing a novel two-stage framework that stores explicit coordinates with distance values exclusively for near-surface points that achieves better compression (small resultant file size) and performance (shorter decoding time).\n\nQuality: Sufficient comparative evidence were provided to support the authors' claims, validated across multiple datasets and benchmarked against multiple established methods. Furthermore, their cross-domain generalization testing provides convincing evidence that the method generalizes beyond its training distribution.\n\nClarity: The paper effectively communicated why sparse representation addresses inefficiencies in dense approaches. The primary contributions and insights are easy to understand and follow.\n\nSignificance: Substantial compression gains (30-90% bitrate reduction over state-of-the-art) across multiple datasets represents genuine practical value. The ability to handle non-watertight surfaces and performance gain could warrant additional development to transition this into a viable alternative for existing methods."}, "weaknesses": {"value": "The absence of systematic ablation studies represents a critical methodological gap. The paper makes numerous design choices e.g., sparsity threshold, channel network width, etc., described as \"empirically set\" or \"default\" without justification. We cannot determine which components drive performance or whether results are robust across hyperparameter variations. At minimum, the authors should ablate the sparsity threshold, which dictates the rate-distortion tradeoff, network architecture choices, and loss component contributions. Without these studies, the work reads as \"we tried something and it worked\" rather than \"we understand why our design succeeds.\"\n\nTable 2 mixes heterogeneous implementations of the work (Python/GPU) and compares it against optimized C++/CPU implementations, making it hard to truly discern if the  observed speed differences originated from algorithmic insight or implementation choices.\n\nThe non-watertight surface handling lacks sufficient justification. The paper claims the method \"robustly represents\" non-watertight meshes based solely on showing it works in practice, without explaining why it should work reliably. While the intuition makes sense, missing the explanations of when and why the approach succeeds or fails, measurements of whether geometric properties are preserved correctly, and comparisons with methods specifically built for handling non-watertight surfaces weakens the paper. A deeper analysis showing when it works, when it doesn't, and how well it preserves geometric structure is valuable here."}, "questions": {"value": "1. Can you provide systematic ablation studies on key design choices?\n2. What is the theoretical basis for non-watertight surface handling?\n3. Can you clarify the source of computational efficiency gains?\n4. How does your method generalize across different mesh types and resolutions? \n    - Can you provide per-category performance breakdowns showing where the method excels versus struggles?\n    - What happens if the resolution exceeds $512^3$ significantly?\n    - Are there mesh characteristics (topology, geometric complexity, scale) that predict compression performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "n3ir4XtJ3O", "forum": "AzsN1qdLwv", "replyto": "AzsN1qdLwv", "signatures": ["ICLR.cc/2026/Conference/Submission6429/Reviewer_YpR1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6429/Reviewer_YpR1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6429/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971288310, "cdate": 1761971288310, "tmdate": 1762918821796, "mdate": 1762918821796, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework for 3D mesh compression called SIR-SNC.The paper introduces a two-stage approach, 1) Sparse Implicit Representation (SIR): A mesh representation that stores Signed Distance Field (SDF) values only on a regular grid of points near the object's surface, 2) Sparse Neural Compression (SNC): A lightweight, sparse convolutional autoencoder (AE) designed to compress the SIR. A Sparse Marching Cubes (SMC) algorithm is used for efficient surface extraction from the SIR."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Promising results on the evaluated benchmarks. The paper shows large gains on most of the benchmarks.\n- Efficiency of method: The proposed method appears to be quite practical using a small model and fast encoding/decoding.\n- The method works on general non-watertight and open meshes."}, "weaknesses": {"value": "- Limited Novelty: The proposed approach appears to closely follow that of Tang et al., without sufficiently acknowledging the fact and without presenting relevant empirical comparison. It is not clear what aspects of the proposed approach are truly original. More on this in the next point.\n- Insufficient comparison with Tang et al.: The method seems to be heavily inspired by that of Tang et al (cited in the paper). As such, it is not clear what aspects of the paper are novel and what are borrowed from existing works. For example, Tang et al, also uses a sparse representation, using an occupancy map (which is losslessly coded and transmitted) to encode the occupied voxels. These occupied voxels are also found using marching cubes algorithm (like the current paper). This allows Tang et al. to avoid coding and transmitting voxels that donâ€™t carry useful information (Fig 3 in Tang et al.). This fact is not mentioned in the paper and/or attributed to Tang et al, though the figures of Sparse SDF in the paper (e.g. Figure 4, first and last diagram) are reminiscent of Figure 3 in Tang et al. Similarly, Tang et al, uses a small autoencoder to encode/decode features of only the occupied blocks of voxels. Again, this is not acknowledged/mentioned in the paper. Further, Tang et al, also uses a rate-distortion loss (eq 1 in Tang et al) to train a compressed representation (similar to eq. 3 in current paper).\n\nOverall, I find it quite concerning that sufficient credit/comparison is to made with the prior art of Tang et al, despite the obvious similarities in the proposed method. While the presented results are promising, I am quite curious about the source of this omission."}, "questions": {"value": "Please elaborate extensively on the differences from the method of Tang et al. and exactly what aspects of the proposed method are claimed to be novel and validated via the experiments."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9XPqLOEslo", "forum": "AzsN1qdLwv", "replyto": "AzsN1qdLwv", "signatures": ["ICLR.cc/2026/Conference/Submission6429/Reviewer_EZUy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6429/Reviewer_EZUy"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6429/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990731674, "cdate": 1761990731674, "tmdate": 1762918821418, "mdate": 1762918821418, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}