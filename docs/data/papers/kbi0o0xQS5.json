{"id": "kbi0o0xQS5", "number": 9248, "cdate": 1758116216563, "mdate": 1759897735393, "content": {"title": "Optimal Affine Framework for Steering Generative Models", "abstract": "An idea of steering intermediate representations of generative models has recently emerged as a simple yet powerful approach for controlling aspects of generated texts and images. However, despite the simplicity of the approach, no theoretical framework has yet been built around steering. In this paper, we aim to bridge this gap, building theory around concapt steering. First, we provide theoretical link between steering and affine concept erasure framework, showing that widely used steering setup for erasing unwanted behaviours or concepts from generative models is a special case of LEACE, a closed-form method for affine concept erasure in neural networks. Next, we consider the task of concept switching, the aim of which is to change information about unwanted concept or behaviour in the modelâ€™s representations into another, more desired concept or behaviour. Here our contribution is two-fold: first, we formulate a theoretical framework for this task, adapting existing affine concept erasure framework used for concept erasure. Then, we identify weaknesses of the resulting framework, and propose a new, improved one, that we call MIDSTEER (MInimal Disturbance concept STEERing). Our results show that MidSteer performs favourably on a variety of tasks modalities and models, including image generative diffusion models and LLMs.", "tldr": "", "keywords": ["steering", "llm", "diffusion", "control"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/73e3d549069dde748a628025d73244a593bcf330.pdf", "supplementary_material": "/attachment/b248450e7bc721693d2059d6b0a667278e93b75f.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes a theoretical connection between affine concept erasure and concept steering, and then adapts affine erasure to the task of concept switching. In addition, a new approach, MiDSteer is proposed, and experiments are conducted to compare it to the prior techniques in both LLMs and generative image models."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "The proposed technique makes sense and the results show the improvement versus the state of the art techniques.\n\nThe theoretical bridging of the different approaches is a sdolid contribution."}, "weaknesses": {"value": "My score is currently low because of the, to me, confusing presentation. If this could be rectified, then the score could improve. For example, it is unclear what LEACE is. It is not well introduced, and we have to infer what it is. Similarly, CASteer is mentioned just above equation (18), but it is not clear what it is and how it differs to LEACE. Even MidSteer itself is not well introduced. There is a tangential definition of it at line 310, which refers back to Thm 5. \n\nThe results in section 4.2.1 experiments are for CASteer and LEACE. These are existing techniques and not the (new) MiDSteer. Why is this included?\n\nMinor:\n- \"subscript\" of $s^c^ should be \"superscript\"\n- miscellaneous grammatical issues, e.g. \"of the concept C in generation result of the model\"\n- Figure 1 is not referenced in the text as far as I could see.\n- there seem to be two betas. One in line 322 and a different one (?) in eqn (20). That is confusing. (and the reference to eqn (21) in line 323 should presumably to to eqn (20))\n- the heat map colour for beta in the figures does not work well\n- in line 471, should \"4\" be \"Fig 4\"?"}, "questions": {"value": "Is the constraint in Theorem 5 on the rank being full satisfied in practise? Was that investigated? If it is not, how does it impact the results?\n\nIn section 4.2.1, unrelated concepts are used for testing. How is the lack of relation to the erased concept established? And would it be interesting to investigated related concepts vs unrelated concepts to see the impact of erasure on the different degrees of relatedness?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SAVCwoG9ZX", "forum": "kbi0o0xQS5", "replyto": "kbi0o0xQS5", "signatures": ["ICLR.cc/2026/Conference/Submission9248/Reviewer_MrFE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9248/Reviewer_MrFE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9248/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761006267614, "cdate": 1761006267614, "tmdate": 1762920902449, "mdate": 1762920902449, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Topic: Steering intermediate representations of generative models\n\nDefinition of steering: adding a steering vector to the intermediate representations to control the generated results.\n* concept deletion = Erasing unwanted behaviors or concepts\n* concept switching = changing a concept with another\n\nProblem statement:\n* Steering is empirically developed without theory.\n* Naive steering often perturbs unrelated features.\n* Affine concept erasure does not solve concept addition or switching.\n\nContribution:\n* a theory of concept steering: steering is a special case of LEACE, a closed form method for affine concept erasing in neural networks\n* Minimal disturbance concept steering (MiDSteer), an improved version of concept steering"}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Originality: not sure\n\nQuality:\n1. L329 The experiments cover various models: Llama 2, Qwen 2.5, SDXL, and SANA.\n\nClarity:\n1. L353, L371, L400 The task and desiderata are clearly noted.\n\nSignificance: not sure"}, "weaknesses": {"value": "1. The previous knowledge and the proposed knowledge should be separated. Which parts are the contribution? It would help the readers recognize the significance of this paper.\n2. Significance of the contribution should be apparent to the readers. Why are the theorems and proofs non-obvious?\n3. L171 Guardedness should be defined in the paper for integrity, even though it is cited. The connection between guardedness and Theorem 1 should be explained. Please be kind to the readers.\n4. L310 MiDSteer, the proposed method, is not proposed. \n5. LEASE should be L054 cited and L196 explained.\n6. Figure 4: The images and the caption do not match: the dog is still there in CASteer\n7. Sentences should be easier to be understood. Please remove redundant or uninformative words and write precisely."}, "questions": {"value": "My questions are apparent in the weaknesses. Resolving them in the rebuttal may improve my rating."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WcUmW1ef0T", "forum": "kbi0o0xQS5", "replyto": "kbi0o0xQS5", "signatures": ["ICLR.cc/2026/Conference/Submission9248/Reviewer_bmDB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9248/Reviewer_bmDB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9248/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762070107477, "cdate": 1762070107477, "tmdate": 1762920902043, "mdate": 1762920902043, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors provide a theoretical connection between representation steering affine concept erasure/switching. In particular, they first show that concept steering is a special case of LEACE, which is a closed-form method for affine concept erasure. Next, the authors study the task of concept switching. By arguing that vanilla concept steering can switch the two targeted concepts, e.g. untruthfulness to truthfulness and vice versa, they propose MIDSteer to only allow one way mapping."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The paper is generally well-written.\n* I think the problem of concept switching is a more controlled variant of concept erasure, which is nice.\n* Empirical results for LLMs show superior concept switching results compared to other methods."}, "weaknesses": {"value": "* The result section on LLMs seem to lack qualitative results, while the result section on diffusion models lack quantitative results. \n* While MIDSteer perform better than other methods for concept steering, I am not sure if CASteer and LEACE are appropriate baselines since they are purely designed for concept erasure.\n* I think the paper would benefit from more justifications on why concept switch is an interesting problem or why is it more preferred than concept erasure."}, "questions": {"value": "* Can the authors provide some qualitative results on LLMs output when MIDSteer, CASteer, and LEACE are applied?\n* What concepts are used to measure erasure for the LLM experiments?\n* Can the authors provide Pareto efficiency frontiers plot for the SDXL experiments?\n* What is the purpose of Section 4.2.1, I do not see MIDSteer being compared for concept erasure, yet the authors are comparing it with the same methods for concept switching?\n* For concept switching, I would be interested to see the Pareto plot using the y-axis as the concept score on c2 and on c1 separately, rather than just the difference between concept scores of c2 and c1."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VeeM2GycwZ", "forum": "kbi0o0xQS5", "replyto": "kbi0o0xQS5", "signatures": ["ICLR.cc/2026/Conference/Submission9248/Reviewer_7vKT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9248/Reviewer_7vKT"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9248/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762156556633, "cdate": 1762156556633, "tmdate": 1762920901419, "mdate": 1762920901419, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a unified theoretical framework for optimizing affine mappings for concept steering in neural representations. They show that the existing approach for concept deletion and flipping can be viewed as special-case solutions for a general constrained optimization problem. Then, they propose MidSteer, a general framework for concept steering. The main novelty compared with the prior works is that they whitens activations and apply steering transformation on the standardized representation space."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The work elegantly connects existing techniques for concept deletion, flipping, and transfer within a single constrained-optimization framework, offering novel insights and guiding future work. MidSteer generalizes prior works by removing the assumption of standardized activations, making the framework applicable to real, anisotropic model embeddings."}, "weaknesses": {"value": "From an implementation standpoint, MidSteer reuses the same affine transformation derived in earlier work, with $\\beta$ now treated as a hyperparameter, and the only non-trivial technical novelty seems to be activation standardization. Similarly, the theoretical contributions, though sound, follow relatively directly from existing frameworks without introducing substantially new analytical insights. Happy to be corrected on this. \n\nThe presentation of the final algorithm can be improved. I could not find any discussion of the computational cost of estimating $\\Sigma_{X, X}$. I suggest that the authors add the pseudo-code for this algorithm. What will the dimension of $X$ be for the language model? Is it seq_len x hidden_dim? Would the algorithm require instantiating the whole matrix of $\\Sigma_{X, X}$?\n\nI do not directly work in this field, so I cannot comment on how significant the experiment results are. Therefore, I set my confidence to 2."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "qBplV6ijJl", "forum": "kbi0o0xQS5", "replyto": "kbi0o0xQS5", "signatures": ["ICLR.cc/2026/Conference/Submission9248/Reviewer_1GAs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9248/Reviewer_1GAs"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9248/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762293324077, "cdate": 1762293324077, "tmdate": 1762920901010, "mdate": 1762920901010, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}