{"id": "B5RBKM4vPY", "number": 16075, "cdate": 1758259464394, "mdate": 1759897263598, "content": {"title": "Counterfactual Explanations on Robust Perceptual Geodesics", "abstract": "Latent-space optimization methods for counterfactual explanations—framed as minimal semantic perturbations that change model predictions—inherit the ambiguity of Wachter et al.’s objective: the choice of distance metric dictates whether perturbations are meaningful or adversarial. Existing approaches adopt flat or misaligned geometries, leading to off-manifold artifacts, semantic drift, or adversarial collapse. We introduce Perceptual Counterfactual Geodesics (PCG), a method that constructs counterfactuals by tracing geodesics under a perceptually Riemannian metric induced from robust vision features. This geometry aligns with human perception and penalizes brittle directions, enabling smooth, on-manifold, semantically valid transitions. Experiments on three vision datasets show that PCG outperforms baselines and reveals failure modes hidden under standard metrics.", "tldr": "We propose Perceptual Counterfactual Geodesics (PCG), a method that generates counterfactuals by tracing geodesics in a perceptually aligned latent space, outperforming prior methods and avoiding failures from misaligned geometry", "keywords": ["Interpretability", "Visual Counterfactual Explanations", "Explainability"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b34051a69248b5be8584987bee515f7b0eca1997.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper studies the problem of generating counterfactual explanations for image classifiers.\n\nThe paper adopts a latent-space approach: the counterfactual explanation is found by traversing the latent space of a generative model.\n\nThe introduction clearly describes the problems faced by existing latent-space approaches and methods that search for counterfactual explanations more generally. For example, we don't want to provide on-manifold adversarial examples as counterfactuals.\n\nThe paper then proposes a novel method  to generate counterfactuals (PCG). The idea is to equip the latent space with a robust perceptual metric via pullback from a robust vision classifier (this is not the same classifier for which they generate the explanations). \n\nThe paper states that when counterfactual explanations are generated in the latent space using the robust perceptual metric, they correspond to smooth, on-manifold, semantically valid transitions between images of different classes.\n\n**Experiments:** The novel method PCG is compared against other latent-space counterfactual methods. The paper contains the following evaluations:\n\n- Visual inspection of interpolation paths in the latent space (Figure 2, Figure 3)\n- Quantitative comparison between different CF generation methods according to standard metrics (Table 1)\n- Qualtitative dedication of counterfactuals generated by different methods (Figure 4)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed method is well-motivated and extensively described in the paper\n- The contribution of the paper is situated within the existing literature\n- The empirical results in the paper are encouraging, both for the geodesics and the generated counterfactual explanations\n- The paper is clearly written"}, "weaknesses": {"value": "**Limited empirical results:** While the motivation and description of the proposed method are extensive, the breadth of the empirical results is surprisingly limited. By this I mean that:\n\n- The qualitative examples in the paper are almost all either for humans or for cats and dogs. So there is a limited breadth in terms of the classes for which the counterfactuals are explored.\n- The classifiers for which the counterfactuals are generated are VGG-19 backbones trained on a binary classification task. This seems like a rather specific choice; it should be relatively easy to extend this to a multi-class setup with other architectures? \n- Some details, like class probabilities assigned by the classifiers, are not reported\n\nFor example, I compared the empirical results in this paper to the results in \"Diffusion Visual Counterfactual Explanations\" NeurIPS 2022 (https://proceedings.neurips.cc/paper_files/paper/2022/hash/025f7165a452e7d0b57f1397fed3b0fd-Abstract-Conference.html). This paper does not use a latent-space approach, but, similarly to the submitted work, it proposes a method to generate robust counterfactual explanations for arbitrary classifiers. This paper has similar limitations to the submitted paper, insofar as it must rely on a visual inspection of the generated counterfactuals and some proxy metrics. However, the empirical results in this paper are much more detailed.\n\n**Unclear if the proposed approach beats the state of the art:** While the proposed method is very well-motivated, the limited empirical evaluation does not make clear to me in what precise sense the obtained counterfactuals can be considered state of the art among latent space methods, or method for generating counterfactual explanations for non-robust classifiers more generally (if we were to compare with diffusion-based approaches as well, as in the above reference)"}, "questions": {"value": "**Question 1:** Why is the proposed approach not applied to arbitrary ImageNet classifiers? (or other standard classifiers from PyTorch repositories)\n\n**Question 2:** If we were to generate counterfactual explanations using a latent-space approach without your robust perceptual metric, but for a robust computer vision classifier (like the robust model that you derive your metric from), would this result in similar explanations?\n\n**Question 3:** Is the direction from the original image to the generated counterfactual approximately aligned with the tangent space of the data manifold at the original image, or is this not the case?\n\n**Reason for Final Score:**  The strengths of this paper is a very well-written introduction and a very good motivation for the proposed method, including the mathematical details. The main weakness of this paper is the limited scope of the empirical results, which fall somewhat below the bar for a conference like ICLR. To me, this makes the current version of the paper a marginal paper. I decided to assign the paper a score of 4 for now."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ozfwDVrdNW", "forum": "B5RBKM4vPY", "replyto": "B5RBKM4vPY", "signatures": ["ICLR.cc/2026/Conference/Submission16075/Reviewer_T7oH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16075/Reviewer_T7oH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16075/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761648314344, "cdate": 1761648314344, "tmdate": 1762926262073, "mdate": 1762926262073, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses an important problem of the potential adversarial nature of counterfactual explanations (CEs) in computer vision. To avoid off- and on-manifold adversarial examples (AEs) as solutions to the empirical CE optimization problem, the authors propose to perform the optimization within the latent space of a generative model with the geometry induced by the aggregated representations of a robustly trained classification model. This optimization takes into account the entire path traced from the true sample to the CE and aims at finding a geodesic between these points wrt. the proposed geometry. Within the experimental section, the authors aim at showing improved smoothness in comparison to baselines, superior results in terms of several geometric measures and the ability to avoid off- and on-manifolds AEs."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1. The considered problem is often overlooked in the CE context, especially in the computer vision domain, where human perception may be easily fooled. It is also of extreme importance to the explainability community -- since CEs stand at the top of the Pearl's causality ladder, it is crucial to generate explanations that are truly valid. The authors provide an elegant solution to this problem, with clearly highlighted motivation and proper mathematical formalism.\n\nS2. The proposed PCG algorithm is actually a novel, two-phase approach with clear motivation behind its construction, especially for phase I. The clarity of the description is great, the baselines are properly described, and the overall flow of the paper is enjoyable for the reader.\n\nS3. Prior methods in the undertaken research direction were mainly considered in the tabular setting. The authors did a very good job in transferring and adapting these methods to the vision domain."}, "weaknesses": {"value": "W1. Robust models are never \"infinitely\" robust (lines 225-227), meaning that their robustness is preserved up to some nieghborhood of each point. What are the ways of measuring this robustness? How does the level of this robustness influence the resulting induced geometry? What limitations spark from that and how can they be overcome?\n\nW2. Is there some theoretical justification for the definition of the robust perceptual metric $G_R$ (its equation is not numbered, but can be seen at line 234)? Or is it purely a heuristic choice? I fully understand the motivation behind it, but this particular choice of the definiton appears in a slightly surprising way without any reference, especially a theoretical one about the robustness itself.\n\nW3. Influence of $\\lambda$ seems crucial as it may significantly impact the robust energy and eventually make the trajectory misaligned with the induced robust semantic geometry. The paper currently lacks any ablation study related to $\\lambda$'s influence.\n\nW4. I am fully aware that evaluating the claimed improved smoothness and manifold consistency is very challenging. However, I must argue that simply providing a few example trajecteries is not enough to properly back the claims. One way of addressing this is through a user study, in which participants are asked about the perceived smoothness, i.e., the ground-truth for the semantic similarity perception. The other, probably less demanding and more suitable to the rebuttal, is finding some proxy measure to quantitatively assess the properties.\n\nW5. While I agree that counterfactuals from other methods seem to be off- or on-manifold AEs, how can this be measured at scale? What is the guarantee that these samples are not just cherry-picked? A quantitative comparison here is important to assess whether PCG is not suffering from the same problems.\n\nW6. The paper currently does not contain any explanandum-related metrics and is missing the typical ones from prior work. While I do understand that baseline works did not use them, the extension to vision domain deems it necessary (at least for me). The paper should additionally contain a comparison in terms of FID ([1], closeness at the distribution level), COUT ([2], sparsity relative to the explained model) and flip/sucess rate (effectiveness of the method).\n\nW7. Important ablations are missing: what is the influence of the choice of the robust model? how does its training data influence the resulting geometry (the proposed method relies on ImageNet-based model everywhere)? How does the choice of the number and weights of the layers affect it?\n\nW8. The paper is currently ignoring two important research directions. First one is related to current state-of-the-art solutions based on pixel-space diffusion-based models, e.g. [3] and [5]. These should be at least mentioned as recent methods that do not focus on the problem considered in the paper, which will only strengthen its relevance. The other direction considers latent-diffusion-based methods, which also perform some kind of optimization in the latent space of a VAE, but with an addition of a diffusion model [4,6,7]. What is the influence of the VAE+diffusion combination in the considered problem of off- and on-manifold AEs? These issues should be at least mentioned in the paper to ensure maximum impact.\n\nMinor:\n- line 095: the mentioned methods are mostly in the vision domain, except the first one\n- line 238: neural networks (for prediction tasks) typically compress data, so it should probably be $d_k << D$\n- line 921: is the change to Softplus actually relevant? If yes, some experiment should be showing that in the paper. If not, why not just remove this procedure and stick with ReLU?\n- the main text should be slightly more precise about phase II, the re-anchoring procedure and the overall details. It is fully understandable only after referring to the pseudocode from the appendix.\n\n[1] Heusel et al., GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium, NeurIPS, 2017\n\n[2] Khorram et al., Cycle-Consistent Counterfactuals by Latent Transformations, CVPR, 2022\n\n[3] Weng et al., Fast Diffusion-Based Counterfactuals for Shortcut Removal and Generation, ECCV, 2024\n\n[4] Sobieski and Biecek, Global Counterfactual Directions, ECCV, 2024\n\n[5] Sobieski et al., Rethinking Visual Counterfactual Explanations Through Region Constraint, ICLR, 2025\n\n[6] Augustin et al., DiG-IN: Diffusion Guidance for Investigating Networks - Uncovering Classifier Differences Neuron Visualisations and Visual Counterfactual Explanations, CVPR, 2024\n\n[7] Luu et al., From Visual Explanations to Counterfactual Explanations with Latent Diffusion, WACV, 2025"}, "questions": {"value": "Overall, I am a big fan of the proposed approach and consider the problem to be extremely relevant. My greatest concerns lie in the scope and scale of the current evaluation scheme, which does not provide sufficient evidence for some of the claims and does not shed light on important aspects of the proposed method, e.g, the $\\lambda$ hyperparameter. During the rebuttal, please refer to the weaknesses above, which either contain the questions directly or implicitly."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5lj8bI0lAO", "forum": "B5RBKM4vPY", "replyto": "B5RBKM4vPY", "signatures": ["ICLR.cc/2026/Conference/Submission16075/Reviewer_RJrE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16075/Reviewer_RJrE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16075/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761676068314, "cdate": 1761676068314, "tmdate": 1762926261545, "mdate": 1762926261545, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a method, Perceptual Counterfactual Geodesics (PCG), for generating counterfactual explanations by optimizing trajectories in a generator's latent space. The core contribution is the introduction of a robust Riemannian metric to define the latent geometry. This is induced from the feature spaces of robust vision models. This perceptually-aligned geometry enables the generation of smooth, semantically valid explanations that successfully avoid both off-manifold artifacts and on-manifold adversarial regions, which are common failure modes for existing latent-space methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Strong motivation: Paper clearly articulates three speicific failure modes of prior latent space methods: 1. off-manifold traversal leading to artifacts, 2. local gradient optimization that ignores global structure, 3. generator exploitation of non-robust metrics.\n- Perceptual Counterfactual Geodesics (PCG) is logical and well-structured. It employs a two-phase optimization process. This involves first finding an energy-minimizing geodesic, and tehn jointly refining the path and its endpoint with a classification loss.\n- The experimental validation is comprehensive. Uses three high dimensional datasets (AFHQ, FFHQ, Plant Village), and two different generator architectures (STYLEGAN2, STYLEGAN3).\n- The paper provides compelling visual evidence that PCG produces smooth, semantically coherent explainations while baselines collapse into off-manifold artifacts or on-manifold AEs. PCG also acheives the best scores in all geometry aware metrics.\n- The authors introduce a robust, geometry-aware evaluation metric, $ L_R $. This proves to be more faithful to perceptual similarity and successfully exposes teh adversarial failure modes of baselines that remain hidden under standard $ L_1 $, $ L_2 $, or even non-robust feature metrics, $ L_F $."}, "weaknesses": {"value": "- The paper's own conclusion frames it's contribution as operationalizing established ideas from pullback geometry and robust perception. The technical novelty is incremental, rather than a fundamental new theory.\n- The paper's main quantitative results is incomplete, with runtime comparisions relegated to appendix. There is limited discussion of scalability to longer paths or higher resolution images.\n- The justification for why robust features necessarily yield semantically meaningful geodesics rests on empirical demonstrations and appeals to prior adversarial robustness literature. It could be strengthened with a self contained theoretical proof for why this alignment must exist.\n- The paper notes that the baseline RSGD methods were mostly proposed for tabular data settings. The authors had to implement their own adaptations for the vision domain, which could mean the comparison isn't fully representative of those methods intended use, and hence somewhat unfair.\n- The sensitivity analysis in Appendix B.3 is limited. It relies on only three initialization runs per input and uses a single perceptual metric (LPIPS) for comparison. A broader statistical analysis would make the claims of low sensitivity more robust."}, "questions": {"value": "(restating some of the weaknesses)\n1. Can you provide theoretical analysis or intuition for why (and when) robust features guarantee semantically meaningful geodesics? Are there failure cases where robustness alone is insufficient?\n2. The runtime analysis in Appendix B.5 mentions using T=10 nodes for the path. How does the computational cost (both time and memory) scale as T increases? Is there a practical limit. What is the trade-off between a smoother geodesic and computational cost?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VNY97XaXge", "forum": "B5RBKM4vPY", "replyto": "B5RBKM4vPY", "signatures": ["ICLR.cc/2026/Conference/Submission16075/Reviewer_Bs9x"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16075/Reviewer_Bs9x"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16075/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762176682647, "cdate": 1762176682647, "tmdate": 1762926261176, "mdate": 1762926261176, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}