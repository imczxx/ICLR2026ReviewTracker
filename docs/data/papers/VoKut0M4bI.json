{"id": "VoKut0M4bI", "number": 2219, "cdate": 1757033814134, "mdate": 1759898162098, "content": {"title": "Unified Stability Bounds for Structured World Models: Geometry, Equivariance, and Identifiability as Sufficient Conditions", "abstract": "Representation learning for model-based RL offers sample efficiency yet raises a practical question, namely which properties of a learned representation govern downstream performance, and how to test them without re-running large-scale training? We present a \\emph{unified stability bound} that decomposes the suboptimality gap into three verifiable channels, consisting of geometric distortion $\\kappa$, an identifiability gap proxied by total correlation, and an equivalence or equivariance defect proxied by local equivariance error. The bound is \\emph{sufficient} and makes explicit how MDP constants and metric choices scale error through a simple, natural-scale right-hand side. Two mechanism theorems explain when and why proxies can appear unstable in practice. For instance, a quotient-space Johnson–Lindenstrauss result accounts for dimension reduction under symmetry, and a quantitative geometry–equivariance trade-off shows that non-isometric actions increase distortion. Building on this theory, we propose a lightweight diagnostic protocol that uses existing checkpoints, which includes a bound--vs--gap plot with a single calibration constant $\\beta$ that is calibrated on early checkpoints and held fixed for validation, and rank consistency with block bootstrap. On DreamerV3 world models, these diagnostics are reproducible, require no retraining, and are consistent with the sufficient-bound view that weak correlations are expected and not counterexamples. This framework provides a principled, low-overhead path to interpretable and auditable representation learning in RL.", "tldr": "", "keywords": ["world models", "DreamerV3", "representation learning", "equivariance", "Johnson–Lindenstrauss", "bi-Lipschitz embedding", "Bellman operator", "nonlinear ICA"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/27c9b82ed3755b25a3464103eb8b8681c405b45c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper explores the impact of learned representations on downstream performance in model-based reinforcement learning, providing a detailed theoretical and empirical investigation of how representation quality influences policy effectiveness.\n\nThe authors derive a performance bound that can be decomposed into three interpretable and verifiable components: geometric distortion, an identifiability gap, an equivalence or equivariance defect.\n\nThese theoretical insights are supported and reinforced by empirical results, demonstrating that the decomposition provides a meaningful explanation of observed performance variations. The combination of theory and experimentation provides a comprehensive understanding of the role of representation learning in improving model-based RL."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This paper demonstrates a strong alignment between theoretical analysis and empirical findings, effectively bridging the gap between abstract guarantees and observed performance. In particular, the use of rank-consistency metrics, such as Kendall’s and Spearman’s, combined with block-bootstrap confidence intervals, provides a statistically robust way to verify that the empirical trends closely match the theoretical predictions. This careful evaluation not only reinforces the validity of the theoretical results but also highlights the reliability of the proposed methods in practice.\n\nThe paper introduces several novel concepts, including the application of Lie groups, to the reinforcement learning literature. These contributions bring fresh mathematical perspectives to the field, expanding the toolkit available for addressing structured and low-rank RL problems and opening new avenues for research in both theory and practical algorithm design."}, "weaknesses": {"value": "The paper could be strengthened in terms of clarity, discussion of related work, and overall writing quality.\n\nThe paper draws on Lie-group and symmetry concepts in the mechanism theorems. Including a brief, accessible primer (or an appendix section) summarizing the essential Lie-group background, citing relevant prior work in RL and representation learning would make the discussion more approachable for readers unfamiliar with this area.\n\nIs there any related prior work which uses Definitions 2.1 and 2.2? It would also help to add concrete examples and intuitive explanations to build readers’ intuition for these definitions."}, "questions": {"value": "Could you clarify the meaning of “sufficient” in the stated upper bound? Specifically, does it imply that the bound always holds under the given assumptions, or that the conditions are merely sufficient but not necessary for the guarantee? By definition, should the upper bound hold with certainty or with high probability, and if so, could this be explicitly stated?\n\nRegarding Theorem 2.4, it would be helpful to explain why the condition gamma L_P < 1  is required, along with some intuitive reasoning behind this requirement. Additionally, the term “LEE” appears in Theorem 2.4 but does not seem to be introduced earlier in the text; a clear definition and explanation of its role would improve readability and comprehension.\n\nIn Section 2.5, the discussion could be strengthened by adding a comparison to prior results, especially in terms of bound tightness. When reducing the proposed bounds to match prior work, including a direct comparison of tightness—potentially in a small summary table or concise paragraph—would help readers quickly assess the novelty and strength of the theoretical contributions.\n\nSome presentation issues should also be addressed: the mathematical expressions in Figure 3 are rendered incorrectly (appearing as plain text rather than proper mathematical symbols), and there is a layout inconsistency on page 6, where one bullet point appears in a different column format.\n\nIncluding intuitive proof sketches or key lemmas in the main text would make the theoretical contributions more accessible. Highlighting which technical ideas are novel versus those that follow established methods would further clarify the paper’s contributions and help readers better appreciate the significance of the work."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "no"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VhVzzsOAeG", "forum": "VoKut0M4bI", "replyto": "VoKut0M4bI", "signatures": ["ICLR.cc/2026/Conference/Submission2219/Reviewer_yhdE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2219/Reviewer_yhdE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2219/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760519806463, "cdate": 1760519806463, "tmdate": 1762916149331, "mdate": 1762916149331, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Overview：\nThis paper addresses a key challenge in model-based reinforcement learning: the lack of a principled and low-overhead framework for diagnosing the quality of learned world-model representations. Motivated by the need to move beyond expensive, end-to-end evaluations and the limitations of existing theories, the authors aim to explain which properties of a representation govern downstream control performance and how to test them on existing model checkpoints. To solve this, the paper introduces a unified stability bound that decomposes the policy's suboptimality gap into three verifiable channels: geometric distortion (κ), an identifiability defect proxied by Total Correlation (TC), and an equivariance defect proxied by Local Equivariance Error (LEE). The authors then propose a practical diagnostic protocol where these proxies are measured on off-the-shelf checkpoints. A single scaling constant, β, is calibrated on an early training window, and the resulting bound is shown to successfully cover the performance gap, even on held-out, later-stage checkpoints, thus providing a practical tool for auditing representation quality."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Strength：\n\n1.\tImportant and Well-Motivated Problem: The paper addresses the critical challenge of auditing the quality of learned representations without relying on expensive, full-scale training runs. \n\n2.\tNovel and Insightful Method: The core contribution, the unified stability bound, is novel in its approach. Decomposing the performance gap into three theoretically-grounded channels—geometric distortion (κ), identifiability (TC), and equivariance (LEE)—is an elegant synthesis of concepts from geometry, information theory, and symmetry. \n\n3.\tThorough and Convincing Empirical Validation: The experiments are thoughtfully designed and effectively support the paper's claims."}, "weaknesses": {"value": "Major concern：\n1. The paper is motivated by providing a diagnostic framework based on \"natural scale, explicit constants, and auditability.\" However, we noted a disconnect between this goal and the final method, which appears entirely empirical and data-driven in its application. Specifically, after normalizing the channels, you consolidate all theoretical MDP constants into a single scalar, β. This β is not derived from theory but is introduced as a fitting parameter, calibrated on early data solely to ensure the empirical bound holds. This procedure, while reproducible, seems to trade the initial goal of \"auditable constants\" for a data-dependent calibration. Could you elaborate on this design choice and the resulting trade-off between theoretical auditability and practical utility?\n\n2. Regarding the Local Equivariance Error (LEE), I question the alignment between its motivation—measuring consistency under meaningful MDP symmetries—and its implementation. The method uses pixel-space transformations like rotation, which in environments like Crafter seem to be image perturbations rather than true symmetric transitions. To use an analogy, this feels like testing a self-driving car's understanding of a \"left turn\" by rotating its camera feed. Consequently, the measured LEE may primarily capture sensitivity to visual artifacts, not the intended equivariance defect. To clarify this, could you justify this choice and provide visual evidence comparing the transformed images to those from plausible symmetric states in the environment?"}, "questions": {"value": "The paper's goal of using \"auditable constants\" is compelling, but the final method consolidates them into a single, empirically fitted parameter β. This seems to trade theoretical auditability for a data-dependent calibration. Could you clarify this design choice and explain how it aligns with the initial goal of auditability?\n\nLEE uses pixel-space rotations to test for symmetry understanding. In environments like Crafter, these transformations seem to create visual artifacts rather than plausible symmetric states. How do you ensure that LEE is measuring a failure to understand true environmental symmetries, rather than just sensitivity to these artificial image perturbations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "rAkeyDr7uI", "forum": "VoKut0M4bI", "replyto": "VoKut0M4bI", "signatures": ["ICLR.cc/2026/Conference/Submission2219/Reviewer_tX1o"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2219/Reviewer_tX1o"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2219/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761795889180, "cdate": 1761795889180, "tmdate": 1762916148921, "mdate": 1762916148921, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a unified theoretical framework for analyzing the stability of learned world models in model-based RL. The core contribution is a sufficient upper bound on the performance gap, which decomposes into three verifiable channels: geometric distortion, an identifiability gap, and an equivariance defect. The authors also propose a lightweight diagnostic protocol using existing checkpoints to validate the bound without retraining, demonstrating its application on DreamerV3."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The work integrates concepts from geometry, identifiability, and symmetry into a single stability bound, providing a unified view that relates to prior analysis methods.\n* The development of a concrete protocol for assessing representation quality using standard checkpoints offers a practical tool for empirical analysis without requiring retraining.\n* The included theoretical results on topics such as a trade-off between geometry and equivariance offer explanations for commonly observed phenomena in representation learning."}, "weaknesses": {"value": "* There are no obvious limitations from my perspective."}, "questions": {"value": "* Could the theoretical insights on the geometry-equivariance trade-off be extended to inform the design of objectives that strategically balance these competing factors？"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "z4LIH6VNAB", "forum": "VoKut0M4bI", "replyto": "VoKut0M4bI", "signatures": ["ICLR.cc/2026/Conference/Submission2219/Reviewer_Txr1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2219/Reviewer_Txr1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2219/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968172185, "cdate": 1761968172185, "tmdate": 1762916148587, "mdate": 1762916148587, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a “unified stability bound” for representation learning in model-based RL. The authors claim that the suboptimality of a latent-space policy can be bounded by three terms: geometric distortion (κ), identifiability via total correlation (TC), and equivariance error (LEE). They further propose a simple diagnostic pipeline to validate these proxies on DreamerV3 checkpoints, arguing that their bound offers a practical and interpretable tool for auditing world-model representations."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "**Ambition and scope**\n\nThe paper attempts to connect several lenses on representation quality — geometry, information-theoretic identifiability, and symmetry — under a single theoretical inequality. This is an interesting direction.\n\n**Potential motivation**\n\nDeveloping practical diagnostics for representation quality is indeed appealing, especially in world-model-based RL where representation collapse and instability can undermine control.\n\n**Empirical intent**\n\nUsing saved checkpoints rather than retraining agents is potentially low-overhead and may appeal to practitioners, assuming the diagnostics are meaningful."}, "weaknesses": {"value": "**Writing quality & clarity**\n\nThis paper is extremely poorly written and suffers from severe clarity issues. Reading it was frustrating and ultimately not productive. Basic concepts are introduced with no definitions, context, or intuition. Examples include: the lipshitz assumptions are not stated formally (which metrics?), total correlation (what is Z_i?), Lie-group action, local equivalence errors, identifiability proxy, manifold JL arguments, equivariance, IB/VIB, and more. Key notation is inconsistent or incorrect (e.g., the MDP definition in Section 2.1 alternates between S, X, Z), many hand-wavy words are unclear and undefined (\"natural scale\"), several symbols (\\delta_{\\mathrm{id}}, LEE) appear without definition or motivation, and several assumptions appear in the proofs which are not stated in the main text (Line 632: \"Crucially, we also require the optimal abstract value function to be Lipshitz continuous.\").\n\nRather than building intuition, the paper name-drops terms without explaining them, connecting them, or deriving useful consequences. The presentation is inadequate and is more akin to jargon-stacking rather than a coherent contribution.\n\n**Novelty & conceptual contribution**\n\nIt is unclear whether anything fundamentally new is being contributed. The bound is essentially a minor tweak of classical bisimulation / Lipschitz continuity bounds but rewritten in new terms. The given decomposition is not shown to yield sharper bounds, new guarantees, or new conceptual understanding. There is no algorithmic implication. The bound is not used to improve training, guide representation design, or inspire new architectures. No insight is given into when the bound is tight, how loose it could be, how one can obtain a representation satisfying these properties, or how it compares quantitatively to prior results. The rhetorical promise of “unification” is not delivered upon and does not materialize into technical innovation. The authors present this as a “diagnostic tool,” but essentially all prior work on bisimulation and representation quality already serves this role.\n\n**Theory quality & correctness**\n\nTheoretical development is sloppy and raises correctness concerns. The proof of Theorem 2.4 largely restates standard bisimulation arguments, and the few new components are simply upper bounds on existing quantities (Equation (4) in the proof of Theorem 2.4). The “manifold JL argument” in Section 2.4.1 is asserted, not proven or defined, and its relevance or connection to Theorem 2.4 is unclear. As explained above, central assumptions are stated in the proof but not in the main text. The bound of Theorem 2.4. states |J(\\pi) - J(\\pi^*)| on the LHS but does not define what $\\pi$ is, and the RHS only depends on MDP dynamics so does not reference any policy, so it is incorrect as stated. Overall, the theory section feels unfinished and mathematically imprecise.\n\n**Experimental issues**\n\nThe experiments section is extremely difficult to parse, and the little that can be understood is not particularly convincing. The method by which the proxy metrics are calculated (Section 3.1) is unintelligible. Some proxies have negative correlation with performance (contradicting the motivation) (Figure 2). The authors wave this away by saying the bound is simply sufficient so negative correlations are not a contradiction (which defeats the point of a diagnostic tool). The bound is not shown to be tight, meaningful, or useful in practice. The empirical section lacks detail — how exactly are proxies computed? How sensitive are they? How does variance propagate? It is unclear what “Kendall” and “Spearman” refer to, what “SPWM metrics” are, or what the labels and scales on any of the plots mean. Key methodological details are missing, making the results difficult to interpret or reproduce. There are no baselines against prior representation-quality metrics (e.g., bisimulation score, reconstruction errors, predictive losses).\n\n**Overall recommendation**\n\nThis paper, in its current form, does not meet the bar for clarity, rigor, novelty, or insight. The writing is opaque, the mathematics is undeveloped and informal, and the experiments do not substantiate useful claims. The idea of unified representation diagnostics is intriguing, but this work does not deliver a substantive or actionable contribution. Significant re-writing, formalization, and conceptual sharpening would be needed before reconsideration."}, "questions": {"value": "Questions for the authors\n- What genuinely new insight or algorithmic value does this bound provide?\n- Is the bound tight? Can you explain the necessity of any of these terms? \n- Can the authors provide clear, formal definitions for all used mathematical objects, and clear formal statements of every lemma and theorem, and clear complete proofs of every statement?\n- Can the authors define and give sufficient detail for the experimental section, including the experimental procedure and a full explanation of the results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QnE9RVYpey", "forum": "VoKut0M4bI", "replyto": "VoKut0M4bI", "signatures": ["ICLR.cc/2026/Conference/Submission2219/Reviewer_FhLj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2219/Reviewer_FhLj"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2219/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762284471656, "cdate": 1762284471656, "tmdate": 1762916148194, "mdate": 1762916148194, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}