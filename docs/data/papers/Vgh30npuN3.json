{"id": "Vgh30npuN3", "number": 5463, "cdate": 1757912144050, "mdate": 1759897972972, "content": {"title": "Curvature-Guided Task Synergy for Skeleton based Temporal Action Segmentation", "abstract": "Fine-grained temporal action segmentation plays a vital role in comprehensivehuman behavior understanding, with skeleton-based approaches (STAS) gaining prominence for their privacy and robustness. A core challenge in STAS arises from the conflicting feature requirements of action classification (demanding temporal invariance) and boundary localization (requiring temporal sensitivity). Existing methods typically adopt decoupled pipelines, unfortunately overlooking the inherent semantic complementarity between these sub-tasks, leading to information silos that prevent beneficial cross-task synergies. To address this challenge, we propose CurvSeg, a novel approach that synergizes classification and localization within the STAS domain through a unique geometric curvature guidance mechanism. Our key innovation lies in exploiting curvature properties of well-learned classification representations on skeleton sequences. Specifically, we observe that high curvature within action segments and low curvature at transitions effectively serve as geometric priors for precise boundary detection. CurvSeg establishes a virtuous cycle: localization predictions, guided by these curvature\nsignals, in turn dynamically refine the classification feature space to organize into a geometry conducive to clearer boundaries. To compute stable curvature signals from potentially noisy skeleton features, we further develop a dual-expert weighting mechanism within a Mixture of Experts framework, providing task-adaptive feature extraction. Comprehensive experiments demonstrate that CurvSeg signif-icantly enhances STAS performance across multiple benchmark datasets, achieving superior results and validating the power of geometric-guided task collaboration for this specific problem.", "tldr": "", "keywords": ["Temporal Action Segmentation", "Skeleton-based Learning", "Geometric Priors", "Curvature Guidance", "Task Synergy"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2aae2511a66f16c96d7c635f5f66de1808e73ca6.pdf", "supplementary_material": "/attachment/92de92f59f79b1318666586b4f35f400e712e550.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses the challenge of conflicting feature requirements in skeleton-based temporal action segmentation (STAS). The key innovation is utilizing the curvature properties of well-learned classification representations on skeleton sequences, with high curvature within action segments and low curvature at transitions serving as geometric priors for boundary detection."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper proposes a novel curvature-based approach that leverages the geometric properties of feature sequences to foster effective collaboration between classification and localization sub-tasks.\n\nThe introduction of a dual-expert weighting mechanism within a Mixture of Experts (MoE) framework enhances the performance of the synergy mechanism by separately capturing semantic representations for classification and fine-grained temporal details for localization."}, "weaknesses": {"value": "There are the following issues with Figure 1: (a) and (b) represent different STAS pipelines, while (c) and (d) do not; (c) and (d) are jumbled together without any spacing to distinguish them; and text in this figure is too small.\n\nLine 231, where, θt ∈ [0, π] quantifies. , should be deleted.\n\nLine 146, Task Decoupling in STAS  . is missing. \n\nThere is no analysis of the method's time complexity and runtime. Although a 1.5% improvement is achieved on the PKU-MMD dataset, it would be meaningless if it comes at the cost of increasing the model's runtime.\n\nIn temporal action segmentation, are the evaluation metrics Acc, Edit, and F1 reasonable? Why not use evaluation metrics similar to IoU?"}, "questions": {"value": "Although the writing in this paper is relatively standardized and the method exhibits some innovations, the task of skeleton-based temporal action segmentation is limited. \n\nThis paper does not provide me with meaningful insights, and even if it were accepted, its contribution to the field would be quite limited. I suggest that the authors expand their method for more tasks to enhance its generality."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gqauYRdCeL", "forum": "Vgh30npuN3", "replyto": "Vgh30npuN3", "signatures": ["ICLR.cc/2026/Conference/Submission5463/Reviewer_doPp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5463/Reviewer_doPp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5463/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761653508900, "cdate": 1761653508900, "tmdate": 1762918077804, "mdate": 1762918077804, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles skeleton-based action understanding by arguing that the geometry of feature sequences over time can be exploited to make classification and temporal localization help each other. The motivation is clear: current methods still show “insufficient cross-task collaboration,” so the authors introduce a curvature-based task synergy mechanism that uses geometric properties of feature trajectories to link both sub-tasks, and they couple it with a dual-expert weighting mechanism in a Mixture-of-Experts setup to adapt features to the task. As the authors themselves note, the approach still struggles with very noisy skeletons and complex multi-person cases, so there is room to improve robustness."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Clear motivation.  The paper starts from an identifiable gap, weak collaboration between classification and localization, and address it directly.\n\nGeometric novelty. using curvature of feature sequences as a bridge between sub-tasks is a fresh angle compared to standard temporal smoothing or boundary refinement.\n\nTask-adaptive extraction: the dual-expert / MoE part makes the framework flexible to different task demands instead of using a single shared feature space."}, "weaknesses": {"value": "Major 1. Across the method section, several symbols are introduced without being defined first, or they are not mathematically specified in a precise way. For example:\n\n\t•\tL176: \\alpha_i and \\alpha_j are not defined.\n\n\t•\tL182 – F_s is introduced without stating whether it is the same as the feature sequence in the problem formulation (X) or already an encoded representation.\n\n\t•\tEq. (4) and L191 – F_{ST} is used without an earlier, explicit definition. From context, it seems to be the spatio-temporal feature output of the Liformer / GCN stage, possibly the same as F_{\\text{gcn}}. Please unify the notation and add a one-sentence definition before Eq. (4).\n\n\t•\tL223 – “frame-wise classification features.” The text seems to refer to the same tensor that in Fig. 2 is denoted by the decoder classification head Y_{cl}. Please make these two references consistent.\n\n\t•\tL225–239 – windowed triplets. The text says “three consecutive points,” but the notation is F_{(cls, t-w)}, F_{(cls, t)}, F_{(cls, t+w)}. This is only strictly consecutive when w=1. For w>1, it is unclear: whether intermediate points are also used,  whether triplets are processed independently or aggregated, and how the final task representation is formed from them.\n\nPlease provide explicit sampling and aggregation equations.\n\n\t•\tL262 – F_{st} is mentioned again, but it is not clear whether this is the same as F_s, F_{st}, or F_{ST}. The shape is given as V \\times T without channels, which is hard to reconcile with the rest of the model.\n\n⸻\n\nMajor 2.\nIn the ablation results, two entries on PKU-MMD (X-view) — the Edit score and F1@10 — should be bold for the CGS-only configuration. I would like to know why this could be happening, because it would somehow break the idea that “EDD provides the high-quality.”\n\n\nTo make this section coherent:\n\t1.\tBold those two CGS-only numbers.\n\n\t2.\tAdd a short interpretation, e.g. that CGS might be better aligned with cross-view variability in PKU-MMD than the EDD augmentation in that specific setup.\n\n⸻\n\nMajor 3.\n\t•\tFigure 2 seems to have two different flow directions: the central pipeline is read from bottom to top, while the side modules are read from top to bottom. This makes it hard to know where the computation actually starts and where it ends.\n\n\t•\tVariable names are placed on top of the drawings and are hard to read (small font, low contrast, and sometimes overlapping the boxes).\n\n\t•\tThe figure repeats equations that are already in the text — equations (7) and (8) and L239 — which makes it redundant and not visually explanatory.\n\n\t•\tThe gray vertical line in the first column is not explained . if it is an encoder/decoder split, please state that.\n\n\t•\tIn text (L293) you say the feature is divided into M segments, but the figure shows g_1, g_2, g_3, which suggests a fixed number of Gaussians G=3. Please make the figure consistent with the text.\n\n\t•\tThe final step after the Gaussian generator ends in something like F_{m1}^{ST}, but it is not shown how these features are merged back into the task representation — that is precisely what readers will want to see.\n\n⸻\n\nMinor issues\n\n\t1.\tL218–220: the statement “intra-segment points must frequently change direction to remain within their class-specific boundary, resulting in high curvature, while inter-segment points exhibit low curvature as they move between class regions” — where is this shown to be true? It would be necessary to include a visualization or some evidence where this can actually be seen.\n\n\t2.\tL143 – “recent advances” needs citations. If you refer to recent advances, please add representative works.\n\n\t3.\tSome of the dimension strings in the description are of the form “(V \\times K) D \\times T \\times v” or “1 \\times I \\times K \\, D \\times D,” which can be a bit confusing regarding how they are multiplied.\n\n\t4.     In the hyperparameter analysis section, the parameter w is not discussed.\n\n\t5.\tSome sentences are not well expressed or well written. For example:\n\t•\tL216: “…feature space. (This observation can be formally proven: the average curvature of a random walk is inversely proportional to the radius of its bounding hyper-sphere. See Appendix B.) This…”\n\t•\tL448: a sentence should not start with a variable.\n\t•\tThe last sentence of L454. Please revise in general.\n\n\t6.\tFigure 4 – confusing “spins” in parts (b) and (c).\nIn Fig. 4 (b) and (c) there appear to be many sharp peaks / spins in regions where, according to the action annotation, the action does not change. Please explain why the method produces such high-frequency responses in stable segments."}, "questions": {"value": "1. Notations and definitions. Can you clarify the symbols in the method section (in particular F_s, F_{st}, F_{ST}, F_{\\text{gcn}}, and \\alpha_i, \\alpha_j) and make them consistent with Fig. 2?\n2. Figure 2 clarify.\n3. Rewrite Ablation on PKU-MMD (X-view): Why does the CGS-only setup outperform the full version for Edit and F1@10?\n4. Triplet/window construction: When you say “three consecutive points” but use t-w, t, t+w, what happens for w>1? Are intermediate points used and how are they aggregated into the final task representation?\n5. Can you provide a small visualization to support the high-curvature vs low-curvature claim, and explain the extra peaks in Fig. 4 (b)–(c) where the action does not change?\n \nFor more details, please see the Weakness section above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WyIoJruv7c", "forum": "Vgh30npuN3", "replyto": "Vgh30npuN3", "signatures": ["ICLR.cc/2026/Conference/Submission5463/Reviewer_t1pj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5463/Reviewer_t1pj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5463/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761898196299, "cdate": 1761898196299, "tmdate": 1762918077449, "mdate": 1762918077449, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a core challenge in Skeleton-based Temporal Action Segmentation (STAS): the conflicting feature requirements for its two main sub-tasks, action classification (which needs temporal invariance) and boundary localization (which needs temporal sensitivity). Existing methods typically decouple these tasks, which prevents beneficial cross-task collaboration and creates \"information silos\". The paper proposes CurvSeg, a novel approach that synergizes these tasks using a geometric curvature guidance mechanism. The key insight is that in a well-learned classification feature space, the trajectory of skeleton frame features exhibits high curvature within an action segment (to stay within its class cluster) but low curvature at transitions when moving between clusters."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.The paper introduces a novel curvature-based task synergy mechanism (CGS) that effectively exploits the geometric properties of feature sequences. This mechanism establishes a self-reinforcing loop where improved boundary detection and more discriminative classification features mutually enhance one another.\n\n2. The method is validated through comprehensive experiments on multiple benchmark datasets (PKU-MMD, LARa, MCFS-22, and MCFS-130) , where it achieves superior, state-of-the-art results. The most significant gains are seen in segmental F1 scores, directly validating the method's ability to enhance temporal boundary precision.\n\n3. Thorough ablation studies demonstrate the efficacy of each core component. The studies show that both the Expert-Driven Decoupling (EDD) and the Curvature-Guided Synergy (CGS)  independently improve performance. When combined, the full model achieves a synergistic effect, with performance gains surpassing the sum of the individual modules.\n\n4. The paper demonstrates that curvature is a more robust proxy for action boundaries than traditional distance metrics like Euclidean or Cosine. Curvature is sensitive to changes in the direction of the feature trajectory, making it better at detecting both gradual and abrupt action transitions."}, "weaknesses": {"value": "1. The related works in Skeleton-based Temporal Action Segmentation are not fully discussed. Only two works in 2020 are discussed. More recent works shuold be incorporated.\n2. As reflected by Eq.9, the information of the classification head and localization head just interact once, not in a self-reinforcing loop as the authors describe.\n3. The description of the foundation framework in sec.3.2 owns too much space. As the baseline and foundational model, it should be compactly introduced.\n4. The key innovation is directly borrowed from the previous work (Shinet al., 2024), and adopted for STAS with a simple transfer.\n5. Although the paper asserts that high curvature corresponds to intra-segment motion and low curvature to boundaries, the theoretical link is only qualitatively motivated and relies on assumptions (e.g., class clusters as hyperspheres). The “Appendix B proof” simplifies dynamics to random walks within spheres, which is too idealized for real, noisy skeleton trajectories."}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yRNpUw02Bt", "forum": "Vgh30npuN3", "replyto": "Vgh30npuN3", "signatures": ["ICLR.cc/2026/Conference/Submission5463/Reviewer_hoUk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5463/Reviewer_hoUk"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5463/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920997565, "cdate": 1761920997565, "tmdate": 1762918077107, "mdate": 1762918077107, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes CurvSeg, a novel framework for skeleton-based temporal action segmentation (STAS) that addresses the long-standing tension between action classification and boundary localization. The key insight is geometric: well-separated classification features naturally induce high curvature within action segments and low curvature at transitions — forming a \"valley\" that serves as a strong prior for boundary detection.\nTo exploit this, the authors introduce two core components:\nCurvature-Guided Synergy (CGS): A bidirectional consistency mechanism where classification feature curvature guides boundary prediction, while boundary supervision regularizes classification features to enhance cluster compactness.\nExpert-Driven Decoupling (EDD): A Mixture-of-Experts module with task-specific experts that refine shared encoder outputs into adaptive representations for classification and localization.\nExtensive experiments on four benchmarks (PKU-MMD, LARa, MCFS-22/130) show consistent improvements over state-of-the-art methods, particularly in segmental F1 scores, validating the effectiveness of curvature-guided collaboration.\nThe work makes a compelling case for geometric priors in structured prediction tasks, offering both conceptual novelty and practical gains."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Originality\n\nInnovative use of representation geometry: Leveraging trajectory curvature as a cross-task signal is conceptually fresh and theoretically grounded (Appendix B). This moves beyond typical attention or fusion mechanisms.\nBidirectional synergy design: Unlike prior decoupled frameworks that treat tasks independently, CurvSeg establishes a mutual reinforcement loop, which is rare in STAS literature.\nTask-adaptive MoE without parameter explosion: The Gaussian expert routing is lightweight yet effective, enabling dynamic feature specialization without full dual-path architectures.\n\n Quality\n\nRigorous experimental evaluation: Results across four datasets, including ablation studies and comparisons with strong baselines (DeST, LaSA), demonstrate robust performance gains.\nWell-designed ablations: Tables 3–6 clearly isolate contributions of CGS and EDD, showing their individual and synergistic effects.\nQualitative visualization: Figure 4 effectively illustrates improved boundary precision and reduced over-segmentation.\n\n Clarity\n\nThe paper is well-written and logically structured, with intuitive figures (Fig. 1–2) explaining the core ideas.\nEquations are clearly presented, and Algorithm 1/2 provide sufficient implementation details.\nAppendices offer valuable theoretical justification and hyperparameter analysis.\n\nSignificance\n\nAddresses a fundamental limitation in STAS: insufficient cross-task collaboration despite semantic interdependence.\nDemonstrates that geometric structure in learned representations can be exploited for downstream tasks — an idea potentially applicable to other time-series problems (e.g., speech segmentation, medical signal analysis).\nOffers a new paradigm: using internal model dynamics (curvature) as supervisory signals, reducing reliance on external priors."}, "weaknesses": {"value": "1) Limited discussion on failure cases\nWhile the method performs well overall, there is no analysis of when or why curvature fails as a boundary proxy. For example:\nIn gradual transitions (e.g., slow hand movement), curvature may not form clear valleys.\nNoisy skeleton data might amplify spurious curvature peaks.\nA brief error analysis (e.g., per-action performance drop) would strengthen the claims.\n\n2) Assumption of uniform segment partitioning\nThe EDD module divides videos into fixed-length segments (e.g., M=64), regardless of actual action duration. This could misalign temporal patterns for very short or long actions. Some discussion on adaptivity (e.g., content-aware segmentation) would improve robustness.\n\n3) Dependency on classification quality\nThe CGS module assumes that classification features already form compact clusters. If initial clustering is poor (e.g., due to ambiguous actions), curvature may not emerge reliably. The paper lacks sensitivity analysis under weak classification regimes.\n\n 4) Reproducibility concerns\nAlthough code will be released, some implementation details are missing:\nHow exactly are classification features $F_{cls}$ extracted? From the encoder output or after the classification head?\nIs the curvature computed per-joint or globally?\nThese should be clarified in the final version."}, "questions": {"value": "Q1: In Section 3.3, you mention that low-curvature regions correspond to boundaries. But in Fig. 4(a), we see high curvature at boundaries. Could you clarify this apparent contradiction? Is it possible that both high and low curvature can indicate transitions depending on context?\nThis could change my understanding of whether curvature acts as a direct boundary detector or only an indirect regularizer.\n\nQ2: You show in Table 5 that curvature outperforms Euclidean/Cosine distance metrics. Have you considered comparing against learned boundary detectors (e.g., gradient-based saliency maps)? Does curvature still dominate in such comparisons?\n\nQ3: What happens if you apply the curvature signal only during training but remove it at inference? Would performance drop significantly? This would help quantify how much of the gain comes from architectural synergy vs. test-time guidance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "1AH5u8urmF", "forum": "Vgh30npuN3", "replyto": "Vgh30npuN3", "signatures": ["ICLR.cc/2026/Conference/Submission5463/Reviewer_7JNX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5463/Reviewer_7JNX"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5463/-/Official_Review"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763108662367, "cdate": 1763108662367, "tmdate": 1763108662367, "mdate": 1763108662367, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}