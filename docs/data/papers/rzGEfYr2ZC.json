{"id": "rzGEfYr2ZC", "number": 19037, "cdate": 1758293003264, "mdate": 1759897064553, "content": {"title": "Don't Be Greedy, Just Relax! Pruning of LLMs via Frank-Wolfe", "abstract": "Pruning is a common technique to reduce the compute and storage requirements of Neural Networks. While conventional approaches typically retrain the model to recover pruning-induced performance degradation, state-of-the-art Large Language Model (LLM) pruning methods operate layer-wise, minimizing the per-layer pruning error on a small calibration dataset to avoid full retraining, which is considered computationally prohibitive for LLMs. However, finding the optimal pruning mask is a hard combinatorial problem and solving it to optimality is intractable. Existing methods hence rely on greedy heuristics that ignore the weight interactions in the pruning objective. In this work, we instead consider the convex relaxation of these combinatorial constraints and solve the resulting problem using the Frank-Wolfe (FW) algorithm. Our method drastically reduces the per-layer pruning error, outperforms strong baselines on state-of-the-art GPT architectures, and remains memory-efficient. We provide theoretical justification by showing that, combined with the convergence guarantees of the FW algorithm, we obtain an approximate solution to the original combinatorial problem upon rounding the relaxed solution to integrality.", "tldr": "", "keywords": ["pruning", "llm", "sparsity", "wanda", "sparsegpt", "efficiency", "optimization", "frankwolfe"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3ccbf5791029bc898784d1c15b759176a122112a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper is above 9 pages, therefore it should be rejected based on https://iclr.cc/Conferences/2026/AuthorGuide ."}, "soundness": {"value": 4}, "presentation": {"value": 1}, "contribution": {"value": 4}, "strengths": {"value": "N/A"}, "weaknesses": {"value": "N/A"}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "gpQOhAOZR2", "forum": "rzGEfYr2ZC", "replyto": "rzGEfYr2ZC", "signatures": ["ICLR.cc/2026/Conference/Submission19037/Reviewer_JQdH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19037/Reviewer_JQdH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19037/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761847453530, "cdate": 1761847453530, "tmdate": 1762931075436, "mdate": 1762931075436, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper exceeds the 9-page limit for ICLR 2026. I believe it should be desk rejected."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "N/A"}, "weaknesses": {"value": "N/A"}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "kOiJGDqL6j", "forum": "rzGEfYr2ZC", "replyto": "rzGEfYr2ZC", "signatures": ["ICLR.cc/2026/Conference/Submission19037/Reviewer_b3v6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19037/Reviewer_b3v6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19037/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761898683926, "cdate": 1761898683926, "tmdate": 1762931074869, "mdate": 1762931074869, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed an LLM pruning method, named SparseFW, which solves mask selection via convex relaxation and the Frank-Wolfe algorithm. Unfortunately, the paper exceeds the 9-page length limit and is therefore subject to desk rejection, according to the Author Guideline: https://iclr.cc/Conferences/2026/AuthorGuide."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "This paper proposed a novel LLM pruning method, SparseFW, that transforms combinatorial LLM pruning into tractable convex optimization via relaxation and the Frank-Wolfe algorithm, which supports multiple sparsity patterns."}, "weaknesses": {"value": "The paper exceeds the 9-page length limit, as mentioned in the Author Guideline: https://iclr.cc/Conferences/2026/AuthorGuide."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "0Iu3vNw47q", "forum": "rzGEfYr2ZC", "replyto": "rzGEfYr2ZC", "signatures": ["ICLR.cc/2026/Conference/Submission19037/Reviewer_LJA4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19037/Reviewer_LJA4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19037/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761899151239, "cdate": 1761899151239, "tmdate": 1762931074494, "mdate": 1762931074494, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}