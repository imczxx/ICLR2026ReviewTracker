{"id": "EplNy91Xqh", "number": 7422, "cdate": 1758021069598, "mdate": 1759897853705, "content": {"title": "SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn Tool-Integrated Reasoning", "abstract": "Large Language Models (LLMs) can enhance their reasoning by interacting with external tools, a paradigm known as Tool-Integrated Reasoning (TIR). However, extending TIR to multi-turn settings using Reinforcement Learning (RL) often exhibits training instability and degraded performance. We attribute the instability to harmful negative samples resulting from distributional drift and compounding errors induced by using external tool outputs during multi-turn rollout. To address this issue, we introduce SimpleTIR, a simple method that stabilizes multi-turn TIR training via filtering out trajectories with \"void turns\", i.e., turns that yield neither a code block nor a final answer. Specifically, we remove those trajectories from the policy update to block harmful gradients, while retaining them in advantage estimation to keep the estimate unbiased. Extensive experiments show that SimpleTIR effectively mitigates gradient norm explosion and stabilizes multi-turn RL training from base models. It achieves state-of-the-art performance on challenging math reasoning benchmarks, including an AIME24 score of 50.5 starting from the Qwen2.5-7B base model. SimpleTIR also promotes more diverse reasoning behaviors such as self-correction and cross-validation, outperforming prior methods trained from stronger instruction-tuned models.", "tldr": "", "keywords": ["Large Language Models", "Tool Integrated Reasoning", "Reinforcement Learning", "Code Generation", "LLM Reasoning"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/306103180c7026ee9cb8244e29e88c35650db3c7.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "SimpleTIR tackles the instability of multi-turn tool-integrated reasoning under Zero-RL by pinpointing a root cause: the distributional drift from external tool feedback that increases low-probability token sampling and triggers gradient explosions. The paper then stabilizes training with a plug-and-play trajectory filter that drops “void turns”. The paper formalizes the issue with a hierarchical MDP view and a logits-space gradient analysis, then shows strong empirical gains."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "(1) The paper did sharp diagnosis of a concrete failure mechanismgrounded in theory, not just anecdote; \n(2) Proposes a minimal fix that is orthogonal to RL algorithm choice and easy to adopt; \n(3) Present consistent empirical wins and smooth, stable training across turn budgets\n(4) Present evidence of emergent, diverse reasoning patterns preserved by Zero-RL rather than constrained by SFT “cold starts.”"}, "weaknesses": {"value": "(1) The “void-turn” heuristic may miss other harmful trajectories and could be task-specific beyond code-based TIR; \n\n(2) Experimental design requires max turns are capped (≤10) and can be further extended"}, "questions": {"value": "Stronger RL training algorithms for tool using like ToolRL for stronger baseline ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "WSWfLMrOTE", "forum": "EplNy91Xqh", "replyto": "EplNy91Xqh", "signatures": ["ICLR.cc/2026/Conference/Submission7422/Reviewer_eE8Z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7422/Reviewer_eE8Z"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7422/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761539730949, "cdate": 1761539730949, "tmdate": 1762919544026, "mdate": 1762919544026, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper identifies and mitigates a key failure mode in multi-turn tool-integrated reinforcement learning under the Zero-RL paradigm. \nThis paper proposes SimpleTIR, a lightweight, plug‑and‑play trajectory filter that drops any trajectory containing a turn that produces neither a complete code block nor a final answer. \nComprehensive experiments on math-reasoning benchmarks (AIME24/25, MATH500, AMC23, HMMT) show that this paper substantially improves both stability and performance."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. The failure‑mode analysis for multi‑turn TIR under Zero RL is clear.  \n2. The “void‑turn” trajectory filter is easy to implement, orthogonal to PPO/GRPO.  \n3. Hyperparameters, prompt formats, and pattern‑labeling prompts are clearly specified.  \n4. Originality is good. Even trajectory/data filtering is not new in RL/RLHF, but the turn‑level “void‑turn” filter tailored to multi‑turn TIR is a useful."}, "weaknesses": {"value": "1. All experiments use a Python interpreter for math. It remains unclear how the void‑turn heuristic transfers to other tool types (search, multi‑API plans), modalities, or noisier settings. Section 6 acknowledges this, but the paper would benefit from even a small study on search‑augmented QA (e.g., a Search‑R1 setup). \n2. The definition & detection seem heuristic. “Void turn = neither a complete code block nor a final answer.” In practice, “complete” relies on formatting and the prescribed prompt conventions. The method’s robustness to format drift (e.g., unboxed answers, partial but executable code, multi‑tool calls) is not evaluated. Clarify detection rules and report false‑positive/false‑negative rates.  \n3. Dropping entire trajectories wastes rollout budget; the paper does not quantify the filter rate over training or its impact on sample efficiency. Reporting the percentage of filtered trajectories vs. steps and wall‑clock/throughput would strengthen the claim."}, "questions": {"value": "1. Notation in sec 2.1 could be clearer (define H, q, K, L explicitly when introducing the hierarchical MDP). \n2. The abstract claims “AIME24 from 22.1 to 50.5 (7B)”, but 22.1 does not appear in Table 1; please reconcile and cite the exact baseline used.  \n3. Figure caption placement/style is inconsistent (some above, some below).  \n4. What is the wall‑clock overhead introduced by filtering (including sandbox latency)? Any guidance on batch sizes/turn caps (Figure 5 top) under a fixed compute budget?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "O2JyAOA1I5", "forum": "EplNy91Xqh", "replyto": "EplNy91Xqh", "signatures": ["ICLR.cc/2026/Conference/Submission7422/Reviewer_7iMa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7422/Reviewer_7iMa"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7422/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761777747116, "cdate": 1761777747116, "tmdate": 1762919542604, "mdate": 1762919542604, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SimpleTIR, a simple yet effective reinforcement learning (RL) algorithm designed to stabilize multi-turn tool-integrated reasoning (TIR) under the Zero RL setting. The authors identify that training instability in multi-turn TIR arises from “void turns, i.e., turns that produce neither a code block nor a final answer, which cause gradient explosions through compounding low-probability tokens. SimpleTIR addresses this by filtering out entire trajectories containing such void turns during policy updates. Despite its simplicity, this plug-and-play strategy substantially improves training stability and performance across math reasoning benchmarks, achieving promising results starting from base Qwen models and enabling the emergence of diverse multi-turn reasoning behaviors."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed method is simple and surprisingly effective.\nThe idea of filtering out trajectories with “void turns” is conceptually straightforward yet powerful. It mitigates a key failure mode in multi-turn RL training without introducing architectural or algorithmic complexity, making it easily adoptable in other setups. These simple but effective tricks will be very elegant in practical use.\n\n- The work tackles an increasingly important and difficult problem.\nMulti-turn RL for reasoning and tool use is becoming a central direction in scaling LLM capabilities. Addressing training instability in this regime is both timely and practically impactful.\n\n- Empirical results are strong and convincing.\nSimpleTIR not only stabilizes training but also significantly improves final accuracy across multiple benchmarks. \n\n- The analysis and visualization are thorough and insightful.\nThe authors provide solid empirical and theoretical analysis to identify the cause of instability, supported by clear visualizations of gradient dynamics and token probability shifts. These figures convincingly demonstrate how SimpleTIR mitigates the problem."}, "weaknesses": {"value": "- First of all: The figure captions, which are all placed above the figures, violate the conference formatting requirements.\n\n- The paper heavily focuses on “void turns” but fails to illustrate them clearly in the main text.\nWhile the appendix includes qualitative cases, the main body lacks a concrete or conceptual example of what a void turn actually looks like. Without this, readers cannot easily form an intuitive understanding of the concept or of why such turns “make no progress” in reasoning. Explicit examples or snippets in Section 3.3 would make the paper much clearer.\n\n- Discarding trajectories may lead to data inefficiency in sample-scarce settings.\nWhile filtering out void-turn trajectories works well for large-scale math reasoning tasks, it could be wasteful in domains where data collection is expensive. Discussing potential mitigations, such as partial reuse or weighting instead of full removal, would strengthen the paper’s generality. I'm curious if the authors tried other approaches that can preserve the data."}, "questions": {"value": "see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "nYhruKnOyE", "forum": "EplNy91Xqh", "replyto": "EplNy91Xqh", "signatures": ["ICLR.cc/2026/Conference/Submission7422/Reviewer_JcTa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7422/Reviewer_JcTa"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7422/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761889101092, "cdate": 1761889101092, "tmdate": 1762919542111, "mdate": 1762919542111, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SimpleTIR, a plug-and-play method to stabilize multi-turn tool integration reinforcement learning. The authors note that tool feedback can induce distribution shifts and lead to low-probability tokens and gradient spikes during multi-turn iterations. They analyse the root cause of this phenomenon and address it by filtering complete trajectories containing void turns, i.e., turns that do not contain a code block or yield an answer. On maths benchmarks, SimpleTIR significantly enhances the performance of Qwen2.5-7B and larger models, yielding smoother training curves compared to standard multi-turn RL. The study also observes emerging patterns such as cross-validation and error-correction mechanisms."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "This paper links multi-turn instability to extremely low-probability tokens emerging after model processing tools, demonstrating that these tokens trigger gradient peaks. Proposition 1 and the case study elucidate this mechanism.\n\nThis paper proposes a straightforward solution: directly filtering trajectories containing invalid rounds, thereby addressing unstable updates. The algorithm description and mask selection are clear and unambiguous.\n\nTable 1 shows consistent improvements across AIME24, AIME25, Math500, AMC23 and more, for 7B, 32B and 4B bases, compared to non-TIR RL baselines and prior TIR systems.\n\nSimpleTIR exhibits smooth training curves. Ablation experiments reveal that filtering mechanisms based on low token probability or high ratio demonstrate poor stability. Similarly, filtering only “stop generation instructions” without loss masking yields suboptimal results."}, "weaknesses": {"value": "Void turns are defined as those where the model fails to generate a complete code block or final answer. The training pipeline detects such instances by enforcing a final answer function and fixed tool output prefixes. The authors also note that this metric may not extend beyond the current multi-turn TIR environment.\n\nAll tasks were constrained on math problem-solving using Python tools. The paper itself acknowledges that this metric may only be applicable to multi-turn TIR scenarios. More complex agency tasks potentially require additional turns.\n\nAblation analysis focuses solely on early training (320 steps) and gives the conclusion that SimpleTIR suffers less from low probability tokens and gradient explosion. It does not mention whether the trajectory filtering with high importance ratios or low probability tokens can resolve the challenge of training instability in the long run.\n\nFiltering the whole trajectory when any void turn appears can reject hard trials and change the reward distribution. There is no quantitative report of filter rate or false positives. It may lean towards keeping easy success trajectories and discard hard trajectories.\n\nThe gradient-norm proposition is insightful, but there is no broad quantitative study that correlates measured low-probability token rates with gradient spikes across many runs and seeds. Evidence is mainly a case study and a few curves."}, "questions": {"value": "What fraction of trajectories are filtered in each step? Did you count the false-positives, e.g. a useful reasoning turn get discarded, because no explicitly final answer was provided.\n\nCan you test your method’s generality on different tasks, for example, QA, general knowledge, and use different tools, e.g. web search)?\nYour ablations focus only on early steps (first 320 steps) to show instability of trajectory filtering with high importance ratios or low probability tokens. Can you report full training curves to confirm that they do not recover in the long run?\n\nCan you give a correlation between low-probability token segments and gradient spikes over many runs and report statistics instead of only a single case?\n\nDid you try to decrease the weight of late bad turns instead of dropping the whole trajectory? Did you try to filter only the suffix after the first void turn?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jIKczrbOqK", "forum": "EplNy91Xqh", "replyto": "EplNy91Xqh", "signatures": ["ICLR.cc/2026/Conference/Submission7422/Reviewer_Pu3v"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7422/Reviewer_Pu3v"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7422/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761965177652, "cdate": 1761965177652, "tmdate": 1762919541740, "mdate": 1762919541740, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}