{"id": "ldYKqmtLm5", "number": 24235, "cdate": 1758354474094, "mdate": 1759896775249, "content": {"title": "Differentially Private One Permutation Hashing", "abstract": "Minwise hashing (MinHash) is a standard hashing algorithm for large-scale search and learning with the binary Jaccard similarity. One permutation hashing (OPH) is an effective and efficient alternative of MinHash which splits the data into $K$ bins and generates hash values within each bin. In this paper, to protect the privacy of the output sketches, we combine differential privacy (DP) with OPH, and propose DP-OPH framework with three variants: DP-OPH-fix, DP-OPH-re and DP-OPH-rand, depending on the densification strategy to deal with empty bins in OPH. Detailed algorithm design and privacy and utility analysis are provided. The proposed DP-OPH methods significantly improves the DP minwise hashing (DP-MH) alternative in the literature. Experiments on similarity search confirm the effectiveness of our proposed algorithms. We also provide an extension to real-value data, named DP-BCWS, in the appendix.", "tldr": "", "keywords": ["Differential privacy", "hashing", "Jaccard similarity"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/87938722ae22f7010c71cdce29df6419a32393e7.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper addresses the privacy of output sketches generated by One Permutation Hashing (OPH) , an efficient algorithm used to approximate Jaccard similarity for large-scale search and learning. The authors propose a framework called DP-OPH, which combines OPH with differential privacy (DP)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The strengths of the paper are as follows:\n1. The paper's originality stems from its focused investigation into the differential privacy of One Permutation Hashing (OPH) , a topic the authors note has not been well-studied. The primary contribution is the novel DP-OPH framework.\n2. The quality of the work is high, demonstrating rigor in both its theoretical and empirical sections.\n3. The paper is written with high clarity and is well-structured."}, "weaknesses": {"value": "The weaknesses of the paper are as follows:\n1. The paper's experimental solution to this is to ensure the lower bound by filtering the data points. This has two practical drawbacks, i. This approach forced the authors to discard 10% of the Webspam dataset. This is a significant utility loss before any privacy noise is even added. ii. The privacy guarantee is contingent on this pre-filtering. It is unclear how the system would handle new data points that fall below a threshold. A practitioner would have to choose to either discard the new data (losing information) or violate the privacy guarantee for that data point.\n2. The authors only develop the DP-BCWS-rand variant (i.e., no densification). The paper's own results on binary data show that the rand variant is suboptimal in many common utility regimes (i.e., when $\\epsilon > 5$) compared to densified versions. The authors state that designing densified versions for BCWS is \"non-trivial\", which effectively punts on the most promising versions of the algorithm."}, "questions": {"value": "Rebuttal questions:\n1. The $(\\epsilon, \\delta)$-DP guarantees for DP-OPH-fix and DP-OPH-re depend on a known lower bound $f$, the minimum number of non-zero elements in any data vector. In the experiments, this is handled by filtering the data, which resulted in discarding 10% of the Webspam dataset. This pre-filtering is a utility loss that is not captured in the subsequent precision/MSE plots. How should a practitioner using this framework handle new, incoming data points that fall below the chosen threshold $f$? Must they be discarded (losing data) or processed (violating the stated $(\\epsilon, \\delta)$-DP guarantee)?\n2. How was the value of $\\delta=10^{-6}$ chosen? \n3. The authors state that designing densified DP-BCWS is non-trivial. Could you please elaborate on the specific technical challenges that prevent the application of the DP-OPH-fix/re strategies to the weighted case?\n4. To make the impact clearer, could the authors briefly comment on the practical consequences? For example, does using the correct bound result in a significantly larger $N$ compared to the flawed calculation in the prior work?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics review needed."}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "BbeFJoOlmp", "forum": "ldYKqmtLm5", "replyto": "ldYKqmtLm5", "signatures": ["ICLR.cc/2026/Conference/Submission24235/Reviewer_yXfd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24235/Reviewer_yXfd"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24235/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761028059653, "cdate": 1761028059653, "tmdate": 1762943009489, "mdate": 1762943009489, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper develops differential privacy schemes for popular hashing algorithms with Jaccard similarity: the MinHash and one permutation hashing. For OPH, it provides algorithms for various re-densification approaches, including fixed and randomized variants. The DP mechanism is quite simple: it's the randomized response technique that flips bits with a certain probability. Both privacy and utility are analyzed for various DP-OPH and DP-MinHash."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The main strength of this paper is to fill in the gap between DP and hashing for Jaccard similarity, in particular by fixing an issue of an early paper for MinHash. The evaluation is quite comprehensive, with various metrics such as sparsity v.s. the privacy parameter of DP v.s. MSE, precision etc. The theoretical claims are sound and proofs are provided and they seem correct to me."}, "weaknesses": {"value": "The DP techniques used are straightforward, the analysis is also standard, so it does not bring new many insights into the scene. The proof boils down to calculating the quality of estimator under randomized response technique. It is quite thin on the front of technical novelty and significance. Maybe one axis that could be improved is to further reduce the variance of the estimator. A minor weakness is on the presentation, e.g., Theorem 3.6 is presented in a very cumbersome way, I think it's fine to present the full statement in the appendix, but in the main body of the paper this theorem contains too many notations and quantities and is very hard to parse. Authors could consider to use a simplified/condensed version in the main body."}, "questions": {"value": "For Theorem 3.6, it seems the variances do not depend on at all? Could you comment on how parameters of DP affect the variances?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UX0eQ9dHhQ", "forum": "ldYKqmtLm5", "replyto": "ldYKqmtLm5", "signatures": ["ICLR.cc/2026/Conference/Submission24235/Reviewer_mUNu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24235/Reviewer_mUNu"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24235/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761099508131, "cdate": 1761099508131, "tmdate": 1762943009255, "mdate": 1762943009255, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a concise review of sketching methods for estimating Jaccard similarity, including MinHash, one-permutation hashing, and two of its variants.  \n\nIt then introduces differentially private versions of these sketches, all based on randomized response techniques.  \n\nAn experimental study is conducted to evaluate and compare their practical performance."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is remarkably well written. It presents one-permutation hashing—including its motivation, relevant literature, and underlying techniques—in a clear and well-organized manner.\n\n2. It provides a solid mini-survey of differentially private variants of one-permutation hashing and includes a comparative experimental evaluation of their performance."}, "weaknesses": {"value": "1. From the experimental results, the simple DP-OPH-rand algorithm appears to achieve the best performance for a reasonable range of $\\epsilon$. Even for very large $\\epsilon$, its performance remains comparable to that of the more complex variants.\n\n\n2. It might be clearer to present DP-OPH-rand (Algorithm 5) before Algorithm 4. In addition, the unbiased estimator and its variance analysis for Algorithm 5 seem to be missing and would strengthen the presentation if included.\n\n\n     Since Sections 2 and 3.1 follow the order *MinHash → OPH → OPH-fix/OPH-re*, it would improve consistency and readability if Section 3.2 adopted the same order when introducing the corresponding privatized variants.\n\n2. The proposed algorithms are largely direct combinations of existing techniques."}, "questions": {"value": "Some minor comments on the writing:\n\n1. The unbiased estimator for the hashes seems to be an important part of the algorithms’ interfaces. However, they are not included in the pseudocode. For instance, the estimators for Algorithms 4 and 6 are only presented later, in Theorem 3.5 on page 7.\n\n2. The variance analysis in Theorem 3.6 is somewhat difficult to interpret. First, it relies on definitions provided only in the appendix. Second, it lacks textual explanation or comparison of the bounds. As a result, it is not entirely clear why these results are included in the main body of the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "oR7CC7A3L0", "forum": "ldYKqmtLm5", "replyto": "ldYKqmtLm5", "signatures": ["ICLR.cc/2026/Conference/Submission24235/Reviewer_UvV5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24235/Reviewer_UvV5"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24235/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761771246277, "cdate": 1761771246277, "tmdate": 1762943008901, "mdate": 1762943008901, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper extends OPH to suit the DP setting by introducing a random permutation strategy called DP-OPH. By theoretically validating the DP-OPH's DP ability, it can provide privacy protection of OPH and empirically present better performance compared with DP-MH."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Theoretical proof of the privacy protection property of DP-OPH.\n2. Experiments showing the superior retrieval performance of DP-OPH over DP-MH."}, "weaknesses": {"value": "1. The novelty is limited. This paper only extends the privacy ability of OPH. The proof seems to be a little bit similar to previous papers.\n2. Lack of experiments on more bits.\n3. The better retrieval performance seems to be benefited from the introduction of OPH not the novel privacy protection strategy as the retrieval performances of DP-OPH-fix and DP-MH on Webspam are really close.\n4. The empirical justifications are limited. More experiments on CIFAR10, CIFAR100, MSCOCO, and Flickr30k would be great. Better empirically performance can only be validated by thoroughly experiments.\n5. $\\epsilon$ is too big for privacy concern. In practice, $\\epsilon$ should be less than 0.1.\n6. [1,2] are two practical post-hoc methods (Randomized Response) for DP-Hashing. Please compare with them for justify the performance and privacy protection.\n7. The robust ϵ-DP analysis for the densified variants (DP-OPH-fix and DP-OPH-re) is heavily reliant on the assumption of a lower bound (f) on the number of non-zero elements in the data vector. If the true sparsity is heterogeneous or if f is set too high (excluding sparse data points), the DP guarantee either loosens or the utility suffers significantly by unnecessarily removing data points.\n\n  \n[1] Stanley L. Warner. Randomized response: A survey technique for eliminating evasive answer bias. Journal of the American Statistical Association, 60(309):63–69, 1965.\n\n[2] Yimu Wang, Shiyin Lu, and Lijun Zhang. 2020. Searching Privately by Imperceptible Lying: A Novel Private Hashing Method with Differential Privacy. In Proceedings of the 28th ACM International Conference on Multimedia (MM '20)."}, "questions": {"value": "1. Please add the performance of OPH and MH (without random perturbation) to see why DP-OPH gets better performance. I do not get which partly contributes the most, the ‘new approach’ OPH or the random perturbation strategy.\n2. Please add more experiments on bigger datasets and more bits to justify the superior performance of DP-OPH.\n3. Please add experiments with adequate and practical choices of $\\epsilon$\n4. Please compare with [1,2] mentioned in Weakness.\n5. Why choose the random permutation strategy? There are some other strategies [1,2 in Weakness] for the binary case. Please compare them theoretically and empirically.\n6. See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "invoSWcZIC", "forum": "ldYKqmtLm5", "replyto": "ldYKqmtLm5", "signatures": ["ICLR.cc/2026/Conference/Submission24235/Reviewer_6Wxa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24235/Reviewer_6Wxa"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24235/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761908021469, "cdate": 1761908021469, "tmdate": 1762943008668, "mdate": 1762943008668, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}