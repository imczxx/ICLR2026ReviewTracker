{"id": "zZj48KOY3M", "number": 21987, "cdate": 1758324370894, "mdate": 1759896892372, "content": {"title": "PolypDB: A Curated Multi-Center Dataset for Development of AI Algorithms in Colonoscopy", "abstract": "Colonoscopy is the primary method for examination, detection, and removal of polyps.  However, challenges such as variations among the endoscopists' skills, bowel quality preparation, and the complex nature of the large intestine contribute to high polyp miss-rate. These missed polyps can develop into cancer later, underscoring the importance of improving the detection methods. To address this gap of lack of publicly available, multi-center large and diverse datasets for developing automatic methods for polyp detection and segmentation, we introduce PolypDB, a large scale publicly available dataset that contains 3934 still polyp images and their corresponding ground truth from real colonoscopy videos.  PolypDB comprises images from five modalities: Blue Light Imaging (BLI), Flexible Imaging Color Enhancement (FICE), Linked Color Imaging (LCI), Narrow Band Imaging (NBI), and White Light Imaging (WLI) from three medical centers in Norway, Sweden, and Vietnam. We provide a benchmark on each modality and center, including federated learning settings using popular segmentation and detection benchmarks. PolypDB is public and can be downloaded at \\url{https://osf.io/xxxx/}. More information about the dataset, segmentation,  detection, federated learning benchmark and train-test split can be found at \\url{https://github.com/xxxxx/PolypDB}.", "tldr": "PolypDB: A Curated Multi-Center Dataset for Development of AI Algorithms in Colonoscopy", "keywords": ["Colonoscopy", "Polyp Segmentation", "Multi-Center Dataset", "Medical Image Analysis", "Deep Learning", "Federated Learning", "Adversarial Robustness"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3569489e0c2f1b70f363b02c89c85511a68d2842.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors present PolypDB, a public multi-center colonoscopy polyp image dataset of 3,934 still images across five imaging modalities (WLI, NBI, LCI, BLI, FICE) and three medical centers, and provide baseline benchmarks for segmentation, detection, federated learning, and adversarial robustness. They claim the dataset fills a gap in publicly available multi-modality, multi-center polyp data and release splits and baseline code."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The most significant strength is the collection of data from three distinct medical centers and five different imaging modalities (BLI, FICE, LCI, NBI, WLI). This is crucial for developing AI models that can generalize across varied clinical settings, patient populations, and equipment, which is a common limitation in medical image analysis\n2. The provision of both pixel-precise segmentation masks and bounding box annotations for all polyps greatly enhances the dataset's utility for various computer vision tasks, including both segmentation and detection.\n3. The paper offers a thorough evaluation of numerous state-of-the-art segmentation and detection models, as well as federated learning approaches. These benchmarks serve as a robust baseline and guide for future research, demonstrating the dataset's immediate applicability.\n4. The meticulous inclusion and exclusion criteria, coupled with expert gastroenterologist verification and annotation, ensure high clinical relevance and data quality. The focus on overcoming high polyp miss-rates highlights its potential real-world impact."}, "weaknesses": {"value": "The manuscript overclaims the dataset’s multi-modality and multi-center value while leaving critical methodological and transparency gaps unaddressed.Below are concrete problems that must be fixed:\n1. The paper primarily focuses on dataset creation and benchmarking existing methods. While this is valuable, the paper lacks novel methodological contributions or new insights into why certain models perform better on specific modalities or how to best leverage the multi-modality aspect beyond simple concatenation or independent training. \n2. While the paper states the dataset's diversity, it provides limited in-depth analysis of the characteristics of polyps across modalities and centers. For example, are certain polyp types more prevalent in specific modalities or centers? What are the inherent difficulties within each modality/center? A more granular statistical breakdown could reveal insights beyond just overall numbers.\n3. While inclusion/exclusion criteria are provided, there's no explicit discussion of potential biases introduced by these criteria. Furthermore, the paper briefly mentions challenges like low recall results for NBI detection, but a more thorough discussion on the underlying reasons for these performance gaps across modalities and models would be beneficial.\n4. The dataset consists of still polyp images from real colonoscopy videos. While the authors mention aiming to develop a comprehensive video dataset in future work, the current dataset's reliance on still images might limit its utility for temporal analysis, which is crucial for real-time CAD systems in colonoscopy."}, "questions": {"value": "1. Could the authors provide a more detailed statistical breakdown of polyp characteristics for each imaging modality and medical center? This would help researchers understand the specific challenges and strengths of each sub-dataset.\n2. For the exclusion criteria, how was this ambiguity resolved during annotation, or were such frames simply excluded? What was the inter-observer variability among the expert gastroenterologists during annotation and cross-verification, especially for challenging cases?\n3. While a good range of models are used, could the authors elaborate on the specific criteria for selecting these particular segmentation and detection models? Were there other contemporary methods considered and why were they excluded? \n4. Given the safety-critical nature of medical imaging, please expand the adversarial robustness analysis using more advanced attack methods and discuss the implications of such vulnerabilities in a clinical context in greater detail.\n5. The paper states that the multi-center dataset allows for different types of equipment and imaging protocols. Can the authors provide more specifics on the variations in equipment models and imaging protocols used across the three centers, and discuss how these variations were handled or standardized during data collection to ensure comparability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics review needed."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NDwjC05Dha", "forum": "zZj48KOY3M", "replyto": "zZj48KOY3M", "signatures": ["ICLR.cc/2026/Conference/Submission21987/Reviewer_4fik"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21987/Reviewer_4fik"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21987/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761818421057, "cdate": 1761818421057, "tmdate": 1762942009504, "mdate": 1762942009504, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to address the issue that existing publicly available datasets for polyp detection and segmentation in colonoscopy are often limited in scale, diversity, and multi-center representation, leading to high polyp miss rates and poor generalizability of AI algorithms in clinical settings. To overcome this problem, the authors propose PolypDB, a large-scale, multi-center, and multi-modality dataset that includes 3934 polyp images with pixel-precise ground truth and bounding box annotations, collected from three medical centers in Norway, Sweden, and Vietnam across five imaging modalities: BLI, FICE, LCI, NBI, and WLI. The dataset is designed to enhance robustness by capturing regional and demographic variations, and it provides comprehensive benchmarks for segmentation, detection, and federated learning using state-of-the-art models such as DuAT, SSFormer-L, and YOLO variants. Overall, PolypDB serves as a valuable resource to advance computer-aided diagnosis systems by improving their adaptability and reliability in real-world colonoscopy procedures."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses an important limitation in current medical AI datasets the lack of large, diverse, and multi-center colonoscopy data by introducing PolypDB, which includes data from multiple countries and imaging modalities.\nThe dataset is well-annotated, providing both pixel-level segmentation masks and bounding boxes, which enhances its utility for a variety of computer vision tasks (detection, segmentation, and federated learning).\nThe inclusion of multiple imaging modalities (BLI, FICE, LCI, NBI, and WLI) is commendable, as it promotes research into modality-aware and cross-domain model generalization.\nThe paper benchmarks several state-of-the-art algorithms (DuAT, SSFormer-L, YOLO variants), establishing a useful baseline for future studies."}, "weaknesses": {"value": "The dataset size (3,934 images) and severe imbalance across modalities significantly undermine the claim of “large-scale” and “multi-modal,” limiting its practical generalization potential.\nCenter-wise data imbalance (with one center contributing the vast majority of samples) introduces potential geographic and demographic bias, reducing representativeness.\nThe dataset construction lacks methodological innovation; it mainly relies on manual annotation without novel data acquisition or annotation techniques.\nThe experimental design is inconsistent with the paper’s stated goals: key experiments are restricted to the WLI modality, and cross-modality or federated comparisons are insufficiently explored."}, "questions": {"value": "Regarding the innovative part, I have few question\n1/  PolypDB contains 3,934 polyp images, which is not considered a large dataset but rather a standard-sized one.\n2/  PolypDB exhibits extreme imbalance in sample sizes across modalities (WLI: 3,558 images, LCI: 60 images, BLI: 70 images, FICE: 70 images, NBI: 146 images), which impacts model generalization. Furthermore, the paper states, “due to the minimal number of images present in both centers, we exclude them from the experiment” (Section 3.1), indicating that the small-sample modalities were excluded from certain experiments. This exclusion fails to reflect the diversity inherent in PolypDB.\n3/  PolypDB collected data from three centers (Norway, Sweden, Vietnam), but Section 2.3 of the documentation shows that Center 2 (Sweden) contributed only 40 images (30 WLI + 10 NBI), far fewer than Center 1 (2,588 images) and Center 3 (1,200 images). This suggests that center-based data bias may introduce geographical bias, undermining PolypDB's representativeness and credibility.\n4/  The construction process of PolypDB did not introduce novel methods, relying instead on manual annotation, and thus no innovative aspects were observed.\n5/  The literature citations are somewhat outdated. For instance, in Section 1, most of the referenced studies were published in 2021 or earlier, rendering the current status presented in the paper obsolete. Additionally, in Table 1, the most recent dataset survey cited is PolypGen (Ali et al., 2023), which may not necessarily represent the latest advancement in this field.\n\nRegarding the technical part, I have several doubts:\n1/  In terms of data partitioning, the paper employs an 80%-10%-10% split ratio but fails to clarify whether it accounts for class imbalance issues (e.g., only 146 images in the NBI modality). It also does not provide statistical tests (e.g., p-values) to substantiate the significance of its findings.\n2/  Section 2.3 refers to the data in Center 3 as zzzz, but in Section 2.4 it is named zzz.\n3/  The federated learning section states that “image normalization uses local mean and standard deviation,” but fails to specify the calculation method, potentially leading to ambiguity.\n（Score  10/15）\nRegarding the experimental part, I have several doubts:\n1/  The detection results show precision scores of 1.000 for some models (e.g., YOLOv8 on BLI). Doesn't this strongly indicate overfitting, likely due to the small scale of the test sets for certain modalities?\n2/  The choice to conduct center-wise experiments exclusively on WLI images (Sec 3.1) seems to contradict the paper's emphasis on multi-modality. If the dataset's strength is its diversity, why weren't cross-modality or multi-modal learning experiments conducted to demonstrate improved generalization?\n3/  Table 5 presents both the experimental results of federated partitioning on WLI and a qualitative comparison of FGSM attack partitioning methods on the PolypDB dataset. However, the paper provides limited explanation regarding federated partitioning, merely citing the literature reference (McMahan et al. (2017)), which serves as the foundation for federated partitioning but does not address FGSM. The direct combination of federated partitioning with FGSM for demonstration appears peculiar, especially since the final experimental results outperform the unimodal WLI approach. Yet the paper merely states: “showing that privacy-preserving training across centers is feasible without substantial loss in accuracy.”\n\nRegarding the structural and presentation i found few issues:\n1/  The conclusion mentions “FGSM” without prior mention in the abstract or introduction.\n2/  Figure 5 is placed in the middle of the references section, which is strange.\n3/  Qualitative results and their analysis are separated: the qualitative result figures (Figure 2 and Figure 3) are placed in the appendix, while the analysis of these results is located in Section 4.2."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "kgKeFfnoAL", "forum": "zZj48KOY3M", "replyto": "zZj48KOY3M", "signatures": ["ICLR.cc/2026/Conference/Submission21987/Reviewer_hEKZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21987/Reviewer_hEKZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21987/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761880735974, "cdate": 1761880735974, "tmdate": 1762942009192, "mdate": 1762942009192, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a novel multi-center, multi-modality dataset for polyp detection and segmentation (PolypDB), addressing the need for greater diversity and generalizability in colonoscopy CAD research. Benchmarking and federated learning studies demonstrate strong potential for different research tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. important and timely topic\n2. multi-centric and multi-modal data in the database included, in particular the multi-modal data is novel\n3. extensive benchmarking both modality and center-wise"}, "weaknesses": {"value": "1. Annotation were only performed by a single annotator (senior research associate), although multiple experts did a quality review it is still challenging since polyps might not have clear boundaries\n2. Benchmarking methods: The criteria for choosing the benchmarked segmentation and detection models are not well justified, the chosen methods do not present the current state of the art, e.g. [1,2,3]. The study could be strengthened by including recent strong baselines such as nnU-Net, Segment Anything (SAM)-based methods, or Transformer-based architectures for medical image segmentation.\n3. While the paper introduces a new dataset, it could better position PolypDB in relation to existing large datasets (e.g., Kvasir-SEG, CVC-VideoClinicDB, …) to emphasize its relative strengths and weaknesses\n4. Challenging cases: a more closely investigation regarding edge cases such as small, flat, or concealed polyps (representation in the dataset as well as benchmarking) could be beneficial\n5. Dataset statistics not clearly summarized: A concise table summarizing dataset characteristics (e.g., number of images per modality, per center, and per polyp size) would improve clarity and reproducibility\n\n[1] https://link.springer.com/chapter/10.1007/978-3-031-72104-5_43\n[2] https://link.springer.com/article/10.1186/s12880-025-01661-w\n[3] https://openreview.net/forum?id=sz9baxSuxF"}, "questions": {"value": "- please justify the chosen benchmarking methods, it would be good to include more recent SOTA methods\n- did you pre-train the chosen segmentation/detection methods with any open datasets?\n- How does your dataset compare to existing large-scale datasets such as Kvasir-SEG or CVC-VideoClinicDB in terms of diversity, benchmarking and clinical relevance, and what are its relative strengths and limitations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "tIjwAhBjQj", "forum": "zZj48KOY3M", "replyto": "zZj48KOY3M", "signatures": ["ICLR.cc/2026/Conference/Submission21987/Reviewer_DFnR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21987/Reviewer_DFnR"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21987/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993919622, "cdate": 1761993919622, "tmdate": 1762942008887, "mdate": 1762942008887, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents PolypDB, a large collection of polyp images from colonscopy from different modalities. The data is sourced from multiple centers accross different countries. The data is annotated for segmentation task. Experiments are done using different models to show the performances."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- Large collection of polyp images and their annotation is given.\n- The data is collected from multiple centers accross three countries.\n- Different modalities are used. \n- Experiments are done to show the validity of the data for segmentaion task."}, "weaknesses": {"value": "- The annotation is limited to segmentation only. Other tasks would improve the value of the data. Thus the work will be more justified with the title. \n- Experiments are done using rather old models. Sota models should have been used."}, "questions": {"value": "Is there any differences in performances for the data collected from different centers, particualry two different parts of the world?"}, "flag_for_ethics_review": {"value": ["Yes, Other reasons (please specify below)"]}, "details_of_ethics_concerns": {"value": "why ethical review was not needed for two of the centers is not clear."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "V2BALSLGHa", "forum": "zZj48KOY3M", "replyto": "zZj48KOY3M", "signatures": ["ICLR.cc/2026/Conference/Submission21987/Reviewer_BfZG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21987/Reviewer_BfZG"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21987/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762066734663, "cdate": 1762066734663, "tmdate": 1762942008486, "mdate": 1762942008486, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}