{"id": "3osmz8XzCR", "number": 18893, "cdate": 1758291811316, "mdate": 1759897074901, "content": {"title": "Do you know what k-means? Clustering with constant number of samples", "abstract": "Clustering is one of the most important tools for analysis of large datasets, and perhaps the most popular clustering algorithm is Lloyd's algorithm for $k$-means.\nThis algorithm takes $n$ vectors $V=[v_1,\\dots,v_n]\\in\\mathbb{R}^{d\\times n}$ and outputs $k$ centroids $c_1,\\dots,c_k\\in\\mathbb{R}^d$; these partition the vectors into clusters based on which centroid is closest to a particular vector. We present a classical $\\varepsilon$-$k$-means algorithm that performs an approximate version of one iteration of Lloyd's algorithm with time complexity $\\widetilde{O}\\big(\\frac{\\|V\\|_F^2}{n}\\frac{k^{2}d}{\\varepsilon^2}(k + \\log{n})\\big)$, exponentially improving the dependence on the data size $n$ and matching that of the \"$q$-means\" quantum algorithm originally proposed by Kerenidis, Landman, Luongo, and Prakash (NeurIPS'19). Moreover, we propose an improved $q$-means quantum algorithm with time complexity $\\widetilde{O}\\big(\\frac{\\|V\\|_F}{\\sqrt{n}}\\frac{k^{3/2}d}{\\varepsilon}(\\sqrt{k}+\\sqrt{d})(\\sqrt{k} + \\log{n})\\big)$ that quadratically improves the runtime of our classical $\\varepsilon$-$k$-means algorithm in several parameters.\nOur quantum algorithm does not rely on quantum linear algebra primitives of prior work, but instead only uses QRAM to prepare simple states based on the current iteration's clusters and multivariate quantum mean estimation. Our upper bounds are complemented with classical and quantum query lower bounds, showing that our algorithms are optimal in most parameters.\nFinally, we conduct numerical experiments that evidence the substantially improved runtime our classical algorithm over the standard Lloyd's algorithm, thus being one of the first cases of a practical dequantised algorithm.", "tldr": "We propose approximate classical and quantum versions of Lloyd's k-means algorithm that require only a constant number of samples", "keywords": ["k-means", "clustering", "quantum algorithms", "unsupervised learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/160ba6b087d7dcc85550695cac22edf97163eee8.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces ε-k-means, a classical approximation of Lloyd’s k-means algorithm that achieves exponential improvements in runtime dependence on data size, matching the efficiency of the q-means quantum algorithm by Kerenidis et al. (NeurIPS 2019). It also proposes an enhanced q-means algorithm that achieves a quadratic speedup over the new ε-k-means in several parameters. The quantum version relies only on QRAM-based state preparation rather than full quantum linear algebra primitives."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses an interesting and worthwhile topic. The reasoning and justification behind the proposed approach appear well-founded and convincing."}, "weaknesses": {"value": "The paper is difficult to follow due to its dense mathematical notation. The experimental evaluation is limited, as the proposed algorithm is compared to the original version only on synthetic datasets with fixed numbers of features and clusters. These parameters should have been varied to thoroughly assess effectiveness. Additionally, many standard synthetic datasets designed for clustering evaluation are omitted. The evaluation relies solely on RSS and runtime, neglecting other important metrics such as silhouette score, cluster sizes correlation, or external measures like Adjusted Rand Index (ARI) and Normalized Adjusted Rand Index (NARI) when ground truth labels are available (or against the original k-means result). Since each metric captures different aspects of clustering quality, this narrow evaluation is insufficient. Moreover, experiments involving quantum implementations are entirely missing. Finally, the paper omits relevant related work, including Poggiali, A., Berti, A., Bernasconi, A., Del Corso, G. M., & Guidotti, R. (2024). Quantum clustering with k-means: A hybrid approach. Theoretical Computer Science, 992, 114466."}, "questions": {"value": "Questions can be derived from the above weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "OqsjV9Xlw8", "forum": "3osmz8XzCR", "replyto": "3osmz8XzCR", "signatures": ["ICLR.cc/2026/Conference/Submission18893/Reviewer_7Cjf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18893/Reviewer_7Cjf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18893/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761811299339, "cdate": 1761811299339, "tmdate": 1762930863362, "mdate": 1762930863362, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "I am not familiar with quantum algorithms, so this review will only cover the classical results presented in the paper.\n\nThis paper presents a quantum-inspired algorithm for k-means. The authors claim that the running time of their algorithm achieves an exponential improvement in the dependence in n (number of data points) compared to classical k-means. They complement this with lower bounds claiming optimality for most parameters. Finally they experimentally compare their algorithm to the classical k-means algorithm."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper’s main strength is the introduction of another quantum-inspired algorithm, which enriches this promising research area."}, "weaknesses": {"value": "There are several critical issues with this paper.\n\nThe running times as stated require a preprocessing step that requires $\\tilde{O}(nd)$ time. So there is no “exponential speed up”.\n\nThe algorithm is essentially a mini-batch style algorithm, but there is no discussion of existing mini-batch approaches.\n\nThe experiments are lacking in several ways:\n1) The paper only considers synthetic datasets - it should consider real world datasets such as mnist etc…\n2) The paper only reports residual sum of squares - it should report ARI and NMI\n3) The algorithm should be benchmarked against mini-batch k-means at the very least. Other approaches such as coresets would also be nice. \n4) No code is provided"}, "questions": {"value": "See Weaknesses. Additional questions:\n- The authors consider a version of k-means which converges if the movement of the centers falls below a certain threshold $\\tau$. This is fine, but shouldn’t the parameter $\\tau$ appear somewhere in the running time? Do your results work without this assumption?\n- How does scaling the input vectors affect your running times?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OR4BhwrfFg", "forum": "3osmz8XzCR", "replyto": "3osmz8XzCR", "signatures": ["ICLR.cc/2026/Conference/Submission18893/Reviewer_yoqP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18893/Reviewer_yoqP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18893/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761907269128, "cdate": 1761907269128, "tmdate": 1762930862858, "mdate": 1762930862858, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a classical $\\varepsilon$-$k$-means (EKMeans)\nalgorithm that performs an exponential reduction in dependence on\ndata size $n$ while maintaining comparable clustering quality. The\nalgorithm estimates cluster sizes and centroids by drawing only a\nconstant number of sampled data points in each iteration, making the\ntime complexity of each iteration almost independent of $n$. In addition,\nthis paper presents an improved $q$-means quantum algorithm that\nquadratically improves the runtime of EKMeans algorithm in several\nparameters. This algorithm avoids complex quantum linear-algebra operations,\nrelying solely on QRAM access and quantum mean estimation to efficiently\nupdate cluster centers. Numerical experiments show that EKMeans achieves\na significant speedup over the standard Lloyd's algorithm\non large-scale datasets while maintaining stable clustering quality.\nThis research is the first time to demonstrate. how the core ideas of quantum algorithms\ncan be transformed into efficient classical algorithms through dequantization."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper proposes a constant-sample, approximate $k$-means algorithm\n(EKMeans) that maintains clustering quality while making the iteration\ntime almost independent of the data size $n$; and it also proposes\nan improved quantum algorithm, forming a theoretical system that mutually\nreinforces classical and quantum approaches.\n\n2. $k$-means is one of the most commonly used clustering algorithms, so the related research has both theoretical and practical values.\n\n3. The EKMeans algorithm in this paper provides a constant-time iterative\nk-means version that can be implemented on conventional hardware without\nrelying on quantum hardware. It serves as a key example bridging QML\nand classical randomized algorithms, deepening the understanding of\nthe boundaries between classical and quantum computing capabilities.\n\n4. This paper is well structured and logically rigorous. It clearly defines\nthe problem and its background."}, "weaknesses": {"value": "1. All experimental designs are based on synthetic data for comparison. Why not use real-world datasets?\n\n2. The figures can be improved. E.g., the color scheme of the curves does not adequately distinguish certain parameter settings, such as  $\\varepsilon=0.0$ vs. $\\varepsilon=0.2$. \n\n3. The title of the paper could be improved."}, "questions": {"value": "1. In the experitmental section,  the authors use only synthetic data. What is the reason for not using real-world datasets?\n\n2. Each iteration of k-means modifies the cluster partition (assigning different points to different clusters). Theoretically, each resampling iteration should reflect the latest cluster structure changes. However, if the same batch of P and Q is consistently used, these samples may primarily represent the structure at the initial partition. As the centroids gradually shift and boundaries adjust, the sampled points may no longer accurately represent the current cluster distribution, and the final updated centroids may be slow to react to the  real changes in some clusters. The algorithm may prematurely fall into a  locally stable solution (appearing convergent but with biases), especially when the initial sampling is not uniform or the cluster\ndistribution is complex. Do you have any theoretical guarantee or analysis against this issue?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "MSQXMUx1oJ", "forum": "3osmz8XzCR", "replyto": "3osmz8XzCR", "signatures": ["ICLR.cc/2026/Conference/Submission18893/Reviewer_ge3j"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18893/Reviewer_ge3j"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18893/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761967051479, "cdate": 1761967051479, "tmdate": 1762930862045, "mdate": 1762930862045, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}