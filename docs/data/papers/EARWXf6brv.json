{"id": "EARWXf6brv", "number": 18527, "cdate": 1758288787202, "mdate": 1759897098018, "content": {"title": "Battery-Sim-Agent: Leveraging LLM-Agent for Inverse Battery Parameter Estimation", "abstract": "Parameterizing high-fidelity ``digital twins'' of batteries is a critical yet challenging inverse problem that hinders the pace of battery innovation. Prevailing methods formulate this as a black-box optimization (BBO) task, employing algorithms that are sample-inefficient and blind to the underlying physics. In this work, we introduce a new paradigm that reframes the inverse problem as a reasoning task, and present \\textsc{Battery-Sim-Agent}, the first framework to deploy a Large Language Model (LLM) agent in a closed loop with a high-fidelity battery simulator. The agent mimics a human scientist's workflow: it interprets rich, multi-modal feedback from the simulator, forms physically-grounded hypotheses to explain discrepancies, and proposes structured parameter updates. On a systematically constructed benchmark suite spanning diverse battery chemistries, operating conditions, and difficulty levels, our agent significantly outperforms strong BBO baselines like Bayesian optimization in identifying accurate parameters. We further demonstrate the framework's capability in complex long-horizon degradation fitting tasks and validate its practical applicability on real-world battery datasets. Our results highlight the promise of LLM-agents as reasoning-based optimizers for scientific discovery and battery parameter estimation.", "tldr": "", "keywords": ["Battery Design", "LLM-Agent"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8ded9a90fb4878ffec340d1fc05a7af6771fbf8d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents an LLM-simulator-in-the-loop optimization method for inverse battery parameter estimation. It uses multimodal features, including numerical data and plot images."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The usage of LLM on this specific application is quite innovative."}, "weaknesses": {"value": "__Baselines.__ The paper uses BO as the baseline but does not clearly specify which acquisition function is used, nor does it provide sufficient detail to justify the fairness of the comparison (for example, in terms of time budget, number of function evaluations etc). Moreover, only one baseline is used, yet it is referred to as a “strong” baseline.\n\n__Details on the LLM used.__ The description of the LLM is unclear. For instance, are the models trained locally from scratch, or are they accessed through OpenAI API calls? Additionally, according to [1], GPT-OSS is not an image–text model. It is therefore unclear how the LLM is used to extract image features in this case. This concern needs to be addressed.\n\n__Loss definition.__ It appears that the Battery-Sim-Agent uses a different loss definition from the baseline. If I understand correctly, the baseline loss is defined in Equation (1), while the Battery-Sim-Agent employs a multi-objective loss defined in Equation (2). This does not seem to be a fair comparison. For example, using multi-objective BO [2, 3, 4] with an appropriate acquisition function might provide a fairer baseline.\n\n__Missing citation and comparison to a key paper.__ While the paper is quite novel within the battery parameter estimation problem, similar techniques have already been presented in [5], where an LLM is also utilized for parameter inference in physical systems. Omitting this related work significantly weakens the paper’s claim to novelty, and a detailed comparison or discussion is necessary.\n\n[1] https://openai.com/index/introducing-gpt-oss/\n\n[2] Preferential Multi-Objective Bayesian Optimization (Astudillo, et al. 2024)\n\n[3] Efficient computation of expected hypervolume improvement using box decomposition algorithms (Yang, et al. 2019)\n\n[4] A Flexible Framework for Multi-Objective Bayesian Optimization using Random Scalarizations (Paria, et al. 2019)\n\n[5] SimLM: Can Language Models Infer Parameters of Physical Systems? (Memery, et al. 2024)"}, "questions": {"value": "__Q1.__ The paper requires significant improvement in clarity, scientific rigor, and baseline selection. I would consider increasing my score if the issues highlighted in the weaknesses are adequately addressed.\n\n__Q2.__ It would also be helpful to include a counter-example where the Battery-Sim-Agent fails. For instance, when the initial memory $M_0$ provided by the user is incorrectly specified. Such a case could be interpreted as a wrongly defined prior, and it would be interesting to observe how the LLM behaves under this condition.\n\n__Q3.__ are the target protocols $Y_p$ in eq (1) all have the same range? (i.e trough normalization/standardization)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vdnlqiwJAA", "forum": "EARWXf6brv", "replyto": "EARWXf6brv", "signatures": ["ICLR.cc/2026/Conference/Submission18527/Reviewer_vtJ7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18527/Reviewer_vtJ7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18527/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761580737386, "cdate": 1761580737386, "tmdate": 1762928220480, "mdate": 1762928220480, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a LLM-based framework for inverse design battery parameter estimation. This complicated optimisation problem arises when trying to match microscopic parameters to experimentally measurable observables. Traditionally, this was done using black-box optimisers like Bayesian optimisation. The workflow consists of two phases—a exploration phase and an optimisation loop afterwards, in which the parameter updates are suggested by the LLM. Simulation benchmark tasks are defined and tested comparing their approach with and without reasoning with BO. Long-horizon degradation fitting and real world validation benchmarks are also included."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper tests the interesting idea of replacing novel black-box optimisers with a LLM and applies this to estimating parameters of complicated physical systems."}, "weaknesses": {"value": "Some of the benchmark results do not seem in line with the  claims of the paper. \n\n- \"our agent significantly outperforms strong BBO baselines\", in Table 2 BO outperforms the agent on 2 of 5 chemistries in the \"extreme mode\".\n-  It is said \"Figure 4 shows convergence behaviour ... revealing robust optimization\", in panel (b) a MAPE  of 230 does not suggest convergence.\n\nThe paper does not discuss limitations of the approach (e.g. provides no convergence guarantees). Comparisons against related approaches that make use of BO plus an expert (LLM) would be helpful. (e.g. https://arxiv.org/abs/2410.10452, Principled Bayesian Optimisation in Collaboration with Human Experts )\n\nThe design choices of Algorithm 1 are not sufficiently explained and ablation studies would be insightful.\n\n- Why is there a random trial and error warm up, instead of prompting the LLM to explore?\n- Why is the LLM prompted to predict the parameter updates rather than directly the next set of parameters?"}, "questions": {"value": "- The tasks based on the 5 chemistries seem to be designed by varying a few or even just a single of the experimental parameters. It seems that the LLM then starts its search from the original unperturbed parameter. This seems very different than an actual experimentally fitting task. Furthermore, the LLM prompt suggests to only modify only some parameters which does not seem fair, since the tasks seem sparse by construction and the BO probably does not \"know\" that.\n- The description of Algorithm 1 does not seem consistent with the prompt. Are the pertubations $\\delta_k$ random or generated by the LLM? Is $N_w$ a fixed input?\n- I was not able to find values for the budget $T$ and learning rate $\\eta_t$, nor was I able to find details on the BO.\n- I was not able to access the source code under the link because all files besides the Read.me files gave the error \"file not found.\"\n- The problem is motivated by saying that microscopic parameters cannot be easily measured. However several of the parameters seem to be design or layout choices which should be known a priori?\n- When referring to the stability limits of the simulator for certain choices of experimental parameters, why is a decrease in resolution or step sizes not possible?\n- I do not understand Fig 2. I would expect that there are only 100 Experiment ID for each mode, and that for each ID are 3 datapoints corresponding to the 3 methods used.\n- Why is BO not tested on the real-world tasks?\n- The design or at least description of the benchmark based on the 5 chemistries and simulation seems inconsistent.\n- From the 5 listed chemistries described as \"classic, well established parameter sets\", I was not able to verify the correctness for 4 of the specifications. (Chen et al seems to use graphite SiO_x instead of graphite, O'Regan et al. seems to use NMC811 and not NMC 532,  Marquis et al. is a maths theory paper without specifying experimental parameters)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "emIhsMAoXw", "forum": "EARWXf6brv", "replyto": "EARWXf6brv", "signatures": ["ICLR.cc/2026/Conference/Submission18527/Reviewer_oibn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18527/Reviewer_oibn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18527/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761817254613, "cdate": 1761817254613, "tmdate": 1762928218547, "mdate": 1762928218547, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces an agentic optimization framework for a simulator-in-the-loop LLM agent applied to a battery inverse problem. The method is evaluated on both synthetic and real-world setups, demonstrating good performance relative to the baseline."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The studied application problem is highly relevant, and the idea of using LLMs as reasoning engines within optimization frameworks is timely. Ignoring the issue of baseline selection, the benchmarks in Section 5 are diverse and include many real-world datasets."}, "weaknesses": {"value": "The method description is insufficient. The main subsections 3.1 and 3.2 are short and list-like, and there is a lack of discussion and justification of the design choices. Below I list some weaknesses in the experimental section of the paper.\n\nExperimental setup\n\nSection 5 lacks relevant aspects discussion on the experimental setup. Instead of starting listing claims: “We conduct comprehensive experiment... Our evaluation demonstrates the superiority…”, it would be good start by explaining the high-level experimental setup and hypothesis. \n\nBaselines\n\n“Bayesian Optimization (BO): We use standard Bayesian Optimization implemented by Meta’s Ax platform (Olson et al., 2025), representing state-of-the-art black-box optimization methods commonly used in parameter estimation.”\nThis is clearly insufficient explanation of the baseline, and does not build trust that the BO baseline selection is carefully considered as all the important details are hidden such as what was acquisition function etc.\n\nMinor comments:\n\nSentences in Lines 32-34 lack citations. \nFigure 4 is not good quality. Font is too small, etc."}, "questions": {"value": "What is the main justification for framing the problem as gradual updates $\\Delta \\theta_{t}$ to the current parameter vector rather than propose new parameter configuration $\\theta_{t+1}$?\n\nEquation (1) collapses multi-objective problem into single objective. Did you consider frame the problem as multi-objective problem, and use e.g. multi-objective BO?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "u9F12Drd0a", "forum": "EARWXf6brv", "replyto": "EARWXf6brv", "signatures": ["ICLR.cc/2026/Conference/Submission18527/Reviewer_QbMG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18527/Reviewer_QbMG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18527/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761833431871, "cdate": 1761833431871, "tmdate": 1762928217626, "mdate": 1762928217626, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents BATTERY-SIM-AGENT, a framework that integrates a large language model (LLM) agent in a high-fidelity battery simulator. The agent emulates a human scientist’s workflow: it interprets rich, multimodal feedback from the simulator, forms physically grounded hypotheses to explain discrepancies, and proposes structured parameter updates.\nThe work demonstrates that LLM agents can serve as reasoning-based optimizers in scientific applications.\nTraditional digital twin approaches iteratively query a simulator and minimize the mismatch between simulated and observed data using black-box optimization. In contrast, this paper explores whether the inverse problem of battery parameter estimation can be reframed as a reasoning-driven scientific workflow guided by an LLM agent.\nIn this framework, the LLM agent functions as an AI scientist: at each iteration, it receives multimodal feedback comparing the current simulation with experimental data, identifies key discrepancies, formulates physical hypotheses (e.g., “a premature voltage drop suggests an electrolyte transport limitation”), and proposes targeted parameter updates accordingly.\n\nThe main steps of this approach:\n1)\tThe agent receives a multi-modal feedback package in a structured JSON format.\n2)\tGuided by its memory, the agent analyzes this feedback to form a causal hypothesis. The prompt encourages a scientific reasoning process\n3)\tThe agent is prompted to translate its hypothesis into a concrete, machine-actionable update, which it returns in a JSON format."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is interesting, timely, and well written.\nThe paper demonstrates that their agent can achieve 67-95% reduction in error compared to traditional black-box approaches."}, "weaknesses": {"value": "This approach relies on large language models as reasoning agents. In particular, the authors use GPT-O3. However, since the training data and internal reasoning mechanisms of GPT-O3 are not publicly known, reproducibility becomes a concern—future updates or changes to GPT-O3 could make these experiments non-reproducible."}, "questions": {"value": "* Line 231: “We initialize the memory M_0 with human expert knowledge from the literature and our own domain expertise”. What exactly was M_0? How large was M_0? Is the full M_0 available somewhere?\n\n* Line 235: “agent undergoes a warm-up phase… The resulting feedback is not for optimization, but is processed by the LLM to enrich its memory… The agent is prompted to summarize the outcomes into learned sensitivity rules”. How many new rules were learned this way? Is the full list of learned rules available somewhere?\n\n* Line 389: “What was the cost of GPT-O3”? What other language models might be suitable for these tasks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UfphYJV1lJ", "forum": "EARWXf6brv", "replyto": "EARWXf6brv", "signatures": ["ICLR.cc/2026/Conference/Submission18527/Reviewer_a8hF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18527/Reviewer_a8hF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18527/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761964086063, "cdate": 1761964086063, "tmdate": 1762928217102, "mdate": 1762928217102, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}