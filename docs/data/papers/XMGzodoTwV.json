{"id": "XMGzodoTwV", "number": 11066, "cdate": 1758188473121, "mdate": 1759897610870, "content": {"title": "From Traits to Circuits: Toward Mechanistic Interpretability of Personality in Large Language Models", "abstract": "Large language models (LLMs) have been observed to exhibit personality-like behaviors when prompted with standardized psychological assessments. However, existing approaches treat personality as a black-box property, relying solely on behavioral probing while offering limited insight into the internal mechanisms responsible for personality expression. In this work, we take a mechanistic interpretability perspective and investigate whether personality traits in LLMs correspond to identifiable internal computation paths. To this end, we construct \\textsc{TraitTrace}, a dataset designed to elicit distinct personality traits and support structural tracing. Using this dataset, we identify personality circuits as minimal functional subgraphs within the model’s computation graph that give rise to trait-specific responses. We then analyze the structural properties of these circuits across model layers and personality traits, and conduct causal interventions to probe the influence of individual components. Our findings offer a novel structural view of personality in LLMs, providing a bridge between behavioral psychology and mechanistic interpretability.", "tldr": "", "keywords": ["feature attribution", "explanation faithfulness", "probing", "hierarchical & concept explanations"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ca683b460290fa6dfe2f79816c69b5ac7126a771.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper discusses personality in LLMs, pioneering the application of mechanistic interpretability to analyze the models themselves. The authors discovered that the identified circuits are functionally complete, structurally sparse, and heavily dependent on early MLP layers, which act as causal bottlenecks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "This is a thoroughly analyzed paper. While it does not introduce a novel methodology, it rigorously analyzes and investigates personality circuits. This approach uncovers many phenomena previously unknown to the community and refutes the conjecture that \"personality is a globally diffuse property.\""}, "weaknesses": {"value": "The paper's definition of personality is oversimplified. I do not believe the Big-Five model is sufficient to encapsulate personality, which could also include, for example, dark personality traits (e.g., the Dark Triad) or aspects such as values, beliefs, and motives. The \"personality circuits\" identified in this paper actually correspond to \"Big-Five trait circuits,\" rather than the broader \"personality circuits\" as claimed. The authors should conduct further analysis on these aspects to reach a more definitive conclusion.\n\nIt is difficult for the paper to prove that these personality circuits are exclusive; they are very likely key components that are also involved in executing other semantic tasks.\n\nThe study was conducted on two relatively small and older LLMs. It remains unknown whether the conclusions can be generalized to state-of-the-art models, especially MoE-based architectures. An analysis of models like Qwen-3-30B-A3B and Qwen-3-235B-A22B would significantly enhance the paper's contribution."}, "questions": {"value": "The template used to identify personality is highly structured. It is unclear whether similar phenomena persist in more realistic, user-focused tasks such as free-form conversation, extended dialogues, or long-form writing."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "eNJ9j1n7yl", "forum": "XMGzodoTwV", "replyto": "XMGzodoTwV", "signatures": ["ICLR.cc/2026/Conference/Submission11066/Reviewer_ZUG2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11066/Reviewer_ZUG2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11066/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761065651784, "cdate": 1761065651784, "tmdate": 1762922242968, "mdate": 1762922242968, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates whether the personality of large language models can be traced to identifiable transformer circuits. Using tools from the mechanistic interpretability community, the authors identify a small set of sparse nodes in a small, pretrained LLaMA model (LLaMA-2-Chat, 7B) that are responsible for generating answers on the proposed Trait-Trace dataset. Ablation studies and causal-intervention analyses show that certain nodes within these circuits can substantially influence LLM performance on the Trait-Trace task."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The perspective of identifying interpretable circuits in Transformer models that are causally responsible for personality-like behaviors is interesting and could have important implications for safety, alignment, and the development of better chatbots.\n\n- The paper is generally well written and easy to read."}, "weaknesses": {"value": "- A major weakness lies in the evaluation. The study relies on a newly proposed Trait-Trace dataset generated by GPT-4o that focuses on single-word reactions to vignettes/trait prompts. All circuit-discovery and causal-intervention experiments depend on this fragile single-word reaction task. It is unclear what the task actually measures—the discovered circuits may merely capture distributional shifts in certain personality-related words rather than any higher-level notion of personality in LLMs. Generalization tests are essential. For example, under causal interventions/steering, do circuits discovered on Trait-Trace transfer to more complex settings (e.g., dialogue generation, storytelling, or psychometric evaluation items)? Given the authors’ access to trained psychology graduate students, such evaluations seem feasible. Demonstrating this would better justify the claim that the identified circuits reflect personality rather than confounding word-distribution shifts.\n\n- The Trait-Trace task design is too simple. The template “I’m {p}, regarding {s}, I feel very {r}” biases lexical and affective choices, making the discovered circuits specific to particular word choices rather than to general personality constructs. It remains unclear what construct this task is evaluating.\n\n- Limited conceptual insight. As framed, one could likely find circuits or sparse subgraphs for almost any language-model behavior. The authors should better demonstrate—or at least discuss—why these circuits matter and why the discovered early-layer MLP features align with human intuitions."}, "questions": {"value": "If you replace the prompt with random fillers unrelated to personality, would the intervened circuits still induce a similar shift in the output-logit distribution?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "jTLKhWRjJe", "forum": "XMGzodoTwV", "replyto": "XMGzodoTwV", "signatures": ["ICLR.cc/2026/Conference/Submission11066/Reviewer_Z59u"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11066/Reviewer_Z59u"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11066/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761258167506, "cdate": 1761258167506, "tmdate": 1762922242164, "mdate": 1762922242164, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper explores whether personality traits (based on the Big Five model) can be localized as identifiable “circuits” within large language models (LLMs). The authors construct a synthetic dataset, TRAITTRACE, containing prompts that express high or low levels of each trait and corresponding trait-consistent reactions. Using Edge Attribution Patching with Integrated Gradients (EAP-IG), they identify minimal subgraphs within the model that preserve performance on trait-consistent response prediction. Results suggest that small, sparse circuits can reproduce the full model’s behavior, that high and low levels of traits share many nodes but differ in edge directions, and that early MLP layers serve as bottlenecks for trait information."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "This paper tries to move beyond behavioral probing toward the mechanistic interpretability of social/psychological constructs."}, "weaknesses": {"value": "## Weaknesses and Suggestions\n\n### 1. The motivation is weak.\nThe authors justify this work through an analogy with neuroscience, arguing that personality traits in humans arise from neural circuits and therefore may also emerge as “trait circuits” in LLMs. However, this analogy is conceptually flawed. Human traits are latent psychological dimensions, not localized neural entities, and the connection to artificial circuits is purely metaphorical.\n\n---\n\n### 2. Ethical statement is missing.\nBecause the paper draws direct analogies between human brain circuits and model activations, it risks **anthropomorphism**, suggesting that LLMs “possess” personality traits or human-like psychology. Such framing requires careful ethical consideration and a clear disclaimer, but no ethical statement is provided. The authors should explicitly acknowledge these limitations and clarify that their findings do not imply genuine human-like cognition.\n\n---\n\n### 3. Experimental rigor is low.\nOnly two small instruction-tuned models (LLaMA-2-7B-Chat and Phi-2) are tested, without including base or larger models. This makes it difficult to assess whether the findings generalize across training phases or scales of LLMs. Including additional models or verifying whether similar trait circuits emerge in non-chat variants would significantly strengthen the paper. Also, I understand that this paper's goal is to discover the circuits lying in the LLMs. But to evaluate the quality and validity of the dataset, I recommend that authors provide the evaluation on other methods, such as pure prompting.\n\n---\n\n### 4. Prompt and task design are conceptually flawed.\nThe Big Five traits are continuous spectra, but the dataset reduces them to binary self-descriptions (e.g., “I am high in openness” vs. “I am low in openness”). This introduces strong lexical cues and risks capturing superficial associations between trait names and responses rather than genuine trait inference. A more realistic approach would involve inferring traits from open-ended essays or autobiographical texts. This method is one of the canonical methods to evaluate the personalities of humans [1].\nFor methodological reference, see [2].\n\n---\n\n### 5. Novelty is limited.\nThe technical approach, combining edge-attribution patching with pruning, is a direct application of existing interpretability methods. The main novelty lies in dataset curation, but the dataset curation is not rigorous enough.\n\n---\n\n### 6. Causal interpretation is overstated.\nIn Section 6.3, the authors conduct causal intervention analysis. However, the key question, whether these circuits truly represent personality traits rather than lexical correlations, remains unresolved. Without ruling out such confounders, it is premature to claim that the identified subgraphs mechanistically encode traits.\n\n[1] McAdams, Dan P. \"Narrative identity.\" Handbook of identity theory and research. New York, NY: Springer New York, 2011. 99-115.\n\n[2] Suh, Joseph, et al. \"Rediscovering the latent dimensions of personality with large language models as trait descriptors.\" arXiv preprint arXiv:2409.09905 (2024)."}, "questions": {"value": "1. **Evaluation details.** The details of the evaluation are not fully provided. The words or phrases like \"procrastinating\" are divided into 5 tokens. And the LLM response can be like a sentence, but how authors check the overlap between the references and LLM-generated tokens is not fully explained.\n\n2. **Dataset details.** Please provide more details of the curated dataset to evaluate the quality."}, "flag_for_ethics_review": {"value": ["Yes, Potentially harmful insights, methodologies and applications", "Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ew1tmudHli", "forum": "XMGzodoTwV", "replyto": "XMGzodoTwV", "signatures": ["ICLR.cc/2026/Conference/Submission11066/Reviewer_zxtA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11066/Reviewer_zxtA"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11066/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761600491603, "cdate": 1761600491603, "tmdate": 1762922241459, "mdate": 1762922241459, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "the paper studies whether personality in LLMs may similarly be realized through structured internal computation paths.\n\nThe authors come to the conclusion that \"only a compact set of attention heads and MLP units appears necessary\nfor encoding and expressing each trait across different models\"."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "The research is on a very timely and interesting topic. The results are convincing and should be interesting for a broad community of researchers."}, "weaknesses": {"value": "Though authors correctly mention that LLMs simulate certain behaviour or personality they do antropomorphize LLMs in other parts of the text. This is unfortunate but minor problem in my opinion."}, "questions": {"value": "How general is your approach and would it be applicable to bigger models? In particular how can we be sure that the conclusions will hold in the models that are order of magnitude bigger and go through a significantly longer post-training phase for alignment?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AMUbxxGeGv", "forum": "XMGzodoTwV", "replyto": "XMGzodoTwV", "signatures": ["ICLR.cc/2026/Conference/Submission11066/Reviewer_g9iQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11066/Reviewer_g9iQ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11066/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762025618390, "cdate": 1762025618390, "tmdate": 1762922240800, "mdate": 1762922240800, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}