{"id": "LaVrNaBNwM", "number": 16354, "cdate": 1758263653530, "mdate": 1759897245992, "content": {"title": "Overcoming Joint Intractability with Lossless Hierarchical Speculative Decoding", "abstract": "Verification is a key bottleneck in improving inference speed while maintaining distribution fidelity in Speculative Decoding. Recent work has shown that sequence-level verification leads to a higher number of accepted tokens compared to token-wise verification. However, existing solutions often rely on surrogate approximations or are constrained by partial information, struggling with joint intractability. In this work, we propose Hierarchical Speculative Decoding (HSD), a provably lossless verification method that significantly boosts the expected number of accepted tokens and overcomes joint intractability by balancing excess and deficient mass across accessible branches. Through extensive large-scale experiments, we show that HSD consistently improves acceptance rates, especially with longer draft sequences. Its strong explainability and generality further highlight the potential for integration into a wide range of speculative decoding frameworks.", "tldr": "", "keywords": ["Speculative Decoding", "Joint Intractability", "Lossless Verification"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/54f533058c2dcf53fc2fb3aadf7f63187f6d2fc6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes Hierarchical Speculative Decoding (HSD), a verification method for speculative decoding that seeks to be provably lossless while accepting longer draft prefixes than token-wise or blockwise verification.   The key idea is to view verification as hierarchical branch resampling with a single resampling step using a capped, branch-local resampling distribution. Several experiments on the Qwen series model demonstrate the effectiveness of the method."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Across three benchmarks and multiple target sizes, HSD shows consistent  improvements in block efficiency and throughput over token-wise and block-wise verification\n- This paper is overall well-written and easy to follow.\n- The appendices provide solid derivations and decomposition lemmas."}, "weaknesses": {"value": "- Results only use Qwen models and three academic datasets; evaluation on modern LLMs (e.g., Llama-2/3 families) and diverse tasks (long-context, multilingual, tool-use) would strengthen external validity.\n- HSD’s acceptance and resampling probabilities depend on capped branch divergences computed over the vocabulary for each position. The authors may want to provide a clear complexity/latency breakdown of these additional reductions relative to blockwise verification (e.g., per-step FLOPs, memory accesses, kernel counts)."}, "questions": {"value": "please refer to weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Wf9hI3k7Ug", "forum": "LaVrNaBNwM", "replyto": "LaVrNaBNwM", "signatures": ["ICLR.cc/2026/Conference/Submission16354/Reviewer_JMzF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16354/Reviewer_JMzF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16354/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760929056542, "cdate": 1760929056542, "tmdate": 1762926483958, "mdate": 1762926483958, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a method termed Hierarchical Speculative Decoding for accelerating inference in LLMs by improving the verification stage of speculative decoding. The claim is that existing methods struggle with “joint intractability” when trying to verify a draft sequence at once, so HSD uses a hierarchical branching/verification approach to boost the number of accepted tokens (i.e., less rollback) in a “lossless” manner."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The topic: Accelerating generative inference in LLMs is a highly important problem"}, "weaknesses": {"value": "1 The flow of the paper is not smooth. The theoretical derivation of “joint intractability” and then the transition to the hierarchical method is abrupt. It is not always clear how the high-level algorithm ties into the low-level proofs and experiments.\n2 While the paper describes “hierarchical speculative decoding”, the exact steps \nie, branch generation, verification hierarchy, mass-balancing, acceptance criteria, are somewhat buried in dense math and less in intuitive explanation or pseudo-code. Readers may struggle to follow the pipeline end-to-end."}, "questions": {"value": "It is hard to identify in one glance “Given draft model → generate K branches → verify hierarchically → accept or rollback”"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "RbOvSbUqw6", "forum": "LaVrNaBNwM", "replyto": "LaVrNaBNwM", "signatures": ["ICLR.cc/2026/Conference/Submission16354/Reviewer_qE7w"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16354/Reviewer_qE7w"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16354/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761096858738, "cdate": 1761096858738, "tmdate": 1762926483585, "mdate": 1762926483585, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Hierarchical Speculative Decoding (HSD), a novel approach to improving the verification process in speculative decoding. The paper addresses verification bottleneck by proposing HSD, a lossless verification method that overcomes joint intractability by resampling portions of the target distribution in a hierarchical manner. Extensive experiments show that HSD significantly improves the expected number of accepted tokens, particularly when dealing with longer draft sequences. The method is also proven to work effectively across different model sizes and tasks, making it a promising tool for accelerating LLM inference."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- The proposed hierarchical branch resampling strategy is a novel and creative approach to addressing joint intractability in speculative decoding. \n\n- The theoretical analysis is rigorous, and the experimental validation is comprehensive, showing consistent improvements across various benchmarks.\n\n- The paper is clearly written, and complex ideas are explained clearly. The use of figures and equations aids in understanding the methodology and its underlying theory."}, "weaknesses": {"value": "- It’s unclear whether the backward scan of HSD introduces any additional computational overhead."}, "questions": {"value": "- Could the author provide a more intuitive example or explanation of why joint verification leads to a higher expected number of accepted tokens? While the simulation using a toy example is convincing, it still isn't entirely clear to me why this happens.\n\n- For Algorithm 2, at line 15, should it still sample from the target distribution until the sequence reaches $\\gamma$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PfEi4LnkO1", "forum": "LaVrNaBNwM", "replyto": "LaVrNaBNwM", "signatures": ["ICLR.cc/2026/Conference/Submission16354/Reviewer_YeUo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16354/Reviewer_YeUo"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16354/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761615078368, "cdate": 1761615078368, "tmdate": 1762926483144, "mdate": 1762926483144, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Hierarchical Speculative Decoding (HSD), a novel approach to address the \"joint intractability\" problem in speculative decoding for large language model (LLM) inference. The authors identify a fundamental limitation in existing speculative decoding methods (tokenwise and blockwise) related to how acceptance probabilities are calculated for draft sequences. HSD solves this by introducing a hierarchical approach to acceptance probability calculation that better approximates the ideal case while maintaining the lossless property (preserving the target distribution exactly). The paper provides rigorous theoretical analysis proving HSD's correctness and demonstrates consistent improvements over baselines across multiple benchmarks (GSM8K for mathematical reasoning, HumanEval for code generation, and CNN/DailyMail for summarization) using the Qwen2.5 model suite with various scale combinations (0.5B draft model with 14B, 32B, and 72B target models)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Exceptionally rigorous theoretical analysis with detailed proofs establishing the lossless property of HSD. The paper clearly demonstrates how HSD correctly recovers the target distribution through careful handling of branch divergence and capped ratios.\n2. Significant conceptual contribution by identifying and solving the \"joint intractability\" problem in speculative decoding - how existing methods miscalculate acceptance probabilities for multi-token sequences, leading to suboptimal performance.\n3. Elegant hierarchical approach to acceptance probability calculation that provides a theoretically sound solution while remaining practically implementable. The capped ratio concept and unique capping indices are particularly insightful innovations."}, "weaknesses": {"value": "1. Limited experimental scope - the paper only evaluates HSD using Qwen2.5 models across three benchmarks. A broader evaluation with multiple model families and additional tasks would strengthen the empirical validation.\n2. Insufficient comparisons with state-of-the-art speculative decoding frameworks. While thoroughly comparing against tokenwise and blockwise methods, the paper omits systematic comparisons with more advanced approachesr.\n3. Limited ablation studies to understand the contribution of different HSD components. For instance, how sensitive is performance to the identification of \"unique capping indices\" or the specific hierarchical structure?"}, "questions": {"value": "1. How does the actual computational overhead of HSD (for hierarchical acceptance probability calculations) compare to simpler methods, particularly for smaller draft lengths? Could this overhead offset some gains in block efficiency?\n2. The paper mentions HSD can be integrated with multi-draft frameworks but provides limited evaluation. Could you share more comprehensive results comparing HSD Multi-draft against Tokenwise Multi-draft across more model combinations?\n4. Have you observed any tasks or model configurations where HSD performs worse than existing methods? Understanding the limitations would help practitioners decide when to use this approach.\n5. Could you provide more intuitive examples showing how HSD's hierarchical acceptance mechanism works in practice for concrete generation examples, perhaps with visualizations of the capped ratios and unique capping indices?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "lcL2jz7Sm3", "forum": "LaVrNaBNwM", "replyto": "LaVrNaBNwM", "signatures": ["ICLR.cc/2026/Conference/Submission16354/Reviewer_ASe8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16354/Reviewer_ASe8"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16354/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761904887057, "cdate": 1761904887057, "tmdate": 1762926482729, "mdate": 1762926482729, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}