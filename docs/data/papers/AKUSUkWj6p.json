{"id": "AKUSUkWj6p", "number": 21210, "cdate": 1758314997381, "mdate": 1759896934569, "content": {"title": "Oracle-efficient Hybrid Learning with Constrained Adversaries", "abstract": "The Hybrid Online Learning Problem, where features are drawn i.i.d. from an unknown distribution but labels are generated adversarially, is a well-motivated setting positioned between statistical and fully-adversarial online learning. Prior work has presented a dichotomy: algorithms that are statistically-optimal, but computationally intractable \\citep{wu2023expected}, and algorithms that are computationally-efficient (given an ERM oracle), but statistically-suboptimal \\citep{pmlr-v247-wu24a}.\n\nThis paper takes a significant step towards achieving statistical optimality and computational efficiency \\emph{simultaneously} in the Hybrid Learning setting. To do so, we consider a structured setting, where the Adversary is constrained to pick labels from an expressive, but fixed, class of functions $\\mathcal{R}$. Our main result is a new learning algorithm, which runs efficiently given an ERM oracle and obtains regret scaling with the Rademacher complexity of a class derived from the Learner's hypothesis class $\\mathcal{H}$ and the Adversary's label class $\\mathcal{R}$. As a key corollary, we give an oracle-efficient algorithm for computing equilibria in stochastic zero-sum games when action sets may be high-dimensional but the payoff function exhibits a type of low-dimensional structure. Technically, we develop a number of novel tools for the design and analysis of our learning algorithm, including a novel Frank-Wolfe reduction with \"truncated entropy regularizer\" and a new tail bound for sums of \"hybrid'' martingale difference sequences.", "tldr": "oracle-efficient hybrid online learning with regret scaling with classical rademacher complexity", "keywords": ["hybrid online learning", "oracle-efficiency", "ERM", "rademacher complexity"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8dc6fc65a8f85acda28cc90549a45dff7e759cf2.pdf", "supplementary_material": "/attachment/81ffccfbeee2646856f647e2b3c1a9f529d8db68.zip"}, "replies": [{"content": {"summary": {"value": "This paper studies hybrid online learning where features are drawn i.i.d. from an unknown distribution, while labels are chosen by an adversary. Different from the fully adversarial case, the adversary is constrained to pick labels from a fixed function class, and the learner competes with a hypothesis class under a Lipschitz abd convex loss function. The main result of this paper is to propose an oracle-efficient algorithm with a high-probability regret guarantee. The proposed algorithm is built upon FTRL framework with the entropy regularizer, implemented via a Frank–Wolfe reduction that calls a linear‑optimization oracle over hypothesis class."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Prior work either attains optimal rates but is computationally intractable, or is oracle‑efficient but statistically suboptimal. This paper achieves near‑optimal rates and oracle efficiency by constraining the adversar, which could be an interesting middle ground.\n\n- Authors propose a FTRL-based algorithm with entropy regularizer, and theoratically show that the proposed algorithm achieves a statistically near-optimal up to the dependence on the adversary’s constraint set $\\mathcal{R}$.\n\n- Proposition 1.3 addresses uniform convergence when the functions $r_t$ are chosen adaptively yet independently of $x_t$. This result could be a good contribution of independent interest.\n\n- This paper is easy-to-follow and well-written. Though I am not quite familiar with the context, I appreciate detailed and clear explainations provided by authors."}, "weaknesses": {"value": "- The tightness of the regret bound remains unclear to me, especially $T* rad_T(\\ell \\circ  \\mathcal{H} \\times \\mathcal{R})$.\n\n- The algorithm runs in $O(T^2)$ time per round and makes $O(T^2)$ calls to a linear optimization oracle, both of which seem to be pretty large.\n\n- In line 265, $\\log(a+1)$ is strongly concave on its domain rather than strongly convex. It should be that $a*log(a+1)$ is strongly convex."}, "questions": {"value": "- I am not sure whether imposing the Lipschitz assumption on loss function is common or not. Can authors justify this assumption?\n\n- The algorithm needs to have access of the loss function. I am curious what if the learner does not have the knowledge of the loss function, but only has bandit feedback (i.e., observe the loss of the chosen one)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "gYH5yhJO6d", "forum": "AKUSUkWj6p", "replyto": "AKUSUkWj6p", "signatures": ["ICLR.cc/2026/Conference/Submission21210/Reviewer_SZPF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21210/Reviewer_SZPF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21210/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761521156007, "cdate": 1761521156007, "tmdate": 1762941619989, "mdate": 1762941619989, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the problem of *hybrid online learning*, where the feature vectors are drawn i.i.d. from an unknown distribution, while the labels are chosen adversarially. It focuses on a structured setting in which the labels are generated by a function belonging to a restricted class. Without restrictions on the labeling functions, Wu et al. (2024) showed that an oracle-efficient online algorithm exists, though its regret bound exhibits a gap compared to the case where the data distribution is known. This paper shows that if the labeling functions are drawn from a class whose complexity is no bigger than that of the hypothesis class, one can achieve the minimax-optimal regret.\n\nThe main proof technique is based on constructing a *surrogate loss* using the previously observed samples and reducing the hybrid online learning problem to an instance of online convex optimization. The paper then introduces a *truncated entropy regularizer* and proves that applying FTRL with this regularizer yields a *pointwise* regret bound of $\\tilde{O}(\\sqrt{T})$. This pointwise guarantee is subsequently converted into a *high-probability* regret bound for the original hybrid learning problem via standard martingale concentration arguments. Finally, since vanilla FTRL requires convexity of the hypothesis class, the authors resolve this issue by employing a Frank–Wolfe–based oracle reduction."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. I find the idea of reducing the hybrid online learning problem to an OCO problem quite interesting. This could inspire researchers to explore similar reductions for more complex hybrid settings, such as the smoothed adversary model.\n\n2. As far as I understand, the truncated entropy regularizer is novel and may have broader application scenarios beyond this particular setting.\n\n3. The authors demonstrated the usefulness of their constrained labeling-function formulation in the context of finding saddle points in minimax games, which I find convincing."}, "weaknesses": {"value": "1. Although the paper provides a use case for the constrained labeling-function setting in games, it still feels somewhat restrictive, especially since the prior result by Wu et al. (2024) does not rely on such constraints. It would strengthen the paper if the authors could present additional examples where similar constraints arise naturally from structural properties of the problem.\n\n2. The paper claims that the obtained regret bound is “near-optimal.” I am not entirely sure how this should be interpreted. In particular, if the VC dimension of $R$ is unbounded, the bound becomes vacuous, even though we know that sublinear regret is still achievable in that case."}, "questions": {"value": "Can the OCO problem and its oracle-efficient solution be stated more generally? As far as I can see, the specific form of the loss does not matter, one only needs that each $\\ell_t$ depends only on the first $t-1$ coordinates of $v$ and is convex and Lipschitz with respect to the $\\ell_1$ norm."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zxeoGDANiJ", "forum": "AKUSUkWj6p", "replyto": "AKUSUkWj6p", "signatures": ["ICLR.cc/2026/Conference/Submission21210/Reviewer_KxDd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21210/Reviewer_KxDd"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21210/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761701153603, "cdate": 1761701153603, "tmdate": 1762941618874, "mdate": 1762941618874, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies hybrid online learning where features are i.i.d. from an unknown distribution $D$ but labels are chosen adversarially from a constrained class $\\mathcal R \\subset [0,1]^X$. Given a linear optimization oracle over the hypothesis class $\\mathcal{H} \\subset [0,1]^X$, the authors design an ERM-oracle-efficient algorithm and prove a high-probability regret bound. The construction includes on (i) an approximate FTRL scheme over the “projection” of $\\mathcal H$ onto seen samples, using a time-varying shifted entropy regularizer (to get strong convexity on the first $t-1$ coordinates), and (ii) a Frank–Wolfe reduction so the regularized ERM calls can be implemented with a linear optimization oracle. A uniform-convergence argument then upgrades in-expectation control to the realized-sample regret bound. The paper also gives an application to approximate equilibria in certain stochastic zero-sum games with separable structure (payoff $u(h(x),r(x))$)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The considered problem is well-motivated and has real-world applications.\n- The designed algorithms are intuitive and easy to implement. The algorithm is also computationally efficient compared to previous works."}, "weaknesses": {"value": "- One concern is about the construction of FTRL. Specifically, I am not sure the role of the entropy regularizer is under-motivated. In the main text, the “truncated” entropy $v\\mapsto \\sum_s v(s)\\log(v(s)+1)$ is chosen because $\\log(1+a)$ is uniformly strongly convex on $[0,1]$, giving strong convexity over the first $(t-1)$ coordinates at step $t$. But the paper does not explain why one could not use a simpler $\\ell_2$ regularizer or mirror maps that may yield cleaner constants or better boundedness. Since the algorithm ultimately calls a FW oracle (not projecting onto the simplex), the specific advantage of entropy beyond “we get strong convexity where we need it” is not spelled out. Is that because of the use of $\\ell_\\infty$ in the gradient side?\n- While the analysis looks reasonable in general, there is one place that I do not understand. Specifically, the proof of Lemma A.6 appears flawed. In Lemma A.6 and the following derivation (lines 796–805), this is replaced by $\\psi_t(v_t)-\\psi_{t+1}(v_{t+1})$ with no justification (should be $\\psi_t(v_{t+1})-\\psi_{t+1}(v_{t+1})$). Can the authors explain more about that.\n- The paper does not provide a problem-specific lower bound for its hybrid setting. As a result it is unclear whether the leading terms in the upper bound are minimax tight. Without a matching lower bound that captures the joint stochastic–adversarial nature and the oracle model, it is difficult to assess optimality or to justify the use of the particular regularizer and surrogate."}, "questions": {"value": "See Weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "sMWhtoFZe2", "forum": "AKUSUkWj6p", "replyto": "AKUSUkWj6p", "signatures": ["ICLR.cc/2026/Conference/Submission21210/Reviewer_JWkH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21210/Reviewer_JWkH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21210/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969577704, "cdate": 1761969577704, "tmdate": 1762941618480, "mdate": 1762941618480, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies hybrid online learning which is an intermediate set up between online and statistical learner where the covariates are chosen in an iid manner while the labels are potentially chosen adversarially. In this setting, statistically it is known that a $sqrt{dT}$ regret is achievable where $d$ is the VC dimension of class with respect to which the learner is competing and $T$ is the horizon (the VC dimension dependence is considered \"good\" since it beats the typical \"Littlestone\" dimension dependence when the covariates are also worst case). Unfortunately, this is not achieved just by running empirical risk minimization on the past data. This motivates the question considered in the paper, which asks whether an algorithm that uses empirical risk minimization as an oracle (perhaps motivated by the success of ERM in practice) can achieve the same regret. The paper achieves this goal with the caveat that the VC dimension of the hypothesis class is replaced by the VC dimension of the loss class induced by the actions of the label generating process (referred to as the adversary) and the hypothesis class. The paper achieves this with an interesting Franke-Wolfe style algorithm which should be of general interest beyond hybrid online learning"}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The problem considered in the paper (hybrid online learning) is a very interesting abstract of \"beyond worst case\" sequential decision making and appears (at least conceptually) as intermediate step in several sequential decision making and game theoretic problems. Further, the study of oracle efficiency is well motivated in these applications (\"best response\" for example) which further justifies the interestingness of the problem. Given that, the paper achieving the strong regret guarantees in this setting should be considered as a strong contribution. Further, though the algorithm presented uses \"standard ideas\" in the community, the application to the present problem overcomes several interesting challenges which should be of broader interest in the community"}, "weaknesses": {"value": "The main issue with the regret bound presented is the dependence on the nonstandard quantity, the rademacher/VC dimension of the composed loss class. This complexity makes it a bit hard to compare the result with previous works directly and (if I understand correctly) should be treated as incomparable (and not an improvement on) to all previous work in the area (see below)."}, "questions": {"value": "-> As mentioned above the appearence of the complexity measure is a bit arbitrary (and has the flavor of \"what makes the analysis work\"). it would at least help the reader to have a small section discussing the measure and evaluating it in interesting setting e.g. R = H. It helps being honest and saying that in the standard setting where R = {all functions} the bound achieved is trivial. \n\nSimilarly, it would be helpful to discuss why this is essential since previous algorithms don't seem to need uniform convergence on the extended class. For example, this could be by explicitly stating why the present algorithm needs this while the Wu et algorithm does not. I suspect it is due to the passing through FTRL in the analysis but it would be good to be explicit regarding whether this is an artifact of the analysis or inherent in the algorithm. \n\n-> The comparison to previous work mildly misrepresents previous work since smoothed online learning has also been studied without knowing the bases measure and as such strictly generalizes hybrid online learning. BRS24 further study this in the oracle efficient setting (ERM directly even) and show that for realizable case they get a sqrt{Td} bound. When the present resuklt is specialized to the realizable setting, the bound recovered is the same but the covariate distribution is more general there; this is a further reason why an extended discussion of the assumption would help since for me the most interesting/interpretable case of the present bound is when R = H which is already shown in previous work. In particular, it would be interesting to see if similar bound in terms of the complexity in the paper can be shown in teh unknown base measure smoothed setting where too it remain open to get a sqrt{dT} rate in the agnostic case (in fact any sublinear oracle efficient rate is open to the best of my knowledge)\n\n-> Minor: FW type algorithms have been studied before in the oracle efficiency line of work (but with different motivation) start with the work of kakade kalai and ligget and more recently garber. WOuld be interesting to have some discussion on this\n\n-> Minor: Though I am happy to recommend acceptance of this paper to ICLR (whose interest I think of as closer to \"modern machine learning\", I personally do not think it is a good fit and would encourage the authors to (have) consider(ed) a different such as COLT where the community would appreciate the contribution more. That said, ICLR is increasingly being considered as a Neurips-style general ML conference and I understand that the authors have potential \"real world\" constraints beyond the maximization of the  community engagement"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "F0bZJTIxU2", "forum": "AKUSUkWj6p", "replyto": "AKUSUkWj6p", "signatures": ["ICLR.cc/2026/Conference/Submission21210/Reviewer_rpou"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21210/Reviewer_rpou"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21210/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762148368338, "cdate": 1762148368338, "tmdate": 1762941617852, "mdate": 1762941617852, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}