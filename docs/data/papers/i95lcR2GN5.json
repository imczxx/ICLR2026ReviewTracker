{"id": "i95lcR2GN5", "number": 14377, "cdate": 1758234139757, "mdate": 1759897374081, "content": {"title": "Rethinking the Value of Multi-Agent Workflow: A Strong Single Agent Baseline", "abstract": "Recent advances in LLM-based multi-agent systems (MAS) show that workflows composed of multiple LLM agents with distinct roles, tools, and communication patterns can outperform single-LLM baselines on complex tasks. However, most frameworks are homogeneous, where all agents share the same base LLM and differ only in prompts, tools, and positions in the workflow. This raises the question of whether such workflows can be simulated by a single agent through multi-turn conversations. We investigate this across six benchmarks spanning coding, mathematics, and general question answering. Our results show that a single agent can reach the performance of homogeneous workflows with an efficiency advantage from KV cache reuse, and can even outperform an automatically optimized heterogeneous workflow. Building on this finding, we propose $\\textbf{OneFlow}$, an algorithm that automatically tailors workflows for single-agent execution, reducing inference costs compared to existing automatic multi-agent design frameworks without trading off accuracy. These results position the single-LLM implementation of multi-agent workflows as a strong baseline for MAS research. We also note that single-LLM methods cannot capture heterogeneous workflows due to the lack of KV cache sharing across different LLMs, highlighting future opportunities in developing $\\textit{truly}$ heterogeneous multi-agent systems.", "tldr": "", "keywords": ["Large Language Models", "Multi-Agent Systems", "KV Cache", "Automatic Workflow Design"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/084aa3ccef9843045c5782c827c835b6eb4cebf6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper examines the value proposition of LLM-based multi-agent systems in settings where current frameworks are largely homogeneous. The authors empirically show that a single LLM using multi-turn conversation with KV cache reuse can match or outperform such multi-agent workflows in both performance and cost across six benchmarks spanning coding, mathematics, and question answering. Building on this finding, they propose OneFlow, an algorithm for automatic, cost-aware workflow optimization tailored for single-agent execution without compromising accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper offers a reassessment of the prevailing practice of homogeneous multi-agent workflows in LLM systems, combining theoretical reasoning with strong empirical evidence. This provides an important sanity check for the rapidly growing MAS literature.\n\n2. Experiments on six standard and one domain-specific dataset using multiple LLMs convincingly show that single-agent execution can match or surpass homogeneous multi-agent performance while reducing cost substantially."}, "weaknesses": {"value": "1. The heterogeneous experiments (Table 3) rely on automatically generated workflows with unclear tuning and no ablation of model-assignment policies. Thus, the claim that a single-LLM implementation can outperform heterogeneous setups is only provisional.\n\n2. The OneFlow search process is fixed and shallow, with no analysis of sensitivity to search depth, hyperparameters, or model choice. This leaves the robustness of the optimization procedure underexplored.\n\n3. While quantitative results are comprehensive, there is little discussion of failure cases or qualitative differences between single-agent and true multi-agent behaviors, leaving interpretability and diagnostic insight limited."}, "questions": {"value": "1. How does OneFlow’s workflow quality and cost-performance trade-off scale with deeper or wider search? Is the dual meta-LLM architecture robust to prompt or model changes?\n\n2. Have the reported KV-cache efficiency gains been validated using open-weight models that support cache reuse, or might the simulated API-based estimates introduce systematic bias?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "0UQkJoPmfF", "forum": "i95lcR2GN5", "replyto": "i95lcR2GN5", "signatures": ["ICLR.cc/2026/Conference/Submission14377/Reviewer_Ldvv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14377/Reviewer_Ldvv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14377/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927374275, "cdate": 1761927374275, "tmdate": 1762924795330, "mdate": 1762924795330, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper shows that homogeneous MAS workflows (same base LLM, different prompts/tools) can be simulated by a single LLM via multi-turn role-play. Then it proposes OneFlow, which consists of two parts: 1. search for optimized workflow. 2. perform single LLM implementation. across six benchmarks, single-agent execution often matches or slightly exceeds multi-agent performance but the price is much cheaper."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* The paper proposes an interesting point of view.\n* The experiments test on six benchmark and report both accuracy and cost to support claims."}, "weaknesses": {"value": "* The OneFlow methods composes of two parts: search for optimized workflow and perform single LLM implementation. The first part seems like an improved version of Aflow and lacks novelty, for example, the critic prompt is adopted from AFlow.\n* The costs for single-agent are simulated due to closed-weight APIs; add open-weight runs (or vendor KV-sharing APIs) to validate real-world latency/$ savings\n* While the method mentions tool calling, the benchmark tested are static QA/math/code; include tool-use tasks with external side-effects and interactive settings."}, "questions": {"value": "* See weakness.\n* Clarification: In 4.2 single-LLM simulator, it writes \"Set the system message to p_{i_t}\", does this mean to replace the system prompt at the beginning? Can you give an example of how this is different from multi-agent system?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "215hXN84Ls", "forum": "i95lcR2GN5", "replyto": "i95lcR2GN5", "signatures": ["ICLR.cc/2026/Conference/Submission14377/Reviewer_b2kC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14377/Reviewer_b2kC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14377/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761955467402, "cdate": 1761955467402, "tmdate": 1762924794916, "mdate": 1762924794916, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates whether the advantages of multi-agent systems built from homogeneous LLMs can be replicated by a single LLM through multi-turn interactions and KV-cache sharing. The authors empirically evaluate this hypothesis across six benchmarks (code generation, mathematics, and QA tasks) and introduce OneFlow, an automated workflow design algorithm that employs dual meta-LLMs (Designer and Critic) under an MCTS framework. The results suggest that single-agent implementations can match or exceed the performance of multi-agent workflows while substantially reducing inference cost. The paper further discusses the limits of this equivalence in heterogeneous multi-agent contexts and proposes directions for future research."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- **S1.** The paper tackles a timely and important issue whether multi-agent systems provide real advantages over single-agent reasoning when the base LLM is homogeneous.\n\n- **S2.** Well-explained theoretical formulation that logically connects shared KV cache to computational efficiency.\n\n- **S3.** Comprehensive experimental coverage across six benchmarks and one domain-specific dataset."}, "weaknesses": {"value": "- **W1.** The OneFlow framework largely replicates the AFlow architecture with minor adaptations. The use of MCTS for workflow generation is not new, and the manuscript does not clearly articulate what conceptual or technical innovation distinguishes OneFlow from AFlow.\n\n- **W2.** The evaluation primarily relies on closed-weight models (GPT-4o-mini, Claude 3.5 Haiku), and the KV-cache advantages are simulated rather than directly measured. The real experiments using open models capable of genuine KV sharing are absent, limiting the credibility of efficiency claims.\n\n- **W3.** The paper primarily contrasts with AFlow and manual CoT baselines, omitting recent heterogeneous agentic frameworks (e.g., MasRouter) that could reveal where single-agent designs fail.\n\n- **W4.** No exploration of when and why the single-agent execution begins to fail (e.g., under longer reasoning chains or tool dependencies)."}, "questions": {"value": "- **Q1.** Could the authors provide concrete evidence (with open-weight models) that KV-cache reuse yields measurable cost savings in practice rather than theoretical simulation?\n\n- **Q2.** How does OneFlow's Designer-Critic interaction differ algorithmically from AFlow's meta-LLM setup beyond re-using prompts?\n\n- **Q3.** Several datasets (e.g., GSM8K, MBPP) are solvable via direct prompting. Have the authors tested tasks that genuinely require multi-stage *agentic* reasoning or tool usage?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZYN017VdAt", "forum": "i95lcR2GN5", "replyto": "i95lcR2GN5", "signatures": ["ICLR.cc/2026/Conference/Submission14377/Reviewer_VtaY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14377/Reviewer_VtaY"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14377/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995873369, "cdate": 1761995873369, "tmdate": 1762924794438, "mdate": 1762924794438, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper questions whether multi-agent LLM workflows truly outperform single LLMs when all agents share the same base model.\nIt formally shows that for homogeneous workflows (same base LLM, different prompts/tools), a single LLM can simulate the entire multi-agent pipeline through multi-turn dialogue while reusing the KV cache, gaining efficiency without loss of expressivity.\nBased on this, the authors propose OneFlow, an automatic workflow design framework using dual meta-LLMs (Designer + Critic) and Monte-Carlo Tree Search to generate workflows optimized for single-agent execution.\nAcross six benchmarks (HumanEval, MBPP, GSM8K, MATH, HotpotQA, DROP) and one domain-specific Shopping-MMLU set, OneFlow-single achieves comparable or better performance than existing multi-agent frameworks (AFlow, etc.) while cutting inference cost by up to 10×.\nThe paper concludes that homogeneous MAS can be largely simulated by a single agent and that future work should focus on truly heterogeneous systems."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The author Reframes multi-agent research with a rigorous single-agent equivalence argument.\n\nthey provide Six general benchmarks + domain-specific tasks.\n\nthey also Quantifies KV-cache benefits clearly.\n\nit shows that OneFlow’s dual-meta LLM + MCTS is a creative and reproducible design. and it  clearly delineates where single-agent simulation applies and where heterogeneity still matters."}, "weaknesses": {"value": "Limited empirical heterogeneity analysis: Pilot study is small; results inconclusive about real multi-model synergy.\n\nSimulation of KV cache: Since APIs hide internal caching, efficiency results are theoretical. A small open-weight replication (e.g., LLaMA-3 8B) would strengthen credibility.\n\nAblations: Lack of ablation on MCTS parameters (α, β, iterations) and meta-LLM roles; unclear how much each contributes.\n\nOver-dependence on closed models: Limits reproducibility beyond cost estimation.\n\nWriting could be tighter: Some redundant explanations and long prompts in appendix."}, "questions": {"value": "Can you verify KV-cache reuse gains empirically using an open-source model?\n\nHow sensitive are results to the α/β weights in Eq. (1)?\n\nWould OneFlow still outperform AFlow if inference cost were excluded (i.e., pure accuracy metric)?\n\nHave you tested whether role-switching (different prompts within same chat) affects coherence or context interference?\n\nHow does OneFlow perform when the base model has small context windows (e.g., 4k tokens)—does summarization degrade accuracy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DppOThMbVZ", "forum": "i95lcR2GN5", "replyto": "i95lcR2GN5", "signatures": ["ICLR.cc/2026/Conference/Submission14377/Reviewer_gFZd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14377/Reviewer_gFZd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14377/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762379866447, "cdate": 1762379866447, "tmdate": 1762924794033, "mdate": 1762924794033, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}