{"id": "89gxHJkCXk", "number": 11008, "cdate": 1758186731392, "mdate": 1759897614936, "content": {"title": "Exposing Mixture and Annotating Confusion for Active Universal Test-Time Adaptation", "abstract": "Universal Test-Time Adaptation (UTTA) tackles the challenge of handling both class and domain shifts in unsupervised settings with stream testing data. Currently, most UTTA methods can only deal with minor shifts and heavily rely on heuristic approaches. To advance UTTA under dual shifts, we propose a novel Active Universal Test-Time Adaptation (AUTTA) framework, Exposing Mixture and Annotating Confusion (EMAC), which incorporates active human annotation into the UTTA setting. To select appropriate samples for annotation in AUTTA, we first identify the mixed regions of target domain samples under dual shifts, highlighting potential candidate samples. We then design a reward-guided active selection strategy to prioritize annotating the most representative samples within this set, maximizing annotation effectiveness. Additionally, to balance the use of pseudo-labels with the limited number of annotations, we propose an adaptation objective designed to address the adaptation imbalance caused by annotation scarcity. Extensive experiments show that the proposed AUTTA approach significantly improves performance and achieves state-of-the-art.", "tldr": "", "keywords": ["Test-Time Adaptation", "Open-set"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/59cbf7c492fde5d402d64776580ecee9d723eada.pdf", "supplementary_material": "/attachment/fbc28de5200d8b0f9489987a087c971613f9d700.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes a new problem setting of Active Universal TTA (AUTTA), providing a few active samples in open-world TTA when both domain and class shifts occur. They propose EMAC (Exposing Mixture and Annotating Confusion) as the solution.. EMAC first exposes mixed “dual-shift” regions by orthogonally decoupling features and fitting a (bi)modal GMM, then annotates a small set of target samples via a reward-guided entropy criterion, and finally applies a clustering-aware contrastive objective to better use scarce labels and pseudo-labels. Evaluations on DomainNet/VisDA (and Office-Home) report gains in UTTA metrics versus TTA/UTTA/ATTA baselines under an AUTTA (human-in-the-loop) protocol."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Timely problem and setup of moving beyond pure UTTA to an active variant that targets the hardest mixed regions is well-motivated and practically relevant. \n\n1. The EMAC method is intuitive for AUTTA setup.\n\n1. Consistent improvements in AH over strong TTA/UTTA/ATTA baselines on DomainNet/VisDA (and Office-Home)."}, "weaknesses": {"value": "1. Related works on active TTA are missing: EATTA [1], BiTTA [2]. I would appreciate if these could be included in the evaluation. Also, balancing between labeled and unlabeled samples can have some references/insights from BiTTA.\n\n1. The paper positions EMAC as an AUTTA method, yet much of the presentation borrows UTTA terminology/metrics (AO/AN/AH). Please explicitly specify, in the main text, the evaluation protocol for each table and method: (i) train/test dataset class separation setting, (ii) the labeling budget, (iii) the querying schedule, and (iv) how UTTA baselines are run/comparable under an AUTTA setting (including whether active samples are allowed). I would say the fair comparison should allow same number of active samples for all methods.\n\n\n\n\n[1] Wang, Guowei, and Changxing Ding. \"Effortless active labeling for long-term test-time adaptation.\" Proceedings of the Computer Vision and Pattern Recognition Conference. 2025.\n\n[2] Lee, Taeckyung, et al. \"Test-Time Adaptation with Binary Feedback.\" Forty-second International Conference on Machine Learning."}, "questions": {"value": "1. Please refer to my weakness above.\n\n1. Equation (4) - I think the old and new pdf should be averaged (not summed) to consist a valid pdf?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "WIosd0B3NM", "forum": "89gxHJkCXk", "replyto": "89gxHJkCXk", "signatures": ["ICLR.cc/2026/Conference/Submission11008/Reviewer_uM52"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11008/Reviewer_uM52"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11008/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761484477437, "cdate": 1761484477437, "tmdate": 1762922189297, "mdate": 1762922189297, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes AUTTA and instantiates it with EMAC to handle simultaneous class shift and domain shift at test time by querying a small number of human annotations and combining them with pseudo-labels. The key ideas include decomposing features to expose the dual-shift “mixed” region through a GMM over known/unknown spaces; actively picking the most beneficial samples with an entropy selector; and balancing real labels and pseudo-labels with a clustering-based contrastive objective so that limited annotations don’t get drowned out. On DomainNet and VisDA-C, EMAC improves over TTA/UTTA/ATTA baselines and stays strong under dual-shift, non-i.i.d., and continual settings."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. Moving from UTTA/ATTA to Active UTTA (AUTTA) is a natural and relevant step.\n2. The insight that dual-shift mixed regions are where pseudo-labels fail the most is valuable, showing good motivation.\n3. The method design is efficient.\n4. Results on DomainNet and VisDA-C are comprehensive and strong."}, "weaknesses": {"value": "1. The core of this paper relies on detecting a bimodal distribution of “unknown energy” after orthogonal decomposition. This can easily break when batches are small, class mixture is skewed, or shifts are not cleanly bimodal.\n2. Orthogonal decomposition on classifier weights is not justified well.\n3. DomainNet + VisDA-C are standard, but both are still vision benchmarks with relatively clean image-level labels.\n4. They mainly report AO/AN/AH; but AUTTA’s value is in not wasting labels.\n5. They reference AL/IG connections and ATTA theory, but don’t give a full bound specialized to their two-stage selection + contrastive update."}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "C8OPmpKpG2", "forum": "89gxHJkCXk", "replyto": "89gxHJkCXk", "signatures": ["ICLR.cc/2026/Conference/Submission11008/Reviewer_4PKJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11008/Reviewer_4PKJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11008/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761932458590, "cdate": 1761932458590, "tmdate": 1762922188950, "mdate": 1762922188950, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Active Universal Test-Time Adaptation (AUTTA) scenario and an approach named EMAC under joint class and domain shifts. The key idea is to actively select a small number of test data to label in the test data stream. EMAC first exposes a mixed region by decomposing the classifier to obtain “known/unknown” subspaces to fit a bimodal GMM distribution to split them.  Further, it uses a Max–Min Entropy reward that prefers old-class samples reducing entropy and new-class samples improving separability to select sample to label. Finally, the model is trained with a clustering-based contrastive objective that balances limited true labels with a lot of pseudo-labels. Experiments on DomainNet and VisDA-C report improved open-set metrics compared to prior UTTA/TTA methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. **Clear problem framing.** The paper tackles UTTA with dual shifts and argues why naive uncertainty sampling can be biased and how human-in-the-loop labeling can help.\n2. **Lightweight mechanics.** The SVD decoupling and per-batch GMM are simple to implement and compatible with standard classifier heads.\n3. **Attention to real practicalities.** Small-batch instability are considered and adds a sliding window with EMA smoothing to stabilize GMM fitting. EMAC also behaves well under noisy annotations."}, "weaknesses": {"value": "1. **Incremental novelty; inherits much of OPTTT’s core.** At EMAC core, the paper targets the open-set TTA problem and largely inherits the OPTTT recipe, which propose the scenario and evaluation. It also assumes a bimodal GMM distribution of known and unknown samples and leverage pseudo-label self-training. The main new pieces are an active selection heuristic and a prototype/contrastive auxiliary loss. Useful in practice, but conceptually incremental rather than a substantial shift in paradigm.\n2. **Active learning feels bolted on for extra points ** The contribution narrative hinges on the AL module, yet its design is relatively standard (uncertainty/entropy flavored) and evaluated against modest baselines. There’s limited exploration of stronger, mixture-aware AL strategies. As a result, the AL part reads as an add-on to lift numbers rather than a principled advance.\n3. **Fairness of comparisons (label budget)** Apart from ATTA, most baselines are not evaluated under the same human-in-the-loop budget in Table 1,2,3. Comparisons that pit AUTTA (with labels) against UTTA/TTA methods (without labels) are not budget-fair. A more informative yardstick would be TTA/UTTA methods + the same label budget augmented with a generic AL wrapper.\n4. **Human-in-the-loop latency & hidden costs.** The method’s practicality hinges on online annotation during streaming. This induces stop-and-go adaptation. Even with small budgets, fixed per-event overheads can make real-time TTA infeasible.\n4. **Scope vs. claims.** Although pitched as “universal” TTA, the empirical scope is closer to open-world classification under a couple of standard datasets. Stronger evidence across more diverse distribution shifts (such as corruption datasets like ImageNet-C) would better substantiate the universality claim."}, "questions": {"value": "1. **Budget schedule.** Is label querying uniform over time or concentrated early? Would early exploration work better than steady drip? \n2. **When does the GMM assumption fail?** Can the authors provide diagnostics before selection that decide whether to trust the bimodal split? What happens when the batch is dominated by new classes, or when domain shift inflates norms uniformly?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5DDuNMyTa7", "forum": "89gxHJkCXk", "replyto": "89gxHJkCXk", "signatures": ["ICLR.cc/2026/Conference/Submission11008/Reviewer_iQMG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11008/Reviewer_iQMG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11008/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761975433126, "cdate": 1761975433126, "tmdate": 1762922188558, "mdate": 1762922188558, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Active Universal Test-Time Adaptation (AUTTA), a novel framework that integrates active learning into Universal Test-Time Adaptation (UTTA) to handle both class shift and domain shift simultaneously in streaming test data. The authors argue that existing UTTA methods struggle under dual shifts due to unreliable pseudo-labeling, and that traditional active learning strategies fail to select the most informative samples in such open-set scenarios. To address this, they propose EMAC (Exposing Mixture and Annotating Confusion). Extensive experiments on DomainNet and VisDA-C demonstrate that EMAC achieves state-of-the-art performance under dual-shift conditions, outperforming existing TTA, UTTA, and ATTA methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper clearly defines and motivates the AUTTA setting, which combines the challenges of Universal Domain Adaptation (open-class shift) with the constraints of Test-Time Adaptation (source-free, streaming data) and the strategy of Active Learning (limited human annotation).\n2. The paper provides comprehensive experiments across multiple datasets (DomainNet, VisDA-C) and shift scenarios (corruption, style transfer). The results consistently show EMAC outperforming a wide range of strong baselines."}, "weaknesses": {"value": "1. The core \"Exposing Mixture\" step relies on the target data distribution being bimodal in the decomposed feature space. While the authors address this in the appendix (A.2), showing robustness with VBGMM and PCA, this remains a potential failure point if the underlying data does not exhibit this property (e.g., highly overlapping or multi-modal new classes).\n2. The overall framework involves several components (SVD, GMM/VBGMM, reward computation with EMA, clustering-contrastive loss) and associated hyperparameters (GMM threshold τ, merging factor λ_merge, EMA factor α, reward weights ω). While the paper provides values, the sensitivity and tuning effort for new datasets could be a concern.\n3. Although the paper compares against several active learning methods (Table 3), the field of active learning for open-set or domain adaptation scenarios is rich. A more detailed discussion on how EMAC specifically advances beyond the limitations of these methods in the test-time setting would be beneficial."}, "questions": {"value": "See weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rykUXrTzvF", "forum": "89gxHJkCXk", "replyto": "89gxHJkCXk", "signatures": ["ICLR.cc/2026/Conference/Submission11008/Reviewer_F4qu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11008/Reviewer_F4qu"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11008/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762011283225, "cdate": 1762011283225, "tmdate": 1762922188184, "mdate": 1762922188184, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}