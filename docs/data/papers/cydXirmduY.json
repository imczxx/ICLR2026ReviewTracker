{"id": "cydXirmduY", "number": 10978, "cdate": 1758186067558, "mdate": 1763595088394, "content": {"title": "Emergent World Representations in OpenVLA", "abstract": "Vision Language Action models (VLAs) exhibit complex control behaviors without explicitly modeling environmental dynamics. However, it remains unclear whether VLAs implicitly learn world models, a hallmark of model-based RL. We propose an experimental methodology using embedding arithmetic on state representations to probe whether OpenVLA, the current state of the art in VLAs, contains latent knowledge of state transitions. Specifically, we measure the difference between embeddings of sequential environment states and test whether this transition vector is recoverable from intermediate model activations. Using linear and non-linear probes trained on activations across layers, we find statistically significant predictive ability on state transitions exceeding baselines (embeddings), indicating that OpenVLA encodes an internal world model (as opposed to the probes learning the state transitions). We investigate the predictive ability of an earlier checkpoint of OpenVLA and uncover hints that the world model emerges as training progresses. Finally, we outline a pipeline leveraging Sparse Autoencoders (SAEs) to analyze OpenVLA's world model.", "tldr": "", "keywords": ["World Representation", "Policy Based RL", "VLA", "SAE"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4fd3d1bdd7b997de93b19b902f6e1ec5901b444d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper studies Vision Language Action models (VLAs) which are trained with policy-based reinforcement learning (RL) methods that do not explicitly model environmental dynamics. The research question is whether VLAs instead do implicitly learn world models. The authors use an experimental approach to investigate whether trained models gather latent knowledge of state transitions. Evaluation results are performed on OpenVLA."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "S1 The considered problem is interesting and relevant.\n\nS2 The paper is overall well-written."}, "weaknesses": {"value": "W1 Regrading the research question, the paper does not provide analytical results.\n\nW2 It remains unclear whether the observations made hold beyond OpenVLA.\n\nW3 The evaluation is too small, contains only few examples and is hence not fully convincing. The question whether trained models gather latent knowledge of state transitions is not clearly answered and the use of the analysis remains unclear (at least to me)."}, "questions": {"value": "Do you expect the same results for VLAs different from OpenVLA?\n\nIs it possible to consider larger problem instances?\n\nIs Theorem 1 supposed to be a key contribution? How does it effectively relate to the numerical observations made?\n\nIs it possible to actively use the located latent world model for state predictions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hFPMOjLhQu", "forum": "cydXirmduY", "replyto": "cydXirmduY", "signatures": ["ICLR.cc/2026/Conference/Submission10978/Reviewer_vAJS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10978/Reviewer_vAJS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10978/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761832341170, "cdate": 1761832341170, "tmdate": 1762922168453, "mdate": 1762922168453, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper aims to study the emergence of implicit world models in pre-trained OpenVLA. Using frozen representations and intermediate activations, they train linear and MLP probes on representations of different layers of the model to predict actions. The central claim is that autoregressive next-token prediction training induces representations consistent with “world models\"."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The use of standard linear and MLP probes and similarity analyses on frozen embeddings is well explained and replicable in principle."}, "weaknesses": {"value": "1. The work largely documents known consequences of autoregressive temporal modeling, i.e., predicting future tokens forces latent spaces to encode local dynamics. If the goal of the paper was to provide a mechanistic interoperability theory of this phenomenon, it would have been valuable, but the current probing approach and corresponding results do not shed any light on the mechanics. The claimed emergence of “world representations” appears to be a direct and unsurprising byproduct of temporal modeling.\n\n2. Following up on my point above, there is no controlled experiment showing or discussing necessity or sufficiency of autoregression for structure emergence. The fact that $R^2$ of internal activations for predicting actions is lower compared to $R^2$ of embeddings for predicting actions, does not show any causality. It is expected that last layer reprs are richer in content compared to internal reprs.\n\n3. The paper claims (even in abstract) that OpenVLA is pretrained using policy-based RL. This is not correct. There is no RL involved in training OpenVLA and it is trained via imitation learning.\n\n4. Dividing RL into model-based and policy-based is not correct. Model-based methods also learn a policy. Do the authors mean model-free RL by \"policy-based\"?\n\n5. Many of the files in the anonymous repo are missing (I get \"The requested file is not found.\")"}, "questions": {"value": "1. What distinguishes your findings from standard properties of temporal predictive models?\n\n2. Would a non-autoregressive masked-video model show similar results as a VLA?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "vxeCSuzGsP", "forum": "cydXirmduY", "replyto": "cydXirmduY", "signatures": ["ICLR.cc/2026/Conference/Submission10978/Reviewer_nEnK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10978/Reviewer_nEnK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10978/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761940926115, "cdate": 1761940926115, "tmdate": 1762922167800, "mdate": 1762922167800, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies whether the large Vision-Language-Action model OpenVLA exhibits an emergent world model, by training linear and nonlinear probes on intermediate activations to predict embedding-based state transition vectors. The authors report that certain layers (e.g., 15, 22, 30) yield statistically significant predictive ability, suggesting that OpenVLA implicitly encodes world dynamics."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "* The question of emergent “world models” in policy-based RL systems is interesting and timely.\n* The methodology (probing activations with linear and MLP regressors) connects recent interpretability work in language models to robotics.\n* The paper is clearly written and includes theoretical motivation using Koopman operators."}, "weaknesses": {"value": "1. *Unclear research question and experimental motivation.* It is never clearly explained why only specific layers (7, 15, 22, 30) are selected for probing. The rationale for these discrete sampling points is missing, and without a systematic sweep or justification, the conclusions about “middle layers” encoding world models are not convincing.\n\n2. *Ambiguous test definition.* The precise experimental test used to claim an emergent world model is difficult to follow. It remains unclear what exactly is being predicted (embedding deltas? latent transitions?) and how statistical significance across layers and datasets translates into evidence for an internal model, as opposed to trivial temporal correlations in embeddings.\n\n3. *Methodological opacity.* The description of the regression probes lacks detail about data partitioning, normalization, and hyperparameter tuning. It is also not fully clear how permutation tests are performed or interpreted.\n\n4. *Interpretation of results.* The claim that “world models emerge” appears overstated relative to the presented evidence. The reported $R^2$ values are modest, and there is no ablation verifying that probes are not learning the dynamics directly."}, "questions": {"value": "1. What is the exact hypothesis being tested — that OpenVLA contains an implicit model of the environment, or merely that its embeddings exhibit temporal coherence?\n\n2. Why are only layers 7, 15, 22, and 30 selected? Are these equidistant checkpoints? Is there empirical or theoretical motivation for these choices? Did you examine whether neighboring layers yield similar behavior?\n\n3. What is the rationale for examining specific horizons K = 1, 3, 10, 30? How were these values chosen, and how sensitive are the results to K?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "9rBeaRZYPL", "forum": "cydXirmduY", "replyto": "cydXirmduY", "signatures": ["ICLR.cc/2026/Conference/Submission10978/Reviewer_tAGf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10978/Reviewer_tAGf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10978/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762259056339, "cdate": 1762259056339, "tmdate": 1762922167037, "mdate": 1762922167037, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}