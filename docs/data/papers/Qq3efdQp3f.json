{"id": "Qq3efdQp3f", "number": 20162, "cdate": 1758303194174, "mdate": 1759896997776, "content": {"title": "White-Basilisk: A Hybrid Model for Code Vulnerability Detection", "abstract": "The proliferation of software vulnerabilities presents a significant challenge to cybersecurity, necessitating more effective detection methodologies. We introduce White-Basilisk, a hybrid approach to vulnerability detection that demonstrates strong performance with efficient architectural design. Utilizing an architecture that integrates Mamba layers, linear self-attention, and a Mixture of Experts framework, White-Basilisk achieves state-of-the-art results in vulnerability detection tasks with a parameter count of only 200M. The model's capacity to process extended sequences enables comprehensive analysis of large codebases in a single pass, addressing context limitations that affect current approaches. White-Basilisk exhibits robust performance on imbalanced, real-world datasets, while maintaining computational efficiency that facilitates deployment across diverse organizational scales. This research establishes new benchmarks in code security and provides empirical evidence that compact, efficiently designed models can achieve competitive performance on specialized tasks, contributing to our understanding of architectural efficiency in domain-specific applications.", "tldr": "", "keywords": ["vulnerability detection", "llm", "linear attention", "mamba", "white-basilisk", "nlp", "moe", "efficient", "source code", "c", "c++"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/16cc726186b8b13cc45dcfb8f674abd5d1058896.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduced White-Basilisk, a 200M-parameter hybrid model designed for code vulnerability detection. The architecture combined Mamba layers, a linear-scaling attention mechanism (Basilisk Self-Attention), and a Mixture of Experts (MoE) framework for conditional computation. Through evaluation across five established vulnerability detection benchmarks (PRIMEVUL, BigVul, Draper, REVEAL, and VulDeepecker), the authors demonstrated that White-Basilisk achieved state-of-the-art performance in binary vulnerability prediction, outperforming significantly larger models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "+ focus on a practical task\n+ good performance\n+ sound model architecture"}, "weaknesses": {"value": "1. lack of architectural ablation\n\nThe core weakness is the absence of a component-wise ablation study. The individual contribution and necessity of each layer type (Mamba, Basilisk Attention, MoE) remain unknown. It is unclear whether the reported performance stems from a synergistic effect of the hybrid design or if a subset of these components would be equally effective. This omission makes it difficult to validate the authors' design choices and to attribute the success to the specific combination of techniques.\n\n2. limited novelty and direct comparison to Jamba \n\nThe overall architecture, including the Mamba, attention, and MoE layers, is highly similar to the Jamba model. The primary differentiation is the replacement of standard attention with the proposed Basilisk linear attention. However, the paper does not include a direct comparison against a Jamba-like baseline (e.g., their architecture with standard attention) to isolate and quantify the performance gain attributable to this new attention mechanism. Without this comparison, the unique impact and advantage of the Basilisk attention over other efficient attention variants in this specific hybrid context are not convincingly established. \n\n3. inconsistent baselines\n\nA major threat to the validity of the performance claims is the use of different sets of baseline models for each dataset. The baselines are drawn from various prior publications rather than being re-evaluated under a consistent, unified experimental setup. This makes it difficult to ascertain whether White-Basilisk's superior performance is inherent or partly an artifact of comparing against sub-optimal or inconsistently trained baselines for a given dataset. A fairer and more convincing evaluation would run all the baseline models on all datasets."}, "questions": {"value": "What's the impact of  Basilisk Attention?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IpMT9davq3", "forum": "Qq3efdQp3f", "replyto": "Qq3efdQp3f", "signatures": ["ICLR.cc/2026/Conference/Submission20162/Reviewer_qnZj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20162/Reviewer_qnZj"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20162/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761713548564, "cdate": 1761713548564, "tmdate": 1762933678345, "mdate": 1762933678345, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces White-Basilisk, a compact 200M parameter model that outperforms larger models in code vulnerability detection tasks, thereby challenging traditional extended wisdom. White-Basilisk focuses on designing dedicated hybrid architectures that meet the unique requirements of vulnerability detection, integrating Mamba layers for local pattern recognition, linear complexity concerns for global context modeling, and conditional computations through Mix of Experts."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "+ Innovative approach: It organically combines the three mechanisms of Mamba, linear attention, and MoE, representing a relatively new architectural integration approach.\n+ Outstanding performance: With a parameter range of only 200M, it outperforms 7B-level models in most tasks."}, "weaknesses": {"value": "- Limited generalization: The method was only trained and validated on C/C++ datasets, and its generalization in languages such as Python and Java was not verified. Given the significance of cross-language vulnerability detection, supplementary evaluations should be conducted on multilingual data.\n- The motivation for model design lacks theoretical support. Although the paper emphasizes that the hybrid architecture \"combines three advantages\", it lacks theoretical or analytical basis for why this combination is particularly effective in vulnerability detection tasks. No clear mapping relationship was provided between task features and architectural components.\n- Unavoidable training costs. GPT-4, without any domain-specific fine-tuning or additional training cost, already attains similar accuracy through prompt-based reasoning. In contrast, White-Basilisk requires extensive data curation, multi-stage pretraining on millions of C/C++ samples, and additional fine-tuning on multiple vulnerability datasets. Therefore, the author needs to discuss the advantages of this method over LLMS in directly identifying code vulnerabilities."}, "questions": {"value": "- Has the model been tested on other programming languages (e.g., Python, Java) to confirm robustness beyond C/C++?\n- What are the advantages of this method over directly using LLM for code vulnerability detection?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2vVhF6VUUM", "forum": "Qq3efdQp3f", "replyto": "Qq3efdQp3f", "signatures": ["ICLR.cc/2026/Conference/Submission20162/Reviewer_8dGP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20162/Reviewer_8dGP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20162/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761789885897, "cdate": 1761789885897, "tmdate": 1762933677820, "mdate": 1762933677820, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents White-Basilisk, a 200M-parameter hybrid model for code vulnerability detection. The architecture interleaves (i) Mamba layers for linear-time local modeling, (ii) a modified Infini-style linear attention called Basilisk Self-Attention that processes the input in segments and maintains cumulative memory across segments, $O=\\sigma(\\beta) \\odot total_{mem} + (1 - \\sigma(\\beta)) \\odot total_{attn}$, and (iii) Mixture-of-Experts layers scheduled by an offset/period rule. The model is first pretrained on 2M C/C++ files from StarCoder and then fine-tuned on five public datasets (PRIMEVUL, BigVul, Draper, REVEAL, VulDeepecker), reporting strong F1 and VD-S despite severe class imbalance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Originality: A task-specific hybrid that combines Mamba, linear attention with cumulative memory, and MoE, rather than scaling a plain transformer. Eq.~(5) gives an explicit layer-scheduling rule.\n\nQuality: The attention mechanism is mathematically specified: $M_{\\text{new}} = M + (\\mathrm{ELU}(K)^\\top + 1) V,\\quad\n  z_{\\text{new}} = z + \\sum_{i=1}^S (\\mathrm{ELU}(K_i) + 1)$, and the complexity is analyzed (Sec. F). Imbalance handling (class weights, weighted sampler, SIFT) is clearly explained.\n\nClarity: Pretraining vs.\\ fine-tuning is clearly separated; datasets and splits are listed; evaluation uses F1 and VD-S appropriate for security.\n\nSignificance: On BigVul and other benchmarks, the dataset-specific model (200M) reports F1 scores higher than several 7B code LLMs, which, if validated, is a practically relevant result."}, "weaknesses": {"value": "Non-reproduced baselines. Many comparisons rely on numbers copied from prior papers (CodeT5, CodeBERT, UnixCoder, StarCoder2, CodeGen2.5, VulBERTa) instead of running them on the same cleaned splits, so the “outperforms models up to 35$\\times$ larger” claim is weaker than stated.\n\nExtremely high BigVul performance. The dataset-specific setting reports $\\text{Acc}=0.994$, $\\text{F1}=0.949$, $\\text{VD-S}=0.040$, which is unusually high for a ~6% vulnerable dataset and could indicate data/sampling advantages. The paper should rule out evaluation leakage or overfitting.\n\n\nPaired PRIMEVUL is still hard. On the PRIMEVUL paired evaluation, White-Basilisk achieves P-C=12.92%, which is close to GPT-4 CoT (12.94%) but still worse than random (22.70%). This contradicts the broader “state-of-the-art across benchmarks” phrasing.\n\nEfficiency is partly unsubstantiated. The method accumulates segment outputs and thus has $O(nd) + O(d^2)$ memory, not the pure streaming $O(d^2)$, and pretraining still took 600 hours on a single A100 40GB GPU, which is nontrivial for a 200M model. \n\nNarrow language scope. All experiments are on C/C++, so claims about “code vulnerability detection” in general should be narrowed to “C/C++-style datasets.”"}, "questions": {"value": "1- The paper claims a 24x memory reduction over quadratic attention. For which sequence lengths and which baseline was this measured? Please provide actual GPU memory and throughput numbers for 16K, 32K, 131K, and 524K tokens.\n\n2- For BigVul and PRIMEVUL, were baselines actually rerun on your preprocessed splits, or were all numbers imported? If imported, please rerun at least CodeBERT/UnixCoder to confirm the gap. \n\n3- In Eq.(5), did you try a denser attention schedule (smaller period $\\pi$)? What was the effect on PRIMEVUL F1? \n\n4- For the PRIMEVUL paired task, can you provide confusion matrices or per-class TP/FP/FN to show that the model is not simply biasing toward one label? \n\n5- For the 524K-token full-file run, was this done on a single A100 40GB with MoE enabled, and what batch size/grad checkpointing settings were used?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nEYslKzcDk", "forum": "Qq3efdQp3f", "replyto": "Qq3efdQp3f", "signatures": ["ICLR.cc/2026/Conference/Submission20162/Reviewer_TP2R"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20162/Reviewer_TP2R"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20162/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761802017443, "cdate": 1761802017443, "tmdate": 1762933676861, "mdate": 1762933676861, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "## **Summary**\nThis paper proposes **White-Basilisk**, a hybrid architecture for code vulnerability detection that integrates Mamba (state-space modeling), linear self-attention, and a Mixture of Experts (MoE) framework. The model aims to achieve efficient long-context processing while maintaining strong representational power. It is evaluated on five public vulnerability datasets (e.g., BigVul, PRIMEVUL, VulDeepecker) and reports state-of-the-art results with only 200M parameters. The paper also claims improved scalability and performance on imbalanced data distributions, positioning White-Basilisk as a compact yet competitive alternative to larger transformer-based models."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "## **Strengths**\n\n1. **Experiment Quality**  \n   The experimental section is extensive in dataset coverage, spanning multiple well-known benchmarks. The reported results suggest strong empirical performance and scalability, demonstrating the potential of hybrid sequence modeling beyond traditional transformers.\n\n2. **Clarity**  \n   The paper is generally well-organized, with detailed architectural diagrams and formulas. The presentation of computational complexity and efficiency claims is clear.\n\n4. **Significance**  \n   The work tackles a high-impact, real-world problem — automated software vulnerability detection — where efficiency and scalability are crucial. If the reported gains are validated, the proposed hybrid approach could have meaningful implications for applying large-sequence models in security-critical domains."}, "weaknesses": {"value": "## **1. Theoretical and Motivation Issues**\n\n### **1) Substantive Theoretical Contribution is weak**\nThe paper’s central contribution — combining Mamba, linear self-attention, and Mixture of Experts — is essentially an engineering-level hybridization of three existing techniques, each already well-studied in prior work. There is no mathematical derivation or new theoretical insight to show why this combination yields better generalization or stability. For example, the “Basilisk Self-Attention” is described mainly as an incremental variant of Infini-Attention, without any theoretical justification for its claimed improvements.\n\n### **2) Weak and overly generic motivation**\nThis paper doesn't articulate why existing models fail conceptually or how the proposed hybrid mechanism directly addresses those failures beyond computational efficiency. The “bigger is not always better” argument lacks concrete analytical grounding and does not build a clear hypothesis linking the hybrid architecture to the domain-specific characteristics of code vulnerability detection.\n\n## **2. Experimental Weaknesses**\n\n### **1) Missing Ablation Studies**\nAlthough the paper lists multiple architectural components, it does not isolate their individual contributions. The “Ablation Study” section mentioned in the appendix index isn't clearly presented in the main results. There are no results showing the effect of removing Mamba, MoE, or Basilisk attention individually, making it impossible to attribute the reported gains to some specific design parts.\n\n### **2) Insufficient Details in Fine-Tuning and Evaluation**\nFine-tuning hyperparameters, validation-split criteria, and early stopping strategies are only listed generically (in an appendix table) without explanations or empirical rationale. Moreover, it remains unclear whether data deduplication, class balancing, or data leakage prevention were applied during fine-tuning—critical issues in vulnerability datasets such as BigVul and VulDeepecker.\n\n## **3. Writing Issues**\n\nThe introduction focuses excessively on industrial motivation while missing conceptual gaps in existing architectures. The theoretical and experimental sections are densely filled with formulae and data but lack an interpretive statement."}, "questions": {"value": "1. **Theoretical Justification**  \n   The main contribution seems to be an engineering combination of Mamba, linear self-attention, and Mixture of Experts.  \n   - Could you clarify the theoretical motivation behind this hybrid design?  \n   - Why should these mechanisms be complementary rather than redundant?  \n   - Is there any analytical or empirical evidence that this combination improves generalization or stability beyond computational efficiency?\n\n2. **Motivation and Problem Framing**  \n   The introduction presents a general “bigger is not always better” argument but lacks domain-specific reasoning.  \n   - What *conceptual failures* of existing models does your method aim to solve in code vulnerability detection?  \n   - How does the proposed hybrid architecture leverage structural characteristics of code, such as control or data flow?\n\n3. **Ablation and Component Analysis**  \n   Multiple components are introduced, yet no ablation studies are provided.  \n   - Could you present quantitative results for removing or replacing **Mamba**, **MoE**, or **Basilisk Self-Attention**?  \n   - Which component contributes most to the reported performance improvements and why?\n\n4. **Fine-Tuning and Evaluation Details**  \n   - Were duplicate or overlapping samples across datasets (e.g., *BigVul*, *VulDeepecker*) removed before fine-tuning?  \n   - How were early stopping, validation splits, and hyperparameter selections determined?  \n   - Please clarify whether class balancing or weighting was applied.\n\n5. **Reproducibility and Statistical Reliability**  \n   - Could you provide standard deviations or significance tests for key metrics?  \n   - If possible, please release the evaluation scripts or processed subsets to facilitate reproducibility."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "o6qgLGgbmD", "forum": "Qq3efdQp3f", "replyto": "Qq3efdQp3f", "signatures": ["ICLR.cc/2026/Conference/Submission20162/Reviewer_ShmY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20162/Reviewer_ShmY"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20162/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761825859602, "cdate": 1761825859602, "tmdate": 1762933673072, "mdate": 1762933673072, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}