{"id": "ZYuPaFsqsS", "number": 19957, "cdate": 1758300963630, "mdate": 1759897010434, "content": {"title": "Accelerating Denoising Generative Models is as Easy as Predicting Second-Order Difference", "abstract": "High-fidelity diffusion and flow models remain latency-bound at inference, motivating acceleration that leaves pretrained weights untouched. We ask: what is the $\\\\textit{minimal yet principled}$ way to accelerate sampling? Under a simple and mild budget, when uniform reduction targets more than $2\\\\times$ speedup, each three-step window contains at most one fresh denoiser call, creating a structural scarcity of real signals.\nFrom this constraint, we isolate the $\\\\textit{observed}$ information at step $t$—the fresh output $\\\\psi_t$ and its backward difference $\\\\Delta \\\\psi_{t}^{(1)}=\\\\psi_t-\\\\psi_{t+1}$—and show it induces a uniquely minimal, affine-exact second-order predictor $\\\\hat\\\\psi_{t-1}=2 \\\\psi_t- \\\\psi_{t+1}$.\nWe prove that, under this scarcity, the two-point second-order rule is the information-consistent optimum: it is BLUE among linear two-point estimators.\nNaively chaining this predictor across consecutive steps destabilizes sampling by compounding approximation errors.\nWe resolve this by $\\textit{reusing the observed tuple}$ in an interleaved zig–zag schedule that prevents back-to-back extrapolations and controls variance. \nThe resulting method, $\\textbf{ZEUS}$, is a zero-overhead, backbone- and parameterization-agnostic plug-in requiring no retraining, no feature caches, and no architectural changes.\nAcross images and video, ZEUS consistently moves the speed–fidelity Pareto frontier outward versus recent state-of-the-art, delivering up to $3.2\\\\times$ end-to-end speedup while improving perceptual similarity.", "tldr": "Accelerating Denoising Generative Models is as Easy as Predicting Second-Order Difference", "keywords": ["Diffusion Models", "Generative Models", "Training-Free Acceleration"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/59642c6a47d4b8405d178b103b59d72c9815f3de.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "ZEUS accelerates diffusion/flow sampling without retraining by leveraging a budget‑induced “signal scarcity,” where each three‑step window contains at most one fresh denoiser call. Using only the fresh output and its backward difference, it derives a uniquely minimal, affine‑exact second‑order predictor proven BLUE among linear two‑point estimators, and stabilizes chaining via an interleaved zig–zag schedule that avoids back‑to‑back extrapolations. The zero‑overhead plug‑in is backbone‑ and parameterization‑agnostic, requiring no caches or architectural changes, and consistently pushes the speed–fidelity Pareto frontier outward on images and video with substantial end‑to‑end speedups and improved perceptual similarity."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper conducts extensive experiments to show the superiority.\n2. It provides a theoretical analysis."}, "weaknesses": {"value": "1. This paper is hard to read due to poor writing.\n2. The proposed method is very similar to Taylor ($\\mathcal{O}=1$) for obtaining $\\widehat\\psi_{t-1}$.\n3. I believe the method induces lots of memory costs, which is not justified by the authors.\n4. The authors only provide comparisons with DiCache for FLUX. I believe they should include comparisons for the other models.  Also, the settings for baselines in this paper are not clear.\n5. The performance of TaylorSeer is inconsistent (a huge gap) with its original paper (Tab. 1 for FLUX)."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Eow6124rZm", "forum": "ZYuPaFsqsS", "replyto": "ZYuPaFsqsS", "signatures": ["ICLR.cc/2026/Conference/Submission19957/Reviewer_34k7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19957/Reviewer_34k7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19957/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761765461307, "cdate": 1761765461307, "tmdate": 1762932134418, "mdate": 1762932134418, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ZEUS (Zero-cost Extrapolation-based Unified Sparsity), a training-free and backbone-agnostic method for accelerating denoising generative models—such as diffusion and flow-based architectures—without modifying model weights, retraining, or using feature caches. Empirically, ZEUS is evaluated across five backbones (e.g., Stable Diffusion 2, SDXL, Flux.1-dev, Wan 2.1, CogVideoX v1.5) and two solvers (Euler and DPM++), consistently pushing the speed–fidelity Pareto frontier forward. It achieves up to 3.2× end-to-end speedup while maintaining or improving perceptual metrics such as LPIPS, FID, and PSNR."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors formally prove the BLUE optimality and second-order accuracy of the proposed predictor, and justify why higher-order extrapolants are suboptimal or unstable under limited fresh computation. The combination of theory (bias–variance characterization, affine invariance) with practical implementation (zig–zag reuse schedule) demonstrates high technical soundness.\n\n2. ZEUS has strong practical and scientific significance. It provides a zero-cost, architecture-agnostic plug-in that can be directly applied to large-scale diffusion and flow models such as SDXL, Flux, and Wan2.1. The method delivers up to 3.2× inference acceleration while maintaining or even improving fidelity (LPIPS/FID), which represents a meaningful advance in the efficiency of generative modeling."}, "weaknesses": {"value": "1. Evaluation scope and metric coverage.\n\nAlthough the experiments are extensive, the paper primarily reports traditional similarity metrics (PSNR, LPIPS, FID) and qualitative visual comparisons. However, these metrics capture perceptual closeness rather than semantic or compositional fidelity. For text-to-image generation, including evaluations such as GenEval or DPG-Bench would better reflect whether ZEUS preserves prompt alignment and fine-grained attribute consistency after aggressive skipping. This would strengthen claims of maintaining “fidelity” beyond pixel-level similarity.\n\n2. No discussion on potential integration with caching or mixed-precision methods.\n\nWhile ZEUS is intentionally designed as a zero-overhead plug-in, the paper stops short of exploring synergy with complementary acceleration families, such as feature-cache re-use (DeepCache, AB-Cache). Discussing how ZEUS could combine with these orthogonal techniques to achieve compound acceleration would expand its utility."}, "questions": {"value": "Lack of analysis on strong modern backbones.\n\nAll reported results focus on mid-scale or publicly available diffusion/flow models (e.g., SDXL, Flux.1-dev, Wan2.1). The paper does not evaluate on more recent state-of-the-art text-to-image backbones like FLUX-Krea, and Qwen-Image that exhibit stronger coupling between text and visual features. Since ZEUS claims architecture-agnostic generalization, demonstrating performance on these modern DiT-based models would further substantiate scalability and practical relevance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "e1z1O2Biba", "forum": "ZYuPaFsqsS", "replyto": "ZYuPaFsqsS", "signatures": ["ICLR.cc/2026/Conference/Submission19957/Reviewer_4EiC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19957/Reviewer_4EiC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19957/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761811195593, "cdate": 1761811195593, "tmdate": 1762932133099, "mdate": 1762932133099, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a training-free acceleration method for diffusion models named ZEUS. Based on an information scarcity assumption, the authors derive that a second-order difference predictor is the only form satisfying the BLUE condition. They further introduce an alternating zig–zag reuse mechanism to balance stability and accuracy. The method is zero-cost, requires no feature cache or structural modification, and can be directly embedded into any diffusion or flow-based model during inference. Experiments on Stable Diffusion, SDXL, Flux, Wan, and CogVideoX demonstrate consistent acceleration while maintaining or even improving generation quality, showing that ZEUS is a simple, stable, and general acceleration paradigm."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. **Theoretical simplicity with solid foundation.** The paper rigorously derives that, under specific conditions, the second-order difference serves as the only optimal estimator satisfying the BLUE criterion, leading to a training-free and architecture-invariant extrapolation scheme.\n\n2. **Efficient and stable design.** The proposed Zig–Zag reuse mechanism effectively suppresses multi-step extrapolation drift while maintaining the accuracy of second-order prediction, achieving stable acceleration with zero additional computational cost.\n\n3. **Comprehensive experiments and strong generality.** ZEUS consistently improves the speed–quality trade-off across multiple image and video diffusion models, verifying its practicality and plug-and-play generalization capability."}, "weaknesses": {"value": "1. **Overly structured core assumption.** The key theoretical derivation relies on a constrained premise—when aiming for acceleration beyond 2×, only one of every three consecutive steps can involve a fresh denoiser call. In real-world inference, non-uniform or adaptive scheduling is common, where this assumption may not hold. The paper has not provided theoretical or empirical evidence that the optimality can generalize to such practical cases.\n\n2. **Lack of global stability and error analysis.** While the paper discusses overshoot phenomena and gives local bias–variance scaling laws, these analyses are confined to fixed short segments. In actual diffusion sampling, the process is a long chained integration. The paper does not provide a global upper bound or long-term error propagation analysis, making current stability conclusions largely empirical.\n\n3. **Limited comparison and ablation scope.** The experiments mainly compare with training-free baselines, which are not strictly comparable to ZEUS. Stronger baselines or hybrid cache–predict strategies could be added. Moreover, the ablation design focuses primarily on the authors’ own setting, limiting the generality of the conclusions."}, "questions": {"value": "1. **Theory.** Under non-uniform or adaptive time-step scheduling, does the theoretical optimality of the second-order predictor still hold?\nCan the authors provide a global stability or error bound for the zig–zag reuse process across long sampling trajectories?\nIf a formal bound is not feasible, what is the empirically observed maximum jump length before instability occurs?\n\n2. **Experiments.** It would strengthen the paper to include stronger baselines and high-order solvers for comparison. In addition, although the paper repeatedly claims model-agnostic generalization, experiments are mostly in visual diffusion models; evaluations on audio or text diffusion tasks (with different smoothness characteristics) are needed to validate the generality claim.\n\n3. **Implementation cost.** Although the method is described as zero-cost at the operator level, additional tensor construction, copying, and logic overhead may still exist. Could the authors provide quantitative profiling data to verify that the reported acceleration indeed reflects the end-to-end wall-clock gain?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Sg36ea6d1r", "forum": "ZYuPaFsqsS", "replyto": "ZYuPaFsqsS", "signatures": ["ICLR.cc/2026/Conference/Submission19957/Reviewer_enNh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19957/Reviewer_enNh"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19957/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761918311102, "cdate": 1761918311102, "tmdate": 1762932132282, "mdate": 1762932132282, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}