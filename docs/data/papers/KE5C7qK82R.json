{"id": "KE5C7qK82R", "number": 4730, "cdate": 1757754177832, "mdate": 1759898017389, "content": {"title": "A Formal Comparison Between Chain-of-Thought and Latent Thought", "abstract": "Chain-of-Thought (CoT) elicits reasoning in large language models by explicitly generating intermediate steps in natural language. In contrast, Latent Thought in looped models operates directly in the continuous latent space, enabling computation beyond discrete linguistic representations. While both approaches exploit iterative computation, their comparative capabilities remain underexplored. In this work, we present a formal analysis showing that Latent Thought in Looped Transformers enables parallel computation, which is more efficient than the inherently sequential process of CoT. In contrast, CoT leverages stochastic decoding to approximate solutions to problems where exact computation is intractable. These separations suggest the tasks for which depth-driven recursion is more suitable, thereby offering practical guidance for choosing between reasoning paradigms.", "tldr": "", "keywords": ["transformer", "chain-of-thought", "latent thought", "looped models"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9734342c7654facb0ff4281fc2894787a1c7f693.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper compares two reasoning paradigms in large language models — Chain-of-Thought (CoT) and Latent Thought implemented via Looped Transformers. It provides a formal theoretical analysis showing that Looped Transformers can perform efficient parallel computation by operating in latent space, while CoT reasoning, being sequential, excels in stochastic or approximate problem solving."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "he paper makes a valuable theoretical contribution by precisely linking CoT and Looped Transformers to formal complexity classes, providing a solid mathematical foundation to compare reasoning in latent versus linguistic space."}, "weaknesses": {"value": "The main limitation lies in lack of conceptual clarity and practical interpretability. The theoretical analysis is rigorous, the motivation and intuition for non-specialist readers however are weak — the connection between abstract complexity classes (e.g., TCk, ACk) and practical model behaviors remains opaque. The formalism is heavy and often repeats known results under new notation rather than offering fresh insights. \n\nMost importantly!!!!1 the experimental validation is **very very narrow and superficial**, relying on small-scale, synthetic tasks that do not convincingly demonstrate real-world implications. The comparison between “loops” and “steps” lacks fairness in terms of computational cost and hardware efficiency, which undermines the practical value of the claimed separation. The assumptions about “log-precision” and “polynomial embedding size” are idealized and may not hold in realistic settings. \n\nLast, \nwhile the paper claims to reveal “complementary strengths,” it fails to discuss how these insights can inform model design or prompt engineering, leaving the contribution mostly theoretical and of limited immediate impact."}, "questions": {"value": "see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1RfWBABx7F", "forum": "KE5C7qK82R", "replyto": "KE5C7qK82R", "signatures": ["ICLR.cc/2026/Conference/Submission4730/Reviewer_hvpQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4730/Reviewer_hvpQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4730/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761802032742, "cdate": 1761802032742, "tmdate": 1762917539918, "mdate": 1762917539918, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the concept of latent thought and attempts to provide a formal analysis demonstrating that latent thought emerges in Looped Transformers. It seeks to explore the distinction between Chain-of-Thought (CoT) reasoning and latent thought within this framework. The authors approach the problem by formalizing deterministic computations as graph evaluations and conclude that latent thought facilitates efficient parallel computation, whereas CoT supports randomized approximation.\n\nOverall, the paper suffers from unclear writing and lacks a well-defined objective and motivation. The theoretical analysis is not logically structured, making it difficult to follow. The experimental design is also weak, providing unconvincing results and offering limited insights."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. The explored problem of investigating the gap between Chain-of-Thought (CoT) and latent thought is somewhat useful for developing effective methods of enhancing latent CoT reasoning."}, "weaknesses": {"value": "1. The paper writing is unclear, lacking a well-defined objective and motivation. \n2. The theoretical analysis is not logically structured, making it difficult to follow. \n3. The experimental design is weak, providing unconvincing results and offering limited insights."}, "questions": {"value": "1. Beyond the Looped Transformer architecture, can the proposed theoretical analysis be generalized to other latent CoT structures?\n2. The theoretical analysis is poorly presented. What are the connections among the proposed theorems and lemmas?\n3. How does the experimental design answer the proposed research question in the introduction?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "h7OeaSCkz6", "forum": "KE5C7qK82R", "replyto": "KE5C7qK82R", "signatures": ["ICLR.cc/2026/Conference/Submission4730/Reviewer_aNPY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4730/Reviewer_aNPY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4730/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761855966360, "cdate": 1761855966360, "tmdate": 1762917539225, "mdate": 1762917539225, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a formal comparison between Chain-of-Thought (CoT) reasoning and Latent Thought in Looped Transformers (Looped TFs). Through theoretical analysis and controlled experiments, the authors demonstrate that Looped TFs enable efficient parallel computation in deterministic settings, whereas CoT excels in stochastic approximation tasks. The work establishes asymptotic separations between the two paradigms, suggesting when each reasoning strategy is more suitable."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- **Clear theoretical framing:** The paper provides a rigorous and formal comparison between CoT and Looped TFs, filling an underexplored gap in reasoning analysis.  \n- **Insightful comparative analysis:** The asymptotic and empirical results jointly clarify when each reasoning paradigm is advantageous.  \n- **Strong motivation:** The study addresses an important and timely question in understanding reasoning mechanisms in LLMs."}, "weaknesses": {"value": "- **Simplifying assumptions:** The theoretical setting (deterministic vs. stochastic) abstracts away several practical factors that may affect real model behavior.  \n- **Clarity issues:** Some formal sections (e.g., proof sketches and separation definitions) could use more intuitive explanation or visualization."}, "questions": {"value": "- **Assumption Robustness:**  The theoretical analysis relies on several strong assumptions (e.g., polynomial-size graphs, log-precision). How sensitive are the conclusions to these assumptions? Would relaxing them change the separation results?\n- **Empirical Validation:**  The experiments (e.g., DAG and DNF counting) are highly synthetic. Can the authors demonstrate results on realistic reasoning benchmarks to confirm the claimed separation holds empirically?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4TjmmThVv4", "forum": "KE5C7qK82R", "replyto": "KE5C7qK82R", "signatures": ["ICLR.cc/2026/Conference/Submission4730/Reviewer_nkKB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4730/Reviewer_nkKB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4730/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931337525, "cdate": 1761931337525, "tmdate": 1762917538982, "mdate": 1762917538982, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}