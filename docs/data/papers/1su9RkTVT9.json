{"id": "1su9RkTVT9", "number": 1431, "cdate": 1756881805210, "mdate": 1763572973289, "content": {"title": "Growing with Your Embodied Agent: A Human-in-the-Loop Lifelong Code Generation Framework for Long-Horizon Manipulation Skills", "abstract": "Large language models (LLMs)-based code generation for robotic manipulation has recently shown promise by directly translating human instructions into executable code, but existing approaches are limited by language ambiguity, noisy outputs, and limited context windows, which makes long-horizon tasks hard to solve.\nWhile closed-loop feedback has been explored, approaches that rely solely on LLM guidance frequently fail in extremely long-horizon scenarios due to LLMs' limited reasoning capability in the robotic domain, where such issues are often simple for humans to identify. \nMoreover, corrected knowledge is often stored in improper formats, restricting generalization and causing catastrophic forgetting, which highlights the need for learning reusable and extendable skills. \nTo address these issues, we propose a human-in-the-loop lifelong skill learning and code generation framework that encodes feedback into reusable skills and extends their functionality over time.\nAn external memory with Retrieval-Augmented Generation and a hint mechanism supports dynamic reuse, enabling robust performance on long-horizon tasks.\nExperiments on Ravens, Franka Kitchen, and MetaWorld, as well as real-world settings, show that our framework achieves a 0.93 success rate (up to 27% higher than baselines) and a 42% efficiency improvement in feedback rounds. \nIt can robustly solve extremely long-horizon tasks such as \"build a house\", which requires planning over 20 primitives.", "tldr": "We teach robots reusable skills with humans in the loop, letting them remember, adapt, and even build a house.", "keywords": ["large language model", "long-horizon manipulation", "code generation", "lifelong learning", "human-in-the-loop"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f00d6f4f4685798dfb2e21993b0a6301036220ce.pdf", "supplementary_material": "/attachment/021c550fc118f2cbca11c104a4f75529f1dbd67d.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces LYRA, a human-in-the-loop lifelong learning framework for LLM-based code generation in robotic manipulation, focusing on acquiring and extending reusable skills to handle long-horizon tasks like building structures. The framework encodes human feedback into modular skill functions stored in an external memory, using retrieval-augmented generation (RAG) and user hints for dynamic reuse, addressing issues like noisy LLM outputs, catastrophic forgetting, and limited context windows in prior code-as-policies approaches. They demomnstrate reasonable performance on benchmarks (Ravens, Franka Kitchen, MetaWorld) and real-world tasks (e.g., \"build a house\" with >20 primitives)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The combination of human-in-the-loop skill learning with lifelong capability extension through user-designed curriculum is a reasonable contribution. The hint mechanism for guiding RAG retrieval is simple but effective. The paper clearly articulates limitations of existing LLM-based code generation approaches (language ambiguity, catastrophic forgetting, limited context) and proposes a well-motivated solution.\n\n2. Evaluation spans three simulation benchmarks plus real-world deployment, demonstrating broader applicability than many code generation works\n\n3. Impressive long-horizon performance: They successfully solve \"build a house\" requiring 20+ primitives represents a genuine advance in manipulation complexity."}, "weaknesses": {"value": "1. Limited Novelty: Individual components (RAG for code generation, human-in-the-loop feedback, skill libraries) exist in prior work. The main contribution is their integration for robotic manipulation.\n\n2. Insufficient comparison to state-of-the-art: The paper mentions VLA foundation models (OpenVLA, π0, GR00T) in related work but does not compare against them experimentally. Given these models address similar long-horizon manipulation problems, the lack of comparison significantly weakens claims about superiority.\n\n3. The heavy reliance on human-in-the-loop for feedback and curriculum design limits scalability to real deployments without experts."}, "questions": {"value": "1. Can the authors provide comparisons with stronger baselines on the benchmarks like OpenVLA, π0?\n\n2. How much human time (in hours) was required to build the skill library for each benchmark? This is critical for assessing practical feasibility. Please provide this analysis in the paper.\n\n3. Since the proposed is based heavily on the human-in-the-loop procedure for feedback, can the authors comment on possible alternatives to avoid this limitation, and how can they be effectively deployed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "TCrT75Hfjp", "forum": "1su9RkTVT9", "replyto": "1su9RkTVT9", "signatures": ["ICLR.cc/2026/Conference/Submission1431/Reviewer_rJdU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1431/Reviewer_rJdU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1431/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761823748845, "cdate": 1761823748845, "tmdate": 1762915767384, "mdate": 1762915767384, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Response letter to the Reviewers, Area Chairs, and Program Chairs"}, "comment": {"value": "We would like to express our sincere gratitude to the reviewers for their thoughtful and constructive feedback throughout the review process, which has been invaluable in improving the clarity, rigor, and overall quality of our submission. We have carefully addressed every comment raised by the reviewers and have incorporated all requested empirical and quantitative analyses, including\n\n**(1) The quantitative assessment of HITL time efficiency.**  \nOur timestamp analysis shows that human reasoning time remains under 8 seconds and the full feedback cycle averages ~30 seconds, which is of the same order of magnitude as LLM-based feedback (15.8 seconds on average); this demonstrates that **human-in-the-loop intervention introduces no substantial time penalty while providing far more reliable guidance.**\n\n**(2) Comprehensive comparisons with recent hierarchical or lifelong RL baselines.**  \nAcross 10 Meta-World tasks, **LYRA** achieves up to **1.0 success rate** with $\\leq 5$ corrections and attains zero forgetting, **outperforming** HiLL, Text2Reward, and LEGION, all of which fail to generalize to **extreme** long-horizon tasks.\n\n**(3) Additional evaluations against recent VLA models.**  \nWhile OpenVLA and $\\pi_0$ perform comparably on short-horizon tasks, both collapse to **0.0 success** on our **$>$20-primitive Ravens tasks**, whereas our **LYRA** maintains **0.80–0.95 success**, demonstrating **clear outperform in extreme long-horizon manipulation.**\n\nDetailed responses to each point are provided in our individual rebuttals. We are deeply grateful to the reviewers, the Area Chairs, and the Program Chairs for their time, effort, and insightful guidance. We respectfully look forward to the reviewers' further feedback on our revised manuscript and respective response comments, and we remain committed to contributing meaningfully and responsibly to the open-source AI and robotics community."}}, "id": "86bdvuSQg7", "forum": "1su9RkTVT9", "replyto": "1su9RkTVT9", "signatures": ["ICLR.cc/2026/Conference/Submission1431/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1431/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1431/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763559635017, "cdate": 1763559635017, "tmdate": 1763565239466, "mdate": 1763565239466, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes LYRA, a human-in-the-loop lifelong code generation framework for robotic manipulation that integrates LLM-based program synthesis, human feedback, and skill memory retrieval. Unlike prior LLM-only closed-loop approaches that struggle on long-horizon tasks, LYRA encodes user feedback into reusable, modular “skills”, stores them in external memory with retrieval-augmented generation (RAG), and enables users to guide the agent through hint-based dynamic skill selection. The framework continually expands its capabilities via a user-designed curriculum, achieving lifelong skill acquisition without catastrophic forgetting. Experiments across Ravens, Franka Kitchen, MetaWorld, and real-world Franka FR3 tasks demonstrate great success rate, outperforming LLM-only baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The integration of human-in-the-loop feedback, external memory, and modular skill representation provides a robust alternative to end-to-end LLM-driven methods.\n2. The framework emphasizes skill inheritance and continual expansion, a key step toward reusable and interpretable robotic skills.\n3. Covers simulation (Ravens, Franka Kitchen, MetaWorld) and real-world deployment, with quantitative and qualitative evidence."}, "weaknesses": {"value": "1. While comparisons to LLM code-generation baselines are thorough, the paper omits strong lifelong or hierarchical RL baselines (e.g., HiLLa, BOSS, Text2Reward-type methods).\n2. The framework heavily relies on manual feedback and a user-designed curriculum. Specifically: (1) user-guided skill code generation, (2) user-guided skill capability extension with few-shot examples, and (3) user-provided hints to direct the agent toward the correct subset of skills as the number of skills |Z| and behaviors |E| increases. This reliance on human intervention can be costly, particularly when scaling to hundreds of skills or when the users are less experienced."}, "questions": {"value": "1. \"a meta-prompt that explicitly asks the agent to preserve prior functionality while adapting to new tasks\" To keep the balance between stability (preserving old skills) and plasticity (acquiring new functionality), the paper uses 1) Meta-prompt Regularization 2) Modular Code Extension 3) Re-evaluation Loop. How is the evaluation result on this part? What is the Average number of corrections (NoC)?\n2. Few-shot examples that show mappings from instructions to task-specific code plan would be really helpful for LLM to generate skill program. These examples are retrieved based on the semantic similarity between the new instruction and previously seen instructions. My question is: are these examples environment-specific to those used in the experiments, or are they designed to be environment-agnostic? Moreover, how robust and generalizable is the proposed approach when faced with a new task that lacks a corresponding example in the existing code library?\n3. \"The agent can freely modify implementation details under the reserved skill name\" How detailed the user's instruction would be(Does it require user be very clear about the attributes of the objects in the envrionments?)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "La8ZhpFPNq", "forum": "1su9RkTVT9", "replyto": "1su9RkTVT9", "signatures": ["ICLR.cc/2026/Conference/Submission1431/Reviewer_ak7i"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1431/Reviewer_ak7i"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1431/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761975552313, "cdate": 1761975552313, "tmdate": 1762915767234, "mdate": 1762915767234, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to address limitations in using LLMs for robotic code generation, specifically their struggles with long-horizon tasks, language ambiguity, and catastrophic forgetting. The authors propose LYRA, a human-in-the-loop (HITL) lifelong learning framework. LYRA enables an agent to learn reusable skills as Python functions, guided by human feedback. These skills and successful task examples are stored in an external memory and retrieved using Retrieval-Augmented Generation to solve new tasks. The framework includes a user-designed curriculum for extending skill capabilities and a \"hint\" mechanism for guiding retrieval. Experiments in simulation (Ravens, Franka Kitchen, MetaWorld) and on a real Franka FR3 robot show LYRA achieves relatively strong performance and improvement in feedback efficiency, successfully solving complex tasks like \"build a house\"."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- Involving HITL feedback, a user-driven curriculum to LLM-robotic control is novel and interesting.\n- The evaluation is thorough, spanning three distinct simulation benchmarks (Ravens, Franka Kitchen, MetaWorld) and a real-world Franka FR3 robot.\n- The ablations are insightful: LYRA w/o memory and LYRA w/ LLM feedback directly prove the value of the two core components.\n- The \"build a house\" task serves as a good and compelling demonstration. Claiming to be the first to solve this task, the authors clearly show how a complex behavior can be decomposed into 12 hierarchically-learned skills."}, "weaknesses": {"value": "- The paper combines several well-established ideas: HITL, RAG, and code-generation. The authors should clarify whether the framework introduces specific novel contributions versus the integration of existing ideas.\n\n- The paper strongly motivates the need for HITL by showing LLM-only feedback is unreliable, but it does not adequately quantify the cost of the human. The \"42% efficiency improvement\" is measured in \"Average number of corrections\". This metric is useful but incomplete. It hides the human's cognitive load and time-per-round. A human correction might be 1 round but take 10 minutes, while an LLM correction takes 10 rounds at 30 seconds each."}, "questions": {"value": "- The \"hint\" mechanism is described as \"simple yet effective\", but its implementation and UI are omitted. How does a user provide this hint? Is it free-form text that is then parsed?\n\n- What is the mechanism for the \"roll back from failure\"? If a 20-step plan (like \"build a house\")  fails at step 15, does the user correct from that state, or must the entire task be restarted? How is task state managed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "52juAuyO3D", "forum": "1su9RkTVT9", "replyto": "1su9RkTVT9", "signatures": ["ICLR.cc/2026/Conference/Submission1431/Reviewer_njQ7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1431/Reviewer_njQ7"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1431/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993010158, "cdate": 1761993010158, "tmdate": 1762915767119, "mdate": 1762915767119, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}