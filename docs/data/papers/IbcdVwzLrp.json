{"id": "IbcdVwzLrp", "number": 2339, "cdate": 1757059515314, "mdate": 1763630366333, "content": {"title": "ProtoTS: Learning Hierarchical Prototypes for Explainable Time Series Forecasting", "abstract": "While deep learning has achieved impressive performance in time series forecasting, it becomes increasingly crucial to understand its decision-making process for building trust in high-stakes scenarios. Existing interpretable models often provide only local and partial explanations, lacking the capability to reveal how heterogeneous and interacting input variables jointly shape the overall temporal patterns in the forecast curve. We propose ProtoTS, a novel interpretable forecasting framework that achieves both high accuracy and transparent decision-making through modeling prototypical temporal patterns. ProtoTS computes instance-prototype similarity based on a denoised representation that preserves abundant heterogeneous information. The prototypes are organized hierarchically to capture global temporal patterns with coarse prototypes while capturing finer-grained local variations with detailed prototypes, enabling expert steering and multi-level interpretability. Experiments on multiple realistic benchmarks, including a newly released LOF dataset, show that ProtoTS not only exceeds existing methods in forecast accuracy but also delivers expert-steerable interpretations for better model understanding and decision support. The source code is available at https://anonymous.4open.science/r/ProtoTS-D791/.", "tldr": "", "keywords": ["Time series forecasting; Interpretability"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ce0b9e3e681f02b97466759a6e665c6658f99737.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a hierarchical prototype framework for explainable time series forecasting, combining prototype similarity with multi-channel embeddings to improve forecasting accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper proposes a clear framework that connects prototype with time series forecasting.\n\n2. Experimental results show competitive accuracy and provide case studies that make it easy to understand."}, "weaknesses": {"value": "1. The introduction claims that ProtoTS is the first to model prototypical temporal patterns. However, Sec 2 already cites some prototype-based time-series models . It would be clearer if the authors could clarify more explicitly what innovation distinguishes ProtoTS from these prior works.\n\n2. The paper does not clearly explain how the learned prototypes remain semantically meaningful throughout training. The optimization objective lacks explicit constraints ensuring diversity or interpretive consistency among prototypes, which may lead to redundant prototypes.\n\n3. In experiment, adding the discussion of computational cost and complexity analysis would make the performance more convincing."}, "questions": {"value": "The authors could refer to Weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HpuFZ1VPLR", "forum": "IbcdVwzLrp", "replyto": "IbcdVwzLrp", "signatures": ["ICLR.cc/2026/Conference/Submission2339/Reviewer_Ju6i"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2339/Reviewer_Ju6i"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2339/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761177124874, "cdate": 1761177124874, "tmdate": 1762916198671, "mdate": 1762916198671, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ProtoTS, an interpretable time series forecaasting framework that learns hierarchical prototypes. The model combines a multi-channel bottleneck encoder for heterogeneous variables with a hierachical prototype tree for coarse-to-fine interpretability. Experiments on load-forecasting and electricity price datasets show accuracy gains and improved interpretability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The framework is conceptually novel. The proposed hierarchical prototypes for interpretable time series forecasting is novel and empircally verified. \n- The model design, including multi-channel embedding, bottleneck fusion, is clearly justified and contributes to performance. \n- The case study is intuitive and interesting. It well-demonstrates real-world applicability. \n- The paper is generally well written, equations align with intuition, and the proposed architecture is easy to follow."}, "weaknesses": {"value": "- Experiments are limited to two datasets within the energy domain. Broader validation on additional domains (e.g., weather, traffic, retail, healthcare) would better demonstrate the generality and adaptability of ProtoTS.\n- Forecasting accuracy is reported only with MAE. Reporting MSE would provide a more comprehensive assessment.\n- Baselines include mainly traditional statistical or early deep models (ARIMA, XGBoost). I suggest comparing with more recent models such as PatchTST and TimesNet, and FEDformer.\n- Reported accuracy gains are not validated by statistical significance tests \n- The relationship with ProseNet (Interpretable and Steerable Sequence Learning via Prototypes, KDD 2019) should be discussed more thoroughly, as both share conceptual similarities in prototype-based interpretability and steering. \n- For quantiative interpretability test, only User Precision and System Usability Score are reported. I suggest considering additional metrics such as fidelity, faithfulness, which do not rely on human judgment.\n- The robustness of learned prototypes could be evaluated by introducing noise or perturbations in the input time series to test whether prototype assignments remain stable.\n- Please clarify whether the 12 participants in the user study were domain experts (e.g., energy analysts) or general users. \n- Also, please justify or discuss whether a sample size of 12 provides sufficient statistical reliability.\n- The case study focuses solely on load forecasting. I suggest adding more case studies on the other dataset as well. I belive this case study is the core result of the paper’s interpretability claim and thus presenting additional case studies (e.g., price forecasting, weather, or traffic datasets) would substantially strengthen the paper.\n- The anonymous GitHub repository provides only minimal instructions. Please add detailed environment setup instructions, data-preprocessing scripts, configuration files, and run commands so that results can be reproduced reliably."}, "questions": {"value": "Please refer to weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HK7htNylWP", "forum": "IbcdVwzLrp", "replyto": "IbcdVwzLrp", "signatures": ["ICLR.cc/2026/Conference/Submission2339/Reviewer_Tt99"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2339/Reviewer_Tt99"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2339/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761368956620, "cdate": 1761368956620, "tmdate": 1762916198336, "mdate": 1762916198336, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ProtoTS, an interpretable forecasting framework that models prototypical temporal patterns. The weights of these prototypes are determined by measuring the similarity between different prototypes. To balance predictability and interpretability, the authors introduce a hierarchical structure, allowing a root prototype to be split into more detailed child prototypes. The experimental results indicate that ProtoTS achieves strong forecast accuracy while also providing interpretations that can be guided by expert knowledge."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed hierarchical structure, where prototypes are progressively refined into lower levels, offers a compelling approach to managing the trade-off between forecasting accuracy and interpretability.\n\n2. The experiments demonstrate that ProtoTS delivers strong performance on time series forecasting tasks that include exogenous variables."}, "weaknesses": {"value": "1.\t**Guidance on Hierarchical Structure**: While the hierarchical prototype structure is a key contribution, the paper lacks a formal or suggested methodology for determining the optimal number of leaf-prototypes. Providing a general splitting rule would enhance the practical applicability of the framework.\n2.\t**Clarity of the Loss Function**: The formulation of the loss function, which combines an L1-norm with an entropy regularization term, could be further clarified. Specifically, the intended effect of the entropy regularization on promoting a few dominant prototypes is not immediately apparent.\n3.\t**Validation of Interpretability**: The assessment of interpretability relies on a questionnaire administered to 12 users. While this provides initial evidence, the small sample size and the potential for subjective responses may limit the generalizability of these findings."}, "questions": {"value": "**Main concern:** \n\n1. **Variable Interactions**: The paper states that the prototype-instance similarity is computed by \"incorporating a multi-channel embedding and bottleneck fusion mechanism\" to model interactions between input variables. However, the embedding described in Equation (2) appears to be a summation of individual variable embeddings prior to the bottleneck layer. Could the authors elaborate on how this specific architecture facilitates the modeling of interactions between variables?\n\n2. **Entropy Regularization**: In line 300, the stated goal of the entropy term in the loss function is to \"encourage a few main prototypes to cover most predictions.\" Given that negative Shannon entropy is minimized by a discrete uniform distribution, could the authors provide further intuition on how this term achieves the stated objective of encouraging a sparse set of dominant prototypes? Additionally, the inclusion of a tuning parameter (e.g., $\\lambda$) to balance the L1-norm and the regularization term seems warranted and would be a valuable addition.\n\n3. **Scope of Regularization**: The current regularization term appears to only consider the first level of the hierarchical structure. Have the authors considered extending this to other levels of the hierarchy, and what might be the potential impact of such a change?\n\n4. **Choice of L1-Norm**: Could the authors provide the rationale for selecting the L1-norm for the loss function over other metrics such as the L2-norm or domain-specific measures like Dynamic Time Warping?\n\n5. **Prototype Splitting Criteria**: The experiments include a sensitivity analysis on the number of prototypes. However, a more detailed discussion on the rules for splitting prototypes would be beneficial. Have the authors considered implementing a formal rule, such as a threshold-based criterion (e.g., $ f(Z|\\mu)>\\alpha $  or a metric like the Gini index, to guide the splitting process and maintain a robust balance between predictive accuracy and interpretability?\n6. **Simulation for Interpretability**: To further strengthen the claims regarding interpretability, have the authors considered conducting a simulation study? A simulation with a known ground truth for the underlying prototypes and hierarchical structure could provide a more objective evaluation of the model's ability to recover these causal relationships.\n\n**Minor concerns:** \n\n1.\tLine 29: The phrase \"their overall interpretability and their potential\" could be revised for clarity, as the second \"their\" is redundant.\n\n2.\tLine 76: \"input covariates\" is repetitive. Using either \"inputs\" or \"covariates\" would be more concise.\n\n3.\tLine 84: Similarly, \"interactions of covariate combinations\" could be shortened to \"interactions of covariates.\"\n\n4.\tFigure 2 (Similarity Computing): The percentages shown (0.35, 0.65, 0.1) sum to 1.1. Please verify these values.\n\n5.\tLine 208: \"is holiday\" should be corrected to \"holiday.\"\n\n6.\tLine 234: The text states the process is \"along the temporal dimension and then along the feature dimension,\" while Equation (3) suggests the fusion occurs along the feature dimension first. Please clarify this sequence.\n\n7.\tLine 236: The meaning of T in Equation (3) is unclear. Please provide a definition.\n\n8.\tLine 249: For consistency, \\mu should be rendered in boldface.\n\n9.\tLine 303: To be precise, the L1-norm should be denoted with a subscript, for instance, $|| \\cdot ||_1$."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ifoZrdjoiK", "forum": "IbcdVwzLrp", "replyto": "IbcdVwzLrp", "signatures": ["ICLR.cc/2026/Conference/Submission2339/Reviewer_AWPh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2339/Reviewer_AWPh"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2339/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761730751988, "cdate": 1761730751988, "tmdate": 1762916198163, "mdate": 1762916198163, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ProtoTS, an interpretable forecasting framework that models hierarchical prototypes to achieve both high accuracy and explainability in time series forecasting. The method builds a hierarchy of prototypes representing multi-scale temporal patterns and incorporates a multi-channel similarity mechanism for heterogeneous inputs. The approach is ambitious and technically solid, aiming to connect interpretable representation learning with practical forecasting performance."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper presents an original attempt to unify interpretability and accuracy through hierarchical prototype learning.\n- It offers a systematic framework combining multi-level structure, prototype reasoning, and human-editable interpretability.\n- The experiments and visual analyses are thorough and insightful."}, "weaknesses": {"value": "### **Problem & Motivation**\n\n- The motivation to move beyond local or post-hoc explanations toward global interpretable forecasting is strong and well justified.\n\n- However, it remains unclear how this approach differs fundamentally from previous prototype-based or dictionary-learning forecasting methods that already encode recurring temporal patterns.\n\n- The paper could better articulate how hierarchical prototypes specifically enhance interpretability compared to flat prototypes or segment-level reasoning.\n\n- The expert-steering feature is intriguing, but its implementation and scalability remain vague.\n\n---\n\n### **Method**\n\n- It is not clearly explained how prototypes and the model output are computed, given an input $x$. The mechanism by which a new time series sample is assigned to or reconstructed from prototypes is ambiguous.\n\n- The description also leaves uncertainty about whether there is a prototype per sample or whether prototypes are shared across samples in a latent cluster space.\n\n- Since the interactions occur in the latent space, it is unclear how one can meaningfully interpret what each prototype represents in the original time domain. A mapping or visualization process should be clarified.\n\n---\n\n### **Experiments**\n\n- The experimental scope is narrow. All evaluations are performed on a limited set of datasets; broader diversity in data domains (e.g., finance, energy, healthcare) and different lookback windows would make the results more generalizable.\n\n- There is almost no comparison with other ante-hoc or post-hoc XAI models. The paper mainly compares against interpretable models, but not against modern post-hoc explanation techniques that could provide competitive interpretability, while also achieving superior performance.\n\n- The paper should explicitly discuss the trade-off between interpretability and performance, perhaps through a 2D evaluation showing both forecast error and explanation quality.\n\n- It is unclear why models like TimeXer and ITrans are excluded from qualitative comparisons in Table 4. These baselines could offer meaningful insights into representational interpretability."}, "questions": {"value": "Please refer to the weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7qXJL2qNC6", "forum": "IbcdVwzLrp", "replyto": "IbcdVwzLrp", "signatures": ["ICLR.cc/2026/Conference/Submission2339/Reviewer_cW3t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2339/Reviewer_cW3t"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2339/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761796228098, "cdate": 1761796228098, "tmdate": 1762916198019, "mdate": 1762916198019, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response (part 3/3): user study"}, "comment": {"value": ">- reviewer AWPh: **Validation of Interpretability**: The assessment of interpretability relies on a questionnaire administered to 12 users. While this provides initial evidence, the small sample size and the potential for subjective responses may limit the generalizability of these findings.\n>\n>- reviewer Tt99: Please clarify whether the 12 participants in the user study were domain experts (e.g., energy analysts) or general users. Also, please justify or discuss whether a sample size of 12 provides sufficient statistical reliability.\n\nWe thank reviewers **AWPh** and **Tt99** for their thoughtful comments regarding the design and reliability of the user study. We clarify that the study participants were **research practitioners with prior familiarity with deep learning methods**. Before the study, all participants received a **brief tutorial** covering essential background on electricity load forecasting and its domain-specific covariates, ensuring they meaningfully evaluate the explanations.\n\nFollowing the reviewers’ suggestions, we have **expanded the user study from 12 to 24 participants**, and we now additionally report the **variance (standard deviation) of user precision**. The low variance indicates that participants’ responses were highly consistent, suggesting that the statistical conclusions are stable. This strengthens the reliability of our interpretability evaluation. Prior usability work [1] also demonstrated that \"sample sizes of at least 12-14 participants are needed to get reasonably reliable results.\", indicating that our updated study with 24 participants provides adequate statistical reliability.\n\nThe updated results are shown below. We have updated the table to the latest revision.\n\n| Model   | UPrec (mean) ↑ | UPrec (std) | SUS Score ↑ |\n| ------- | -------------- | ----------- | ----------- |\n| ProtoTS | **79%**        | 3.6%        | **73.36**   |\n| TFT     | 64%            | 3.4%        | 29.74       |\n| NBEATSx | 62%            | 2.8%        | 38.66       |\n\n[1] A Comparison of Questionnaires for Assessing Website Usability"}}, "id": "bz6mMC09me", "forum": "IbcdVwzLrp", "replyto": "IbcdVwzLrp", "signatures": ["ICLR.cc/2026/Conference/Submission2339/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2339/Authors"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2339/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763556761221, "cdate": 1763556761221, "tmdate": 1763556900834, "mdate": 1763556900834, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response (part 2/3): dataset scope and different lookback window"}, "comment": {"value": ">- reviewer cW3t: The experimental scope is narrow. All evaluations are performed on a limited set of datasets; broader diversity in data domains (e.g., finance, energy, healthcare) and different lookback windows would make the results more generalizable.\n>\n>- reviewer Tt99: Experiments are limited to two datasets within the energy domain. Broader validation on additional domains (e.g., weather, traffic, retail, healthcare) would better demonstrate the generality and adaptability of ProtoTS.\n\nWe thank both reviewers for raising the concern regarding the experimental scope. We would like to clarify that the main paper includes two energy datasets due to space limitations, but our full experimental evaluation spans other domains (energy, meteorology, finance), as shown in Appendix G (table 10). ProtoTS is additionally evaluated on:\n\n- **Etth** dataset (energy domain),\n\n- **Weather** dataset (meteorology domain),\n\n- **Exchange** dataset (finance domain).\n\nThis evaluation follows the same dataset scope as prior work TimeXer[1], ensuring fair comparison. Moreover, beyond these public datasets, we also contribute a new **LOF dataset with 22 heterogeneous exogenous variables**, offering richer covariates than existing benchmarks.\n\nTo further validate generality under different lookback window, we additionally test ProtoTS and three best preformed baseline (TimeXer , iTransformer, TiDE) under a **different lookback window setting** (lookback = 288, forecast = 96) on the LOF dataset. ProtoTS continues to outperform strong baselines:\n\n| MSE  | TimeXer | iTrans | TiDE   | ProtoTS    | MAE  | TimeXer | iTrans | TiDE   | ProtoTS    |\n| ---- | ------- | ------ | ------ | ---------- | ---- | ------- | ------ | ------ | ---------- |\n| RE   | 0.1638  | 0.1650 | 0.1574 | **0.0980** | RE   | 0.2777  | 0.2651 | 0.2525 | **0.2099** |\n| PC   | 0.0649  | 0.0459 | 0.0666 | **0.0268** | PC   | 0.1726  | 0.1410 | 0.1646 | **0.1158** |\n| YC   | 0.0129  | 0.0082 | 0.0070 | **0.0064** | YC   | 0.0859  | 0.0646 | 0.0578 | **0.0569** |\n| EA   | 0.0171  | 0.0111 | 0.0082 | **0.0067** | EA   | 0.0867  | 0.0765 | 0.0622 | **0.0587** |\n\n[1] TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables. NIPS 2024."}}, "id": "bomIul3Zh4", "forum": "IbcdVwzLrp", "replyto": "IbcdVwzLrp", "signatures": ["ICLR.cc/2026/Conference/Submission2339/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2339/Authors"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission2339/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763556802540, "cdate": 1763556802540, "tmdate": 1763556881105, "mdate": 1763556881105, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response (part 1/3): the difference from previous prototype-based methods"}, "comment": {"value": "> - reviewer cW3t: However, it remains unclear how this approach differs fundamentally from previous prototype-based or dictionary-learning forecasting methods that already encode recurring temporal patterns.\n> - reviewer Tt99: The relationship with ProseNet (Interpretable and Steerable Sequence Learning via Prototypes, KDD 2019) should be discussed more thoroughly, as both share conceptual similarities in prototype-based interpretability and steering.\n> - reviewer Ju6i: The introduction claims that ProtoTS is the first to model prototypical temporal patterns. However, Sec 2 already cites some prototype-based time-series models . It would be clearer if the authors could clarify more explicitly what innovation distinguishes ProtoTS from these prior works.\n\nWe thank reviewers **cW3t, Tt99, and Ju6i** for the insightful comments.\n\nTo clarify the conceptual distinction between **ProtoTS** and prior prototype-based time-series models, we provide a **unified mathematical view** showing that *all* prototype-based time series methods—whether for anomaly detection, classification, or forecasting—can be written in an attention-style **Q–K–V structure**:\n$$\n\\text{Query  Q}=f(x),\\text{Keys K} = \\text{prototype embedding},\\text{Values V} = \\text{prototype value}.\n$$\nA sample is encoded into a **query** $Q$, which retrieves a set of **prototype embeddings** (keys) $K$, whose associated **values** $V$ determine how prototypes contribute to prediction. Under this unified Q–K–V view, prior works differ *primarily* in how the value $V$ is defined:\n\n**“Prototype-as-hidden-state” methods (e.g., hybrid anomaly detection [1, 2], Time-LLM [3]): **These methods use $V \\in R^{d_\\text{latent}}$, $V$ represent a latent hidden state passed into a downstream black-box decoder. Therefore, the prototypes **do not map directly** to the forecasting targets. \n\n**\"Prototype-as-parameters\" method (e.g. channel clustering [4]): ** These methods use $V = g(x)$, $V$ represent a forecasting model. The prototypes do not correspond to any fixed temporal pattern in output space.\n\n**“Prototype-as-output-logit” methods (e.g., ProseNet [5, 6], TIMEX [7, 8]):** These methods decode a prototype into a single output variable $V \\in \\mathbb{R}$ or at most a very low-dimensional vector. This structure suits **classification**, where each prototype corresponds to a logit, but fundamentally cannot support multi-step forecasting. Thus they lack the ability to help users quickly interpret the reasons behind the overall trend in the forecast curve.\n\nIn contrast, ProtoTS is, to our knowledge, the first framework that decodes each prototype into an entire multi-step forecasting curve $V \\in R^{T}$, $T$ represents a cycle length (e.g. 96 time steps). This enables temporal-pattern interpretability, which prior prototype-based time-series models fundamentally cannot provide.\n\n[1]Learn hybrid prototypes for multivariate time series anomaly detection.  ICLR 2025.\n\n[2]Prototype-oriented unsupervised anomaly detection for multivariate time series.  ICML 2023.\n\n[3]Time-llm: Time series forecasting by reprogramming large language models. ICLR 2024.\n\n[4]From similarity to superiority: Channel clustering for time series forecasting. NIPS 2024.\n\n[5]Encoding time-series explanations through self-supervised model behavior consistency. NIPS 2023.\n\n[6]Timex++: Learning time-series explanations with information bottleneck. ICML 2024.\n\n[7]Interpretable and steerable sequence learning via prototypes. KDD 2019.\n\n[8]Example or prototype? learning concept-based explanations in time-series. ACML 2022."}}, "id": "8jm3lvGerP", "forum": "IbcdVwzLrp", "replyto": "IbcdVwzLrp", "signatures": ["ICLR.cc/2026/Conference/Submission2339/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2339/Authors"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission2339/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763556850582, "cdate": 1763556850582, "tmdate": 1763556850582, "mdate": 1763556850582, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}