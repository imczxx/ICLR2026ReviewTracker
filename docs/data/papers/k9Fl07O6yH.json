{"id": "k9Fl07O6yH", "number": 10926, "cdate": 1758184889629, "mdate": 1759897620662, "content": {"title": "Knowledge Guided Bayesian Flow Network for CAD Sequence Generation", "abstract": "The controllable generation of parametric CAD sequences under explicit quantitative constraints (e.g., surface area, volume) is crucial for automating design processes, as it enables the efficient and precise creation of complex geometric models that meet predefined functional or physical requirements. However, this task remains highly challenging due to the multimodal nature of CAD data, which combines discrete commands and continuous parameters, as well as the long-range dependencies among parameters that are critical for satisfying the constraints. While deep generative models have shown remarkable progress in various domains, they still struggle with parametric CAD sequence generation under strict quantitative constraints. To tackle this, we propose a generative framework based on a Knowledge-Guided Bayesian Flow Network (KGBFN). Our approach leverages Bayesian flow to jointly model discrete and continuous variables, effectively capturing the complex structure of CAD data. Moreover, we introduce a knowledge-guided Bayesian update strategy that iteratively injects property constraints during the generation process, significantly enhancing the accuracy of the produced sequences. To improve computational efficiency, we design a dual-channel Bayesian flow network that integrates both traditional and knowledge-guided updates, employing an annealing mechanism to dynamically control the activation of different channels. This design effectively balances knowledge guidance with optimization efficiency. We validate our method on CAD generation tasks constrained by quantitative properties such as surface area and volume. Experimental results demonstrate that our model consistently outperforms state-of-the-art methods in both single and multi-condition constrained generation, achieving superior performance in terms of accuracy and feasibility.", "tldr": "", "keywords": ["Parametric CAD modeling", "Bayesian flow network", "Quantitatively constrained generation"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c26ac3449e662a0e74d2c6875773d553e9b2be9f.pdf", "supplementary_material": "/attachment/a87a08bceb9394c86c5826ff287bed2cc4cf5fc2.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces the Knowledge-Guided Bayesian Flow Network (KGBFN) to address the generation of parametric CAD sequences under precise quantitative constraints (e.g., target surface area or volume). The framework represents CAD sequences as a flat, discrete token sequence, making them suitable for a Bayesian Flow Network (BFN). The use of direct, non-differentiable error feedback from a geometry engine is a clever mechanism."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. This paper is well-written and easy to follow.\n\n2. Most CAD generation research focuses on qualitative shape fidelity. This paper tackles the much more difficult and practical engineering problem, generating a model that adheres to precise quantitative specifications.\n\n3. The core mechanism of injecting a direct error signal from a non-differentiable, external geometry engine back into the generative process is an innovative touch."}, "weaknesses": {"value": "1. The paper's novelty is significantly tempered by latest work (TGBFN[*]) that addresses the identical problem with the same base model (BFN) and data representation. Besides, the performance of proposed KGBFN is much far from the TGBFN, which again further weakens the contribution of this manuscript.\n\n2. The overview diagram shown in Figure 1 is extremely similar to the architecture diagram in TGBFN[*] in terms of composition style and icons used. The reviewer strongly suggests that the author modify and redraw Figure 1. \n\n3. While the annealing mechanism is shown to reduce training time, the inference process for the final KGBFN model is still computationally expensive. Table 4 shows that KGBFN inference (2266s) is ~63% slower than the standard BFN baseline (1390s), which could be a barrier to practical, real-time applications. Meanwhile, the inference time of TGBFN[*] could run in round 12s, which significantly surpasses the proposed KGBFN.\n\n4. The general approach of using BFNs for quantitatively-constrained CAD generation is not unique. The latest paper \"Target-Guided Bayesian Flow Networks\" (TGBFN[*])  tackles the identical problem (BFN for CAD under area/volume constraints) and also discretizes the data. While the method of guidance differs (direct error-signal injection in KGBFN vs. a learned posterior guidance model in TGBFN), the core problem setup and base model are the same, which significantly reduces the paper's fundamental originality.\n\n5. The current framework is only demonstrated on global constraints (total surface area, total volume). It is unclear how this method would scale to more complex and common local constraints (e.g., \"the radius of this specific hole must be 10mm\"). The current global error-vector feedback signal seems insufficient for such fine-grained, local control.\n\n[*] Wenhao Zheng, Chenwei Sun, Wenbo Zhang, Jiancheng Lv, and Xianggen Liu. Target-Guided Bayesian Flow Networks for Quantitatively Constrained CAD Generation. In Proceedings of the 33rd ACM International Conference on Multimedia (MM '25). Association for Computing Machinery, New York, NY, USA, 3330–3339. https://doi.org/10.1145/3746027.3755052"}, "questions": {"value": "1. Considering the proposed whole framework of KGBFN is very similar to TGBFN[*]. Can the authors clearly state the advantages of their \"direct error injection\" method compared to TGBFN's \"learned guided posterior\" method? Why is one approach superior to the other? From an experimental perspective, the performance of KGBFN is far inferior to that of TGBFN.\n\n[*] Wenhao Zheng, Chenwei Sun, Wenbo Zhang, Jiancheng Lv, and Xianggen Liu. Target-Guided Bayesian Flow Networks for Quantitatively Constrained CAD Generation. In Proceedings of the 33rd ACM International Conference on Multimedia (MM '25). Association for Computing Machinery, New York, NY, USA, 3330–3339. https://doi.org/10.1145/3746027.3755052"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ooDDDBMmWe", "forum": "k9Fl07O6yH", "replyto": "k9Fl07O6yH", "signatures": ["ICLR.cc/2026/Conference/Submission10926/Reviewer_dNRF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10926/Reviewer_dNRF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10926/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761824244993, "cdate": 1761824244993, "tmdate": 1762922126889, "mdate": 1762922126889, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes the Knowledge-Guided Bayesian Flow Network (KGBFN) for generating parametric CAD sequences under quantitative constraints (e.g., surface area, volume). Its core innovation is a \"knowledge-guided Bayesian update.\" During denoising, the model periodically uses an external CAD tool (PythonOCC) to compute the geometric properties of intermediate sequences. The resulting property deviation is then injected back as \"knowledge\" to guide generation. To manage the high computational cost, the authors use a dual-channel architecture with an annealing mechanism to balance guidance frequency and efficiency. Experiments on a CAD subset show KGBFN outperforms baselines on single and multi-constraint tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The key contribution is integrating non-differentiable domain knowledge directly into the BFN's iterative process. By rendering and calculating property deviations mid-generation, the model gets explicit feedback on hard constraint satisfaction, a clever approach for constrained generation.\nThe authors pragmatically address the computational bottleneck of the PythonOCC guidance. The proposed dual-channel architecture and annealing mechanism allow the model to dynamically skip expensive guidance steps, achieving a reasonable trade-off between performance and efficiency, as validated by ablation studies."}, "weaknesses": {"value": "All experiments use a highly simplified dataset. Real-world CAD models have far longer sequences. The examples shown are simple extrusions, not \"complex geometric models.\" There is no evidence this method scales to complex, long-sequence tasks.\n\nThe core mechanism relies on repeatedly calling PythonOCC for B-Rep rendering. This is extremely expensive: inference time increased significantly (Table 4) and training took 200-370 hours (Table 3) for simple tasks. The method is computationally unfeasible for longer sequences, limiting its practical value."}, "questions": {"value": "Can you provide performance data on longer, more complex CAD sequences (e.g., length > 200)? how do you assess the computational feasibility of this method for real-world tasks?\nthe annealing probability is not deeply analyzed.which stage of the denoising process is knowledge guidance most critical?\nThe experiments are limited to global properties (area, volume). What about others?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ikqhkBLO5s", "forum": "k9Fl07O6yH", "replyto": "k9Fl07O6yH", "signatures": ["ICLR.cc/2026/Conference/Submission10926/Reviewer_1Z6b"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10926/Reviewer_1Z6b"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10926/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761837417354, "cdate": 1761837417354, "tmdate": 1762922126383, "mdate": 1762922126383, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In the field of CAD generation, this paper proposes a knowledge guided Bayesian flow network, which, on the basis of the traditional Bayesian flow network, introduces the guidance of surface area and volume through an annealing mechanism, improving controllability over surface area and volume. However, this paper lacks originality, contains some ambiguous technical points in its writing, and the method has issues at the practical application level. Besides,  the experiments in the paper are insufficient. The specific comments are presented in the Strengths and Weaknesses parts."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-organized and easy to follow. \n\n2. The CAD sequence generation problem is interesting."}, "weaknesses": {"value": "- Novelty:\n\n(1) This paper shows a very large similarity to TGBFN [1] in both figures and methodology; both add control information of surface area and volume on top of BFN, and the originality is very limited.\n\n- Methods:\n\n(1) Despite the annealing mechanism, the time for PythonOCC to compute surface area and volume is still too long, leading to defects of the method in practical applications.\n\n(2) The paper uses BFN as the basic generation method, but lacks a theoretical comparison with D3PM and a comparison of generation results with D3PM under the same experimental conditions, i.e., knowledge guiding based on the annealing mechanism.\n\n(5) In the early stage of inference when noise is relatively large, the CAD sequence tends to be invalid, and it may not be possible to compute volume and surface area through PythonOCC. The paper does not specifically explain how this situation is handled.\n\n- Writing:\n\n(1) The guidance information in the paper is surface area and volume; calling it “knowledge guided” is somewhat far-fetched.\n\n(2) The paper presents the method pipeline with only one figure, resulting in rather cluttered information in the figure and some missing information. It is recommended to split this figure into multiple figures and appropriately add details such as the network architecture.\n\n(3) The abstract mentions “jointly model discrete and continuous variables” but the subsequent content does not further explain how continuous parameters are modeled.\n\n- Experiments:\n\n(1) The paper does not compare with the latest CAD sequence generation methods, e.g., TGBFN [1], Seek-CAD [2], CAD-GPT [3].\n\n(2) The paper needs to add more generated visual results to demonstrate the diversity of the generations.\n\n\n- Reference:\n\n\n[1]Zheng, Wenhao, et al. \"Target-Guided Bayesian Flow Networks for Quantitatively Constrained CAD Generation.\" Proceedings of the 33rd ACM International Conference on Multimedia. 2025.\n\n[2]Li, Xueyang, et al. \"Seek-CAD: A Self-refined Generative Modeling for 3D Parametric CAD Using Local Inference via DeepSeek.\" arXiv preprint arXiv:2505.17702 (2025).\n\n[3]Wang, Siyu, et al. \"Cad-gpt: Synthesising cad construction sequence with spatial reasoning-enhanced multimodal llms.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 39. No. 8. 2025."}, "questions": {"value": "(1) The proposed method uses surface area and volume as control conditions; however, in practical applications it is rare to use surface area and volume as control conditions. Could methods that use more common controls such as bounding boxes, point clouds, and sketches be further explored?\n\n(2) Where is the advantage of guidance based on surface area and volume compared with guidance based on rendered vision?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ybPkWU3zIt", "forum": "k9Fl07O6yH", "replyto": "k9Fl07O6yH", "signatures": ["ICLR.cc/2026/Conference/Submission10926/Reviewer_9Yuq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10926/Reviewer_9Yuq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10926/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761873388103, "cdate": 1761873388103, "tmdate": 1762922125889, "mdate": 1762922125889, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focus on generating  parametric CAD sequences under geometric constraints. It proposed a knowledge-guided BFN to jointly model discreate and continuous parameters in the CAD sequences. The rendered geometric property feedback is computed from intermediate steps."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Authors proposed knowledge-guided and dual channel BFN, which leads to better results. But I should say I am not an expert in BFN. And it is unclear to me why we even need BFN for this task. There is clearly a lot of diffusion and AR or combined model that can handle both continuous and discrete data. I don't see a clear advantage for BFN in this case."}, "weaknesses": {"value": "Task formulation is a bit weird, usually when it comes to CAD constraints, one think of geometry or topology constraints. E.g two holes should be equal radius, the two planes should be parallel to each other, the holes should be positioned here for connectivity etc. Directly using volume and surface area to control overall generation is definitely a less common task. It is also more interesting to understand how the constraint enable reasoning or CoT during generation, as oppossed to directly using it as a condition as in the paper."}, "questions": {"value": "Since I am not an expert on Bayesian Flow Networks, I will leave detailed questions about the network design and implementation to other reviewers. From a CAD generation perspective, the visual results are quite limited . Examples shown are mostly simple primitives such as cubes and cylinders. This level of visual complexity is insufficient to demonstrate the model’s capability for generating realistic or diverse CAD, which honestly is a more fundemantal problem that needs to be solved before controllable generation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "L3SzI2N2SK", "forum": "k9Fl07O6yH", "replyto": "k9Fl07O6yH", "signatures": ["ICLR.cc/2026/Conference/Submission10926/Reviewer_VUuG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10926/Reviewer_VUuG"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10926/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762204632728, "cdate": 1762204632728, "tmdate": 1762922125486, "mdate": 1762922125486, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}