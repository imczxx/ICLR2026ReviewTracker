{"id": "p15DIvdOV9", "number": 12961, "cdate": 1758212116793, "mdate": 1763000788942, "content": {"title": "Flowing with Precision: Rectified Flow Image Editing with Trajectory and Frequency Guidance", "abstract": "Rectified flow text-to-image models have shown remarkable progress. However, editing complex scenes containing multiple objects remains challenging due to semantic entanglement and structural inconsistency. To address this, we propose a dual-domain framework that jointly refines temporal editing trajectories and adapts frequency domain. First, we design a Starting Point Optimization (SPO) strategy, which intelligently determines the optimal editing starting point based on the structural complexity of different images. Second, we introduce a Trajectory Optimization (TO) strategy. In the time domain, it performs semantic-aware vector orthogonalization to suppress source bias while preserving target semantics. In the frequency domain, it adaptively re-weights high and low frequency residuals according to stage-specific spectral characteristics. Furthermore, we leverage the frequency-aware capabilities of MM-DiT to dynamically inject structural priors from the source image at different denoising steps.Our method allows users to add, replace, or modify multiple objects, making it highly efficient for editing complex scenes. Experiments show that our method significantly outperforms existing methods for image editing and achieving higher user preference in human evaluations.", "tldr": "", "keywords": ["Image edit；Diffusion model"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/d82e4bd2fcff6dde2f4b9f7564f30c2c12cb377c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a rectified-flow-based image editing framework that improves semantic alignment and structural preservation in complex, multi-object scenes. The key innovations include:\n1. Starting Point Optimization (SPO) – adaptively choosing the optimal timestep to start editing.\n2. Trajectory Optimization (TO) – orthogonalizing semantic and structural editing vectors in both time and frequency domains.\n3. Attention Remapping – selective feature injection across MM-DiT layers for layout and refinement phases.\n4. Experiments on PIEBench, PIEBench++, and OIR-Bench demonstrate superior fidelity and flexibility over RF-based and diffusion-based baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear problem definition and systematic analysis of editing phases.\n2. Well-motivated dual-domain (time + frequency) optimization.\n3. Impressive visual results and detailed ablation/user studies.\n4. Training-free, plug-and-play design suitable for practical use."}, "weaknesses": {"value": "1. Limited theoretical novelty.\nSPO and frequency-aware scaling are clever extensions but largely heuristic; they build upon existing inversion-free frameworks like FlowEdit and FlowAlign with incremental innovation. The paper could more explicitly differentiate its contributions from prior flow-guided works.\n\n2. Complexity and interpretability.\nThe method involves several intertwined components (SPO, vector orthogonalization, FFT modulation, multi-phase attention). It is unclear which components most critically drive improvements—despite ablations, the causal links are not deeply analyzed.\n\n3. Computational efficiency.\nThe approach adds frequency transforms and per-timestep adaptive scaling, potentially increasing runtime. There is no comparison of inference time or memory usage against baselines such as FireFlow or StableFlow.\n\n4. Heuristic parameter tuning.\nThe determination of SPO start point (via low-frequency MSE) and scaling factors (α, β) are empirically set. The paper lacks sensitivity analysis or robustness evaluation for these hyperparameters.\n\n5. Scope of generalization.\nWhile results on multi-object scenes are impressive, the paper focuses only on static images. Discussion of extension to video or 3D scenes would improve its broader impact."}, "questions": {"value": "1. How sensitive is performance to the SPO threshold or to the frequency weighting parameter α?\n2. What is the computational overhead compared to FlowEdit or StableFlow?\n3. Could the same idea be generalized to temporal consistency in video editing?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Y81ROZZypj", "forum": "p15DIvdOV9", "replyto": "p15DIvdOV9", "signatures": ["ICLR.cc/2026/Conference/Submission12961/Reviewer_h4Yd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12961/Reviewer_h4Yd"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12961/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761314884884, "cdate": 1761314884884, "tmdate": 1762923718566, "mdate": 1762923718566, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "kOEQjY5pDq", "forum": "p15DIvdOV9", "replyto": "p15DIvdOV9", "signatures": ["ICLR.cc/2026/Conference/Submission12961/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12961/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763000788208, "cdate": 1763000788208, "tmdate": 1763000788208, "mdate": 1763000788208, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes an integrated editing framework, leveraging three distinct components targeting at different aspects of diffusion model's generation process to perform image edting. The framework combines several technical operations, including identification of different stages of diffusion generation process, semantic isolation by orthogonal projection, frequency modulation and attention injection. All these techniques reflect the up-to-date progress of image editing with diffusion models comprehensively. With such effort the proposed editing framework achieves good editing results on both PIE and OIE benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The paper tackles the image editing task from different aspects of diffusion models,  including:  \n-  The generation machnism like different stages of generation process and frequency evolving characterstics, that is being studied to network components (attention modules).\n- The semantic space of diffusion models and corresponding operations.\n- The widely studied and applied attention operation to fuse generation from two branches/paths.\n\nSpecifically, the paper proposes:\n\n1. Identifying different stages of generation process via comparing the similarity of scores(diffusion network output) from different branches.\n2. Semantic isolation of the cross branch to decrease the constraint from the source structure.\n3. Frequency bands modulation on the overall editing score $V_{edit}$ to eliminate distortion.\n4. Attention injection to prevent editing leakage.\n\nWith combining the technical components together, the proposed editing framework achieve good editing results on two general editing benchmarks."}, "weaknesses": {"value": "1. Several of the proposed technical components lack clear motivation or demonstration of originality. For instance, regarding the orthogonal projection of the cross-prompt vector onto the cross-trajectory vector, it remains unclear how this improvement was discovered or why the projection is implemented in the current manner rather than an alternative formulation. Similarly, for the frequency-modulation component, the paper does not explain how the authors identified this particular frequency as crucial for addressing distortion, nor why Eq. (11) provides an effective solution to this issue. **The absence of explicit motivation and analytical justification for these technical designs hinders the perceived originality of the work, especially given that similar components have appeared in prior studies.**\n\n2. Important implementation details and hyperparameters are missing. For example, the numerical value of $\\alpha$ used in frequency modulation is neither specified nor discussed in the main text or the supplementary materials. Although the authors mention setting $\\beta = 4$, the initial value $\\beta_0$ is not clarified. Additionally, the definition of the boundary between high- and low-frequency regions is omitted. Other key parameters used during the editing process, such as $T_{\\text{turn}}$, are also unspecified — it is unclear whether this is fixed to a common value such as $T_0$ or determined individually for each editing pair. \n\n3. Most proposed components are insufficiently analyzed through experiments. The ablation study only reports quantitative benchmark results obtained by removing individual components, without providing deeper empirical investigations into the choice or sensitivity of corresponding hyperparameters.\n\n4. The entire editing framework integrates multiple components, temporal operations across different diffusion timesteps, and layer-specific attention injections. To improve clarity and reproducibility, the paper should include a pseudo-code algorithm summarizing the complete framework."}, "questions": {"value": "Please check the weakness mentioned above. And below are some further suggestions:\n\n(1) The Eq.(6) should be moved to preliminary since it is proposed in TurboEdit and serves as one of their main contributions.\n\n(2) There is missing space for $T_{0}$ $T_{turn}$ in Sec 3.2\n\n(3) Please add clear definition to $V^{src}_{tar}$, $V^{src}_{src} $, $V^{tar}_{tar}$, in Fig.4 to avoid confusion.\n\nRating for this paper would be impoved if the questions are addressed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None."}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "1OCPZeIPHQ", "forum": "p15DIvdOV9", "replyto": "p15DIvdOV9", "signatures": ["ICLR.cc/2026/Conference/Submission12961/Reviewer_9Q8V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12961/Reviewer_9Q8V"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12961/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761906836068, "cdate": 1761906836068, "tmdate": 1762923718232, "mdate": 1762923718232, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a training-free image editing method based on text-to-image flow models. The method is divided into two main parts. First, a module called Starting Point Optimization that determines the “optimal” editing starting timestep according to the spectral components of the intermediate edit directions. Second, a module called Trajectory Optimization which decomposes the commonly-used editing direction into a cross-prompt term and a cross-trajectory term, and forces orthogonalization between them. Additionally, this module employs frequency domain reweighting, and uses attention feature injection. The authors conduct various experiments to evaluate their method."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The quantitative and qualitative results are promising.\n- Novel decomposition of edit velocities into cross-prompt and cross-trajectory.\n- Novel starting timestep selection for the editing procedure."}, "weaknesses": {"value": "Major:\n- Writing clarity - the paper needs refinement in terms of writing clarity. In its current state, it is quite difficult to understand some parts of the method.\n\nFor example:\n\n(a) L262 - the orthogonalized cross-prompt should appear rather than cross-trajectory. Then $\\Delta_{ts}$ and $\\Delta_{ss}$ are defined again, and $V\\' \\_{edit}(t)$ is defined without any further explanation as well as the hyperparameter $\\omega$.\n\n(b) The low frequency and high frequency bands are not defined and are used both in Sections 3.2 and 3.3.2 without any further explanation.\n\n(c) In Eq. (9) $\\Delta_{t_i}$ is first presented without any further explanation.\n\n(d) It’s not clear what happens to the channel dimension during the transformation in Eq. (9), and how it translates to the channel dimension of the weighting coefficients defined in Eq. (11).\n\n(e) In Section 3.4 the definitions of $A_j$ and $B_{\\phi(j)}$ are not clear - from which attention map calculations are they taken (for example - from the attention maps of $V(X_{tar}, t, c_{src})$?\n\n(f) In Section 4.1.2 - The paragraph is not complete, so it is not fully clear how the text metrics are evaluated.\n- Qualitative concerns - some results do not fully follow the target text-prompt, for example in Figure 1 in the ‘cartoon style’ edit - the result is not really a cartoon. In Figure 16 in the ‘fox roses’ edit - the flowers have not really changed into roses.\nMoreover, some results do not preserve the structure or identity of the subject, as in Figure 1 in the ‘wearing earrings’ edit - the facial features are changed.\n\nMinor:\n- References to the appendix are missing, e.g. in L392.\n- $V_{tar}^{src}$, $V_{tar}^{tar}$ and $V_{src}^{src}$ are not defined in the main paper (Figure 3 and 4).\n- L296 - Figure number is not mentioned (referenced), and the following paragraph is not fully clear.\n- L309 - cross-attention (CA) abbreviation is used before, this abbreviation should be defined earlier.\n- L316 - $t$ is not consistently defined. In Eq. (1) it is defined in the range [0, 1], but in Eq. (13) it is defined as an integer indicating the timestep index.\n- Figure 7 - Typo in Stableflow.\n- Figures 4, 6, 8 - High negative vspace values used.\n- Figure 14 - looks very compressed with major artifacts (for example in the sixth and seventh rows)."}, "questions": {"value": "- In the Introduction section the authors mentioned that the SPO module determines the editing starting point by calculating the low frequency MSE between the source and target images. However, in Section 3.2 the authors measured the cosine-similarity between the velocity predictions. Which one was used to determine the starting timestep?\n- L234-235 - After the “Chaotic Phase” the image information guides the predictions. What happens if from this point we use an empty prompt or another prompt - It would be interesting to see how it affects the generated image path (as in Figure 3).\n- L272-274 - It could be beneficial to see a few qualitative examples of the effect of different $\\omega$ values.\n- The motivation for the editing velocity decomposition is vague. A visualization of these velocities could be beneficial to understand what they represent across different timesteps. Additionally, how do the orthogonal and non-orthogonal components look like?\n- L308 - How is the mapping $\\phi(j)$ defined? Is it done automatically, or manually chosen by the user? If a token in the source prompt exists in the target prompt, but in another context, what would happen?\nFor example:\nSource prompt - A cat is jumping in a grassy field.\nTarget prompt - A cat is sitting in a grassy field, and a man is jumping in the background of the scene.\n- Section 4.2.2 - It seems like the quantitative evaluation is made with the hyperparameters provided in the official github implementations. However, for different methods, such as RF-Inversion and FireFlow, they provide several hyperparameters. How did the authors choose the set for their evaluations and comparisons?\n\nPlease also see weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3ofLhKLWRk", "forum": "p15DIvdOV9", "replyto": "p15DIvdOV9", "signatures": ["ICLR.cc/2026/Conference/Submission12961/Reviewer_TexM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12961/Reviewer_TexM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12961/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761915803498, "cdate": 1761915803498, "tmdate": 1762923717790, "mdate": 1762923717790, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of high-fidelity, text-guided image editing, particularly in complex, multi-object scenes, using Rectified Flow models. The authors argue that existing methods struggle with a trade-off between structural consistency and semantic alignment  often leading to artifacts or weak edits.  To solve this problem, the authors design a Starting Point Optimization (SPO) strategy and a Trajectory Optimization (TO) strategy. Extensive experiments are conducted to validate their method."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper presents a very well-rounded solution that tackles the editing problem from multiple, complementary angles: SPO, time-domain TO, frequency-domain TO, and Attention Remapping. This multi-pronged approach makes the methodology very solid. \n\n2. The analytical experiments and comparisons with other methods are very thorough, and the results are quite convincing."}, "weaknesses": {"value": "1. The motivation of some strategies is not clearly stated. For example, in Section 3.3 Trajectory Optimization, why are the four terms in Eq. (6) combined into cross-prompt and cross-trajectory?\n\n2. The meaning of some symbols and concepts is not explained. For example,  $V_{src}^{src}$, $V_{tar}^{tar}$ in Figure 3, appearance leakage in Line 73, and so on.\n\n3.  The motivation in the introduction is confusing. The authors base their method on FlowEdit, but don't explain why FlowEdit is unable to perform multi-object editing. Instead, in Lines 65-75, they attribute the difficulty of multi-object editing to the image->latent->image editing framework, which is exactly the problem FlowEdit solves. \n\n4.  The captions of the figures are difficult to understand. For example, it is hard from Figure 5 to conclude the problem in Lines 272-273."}, "questions": {"value": "1. How to obtain $X^{target}_t$ during the editing process? Could the authors provide an algorithm to illustrate the editing process?\n\n2. How does the SPO strategy work? This is not reflected in the main text or Figure 2.\n\n3.  In Section 3.3.2,  why can controlling the frequency components help with the edit? It is hard to understand the motivation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "L9rpBph1wp", "forum": "p15DIvdOV9", "replyto": "p15DIvdOV9", "signatures": ["ICLR.cc/2026/Conference/Submission12961/Reviewer_3kLx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12961/Reviewer_3kLx"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12961/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761930155176, "cdate": 1761930155176, "tmdate": 1762923717414, "mdate": 1762923717414, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a framework for text-guided image editing using rectified flow models, focusing on multi-object and complex scene edits. The method introduces three key components: Starting Point Optimization (SPO), Trajectory Optimization (TO), and attention remapping in MM-DiT. While the approach shows promising results and provides insights into frequency-domain analysis and attention mechanisms, the paper suffers from significant clarity issues that hinder understanding and reproducibility."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper offers a detailed analysis of frequency components during the denoising process (e.g., chaos, layout, and refinement phases) and visualizes attention in MM-DiT layers. This provides valuable insights for future work on rectified flow models, especially in understanding how different stages handle structural and semantic information.\n2. The method achieves promising performance on multiple benchmarks."}, "weaknesses": {"value": "1. Poor Writing, which makes it difficult to follow. Many critical elements are not clearly explained, which significantly undermines the clarity of the motivation and main ideas.\n   - Section 3.2 (Observations on Phased Editing): This should be the most important section, as its analysis motivates the subsequent method design. However, it is severely lacking in clarity: 1) The three variables V in Figure 3 are not properly defined. How are they calculated? What do the superscripts and subscripts represent? 2) It is unclear what is being visualized, is it the V vectors directly, or the latent representations from a denoising process based on V?\n   - SPO Strategy: The details and concrete implementation of the Starting Point Optimization (SPO) strategy are vague. 1) Is a specific step (e.g., step 10, as mentioned in the supplement) used for all images? If so, how does this align with the claim of being \"adaptive\" ? 2) Where does the adaptivity based on \"structural complexity\" come from? Does it require a pre-computation (e.g., denoising and similarity calculation) for each individual image? 3) These crucial questions are all missed, addressed only in a single sentence (lines 236-237).\n\n2. The motivation for the Trajectory Optimization (TO) is not well-justified. Why is it necessary to decompose the editing direction into a cross-prompt term and a cross-trajectory term? What is the purpose and theoretical justification for the subsequent orthogonal projection of these terms?\n\n3. The method involves a highly detailed, architecture-specific analysis of the MM-DiT's attention layers, but does not discuss or demonstrate the generalization capability. It remains unclear whether the method, particularly the attention layer analysis and injection strategy, can be transferred to other DiT models, such as Stable Diffusion 3 (SD3).\n\n4. The experimental section lacks a comparison with a key and relevant baseline: ParallelEdits from the PIE-Bench++ (Huang et al., 2025) benchmark. This omission weakens the comprehensiveness of the experimental validation."}, "questions": {"value": "1. How many denoising steps are used? \n2. After incorporating additional attention injection, what are the memory usage and inference time when processing a single sample?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "9sW3YpaXPc", "forum": "p15DIvdOV9", "replyto": "p15DIvdOV9", "signatures": ["ICLR.cc/2026/Conference/Submission12961/Reviewer_dLgp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12961/Reviewer_dLgp"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission12961/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761981888265, "cdate": 1761981888265, "tmdate": 1762923717003, "mdate": 1762923717003, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}