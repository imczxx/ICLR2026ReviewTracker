{"id": "AC1XQjy8Sa", "number": 18528, "cdate": 1758288818371, "mdate": 1763760490827, "content": {"title": "GapONet: Nonlinear Operator Learning for Bridging the Humanoid Sim-to-Real Gap", "abstract": "The sim-to-real gap, arising from imperfect actuator modeling, contact dynamics, and environmental uncertainty, poses fundamental challenges for deploying simulated policies on physical robots.\nIn humanoids, object manipulation further amplifies this gap: end-effector payloads alter joint inertia, gravity torques, and transmission efficiency, introducing state- and payload-dependent nonlinearities. Yet existing approaches lack both systematic analysis and a generalizable representation of this payload-induced degradation.\nTo address this limitation, we propose GapONet, a payload-conditioned nonlinear operator that maps simulation context functions to residual actions for hardware. We then introduce a payload-aware <collect–analyze–solve> framework to learn this operator GapONet. First, we curate a sim-real paired dataset TWINS spanning multiple payloads, robots, motions, actuation rates, and simulators, comprising more than 11,298 motion sequences. Second, we perform payload-aware system identification to isolate payload-related effects and quantify their contributions, and analyze sim-to-real gaps across different simulators. Third, we train the operator GapONet to predict delta action for real-time, generalized, payload-conditioned compensation. We further introduce actuation functions and sensor predictors, which enable parallel RL training of GapONet with substantially reduced energy consumption.\nWhile tracking unseen motions, GapONet keeps the incidence of large sim-to-real gaps below 0.09%, whereas competing methods remain near 10%. By correcting upper-body gaps, GapONet also stabilizes lower-body locomotion tracking, laying the foundation for improved performance in humanoid loco-manipulation tasks.", "tldr": "", "keywords": ["Sim-to-real gap", "Nonlinear operator", "Humanoid robot"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6bb22ee47863532a2947060d097a58a06e73cae0.pdf", "supplementary_material": "/attachment/27c6696fd6c3d149a4213a0d5839fb2e8d856c9c.zip"}, "replies": [{"content": {"summary": {"value": "The paper presents a well-motivated study on improving sim-to-real transfer for humanoid robots. It contributes a sim–real data collection pipeline and introduces TWINS, the first dataset focusing on payload-induced domain gaps across multiple robots, motions, and simulators. The authors further provide 30+ hours of synchronized sim–real data and quantitative analyses of simulator discrepancies. Finally, they propose GapONet, a payload-conditioned nonlinear operator that maps simulation actuation functions to residual hardware actions, demonstrating its feasibility through reinforcement learning."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper addresses a highly practical challenge in humanoid sim-to-real transfer by explicitly modeling the payload effect not as random noise but as a structured conditioning variable during motion tracking. This perspective is realistic and directly relevant for real-world humanoid deployment.\n2. Building on DeepONet’s operator-learning framework, the paper presents a novel combination between nonlinear operator learning and the sim-to-real transfer process in robotics. It highlights the separable nature of the payload by treating it as the query variable in the operator formulation. Moreover, it introduces an insightful perspective on sim-to-real alignment—modeling the domain gap as a mapping from simulation actuation functions to residual actions, rather than as pointwise corrections.\n3. The paper provides detailed technical descriptions of its data collection pipeline, including the construction of a cross-robot, cross-simulator dataset covering diverse humanoid motions under varying payload conditions. The dataset curation and labeling process are thoroughly documented.\n4. The paper also includes a joint-level comparison across three mainstream simulators. Although not comprehensive and is not the focus of this paper, this analysis provides useful insights and contributes valuable reference for the community."}, "weaknesses": {"value": "1. The paper does not compare the proposed method with other nonlinear system identification approaches, such as neural network-based or kernel-based methods. The related work section on nonlinear system identification is insufficient.\n2. The generalization capability of GapONet beyond payload variation remains unclear. As a method for bridging the sim-to-real gap, its applicability under other changing factors is not demonstrated.\n3. The experimental settings lack clarity, e.g. the training details of baseline methods are missing, including the choice of training and test sets, which makes reproducibility difficult.\n4. The training pipeline and design choices are not well explained. It is unclear why reinforcement learning was chosen.\n5. Some mathematical symbols appear in the paper without explicit definitions, making the derivations harder to follow."}, "questions": {"value": "1. In Figure 1, why does the dataset illustration show the Unitree G1 performing Kung Fu, while the data used for experiments only include three types of lower-body gaits without whole-body tracking motions?\n2. Why did you choose a reinforcement learning (PPO) algorithm to train GapONet, given that the original DeepONet paper uses supervised learning? The paper does not explain the motivation or provide the formal RL formulation.\n3. In Section 4.3, you claim that computing all sensor values is computationally prohibitive. Could you clarify whether this limitation is due to the RL setup? If so, why is RL used instead of supervised regression?\n4. Why is the default large-gap ratio set to 0.5 rad, especially when Figure 3(b) shows that the typical error is below 0.3 rad?\n5. In Section 3.3.2, you state that the deviation is nonlinear and that phase lag is related to payload. However, the phase difference between sim and real does not necessarily imply delay, and there is no quantitative result showing nonlinearity. Could you clarify this claim?\n6. How did you select the data and motions used in Section 3.3? In Figure 3(b), the deviation at 0 kg payload reaches 0.1 rad, but in Figure 3(c), the inter-simulator joint angles appear much smaller. Why?\n7. In the motion tracking and trajectory tracking experiments, what role does GapONet play in real-world tests? \n8. In Section 5.2, you mention an online residual compensation method. Could you describe this method in detail? It is currently unexplained.\n9. In Section 5.1(ii), what is the \"Transformer-learned dynamics model\"? Please specify its structure and training configuration.\n\nAdditional Feedback:\n\n1. Writing and formatting:\n   - Redundant sentence in Section 2.2.\n   - Uneven layout and spacing issues in Figure 1.\n   - Multiple typos in the *Method* section.\n2. Technical presentation:\n   - Please define all mathematical symbols when they first appear.\n   - Consider reorganizing Section 4 to make the training pipeline easier to follow.\n   - Provide explicit details for experimental setup."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2gIjIS7bhM", "forum": "AC1XQjy8Sa", "replyto": "AC1XQjy8Sa", "signatures": ["ICLR.cc/2026/Conference/Submission18528/Reviewer_DFMY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18528/Reviewer_DFMY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18528/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761890043175, "cdate": 1761890043175, "tmdate": 1762928222883, "mdate": 1762928222883, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies sim-to-real gaps introduced due to the end-effector payload during object interaction for humanoid loco-manipulation tasks. The authors proposed TWINS, the first dataset focused on payload-induced sim-to-real gaps across multiple robots, and found a consistent nonlinear increase in dynamics error. They address this by using GapONet, a nonlinear operator that maps simulation context features to real with a function-to-function learning objective, to propose delta actions that compensate for such gaps. Through empirical studies, they demonstrate the effectiveness of their method in motion tracking tasks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "This paper is well motivated, it provides solid problem formulation and theoretically analysis."}, "weaknesses": {"value": "There exist multiple typos in this manuscript (for example: “Modelin” in figure 1) and inconsistent font. These errors in the main figure may reduce reader confidence in the presentation."}, "questions": {"value": "1. \"The discrepancy arises from coupled channels—gravity, friction, Coriolis and inertial coupling, actuator limits and efficiency drift, sensing noise, and delays—that a pointwise function mapping cannot capture or generalize.\" I am still not convinced why learning operators of actuator functions has been necessary or superior to point-wise mappings. Can authors provide more empirical evidence that the insufficiency of the point-wise mapping method fails to generalize?\n\n2. In Table 1, while all methods demonstrate relatively close IQR and Range, baseline methods have significantly larger LGR. What is the explanation of this difference? I am also curious about the effectiveness of these metrics. Which one of the does the author consider the most faithful in measuring the sim-to-real gap?\n\n3. How does the proposed method work for motion tracking that includes agility or actual object interaction? Motion tracking with payload might not be"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "H75g54rQSf", "forum": "AC1XQjy8Sa", "replyto": "AC1XQjy8Sa", "signatures": ["ICLR.cc/2026/Conference/Submission18528/Reviewer_unGq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18528/Reviewer_unGq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18528/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986985697, "cdate": 1761986985697, "tmdate": 1762928221824, "mdate": 1762928221824, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper, \"GapONet: Nonlinear Operator Learning for Bridging the Humanoid Sim-to-Real Gap,\" addresses the critical challenge of transferring policies learned in simulation to real-world humanoid robots. The authors correctly identify that the sim-to-real gap is exacerbated by complex, payload-induced nonlinearities and unmodeled dynamics in high-DoF systems. To tackle this, they propose GapONet, a novel payload-conditioned nonlinear operator network. GapONet is designed to learn a mapping from the simulation context function (i.e., the state and action in sim) to the residual action required on the real hardware, effectively acting as a nonlinear correction layer. The authors also introduce TWINS, a large-scale, synchronized sim-to-real dataset collected across multiple simulators and a real humanoid platform, which is a significant contribution in itself. Experimental results demonstrate that GapONet achieves superior performance in reducing the sim-to-real gap compared to competitive baselines, showing a reduction in tracking error and improved stability, particularly under varying payload conditions."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The core idea of framing the sim-to-real gap correction as a nonlinear operator learning problem is highly original and compelling. While prior work has used residual learning, the application of a payload-conditioned operator network (inspired by Neural Operators) to model the complex, functional relationship of the sim-to-real discrepancy is a novel approach in the context of humanoid robotics. The use of a branch-trunk decomposition to separate the payload-independent dynamics from the payload-dependent non-linearities is a clever architectural choice that enhances generalization. The work is highly significant for the field of sim-to-real transfer, especially for complex, high-DoF systems like humanoids. The introduction of the TWINS dataset is a valuable resource for future research. The GapONet model offers a powerful, generalizable framework for modeling complex unmodeled dynamics, which could be broadly applicable beyond payload variation to other sources of discrepancy (e.g., friction, compliance)."}, "weaknesses": {"value": "1. While the operator network formulation is the central claim of the paper, the experiments do not sufficiently justify its necessity over a standard, high-capacity Multi-Layer Perceptron (MLP) with the same payload conditioning. The authors should provide an ablation comparing GapONet to a simpler, non-operator network that takes the same inputs (sim context and payload) and outputs the residual action. Without this, it is difficult to ascertain if the performance gain is due to the operator learning formulation or simply the nonlinear, payload-conditioned residual structure.\n\n2. The paper focuses heavily on payload variation. While this is a critical source of non-linearity, the true test of an operator network is its ability to generalize across different functional inputs. The current evaluation only tests generalization across a continuous parameter (payload mass).\n\n3. he paper mentions the curation of the TWINS dataset, which is a major contribution. However, the paper does not explicitly state whether the dataset and the trained GapONet models will be made publicly available. Given the scale and complexity of the data collection, the lack of public release significantly hinders the reproducibility of the results and limits the impact of the dataset contribution.\n\n4. The paper's primary focus is on a model-based correction approach. A key alternative for sim-to-real is robust policy learning via Domain Randomization (DR). The paper should include a more direct and quantitative comparison to a strong DR baseline, where the policy is trained with randomization over the payload range, to demonstrate the superiority of the GapONet correction approach in terms of sample efficiency or final performance."}, "questions": {"value": "1. Ablation on Operator vs. MLP: Could the authors provide an ablation study comparing the proposed GapONet architecture against a standard, high-capacity MLP that is also conditioned on the payload and the simulation context? This is crucial to isolate the performance benefit derived specifically from the operator learning framework.\n\n2. Generalization to New Tasks: The current experiments focus on generalization across payload mass for a fixed set of motions. Can the authors comment on or provide results for the generalization of a trained GapONet to a completely new motion or task that was not part of the TWINS training set?\n\n\n3. Computational Overhead: What is the inference time overhead introduced by GapONet on the real hardware? Given that the correction is applied at the control frequency, the latency is critical. Please provide a quantitative measure of the inference time compared to the control loop frequency.\n\n4. Role of the Branch-Trunk Decomposition: The paper mentions the branch-trunk decomposition. Could the authors elaborate on the specific functional form learned by the trunk network? Is the trunk network primarily learning the payload-independent dynamics, and the branch network the payload-dependent non-linearities, as hypothesized? A visualization or analysis of the learned functions would be highly informative."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "h9Kqa5WyTk", "forum": "AC1XQjy8Sa", "replyto": "AC1XQjy8Sa", "signatures": ["ICLR.cc/2026/Conference/Submission18528/Reviewer_R4BQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18528/Reviewer_R4BQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18528/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988320387, "cdate": 1761988320387, "tmdate": 1762928221324, "mdate": 1762928221324, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response (1 / 2)"}, "comment": {"value": "We thank reviewer R4BQ, unGq, and DFMY for their valuable feedback, especially highlighting the originality and novelty of framing sim-to-real correction as a nonlinear operator-learning problem (R4BQ, DFMY), the strong motivation and solid theoretical grounding of our formulation (unGq), and the value of the TWINS dataset(R4BQ, DFMY). We follow comments and suggestions from all reviewers and revise our manuscript (colored in blue). We summarize the revisions and supplementary experimental results as follows:\n\n1. **Ablation on Operator vs. MLP.** \nWe added nine ablation experiments across different inputs, architectures, and parameter counts, showing that the operator’s learning ability comes from the operator itself rather than the residual structure. The results also confirm its better zero-shot generalization over pointwise MLPs, particularly under larger payloads. Detailed results and analysis are provided in **Appendix A.7.3**, with representative tables shown below.\n\n| Method               | LGR (%) ↓ (0kg)         | IQR ↓ (0kg)           | Range ↓ (0kg)         | LGR (%) ↓ (1kg)         | IQR ↓ (1kg)            | Range ↓ (1kg)          |\n|----------------------|--------------------------|-------------------------|-------------------------|---------------------------|--------------------------|--------------------------|\n| MLP-Pointwise-Large  | 0.08±0.05               | 0.097±0.008            | 0.653±0.090            | 0.76±0.88               | 0.206±0.012             | 0.665±0.059             |\n| MLP-History-Large    | 0.11±0.05               | 0.111±0.007            | 0.675±0.098            | 1.17±1.26               | 0.197±0.010             | 0.674±0.058             |\n| MLP-Sensor-Large     | 0.09±0.05               | 0.093±0.009            | 0.651±0.076            | 0.87±1.03               | 0.128±0.007             | 0.572±0.066             |\n| **\\model (Ours)**    | **0.09±0.03**           | **0.093±0.016**        | **0.449±0.117**        | **0.22±0.11**           | **0.115±0.013**         | **0.537±0.148**         |\n\n\n| Method               | LGR (%) ↓ (2kg)         | IQR ↓ (2kg)            | Range ↓ (2kg)          | LGR (%) ↓ (3kg)         | IQR ↓ (3kg)            | Range ↓ (3kg)          |\n|----------------------|---------------------------|-------------------------|--------------------------|---------------------------|--------------------------|--------------------------|\n| MLP-Pointwise-Large  | 2.19±1.23                | 0.200±0.011            | 0.780±0.075             | 10.76±1.53              | 0.355±0.011             | 0.976±0.096             |\n| MLP-History-Large    | 2.43±1.16                | 0.199±0.009            | 0.792±0.077             | 10.74±1.57              | 0.358±0.011             | 0.999±0.104             |\n| MLP-Sensor-Large     | 2.66±1.27                | 0.208±0.009            | 0.607±0.067             | 12.05±1.25              | 0.458±0.010             | 0.995±0.114             |\n| **\\model (Ours)**    | **0.39±0.10**           | **0.161±0.004**        | **0.578±0.112**         | **0.84±0.23**           | **0.317±0.005**         | **0.498±0.157**         |\n\n2. **Experiments of Three New Strong Baselines.**\nWe additionally incorporated a domain-randomization baseline for sim-to-real transfer and two nonlinear system-identification baselines to further validate the effectiveness of operator learning. The corresponding results and analyses are provided in **Table 1, Appendix A.7.4, Appendix A.8.3, and the supplementary videos.**\n\n3. **Analysis of Train/Test Dataset.**\nWe detailed the analysis for both the train and test sets, along with t-SNE visualizations of position, velocity, and torque in **Appendix A.3.3**, which directly validates the correctness of our zero-shot setup and further demonstrates that GapONet generalizes across payloads, motions, and even new hardware instances (robot).\n\n4. **Mathematical symbols and details.**\nTo improve readability and in response to Reviewer DFMY’s suggestion regarding reorganization, we added more detailed explanations of the **symbols in Section 4**, and expanded **Appendix A.3.3 (train/test data split)**, **Section 5 & Appendix A.7.6 (experiment setup)**, and **Appendix A.8.3 (baseline execution details)**. We also included the **algorithm for our method in Appendix A.6** and provided a complete list of **symbol definitions in Appendix A.6.2.**"}}, "id": "mqJhuj2As6", "forum": "AC1XQjy8Sa", "replyto": "AC1XQjy8Sa", "signatures": ["ICLR.cc/2026/Conference/Submission18528/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18528/Authors"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18528/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763760763680, "cdate": 1763760763680, "tmdate": 1763760763680, "mdate": 1763760763680, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}