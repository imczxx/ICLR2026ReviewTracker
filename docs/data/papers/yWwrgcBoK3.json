{"id": "yWwrgcBoK3", "number": 22261, "cdate": 1758328536425, "mdate": 1759896876383, "content": {"title": "RedTeamCUA: Realistic Adversarial Testing of Computer-Use Agents in Hybrid Web-OS Environments", "abstract": "Computer-use agents (CUAs) promise to automate complex tasks across operating systems (OS) and the web, but remain vulnerable to indirect prompt injection, where attackers embed malicious content into the environment to hijack agent behavior. Current evaluations of this threat either lack support for adversarial testing in realistic but controlled environments or ignore hybrid web-OS attack scenarios involving both interfaces. To address this, we propose RedTeamCUA, an adversarial testing framework featuring a novel hybrid sandbox that integrates a VM-based OS environment with Docker-based web platforms. Our sandbox supports key features tailored for red teaming, such as flexible adversarial scenario configuration, and a setting that decouples adversarial evaluation from navigational limitations of CUAs by initializing tests directly at the point of an adversarial injection. Using RedTeamCUA, we develop RTC-Bench, a comprehensive benchmark with 864 examples that investigate realistic, hybrid web-OS attack scenarios and fundamental security vulnerabilities. Benchmarking current frontier CUAs identifies significant vulnerabilities: Claude 3.7 Sonnet | CUA demonstrates an Attack Success Rate (ASR) of 42.9%, while Operator, the most secure CUA evaluated, still exhibits an ASR of 7.6%. Notably, CUAs often attempt to execute adversarial tasks with an Attempt Rate as high as 92.5%, although failing to complete them due to capability limitations. Nevertheless, we observe concerning ASRs of up to 50% in realistic end-to-end settings, indicating that CUA threats can already result in tangible risks to users and computer systems. Overall, RedTeamCUA provides an essential framework for advancing realistic, controlled, and systematic analysis of CUA vulnerabilities, highlighting the urgent need for robust defenses to indirect prompt injection prior to real-world deployment.", "tldr": "We provide a realistic, controlled and hybrid sandbox for systematic adversarial testings against computer-use agents.", "keywords": ["Computer-Use Agents", "Adversarial Risks", "Sandbox", "Benchmark"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d99c4110ef18fd6345fe4a272ef4c264a3f138f2.pdf", "supplementary_material": "/attachment/bf101c4fbf547169d10c8ded789b88f5be133094.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces RedTeamCUA, a novel adversarial testing framework designed to evaluate the susceptibility of Computer-Use Agents (CUAs) to prompt injection in realistic, controlled, hybrid environments spanning both the web and the operating system. The core of the framework integrates a VM-based OS environment (based on OSWorld) with Docker-based containers. This design allows for controlled, end-to-end evaluation of attacks that cross the web and OS boundary, such as an injection on a forum leading to a harmful local OS action.\n\nThe authors also propose RTC-BENCH, a comprehensive benchmark of 864 examples that investigates realistic hybrid attack scenarios targeting fundamental security violations categorized by the Confidentiality, Integrity, and Availability (CIA) triad. The framework also introduces a Decoupled Eval setting, which bypasses CUA navigation limits to isolate and focus on core adversarial robustness.\n\nBenchmarking frontier CUAs, including Claude and Operator revealed significant vulnerabilities. Even the most secure agent, Operator, exhibited an Attack Success Rate (ASR) of 7.6% in the Decoupled setting, while Claude 3.7 Sonnet reached an ASR of 42.9% and in realistic End2End settings, ASRs reached ~50%. The authors conclude that CUA threats are already tangible and current defenses, including both built-in CUA mechanisms and four evaluated defense methods, are insufficient."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1. The first controlled, integrated framework for adversarial testing across both realistic OS and web environments.\n\n2. Decoupled Evaluation Setting effectively isolates an agent’s true adversarial robustness from confounding factors like navigational capability, providing a clear measure of vulnerability once an injection is encountered.\n\n3. The empirical results demonstrate that frontier CUAs are highly vulnerable, with Attack Success Rates reaching up to 50% in end-to-end settings, confirming that these are immediate, tangible risks.\n\n4. The threat model is more realistic than much prior work."}, "weaknesses": {"value": "1. The current findings are primarily limited to a few closed source models and do not test on open source CUA models like UI-TARS 1.5 70B.\n\n2. The realistic End2End evaluation was performed only on a subset of 50 tasks out of the 864 examples in the benchmark."}, "questions": {"value": "N/A."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "NGyYnPbH8x", "forum": "yWwrgcBoK3", "replyto": "yWwrgcBoK3", "signatures": ["ICLR.cc/2026/Conference/Submission22261/Reviewer_Djvv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22261/Reviewer_Djvv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22261/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761543618934, "cdate": 1761543618934, "tmdate": 1762942141316, "mdate": 1762942141316, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Responses (1/3)"}, "comment": {"value": "We thank all reviewers for their time and comments. Below, we present the rationale behind our selection of agents. We also include our newly added experiments on Claude 4.5 Sonnet [1], the top-performing CUA on the OSWorld leaderboard [2] at the time of our rebuttal, and on Qwen-3-VL-235B-A22B-Thinking [3], the top-performing open-source CUA on OSWorld that is currently accessible.\n\n**[Agent Selection]**\n\nAdversarial risk evaluation of computer-use agents (CUAs) represents a timely and high-impact direction. To conduct a meaningful and reliable adversarial risk assessment, we selected agents representative of the current state of CUAs while **maintaining the fundamental principle that evaluated CUAs must be reasonably capable**. Otherwise, *(1) an incapable agent would not be adopted in real-world settings, limiting relevance to the community and (2) an underperforming agent may appear spuriously safe simply because it fails to understand or even perceive adversarial instructions in the first place.*\n\nNevertheless, computer-use tasks are inherently complex, featuring long-horizon trajectories and highly idiosyncratic environments. Given this complexity and the goal of reliable assessment, we deliberately focus on the strongest available agents as indicated by OSWorld [4] performance, one of the most representative and widely used benchmarks for computer use evaluation. At the time of submission, CUAs developed by OpenAI and Anthropic (e.g., Claude series and Operator) represent the most capable and frontier CUAs. As such, this rationale justifies our choice to adopt them as the main baselines in our work. Additionally, we performed sanity checks to verify their basic utility and ensure the validity of our results.\n\nBeyond general capabilities, the agents selected for our study provide a strong foundation for systematic analysis of CUA security given the following considerations: \n\n- **Diverse Developers**: Our evaluated CUAs include CUAs built by multiple independent organizations, such as Anthropic’s Claude series and OpenAI’s Operator.\n- **Agent Types**: Our evaluated CUAs span two categories, including (a) Adapted LLM-based Agents, which are general-purpose LLMs scaffolded for computer-use (e.g. GPT-4o, Claude 3.5/3.7 Sonnet) and (b) Specialized Computer-Use Agents, which are models purposefully designed for computer-use scenarios (e.g. Operator, Claude 3.5/3.7 Sonnet | CUA).\n- **Defense Strategies**:  Diverse approaches to mitigating indirect prompt injection are covered by our selected CUAs, including dedicated RL-based training and external guardrails outlined in Section 4.2 of the Claude 3.7 Sonnet system card [5] and permission/safety checks that enable human oversight for Operator [6]. According to their reports, Claude 3.7 Sonnet's defense strategies prevented prompt injections in 88% of cases on their  evaluation set, while Operator reduced susceptibility from 62% without mitigations to 23%, demonstrating the perceived robustness of these methods. We hope to evaluate the effectiveness of these defense strategies under our adversarial attack.\n\nTogether, these choices ensure comprehensive coverage of the current CUA landscape (in terms of agent types, developers and defense strategies) and support a systematic assessment of CUA security vulnerabilities."}}, "id": "betXLSZ2rY", "forum": "yWwrgcBoK3", "replyto": "yWwrgcBoK3", "signatures": ["ICLR.cc/2026/Conference/Submission22261/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22261/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22261/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763700129878, "cdate": 1763700129878, "tmdate": 1763700129878, "mdate": 1763700129878, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose RedTeamCUA, a benchmark for \"hybrid web-OS\" indirect prompt injections on a number of frontier models / agents. They find that most tested agent+scenario+model combinations are vulnerable to attacks in their benchmark in both targeted and end-to-end experiments. In addition, a suite of recent defenses are circumvented."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Well written and designed benchmark.\n- Addresses an important niche of attacks on CUA and hybrid models.\n- Interesting findings on the limitations of current defense frameworks in this regime."}, "weaknesses": {"value": "- Novelty: The method seems to build on top of and combine existing benchmarks and attacks. In a future version, I would like to see the authors spell how their benchmark differs a little more.\n- Attacks: Only one format of attack was evaluate. Would be nice to see evaluation of more.\n- Sanitization: How sensitive are results to realistic UI noise (extra messages/files)?"}, "questions": {"value": "- How sensitive are results to realistic UI noise (extra messages/files)?\n- Any signal as to whether results transfer to other common platforms (e.g., wikis, issue trackers)? \n- In End2End, how much of the ASR drop is due to navigation vs perception vs tool-use? A per-failure taxonomy would be very interesting."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Z9JGSdGsct", "forum": "yWwrgcBoK3", "replyto": "yWwrgcBoK3", "signatures": ["ICLR.cc/2026/Conference/Submission22261/Reviewer_aku4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22261/Reviewer_aku4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22261/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761774377000, "cdate": 1761774377000, "tmdate": 1762942141032, "mdate": 1762942141032, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Authors propose a new framework (redTeamCUA) + benchmark (RTC Bench) by combining OSWorld environment w/ WebArena and TheAgentCompany.\n\nCombination of benign goals and adversarial goals similarly to AgentDojo:\n(9 benign goals × 24 adversarial goals × 4 types of instantiation)\n- instantiation means: Code vs. NL prompt injection x General vs. Specific benign goal\n\nInteresting seeting: Decoupled Eval, where the agent is brought to the point of adversarial injection (hardcoded prior tool calls?)\n\nMetrics are ASR and AR (attempt rate for adversarial goals).\n\nThey show high ASR for all evaluated models, except for Operator, which still has 7.6%."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- OSWorld backbone allows for hybrid attacks over both OS and web\n- Realistic threat model\n- Decoupled evaluation setting is good for helping weaker capability models reach the point of prompt injection, though it might be somewhat un-natural depending on how the tool-calling/traces are hard-coded to the agent history\n- Great having both Web -> OS -> Web and Web -> OS adversarial scenarios"}, "weaknesses": {"value": "- The large number of 864 examples is only achieved by cross-product of benign, injection, and instantiation. The number of benign tasks (9) might be too small to accurately estimate agent utility, which is critical in any security benchmark (otherwise a useless agent might have perfect security). \n- I disagree with the the assessment that the Doomarena threat model is requires full webpage control; even though the authors note that the banners and pop-up attacks are injected into the web page (e.g. of PostMill) by modifying the DOM, these elements are typically 3rd party content, which is editable without full page access by, e.g., submitting the attacks through some advertising platform."}, "questions": {"value": "- You use the CIA taxonomy of threats. I'm curious where something like Direct Harm (e.g. send money to attacker) would land."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CoFse4EN9f", "forum": "yWwrgcBoK3", "replyto": "yWwrgcBoK3", "signatures": ["ICLR.cc/2026/Conference/Submission22261/Reviewer_MWPP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22261/Reviewer_MWPP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22261/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761940883921, "cdate": 1761940883921, "tmdate": 1762942140756, "mdate": 1762942140756, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents REDTEAMCUA, a framework for realistic adversarial testing of computer-use agents (CUAs) across hybrid web–OS environments. It builds a VM + Docker sandbox and an RTC-BENCH benchmark with 864 adversarial cases to evaluate indirect prompt-injection risks. Experiments show serious vulnerabilities in leading CUAs (e.g., ASR up to 66%, AR > 90%), even for models like Claude 3.7 Sonnet | CUA and Operator. Existing defenses such as LlamaFirewall and Meta SecAlign offer limited protection, revealing urgent needs for stronger security in CUAs."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "– Proposes a well-designed, hybrid sandbox integrating web and OS layers, bridging realism and safety in adversarial testing.\n\n– Builds a large-scale, systematic benchmark (RTC-BENCH) grounded in realistic tasks and security principles (CIA triad).\n\n– Provides comprehensive empirical results with both execution-based and LLM-judge metrics, revealing concrete weaknesses in current frontier CUAs.\n\n– Conducts thoughtful analysis comparing adapted LLM agents vs. specialized CUAs, and offers valuable insight into the trade-off between autonomy and safety."}, "weaknesses": {"value": "– some closed-source CUAs evaluated (GPT-4o, Claude 3.5/3.7 Sonnet, Claude 4 Opus, Operator) dominate the study; no strong open-source CUAs (e.g., UI-TARS 2, OpenCUA) are included, limiting reproducibility and community relevance. More closed-source CUAs and open-source CUAs need to be included.\n\n– The defense evaluation is superficial—existing methods are merely tested rather than extended or improved.\n\n– Provides limited mechanistic analysis of why specific CUAs succumb to injection (e.g., reasoning path, memory, or grounding failure).\n\n– Some sections are overly descriptive and lengthy, diluting the main technical insights."}, "questions": {"value": "see weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SEx0KnuQVH", "forum": "yWwrgcBoK3", "replyto": "yWwrgcBoK3", "signatures": ["ICLR.cc/2026/Conference/Submission22261/Reviewer_y1z7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22261/Reviewer_y1z7"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22261/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969577375, "cdate": 1761969577375, "tmdate": 1762942140456, "mdate": 1762942140456, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}