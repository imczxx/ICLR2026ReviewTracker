{"id": "Czul60ELOH", "number": 9866, "cdate": 1758145000680, "mdate": 1759897690803, "content": {"title": "Is This Just Fantasy? Language Model Representations Reflect Human Judgments of Event Plausibility", "abstract": "Language models (LMs) are used for a diverse range of tasks, from question answering to writing fantastical stories. In order to reliably accomplish these tasks, LMs must be able to discern the modal category of a sentence (i.e., whether it describes something that is possible, impossible, completely nonsensical, etc.). However, recent studies have called into question the ability of LMs to categorize sentences according to modality. In this work, we identify linear representations that discriminate between modal categories within a variety of LMs, or modal difference vectors. Analysis of modal difference vectors reveals that LMs have access to more reliable modal categorization judgments than previously reported. Furthermore, we find that modal difference vectors emerge in a consistent order as models become more competent (i.e., through training steps, layers, and parameter count). Notably, we find that modal difference vectors identified within LM activations can be used to model fine-grained human categorization behavior. This potentially provides a novel view into how human participants distinguish between modal categories, which we explore by correlating projections along modal difference vectors with human participants' ratings of interpretable features. In summary, we derive new insights into LM modal categorization using techniques from mechanistic interpretability, with the potential to inform our understanding of modal categorization in humans.", "tldr": "", "keywords": ["LLMs", "cognitive science", "interpretability", "common sense reasoning"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d380b5523581c2d20ce24bd24c382882e782f8f6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates whether LLMs encode human-like distinctions between possible, impossible, and inconceivable events. Using “modal difference vectors” derived from contrastive pairs (e.g., Someone chilled a drink using ice vs. using fire), the authors claim that these linear directions in activation space reflect graded human judgments of plausibility. The paper reports four main studies analyzing representational structure, training dynamics, correspondence to human categorization, and interpretability. Results show that linear separability of modal categories emerges during training and correlates with human judgments. The work contributes to the growing line of research linking mechanistic interpretability with cognitive semantics."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This paper's primary strength lies in its originality of problem formulation and the clarity of its investigation. The authors compellingly shift the debate on world models in LM: instead of focusing on output probabilities as an indicator of modal understanding (which prior work has shown to be unreliable), this paper poses a more original and nuanced question about how modal categories are encoded in the model's internal representations. The introduction of \"modal difference vectors\" as a specific, linear, and geometrically interpretable tool is a novel methodological contribution. The entire paper is well-structured around four precise research questions, which creates a clear, logical narrative that guides the reader from the vector's existence (Study 1) to its development (Study 2), its link to human cognition (Study 3), and its interpretability (Study 4).\n\nThe paper's contribution (Study 3) is the demonstration that these modal difference vectors, extracted from LMs, can model fine-grained human categorization behavior better than strong baselines. This moves the field beyond simply asking if LMs \"know\" the difference between possible and impossible, and instead investigates whether their internal representational geometry captures the graded and fuzzy nature of human modal judgments. This finding is significant because it provides a novel, quantitative framework for comparing the \"intuitive theories\" of LMs against those of humans.\n\nFinally, the quality of the exploratory analysis in Study 4 is a key strength. The attempt to find interpretable correlates for these abstract vectors is valuable. By correlating vector projections with human ratings of features like \"subjective event likelihood\" and \"imageability,\" the paper provides a crucial first step toward grounding these internal representations in human-understandable concepts."}, "weaknesses": {"value": "1. There appears to be an inconsistency between the paper's high-level claims and its detailed experimental findings. The abstract makes a general claim that \"LMs have access to more reliable modal categorization judgments...\". This suggests a general property of the language models studied. However, the paper's own results in Section 3.2 (and detailed in Figure 6, Appendix B ) show that this finding does not hold for models with fewer than 2B parameters. For this group of models, the results are described as \"substantially less clear\" and \"mixed\", with the probability-based baseline \"sometimes result in higher classification accuracy\". \n\n2. The experiment presented in Appendix D, while intriguing, is too small in scale to support a conclusion about the causal properties of the modal difference vectors. The authors state this is \"preliminary evidence\" and assess it using only \"a manually-constructed corpus of 30 novel sentence prefixes\" on just two models. This sample size is insufficient to demonstrate a generalizable or reliable phenomenon, providing only anecdotal evidence. \n\n3. A minor point about presentation. The paper's core conceptual framework relies on the distinction between four modal categories (Probable, Improbable, Impossible, Inconceivable). These distinctions, particularly between \"Impossible\" and \"Inconceivable,\" are subtle and central to the paper's thesis. While the text definitions are provided, a reader not already familiar with this specific literature may struggle to immediately grasp the precise boundaries. It could be improved by including an illustrative figure in the Introduction or Background."}, "questions": {"value": "1.  There appears to be a notable discrepancy between the main claim in the Abstract, which suggests that \"LMs\" as a general category possess more reliable modal judgments, and the specific results in Section 3.2. Your analysis explicitly states that for models with <2B parameters, the results are \"substantially less clear\" and that the probability baseline can even \"sometimes result in higher classification accuracy\". This suggests the paper's core finding is an emergent property of scale. Could you clarify whether you see this as a general property of LMs or a scale-dependent one? \n\n2. Could you provide a bit more rationale on the selection of these specific datasets (e.g., Hu et al. 2025b, Kauf et al. 2023, Goulding et al. 2024)? It would be good to know how this particular combination of datasets helps ensure that the model is learning the abstract concept of modality, rather than potentially learning statistical heuristics that might be common across these specific benchmarks. \n\n3. The steering experiment in Appendix D is an interesting proof-of-concept for the causal effect of the vectors. However, the experiment's scale is very limited, based on \"a manually-constructed corpus of 30 novel sentence prefixes\" and only two models. While you correctly label this as \"preliminary evidence\", it is difficult to draw a strong conclusion from such a small sample."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "g0773LEQRS", "forum": "Czul60ELOH", "replyto": "Czul60ELOH", "signatures": ["ICLR.cc/2026/Conference/Submission9866/Reviewer_bMoA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9866/Reviewer_bMoA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9866/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761716420602, "cdate": 1761716420602, "tmdate": 1762921337871, "mdate": 1762921337871, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates whether language models (LMs) encode modal categories—probable, improbable, impossible, and inconceivable—via linear structure in their hidden states. Using Contrastive Activation Addition, it derives modal difference vectors from minimal pairs and shows that, for models ≥2B parameters, these vectors classify modality across multiple datasets (including adversarial ones) and typically outperform sentence-probability baselines. Developmentally, coarser distinctions (e.g., inconceivable vs. the rest) emerge earlier in training, shallower layers, and smaller models, with finer distinctions appearing later and at larger scales. Projecting sentences onto three modal vectors yields a low-dimensional feature space that predicts graded human categorization distributions via logistic regression. Correlation analyses suggest the probable–improbable vector tracks subjective event likelihood, while the impossible–inconceivable vector aligns with imageability/physical concreteness. Preliminary steering results hint these vectors can nudge model generations toward targeted modal categories."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1) It shows simple linear method could transfer across datasets and model families, beating stronger-than-naïve baselines on modality classification.\n2) Uses projections as features to predict human response distributions (not just hard labels), capturing graded intuitions."}, "weaknesses": {"value": "1) Probability is a weak straw baseline for modality; missing stronger comparators (e.g., calibrated logit regressors over tokenwise surprisals, fine-tuned linear probes with controls) and clearer uncertainty estimates/CIs across splits and seeds."}, "questions": {"value": "Can you demonstrate that injecting/removing these vectors causally mediates modality judgments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tqNWrc0BKy", "forum": "Czul60ELOH", "replyto": "Czul60ELOH", "signatures": ["ICLR.cc/2026/Conference/Submission9866/Reviewer_swG3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9866/Reviewer_swG3"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9866/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761774798355, "cdate": 1761774798355, "tmdate": 1762921337542, "mdate": 1762921337542, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the ability for language models to categorize the modal categories of sentences, i.e. whether an event is possible, impossible, etc. They identify linear representations that separate modal categories, which they call modal difference vectors. They find that modal difference vectors emerge in a consistent order as the number of training steps, parameter count, and layers increase. They also validate these modal difference vectors with human judgments.\n\nIn the first study, they focus on four modal categories, probable, improbable, impossible and inconceivable events and test modal difference vectors vs. a logprob based, PCA based, and random baselines and find that in models above 2B, the modal difference vectors perform better at categorizing the modal category of a sentence, but this is not so for models below 2B parameters. In the second study, they examine accuracy on the classification task for models with different parameter counts, modal category distinctions and throughout the training of a sample model (olmo2 7B). They find that more coarse-grained modal distinctions tend to arise earlier and are more accessible for small models. Lastly, they interpret modal difference vectors by correlating projections with human-rated features."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**S1**: I appreciate the thoroughness in terms of types of experiments done, as the modal category vectors are analyzed in multiple different settings, from classification accuracy to emergence in scaling to correlation with human judgements. This makes me more confident that the vectors found do correspond to the modal categories, though I still have some doubts (see weaknesses)\n\n**S2**: The paper is overall clear and well written, with the motivation and importance of the problem being addressed up front and each section. I think the results of the paper would be interesting to the community.\n\n**S3**: The topic is interesting to the community and timely, I think the paper would be interesting to those working on hallucination, factuality or related topics."}, "weaknesses": {"value": "**W1**: This paper falls into a category which I call \"vector for X\". I want to say here that I don't necessarily believe that \"vector for X\" type papers are bad, but I think that to be sound work, I would want to see some causal analysis or intervention applied to the vectors found. Keeping in mind that linear separability between groups of points in high dimensions is the default, this makes me automatically a bit wary of papers that have this as a main contribution. In order to validate that the vectors found are meaningful, I'd want to check that they influence the model behaviour in some way. Appendix D is a good start but I would want to see a more thorough investigation:\n\n- necessity of the direction: for instance by nulling out the modal subspace and checking that performance drops on a modal classification task\n\n- behavioural linkage: it would be nice to show that steering vectors have an effect on some kind of classification task rather than just through surprisal. For example, can steering actually change model decisions on modal classification tasks(e.g. with a fine-tuned head?)\n\n- comparison to alternatives: how do CAA-derived vectors compare to other methods? \n\n**W2**: It seems like there’s the possibility for some conflation with some other linguistic concepts such as negation, sentiment or other concepts. Could you comment on whether this is a concern or if you attempted to control for this? Specifically, for the inconceivable/impossible sentences, is it possible that they have more negation-like linguistic terms or that they are less grammatical? A further thing that I would like for papers like this is a frequency control (as much as possible) -- the inconceivable and impossible sentences probably appear far less in pretraining data compared to the other categories?"}, "questions": {"value": "- The paper identifies a stark qualitative difference at 2B parameters, with even the random baseline outperforming modal vectors, but this finding receives minimal analysis. Can you comment more on this and why you believe this to be the case?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0gpC3sd8WX", "forum": "Czul60ELOH", "replyto": "Czul60ELOH", "signatures": ["ICLR.cc/2026/Conference/Submission9866/Reviewer_83R5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9866/Reviewer_83R5"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9866/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966117972, "cdate": 1761966117972, "tmdate": 1762921337297, "mdate": 1762921337297, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates whether large language models encode internal representations of modal categories (probable, improbable, impossible, and inconceivable) and whether these internal representations align with human judgments.\nUsing Contrastive Activation Addition (CAA), the authors construct modal difference vectors, representing linear directions in hidden-state space that capture distinctions between modal categories."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- It is very interesting that these internal representations develop systematically with model scale, depth, and training progression, mirroring human developmental trajectories.\n- The work builds on linguistic, philosophical, and cognitive frameworks of modality and imaginability, connecting results to human developmental and philosophical theories \n- The correspondence between model-internal representations and human categorization behavior is compelling and well-analyzed."}, "weaknesses": {"value": "- The study primarily focuses on short, declarative English sentences describing simple physical or conceptual scenarios. As a result, the findings may not generalize to contextualized modality. Expanding the dataset to include diverse syntactic and pragmatic expressions of modality would provide stronger evidence that the observed internal representations are not tied to a narrow stimulus set.\n- Lack of analysis on confidence and uncertainty alignment. While the paper examines model–human alignment in categorical judgments, it does not analyze how models express confidence in those judgments and contrast between the narrative confidence (what the model says) and the representational confidence, what it encodes internally . It would be valuable to explore cases where the model is confidently wrong or hesitantly correct, and to compare the model’s internal certainty with the explicit “confidence” conveyed in its output probabilities. \n- Some datasets (e.g., Hu et al. 2025a) are small; robustness of correlations might depend on a few stimuli.\n- The reported findings are based on a small family of transformer models. It remains unclear whether the same modal geometry emerges across architectures or initialization seeds."}, "questions": {"value": "- The logistic regression uses three modal difference vectors as features. How sensitive are the results to this choice? \n- The authors employ correlation, MSE, and entropy metrics to compare model predictions and human judgments. Whether these metrics capture qualitative alignment as well as quantitative similarity, like category boundaries? For instance, do models misclassify in similar ways as humans do?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XWvdyY2QX1", "forum": "Czul60ELOH", "replyto": "Czul60ELOH", "signatures": ["ICLR.cc/2026/Conference/Submission9866/Reviewer_8BZg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9866/Reviewer_8BZg"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9866/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968260008, "cdate": 1761968260008, "tmdate": 1762921336740, "mdate": 1762921336740, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}