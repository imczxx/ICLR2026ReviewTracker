{"id": "jXfDwmcA1U", "number": 5303, "cdate": 1757896233923, "mdate": 1759897982309, "content": {"title": "Enhancing Adversarial Transferability in Vision-Language Models via Search-Space Expansion", "abstract": "Adversarial attacks are crucial for evaluating the robustness of vision-language pre-trained (VLP) models. However, existing methods suffer from limited transferability across unseen models, limiting their effectiveness as a universal robustness probe. We attribute this partially to the narrow search space of adversarial examples, which can trap optimization in local optima and lead to overfitting. To address this, we propose SEA (\\textbf{S}earch-space \\textbf{E}xpansion \\textbf{A}ttack), a unified framework that improves cross-model transferability by enlarging the adversarial search space across both modalities. For images, SEA leverages historical updates to explore novel optimization directions, effectively avoiding suboptimal optimization  trajectories and overfitting. For text, SEA considers both individual word importance and word interactions, recognizing that less salient words can sometimes yield stronger and more transferable attacks. It performs word substitutions across multiple influential positions rather than focusing solely on the most salient word. Consequently, SEA can substantially disrupt cross-modal interactions across different models. Extensive experiments on diverse benchmarks, VLP models and tasks, supported by rigorous theoretical analysis, demonstrate that SEA significantly advances the state of the art. The source code is provided in the supplementary material.", "tldr": "This paper propose a novel transfer-based attack to evaluate the robustness and security of VLP models across different scenarios", "keywords": ["Adversarial Attack", "Vision-Language Models", "Robustness"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9937d545ab37bb6815d192b1bbd6dac4fcaf1a99.pdf", "supplementary_material": "/attachment/f9dad48073b900f7fbbe887d9c93b0419fad0a23.zip"}, "replies": [{"content": {"summary": {"value": "This paper focuses on the limited adversarial transferability of Vision-Language Pre-trained (VLP) models, attributing it to narrow adversarial search spaces that cause overfitting to source models. It proposes SEA, a framework that expands the search space for both modalities."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Well written.\n- SEA addresses transferability issues by expanding the search space for image and text modalities.\n- SEA has good cross-task/model generalization ability."}, "weaknesses": {"value": "- SEA's image module combines \"current gradient \" and \"historical information \", but the paper does not isolate the contribution of each component.\n- This paper claims SEA avoids \"local optima\", but no visualization of optimization trajectories is provided. Without this, it is impossible to verify if SEA truly escapes local optima or just converges to different ones. \n- This paper lacks visualization results.\n- This paper lacks a framework of the method, making it difficult to understand the SEA intuitively.\n- The text module claims to \"account for word interactions\", but no quantitative evidence supports this.\n- What is the significance of Proposition 1? It seems that the author merely conducted some mathematical derivations and did not provide an analysis of Proposition 1."}, "questions": {"value": "- Please see \"Weaknesses\"."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4rvzJpNHfk", "forum": "jXfDwmcA1U", "replyto": "jXfDwmcA1U", "signatures": ["ICLR.cc/2026/Conference/Submission5303/Reviewer_b2fs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5303/Reviewer_b2fs"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5303/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761789836917, "cdate": 1761789836917, "tmdate": 1762917996997, "mdate": 1762917996997, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors proposed SEA (Search-space Expansion Attack) to improve the transferability of the generated adversarial text-images pairs from one VLP model (vision-language pretrained model) to others, by introducing more candidates to explore during each optimization step besides the one that's directly chosen by PGD for the image attack and allowing the word replacement to happen at more possible positions instead of only the most saliant word for the text attack. Specifically, the new directions (or informally \"gradients\") to explore for potential adversarial images are chosen by drawing random linear combinations of all past gradients (difference with last iteration) or past perturbations (difference with original image), and the new word replacement possibilities come from words other than the most saliant one whose change might induce larger drop in text-image similarity. SEA is tested in retrieval, grounding and captioning tasks for different source and target VLP models. It shows improvement relatively significant in retrieval and milder but still consistent in the other tasks comparing to existing attacks, including SA-AET which also aims at improving attack transferability and enlarges the search space to some extent."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "+ The proposed attack achieves noticeable improvement over existing attacks including very recent ones also working on transferability.\n+ The authors focused on expanding the search space and applied the same idea to both the image and text domain."}, "weaknesses": {"value": "+ The writing and presentation are unclear and sometimes even confusing. For instance, while it is understandable to think of the combined gradients as some new \"gradient\", it is not technically a gradient of anything; symbols like $m\\in\\{1,2\\}$ and $m+$ in Eq. 5 are used without any expiation; Figure 2 doesn't explain at all what the triangular samples are but introduces inverse directions that appear only in this figure an nowhere else for unknown reasons.\n+ The linkage between the motivation, the theory and the method are not very strong. For comparison, SA-AET broadens the adversarial image search space by sampling from a triangular region enclosed by original, previous and current compromised images which intuitively defines a search space that is both semantically relevant and more diverse than the neighboring areas of the current image. Dropping the constraints of \"regions\" is said to be a good thing about SEA but how and why? The proposed linear combination of past gradient or perturbations seem more like a successful trick that the authors picked up purely empirically than designed carefully."}, "questions": {"value": "+ While linearly combining past gradients sounds somewhat understandable, what's the logic behind combining the perturbations? What does $\\sum \\eta=1$ mean when the norm of the past perturbations are related to the time step? \n+ What is the reason for choosing normal distribution for for perturbation-base search space expansion?\n+ What selection criterion does Eq. 5 define? What is $m\\in\\{1,2\\}$ and \"m+\"?\n+ How large is $l$ in practice? In the example, \"cat\" is replaced with \"fairy\" which doesn't sound very close to each other. Given that TextAttack is the shared library, are the budgets set to the same as your baselines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gmKLInFWg1", "forum": "jXfDwmcA1U", "replyto": "jXfDwmcA1U", "signatures": ["ICLR.cc/2026/Conference/Submission5303/Reviewer_xW2Z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5303/Reviewer_xW2Z"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5303/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761891116524, "cdate": 1761891116524, "tmdate": 1762917996732, "mdate": 1762917996732, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SEA (Search-space Expansion Attack), a unified framework that improves cross-model transferability by enlarging the adversarial search space across both modalities. For images, SEA leverages historical updates to explore novel optimization directions, effectively avoiding suboptimal optimization trajectories and overfitting. For text, SEA considers both individual-word importance and word interactions, recognizing that less salient words can sometimes yield stronger, more transferable attacks.\nHowever, I found that some of the paper’s claims are not substantiated and there are several noticeable grammatical errors; therefore, I believe the manuscript should be thoroughly revised before being considered for acceptance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper is relatively complete.\n2. An interesting point is the enlargement of the adversarial search space across both text and image modalities."}, "weaknesses": {"value": "1. There are some typos in this paper. For example, (1) In Equation (6), the summation is written as $\\hat{\\Delta }_{t}$. (2) Table 2's caption: \"isual\". (3) In Section 3.3.1, the author refers to “Figure 4”, but this figure does not appear in the paper.\n\n2. The paper claims that using historical update information can avoid overfitting and local optima, but no empirical or theoretical evidence is provided to substantiate this claim.\n\n3. The motivation highlights factors affecting text presentation—namely the semantics of individual words, substitution candidates, and their contextual relationships. But the proposed text attack does not explicitly model or target these factors."}, "questions": {"value": "1. What are the actual memory usage and runtime speed of the proposed method?\n\n2. Please refer to the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "J1J4hv0RQ9", "forum": "jXfDwmcA1U", "replyto": "jXfDwmcA1U", "signatures": ["ICLR.cc/2026/Conference/Submission5303/Reviewer_tWKh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5303/Reviewer_tWKh"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5303/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761921151912, "cdate": 1761921151912, "tmdate": 1762917996434, "mdate": 1762917996434, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an attack named SEA (Search-space Expansion Attack) to improve the transferability of adversarial attacks across vision-language pre-trained (VLP) models. SEA expands the adversarial search space in both image and text modalities. It leverages historical gradients for image perturbations and performs multi-word substitutions that account for both word importance and interactions in text. The authors conduct extensive experiments across various VLP models and tasks, showing consistent but modest improvements over existing approaches, accompanied by solid theoretical analysis."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Quality: The theoretical and empirical analyses on transferability are rigorous and add credibility to the findings.\n\n2. Clarity: The paper is clearly written and well-organized, making the proposed framework easy to understand.\n\n3. Significance: While the performance gain is moderate, the paper contributes another aspect of insights into improving cross-modal adversarial transferability, an important aspect of robustness evaluation. The approach is methodically implemented and systematically evaluated across diverse settings."}, "weaknesses": {"value": "1. Incremental contribution: The main ideas of expanding the search space and using historical updates are extensions of well-studied techniques in adversarial optimization. The novelty is limited.\n\n2. Minor empirical improvement: The performance gains in Table 1 are relatively small, suggesting that the proposed method offers incremental progress rather than a clear leap forward.\n\n3. Incomplete related work discussion: The discussion of textual adversarial attacks is brief and omits important gradient-based approaches such as \"LeapAttack: Hard-Label Adversarial Attack on Text via Gradient-Based Optimization\", which are directly relevant.\n\n4. Limited insight on cross-modal interactions: While SEA aims to expand search space across modalities, the analysis could further explain how image and text perturbations jointly enhance transferability."}, "questions": {"value": "1. Since the improvement is modest, could the authors further clarify the necessity of this type of method?\n2. Would integrating recent hard-label text attack baselines (e.g., TextHoaxer and LeapAttack) change the comparative performance results?\n3. What's the performance for attacking the latest VLP models such as InternVL and Qwen-VL?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "pU5aApvwRK", "forum": "jXfDwmcA1U", "replyto": "jXfDwmcA1U", "signatures": ["ICLR.cc/2026/Conference/Submission5303/Reviewer_hbij"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5303/Reviewer_hbij"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5303/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761947707329, "cdate": 1761947707329, "tmdate": 1762917996215, "mdate": 1762917996215, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}