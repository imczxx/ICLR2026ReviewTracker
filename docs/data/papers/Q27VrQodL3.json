{"id": "Q27VrQodL3", "number": 1759, "cdate": 1756915229447, "mdate": 1759898188370, "content": {"title": "Diffusion Large Language Models for Black-Box Optimization", "abstract": "Offline black-box optimization (BBO) aims to find optimal designs based solely on an offline dataset of designs and their labels. Such scenarios frequently arise in domains like DNA and material science, where only a few labeled data points are available.\nTraditional methods typically rely on task-specific proxy or generative models, overlooking the in-context learning capabilities of pre-trained large language models (LLMs).\nRecent efforts have adapted autoregressive LLMs to BBO by framing task descriptions and offline datasets as natural language prompts, enabling direct design generation. \nHowever, these designs often contain bidirectional dependencies, which left-to-right models struggle to capture.\nIn this paper, we explore diffusion LLMs for BBO, leveraging their bidirectional modeling and iterative refinement capabilities. This motivates our in-context denoising module: we condition the diffusion LLM on the task description and the offline dataset, both formatted in natural language, and prompt it to denoise masked designs into improved candidates.\nTo guide the generation toward high-performing designs, we introduce masked diffusion tree search, which casts the denoising process as a step-wise Monte Carlo Tree Search that dynamically balances exploration and exploitation.\nEach node represents a partially masked design, each denoising step is an action, and candidates are evaluated via expected improvement under a Gaussian Process trained on the offline dataset.\nOur method, dLLM, achieves state-of-the-art results in few-shot settings on design-bench.", "tldr": "", "keywords": ["Diffusion Large Language Models", "Offline Black-Box Optimization", "Monte-Carlo Tree Search"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9a6d65a5ae32f01b59c8b08ddbe135e84d1e3f1f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This manuscript looks at the utility of diffusion LLMs for solving black-box optimization problems – specifically evaluating their method against baseline optimizations strategies on 4 tasks from Design Bench. The authors combine diffusion LLMs with a tree search strategy where the goal of the diffusion LLM is to navigate a tree of possible designs. The proposed methods ranks first across the 4 evaluated tasks when compared against baseline methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- This is an interesting and intuitive method. I have personally been working on offline MBO and Design Bench for a while now, and think that using diffusion LLMs is a natural strategy for offline MBO problems. The strategy to also incorporate MCTS is also interesting.\n- This manuscript is well-written. I found the language easy to understand and follow, with minimal (if any) grammatical issues that would preclude scientific understanding."}, "weaknesses": {"value": "My main concerns with this work relate to the empirical evaluation of the proposed method. I detail my comments point-by-point below:\n1. The performance of the OPRO baseline helps illustrate the limitation of traditional autoregressive LLMs in capturing potential right-to-left dependencies in designs, as noted by the authors. However, several methods could have been used to significantly boost the performance of the baseline – for example, chain-of-thought prompting (encouraging the model to reason about the specific task/domain before answering); or providing additional domain-specific knowledge (e.g., context about the SIX6 REF R1 transcription factor); or even using a more performant LLM (maintaining the same size as the diffusion LLM is fine).\n2. I do not understand why the sizes of the offline dataset were kept so small. Ablating the offline dataset size between 2 and 20 is helpful, but in many tasks (and also in Design Bench), the sizes of the offline datasets can be in the thousands, which is orders of magnitude larger than what is reported here. Because many of the baselines are data driven, I would be surprised to see any of the baselines perform particularly well here. At the very least, the authors should sweep over much larger ranges of the size of the offline dataset. In particular, it would be helpful to know at what point do existing methods surpass the proposed dLLM method (if ever).\n3. Somewhat of a continuation of comment (2) above, but it doesn’t make sense that the offline dataset would be so small (implying that oracle evaluations are very expensive), and yet the number of final designs that you can evaluate with the oracle at the very end is so much larger (128). The reasoning would be that if the oracle is truly inexpensive enough to allow for 128 final evaluations in real life, then we should have spent time building a better dataset first to have more data to learn from. To end, it would be important to ablate the number oracle evaluation budget – particularly focusing on extremely small values (e.g., 1 instead of 128 allowed evaluations).\n4. Similar to 2, a naïve strategy to improve the performance of both dLLM and baselines is to use the best 10 (or however many) designs in the offline dataset, rather than picking a random sample of 10 designs. It would also be helpful to see how it performs if sampling the worst N designs as well (although not as important).\n5. It would also be helpful to see an ablation study on $J$ in estimating the node’s reward in line 260.\n6. Similarly, ablating $\\omega$ in (4) is important to characterize the impact of the trade-off between exploration and exploitation on algorithm performance.\n7. Similarly, ablation the temperature parameter of the diffusion LLM is also important, as I would imagine it would similarly impact the trade-off between exploration and exploitation.\n8. TFBind8 and TFBind10 are very similar tasks, and overall it feels like the number of baseline tasks evaluated are relatively small. The manuscript would benefit from evaluating the performance of the proposed method on NAS from the original Design-Bench paper, and/or on other benchmarking tasks (e.g., the Warfarin and LogP tasks from [this paper](https://arxiv.org/abs/2402.06532)). This would help better characterize the generalizability of the method across a more representative set of tasks.\n\nMinor Comments:\n- Line 108: It would be helpful to include a brief overview of what the UCT score is (e.g., what the acronym stands for) and the main intuition behind it. I understand that it’s formally defined in Eq (4), although it’s first introduced earlier in the paper."}, "questions": {"value": "9. In Line 210, it is mentioned that \"any additional invalid designs… are excluded.\" How often does this actually happen? It would be helpful to report to know how much of the compute resources are being used to generate valid vs invalid designs.\n10. I am not sure if I fully understand the claimed \"left-to-right\" limitation of traditional autoregressive LLMs. For the full designs that are included as context in the LLM prompt, attention should capture dependencies bidirectionally between the tokenized components of any given design.\n11. I might have missed this, but I’m not sure how many seeds/experimental runs were used to report the experimental results in Table 1. Also, are the error bars Standard Deviation, SEM, or something else?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "3tv0JbfJLU", "forum": "Q27VrQodL3", "replyto": "Q27VrQodL3", "signatures": ["ICLR.cc/2026/Conference/Submission1759/Reviewer_mECb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1759/Reviewer_mECb"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1759/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760650188368, "cdate": 1760650188368, "tmdate": 1762915883272, "mdate": 1762915883272, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a new method, dLLM, for offline black-box optimization (BBO) in few-shot settings. The core idea is to leverage pre-trained diffusion-based large language models, which are hypothesized to be better suited for design tasks with bidirectional dependencies than their autoregressive counterparts. The method consists of two main components: (1) an \"in-context denoising\" module, which prompts the diffusion LLM with a task description and an offline dataset to iteratively refine a masked design, and (2) a \"masked diffusion tree search\" (MDTS), which frames the denoising process as a Monte Carlo Tree Search (MCTS). The search is guided by rewards derived from the Expected Improvement (EI) of a Gaussian Process (GP) trained on the offline data, effectively balancing exploration and exploitation. The authors demonstrate that dLLM achieves state-of-the-art performance on four tasks from the design-bench benchmark."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed method consists of a straightforward integration of several existing techniques. The use of a GP's EI as a reward signal for an MCTS-guided denoising process is intuitive\n- The paper is overall well-written and the ablation studies are well-designed to demonstrate the importance of each of the proposed components\n- This work highlights a promising new direction for LLM-based optimizers by moving from autoregressive to diffusion-based models. If the efficiency concerns can be addressed, this approach could have a profound impact on scientific and engineering design problems"}, "weaknesses": {"value": "- The paper's most significant weakness is its lack of theoretical analysis. Specifically, the proposed MDTS is presented without any formal guarantees (such as regret analysis), despite being built upon the MCTS framework\n- The method's guidance relies on EI from a GP trained on only a few examples in very high dimensional spaces. However, it is well-known that GPs with standard kernels often perform poorly in such settings (curse of dimensionality), and their uncertainty estimates can be unreliable [1]-[4]. The paper does not analyze the quality of the GP fit or the sensitivity of the method to the GP's configuration (e.g., kernel choice), making it unclear how robust the approach is.\n- The paper also lacks any discussion on the computational complexity/cost of the proposed method. This omission makes it difficult to assess the practical viability of the method\n\n[1] D. Eriksson and M. Jankowiak, \"High-dimensional Bayesian optimization with sparse axis-aligned subspaces,\" UAI, 2021.\n\n[2] R. C. Suwandi et al., \"Adaptive kernel design for Bayesian optimization is a piece of CAKE with LLMs,\" arXiv preprint arXiv:2509.17998, 2025.\n\n[3] Z. Wang et al., \"Bayesian optimization in a billion dimensions via random embeddings,\" Journal of Artificial Intelligence Research, 2016.\n\n[4] M. Riccardo et al., \"High-dimensional Bayesian optimization using low-dimensional feature spaces,\" Machine Learning, 2020."}, "questions": {"value": "- How are the few-shot examples in the offline dataset ordered within the in-context prompt? Have the authors tested the sensitivity of dLLM's performance to the permutation of these examples, as this is a known factor that can significantly impact the performance of in-context learning\n- The introduction and Section 4.4 argue that diffusion models excel due to \"bidirectional modeling\", which is a central motivation for this work. Could the authors provide a concrete example from the tasks that illustrates this? For instance, can the authors show a case where an autoregressive model makes a greedy left-to-right decision that proves suboptimal, whereas dLLM's iterative refinement corrects this by considering both left and right context simultaneously?\n-  In the UCT score, how does the model likelihood term $p_\\theta(x_{s,i}|x_t)$ interact with the value estimate $V(x_{s,i})$ during the search? Is there a risk that the LLM's prior could overwhelm the optimization signal from the GP, especially early in the search when $V$ is poorly estimated?\n- Lines 205-208: \"we then remask the least confident tokens.\" How is token \"confidence\" formally defined and calculated in this context?\n- Did you experiment with different kernels or alternative acquisition functions? \n- How does the performance of dLLM change if a simpler reward, like the GP's predictive mean, is used instead of EI?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "o7GtXBMJtS", "forum": "Q27VrQodL3", "replyto": "Q27VrQodL3", "signatures": ["ICLR.cc/2026/Conference/Submission1759/Reviewer_78bn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1759/Reviewer_78bn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1759/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760804476669, "cdate": 1760804476669, "tmdate": 1762915882962, "mdate": 1762915882962, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work considers black box optimization using the in context abilities of LLMs. But autoregressive LLMs can be poor planners, when bi-directional dependencies exists. Therefore, this work considers diffusion language models for this task. The paper introduces Masked diffusion tree search to do black box optimization with some in-context information, which is a UCT based MCTS algorithm. The algorithm's performance is then evaluated on various BBO tasks to show significant gains."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The empirical gains are impressive and showcases a strong case for pretrained diffusion models being used for BBO in planning problems. In this case, an autoregressive LLM base methods  such as ORPO do not even perform as well as the classical Gaussian process based methods. The algorithm design is a simple adaptation of MCTS to this case. There are extensive ablations on the effect of tree depth, branching factor and offline dataset size."}, "weaknesses": {"value": "The paper is poorly written on a technical level and the algorithmic and experimental details have not been explain within the paper. See \"Questions\" for some specific queries in this regard. Given these drawbacks, I cannot recommend acceptance for this work.\n\nSince this paper uses a large diffusion model whereas the previous works in this domain use simple techniques such as Gaussian process, a comparison of computation complexities of various methods is important. This is not provided in the paper\n\n**Minor**\n* Some additional references to consider:\nhttps://arxiv.org/abs/2410.07432 considers reasoning with transformers using COT inspired algorithms to solve planning problems. The benefits of solving bi-directional planning problems using diffusion models have been explored in the literature (see https://arxiv.org/pdf/2410.14157,  https://arxiv.org/pdf/2502.13450 and references therein). This is not exactly BBO, but can be relevant. \n\n* The authors use the phrase “domains such as DNA” – which seems to be confusing."}, "questions": {"value": "In algorithm 1, what is t? The selection procedure here tells us to pick $x_t$ based on $x_1$ but the line 234 tells us how to pick $x_s$ based on $x_t$. There is some notation overload causing confusion here. \n\nWhat is the value function V(.) here and how is it calculated? (for instance, in the DNA affinity task). Where is this initialized in the algorithm? Is this tabular? In this case even with length 8, the number of sequences would be ~65k. \n\nIn line 234 **selection** –  what does “select child based on UCT score” mean? Does this mean you are picking the child with the maximum UCT score?\n\nIn **Expansion**: Does this mean that we generate $x_{0,i}$ which is the completion and then re-mask it randomly to generate new leaves $x_{s,i}$ ? In this case shouldn't the remask ratio be s instead of $s/t$ ?\n\nIn **Evaluation**: I did not understand how the predictive mean and variance are obtained through the Gaussian process given that ATGC are discrete categories in the DNA affinity case. Can you please point me to references where such modeling is done? Also, the details about the updation of this gaussian process is not available. Is it the case that only the offline data points have affinity score available and a GP is used to “fit” the data to other generated points? I understand this is so given the algorithm pseudocode. I would also appreciate a reference for the expression for “Expected Improvement” and its meaning."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NN0vAC6xja", "forum": "Q27VrQodL3", "replyto": "Q27VrQodL3", "signatures": ["ICLR.cc/2026/Conference/Submission1759/Reviewer_wStR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1759/Reviewer_wStR"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1759/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761386820614, "cdate": 1761386820614, "tmdate": 1762915882450, "mdate": 1762915882450, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes dLLM, a new method for offline black-box optimization (BBO) that utilizes pre-trained diffusion large language models. BBO is a classical environment for data-rare scenarios, such as AI for Science, where only a small offline dataset of designs and their scores is available. The authors identify that standard autoregressive LLMs struggle with bidirectional dependencies common in design tasks (e.g., DNA sequences). This work studies a diffusion language model, where the denoising is autoregressive, conditioned on task description, the offline dataset, and an instruction (all concatenated to a natural language prompt). MCTS is also included to balance exploration and exploitation in the denoising process."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. First of all this work has a good presentation. Its way of introducing methodology is easy to follow. The paper also provides a thorough review of related work in Section 5, which, to my understanding, is important because, since 2023, there has been a line of works applying diffusion models/LLMs for black-box optimization. Diffusion LMs are also a part of LLMs, bearing huge similarities and relevantness; it is extremely important to situate this work with respect to the prior works.\n\n\n\n2. Related to 1. The selection of baselines is also thorough. The authors compare their method against 15 baselines, including proxy-based methods and various generative models. This includes the must-have prior works in both LLM for BBO (such as OPRO) and diffusion for BBO (such as DDOM)."}, "weaknesses": {"value": "1. First, this work extends LLMs for BBO to diffusion LMs. The reason for such extension, is described by: using diffusion models to capture bidirectional dependencies. This does not seem to be wrong, but it is also highly untrivial to evaluate. Have the authors come up with certain mechanism theories to formally describe this to this argument?\n\n2. The originality of the paper is somewhat limited. As mentioned, the work feels like a natural and incremental extension of existing ideas. The field already has \"LLMs for BBO\" and \"diffusion models for BBO\". This paper's \"in-context denoising\" component is a straightforward combination of these two, which has been introduced by Tang et al. 2025 to optimize molecules.\n\n\nSimilarly, the use of MCTS to guide diffusion models is also an existing area of research, which the authors acknowledge, e.g., Tang et al. (2025, which proposes an MCTS framework built on top of diffusion language models for molecular optimization, more specifically, SMILES. This work, on the other hand, has studied DNA sequences, which appear to be even more approachable than SMILES as SMILES encodes complicated structural information and many atoms.\n\n3. The ablation study in Table 2 is a major concern. Removing MDTS (the tree search) leads to a massive performance drop (e.g., 0.876 to 0.798 on TF8; 0.642 to 0.503 on TF10). This strongly suggests that the search framework (MCTS guided by the GP's EI) is doing almost all the work. The dLLM is just acting as a proposal mechanism within this search."}, "questions": {"value": "1. see above\n\n2. To truly isolate the contribution of the dLLM as a better mechanism then AR, could the authors add an ablation study? Specifically, please compare the full dLLM method against a baseline that uses the exact same MDTS framework (same tree depth, branches, GP-EI reward) but replaces the dLLM with a simpler mechanism (e.g., simpler generative models such as a VAE)\n\n3. As mentioned, dLLMs are claimed to be better about \"bidirectional dependencies\" than LLMS, but no theoretical explanations are given. If we only examine experimental validations, results on TF8/TF10 (DNA sequences) seem to support this, as the gaps to LLMs are largest there. However, it seems performance gaps on the continuous tasks are tiny. Is the method's advantage primarily for discrete, sequence-like design spaces, and less so for continuous ones? Is there a theory to explain this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wgn8e3vGua", "forum": "Q27VrQodL3", "replyto": "Q27VrQodL3", "signatures": ["ICLR.cc/2026/Conference/Submission1759/Reviewer_9Unr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1759/Reviewer_9Unr"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1759/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761775372871, "cdate": 1761775372871, "tmdate": 1762915880878, "mdate": 1762915880878, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}