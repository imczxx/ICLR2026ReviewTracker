{"id": "6rvpzYGNOn", "number": 4406, "cdate": 1757674943196, "mdate": 1759898034202, "content": {"title": "Accuracy-First Rényi Differential Privacy and Post-Processing Immunity", "abstract": "The accuracy-first perspective of differential privacy addresses an important shortcoming by allowing a data analyst to adaptively adjust the quantitative privacy bound instead of sticking to a predetermined bound. Existing works on the accuracy-first perspective have neglected an important property of differential privacy known as post-processing immunity, which ensures that an adversary is not able to weaken the privacy guarantee by post-processing. We address this gap by determining which existing definitions in the accuracy-first perspective have post-processing immunity, and which do not. The only definition with post-processing immunity, pure ex-post privacy, lacks useful tools for practical problems, such as an ex-post analogue of the Gaussian mechanism, and an algorithm to check if accuracy on separate private validation set is high enough. To address this, we propose a new definition based on Rényi differential privacy that has post-processing immunity, and we develop basic theory and tools needed for practical applications. We demonstrate the practicality of our theory with an application to synthetic data generation, where our algorithm successfully adjusts the privacy bound until an accuracy threshold is met on a private validation dataset.", "tldr": "", "keywords": ["Differential Privacy", "Accuracy-first privacy", "Ex-post privacy"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6592d903eafb5969e8506acf9b6998f569493f8d.pdf", "supplementary_material": "/attachment/1a3491888e8deddc93d2ae5e8fd093c733271eb2.zip"}, "replies": [{"content": {"summary": {"value": "The paper formally proves the PPI guarantee of some existing accuracy-first RDP/DP notions and introduces a new notion, ex-post RDP, which involves the $\\epsilon$ as part of the output. The new privacy notion satisfies PPI."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper identifies a concrete invariance gap in ex-post privacy guarantees and proposes a clean, easy notion by treating the realized bound as part of the output and formalize PPI. The ex-post RDP's framework is tidy, creative recombination that satisfies PPI.\n\nThey formally proves the PPI property of some important existing accuracy-first privacy notions."}, "weaknesses": {"value": "# W1:\n\nWhile the paper is framed as \"accuracy-first\", the concrete contribution is primarily a definitional/packaging fix (carrying the per-run certificate and proving PPI on (Y,$\\epsilon$)). The work does not yet advance accuracy per se (no new calibration/mechanism or demonstrated utility gains at fixed privacy). In addition, the experiments are limited and do not support the \"accuracy-first\" narrative.\n\n\nIn Related Work, the ordermeter literature is merely conceptually adjacent, but the present paper's technical contributions do not build on odometers. So, the discussion here is mostly contextual but feels disconnected from the paper's position. \n\n\n\n# W2:\n\nMy main concern is as follow.\n\n\nThe paper pointing out a limitation of existing ex-post notations: after post-processing, we often cannot construct a non-vacuous $E'(Y')$ (see the example of Brownian mechanism's \"$T$\" issue in Page 5 of the paper). \n\n\nHowever, it seems that the root cause is the lack of bookkeeping the privacy parameter/certificate, rather than an intrinsic or fundamental limiation of the existing notions (except the $\\delta$-approximate ex-post).\n\nThe proposed fix is to treat the realized bound as part of the output and requireing it to be copied through post-processing. This is best viewed as an interface/notation repair, not a new privacy notion with new privatization mechanism nor an impossibility result. \n\n\nIn practice, the post-processing functions/algorithms operates independently of $\\epsilon$. The only requirement is to carry the certificate tag $\\epsilon$ with the output so that an auditor at the end of the pipeline can attest the same per-run guarantee.\n\n\nWhile the theory is clear (though not, in my view, especially significant), the experiments are narrow illustrations (Adult synthetic data) and do not substantiate the paper’s \"accuracy-first\" framing or demonstrate utility gains at fixed privacy against strong baselines. Thus, the experiments do not support the broader claims.\n\n\nOverall, the contribution feels illustrative rather than substantive: a neat packaging/notation fix with a small-scale demo, but not yet a result that moves practice or theory."}, "questions": {"value": "Please see the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UrjMHs4wxk", "forum": "6rvpzYGNOn", "replyto": "6rvpzYGNOn", "signatures": ["ICLR.cc/2026/Conference/Submission4406/Reviewer_3cjJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4406/Reviewer_3cjJ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4406/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761767167827, "cdate": 1761767167827, "tmdate": 1762917347793, "mdate": 1762917347793, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper advocates a practical shift in how differential privacy is used in ML training: instead of fixing a privacy budget and measuring performance afterward, it proposes an accuracy-first paradigm where the training process dynamically adjusts the privacy parameters until a target accuracy is achieved, then computes the final privacy level using Rényi Differential Privacy (RDP)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Experimental results on several benchmark datasets show improved accuracy while maintaining reasonable privacy levels.\n2. The authors’ accuracy-first framing is intuitive and addresses a real deployment gap between theoretical guarantees and practitioner needs."}, "weaknesses": {"value": "There seems to be a lack of variance or sensitivity analysis (e.g., different α values in RDP) to confirm the stability of the bounds (robustness)."}, "questions": {"value": "It would be better to clarify the variance or sensitivity analysis (e.g., different α values in RDP) to confirm the stability of the bounds (robustness)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "0t0UAahoQS", "forum": "6rvpzYGNOn", "replyto": "6rvpzYGNOn", "signatures": ["ICLR.cc/2026/Conference/Submission4406/Reviewer_f84H"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4406/Reviewer_f84H"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4406/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761867420775, "cdate": 1761867420775, "tmdate": 1762917347526, "mdate": 1762917347526, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses post-processing immunity (PPI) within the ``accuracy-first'' paradigm of DP. It first shows that existing practical ex-post privacy definitions do not satisfy PPI. To resolve this, the authors introduce a new notation that treats the privacy bound $\\epsilon$ as part of the algorithm's output. Using this notation, they propose a new definition, ex-post Rényi DP, and show that it satisfies PPI. The paper also provides a new privacy analysis for the existing Brownian mechanism, showing that it satisfies ex-post RD by proving its equivalence to a simpler sequential mechanism."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The extension to ex-post RDP is natural.\n- I believe the results are sound (at least by intuition), though I did not check every detail in the Appendices.\n- Both theoretical and experimental results are provided."}, "weaknesses": {"value": "- The paper does not propose any novel algorithm specially designed for the new ex-post RDP framework, focusing instead on re-analyzing an existing one.\n- The empirical evaluation lacks a comparative analysis against other established privacy notions, so it is unclear if the framework offers a superior privacy-utility tradeoff in practice.\n- The paper lacks discussion on the limitations of the ex-post RDP notion."}, "questions": {"value": "- From a theoretical perspective, does the ex-post RDP notion provide a better or worse privacy-utility tradeoff, while comparing with other accuracy-first notions? What is the cost of PPI here?\n- The privacy guarantee is now a random variable. How should practitioners interpret, report, or compare such guarantees? For example, if we have two mechanisms, each with a different distribution of $\\epsilon$, how do we decide which one is ``more private''?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "glUqpcAoAP", "forum": "6rvpzYGNOn", "replyto": "6rvpzYGNOn", "signatures": ["ICLR.cc/2026/Conference/Submission4406/Reviewer_coYK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4406/Reviewer_coYK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4406/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761904210600, "cdate": 1761904210600, "tmdate": 1762917347256, "mdate": 1762917347256, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates post-processing immunity (PPI) under accuracy-first ex-post DP.  In contrast to conventional DP, ex-post DP allows different privacy loss on different outputs through a function $\\mathcal{E}:Y\\to \\mathbb{R}$, and post-processing would change the output space and lose meaningful privacy loss, e.g., multiple $y$ collapse to one.  This paper proposes post-processing that outputs not only the function of $Y$ but also the privacy loss $\\epsilon$, which addresses the output collapse issue.  Under this new notion, they prove that the pure ex-post DP and Rényi DP satisfy PPI, but the $\\delta$- probabilistic ex-post DP does not.  For Renyi DP, they also prove adaptive composition and analyze the Brownian mechanism."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Making $\\epsilon$ part of the output and defining post-processing is a nice way to handle post-processing.  \n- Though scattered around the literature, the paper gives a clean survey on PPI on various ex-post DP."}, "weaknesses": {"value": "- The motivation of outputting $\\epsilon$ is limited.  It seems like theory-first and departs from the conventional usage of post-process.  In practice, do people post-process data but also output all privacy loss in the previous post-process and composition $\\epsilon_{1:K}$ as Theorem 4.5?  \n- The exploration of the composition theorem is partial.  There is no composition theorem for pure ex‑post privacy analogous to Theorems 4.4–4.6."}, "questions": {"value": "Can you prove adaptive composition for pure and approximate ex‑post DP, or provide counterexamples/conditions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "KCxoMQ8ApO", "forum": "6rvpzYGNOn", "replyto": "6rvpzYGNOn", "signatures": ["ICLR.cc/2026/Conference/Submission4406/Reviewer_GHWG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4406/Reviewer_GHWG"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4406/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762328886869, "cdate": 1762328886869, "tmdate": 1762917346927, "mdate": 1762917346927, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}