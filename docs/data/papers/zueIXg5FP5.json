{"id": "zueIXg5FP5", "number": 20068, "cdate": 1758302060417, "mdate": 1759897003480, "content": {"title": "Algorithmic Guarantees for Distilling Supervised and Offline RL Datasets", "abstract": "Given a training dataset, the goal of dataset distillation is to derive a synthetic dataset such that models trained on the latter perform as well as those trained on the training dataset. In this work, we develop and analyze an efficient dataset distillation algorithm for supervised learning, specifically regression in $\\mathbb{R}^d$, based on matching the losses on the training and synthetic datasets with respect to a fixed set of randomly sampled regressors without any model training. Our first key contribution is a novel performance guarantee proving that our algorithm needs only $\\tilde{O}(d^2)$ sampled regressors  to derive a synthetic dataset on which the MSE loss of any bounded linear model is approximately the same as its MSE loss on the given training data. In particular, the model optimized on the synthetic data has close to minimum loss on the training data, thus performing nearly as well as the model optimized on the latter. Complementing this, we also prove a matching lower bound of $\\Omega(d^2)$ for the number of sampled regressors showing the tightness of our analysis.\n\nOur second contribution is to extend our algorithm to offline RL dataset distillation by matching the Bellman loss, unlike previous works which used a behavioral cloning objective. This is the first such method which leverages both, the rewards and the next state information, available in offline RL datasets, without any policy model optimization. We show similar guarantees: our algorithm generates a synthetic dataset whose Bellman loss with respect to any linear action-value predictor is close to the latter’s Bellman loss on the offline RL training dataset. Therefore, a policy associated with an action-value predictor optimized on the synthetic dataset performs nearly as well as that derived from the one optimized on the training data. We conduct extensive experiments to validate our theoretical guarantees and observe performance gains on real-world RL environments with offline training datasets and supervised regression datasets.", "tldr": "Algorithms and performance guarantees for supervised and offline RL dataset distillation along with experimental validation.", "keywords": ["dataset distillation", "supervised learning", "offline RL", "learning theory"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/391cca79c6c0e8a990cf0c495d757fcf74e486b9.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a dataset distillation algorithm by matching the losses between training and synthetic datasets without introducing extra model training. The authors develop and analyze a method for supervised learning and offline reinforcement learning, where only $\\hat{\\mathcal{O}}(d^2)$ regressors are sufficient to ensure the MSE loss of any bounded linear model is approximately preserved. They also provide a matching lower bound of  $\\Omega (d^2)$, establishing tightness. Furthermore, the authors extend the algorithm beyond supervised learning, i.e., offline RL, by leveraging the next state and reward information in the dataset to match the Bellman loss rather than the behavior cloning loss. Extensive theoretical analysis and supplementary experiments prove that the proposed method efficiently distills the synthetic dataset from the training dataset without relying on auxiliary techniques-additional classifier training."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is well structured and addresses comprehensive details.\n- Extensive theoretical proofs concretely support the main claim.\n- Experiments demonstrate that the proposed method shows a clear margin compared to other baselines, recovering near-optimal or even outperforming performance."}, "weaknesses": {"value": "- The experimental section appears relatively narrow, focusing on small regression settings with Gym control tasks. Comparing with other baselines (Lei et al. 2024, Light et al. 2024) for generating synthetic datasets would improve the soundness of the suggested method."}, "questions": {"value": "- What would be the major bottleneck when extending the proposed method to a non-linear function approximator (i.e., neural network) with offline RL?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "VHEo2HqECK", "forum": "zueIXg5FP5", "replyto": "zueIXg5FP5", "signatures": ["ICLR.cc/2026/Conference/Submission20068/Reviewer_4Kx3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20068/Reviewer_4Kx3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20068/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761915899680, "cdate": 1761915899680, "tmdate": 1762932957238, "mdate": 1762932957238, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a dataset distillation method for supervised regression and offline RL that matches the loss on the original and synthetic datasets with respect to a fixed set of randomly sampled models, avoiding bi-level optimization. The key contribution is a theoretical guarantee that only $O(d^{²})$ sampled linear regressors are needed for the supervised case, with a matching lower bound. The experiments demonstrate its effectiveness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper provides theoretical guarantees for dataset distillation, an area where such analysis is often lacking. The upper and matching lower bounds for the supervised case are particularly compelling.\n2. The experiments adequately support the theoretical claims, showing that the method works well in practice, even with non-linear neural networks, and outperforms baseline approaches like random subsampling."}, "weaknesses": {"value": "1. The empirical evaluation is limited to relatively small-scale datasets and standard RL benchmarks. A more extensive evaluation on larger-scale or more complex datasets would strengthen the claims of practical efficacy."}, "questions": {"value": "1. Could the authors discuss potential pathways for extending the theoretical guarantees to non-linear function approximators, such as neural networks? Note that I'm not asking for additional experimental results, just want to have a discussion, since making a more constructive theoretical analysis on non-linear functions is more feasible and practical for most real-world cases.\n2. For the offline RL setting, how restrictive is the decomposable feature map assumption in practice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "ToQIoagaiQ", "forum": "zueIXg5FP5", "replyto": "zueIXg5FP5", "signatures": ["ICLR.cc/2026/Conference/Submission20068/Reviewer_Ham7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20068/Reviewer_Ham7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20068/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761967109661, "cdate": 1761967109661, "tmdate": 1762932956810, "mdate": 1762932956810, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles supervised regression and offline RL settings by constructing synthetic datasets that preserve the original objective of training with original training dataset. It introduces a loss-matching method using randomly sampled linear regressors/Q-value predictors achieving Õ(d^2) sampling guarantees for regression (alongside a matching Ω(d^2) lower bound) and exp(O(d log d)) in offline RL (furthermore relaxed Õ(d^2) under decomposable feature maps). The approach shows solid empirical performance on standard regression datasets and classic offline RL benchmarks, and offers a timely theory-first approach for distillation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The use of loss-matching method using randomly sampled linear regressors/Q-value predictors is particularly important tool that is used in RL literature. \n- Two results for each setting look comprehensive as contributions to the learning community.\n- Experiments demonstrate that small synthetic sets and few sampled models can perform competitively on standard regression datasets and classic offline RL benchmarks."}, "weaknesses": {"value": "- Even though experiments demonstrate that small synthetic sets match the performance when trained with entire training dataset, some issues pop up:\n- - This phenomena cannot be explained by the current theory. The distillation problem is only interesting for the case $n>>m$. This is also the focus of the literature (Light et al. 25, Lei et al. 24) cited by this work.\n- - Lemma C.4 does provide net arguments for the choice of synthetic dataset size. But it seems that both $m$ and $n$ are proportional to $d$, whereas the dependence on $\\epsilon$ for $m$ is unclear.\n- - The training size for toy sequential decision problems are high. I suggest authors to really use established benchmarks like D4RL to demonstrate their distillation behavior."}, "questions": {"value": "- na -"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rDb425zHej", "forum": "zueIXg5FP5", "replyto": "zueIXg5FP5", "signatures": ["ICLR.cc/2026/Conference/Submission20068/Reviewer_3Mno"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20068/Reviewer_3Mno"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20068/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762561755376, "cdate": 1762561755376, "tmdate": 1762932956361, "mdate": 1762932956361, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}