{"id": "j63W4sMjFE", "number": 6509, "cdate": 1757987429059, "mdate": 1759897910616, "content": {"title": "High Performance Space Debris Tracking in Complex Skylight Backgrounds with a Large-Scale Dataset", "abstract": "With the rapid development of space exploration, space debris has attracted more attention due to its potential extreme threat, leading to the need for real-time and accurate debris tracking. However, existing methods are mainly based on traditional signal processing, which cannot effectively process the complex background and dense space debris. In this paper, we propose a deep learning-based Space Debris Tracking Network (SDT-Net) to achieve highly accurate debris tracking. SDT-Net effectively represents the feature of debris, enhancing the efficiency and stability of end-to-end model learning. To train and evaluate this model effectively, we also produce a large-scale dataset Space Debris Tracking Dataset (SDTD) by a novel observation-based data simulation scheme. SDTD contains 18,040 video sequences with a total of 62,562 frames and covers 250,000 synthetic space debris. Extensive experiments validate the effectiveness of our model and the challenging of our dataset. Furthermore, we test our model on real data from the Antarctic Station, achieving a MOTA score of 73.2%, which demonstrates its strong transferability to real-world scenarios.", "tldr": "", "keywords": ["deep learning", "AI for science", "object tracking", "dataset"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d976b2f761cf8683e7ceac2a439e9b97095c7da9.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces SDT-Net, a deep-learning-based tracker for space debris, and SDTD, a large-scale synthetic dataset for training/evaluation. The authors simulate 18k videos (62k frames) of linear-shaped debris on real ZTF backgrounds, then benchmark SDT-Net against MOT methods. An ablation study confirms the utility of the proposed RoI-FE module, line-source detection head, and debris-offset association mechanism."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Automated debris tracking is critical for space-safety, and data-hungry DL approaches have been stymied by the absence of large annotated corpora.\n2. SDTD is two orders of magnitude larger than prior debris data and includes both synthetic and real labels; the simulation pipeline (PSF convolution, realistic motion, ZScale preprocessing) is well motivated and reproducible."}, "weaknesses": {"value": "1. Recent transformer trackers (e.g., MOTR, TrackFormer) and joint detection-embedding models (e.g., FairMOT) are ignored. The authors should at least include one modern transformer baseline or justify its exclusion.\n2. The performance improvement compared with OCSORT is minor. More importantly, the proposed method is trained on the debris tracking dataset, while the OCSORT is trained on the general video. It is hard to identify whether the performance improvement comes from the method or the training data."}, "questions": {"value": "I am not an expert on debris tracking. I encourage the authors to clarify the Weaknesses. The proposed benchmark seems valuable."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "R8lttxCqwu", "forum": "j63W4sMjFE", "replyto": "j63W4sMjFE", "signatures": ["ICLR.cc/2026/Conference/Submission6509/Reviewer_k1G9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6509/Reviewer_k1G9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6509/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761464297443, "cdate": 1761464297443, "tmdate": 1762918875803, "mdate": 1762918875803, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This manuscript proposes SDT-Net, a deep learning-based network for space debris tracking, designed to achieve high-precision, real-time debris monitoring. The authors concurrently constructed a large-scale simulated dataset, SDTD, for model training and evaluation. Experimental results demonstrate that SDT-Net achieves exceptional performance in both synthetic and real-world scenarios (utilizing data from the Antarctic station), attaining 73.2% MOTA on real-world data, which validates its strong generalization capability and practical utility."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Motivation and Meaning: motivation is feasible\nThis manuscript focuses on detecting and predicting the motion trajectories of space debris to mitigate collision risks and advance the development of the aerospace industry.\n\nDataset：\nThis manuscript constructs a relatively large-scale dataset for space debris tracking, addressing a critical gap in existing research resources.\n\nWriting Quality：\nThe manuscript is clearly articulated and highly readable. The methodological approach, experimental validation, and visualizations are comprehensively presented and well-supported."}, "weaknesses": {"value": "Innovation: the contribution not enough for a ICLR paper\nThe design of RoI-FE demonstrates the distinction between SDT tasks and classical detection and tracking methods, suggesting that solutions tailored to the unique challenges of SDT may be necessary.\n\n\nMethodology Section:\nThe explanation of the final loss function is insufficient, and there is a lack of corresponding ablative experimental analysis.\n\nExperimental Evaluation:\nThe comparative experiments and ablative studies are inadequate."}, "questions": {"value": "1. The comparative experiments lack comparisons with state-of-the-art methods published after 2024, and also lack comparisons with backbone methods.\n2. What are the fundamental distinctions between the SDT task and classical detection and tracking methods, and what are its unique challenges?\n3. RoI-FE is a straightforward feature fusion module composed of multiple stacked convolutional layers. What is the computational cost associated with this operation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "iOuUoT1HMJ", "forum": "j63W4sMjFE", "replyto": "j63W4sMjFE", "signatures": ["ICLR.cc/2026/Conference/Submission6509/Reviewer_AqoJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6509/Reviewer_AqoJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6509/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761808939771, "cdate": 1761808939771, "tmdate": 1762918875481, "mdate": 1762918875481, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces SDT-Net, a CenterTrack-style tracker tailored to long-exposure, line-like space debris. The network adds a Region-of-Interest Feature Enhancement (RoI-FE) segmentation mask, endpoint heatmaps with a pairing embedding, and a per-endpoint offset head for frame association. The authors also build SDTD, a large synthetic-plus-real benchmark derived from ZTF backgrounds via an observation-based simulation with PSF blur and random truncation. SDTD comprises 18,040 videos / 62,562 frames / ~250k debris and is used to train/evaluate SDT-Net"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Large, reproducible benchmark built from real survey backgrounds (ZTF) with PSF and truncation adds realism; the dataset scale and explicit dense-scene split are valuable to the community.\n\n2. On SDTD, SDT-Net improves over CenterTrack/OCSORT/ByteTrack; on real Antarctic data it leads across MOTA/HOTA/DetA. Ablations isolate the gains from line-segment detection, RoI-FE, and the offset head.\n\n3. Clear task formulation with architecture tweaks that match physics. Modeling debris as paired endpoints plus an offset field is well-motivated for line-sources; RoI-FE reduces skylight clutter before detection/association. The components (heatmap loss, CornerNet-style embedding push/pull, offset regression) are standard but effective."}, "weaknesses": {"value": "1. Although the SDTD dataset is large and covers complex backgrounds, its generation process is mainly based on superimposing line sources from the background of ZTF astronomical images. The paper uses simple long-exposure line drawing with Gaussian blurring, without introducing high-fidelity physical constraints such as realistic trajectory dynamics modeling, PSF spatial variation, photosensitivity saturation, or noise field modeling. Therefore, from a technical perspective, the dataset's contribution leans more towards the scale of engineering collection and synthesis than proposing new physical fidelity or statistical generation mechanisms in simulation methods.\n\n2. The overall architecture of SDT-Net largely follows the existing multi-object tracking paradigm: it centers on detection-regression-association, using heatmap regression endpoints, embedding matching, and offset prediction to achieve temporal correlation. The proposed \"Region-of-Interest Feature Enhancement (RoIFE)\" module and \"offset module\" are essentially lightweight integrations of existing feature enhancement and motion offset ideas, without introducing new mechanisms in the algorithm's principles or optimization objectives.\n\n3. Train/val clips are mostly 1–4 frames, whereas test sets include sequences up to 30 frames (dense set concentrated around ~18). It’s unclear whether training on very short clips biases the tracker or underutilizes temporal cues."}, "questions": {"value": "Please refer to the weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Pv5prOEtM5", "forum": "j63W4sMjFE", "replyto": "j63W4sMjFE", "signatures": ["ICLR.cc/2026/Conference/Submission6509/Reviewer_y5Cr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6509/Reviewer_y5Cr"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6509/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979735945, "cdate": 1761979735945, "tmdate": 1762918874920, "mdate": 1762918874920, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents SDT-Net, a deep learning framework for tracking space debris in complex skylight backgrounds, and introduces the Space Debris Tracking Dataset (SDTD), a large-scale synthetic dataset containing 18,040 video sequences with 62,562 frames and 250,000 synthetic debris instances. SDT-Net integrates feature enhancement, detection, and tracking modules to achieve high accuracy in cluttered, occluded, and dense debris environments. Evaluations on both synthetic and real Antarctic telescope data demonstrate strong performance, achieving a 73.2% MOTA score. The study highlights the potential of deep learning for real-time, transferable debris tracking and establishes SDTD as a benchmark for future research.Is this conversation helpful so far."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper proposes a deep-learning approach for space debris tracking in complex skylight backgrounds. The main contributions are:\n\n1.The authors introduce a novel dataset, the Space Debris Tracking Dataset (SDTD), created by an observation-based simulation scheme, drawing on astronomy images (from e.g. the Zwicky Transient Facility, ZTF) and synthetically imposing debris trajectories and backgrounds. The dataset reportedly includes 18,040 video sequences (≈ 62,562 frames) and ~250,000 synthetic debris instances. \nMoonlight\n\n2.They propose a network named SDT‑Net, which comprises a Region-of-Interest Feature Enhancement (RoIFE) module, a detection module and a tracking module (tracking by detection plus association across frames). The network is targeted at the multi-object tracking (MOT) task in astronomical / debris scenarios. \n\n3.They conduct experiments on their synthetic dataset and also evaluate transfer to real-world data: they claim a MOTA score (Multiple Object Tracking Accuracy) of ~73.2% (or ~70.6% in some versions) on a small real dataset collected at an Antarctic station. \n\n4.They argue that their dataset addresses the paucity of annotated debris-tracking data, and that SDT-Net exhibits robustness under dense debris, occlusion, and complex star-field backgrounds.\n\nThus the paper is an attempt to bring modern deep-MOT methods into the space-debris tracking domain, supported by a large synthetic benchmark."}, "weaknesses": {"value": "While the paper makes interesting advances, there are several concerns and weaknesses that the authors should address:\n\n1. Synthetic-to-real transfer gap / dataset realism\n\n1) Although the dataset is large and simulation-based, synthetic data may not fully replicate the statistical characteristics of real debris tracks, noise sources, background clutter, telescope artefacts, or imaging conditions (e.g., atmospheric scintillation, streak brightness variation, non-uniform PSF, variations in exposure times, sensor noise). The authors do test on a small real dataset, but the size is tiny (36 video sequences, ~2,228 frames) and limited to one station (Antarctic). This raises questions about generalisability to other sensors, orbital regimes, debris sizes, lighting conditions, star-field densities.\n\n2) The paper reports a single performance number on real data; more extensive evaluation across different observational setups would strengthen the claim of “strong transferability”.\n\n2. Dataset annotation / ground-truth fidelity and bias\n\n1) The synthetic generation process may introduce biases (e.g., debris speed, size, appearance, background variation) that favour their method, especially since the method is trained on the synthetic data. It’s unclear how well annotation errors, occlusion patterns, sensor artefacts, and false positives/negatives are handled.\n\n2) The real data annotations (astronomy experts) are limited in quantity; the annotation criteria, inter-annotator consistency, debris definitions (what qualifies as debris vs star/artefact) may affect reproducibility.\n\n3. Evaluation metrics and baseline comparisons\n\n1) The paper uses MOTA as a key metric; however, MOTA alone may not capture fine issues like ID-switches, fragmentation, false alarms in cluttered star fields, long-term track survival, or tracking latency (important for real-time/operational use).\n\n2) The baselines compared are relatively generic MOT methods (e.g., CenterTrack, OCSORT) rather than domain-specific methods tailored to astronomical debris or long-exposure streak detection. A stronger argument would include recent astronomy/space-debris tracking methods.\n\n3) The paper claims “state-of-the-art”, but many details about run-time, sensor input frame rate, false positive/false negative rates, resource usage (GPU/CPU) are missing. For an operational system, these are important.\n\n4. Scalability and real-time viability\n\n1) Space debris tracking in real operational settings often demands real-time or near-real-time performance, dealing with many debris objects, variable frame rates, large fields of view, and possibly resource-constrained platforms. The paper does not sufficiently discuss latency, computational load, or memory constraints.\n\n2) Dense debris scenarios (e.g., mega-constellations, low Earth orbit clutter) may stress the method beyond the distribution of synthetic data; how well does it scale beyond the densities in the dataset?\n\n5. Lack of orbital/physical modelling integration\n\n1) The method appears largely vision-based (image/video processing) without explicit incorporation of orbital dynamics, sensor geometry, debris kinematics, or space situational awareness (SSA) context (e.g., Two-Line Elements, orbital propagation). In many practical applications, combining image tracking with orbital dynamics yields more robust performance. The paper doesn’t show how their output could link to orbit prediction or catalogue maintenance.\n\n2) Without physics-based constraints (motion models, known debris motion patterns), the tracker may fail in ambiguous scenarios (e.g., overlapping tracks, rapid acceleration, non-linear motion), and the paper does not explore these limitations in depth.\n\n6. Generalisation to other observational platforms\n\n1) The dataset is constructed from ZTF images (ground-based optical telescope) and the real evaluation is from a single station. It is unclear how well the method would generalise to different sensors: e.g., space-based optical imagers, radar, different exposure times, spectral bands, or telescopes with different PSFs, different background noise levels, different orbital altitudes.\n\n2) The authors should discuss how the method would adapt to e.g., GEO, MEO, or LEO regimes, or to different sensors (infrared, radar) or daytime/nighttime imaging.\n\n7. Benchmark release and reproducibility\n\n1) The paper mentions that “dataset and code will be released soon”. Without immediate availability, reproducibility and community uptake may be limited. The authors should commit to making the dataset, annotations, evaluation scripts and code available under a clear license, and provide a leaderboard or standard evaluation split.\n\n2) If synthetic only, there is a risk that future users will duplicate their simulation bias. Clear documentation of simulation parameters, debris motion models, background modelling is needed.\n\n8. Limited real-world deployment discussion\n\n1) The paper could benefit from a deeper discussion of how this tracking method would integrate into operational debris tracking pipelines, what the false alarm risk is, how track continuity and object correlation across multiple passes/sensors would be handled, and what the end-to-end system implications are (e.g., collision avoidance, catalogue updating).\n\n2) It is also unclear how many frames per second, what field of view, and what detection sensitivity (size/magnitude of debris) the system supports; practical relevance to e.g., <10 cm debris tracking is not characterised."}, "questions": {"value": "Here are several relevant prior works that the authors should cite, covering space-debris detection/tracking, multi-object tracking in astronomy, datasets, and physics-informed approaches:\n\n**Space-debris detection/tracking and optical observations**\n\nCament, L. et al., “Space Debris Tracking with the Poisson Labeled Multi-Bernoulli Multi-target Tracking Filter”, Sensors, 21(11):3684, 2021.\n\n“A Robust Vision-based Algorithm for Detecting and Classifying Small Orbital Debris” (NASA MSFC) – algorithm for small debris using optical detection. \nNASA Technical Reports Server\n\nNavya, M. et al., “Deep Learning-Based Space Debris Tracking and Mitigation”, J Electrical Systems, 20(1):606-611, 2024. \n\nZhou, D., Sun, G., Zhang, Z., Wu, L., “On Deep Recurrent Reinforcement Learning for Active Visual Tracking of Space Non-cooperative Objects”, arXiv:2212.14304, Dec 2022. \n\nRoll, D. S., Kurt, Z., Woo, W. L., “CosmosDSR – a methodology for automated detection and tracking of orbital debris using the Unscented Kalman Filter”, arXiv:2310.17158, Oct 2023. \n\n**Astronomical multi-object tracking / star-field object tracking**\n\nGuan, J., Cheng, H-Y., Wu, Y-P., Tian, C., Qi, J-Y., “Multi-target tracking for star sensor based on CenterTrack deep learning model”, Scientific Reports 15:37125 (2025). \n\n**Space-debris modelling / simulation and environment context**\n\nKim, et al., “Review of Space Debris Modeling Methods and Development Trends”, Journal of Astronautical Sciences, 41(4):209-… (2024) \n\nESA Space Debris Environment Report, https://sdup.esoc.esa.int/discosweb/statistics/, sdup.esoc.esa.int\n\n**Deep learning object/tracking methods in cluttered/low SNR astronomical settings**\n\nSDebrisNet: “SDebrisNet: A Spatial–Temporal Saliency Network for Space Debris”, Applied Sciences 13(8):4955 (2023). \n\n**Benchmarks/datasets for debris/satellite detection**\n\nThe authors should mention existing optical/space-object detection datasets, even if only for detection (not tracking) to position their contribution. For example, the Kaggle “Debris Detection Dataset” (optical images) – though limited. \n\n**Orbit/dynamics embedding into tracking**\n\nAlthough not directly DL-tracking, works that link vision tracking with orbit dynamics may strengthen the discussion. For example the PINN-based tracking after collision: “Tracking an Untracked Space Debris After an Inelastic Collision Using Physics Informed Neural Network”, arXiv:2307.09938 (2023)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bocoz5dggB", "forum": "j63W4sMjFE", "replyto": "j63W4sMjFE", "signatures": ["ICLR.cc/2026/Conference/Submission6509/Reviewer_9kga"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6509/Reviewer_9kga"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6509/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762465663165, "cdate": 1762465663165, "tmdate": 1762918874373, "mdate": 1762918874373, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}