{"id": "HAP8useYqu", "number": 22218, "cdate": 1758327884771, "mdate": 1759896879543, "content": {"title": "Operator Flow Matching for Timeseries Forecasting", "abstract": "Forecasting high-dimensional, PDE-governed dynamics remains a core challenge for generative modeling. Existing autoregressive and diffusion-based approaches often suffer cumulative errors and discretisation artifacts that limit long, physically consistent forecasts. Flow matching offers a natural alternative, enabling efficient, deterministic sampling. We prove an upper bound on FNO approximation error and propose TempO, a latent flow matching model leveraging sparse conditioning with channel folding to efficiently process 3D spatiotemporal fields using time-conditioned Fourier layers to capture multi-scale modes with high fidelity. TempO outperforms state-of-the-art baselines across three benchmark PDE datasets, and spectral analysis further demonstrates superior recovery of multi-scale dynamics, while efficiency studies highlight its parameter- and memory-light design compared to attention-based or convolutional regressors.", "tldr": "", "keywords": ["Flow matching", "neural operators", "PDEs", "forecasting"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9a95fd7be4a0cbb36f40a635f156feab1ab03939.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces TempO, a novel framework for PDE forecasting based on flow matching in latent space. Unlike stochastic diffusion models, TempO leverages deterministic ODE-based sampling through a time-conditioned Fourier Neural Operator (FNO) to capture both global and local spectral dynamics. The paper provides theoretical error bounds, showing that FNOs can approximate flow fields more efficiently than Transformer- or U-Net–based samplers. Experiments are conducted on three PDE benchmarks (Navier–Stokes, Shallow Water, Reaction–Diffusion)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is technically solid, with a clear theoretical contribution (Theorem 3.1, Proposition 3.2) establishing approximation bounds for FNO-based flow matching.\n2. The idea of coupling flow matching with operator learning (FNO) is elegant and well-motivated.\n3. The experimental evaluation is rigorous and diverse, covering several PDE datasets and comparing against recent ViT-based and diffusion-based baselines."}, "weaknesses": {"value": "1. The training details (e.g., hyperparameter sensitivity, stability beyond 40-step rollouts) are under-discussed. Since the main claim is long-horizon stability, results on longer or more chaotic regimes would strengthen the argument.\n2. The novelty claim could be better contextualized: related works such as Functional Flow Matching (Kerrigan et al., 2023) and Conditional Flow Matching (Tamir et al., 2024) are mentioned but not deeply contrasted with TempO in terms of scalability or architecture"}, "questions": {"value": "1. Please see the weaknesses above.\n2. Could the model extend to irregular sampling or missing data, for example through Neural ODE–like continuous-time conditioning?\n3. How sensitive is TempO’s performance to the number of Fourier modes or truncation level (beyond the eight-mode empirical finding)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "FXz9iF2m42", "forum": "HAP8useYqu", "replyto": "HAP8useYqu", "signatures": ["ICLR.cc/2026/Conference/Submission22218/Reviewer_sseo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22218/Reviewer_sseo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22218/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760909934591, "cdate": 1760909934591, "tmdate": 1762942119374, "mdate": 1762942119374, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles long-horizon forecasting for high-dimensional PDE dynamics , proposing Tempo, a novel latent flow matching model. Tempo's core innovation is using a time-conditioned Fourier Neural Operator (FNO) as its velocity field regressor. The model operates in a latent space, employing sparse conditioning and channel folding for efficient 3D spatiotemporal processing. The authors provide theoretical justification that this FNO-based design is asymptotically more parameter-efficient than sampler-based architectures like Transformers or U-Nets. Experimentally, Tempo outperforms SOTA baselines on three PDE datasets, demonstrating highly stable long-horizon forecasting where competitors fail , while also being significantly more parameter-efficient"}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* Proposes **Tempo**, a novel model combining latent flow matching with an FNO regressor, which is well-motivated by aligning the FNO's spectral bias with continuous PDE dynamics.\n\n* Provides a theoretical analysis (Theorem 3.1, Prop 3.2) to justify the architecture, suggesting FNOs can achieve a target accuracy with asymptotically fewer parameters than sampler-based models like U-Nets or Transformers.\n\n* Demonstrates highly stable 40-step autoregressive forecasting on the NS-w dataset. This significantly outperforms ViT and U-Net baselines, which show clear degradation.\n\n* The model is highly parameter-efficient. It also shows superior sampling efficiency, requiring the fewest Number of Function Evaluations (NFEs) for inference."}, "weaknesses": {"value": "* The paper suffers from significant clarity issues. It lacks a high-level overview of the proposed method, making it difficult to grasp the core components. The writing style relies on overly long and convoluted sentences, hindering readability. The overall structure feels disjointed, making the paper's narrative hard to follow.\n\n* The paper's core motivation—that existing methods fail due to \"cumulative errors and discretisation artifacts\"—is not sufficiently substantiated. This claim is presented as a given, but the paper lacks the necessary citations or analysis to support it.\n\n* The connection between the stated problem and the proposed solution is weak. The paper does not adequately explain *why* flow matching is the right choice to mitigate \"cumulative errors\" or *how* the FNO architecture specifically addresses \"discretisation artifacts\" better than other regressors. The design choices feel disconnected from the initial problem statement.\n\n* The methodological novelty is unclear. The primary components, Flow Matching and FNO, are both well-established. The paper fails to clearly articulate what makes their specific combination (Tempo) a significant and novel contribution beyond a straightforward engineering application.\n\n* The empirical results are not fully convincing.\n    * The performance gains over the ViT and U-Net baselines are marginal in several next-step prediction tasks. The strong long-rollout performance is only demonstrated on one dataset (NS-w).\n    * The baseline comparison is insufficient. The paper omits direct comparisons against the original FNO (which should be a key baseline/ablation) and other strong operator learning models (e.g., WNO, DeepONet), making it difficult to properly contextualize the results."}, "questions": {"value": "1.  The paper's motivation hinges on addressing \"cumulative errors\" and \"discretisation artifacts.\" Could the authors elaborate on the explicit mechanism by which the flow matching framework and the FNO's spectral bias inherently mitigate these specific error types, in a way that standard autoregressive U-Nets or Transformers do not?\n\n2.  The experimental comparison focuses on ViT and U-Net regressors *within* the flow matching setup. Could the authors provide a comparison against a standard autoregressive FNO (or other strong neural operators like WNO/DeepONet)? This seems crucial to disentangle the benefits of the proposed flow matching framework from the known benefits of the FNO architecture itself.\n\nSee the above weaknesses for further details."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fYTQFeOVJ1", "forum": "HAP8useYqu", "replyto": "HAP8useYqu", "signatures": ["ICLR.cc/2026/Conference/Submission22218/Reviewer_txKP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22218/Reviewer_txKP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22218/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761197586147, "cdate": 1761197586147, "tmdate": 1762942118948, "mdate": 1762942118948, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose using FNO as the denoiser during flow matching, motivated by some theoretical insight. When compared to ViT or Unet based denoisers across different noise schedules, the method works well and seems to improve on 2D benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The authors present a variety of baselines, including different noise schedules and backbones.\n- The theoretical motivation for using FNO as a denoiser is apparent.\n- The performance gains are good, with consistent gains across different noise schedules/datasets/baselines."}, "weaknesses": {"value": "- I’m having a hard time differentiating this work from prior work (Functional Flow Matching https://arxiv.org/pdf/2305.17209), where an FNO is also used as the denoiser and an OT schedule is used. Is the novelty using sparse conditioning and channel folding? The additional experiments to a longer horizon are also somewhat lacking (an ablation in Table 5 for some unspecified dataset).  \n- Reporting next-step error is a good start, but in general, most works are concerned with rollout error since the main driver of error in neural PDE surrogates is autoregressive error accumulation. MSE/time is shown in Table 5, but it would be good to see this for all models (backbones + noise schedules), since it is more informative than single-step error. \n- There seems to be better spectral performance at the highest frequency bands for ViT-based models, which may be related to FNO’s mode truncation. This might be more relevant for spectral accuracy in more complex systems (turbulence, multiscale phenomena)\n- The ablation in Table 5 on the effect of context length on accuracy could be expanded on. Is the model with a sequence length of 25 predicting 15 unseen frames and the model with sequence length of 2 predicting 38 unseen frames? \n    - This also seems to contradict prior results (https://arxiv.org/pdf/2507.02608,  https://arxiv.org/abs/2111.13802) that suggest that the context length either does not have an effect on rollout error or harms it. \n- Some comparisons to deterministic models (FNO/Unet) for SWE/NS/RD would be beneficial just to calibrate what is the baseline performance for neural surrogates on these common systems."}, "questions": {"value": "- There could be a few more relevant works (related to flow matching for PDEs) that could be cited:\n    - Latent flow matching (https://arxiv.org/abs/2503.22600)\n    - Flow matching for PDEs (https://arxiv.org/abs/2506.08604)\n    - Using FNO as a Denoiser (https://arxiv.org/abs/2302.07400)\n- What dataset is used in Table 5? \n- Is Figure 1 generated with a single trajectory or averaged across the validation set? \n- Not a problem, but there seem to be a lot of red references to lead nowhere. \n- The performance of the UNet denoiser seems to be very poor based on qualitative observations (Figure 6), but since the NS dataset has been standard for quite some time now, there is a lot of prior work that shows that vanilla FNO/Unet can approximate the system well + even more challenging systems (https://arxiv.org/abs/2209.15616, https://arxiv.org/abs/2309.01745). \n    - This isn’t explicitly an issue, but just curious that Unet struggles so much.\n- Also not a clear issue, but the use of a transformer as a diffusion/flow matching backbone is very ingrained in modern machine learning, not only in image generation, but also in PDEs. There is a lot of prior work that uses this paradigm successfully, so suggesting an alternate and expecting people to adopt it would need to include a very rigorous set of experiments, likely on more challenging PDEs/benchmarks (https://arxiv.org/abs/2412.00568).\n    - Perhaps a thought experiment would be: \"If I am building a large, latent generative model, would I use a transformer or FNO as the backbone?\" How would you convince someone of one method or another?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "B30dQPNbRG", "forum": "HAP8useYqu", "replyto": "HAP8useYqu", "signatures": ["ICLR.cc/2026/Conference/Submission22218/Reviewer_CwD2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22218/Reviewer_CwD2"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22218/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761684685607, "cdate": 1761684685607, "tmdate": 1762942118721, "mdate": 1762942118721, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a method called TempO, which evolves the solution of PDEs using flow matching. First, TempO projects the input into a latent space. The evolution of the solution in latent space is trained with flow-matching, including sparse conditioning on the previous latent space values. Here, TempO uses a time-conditioned FNO to learn the latent flow.  The authors evaluate TempO against other flow-matching video-generation methods based on vision transformers and UNets in combination with different flow-matching paths. The experiments are performed on the Navier-Stokes, shallow water, and reaction-diffusion PDEs, showing that TempO reaches a lower MSE and diverges more slowly than the other models."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Novel combination of Flow-matching and FNO.\n2. Theoretical bounds on the model approximation error are provided.\n3. Extensive evaluation against other flow-matching approaches.\n4. The paper is clear and well written."}, "weaknesses": {"value": "1. No evaluation against PDE-specific models, only other flow-matching models from the video generation domain are tested. There are a number of PDE models that employ diffusion [1,2,3], for example, and also improve the rollout stability in that way.  Additionally, since the model uses an FNO in latent space, a plain FNO should also be used as a baseline. \n \n2. In the introduction, the stochasticity of diffusion-based models is described as a disadvantage for PDEs. However, as shown in [2], the stochasticity is still helpful, even in deterministic PDEs, since it can act as an uncertainty measure. It is especially helpful for chaotic PDEs, where diffusion can help to describe the distribution of plausible trajectories (since any estimator will diverge at some point for chaotic dynamics)\n\n\n\n[1] Serrano, L., Wang, T. X., Le Naour, E., Vittaut, J. N., & Gallinari, P. (2024). AROMA: Preserving spatial structure for latent PDE modeling with local neural fields.  \n[2] Lippe, P., Veeling, B., Perdikaris, P., Turner, R., & Brandstetter, J. (2023). Pde-refiner: Achieving accurate long rollouts with neural pde solvers.  \n[3] Holzschuh, B., Liu, Q., Kohl, G., & Thuerey, N. (2025). PDE-Transformer: Efficient and Versatile Transformers for Physics Simulations."}, "questions": {"value": "1. For the sparse conditioning, the experiments (line 269) mention that the last 15 frames are used to condition. During inference, how does the sparse conditioning work at the beginning (ie, when you only have the embedding of the initial condition as the input)? Does the model need to encode multiple timesteps for that?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "z1rJ4xI6LP", "forum": "HAP8useYqu", "replyto": "HAP8useYqu", "signatures": ["ICLR.cc/2026/Conference/Submission22218/Reviewer_D1ut"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22218/Reviewer_D1ut"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22218/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761852776439, "cdate": 1761852776439, "tmdate": 1762942118486, "mdate": 1762942118486, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}