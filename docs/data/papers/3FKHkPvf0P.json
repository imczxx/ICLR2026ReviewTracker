{"id": "3FKHkPvf0P", "number": 19549, "cdate": 1758297154158, "mdate": 1759897033264, "content": {"title": "Changanya Ndimi:  Code-Switched Speech Generation via a Diffusion Prior and Linguistic Constraints", "abstract": "We consider the problem of generating code-switched speech by editing monolingual utterances using a pre-trained generative prior and a set of linguistic constraints. In our setting, the prior is a diffusion-based speech synthesis model trained independently on monolingual data, while the constraints are differentiable functions that guide the insertion of foreign language segments. These constraints include a multilingual language classifier and a contrastively trained segment encoder, which together ensure that inserted content is linguistically plausible, semantically coherent, and socio-linguistically grounded.By iteratively modifying the noisy speech representation and conditioning on segment-level constraints, our model performs targeted segment replacements without requiring parallel code-switched data. We evaluate our system on a semantically aligned speech corpus spanning five African languages from three major phyla. The resulting speech achieves a COMET score of 0.815 and a LaBSE similarity of 0.880 at the segment level, while preserving speaker identity with an Equal Error Rate of 6.7\\%. It also reproduces natural code-switching patterns in frequency, position, and alternation rate without explicit supervision.To our knowledge, this is the first approach that enables controlled multi-language infusion in a single utterance, producing fluent, coherent, and sociolinguistically realistic code-switched speech. Our work demonstrates that guided diffusion is a promising plug-and-play mechanism for cross-lingual and low-resource speech generation tasks.", "tldr": "", "keywords": ["Code-switching", "speech", "low resource", "Difussion"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/dd9f0a3f3567e84b6dceb515ecc2b26a75793ad7.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents a method for generating code-switched speech using diffusion models. The approach transforms monolingual speech into realistic code-switched utterances without requiring parallel code-switched training data.\n\nThe author leverage a pre-trained diffusion model and guides it with two differentiable constraints: 1) multilingual Language Identification classifier that determines \"where\" and \"how much\" to switch languages; 2) a multilingual encoder that choses \"what\" to insert."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- To the best of my knowledge, the proposed approach is novel in the code-switching setting.\n- Strong empirical results on five African languages (Swahili, Luo, Kikuyu, Nandi, English), which include human evaluation."}, "weaknesses": {"value": "- The overall paper is hard to read and follow; it overuses math equations. Most of the equations could be simplified and moved to the appendix. The paper would be greatly improved by a thorough rewrite and by adding figures that explain the overall method.\n- The paper lacks any baseline methods to compare to the proposed model. For instance, since the paper proposes a synthetic dataset generation approach, it would be important to show other methods for generating synthetic datasets (e.g., randomly chopping and inserting speech from a different language)."}, "questions": {"value": "- why no other methods are considered to generate pseudo data? as well as other models to use these data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "KjuIhqqGEQ", "forum": "3FKHkPvf0P", "replyto": "3FKHkPvf0P", "signatures": ["ICLR.cc/2026/Conference/Submission19549/Reviewer_qSNe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19549/Reviewer_qSNe"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19549/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761579823934, "cdate": 1761579823934, "tmdate": 1762931434681, "mdate": 1762931434681, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper uses a diffusion-based framework to generate code-switched speech in African languages. They do this with a retrieval-augmented, constrained denoising diffusion model (DDPM). The denoising happens using both the language ID and a retrieval-based encoder blending semantically matched segments in different languages.\n\nThe authors look at four Kenyan languages and English, measuring semantic fidelity of codeswitched utterances using BLEU score, BERT score, COMET and LaBSE similarity of English translations.\n\t\n Human ratings show that the generated speech is perceived as fluent, coherent and realistic in all languages."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "This is an original problem setting using new speech data for Kenyan languages. The use of diffusion models for multilingual codeswitched speech generation is an interesting contribution given the data constraints that exist with Kenyan languages.\n\nThe authors have carefully evaluated not only the quality of the generated speech in three dimensions (fluency, coherence, realism), but also they evaluate the semantic fidelity of the generated speech with various metrics."}, "weaknesses": {"value": "The presentation could be a bit clearer:\n- The tables are very small and could be made bigger\n- Please add ‘Indo-European’ as the language family for English\n- It would be great to know how many selected items were rerecord (line 282) and what percentage of the dataset constitutes of re-rcorded utterances. We don’t have statistics on the code-switched data either.\n- Including more information on your MT system in Appendix F would be helpful, especially since it’s integral to your scoring. Which transformer-based MT model did you use? Did you pretrain it, or finetune an existing model?"}, "questions": {"value": "Why is most of the evaluation on text-based similarity of transcribed and translated utterances? Do you do any sanity checking of the transcription and translation of utterances, or just evaluate all of the translated text out-of-the box? \n\nIt would also be great to hear some examples at the empty GitHub repo linked!"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "C7hmRsQF0V", "forum": "3FKHkPvf0P", "replyto": "3FKHkPvf0P", "signatures": ["ICLR.cc/2026/Conference/Submission19549/Reviewer_TACB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19549/Reviewer_TACB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19549/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991134564, "cdate": 1761991134564, "tmdate": 1762931434163, "mdate": 1762931434163, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a technical, ambitious approach to generating speech in African languages that includes artificially-induced code-switching (CS) between languages.  Key objectives are to generate high quality, natural speech that has a consistent speaker identity.  It aims to include switching across multiple languages."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The paper is highly ambitious, incorporating a wide range of SOTA techniques in machine learning.  Realistic CS generation is challenging even between well-resourced language pairs such as English-Chinese or English-Spanish, so using very natural speech from low-resource languages is an impressive endeavour.\n\nThe paper includes a very range of techniques and evaluation methods and goes into considerable technical detail."}, "weaknesses": {"value": "I am very familiar with the topic of CS generated, but even I found this paper exceptionally hard to follow.  The technical parts – especially the infusion specification (Section 2, unnumbered equation), the DDPM (§2.1), and free-energy methods  (§2.2) and the diffusion-based CS models (§3.1 and §3.2) were extremely difficult for me to follow.  This may simply be my inability to follow the overwhelming amount of mathematical notation – but it was not helped by the equations consistently lacking any clear justification or explanation.  Why did you choose the methods you did?  How did you derive your formulae?  Which equations were your own and which were standard approaches taken from the literature?  What were the key innovations, and why were they successful?\n\nIt did not help that a very large number of symbols and notation was introduced, not all of it properly explained.  Clashes such as using $\\mathcal{L}$ for \"language\" as well as the more standard loss-function did not help.\n\nI personally found the paper to be overly long, and too heavily reliant on appendices for important details – including a review of prior work.   If you had trimmed it down and focused on the key parts, it might be more readable. \n\nMore importantly, the review of work was inadequate, failing to explain the relationship of this paper to other CS generation works cited – simply investigating different languages is insufficient novelty.  More importantly, the results presented merely compared the proposed generation techniques to natural samples, not to any prior, or simpler baseline methods for CS generation – many sensible baselines were entirely missing.  They simply showed that the proposed technique under-performs natural CS, which is unsurprising.\n\nAlthough many evaluation metrics were used, it is unclear whether they adequately assess the quality of the output – though it didn't help that the objectives of the CS generation were not clearly stated, making it hard to truly understand the value of the work.\n\nAlthough switching frequency was cited as a metric, this is a gross simplification of the nuances of real CS (see for an example, Chi, J., Wallington, E., & Bell, P. (2024). Characterizing code-switching: Applying linguistic principles for metric assessment and development. In Proceedings of Interspeech 2024 https://doi.org/10.21437/Interspeech.2024-551)\n\nGenerally, the nature of the CS data not properly explained – did speakers freely mix many different language pairs in natural data?  If so, which pairs?  What was the distribution of utterances containing more than two languages?\n\nNumerous technical jargon was used without clear explanation, for example:\n- FAISS index\n- \"plug-and-play\" (in what sense?)\n- \"retrieval-augmented\" (mentioned twice on page 1 but never explained in this context)\n- Refine function (no definition given)\n- FiLM-style modulation (???)\n- symbols $x_t$ and $x_j$ seem to clash (eg. in equation 5)\n\nPromised audio samples could not be found at the link referenced."}, "questions": {"value": "It would be great if you could more clearly clarify the high-level motivation for the dataset and specifically, for your proposed method.  \n\nWhy did you choose not to investigate more basic baselines?\n\nWhich metrics did you consider most important and why?\n\nWhich prior work in CS generation is your work closest to, and why?\n\nWhat was your main scientific contribution?\n\nHow does the CS behaviour of your method compare to natural data in respect of more subtle CS metrics beyond alternation rate?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BGEj7wkKyA", "forum": "3FKHkPvf0P", "replyto": "3FKHkPvf0P", "signatures": ["ICLR.cc/2026/Conference/Submission19549/Reviewer_QKKn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19549/Reviewer_QKKn"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19549/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762173032653, "cdate": 1762173032653, "tmdate": 1762931433291, "mdate": 1762931433291, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper shows a diffusion-based way to generate code-switched speech from monolingual audio without using any parallel data. It brings two control parts — a Language identification (LID) module to decide where to switch and a retrieval-based infusion part to keep meaning consistent. The proposed method is extensively validated on five african languages."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The application of constraint guided diffusion for multilingual code-switch speech generation is novel and interesting. \nThe two control modules (c1 and c2) are well described and make sense; they give clear control over when to switch languages and how to keep the meaning consistent. \nThe retrieval-based infusion idea is well thought, original, and helps to keep both meaning and speech flow natural.\nThe evaluation is thorough and extensive, focusing on five African languages, which makes it useful and meaningful work."}, "weaknesses": {"value": "The reason for using the DDPM module is not clear. It is hard to see why denoising diffusion is really needed for this task. The authors can add further justification on why denoising helps code-switched generation, not just saying it works as a general generative prior.\nThe description of the c2 module separates notations and description, which makes it confusing to read. It would be better if the authors clearly said which parts are trained and which are frozen, while describing their roles. The solution primarily relying on usage of pre-trained modules, requiring only the switching prior and clean point \\eta to be optimized. The readability would be improved if authors explicitly specifies the trainable components of the c2 module. \nThe distinction between training and inference is unclear.\nThere is room for improvement for the clarity of the paper. The presentation could be improved for the methodological part. \nFurther the scope of the problem seems limited. It may not be interesting to the broader audience. The authors may consider providing further justification for choosing this problem."}, "questions": {"value": "1) The authors can add further justification on why denoising helps code-switched generation. 2) Specify trainable parts of c1 and c2 modules."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SbtXk897DU", "forum": "3FKHkPvf0P", "replyto": "3FKHkPvf0P", "signatures": ["ICLR.cc/2026/Conference/Submission19549/Reviewer_rZXK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19549/Reviewer_rZXK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19549/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762251499318, "cdate": 1762251499318, "tmdate": 1762931432875, "mdate": 1762931432875, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}