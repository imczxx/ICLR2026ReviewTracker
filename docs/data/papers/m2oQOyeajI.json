{"id": "m2oQOyeajI", "number": 13266, "cdate": 1758215828856, "mdate": 1759897451187, "content": {"title": "SENSE: $\\underline{\\text{SEN}}$sing Similarity $\\underline{\\text{SE}}$eing Structure", "abstract": "Dimensionality reduction is widely used to visualize and analyze high-dimensional data, but most methods assume centralized access to all pairwise similarities, which is infeasible in privacy-sensitive, decentralized settings. We introduce $\\textbf{SENSE}$, a geometry-aware framework for privacy-preserving decentralized representation learning. SENSE reconstructs global structure from sparse, locally observed distances via structured matrix completion, requiring no raw data sharing or iterative communication. It supports both Euclidean and hyperbolic geometries, adapts to flat and hierarchical structures, and operates under four deployment regimes reflecting real-world data availability. By design, SENSE safeguards raw features while producing faithful embeddings. Our theoretical analysis establishes formal privacy guarantees, and experiments on diverse benchmark datasets show that SENSE matches centralized baselines while remaining efficient and privacy-preserving.", "tldr": "SENSE is a privacy-preserving framework that builds high-quality global embeddings across decentralized clients without sharing raw data, working in both Euclidean and hyperbolic spaces.", "keywords": ["Privacy Preserving", "Distributed Learning", "Federated Learning", "Contrastive Neighbor Embedding", "Hyperbolic Embedding", "Matrix Completion"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/994fe2be479748d77a1ef35ccf72070e5ce52306.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces SENSE (Structured Embedding via Neighborhood Smoothing and Entropy regularization), a framework for learning graph embeddings that explicitly smooths neighborhood information and incorporates an entropy-based regularizer to encourage diverse, informative representations. The method combines spectral-style smoothing with contrastive learning, ensuring that nearby nodes in the graph have more consistent embeddings while preserving discriminative structure. The authors provide theoretical justification showing that the proposed loss reduces embedding variance and improves generalization. Experiments on several standard graph benchmarks (Cora, Citeseer, Pubmed, Ogbn-Arxiv, etc.) demonstrate consistent gains over existing baselines such as DeepWalk, Node2Vec, and GraphSAGE."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1 The paper proposes a novel and well-motivated combination of neighborhood smoothing and entropy regularization for graph representation learning. The method is simple and interpretable, making it potentially useful as a drop-in replacement for other embedding frameworks.\n\nS2 The theoretical analysis connects the method to variance reduction and information maximization principles, providing good intuition.\n\nS3 The writing is mostly clear, and the ablation on entropy regularization provides some insight into the contribution of each component."}, "weaknesses": {"value": "W1 The experimental validation is somewhat limited. The datasets used (Cora, Citeseer, Pubmed, Ogbn-Arxiv) are relatively small and standard; there are no large-scale or more complex benchmarks (e.g., Ogbn-Products or social graphs).\n\nW2 The comparisons are missing a few key modern baselines, especially recent self-supervised or contrastive graph representation methods like GraphCL, DGI, or GCA. This makes it unclear how SENSE performs relative to the current state of the art.\n\nW3 There is no analysis of computational overhead or scalability — since the method involves neighborhood smoothing and entropy regularization, its cost might grow with graph density, but this is not discussed.\n\nW4Some theoretical assumptions (e.g., smoothness and neighborhood homogeneity) seem quite restrictive and may not hold in real-world, heterogeneous graphs.\n\nW5 The ablation studies are minimal — it would be useful to see how sensitive the performance is to the choice of neighborhood size or entropy coefficient."}, "questions": {"value": "NA, see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "KO7AytT1dl", "forum": "m2oQOyeajI", "replyto": "m2oQOyeajI", "signatures": ["ICLR.cc/2026/Conference/Submission13266/Reviewer_seDM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13266/Reviewer_seDM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13266/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761903118876, "cdate": 1761903118876, "tmdate": 1762923940989, "mdate": 1762923940989, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SENSE, a dimensionality reduction framework which is designed for a decentralized, privacy-sensitive setting. The authors wish to avoid sharing raw data by having local parties compute distances to a shared set of \"anchor\" points. These anchor distances are then used to reconstruct a global similarity matrix using matrix completion. This completed matrix is then used to learn a low-dimensional embedding and the method is applicable to Euclidean and hyperbolic distances."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Dimensionality reduction is of broad interest to the ML community, especially in settings where communication costs of privacy are important."}, "weaknesses": {"value": "To me paper has some flaws in its motivation, problem formulation, and technical exposition, which make it hard for me to evalute it's contributions.\n\n- First, the paper starts by saying \"most similarity-based DR approaches assume centralized access to all pairwise similarities\". This seems very inaccurate and misleading to me as many established DR methods do not require this. For example, widely used methods such as PCA or random projections (e.g. using Johnson Lindenstrauss based mappings) can be very easily computed in a decentralized or distributed fashion. For example, JL maps can be generated from a shared random seed meaning none of the data has to be shared, while still guaranteeing that the resulting projections can be compared in terms of preserving pairwise distances. Another class of mappings that contradicts what seems to be the central thesis of the paper are learned mappings (e.g. autoencoders or neural networks trained on prior public data or public models). They learn an explicit mapping to a lower dimensional space and once trained, the network on public data, the network can be locally accessed by any party. \n\n- The other main weakness of the paper is that it lacks a well defined formal problem setting. The paper claims to handle privacy, but does not have a formal privacy statement (for ex differential privacy is a formal privacy gurantee). The paper claims to work in a decentralized setting, but does not define a formal communication model between parties holding pieces of the data. While these are practical considerations, it is difficult to understand the merits of the proposed method if privacy/communication is not formally defined. For example, how is the data partitioned across parties? What are the exact communication model? Is there a central server where the parties can interact with? What is the adversarial model for privacy? In terms of privacy, the main statement is essentially that points cannot be exactly reconstructed unless some number of distances are revealed, but this is almost a trivial observation from parameter counting. However, even if points cannot be reconstructed exactly, there is always some leakage of information even if a single distance is observed! For ex, even if you know that a 'private' point has a certain distance to a fixed point, it leaks some about of non trivial 'information' about the private point. That is why a formal privacy model is necessary! IT is also impossible to compare the paper's 'privacy' guarantee to any other method in a meaningful way since it is not formally defined.\n\n- The paper also does not give a very clear description of the proposed algorithm. E.g. there is no algorithm block or a clear step by step guide, clearly explaining the process from the input data (at each local party) to the final low-dimensional representation. What are the precise assumptions? What exactly is the computational problem being solved? The method appears to be a vague combination of arbitrary steps (matrix completion, contrastive learning) without a clear unifying objective. In addition, there are no formal guarantees about the proposed method. They claim to be minimizing a reconstruction error (Eq. 5), but no precise bounds are provided for this error. While a reconstruction error is defined (Equation 5), no theoretical bounds are provided for this error. What is its \"natural\" scale? How does it depend on the number of anchors, data points, or assumptions on the geometry? Does the learned embedding preserve distances, neighborhood structure, or any other geometric property with any guarantee? \n\n- The paper's claim about efficiencuy are also very unclear. Note that projection based methods such as PCA or JL transforms have a linear complexity on the number of points, but the submission is proposing a constratinve learning objective, which typically requires knowledge of pairwise distances, which is an $O(n^2)$ operation. Thus, the paper does not adequately explain how its method (which seems to require a dense $n \\times n$ matrix after completion) is more efficient than projection-based methods.\n\n\n- In terms of novelty, while the proposed idea of the paper could be novel, but in its current form, the contribution is entirely unclear.\n\nThus overall, I cannot identify any single community that would be excited about this paper. The privacy community would clearly be very uncomfortable with the lack of formal privacy guarantees. The federated learning community would not be satisfied with the lack of a formal communication model. Finally, empirical ML researchers would not be satisfied with the lack of comparison to very sensible baselines e.g. model based or projection based methods."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nTzvwxq2mI", "forum": "m2oQOyeajI", "replyto": "m2oQOyeajI", "signatures": ["ICLR.cc/2026/Conference/Submission13266/Reviewer_o7FR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13266/Reviewer_o7FR"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13266/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761940450130, "cdate": 1761940450130, "tmdate": 1762923940508, "mdate": 1762923940508, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SENSE, a geometry-aware framework for decentralized dimensionality reduction that preserves privacy while maintaining structural relationships in data. Instead of sharing raw features, SENSE uses distances to anchor points as coordination signals, enabling faithful low-dimensional embeddings under privacy constraints. The framework supports both Euclidean and hyperbolic spaces and operates across four data observation regimes. The authors claim provable privacy guarantees without relying on traditional mechanisms like differential privacy or homomorphic encryption, demonstrating competitive performance with centralized baselines while preserving privacy.\n\n__Code link is accessible but files are not__"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "__Novel privacy approach__: The paper makes a significant contribution by framing privacy through geometric underdetermination rather than traditional noise injection. As stated in the paper, \"_geometric underdetermination preserves both fidelity and privacy_\" (p.4), offering a conceptually fresh perspective that avoids the utility-privacy trade-off inherent in differential privacy approaches. This represents genuine originality in privacy-preserving representation learning.\n\n__Practical deployment flexibility__: SENSE demonstrates impressive adaptability across multiple scenarios, handling both Pointwise (single non-anchor per client) and Multisite (multiple non-anchors) settings. The framework's ability to work with \"four observation regimes\" reflecting \"_real-world data availability_\" (p.3) enhances its practical significance for real-world applications like healthcare and finance where data distribution constraints are common."}, "weaknesses": {"value": "__Unjustified complexity over simpler alternatives__: The paper doesn't sufficiently justify why its matrix completion approach is preferable to adding differential privacy to standard dimensionality reduction. As the authors note \"injected noise quickly degrades embedding quality\" (p.4), but they don't quantitatively compare against modern DP mechanisms that carefully calibrate noise to preserve utility. For large-scale applications, the matrix factorization complexity ($O(n^3)$ in worst case) creates unnecessary computational burden compared to simpler DP approaches.\n\n__Insufficient scalability analysis__: While Table 13 mentions \"scalability and runtime on large-scale datasets,\" the paper lacks concrete evidence of how SENSE performs on truly massive datasets (millions of points). The Tiny ImageNet and SVHN experiments don't demonstrate whether the approach remains practical at web-scale.\n\n__Incomplete privacy analysis__: The claim of \"provable reliability\" with \"formal privacy guarantees\" lacks rigorous mathematical treatment. The discussion about anchor count (K) affecting privacy (p.21) needs formal privacy bounds rather than empirical observations. Without proper privacy accounting, it's difficult to compare against established privacy frameworks like differential privacy."}, "questions": {"value": "1. How would SENSE's utility-privacy trade-off quantitatively compare against adding calibrated Gaussian noise (DP-SGD) to standard t-SNE/UMAP? Could you provide $\\epsilon, \\delta$ values for your approach?\n2. For $K < d$ anchors, what's the exact mathematical relationship between K, dimensionality d, and the privacy leakage? Can you derive a formal privacy bound similar to differential privacy's $\\epsilon$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Im4VUXedYv", "forum": "m2oQOyeajI", "replyto": "m2oQOyeajI", "signatures": ["ICLR.cc/2026/Conference/Submission13266/Reviewer_qbSV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13266/Reviewer_qbSV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13266/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971160874, "cdate": 1761971160874, "tmdate": 1762923939866, "mdate": 1762923939866, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}