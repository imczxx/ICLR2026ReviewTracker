{"id": "wjH5SlB9ro", "number": 19224, "cdate": 1758294579057, "mdate": 1763632538118, "content": {"title": "Index-Overlap Similarity: A Value-Free Proxy for Model Relatedness", "abstract": "Measuring client relatedness is central to clustering and personalization in federated learning (FL), but value-based similarities over full weights or gradients are bandwidth-heavy and leak information. We propose \\emph{Index-Overlap Similarity (IOS)}, a value-free metric that represents each client by the indices of its Top-$K$ salient parameters and scores pairs by the normalized overlap of these supports. We show why IOS preserves alignment: under head-dominance with bounded dispersion, it lower-bounds cosine up to tail error; Top-$K$ is invariant to common layerwise rescalings; and exponential moving averages stabilize supports across rounds. We instantiate IOS for clustered personalized FL, neighbor selection, donor ranking, and oracle distribution alignment. Across FMNIST, CIFAR-10/100, and 20News under Dirichlet and pathological splits, IOS matches or exceeds cosine/Euclidean while sharing only indices. IOS is a simple, scalable primitive for similarity search under communication and privacy constraints.", "tldr": "We introduce IOS, a value-free index-overlap similarity that replaces cosine to enable accurate client clustering/personalization in FL while slashing communication and leakage.", "keywords": ["machine learning", "distributed learning", "similarity and search", "Value-Free Similarity"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ff77df9c9f0067e25c11f3e09719fd059e647740.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper tackles the problem of measuring model relatedness in federated learning without incurring high communication cost or risking privacy leakage from sharing real valued parameters. It **introduces Index Overlap Similarity (IOS)**, a value-free metric that represents each model by the **indices** of its **Top $K$ most important parameters** and measures similarity through their normalized overlap. The authors provide theoretical guarantees showing that IOS lower bounds cosine similarity (Proposition 1) and that the Top $K$ support remains stable under noise when smoothed with an EMA (Theorem 1). Experiments on FMNIST, CIFAR10, CIFAR100, and 20News show that IOS matches or outperforms cosine and Euclidean metrics across four federated learning tasks: clustered PFL, neighbor selection, donor ranking, and oracle distribution alignment."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**1) Strong Empirical Validation:** IOS is tested as a drop-in replacement for cosine similarity across four federated learning tasks: clustered PFL, neighbor selection, donor ranking, and oracle distribution alignment. It shows consistent gains on both vision and text tasks using diverse models demonstrating strong robustness and generality. \n\n**2) Significance of the Value-Free Design:** The value-free, index-only idea behind IOS is simple and important. By using only the indices of the most important parameters instead of their values, IOS offers a practical alternative when sharing real-valued updates is costly or raises privacy concerns. \n\n**3) Methodological Completeness and Practicality:** The paper presents a complete and well designed method. The procedure for selecting $K$ is principled and local, balancing coverage $(\\tau) $ and stability $ (\\rho_0)$ instead of treating $K$ as fixed (Algorithm 1). \n\n**4) Clear Motivation and Writing:** The paper is clearly written and well-organised. The introduction frames the work around three main challenges of communication cost, privacy risk, and numerical instability, making the motivation and importance easy to understand. That being said, I later raised a question in my review about how fully these motivations are addressed."}, "weaknesses": {"value": "**1) Reproducibility and Missing Code (Major):**\nThe paper’s contribution relies heavily on experimental validation, comparing the effectiveness of IOS across several federated learning tasks. However, a link to the code is not provided in the paper or the supplementary material, making it difficult for others to reproduce the results or verify the findings. Since the work is largely experiment based, providing access to the code is important for supporting the credibility and reliability of the results.\n\n**2) Missing Evaluation of Privacy and Communication Benefits:**\nThe paper highlights privacy and communication efficiency as key motivations for IOS (first paragraph of the introdcution), yet the experiments focus only on performance and similarity. There is no quantitative analysis of communication savings or empirical evaluation of privacy protection, leaving these claims unverified. Moreover, although the authors note that they “make no formal privacy claims,” this is a major gap, as sharing the indices of the Top-$K$ most salient parameters could still reveal sensitive information about client data. For example, an attacker might infer aspects of a client’s data distribution if certain classes consistently activate specific parameters.\n\n**Minor Point:** In the appendix, Section E appears to be empty. It seems that the following section (Section F) was intended to be a subsection of it."}, "questions": {"value": "**1.** Theorem 1 assumes independent, mean-zero sub-Gaussian coordinates. How realistic is this assumption for gradient-based importance measures in deep networks? Can these measures not often be heavy-tailed and correlated across layers? More broadly, could the stability theorem be extended to cases with sub-exponential or heavy-tailed noise, which are frequently observed in deep learning settings?\n\n**2.** Could the authors provide at least a preliminary analysis or discussion of potential information leakage risks (e.g., linkage or reconstruction attacks) that might arise from sharing Top-$K$ indices, and how such risks could be mitigated?\n\n**3.** In line 697 of the proof of Proposition 1, could the authors clarify the use of $s_{ij} $? Should this term be replaced by $ |I_i \\cap I_j| $ so that dividing by $K$ yields $R_{ij} $, consistent with the final statement of the proposition?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JJvuiDwPQU", "forum": "wjH5SlB9ro", "replyto": "wjH5SlB9ro", "signatures": ["ICLR.cc/2026/Conference/Submission19224/Reviewer_okFg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19224/Reviewer_okFg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19224/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761345144708, "cdate": 1761345144708, "tmdate": 1762931208734, "mdate": 1762931208734, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a novel model similarity metric, Index-Overlap Similarity (IOS), for Federated Learning (FL). It assumes a standard FL setup where clients begin with a global model and train it on their local data. The work is motivated by the communication overhead, privacy risks, and numeric instability associated with traditional \"value-based\" similarity metrics.\n\nThe proposed method requires clients to locally determine the importance of their model's parameters (using a diagonal Fisher proxy) and then transmit only the indices of the Top-K most important parameters. The similarity between any two clients is then calculated as the normalized overlap of these two index sets.\n\nTo validate this approach, the paper provides theoretical justifications for the metric's stability and its connection to cosine similarity. It also presents an empirical evaluation across four distinct FL applications (e.g., Clustered FL, Neighbor Selection), comparing IOS against Cosine and Euclidean distance as baselines."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "+ The paper addresses a well-defined and critical problem in FL. Finding a communication-efficient, robust, and privacy-preserving proxy for client-relatedness is a significant challenge.\n\n+ The core idea of using the support (the set of salient indices) rather than the parameter values is intuitive and an elegant way to abstract model-level relatedness.\n\n+ Taken at face value, the empirical results are strong. The IOS method consistently outperforms the Cosine and Euclidean baselines across all four applications, often by a noticeable margin.\n\n+ The choice of four different experimental applications (CPFL, Neighbor Selection, Donor Ranking, and Distribution Alignment) is commendable and provides a comprehensive view of the method's potential utility."}, "weaknesses": {"value": "- The paper dedicates its introduction to explaining why Cosine and Euclidean distance are flawed, unstable, and \"debilitating\" metrics, yet these are the only baselines it compares against. A convincing evaluation must include comparisons against modern, robust model similarity metrics. The paper explicitly cites methods such as CKA (Central Kernel Alignment) and FedProto, but makes no effort to compare against them or justify their exclusion. This use of \"strawman\" baselines makes it impossible to assess the true contribution of IOS.\n\n- A primary motivation for IOS is its \"value-free\" nature, which the paper claims \"advancing scalable personalization in decentralized learning\" with a \"strong privacy posture\". However, this claim is not supported by any formal privacy proof (e.g., differential privacy) or empirical leakage analysis. It is not self-evident that leaking the Top-K indices of the most important parameters is inherently more private than, for example, sharing the penultimate layer activations for a CKA calculation. The privacy benefits are asserted, not proven.\n\n- The paper is also motivated by efficiency and low overhead. However, it fails to provide a proper analysis of the new costs it introduces. The method requires new, non-trivial client-side computation: estimating the diagonal Fisher proxy and performing a global Top-K selection over all model parameters. The paper provides no analysis (neither theoretical nor empirical) of this computational trade-off, making its efficiency claims one-sided.\n\n- The efficiency and communication arguments are motivated by the challenge of \"multi-billion-parameter checkpoints\". However, the experiments are conducted on much smaller models, with ResNet-50 and BERT-base being the largest. The feasibility of performing a global Top-K selection on a vector with billions of entries on a client device is not discussed, creating a significant gap between the paper's motivation and its evidence.\n\n- The paper feels very unpolished and is riddled with minor errors. For example, in Table 4, IOS is italicized for FMNIST, but bold-faced for other datasets. There are multiple cases in Table 3 where the results for the proposed methodology are in bold font instead of better results attained by the baselines. Table formatting is inconsistent."}, "questions": {"value": "Why did the evaluation exclude comparisons against contemporary and potentially more robust model-relatedness metrics, such as CKA or FedProto, both of which the paper cites? \n\nGiven the assertion of a strong privacy posture, could the paper provide an empirical analysis quantifying the information leakage (e.g., via model inversion or membership inference attacks) from the shared Top-K index sets compared to the leakage from the baseline real-valued vectors? \n\nPlease clarify the explicit criterion for determining the best result (i.e., the bolded number) across all tables, as inconsistencies exist (e.g., in Table 3). Furthermore, were the observed empirical gains over the baselines subjected to tests for statistical significance? If so, please provide the relevant statistical evidence (e.g., confidence intervals or $p$-values) to confirm."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "38VMAjD78F", "forum": "wjH5SlB9ro", "replyto": "wjH5SlB9ro", "signatures": ["ICLR.cc/2026/Conference/Submission19224/Reviewer_xNXp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19224/Reviewer_xNXp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19224/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761918187130, "cdate": 1761918187130, "tmdate": 1762931208148, "mdate": 1762931208148, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Revision and generic comment"}, "comment": {"value": "We thank all reviewers for their careful reading and constructive feedback. We are encouraged that all three reviewers appreciated the core idea of IOS, the theoretical development, the novelty of the framework, and the breadth of applications, and that the main concerns focus on missing analyses and clarifications rather than flaws in the approach itself.\n\nAcross the reviews, the key issues cluster into three aspects:\n(1) privacy, Robustness against attacks, and potential leakage from Top-$K$ indices;\n(2) computational and communication overhead, and the ablation study on the overhead of different modules of IOS;\n(3) positioning and completeness of the evaluation, including stronger baselines, CPFL aggregation details, and reproducibility.\n\nIn response, we have:\n\n  i) Privacy and threat model: clarified the honest-but-curious threat model(Sec. 2.2), and added an **empirical membership-inference study** comparing gradient leakage to IOS index leakage while describing why a **reconstruction attack can not apply to IOS** (Sec. 6.3).\n\n  ii) Overhead analysis: provided analytic **cost expressions in terms of communication and computation time** (Sec. 4.4 and Appx. D.4), and also new wall-clock measurements of client-side training, important calculation, EMA update, and Top-$K$ overhead, quantified communication savings (Appx. E.1)\n  \niii) Positioning, baselines, and clarity: clarified how IOS differs from representation-level metrics (CKA, FedProto, etc.), added a stronger similarity baseline where applicable, detailed the CPFL aggregation pipeline (Sec. 3.3), adding theoretical remarks for going beyond sub-Gaussian noise (Appx. C.4), and supplied an anonymized code link for reproducibility.\n\nWe have not changed the core technical content or main claims of the original submission, except for minor edits explicitly requested by the reviewers; instead, we have added new analyses and clarifications, which are highlighted in red in both the main text and appendix. Since IOS provides a general framework for model similarity that can be applied across many machine-learning settings, we kindly ask you to consider these additions when reassessing the paper, and we would be grateful for any further changes you deem necessary. In addition, we provide separate comments for each reviewer, addressing their stated weaknesses and questions individually."}}, "id": "CtccodI0eE", "forum": "wjH5SlB9ro", "replyto": "wjH5SlB9ro", "signatures": ["ICLR.cc/2026/Conference/Submission19224/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19224/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19224/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763632985941, "cdate": 1763632985941, "tmdate": 1763635246245, "mdate": 1763635246245, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a novel, value-free metric called Index-Overlap Similarity (IOS) to quantify the similarity between client models in a Federated Learning environment. The core idea is to move away from transmitting high-dimensional, real-valued weights or gradients. Instead, each client's model is represented by an index set (I_i) (or \"support set\") of its Top-K most significant parameters. The similarity is then computed solely based on the normalized overlap of these index sets. This approach claims to significantly reduce communication bandwidth and narrow the privacy attack surface created by the leakage of real-valued parameters."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Experiments are thorough, covering both vision and text domains (FMNIST, CIFAR-10/100, 20News) and different application scenarios.\n2. The work is not purely empirical, offering critical theoretical insights, particularly Proposition 1 (Lower Bound for Cosine Similarity) and Theorem 1 (Stability of Top-K Selection). This greatly enhances the credibility and explainability of the method.\n3. The paper addresses the similarity calculation overhead for a large number of clients by mentioning the use of MinHash-LSH, demonstrating attention to system-level scalability."}, "weaknesses": {"value": "1. Privacy is a core motiviation, but the Top-K index set I_i itself encodes sensitive information about data distribution and model structure. The paper lacks in-depth analysis and quantification of the risk associated with index leakage, which is a major weakness.\n2. Certain parameters need clearer definitions, for example, M (total number of model parameters) and the meaning of C(K) (proportion of total importance represented by the Top-K parameters).\n3. IOS performance is highly dependent on the optimal support set size K^* chosen by Algorithm 1. Even small increases in K (e.g., 15% or 25%) lead to a significant drop in downstream task performance. This raises concerns about the robustness of the automatic K selection mechanism\n4. The paper fails to clearly explain the method for model parameter upload and aggregation in the CPFL context, only providing a client similarity metric."}, "questions": {"value": "1. Given that privacy is a core motivation, could you more deeply discuss the specific attack vectors that could arise from only leaking the index set I_i? For instance, what inferences could an adversary make about the model structure or the underlying data distribution based on the indices of the most significant parameters? A quantified analysis of this index-leakage risk is requested.\n2. The main benefits of IOS are on the server side and in communication. Please quantify the absolute time overhead introduced by IOS on the client side. Specifically, compared to the total time for one local SGD and backpropagation, what is the proportional increase in wall-clock time spent on computing the Fisher diagonal proxy and Top-K selection? Preferably with specific ablation experiments.\n3. The paper mentions using a mechanism similar to IFCA (or similar approaches) to train the clustered models. Could the authors explicitly explain how the parameter fusion/aggregation is actually performed? Does the system still involve directly sharing the numerical values of the model parameters for the aggregation step, or is the information transfer still restricted to the \"value-free\" indices even during the final model update?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9jXz38zKU6", "forum": "wjH5SlB9ro", "replyto": "wjH5SlB9ro", "signatures": ["ICLR.cc/2026/Conference/Submission19224/Reviewer_gaMV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19224/Reviewer_gaMV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19224/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761941916113, "cdate": 1761941916113, "tmdate": 1762931207767, "mdate": 1762931207767, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}