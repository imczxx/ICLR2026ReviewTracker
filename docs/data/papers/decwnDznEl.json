{"id": "decwnDznEl", "number": 23292, "cdate": 1758341797952, "mdate": 1759896822468, "content": {"title": "OPERATOR LEARNING USING WEAK SUPERVISION FROM WALK-ON-SPHERES", "abstract": "Training neural PDE solvers is often bottlenecked by expensive data generation\nor unstable physics-informed neural network (PINN) that involves challenging\noptimization landscapes due to higher-order derivatives. To tackle this issue, we\npropose an alternative approach using weak supervision from stochastic processes\nto produce training data of varying quality. Specific to Poisson PDEs, an efficient\nMonte-Carlo algorithm called Walk-on-Spheres (WoS) is capable of generating\nsolutions using efficient random walks. We introduce a learning scheme called\nWalk-on-Spheres Neural Operator (WoS-NO) using weak supervision from WoS to\ntrain any given neural operator. The central principle of our method is to amortize\nthe cost of Monte Carlo walks across the distribution of PDE instances. Our\nmethod leverages stochastic representations using the WoS algorithm to generate\ncheap, noisy, yet unbiased estimates of the PDE solution during training. This is\nformulated into a data-free physics-informed objective where a neural operator\nis trained to regress against these weak supervisions. Leveraging the unbiased\nnature of these estimates, the operator learns a generalized solution map for an\nentire family of PDEs. This strategy results in a mesh-free framework that operates\nwithout expensive pre-computed datasets, avoids the need for computing higher-\norder derivatives for loss functions that are memory-intensive and unstable, and\ndemonstrates zero-shot generalization to novel PDE parameters and domains.\nExperiments show that for the same number of training steps, our method exhibits\nupto 8.75× improvement in L2-error compared to standard physics-informed\ntraining schemes, upto 6.31× improvement in training-speed, and reductions of up\nto 2.97× in GPU memory consumption.", "tldr": "", "keywords": ["Neural operator", "walk on spheres", "poisson solver", "weak supervision", "monte-carlo method"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/728f6f63bdfad1c0388315c20cda40cc96e85ce6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper present an interesting training methodology for neural operators. They make use of the walk-on-sphere Monte Carlo algorithm to generate noisy, unbiased, estimated of Poisson problems and regress a NO to it's mean. They focus on the standard linear Poisson problem and a modified version of a Poisson with variable coefficients. The method is architecture agnostic."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well written, and in the majority, easy to follow.\n- The paper presents a creative use of the WoS algorithm which seems to work well with learning surrogate models.\n- The paper explores a few interesting applications. In particular, the inpainting example is creative.\n- The experiments are well conducted and report relevant metrics, if however limited in terms of benchmarks against standard numerical solvers."}, "weaknesses": {"value": "- The paper claims to apply their methodology to a **nonlinear** Poisson PDE. The equation presented is linear in the solution with variable coefficients. This is a significant limitation.\n\n- Overall the Poisson PDE is of some practical use, however it is generally used a 'fruit-fly' type problem for PDEs, particularly in the context of neural operators as direct solvers are already very efficient for such problems. Neural operator mainly find their use in nonlinear problems. The method being specific to linear Poisson-type PDEs greatly limits its practical use. \n\n- WoS is not the standard method for solving Poisson PDEs. The authors do not use classical solvers such a conjugate-gradients to benchmark their method.\n\n- This is a minor point, but the mathematics in some places is overly terse. I would suggest added a few sentences to help readers less familiar with stopping time MC estimates of harmonic functions and WoS."}, "questions": {"value": "- The first 4 short paragraphs in section 3 are extremely terse. Can these be expanded (or justified why this is necessary) to help the reader understand why you are taking care in being specific. For example, what is the purpose of invoking $D$, $\\mathcal{T}$, $S_T$, etc to then only use $\\Omega$? Could we have equivalently assumed $\\Omega$ to be open and Lipschitz?\n\n- In figure 4, I cannot see the runtime for WoS-NO."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MypKMZYDO4", "forum": "decwnDznEl", "replyto": "decwnDznEl", "signatures": ["ICLR.cc/2026/Conference/Submission23292/Reviewer_f4PC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23292/Reviewer_f4PC"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23292/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761232184920, "cdate": 1761232184920, "tmdate": 1762942592918, "mdate": 1762942592918, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an innovative neural operator training framework called WoS-NO, which utilizes weak supervision signals generated by the Walk-on-Spheres (WoS) stochastic process to train neural operators. This approach avoids the expensive pre-computed data generation and unstable Physics-Informed Neural Network (PINN) optimization traditionally associated with solving Partial Differential Equations (PDEs). The core idea is to use unbiased estimates from a minimal number of WoS trajectories as training targets, enabling the neural operator to learn to \"denoise\" and converge to the true solution, thereby achieving data-free and derivative-free operator learning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. **Well-Defined and Significant Problem:** The paper accurately identifies a critical bottleneck in current PDE solving: the high cost of pre-computed data and the instability of PINN optimization. Addressing this issue is crucial for advancing practical applications in scientific computing.\n2. **Novelty of the Weakly-Supervised Training Strategy:** The proposed idea of using the WoS stochastic process for weak supervision is pioneering in this field. It cleverly combines the unbiased nature of Monte Carlo methods with the representational power of neural networks, offering a fresh perspective on solving PDEs."}, "weaknesses": {"value": "1. **Limited Scope of Problem Types:** The method is primarily applied to the family of Poisson equations. Its applicability to a broader range of PDE types (e.g., Navier-Stokes equations, wave equations) remains unverified. The paper should discuss the potential and challenges of extending this framework to other important PDE classes.\n2. **Lack of Systematic Study on WoS Parameter Selection:** The choice of the number of WoS trajectories (L ≤ 10) appears empirical. There is a lack of systematic analysis on how different L values affect training efficacy and final performance. An ablation study on the hyperparameter L is recommended.\n3. **Insufficient Integration with Modern Variance Reduction Techniques:** While WoS estimates are unbiased, they inherently possess high variance. The paper would benefit from exploring the integration with other advanced variance reduction techniques (e.g., importance sampling, stratified sampling) to control this variance and improve stability.\n4. **Insufficient Validation on Large-Scale Problem Scalability:** Experiments are conducted primarily on medium-scale problems. The scalability of the method to very high-dimensional or large-scale industrial-level problems requires further demonstration."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "vCTYovhY5R", "forum": "decwnDznEl", "replyto": "decwnDznEl", "signatures": ["ICLR.cc/2026/Conference/Submission23292/Reviewer_t1DZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23292/Reviewer_t1DZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23292/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761659681543, "cdate": 1761659681543, "tmdate": 1762942592731, "mdate": 1762942592731, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The proposed paper studies solving Poisson PDE using stochastic Walk-on-sphere methods. In a first time, the method is introduced and the Walk-On-Sphere algorithm explained. Finally, the method is evaluated against a selection of baslines on several tasks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The experimental results showcase an improvement wrt to baseline. \n- The proposed method is both GPU-memory and time efficient and performs best on the studied problems."}, "weaknesses": {"value": "-\tMy main concerns is about the scope of applicability : in my understanding the proposed method applies only to a limited familly of PDE : Poisson PDE. \n-\tIt is not detailed why focusing that much on such PDEs is important. \n-\tThe paper is hard to read, I think some re-writing would help the understanding of the paper (eg in section 2.2 which give a lot of references which makes the paragraph hard to follow).  I felt hard to understand the key objectives of the paper.\n-\tSome experimental details/settings are missing, making the paper hard to position and understand.\n-\tNo reference to some figures in the text (eg figure 2)"}, "questions": {"value": "### Questions :\n-\tCould you illustrate/detail about the O(1) stated in the introduction line 107. Is it illustrated in the experiments ? \n-\tIs the method limited to Poisosn PDEs ? What application could it be used for ? Why focusing that much on such PDEs? Is the method applicable on other PDEs? I saw an experiment on a Laplace PDE, but is it applicable to other PDE/datasets, that are commonly used in the PDE community?\n-\tCould you detail the PDEs setting ? What are considered in « new PDE instances » ? OOD or In-distribution evaluations ? \n-\tIt is hard to make a link with the proposed figures, particularly figures 1 and 2. \n-\tIn figure 3, why are the curves stopping before 200 mins ? I guess this is because the training time is lower, but I can’t find any justification on that point\n-\tCould you detail what are PINO losses ? A combination of a MSE loss with a residual pinns loss ? \n-\tFigure 4, right, what is your run time for comparison?\n-\tFigure 5 : how do we know/compare the proposed visualization with ground truth ? \n-\tWhy providing wandb screenshots (I guess) of the GPU utilization? These figures are hard to read, I think such figure could be summarized in a table. \n\n### Minor comments :\n-\tI think bolding the best metrics in tables helps reading the experimental parts."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0LxgXb18og", "forum": "decwnDznEl", "replyto": "decwnDznEl", "signatures": ["ICLR.cc/2026/Conference/Submission23292/Reviewer_2Nx6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23292/Reviewer_2Nx6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23292/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761760088784, "cdate": 1761760088784, "tmdate": 1762942592551, "mdate": 1762942592551, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a weakly supervised learning framework for solving Poisson equations, where training labels are generated using the Walk-on-Spheres (WoS) algorithm. Unlike prior works that integrate WoS directly into neural architectures to simulate stochastic trajectories, this approach leverages WoS purely as a label generator, producing inexpensive yet noisy approximate solutions for a large number of Poisson PDE instances. A neural operator is then trained to regress toward these approximate solutions, effectively learning to denoise and generalize beyond. Once trained, the resulting operator demonstrates strong generalization ability to new Poisson problems with unseen boundary conditions and source terms, without requiring any additional fine-tuning."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper demonstrates that inexpensive unbiased estimates of the solution can be effective for physics-informed neural operator learning. This aligns with the broader trend of scaling training data using pseudo-labels across wider problem domains.\n- Some efforts have also been made to extend the framework to nonlinear PDEs.\n- As the approach relies on pseudo-labeling, the proposed framework remains orthogonal to the choice of neural network architecture."}, "weaknesses": {"value": "- Another related approach is PI-DeepONet (Wang et al., 2021), which adopts a PINN-style residual loss. It would be interesting to clarify how WoS-NO compares to this method, especially since PI-DeepONet is less constrained regarding the types of PDEs it can handle.\n- Given the inherent specificity of the Walk-on-Spheres algorithm, WoS-NO appears applicable only to a limited class of PDEs. It would be valuable to discuss the potential for extending this framework to broader PDE families.\n\nReferences:\n- Wang et al. (2021), Learning the solution operator of parametric partial differential equations with physics-informed DeepONets"}, "questions": {"value": "- An analysis under varying numbers of training PDE instances would also be valuable for assessing data efficiency and scalability. In particular, it would be informative to examine how performance evolves as the number of sampled PDE instances increases—does accuracy continue to improve, or does it eventually saturate?\n- It would be beneficial to include a baseline trained with high-fidelity PDE solutions to provide an orthogonal comparison with the current weakly supervised setting. Such an ablation would help clarify how the training regime—noisy versus accurate labels—affects both convergence behavior and generalization performance. For instance, to reach a comparable generalization error, how much accurate data versus noisy data is required?\n- The paper could be further strengthened by emphasizing the unique advantages of the WoS algorithm, such as its natural scalability to high-dimensional Poisson problems and its potential to alleviate the restrictions on PDE forms typically faced by grid-based or deterministic solvers."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "p8R4gz442S", "forum": "decwnDznEl", "replyto": "decwnDznEl", "signatures": ["ICLR.cc/2026/Conference/Submission23292/Reviewer_ysKH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23292/Reviewer_ysKH"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23292/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761870362103, "cdate": 1761870362103, "tmdate": 1762942592357, "mdate": 1762942592357, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}