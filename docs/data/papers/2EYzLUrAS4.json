{"id": "2EYzLUrAS4", "number": 21736, "cdate": 1758321128372, "mdate": 1759896905984, "content": {"title": "Fixing Incomplete Value Function Decomposition for Multi-Agent Reinforcement Learning", "abstract": "Value function decomposition methods for cooperative multi-agent reinforcement learning compose joint values from individual per-agent utilities, and train them using a joint objective. To ensure that the action selection process between individual utilities and joint values remains consistent, it is imperative for the composition to satisfy the individual-global max (IGM) property. Although satisfying IGM itself is straightforward, most existing methods (e.g., VDN, QMIX) have limited representation capabilities and are unable to represent the full class of\nIGM values, and the one exception that has no such limitation (QPLEX) is unnecessarily complex. In this work, we present a simple formulation of the full class of IGM values that naturally leads to the derivation of QFIX, a novel family of value function decomposition models that expand the representation capabilities of prior models via a thin \"fixing\" layer. We derive multiple variants of QFIX, and imple-\nment three variants in two well-known multi-agent frameworks. We perform an empirical evaluation on multiple SMACv2 and Overcooked environments, which confirms that QFIX (i) succeeds in enhancing the performance of prior methods, (ii) learns more stably and performs better than its main competitor QPLEX, and (iii) achieves this while employing the simplest and smallest mixing models.", "tldr": "We provide a simple formulation for IGM-complete value function decomposition, and develop a novel family of value function decomposition models based on it.", "keywords": ["multi-agent", "reinforcement-learning", "value-function-decomposition", "cooperative", "dec-pomdps"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c7f72c296314dc3121a7e022403bb99c2cbb5eeb.pdf", "supplementary_material": "/attachment/e9e554861795c0d5d07196ed655015f6dfba8b91.zip"}, "replies": [{"content": {"summary": {"value": "This paper investigates the problem of complementing value-decomposition methods which are not capable of achieving the complete class of IGM value-functions. To do so, it first proposes a simplified version of QPLEX IGM criteria, which are then in turn adapted into a fixing mechanism for other existing value-decomposition methods. Furthermore, a more practical version of the method is derived, which holds the same theoretical guarantees. Experimental results show how the fixed versions of various value-decomposition methods achieve better performances and stability than their original counterparts."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Given the extreme popularity of value-decomposition methods, and their known limitations, the proposed methodology that aims at fixing them in a clear and simple way is a good contribution to the field. The discussion of why QPLEX, although in principle capable of representing the complete IGM class, is defined redundantly or sometimes ill-posed is very clear and interesting, and it serves as a basis for the simpler formulation that is then used in proposing QFIX. I also liked the results on the state-based variant, which gives consideration to an aspect that is often overlooked in CTDE. Experimental results on the proposed problems are very good, and show how the fix can help in improving learning performances."}, "weaknesses": {"value": "The main weakness of the paper is in its empirical evaluation. Although, as I listed in the strengths, the proposed results are good indeed, what it is missing here in my opinion is some rigour. Only the Q+FIX variant is evaluated, but no results for the original QFIX formulation is provided. This makes it difficult to assess how much better Q+FIX is in practice, and if the two are also equivalent in terms of practical performances. Also, the investigated problems are not known for being un-learnable with existing value-decomposition methods, but only to be difficult. For example, some simpler problem, but with an accent on the actual representation limitations of these, would have been much more interesting to prove the impact of your proposed fixing beyond a \"simple\" improvement in performances."}, "questions": {"value": "- Why do you say the WQMIX is specifically developed for fully observable settings? The original paper uses Dec-POMDP as its working setting, and all the practical formulations and empirical results are all proposed on the partially observable setting.\n\n- The beginning of Section 4.1 is not very explicative: while I can follow your reasoning here, having a more detailed explanation of both why three of the four constraints are satisfied by definition and why and how there is a misspecified case would help a lot in clearly understanding the problems you are highlighting with QPLEX.\n\n- Perhaps explain what you mean with *measurable* IGM values would help in better understanding the properties of your proposed QFIX.\n\n- Figure 1 is a bit difficult to read, as the text and details are fairly small. Given that the two figures are basically identical except for how $w(\\mathbf{h},\\mathbf{a})$ is computed, perhaps simply merge the two into a single figure which highlight such difference?\n\n- Why not evaluating QFIX as well? It would have been interesting to assess the learning performance gap between this and its more learning-amenable variant Q+FIX, while this way we have basically no clue but your own words to believe that Q+FIX is more suitable for learning than the base QFIX formulation.\n\n- It would have been interesting to show results on a setting where existing value-decomposition methods like VDN and QMIX are known to fail, like the popular climb matrix game. If their fixed counterparts were capable of achieving the optimal policy there, then this would have been a clear indication that the fixing process is indeed extending their representation capabilities. The current experiments are too large and complex to be able to say anything too precise on its effect per-se, other than the fixes are helping in learning faster and better generally.\n\n- Your statement that your proposed QFIX requires smaller mixing models is not really true: while Q+FIX-lin is indeed smaller than QPLEX, getting rid of all the non-required components that you highlighted in your analysis, Q+FIX-mono is using more parameters than QMIX alone, and Q+FIX-sum is using some where standard VDN do not. I suggest you reformulate such a statement to be closer to what the situation actually is."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "J5tKuQGGEe", "forum": "2EYzLUrAS4", "replyto": "2EYzLUrAS4", "signatures": ["ICLR.cc/2026/Conference/Submission21736/Reviewer_W1FR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21736/Reviewer_W1FR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21736/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761056803326, "cdate": 1761056803326, "tmdate": 1762941911745, "mdate": 1762941911745, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the representational limitations of common value-decomposition methods in cooperative MARL (e.g., VDN, QMIX) under the individual-global-max (IGM) principle. The authors argue that while methods like QPLEX are provably IGM-complete, they are overly complex. They propose a principled and simpler formulation of IGM-complete value decomposition and introduce QFIX, a family of methods that “fix” incomplete decompositions by adding a thin correction layer. An additive variant (Q+FIX) is shown to significantly improve stability and performance. Experiments on benchmarks, such as SMACv2, demonstrate that Q+FIX improves over VDN/QMIX and matches or exceeds QPLEX while being simpler and smaller."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper provides a clean, minimal characterization of the IGM-complete function class and highlights a core mechanism (weighted transformation of advantages) without complex transformation stacks.\n2. QFIX uses a “fixing” layer over existing factorizations, requiring small architectural changes.\n3. Benchmarks across SMACv2 (9 scenarios, multiple races/sizes) and Overcooked; includes stability and model-size comparisons. The proposed method exhibits better convergence stability than QPLEX and uses fewer parameters."}, "weaknesses": {"value": "1. Comparisons only within value-decomposition class (no MAPPO, MADDPG variants).\n2. Some practical tricks (advantage detach, annealing) feel heuristic, and they seem to lack a limited theoretical justification.\n3. Limited analysis of when fixing hurts performance."}, "questions": {"value": "1. How sensitive is QFIX/Q+FIX to hyperparameters relative to QMIX/QPLEX?\n2. Could fixing networks destabilize learning in extremely large action spaces?\n3. The baseline algorithms selected are necessary but old. How is the performance when compared against newer algorithms, such as ResQ, or other types of methods like MAPPO?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "eXgIpcEQ0z", "forum": "2EYzLUrAS4", "replyto": "2EYzLUrAS4", "signatures": ["ICLR.cc/2026/Conference/Submission21736/Reviewer_SVj3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21736/Reviewer_SVj3"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21736/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761877176225, "cdate": 1761877176225, "tmdate": 1762941911365, "mdate": 1762941911365, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes QFIX, a new method to address representational constraints imposed by some methods that adhere to the IGM condition, such as VDN and QMIX. This method uses a fixing layer to ensure that it can represent the full classes of functions that satisfy the IGM condition. This layer can be applied ot other existing methods and extend their representational capabilities."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper is well written and easy to read. The experiments provided are quite extensive and the method has strong theoretical groundings. The authors also aim to address specific limtiations of other previous methods, which is good.\n\nHowever, there are some points that are a bit less clear. Please find below."}, "weaknesses": {"value": "Overall, I am unsure about the strength of the motivations for the proposed method; the proposed method is based on a structure that contains all functions that satisfy IGM, but other methods such as QTRAN can theoretically factorise any function which means that all functions that satisfy IGM are theoretically also included in that set of functions. QPLEX also has a strong representational complexity and the argument that it is \"unnecessarily complex\" does not sound convincing enough as a motivation without some further empirical support, for instance. In addition, the authors build the argument around other methods not being able to represent all functions that satisfy IGM which is valid. However, methods such as QTRAN have theoretically proved to be able to factorise any family of functions, which implies that they are able to factorise all functions that satisfy IGM.\n\nThe authors claim that the necessity some the architectural choices of QPLEX such as some transformations is questionable; while that seems valid from a theoretical perspective in terms of being IGM-complete, it is not clear whether removing these transformations will also decrease their performance, meaning that they might indeed be necessary in practice.\n\nThe performance of the proposed method is very close to the baselines in almost every SMAC scenario, which makes me question the necessity for such approach in terms of practical performance.\n\nI could not find some of the proofs in the paper, for example for propositions 1 and 2; if they are taken from other works these should be mentioned accordingly.\n\nMinor:\n- the meaning of some terms in equations could be better defined; for example, $Q_-$ in eq 1 and \"hao\"\n\n[1] QTRAN https://arxiv.org/abs/1905.05408\n\n[2] QPLEX https://arxiv.org/abs/2008.01062\n\n[3] DuelMIX: https://arxiv.org/pdf/2408.15381"}, "questions": {"value": "1. why is it more advantageous to be IGM-complete (containing only all the functions that satisfy IGM, as per Def 2) instead of being able to factorise any function, such as in the case of QTRAN?\n2. how do the authors ensure that (i) is satisfied? i.e., avoid assumptions like full observability or centralised control (lines 49-51) \n3. since this work builds upon some of the insights from DuelMIX [3], it would be useful to see how the proposed method compares to DuelMIX, both theoretically and in practice\n4. in figure 1 and in the equations (for example eq 10) the authors use the notation $V(h)$ similarly to QPLEX notation of $V(\\tau)$, i.e., the function is based on the history; however, in [3] it is argued that in QPLEX this theory is inconsistent with the practice where the authors use the state instead, which can cause inconsistencies and degradation in learning. Is that the case in this work as well?\n5. the authors propose 3 different variations of QFIX (sum, mono and lin) which in essence the differences seem to be in the mixer; would it be possible to generalise everything in a single method that could fix all the baseline methods mentioned at once? also how easy would it be to apply this method to other value function factorisation methods since apparently a distinct one is defined for each basline?\n6. it is unclear to me the intuition for proposing QFIX and then Q+FIX right after if only Q+FIX is used in the experiments as the proposed method; why not only introducting Q+FIX and building from the equations of QFIX but in the same section?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "toTUjJ9yCt", "forum": "2EYzLUrAS4", "replyto": "2EYzLUrAS4", "signatures": ["ICLR.cc/2026/Conference/Submission21736/Reviewer_JrsL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21736/Reviewer_JrsL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21736/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761908993589, "cdate": 1761908993589, "tmdate": 1762941911018, "mdate": 1762941911018, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a characterization of the IGM-consistent function class using advantage-level equivalences and uses it to derive QFIX, which wraps any IGM but a non-IGM-complete decomposer with a family of value function decomposition models based on it."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- I find the theoretical contribution sound and ample. The proposal of QIGM is compact and complete with proof constructive. I find most of the theoretical derivation correct.\n\n- The measurable-UAT framing is accurate and improves the rigorisness of IGM-complete in literature.\n\n- The fixing intervention that empirically stabilizes and improves performance verified in the experiments.\n\n- The experiment design is carefully designed with comprehensive benchmarks and representative baselines for theoretical improvement demonstation."}, "weaknesses": {"value": "- The measurable-UAT claim is correct but depends on appendix-level assumptions. A short brief mention would complete the main text during network family explanation and convergence.\n\n- Missing some of the SOTA baselines like MAPPO or more recent works, but given this experiment design is more on verifying the theoretical contribution I think this is acceptable to only compare with QMIX and QPLEX.\n\n- This paper could also benefit from simplifying the key assumption and findings and leave most of the theoretical proof to appendix.\n\n- Some very minor presentation issue like missing ref on line 1178"}, "questions": {"value": "In Overcooked, Q+FIX benefits from annealed intervention in addition to detach. I wonder why this simple design can help the stabilizers to all baselines in a controlled way.\n\nParameter-count comparisons focus on mixers; indicating agent parameters are the same? Also time-to-target metric would better disentangle capacity vs. architecture effects. Some size controls are present but could be expanded."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5rX8kJ9GaZ", "forum": "2EYzLUrAS4", "replyto": "2EYzLUrAS4", "signatures": ["ICLR.cc/2026/Conference/Submission21736/Reviewer_sZyZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21736/Reviewer_sZyZ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21736/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980553826, "cdate": 1761980553826, "tmdate": 1762941910663, "mdate": 1762941910663, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}