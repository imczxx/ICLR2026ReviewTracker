{"id": "HXSATlFtky", "number": 14921, "cdate": 1758245562908, "mdate": 1759897341219, "content": {"title": "The Other Side of the Coin: Unveiling the Downsides of Model Aggregation in Federated Learning from a Layer-peeled Perspective", "abstract": "In federated learning (FL), model aggregation plays a central role in enabling decentralized knowledge sharing.\nHowever, it is often observed that the aggregated model underperforms on local data until after several rounds of local training.\nThis temporary performance drop can potentially slow down the convergence of the FL model. Prior work regards this performance drop as an inherent cost of knowledge sharing among clients and does not give it special attention. While some studies directly focus on designing techniques to alleviate the issue, its root causes remain poorly understood. To bridge this gap, we construct a framework that enables layer-peeled analysis of how feature representations evolve during model aggregation in FL.  It focuses on two key aspects: (1) the intrinsic quality of extracted features, and (2) the alignment between features and their subsequent parameters---both of which are critical to downstream performance. Using this framework, we first investigate what model aggregation does to the internal feature extraction process. Our analysis reveals that aggregation degrades feature quality and weakens the coupling between intermediate features and subsequent layers, both of which are well shaped during local training. More importantly, this degradation is not confined to specific layers but progressively accumulates with network depth---a phenomenon we term Cumulative Feature Degradation (CFD).\nCFD severely impairs the quality of penultimate-layer features, ultimately compromising the model's decision-making capacity.\nNext, we examine how key FL settings---such as aggregation frequency---can exacerbate or alleviate the negative effects of model aggregation. Finally, we revisit several commonly used strategies, such as initialization from pretrained models, and explain \\textbf{why} they are effective through layer-peeled analysis. To the best of our knowledge, this is the first systematic study of model aggregation in FL from a layer-peeled feature extraction perspective, potentially paving the way for the development of more effective FL algorithms.\nThe code is available at:https://anonymous.4open.science/r/ICLR_14921_Code-3565.", "tldr": "Understanding model aggregation in federated learning using layer-peed feature extraction perspective.", "keywords": ["Federated Learning", "Representation Learning", "Model Aggregation"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5d389973775dd4cbf0d06b620dde73f72dbb7184.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates model aggregation in FL from a layer-wise feature perspective by proposing a layer-peeled analysis framework for a more interpretable lens to understand the internal dynamics of FL. The analysis reveals a key phenomenon termed Cumulative Feature Degradation (CFD), and the study further examines how different FL settings influence this degradation during model aggregation."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The topic is relevant and important. The construction of a layer-peeled feature analysis framework is helpful.\n- The findings of CFD help explain why the performance drop is so pronounced and why it is a fundamental challenge in aggregating deep models.\n- The analysis covers multiple datasets and model architectures to support the findings."}, "weaknesses": {"value": "- The current analysis is primarily empirical, relying on experimental metrics. The paper would be strengthened by incorporating theoretical analysis to support or generalize the empirical findings.\n- While the abstract and introduction highlight aggregation frequency as a key factor, the corresponding analysis is put into appendix. Including it in the main text along with a more detailed discussion would be better.\n- Although the paper successfully diagnoses a key issue (CFD), it does not propose concrete solutions or algorithmic adjustments inspired by the insights. The claim in the abstract that the work “potentially paves the way” for better FL algorithms would be more convincing if accompanied by specific, testable hypotheses or design principles.\n- The figures and captions in the supplementary section can be further elaborated."}, "questions": {"value": "Please see the weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Eprihyk7VZ", "forum": "HXSATlFtky", "replyto": "HXSATlFtky", "signatures": ["ICLR.cc/2026/Conference/Submission14921/Reviewer_4CgH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14921/Reviewer_4CgH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14921/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761728616434, "cdate": 1761728616434, "tmdate": 1762925265250, "mdate": 1762925265250, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a layer-peeled analysis framework to investigate performance degradation after model aggregation in federated learning (FL). The study shows that feature variance and feature-parameter alignment deteriorate as network depth increases, a phenomenon the paper refers to as cumulative feature degradation (CFD). The paper further demonstrates that model aggregation can improve feature generalization across clients. Finally, it analyzes how existing FL strategies mitigate the effects of CFD to achieve improved performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Overall, the paper is well-written, and the figures and explanations are clear and easy to follow. \n\n- The paper provides a systematic set of metrics for analyzing the dynamics of features and model parameters in FL settings."}, "weaknesses": {"value": "- The analysis mainly focuses on the proposed analytical metrics without presenting accompanying accuracy trends to support the findings. While the paper suggests that model aggregation may degrade performance, it does not clearly demonstrate how the performance drops would correlate with the reported feature and parameter metrics and their dynamics.\n\n- At Lines 273-279, the paper briefly introduces and defines CFD as the larger relative changes in the metrics as network depths increase. However, this definition is somewhat vague and lacks direct evidence that the degradation is indeed cumulative, since the observed relative changes may be influenced by various factors. For example, if performance is already low at earlier layers, the relative change may appear smaller simply because there is limited room for further degradation.\n\n- The paper introduces CFD and uses it to analyze feature and parameter dynamics in FL, as well as to interpret the behavior of existing FL approaches. However, it is not entirely clear what concrete insights CFD offers that would meaningfully guide the design of future FL methods or lead to further advances in the field."}, "questions": {"value": "Besides the weakness shown in the above section, please also see the following questions: \n\nQ1: In Figures 2 and 3, the relative changes in feature variance increase with network depth. However, the feature variances in the shallow layers are already not performing well (e.g., large within-class variance and small between-class variance for “L1” in Figures 2(a) and 2(c)). In this case, can we still conclude that feature degradation becomes more severe in deeper layers? The smaller relative change observed in shallow layers may simply be due to their initially poor performance, rather than indicating less degradation. \n\nQ2: In Figure 8, it seems that the personalization method FedBN still exhibits larger relative changes in the deeper layers than FedAvg. Does this imply that FedBN is less effective in mitigating CFD? Additionally, what is the accuracy comparison between FedAvg and FedBN?\n\nQ3: At Lines 14-16 in the abstract, the paper states that performance drops after aggregation can potentially slow down the convergence of FL. However, in Section 4.4, the results indicate that model aggregation improves generalization. Why would improved model generalization hinder convergence? Does this imply that without aggregation, the model would converge more quickly but to an overfitted local minimum? If so, would slower convergence in this case actually be preferable?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YQ4Ro15sYB", "forum": "HXSATlFtky", "replyto": "HXSATlFtky", "signatures": ["ICLR.cc/2026/Conference/Submission14921/Reviewer_jURL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14921/Reviewer_jURL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14921/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761897810567, "cdate": 1761897810567, "tmdate": 1762925264653, "mdate": 1762925264653, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates why model averaging in federated learning (FL) often causes a temporary drop in clients’ local performance after aggregation. The authors identify that existing work treats this post-aggregation degradation as an inherent cost without explaining its internal mechanisms. To address this, they propose a layer-peeled analysis framework that examines how aggregation alters feature representations and their alignment with subsequent layers, introducing the concept of Cumulative Feature Degradation (CFD), a depth-accumulating degradation of feature quality and feature-parameter alignment. Through empirical analysis, they show that aggregation increases within-class variance, decreases between-class variance, and disrupts alignment between penultimate features and classifiers, while also improving out-of-distribution generalization."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The figure illustrating the layer-wise performance trend is well-presented and effectively supports the analysis.\n\n2. The experimental setup is described with sufficient clarity and detail to ensure reproducibility."}, "weaknesses": {"value": "1. Limited novelty compared to prior layer-wise/feature-alignment analyses. Prior work already diagnoses aggregation-induced feature/layer misalignment and layer-dependent behavior, and studies when layer-wise averaging or alignment helps (e.g., Fed2 [1] aligns features across clients; pFedLA [2] learns layer-wise aggregation analysis in personalized FL setting; FedFA provides detailed analysis of latent feature statistics and provide a feature alignment method; Layer-wise Linear Mode Connectivity [4] shows layers often admit linear connectivity with thorough analysis of the layer-wise parameter dynamics in model aggregation). I don’t clearly see what new insight this paper adds beyond those feature alignment analyses. \n\n2. CFD seems like a correlate, not a fundamental driver. The experiments mainly establish correlations between CFD metrics and accuracy without causal interventions; the “cumulative” phrasing is also puzzling because aggregation is a weight-averaging step (no depth-wise propagation), and the depth trend likely reflects local training signals rather than averaging per se.\n\n3. Explanation is generic and widely known. The argument reduces to “within-class variance rises and between-class separation falls after averaging,” which mirrors established neural-collapse/feature-separation results [5, 6] in standard deep nets; please clarify what is federation-specific beyond these generic patterns or provide theory linking heterogeneity of federated learning setting.\n\n[1] Yu, Fuxun, et al. \"Fed2: Feature-aligned federated learning.\" Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data mining. 2021.  \n[2] Ma, Xiaosong, et al. \"Layer-wised model aggregation for personalized federated learning.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022. \n[3] Zhou, Tianfei, and Ender Konukoglu. \"FedFA: Federated Feature Augmentation.\" The Eleventh International Conference on Learning Representations.  \n[4] Adilova, Linara, et al. \"Layer-wise linear mode connectivity.\" The Twelfth International Conference on Learning Representations.  \n[5] Papyan, Vardan, X. Y. Han, and David L. Donoho. \"Prevalence of neural collapse during the terminal phase of deep learning training.\" Proceedings of the National Academy of Sciences 117.40 (2020): 24652-24663.  \n[6] Parker, Liam, et al. \"Neural collapse in the intermediate hidden layers of classification neural networks.\" arXiv preprint arXiv:2308.02760 (2023)."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NaNmZTI9KI", "forum": "HXSATlFtky", "replyto": "HXSATlFtky", "signatures": ["ICLR.cc/2026/Conference/Submission14921/Reviewer_cMUs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14921/Reviewer_cMUs"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14921/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926184726, "cdate": 1761926184726, "tmdate": 1762925263890, "mdate": 1762925263890, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the temporary performance drop seen in Federated Learning (FL) after models are aggregated, using a novel \"layer-peeled\" analysis framework to understand the root causes. The authors identify a phenomenon called Cumulative Feature Degradation (CFD), where aggregation progressively degrades feature quality and disrupts the alignment between features and parameters as network depth increases. This degradation, especially the mismatch between the final features and the classifier, is pinpointed as the main cause of the performance drop. Despite this downside, the study confirms that aggregation is vital for improving model generalization and preventing overfitting to local client data. The paper also uses this framework to explain why common FL solutions work, showing that methods like parameter personalization, pre-trained initialization, and classifier fine-tuning are effective because they successfully mitigate the CFD effect"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The authors rigorously demonstrate that the negative impact of aggregation is not a uniform hit but a compounding problem that progressively accumulates with network depth.\n\n2. The study offers a balanced perspective. It not only identifies the downsides of aggregation (CFD) but also validates its crucial upside, showing that aggregation is what enables the model to create more generalizable features and mitigate local overfitting.\n\n3. The paper introduces a \"layer-peeled\" analysis framework  that moves beyond standard accuracy or loss metrics."}, "weaknesses": {"value": "1. The experimental setup involves a very small number of clients (e.g., 4 clients for PACS, 6 for DomainNet). This is not representative of typical cross-device FL scenarios, which can involve hundreds, thousands, or even millions of clients. The dynamics of averaging four or six models may be very different from averaging thousands, and it remains an open question whether the severity and behavior of CFD would scale, diminish, or change entirely in a massively federated setting. \n\n2. The paper's conclusions about \"model aggregation\" are almost exclusively based on analyzing the FedAvg algorithm, which uses simple parameter-wise averaging. While FedAvg is a foundational baseline, the paper does not investigate whether the Cumulative Feature Degradation (CFD) phenomenon persists in more advanced FL algorithms designed specifically to combat aggregation problems (like FedProx, SCAFFOLD, or FedDyn). It's possible that CFD is a specific artifact of the naive FedAvg approach rather than an unavoidable downside of all model aggregation in FL\n\n3. All experiments are conducted on image classification datasets (Digit-Five, PACS, and DomainNet) using standard vision architectures (CNNs and ViT) . The findings, while significant for computer vision, cannot be assumed to generalize to other major applications of FL. It is unknown if CFD manifests similarly in fundamentally different tasks, such as Regression problem, classification on text datasets etc."}, "questions": {"value": "1. Can the author suggest that this analysis still holds for strong FL algorithms like SCAFFOLD, FedDyn, pFedMe, etc.?\n\n2. Does the authors have any theoretical justification to explain why the simple averaging of model parameters fundamentally leads to this progressive, layer-by-layer degradation in feature quality and alignment?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "J4Di6LKZBG", "forum": "HXSATlFtky", "replyto": "HXSATlFtky", "signatures": ["ICLR.cc/2026/Conference/Submission14921/Reviewer_FUHN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14921/Reviewer_FUHN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14921/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762304793140, "cdate": 1762304793140, "tmdate": 1762925263271, "mdate": 1762925263271, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}