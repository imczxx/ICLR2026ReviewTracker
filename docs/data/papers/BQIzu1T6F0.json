{"id": "BQIzu1T6F0", "number": 19936, "cdate": 1758300783649, "mdate": 1759897011511, "content": {"title": "A New Approach to Controlling Linear Dynamical Systems", "abstract": "We propose a new method for controlling linear dynamical systems under adversarial disturbances and cost functions. Our algorithm achieves a running time that scales polylogarithmically with the inverse of the stability margin, improving upon prior methods with polynomial dependence maintaining the same regret guarantees. The technique, which may be of independent interest, is based on a novel convex relaxation that approximates linear control policies using spectral filters constructed from the eigenvectors of a specific Hankel matrix.", "tldr": "We give a new algorithm for online control of LDS based on spectral filtering with exponential improvement in running time.", "keywords": ["Online Convex Optimization", "Online Control", "Linear Dynamical Systems"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7ef9dec710fd0a60f9101b4876c480d6d209aadb.pdf", "supplementary_material": "/attachment/54d868753126e21ee600e7d8dfe5c059e655b6e9.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a new algorithm for online control of linear dynamical systems (LDS) under adversarial disturbances and convex cost functions. The central idea is to use a spectral representation of control policies, transforming the non-convex control problem into a convex online learning problem using Hankel-based spectral filters. This allows efficient computation while preserving strong theoretical guarantees."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The spectral filters for marginally stable LDS can effectively compress the information of external disturbance. Thus, it allows efficient computation while preserving strong theoretical guarantees.\n\n2. The work sounds solid, although I didn't check the detail proofs."}, "weaknesses": {"value": "1. **The criticism on LQR is not accurate**\n\nFor modern industrial applications, the top three control algorithms are likely to be PID, LQR and MPC, despite that those theoretical assumptions are not satisfied. Moreover, the example of drone flying control system is not a good motivate example for the proposed approach. A simple reason is that those scenarios mentioned in this paper are currently handled by the above three algorithms in many commercial products.  \n\nAlso, the statement about the benefits of marginal stability is misleading: \"...yields smoother, more energy-efficient control, useful in settings like robotics, thermal systems, and satellite dynamics\". It can lead to small control effort if the open-loop system is unstable or marginally stable. If open-loop is very stable, then one needs extra control effort to reduce the stability margin. Due to its small robustness margin, marginally stability is often not desired in applications related to robotics and satellites. A common setup in those applications is a strong stable tracking controller together with a smooth reference generator. It can yield smooth control input while remaining strong robustness against disturbances.\n\n2. **Some highly related works  are missing**\n\nIn Section 1.2, the first two paragraph dates back to the beginning of control theory, which is not necessary. On the other side, it missed some more recent and highly related works called **system level synthesis (SLS)** [1,2] in the control literature. From my understanding, the proposed approach is a special case of SLS, which belongs to a more general framework called **Youla parameterization**. Compared to SLS, the proposed approach has two new features: 1) in SLS setup, the cost function is often known while this work considers the online convex optimization setup; 2) SLS is for general stability while this paper has a tailed algorithm for marginally stable LDS. \n\n3. **Does the proposed approach guarantee stability?**\n\nIn this work, it only assumes that the cost function is convex and Lipschitz. Let us consider a linear cost on $x$ and $u$ and there is not constraint $\\mathcal{K}$. Then, Algorithm 1 will drive the state to infinity.  Maybe it needs some additional assumptions, e.g., $c(x,u)$ is bounded from below.\n\n4. **Lack of experiments on adversarial cost and disturbance**\n\nThis paper claims those benefits in the theory but no experimental illustration is provided. It only investigates simple disturbances including Gaussian,  Rademacher noise and deterministic sinusoidal. And the cost is a fixed quadratic.\n\n[1] Anderson et al. System level synthesis. Annu. Rev. Control, 2019.\n\n[2] Wang et al. A system level approach to controller synthesis. IEEE-TAC, 2019."}, "questions": {"value": "1. Let us consider an extreme case where System (1.1) does not have any external disturbance (i.e. $w_t \\equiv 0$). Then, under this setup, Line 7 of Algo. 1 will produce $\\tilde{W}=0$. Moreover, whatever $M^t$ is optimized, there is no effective control input, i.e. $u_t=0$. Do those theoretic claims still hold?\n\n2. Follow the previous question. If $w_t$ is small, how will the proposed algorithm behave? Will the loss decreases slower? Or the decay rate does not change?\n\n3. The examples consider simple diagonal $A$ and dense $B$. How about the controllable canonical form where both $A$ and $B$ has certain sparse property? If there is one control input $u\\in \\mathbb{R}^{1}$ but many states $x\\in \\mathbb{R}^n$ with large $n$, then the effect on $x(n)$ is delayed by $n$ steps. Will it causing some large oscillations in this loss curve?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8RZFFq5e2z", "forum": "BQIzu1T6F0", "replyto": "BQIzu1T6F0", "signatures": ["ICLR.cc/2026/Conference/Submission19936/Reviewer_AjXG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19936/Reviewer_AjXG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19936/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761449336786, "cdate": 1761449336786, "tmdate": 1762932102049, "mdate": 1762932102049, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a new \\emph{spectral convex relaxation} for online (adversarial) control of linear dynamical systems. \nIt replaces explicit system-dependent features with a fixed, universal set of \\emph{Hankel eigenvector filters}, \nthereby transforming control into an online convex optimization problem. \nThe resulting algorithm achieves a regret bound of $\\widetilde{\\mathcal{O}}(\\gamma^{-4}\\sqrt{T})$, \nwhere $\\gamma$ denotes the \\emph{stability margin} of the comparator policies (i.e., the spectral radius bound of the closed-loop matrix). \nThis dependency in $\\gamma$ is better compared to existing approaches.\nThe method runs in polylogarithmic time per step and is supported by a detailed approximation analysis \nand experiments demonstrating a competitive runtime efficiency compared to existing baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is very well written and the overall presentation is clear and easy to follow. \nThe structure and flow of ideas make it straightforward to understand the motivation, \ntechnical setup, and implications of the proposed approach. \nBoth the algorithmic framework and the main theoretical result Theorem 2.1) are presented in a transparent way, \nwith all relevant quantities and assumptions clearly defined. \nIn particular, the paper explicitly spells out the concrete hyperparameter choices \n$m$, $h$, and $\\eta$ that lead to the stated regret bound, \nwhich greatly improves the reproducibility and interpretability of the theoretical results. \nA further strength is the improved dependence on the stability margin $\\gamma$ in the regret bound, \nwhich represents a significant advance over previous approaches whose computational or regret guarantees scale more unfavorably with $\\gamma$. \nFinally, the discussion of related work is comprehensive and well organized, \nsituating the contribution within the broader literature on online control and learning-based methods."}, "weaknesses": {"value": "**Weaknesses and Suggestions.**\n\n 1) *Reliance on known $(A,B)$ is unrealistic in many applications.*\n  The entire pipeline assumes exact knowledge of the system matrices to reconstruct disturbances and build spectral features.\n  This limits applicability to model-mismatch or unknown-dynamics settings.\n  Suggestion: Add a discussion (or short appendix) on robustness to misspecified $(A,B)$ and outline a data-driven variant where\n  $(\\widehat A,\\widehat B)$ are estimated online (or pre-estimated) with explicit stability conditions under identification error,\n  e.g., bounds of the form $\\|A-\\widehat A\\|,\\|B-\\widehat B\\|\\le\\varepsilon$ and their impact on regret constants.\n\n  2) *Placement of Theorem 2.1 (many forward references).*\n  As written, Theorem 2.1 appears before the technical setup of Section 3, causing heavy forward referencing and making the statement hard to parse on first reading.\n  Suggestion: Move Theorem 2.1 to immediately \\emph{after} Section 3, once the comparator class, spectral filters, and surrogate loss are fully defined.\n  This will make the result self-contained at its first occurrence.\n\n  3) *Reorder Section 3 before the main results.*\n  Closely related to the previous point: placing the entire Section~3 (setup, assumptions, and construction of the spectral controller)\n  before the main theorem would improve readability and reduce back-and-forth navigation.\n  Suggestion: New order: (i) problem setup and assumptions, (ii) spectral feature construction \\& surrogate loss (current Section 3),\n  (iii) then algorithm and main regret theorem.\n\n  4) *No empirical verification of the $\\sqrt{T}$ regret scaling in Theorem 2.1.*\n  The current experiments do not test the $\\sqrt{T}$ dependence, so they cannot confirm the rate empirically.\n  Suggestion (add a minimal experiment):\n\n   4a) Fix a stable LTI instance and cost sequence within the paper's assumptions (convex Lipschitz costs), and fix a stability margin $\\gamma$ (e.g., by choosing a comparator with spectral radius $1-\\gamma$).\n    \n4b) Run the proposed method for horizons $T\\in\\{2^{10},2^{11},\\dots,2^{18}\\}$, keeping all other hyperparameters at the prescribed values in Theorem 2.1 (the stated $m,h,\\eta$ schedule).\n   \n4c) For each $T$, compute regret with respect to the comparator class used in the theory (or as close as feasible), average over multiple seeds, and report the mean $\\pm$ std.\n   \n4d) Plot $\\log(\\text{regret})$ vs.\\ $\\log T$ and report the fitted slope (expectation: slope $\\approx\\frac{1}{2}$ within confidence bands).\n    \\item (Optional) Repeat for a few $\\gamma$ values to visualize the $\\gamma$-dependence of constants in the regret (even if asymptotically the slope stays $\\approx\\frac{1}{2}$)."}, "questions": {"value": "1) What can be said when $A,B$ are unknown (cf. weakness section above)? \n    Do the results extend to estimated $(\\widehat A,\\widehat B)$, and how do identification errors \n    $\\|A-\\widehat A\\|$, $\\|B-\\widehat B\\|$ affect the feature construction, stability, and regret guarantees?\n\n2) When referring to a ``convex cost,'' do you mean convex jointly in $(x,u)$ for each $t$? \n    Please clarify the precise convexity and Lipschitz assumptions, including in which variables and norms they hold.\n\n3) In the first displayed equation of Section 1.1, the policy class in the regret definition is missing. \n    Please specify explicitly over which set of policies or feedback gains the infimum is taken.\n\n4) In Algorithm 1, the loss function $\\ell_t$ is referenced but not defined at that point. \n    It only appears later in Equation (4.1), which interrupts the reading flow. \n    Please either define $\\ell_t$ where Algorithm~1 appears or add a forward reference in the algorithm caption.\n\n5) Definition 3.1: can the stated condition occur at any time $t$? \n    I assume yes, please make the time quantification explicit.\n\n6) Definition 3.4: please be precise that $K$ denotes a feedback gain that induces a linear policy; \n    $K$ itself is not a policy. Consider rephrasing accordingly to avoid ambiguity."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "X28BjlhN3Q", "forum": "BQIzu1T6F0", "replyto": "BQIzu1T6F0", "signatures": ["ICLR.cc/2026/Conference/Submission19936/Reviewer_tXpd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19936/Reviewer_tXpd"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19936/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761633759150, "cdate": 1761633759150, "tmdate": 1762932101271, "mdate": 1762932101271, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an online control algorithm for linear stochastic systems with adversarial disturbance. The proposed algorithm approximates a policy using spectral features derived from Hankel matrix eigenvectors, allowing efficient updates with regret comparable to existing approaches while significantly improving runtime. The author demonstrates that the proposed algorithm can match or surpass existing baselines empirically while using far fewer parameters."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The use of spectral filtering in online control appears to be a novel idea that could have a broader impact on the control domain.\n- The theoretical analysis is thorough and clearly demonstrates improvement over prior approaches."}, "weaknesses": {"value": "- The empirical evaluation remains relatively narrow in scope. Including results on higher-dimensional systems would strengthen the paper.\n- While the main advantage of the proposed algorithm lies in its runtime efficiency, this aspect is not evaluated in the experiments."}, "questions": {"value": "- Could the authors provide more intuition behind the motivation for using spectral filters? What advantages do spectral features offer compared to other feature representations in online control?\n- Could the authors comment on the actual runtime improvement over baseline methods in the experiments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "nPuKXwe5D9", "forum": "BQIzu1T6F0", "replyto": "BQIzu1T6F0", "signatures": ["ICLR.cc/2026/Conference/Submission19936/Reviewer_Enzf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19936/Reviewer_Enzf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19936/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761764545076, "cdate": 1761764545076, "tmdate": 1762932100062, "mdate": 1762932100062, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper considers the problem of controlling a known linear dynamical system under possibly adversarial disturbances and time-varying costs. The authors propose an approach motivated by \"spectral filters\", wherein the eigenvalues/eigenvectors of a particular Hankel matrix determined by a user-set stability margin (over)estimate are used to parameterize a control law that maps past disturbances to controls. Compared to prior work in \"non-stochastic control\", by using this particular parameterization, the proposed method attains regret bounds that improve the dependence on the stability margin, as well as improve the run-time dependence on the stability margin from polynomial to polylogarithmic."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Overall, this paper is well-written and the message is rather clear. The proposed method is a novel adaptation of prior literature in both non-stochastic control and spectral filtering that seems to improve existing regret and runtime guarantees for this problem under relatively relaxed theoretical conditions. The approximation techniques involving the Hankel matrix are interesting, and as far as I know rather novel in the space of (linear) control. Thus, I think this paper contains worthy and interesting content for the niche of learning on dynamical systems researchers."}, "weaknesses": {"value": "Some immediate points that deserve some discussion are as follows:\n\n1. The results seem to rely on the dynamics matrices $A,B$ being known. How well do the proposed results extend to the unknown dynamics case?\n\n2. The proposed method seems rather tied to linear dynamics parameterization. How does one naturally apply this method to non-linear dynamics/policy parameterization? On that note, the discussion of applying GPC and OSC to nonlinear systems (with potentially nonlinear parameterization) in experiment Section 5.1 is rather terse, and it is not immediately clear how the proposed methods are being applied---the appendix doesn't seem to have further information on this front.\n\n3. The numerical experiments lack comparisons to even simple baselines. For example, considering some of the experiments concern control with Gaussian or zero-mean stochastic disturbances, it would be instructive to see the loss dynamics of, e.g. online LQR. Furthermore, in the known-linear-dynamics (potentially quadratic-loss case), there is quite a lot of literature on robust control, see e.g. classical mixed H2/H$\\infty$ control, competitive control [1], and adversarially robust synthesis [2]. I think it is both worth including some discussion about robust control perspectives, and a couple more simple baselines beyond disturbance-action filter approaches to get a better sense of the method's relative performance.\n\n4. As a minor comment, it should be noted the margins of the submission seem to have been different than the template.\n\n[1] Goel and Hassibi, \"Competitive Control\"\n\n[2] Lee et al. \"Performance-Robustness Tradeoffs in Adversarially Robust Linear-Quadratic Control\""}, "questions": {"value": "Please see under Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SGmNecRANv", "forum": "BQIzu1T6F0", "replyto": "BQIzu1T6F0", "signatures": ["ICLR.cc/2026/Conference/Submission19936/Reviewer_71FK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19936/Reviewer_71FK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19936/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761958322312, "cdate": 1761958322312, "tmdate": 1762932099349, "mdate": 1762932099349, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}