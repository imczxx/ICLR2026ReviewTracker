{"id": "5jkzTzV5Ao", "number": 1175, "cdate": 1756858970158, "mdate": 1763448568274, "content": {"title": "Understanding the Implicit Biases of Design Choices for Time Series Foundation Models", "abstract": "Time series foundation models (TSFMs) are a potential class of powerful, general-purpose tools for forecasting and related temporal tasks, but their behavior is strongly shaped by subtle inductive biases in their design. \nRather than developing a new model and claiming that it is better than existing TSFMs, e.g., by winning on existing benchmarks, our objective is to understand how the various \"knobs\" of the training process affect model quality. \nUsing a mix of theory and controlled empirical evaluation, we identify and show how various design choices (e.g., patch size, embedding choice, training objective, etc.) lead to implicit biases in fundamental model properties (e.g., temporal behavior, geometric structure, how aggressively or not the model regresses to the mean, etc.), and how these biases can be intuitive or counterintuitive, depending on properties of the model and data. \nWe illustrate in a case study on outlier handling how multiple biases interact in complex ways.", "tldr": "", "keywords": ["time series", "foundation models", "inductive bias", "frequency", "uncertainty", "geometry"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/55f59791f8364e0bcb7cea4716a7c58ec9c84284.pdf", "supplementary_material": "/attachment/0bc9ef58cde533da14e7158709e81b5f5f362da1.zip"}, "replies": [{"content": {"summary": {"value": "This paper did a investigation on implicit biases in Time Series Foundation Models (TSFMs). These implicit biases are introduced by several design knobs such as patch size, embedding type, and training loss. Instead of proposing a new model, this paper systematically analyzes how these design choices the model’s internal representations and generalization behavior. In this paper, it mainly identifies and discuss three main biases: temporal bias, geometric bias and regression to the mean bias. Combined theoretical analysis with empirical validation, it explains and shows how each biases cause issues and how to improve them."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1: This paper shows a wealth of visualization, including different type of figures. These figures are very easy to understand.\n\n2: The motivation of this paper is very clear. It shifts the focus from performance chasing to understanding inductive biases, highly relevant for Time Series Foundation Models (TSFMs)'s  robustness and transferability.\n\n3: This paper did a deep analysis on each implicit bias, validating findings across several leading Time Series Foundation Models (TSFMs). It also shows practical insights on each bias's investigation."}, "weaknesses": {"value": "1: For theorem 1, it seems that its theoretical scope is a little bit narrow and relies on simplified assumptions. In Theorem 1, it assumes a linearized ReLU MLP and random Gaussian projections to derive the property of patch embeddings. However, in modern Time Series Foundation Models (TSFMs), they have some attention and temporal positional encoding to dominate their feature engineering. We didn't see any assumptions or discussions on these. We are not sure if this paper's conclusions can hold for transformers trained end-to-end.\n\n2: When this paper discussed about low-frequency preference to large patch size, it didn't provide enough quantitative analysis of how this emerges during training. For example, visualization of any frequency-domain activations through epochs may support this claim. More explanations and rigorous proofs are needed to clarify these points. \n\n3: For its geometric bias, its geometry discussion shows that angle between embedded vectors for discrete embeddings is much larger than that for continuous embeddings. Also, this grows with the number of bins. However, this paper didn't measure vocabulary size systematically over this observation shown in its figure. More ablation study should be discussed and provided to show that whether the reported geometry is an inherent property of discretization or an artifact of one particular size."}, "questions": {"value": "Most of questions are mentioned in weaknesses.\n\n1: Could you please give more evidence to support how large patches can lead to low-frequency alignment? especially any end-to-end training support?\n\n2: Could you include structural evaluation metrics to show your conclusions for model's structural correctness?\n\n3: Have you tested your conclusions or findings on real industrial datasets with missing values, multi-seasonality, and domain shifts? How will your findings help the improvements?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gMNBDeJKSV", "forum": "5jkzTzV5Ao", "replyto": "5jkzTzV5Ao", "signatures": ["ICLR.cc/2026/Conference/Submission1175/Reviewer_UNdi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1175/Reviewer_UNdi"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1175/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761724520069, "cdate": 1761724520069, "tmdate": 1762915698209, "mdate": 1762915698209, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response (2/2)"}, "comment": {"value": "## **Real-World and Noisy Dataset**\n\n  Experiments in our paper use both synthetic and real-world datasets. Synthetic settings allow us to isolate and precisely probe subtle differences between architectural design choices. The patterns we purposefully construct (e.g., multi-scale structure, multi-offset trends, and high-frequency components) reflect common, important, and hard-to-capture phenomena in practical time-series applications. In addition, our conclusions are not based solely on synthetic data. The results in Figures 6 and 7 use a large corpus of real-world datasets, and demonstrate that the geometric bias we identify does manifest in practice. Section 5 provides an explicit and systematic study of noise robustness, which further validates our findings.\n\n  To make our analysis more comprehensive, we also augment our experiment in Section 4 with noise. See Appendix E.4 for the new results. Our results show that the regression-to-the-mean bias holds seamlessly for noise-free and noisy data.\n\n## **Vocabulary Size and the Geometric Bias**\n\n  Reviewers also mentioned the vocabulary size (when a quantization embedding is in use) as a potential factor that impacts the geometric bias. We believe this is a very interesting point and have done some additional experiments to investigate the role of the vocabulary size. (See the results in Appendix D.4.) We observe that an increasing vocabulary size makes Chronos attend more to the local content. In addition, an increasing vocabulary size equips Chronos with a stronger distance bias that makes it capable of handling the fine-scale signals better, while using a small vocabulary size nonetheless makes Chronos better at capturing fine-scale signals than Chronos-Bolt, which aligns with our discussion of the distance bias.\n\n## **Outlier Handling Discussion**\n\n  We appreciate the reviewers' interest in our outlier bias case study, which is an application of how these various biases can interact with each other. We agree that this is very interesting and with an additional page for the rebuttal revision, we have expanded our discussion of the outlier handling case study in Section 5 to highlight how each bias comes into play. We also added a Figure in Appendix F to reveal how TSFMs with different design choices handle these outliers."}}, "id": "eN43KIe1gG", "forum": "5jkzTzV5Ao", "replyto": "5jkzTzV5Ao", "signatures": ["ICLR.cc/2026/Conference/Submission1175/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1175/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1175/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763448944775, "cdate": 1763448944775, "tmdate": 1763449168359, "mdate": 1763449168359, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a study of implicit biases that follow from the design choices of time-series foundation models. Five biases are categorized into two categories, namely temporal (2) and geometry (3) biases. The biases are subtle but are revealed through experiments and proofs (given in the appendix)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "* The topic and analysis are novel. \n* I expect this paper to be highly significant for time-series modelling relying on deep learning in general and not only for research in time-series foundation models.\n* The paper is extremely thorough.\n* The structure of the paper is nice.\n* I believe the conclusion to be stronger than what is stated in the paper (see question section)."}, "weaknesses": {"value": "While the writing generally is good, this paper has some issues that I would like to point out. \n* The different biases are not defined explicitly in text. For example, what is meant by temporal and geometric bases? Please specify.  What is the frequency bias and the periodicity bias? What are the angels, distances and norms biases? Explicitly state this, preferably right after the bold heading for each term.\n* For temporal bias, frequency, periodicity and seasonality are mentioned, but while frequency and periodicity have their own bias, seasonality is not mentioned again explicitly. What is the difference between seasonality and periodicity?\n* On line 149: “In general, these models show different inductive biases …” Which? Be explicit and give examples. \n* The term frequence seems to be overloaded and sometimes mean frequency as measured by Hz and at other times mean “Fourier modes”. When it means one thing and when it means another thing is not explicit. Thie reduces the readability. I would suggest to not use frequency to indicate “Fourier modes” and use a different term instead?\n* For geometry bias, paragraph starting on line 267, it is not clear what geometry bias means, as mentioned above, nor which biases are grouped under this term. This is stated for temporal biases.\n* The term “breaking the geometry” is used on line 280, but as it is not clear what is meant by geometry, the term is not easily understood. \n* Line 314: Please explain what is meant by more complex reasoning. \n* Not clear what is meant by “the geometry of the input domain”.\n* Section 5 Mixture of Biases is a bit short. It would improve with more thorough explanations. \n\nIn summary, this paper is not very easy to read. However, this should be fairly easy to correct given that more space is available for final submission (and in the rebuttal phase). \n\nGiven the depth of the analysis and the complexity of the topic, it would probably improve by having less restrictions on page numbers. Publishing the paper in a journal could be an alternative to a conference because of the share amount of work that is reported. I realize that few journals have the reputation of ICLR and that publication might take longer. \n\nThere are issues with the PDF. It is heavy. The problem is especially noteable on page 7. I assume this is because of Figures 5 and 7. Is it because the figures contain text? Is the text the cause of the problem? They seem like vector graphics and not high-resolution images when I zoom in. Still, the page loads terribly slowly. This issue should be rectified if accepted. \n\nImproving the text will not only improve the presentation score, but also the soundness, as it will be easier to evaluate it with better presentation."}, "questions": {"value": "On line 346, what seems like a very important insight is mentioned, but only implicitly. I read it as: Because of the findings in this paper, foundation models for time-series might not be possible because the different design decisions will affect the performance on different tasks. Therefore, TSFMs are task specific, which is not the case for language models as they all operate on the same type of representation (language) with similar characteristics, as words and sentences. Is this the conclusion, or am I misunderstanding something? If this is the case, then the argument should probably be made explicitly in the conclusion. \n\nDoes the summary of results in Figure 1 that is described in text from line 93 reflect the summaries given in the boxes after the description of the biases? For example, Patch Size $\\rightarrow$ Temporal bias. However, patch size is a subset of temporal bias, but it also contains architectural choices and unmasked [REG] tokens as well? Did I understand this correctly?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "n06g7RdDYH", "forum": "5jkzTzV5Ao", "replyto": "5jkzTzV5Ao", "signatures": ["ICLR.cc/2026/Conference/Submission1175/Reviewer_8DhK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1175/Reviewer_8DhK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1175/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761841120717, "cdate": 1761841120717, "tmdate": 1762915698084, "mdate": 1762915698084, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response (1/2)"}, "comment": {"value": "We appreciate the reviewers' valuable feedback to help improve the clarity and generality of our manuscript. We are glad that the reviewers found our work an important contribution to the field to help better understand the subtle design choices and inductive biases in TSFMs. To summarize:\n\n* **Reviewer SCK8** highlights that \"the paper addresses a critical need in the TSFM literature. [...] This is the kind of scientific inquiry that fosters deeper understanding.\" In addition, they state that \"the authors do an excellent job of explaining not just that a bias exists, but how the specific design choice leads to it\" and that our work \"helps bridge the gap between theory and practice.\"\n\n* **Reviewer cdYf** appreciates \"the focus on clarifying the impact of design choices that are often overlooked\" and \"believes the paper is a solid contribution to the conference.\"\n\n* **Reviewer 8DhK** highlights that the \"topic and analysis are novel\" and that \"the paper is extremely thorough.\" In addition, they state that they expect our work to \"highly significant for time-series modelling relying on deep learning in general and not only for research in time-series foundation models.\"\n\n* **Reviewer UNdi** acknowledges that our paper \"shifts the focus from performance chasing to understanding inductive biases, highly relevant for Time Series Foundation Models (TSFMs)'s robustness and transferability.\" They also state that our paper \"did a deep analysis on each implicit bias, validating findings across several leading Time Series Foundation Models (TSFMs). It also shows practical insights on each bias's investigation.\"\n\nWe address the minor, reviewer-specific comments in our individual reviewer responses and the common response below. We have also updated the manuscript with the changes highlighted in red in the rebuttal version.\n\n\n## **Experiments with TSFMs Beyond Chronos**\n\n  To show the generality of our discussion of inductive biases beyond Chronos and Chronos-Bolt, we have added several additional experiments with more TSFMs in addition to the ones we already have in the paper:\n\n  * For the geometric distance and norm biases, we have included Moirai, in addition to the existing Chronos, Chronos-Bolt, and TimesFM, in our empirical evaluations. (See the updated Figures 5-6). The results confirm that a continuous embedding preserves geometry more than a quantization embedding does as we demonstrated with Chronos-Bolt, which we used to represent continuous-embedding-based TSFMs.\n\n  * For the regression-to-the-mean bias, we also added Moirai in our experiments in Appendix E.4, in addition to TimesFM, which we had already included for $L^2$ regression loss. The results again show that a regression-based TSFM, represented by Chronos-Bolt, regresses to the mean forecast while a classification-based TSFM, represented by Chronos, does not.\n\n## **Practicality of Theorem 1**\n\n  Theorem 1 concerns the setting of random Gaussian weight matrices. While the weight matrices in a pretrained model are generally not random Gaussian, our theorem shows that neural networks that embed low- and high-frequency patches into orthogonal spaces are very dense in the space of parameters. To empirically validate this orthogonality for pretrained models, we saved several checkpoints of Chronos-Bolt during training. Our new results in Appendix C.1.4 show that the conclusion of Theorem 1 holds throughout pretraining."}}, "id": "U82GyYSn43", "forum": "5jkzTzV5Ao", "replyto": "5jkzTzV5Ao", "signatures": ["ICLR.cc/2026/Conference/Submission1175/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1175/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1175/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763449082715, "cdate": 1763449082715, "tmdate": 1763449164254, "mdate": 1763449164254, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper discusses how different architectural choices in modern time series foundation models lead to learning biases in the resulting models. In particular, it focuses on biases in modeling the dynamics of input time series and in the structure of the predictions. Each observation is supported by convincing empirical results and well-designed experiments. I found the paper interesting and believe it is a relevant contribution to our understanding of the properties of current time series forecasting architectures. Although there are some presentation issues, I believe the paper is a solid contribution to the conference."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* The paper studies interesting and important phenomena in time series forecasting models.  \n* The findings are particularly relevant in the context of foundation models.  \n* I appreciate the focus on clarifying the impact of design choices that are often overlooked.  \n* The empirical analysis is interesting and well-designed."}, "weaknesses": {"value": "### Main weaknesses\n\nThe writing and presentation could be improved, and several claims would benefit from additional discussion and supporting evidence.\n\n- The introduction could do a better job summarizing the main takeaways of the paper and explaining why the discussed phenomena are particularly important in the context of foundation models (i.e., when learning a transferable model). Some sentences are difficult to contextualize without having read the full paper — for example:  “that time is continuous and this continuity should be maintained, and that regression algorithms should regress to the mean,” or “while a quantization-based embedding introduces a continuous-to-discrete ‘unrounding’ bias, and then relies on training to (imperfectly) recover continuous information in the hidden space.”  Moreover, the example on Chronos vs. Chronos-Bolt performance on chaotic systems is not self-contained and not particularly informative without the cited paper. I would use the introduction to provide more context and clearer motivations for the study. To clarify, I find the motivations sound — I am only referring to the quality of the presentation.  \n- I found Theorem 1 quite difficult to parse, as the terminology and assumptions are packed into a few lines. I understand its purpose, but I recommend streamlining the presentation and expanding the discussion on assumptions and their implications. While the appendix provides detailed explanations (which I appreciate), the main text does not adequately contextualize the theorem or its significance. For instance, the assumptions on the weight and bias matrices seem unreasonable without further discussion.  \n- The discussion on periodicity bias — specifically the impact of architecture (encoder vs. decoder vs. encoder-decoder), REG token, and patch size — is rather limited in the main body. I understand the space constraints, but as it stands, some claims appear less convincing without looking at the appendices.  \n- In Section 3, please clarify the notation. If I understand correctly, *x* and *y* refer to arbitrary patches, and since *k = 1*, these are scalar. Please make this explicit in the text.  \n- “When a period is far from zero, its embedded vectors occupy a larger portion of the embedded context, which makes it easier for the model to learn. [...]”  This is unclear and should be elaborated on further. Please clarify and/or provide an example.  \n- Please include the related work section in the main paper (you can make it more compact). Since much of the analysis focuses on comparing Chronos and Chronos-Bolt, a more in-depth comparison of the two architectures should be provided — particularly regarding the tokenization mechanism used in Chronos. I understand the space limitations, but I would recommend moving some empirical results to the appendix (or making the introduction more concise) to make room for a clearer context.  \n- While some parts of the paper would benefit from more discussion and detail (preliminaries, related work, etc.), other parts could be streamlined (e.g., Sections 3 and 4).  \n\n### Additional comments\n\n- The paper does not mention plans to release the code, but doing so would be very helpful. I also encourage the authors to include a reproducibility statement, as suggested by the ICLR guidelines.  \n- Most empirical results are based on synthetic datasets with no noise (systematic noise, not outliers). How do the authors expect the presence of noise to affect their observations?  \n\nOverall, I liked the paper, and if the authors address the issues above and improve the presentation, I'd be happy to increase my score.\n\n### Minor comments\n\n* What do you mean by “first-order structure” (e.g., line 221)?  \n* Rather than “periodicity,” I would suggest using “seasonality,” which is the more common term in the time series literature.  \n* In Figure 4a, please clarify exactly what *x* and *y* represent.  \n* All models used in the study are pretrained, correct?  \n* It would be interesting to include experiments on more varied datasets, both synthetic and real."}, "questions": {"value": "Please comment on the above weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "R7O0gyFXbY", "forum": "5jkzTzV5Ao", "replyto": "5jkzTzV5Ao", "signatures": ["ICLR.cc/2026/Conference/Submission1175/Reviewer_cdYf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1175/Reviewer_cdYf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1175/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761845660192, "cdate": 1761845660192, "tmdate": 1762915697906, "mdate": 1762915697906, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a systematic investigation into the implicit biases of modern Time Series Foundation Models (TSFMs). Rather than proposing a new model, the authors aim to understand how common design choices (\"knobs\") influence model behavior. They identify three primary classes of biases: 1) Temporal Bias, induced by patch size, which affects how models handle different frequencies and periodicities; 2) Geometric Bias, arising from the choice between continuous and discrete (quantization-based) embeddings, which impacts how the model perceives locality, scale, and offsets; and 3) Regression-to-the-Mean Bias, driven by the training loss function (e.g., L1/L2 vs. Cross-Entropy), which determines a model's behavior under uncertainty. The study uses a mix of theory and controlled empirical evaluations, primarily comparing Chronos and Chronos-Bolt, to demonstrate how these biases manifest and interact, ultimately shaping a model's suitability for different types of time series data (e.g., standard benchmarks vs. chaotic systems)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses a critical need in the TSFM literature. By shifting the focus from \"what is SOTA\" to \"why models behave the way they do,\" it provides lasting insights that will remain relevant even as new models emerge. This is the kind of scientific inquiry that fosters deeper understanding.\n\nThe combination of theory, controlled synthetic experiments, and analysis on real data is a major strength. The use of Chronos vs. Chronos-Bolt as a primary case study is an elegant experimental design choice that isolates the effects of specific design decisions.\n\nThe paper is exceptionally clear. The three-part framework of Temporal, Geometric, and Regression-to-the-mean biases is intuitive, well-supported, and provides a powerful lens through which to view TSFM design. The authors do an excellent job of explaining not just that a bias exists, but how the specific design choice leads to it.\n\nThe paper provides practical takeaways. For example, it explains why a model like Chronos (with quantization and cross-entropy loss) might be better for chaotic systems (due to less regression-to-the-mean and a different geometric bias), while a model like Chronos-Bolt might be more robust for noisy, trend-based series. This helps bridge the gap between theory and practice."}, "weaknesses": {"value": "While the focus on Chronos/Chronos-Bolt is a strength for control, it is also a potential weakness for the generality of the conclusions. The paper does include other models like TimesFM and Moirai in some experiments (which is great!), but the core narrative and many of the detailed analyses are tightly coupled to the Chronos family. It would strengthen the paper to either include more direct evidence from a wider variety of architectures or to more explicitly frame the conclusions in terms of the design choices themselves (e.g., \"models using continuous embeddings and L1 loss...\") rather than implying they hold for all TSFMs.\n\nThe case study on outlier handling in Section 5 is a good first step toward understanding how biases interact. However, this aspect feels somewhat underexplored compared to the detailed analysis of each individual bias. The real world is messy, and models are always operating under a combination of these effects. A slightly deeper discussion or another case study (e.g., handling non-stationarity) could have made the \"mixture of biases\" a more central contribution.\n\nThe inclusion of Theorem 1 is a strength. However, the theorem relies on standard but strong assumptions (e.g., random Gaussian weights) that are not met in a fully trained network. A brief discussion on the expected qualitative persistence of these results in trained models would be helpful to bridge the gap for practitioners. For instance, do we expect the orthogonality of embeddings for different frequencies to be as clean, or just a general tendency?"}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "BlVcgKzenN", "forum": "5jkzTzV5Ao", "replyto": "5jkzTzV5Ao", "signatures": ["ICLR.cc/2026/Conference/Submission1175/Reviewer_SCK8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1175/Reviewer_SCK8"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1175/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761890252070, "cdate": 1761890252070, "tmdate": 1762915697714, "mdate": 1762915697714, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}