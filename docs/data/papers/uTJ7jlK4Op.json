{"id": "uTJ7jlK4Op", "number": 8071, "cdate": 1758058113874, "mdate": 1759897810153, "content": {"title": "Disentangling Shared and Private Neural Dynamics with SPIRE: A Latent Modeling Framework for Deep Brain Stimulation", "abstract": "Disentangling shared network-level dynamics from region-specific activity is a central challenge in modeling multi-region neural data. We introduce SPIRE (Shared–Private Inter-Regional Encoder), a deep multi-encoder autoencoder that factorizes recordings into shared and private latent subspaces with novel alignment and disentanglement losses. Trained solely on baseline data, SPIRE robustly recovers cross-regional structure and reveals how external perturbations reorganize it. On synthetic benchmarks with ground-truth latents, SPIRE outperforms classical probabilistic models under nonlinear distortions and temporal misalignments. Applied to intracranial deep brain stimulation (DBS) recordings, SPIRE shows that shared latents reliably encode stimulation-specific signatures that generalize across sites and frequencies. These results establish SPIRE as a practical, reproducible tool for analyzing multi-region neural dynamics under stimulation.", "tldr": "", "keywords": ["Latent Variable Models", "Disentanglement", "Shared and Private Subspaces", "Neural Dynamics", "Deep Brain Stimulation", "Intracranial Recordings"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/41100014dcd96fdc8012711e717e25eebc0e5fab.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents SPIRE, a deep learning framework for separating shared and private latent subspaces in multi-region intracranial recordings. The model employs a multi-loss objective combining reconstruction, alignment (VICReg), and disentanglement (orthogonality, variance guards), with lightweight temporal alignment via ConvAlign. The proposed method is first validated in synthetic datasets in varying degrees of nonlinearity and then, in human DBS datasets with intracranial recordings."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The problem formulation is a well-motivated neuroscience problem as modeling multi-region activity and their coordination is important to understand large-scale brain dynamics.\n- The synthetic evaluations are strong in the sense that SPIRE achieves robust performance with gradually increased nonlinearities and misalignments.\n- The results are backed up by statistical significance levels, which are usually overlooked for deep-learning research but are important to quantify the robustness of findings."}, "weaknesses": {"value": "- I think the training objective is over-engineered and extremely complex: it is composed of 9 different loss items, where each loss item requires individual scaling and scheduling, and thus, it significantly increases the hyperparameter search complexity. \n- As each regional recording requires its corresponding encoder/decoder pair and alignment modules between each pairwise regions, the scalability of the proposed approach beyond many regions is unclear. \n- I think an important attribute of a multi-region brain activity model should be inferring the directional signal flow between multiple brain regions, which can reveal complex causal relationships or inter-regional dynamics between individual brain regions, similar to DLAG. However, I am not sure if the proposed approach reveals such relationships, but rather, it merely aligns the shared latents across regions.\n- The downstream analysis is limited to one dataset with only one downstream stimuli prediction task, hindering the applicability and generalizability of the proposed approach. The authors could have tested their model on multi-regional spike recordings in non-human primates, such as Makin et al., 2018; Perich et al., 2017; Churchland et al., 2012; Gallego-Carracedo et al., 2022. \n- Some terms and identifiers are not clearly defined, for example, the subject names S3_R and S8_R. Also, the simulation details in Appendix A.2.1 require further clarification on the details. \n\nReferences: \n- Joseph G Makin, Joseph E O’Doherty, Mariana M B Cardoso, and Philip N Sabes. Superior arm-movement decoding from cortex with a new, unsupervised-learning algorithm. Journal of Neural Engineering, 15(2):026010, January 2018. Publisher: IOP Publishing.\n- Matthew G. Perich and Lee E. Miller. Altered tuning in primary motor cortex does not account for behavioral adaptation during force field learning. Experimental Brain Research, 235(9):2689–2704, September 2017.\n- Mark M. Churchland, John P. Cunningham, Matthew T. Kaufman, Justin D. Foster, Paul Nuyujukian, Stephen I. Ryu, and Krishna V. Shenoy. Neural population dynamics during reaching. Nature, 487(7405):51–56, July 2012. Publisher: Nature Publishing Group.\n- Juan A. Gallego, Matthew G. Perich, Raeed H. Chowdhury, Sara A. Solla, and Lee E. Miller. Long-term stability of cortical population dynamics underlying consistent behavior. Nature Neuroscience, 23(2):260–270, February 2020."}, "questions": {"value": "- Is there a specific reason that authors focused on stimulation datasets, as they state that 'Future work will extend SPIRE to longer stimulation paradigms ...'?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "U2k7k0pDJR", "forum": "uTJ7jlK4Op", "replyto": "uTJ7jlK4Op", "signatures": ["ICLR.cc/2026/Conference/Submission8071/Reviewer_rMns"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8071/Reviewer_rMns"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8071/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761013108206, "cdate": 1761013108206, "tmdate": 1762920063584, "mdate": 1762920063584, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents SPIRE, a new model to disentangle shared and private network dynamics from multi-region intracranial local field potential recordings. The model uses a GRU-based autoencoder framework with separate private and shared latent variables for each observed region. Shared and private latents are produced via linear projections of a per-region GRU encoder's hidden state. The loss function includes self- and cross-region reconstruction terms, a novel near-impulse 1D convolution kernel (ConvAlign) to align temporally misaligned shared latents across regions, and VICReg-style shared latent alignment applied after the ConvAlign step. Disentangling between shared and private latent spaces is encouraged by penalizing the Frobenius norm of the linear cross-covariance between shared and private latents. On synthetic datasets with realistic nonlinearities, SPIRE outperforms the linear DLAG model. On real deep brain stimulation data from GPi and STN, SPIRE achieves superior reconstruction accuracy to MMVAE and SharedAE, and the SPIRE shared latents were reported to encode stimulation frequency. Although the overall framework is conceptually interesting, the loss function and training procedure are quite complicated, and the use of a linear cross-covariance penalty to disentangle deep nonlinear representations is theoretically weak. The paper's results also show that the disentangling term is insufficient in practice; on real DBS data, the median CCA correlation between shared and private latents was between 0.55 and 0.65, indicating substantial information leakage that directly contradicts the paper's central claim of successful disentangling. Additionally, comparisons to existing methods are insufficient to fully evaluate SPIRE in the context of the broader literature: synthetic benchmarks include only DLAG, a linear model, and real-data comparisons do not assess disentangling quality for baseline methods. While the neuroscience motivation and framework are promising, the current implementation does not yet achieve the level of disentanglement the authors claim."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The use of ConvAlign for shared latent alignment is conceptually interesting and interpretable.\n- The ablation studies presented in the supplement are thorough.\n- Synthetic data generation and training/hyperparameter details are well-documented and anonymized code is provided."}, "weaknesses": {"value": "- **Disentangling loss term:** The use of a linear cross-covariance penalty to enforce independence between shared and private latent spaces is theoretically insufficient for nonlinear neural networks. The empirical results on real data confirm this: the reported 0.55-0.65 median linear correlation between inferred shared and private latent variables from the real dataset indicates significant information leakage. Stronger disentangling approaches exist in the shared-private representation learning literature, including total-correlation penalties [1, 3] and adversarial schemes [2].\n- **Mismatch between claims and results:** The paper claims that SPIRE successfully disentangles shared and private variables in real neural data, but reports 0.55-0.65 median correlation between shared and private latents. The paper describes this correlation as indicative of \"weak\" information leakage, but this interpretation is factually untrue and misleading; such high values indicate moderately strong linear dependence, and nonlinear dependence (e.g. measured via mutual information or DeepCCA) would likely be even higher. Thus, the results on real data directly contradict the central claim of successful disentanglement.\n- **Insufficient comparison/evaluation of existing methods:** On synthetic data, SPIRE is compared only to DLAG, a linear model. Since ground-truth shared and private latent variables are known only for the synthetic data, a comparison on the synthetic datasets of SPIRE's latent variable recovery and disentangling quality to modern nonlinear disentangling methods (even SharedAE) are necessary to demonstrate improvement over existing methods. On real data, comparisons to other SharedAE and MMVAE are limited to reconstruction MSE. The paper quantifies disentangling for SPIRE via CCA correlation of the shared and private latent spaces, but given that disentanglement is a main goal of the model, disentangling quality should also be quantified for SharedAE. Additionally, the comparison to MMVAE is questionable (over methods with similar objectives to SPIRE, e.g. [1 - 4])  given that MMVAE does not architecturally separate shared and private latents. \n- **Disentangling quantification:** The use of linear CCA correlation to quantify shared-private disentangling likely underestimates the true degree of dependence between the latent spaces. The authors should also incorporate nonlinear measures of dependency to more accurately quantify disentanglement (e.g. via DeepCCA correlation).\n\n### References\n[1] H. Hwang, G.-H. Kim, S. Hong, and K.-E. Kim, “Multi-View Representation Learning via Total Correlation Objective,” in Advances in Neural Information Processing Systems, 2021.\n\n[2] Q. Lyu, X. Fu, W. Wang, and S. Lu, “Understanding Latent Correlation-Based Multiview Learning and Self-Supervision: An Identifiability Perspective,” presented at the International Conference on Learning Representations, 2021.\n\n[3] Mihee Lee and V Pavlovic. Private-shared disentangled multimodal VAE for learning of latent representations. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pp. 1692–1700, June 2021.\n\n[4] Emanuele Palumbo, Imant Daunhawer, and Julia E Vogt. MMVAE+: Enhancing the generative quality of multimodal VAEs without compromises. In The Eleventh International Conference on Learning Representations, 2023."}, "questions": {"value": "- The authors state that current nonlinear disentangling models are not applicable to LFP data. Could the authors clarify what LFP signal characteristics makes these approaches unsuitable?\n- The authors note that SPIRE received lag-augmented inputs, which empirically improved robustness to temporal shifts. Why is this necessary, given that SPIRE already uses GRU encoders and the ConvAlign kernel? Does the need for augmented input suggests that SPIRE's architectural features and loss functions are insufficient to properly account for time lags between regions?\n- Robustness to misspecified model dimensionality (or an automatic dimensionality selection procedure) is crucial for application to real data, where ground-truth dimensionality is rarely known a priori. Did the authors investigate whether SPIRE's performance degrades when the model is trained with the incorrect latent dimensionality?\n- The reported reconstruction MSE results are difficult to interpret without knowledge of the scale of observed features . Are the differences in MSE between methods large or small compared to the total variance in the data? Could the authors report normalized reconstruction metrics (e.g. variance explained) across datasets and baseline methods to make reconstruction accuracy results more interpretable?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "P8zajPaMxq", "forum": "uTJ7jlK4Op", "replyto": "uTJ7jlK4Op", "signatures": ["ICLR.cc/2026/Conference/Submission8071/Reviewer_8eiG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8071/Reviewer_8eiG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8071/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761792506639, "cdate": 1761792506639, "tmdate": 1762920063237, "mdate": 1762920063237, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present an autoencoder they call SPIRE which ostensibly partitions the latent space into \"shared\" and \"private\" latent variables that independently encode multivariate time series for the purpose of identifying shared information between brain regions. The model is constructed specifically for two brain regions and architecturally there are two autoencoders, one for each brain region's data.  Each autoencoder is composed of a GRU encoder and GRU decoder. The latent space is composed of a separate set of \"private\" and \"shared\" latent variables.The authors benchmark against simulated data (described as D0, D1, and D2) and compared with DLAG. The model was further validated using human electrophysiological data during deep brain stimulation."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The method appears to be different from existing methods that I'm aware of and performs well on the simluated data benchmarks, although I have misgivings about their simulated data analysis, which I outline under \"weaknesses\". The real-data validation also appears to be interesting and to be consistent with hypotheses from neurophysiology.  The paper is also fairly well written and well organized."}, "weaknesses": {"value": "The biggest weakness of this paper is that it did not sufficiently engage with the existing literature. Specifically, it is not entirely clear what this paper adds to the existing literature as it did not benchmark against some important contributions. Some examples are included below. While the papers I've cited are described as \"multi-model\" and explicitly model a combination of neural and behavioral data I see no practical limitation to using a second neural dataset as the \"behavior\". The authors themselves reference several other multi-model models that disentangle private and shared information (Yi el a.l, Shi et al., 2019, Lee &Pavlovic 2021) but imply that there is some formal distinction between neural-behavioral and neural-neural methods. I do not believe that there is such a distinction and the authors need to do more work to either a) include more benchmarks, or b) provide a better argument for why any of the multi-modal approaches are disqualified. Finally, despite describing a number of nonlinear methods (two additional nonlinear methods are cited below) the authors do no benchmark against either of them.\n\nKoukuntla, Sai, et al. \"Unsupervised discovery of the shared and private geometry in multi-view data.\" arXiv preprint arXiv:2408.12091 (2024).\nGondur, Rabia, et al. \"Multi-modal Gaussian Process Variational Autoencoders for Neural and Behavioral Data.\" The Twelfth International Conference on Learning Representations.\nSani, O.G., Abbaspourazad, H., Wong, Y.T. et al. Modeling behaviorally relevant neural dynamics enabled by preferential subspace identification. Nat Neurosci 24, 140–149 (2021). https://doi.org/10.1038/s41593-020-00733-0\n\nThe other, and potentially disqualifying, weakness of the benchmarking is how the comparison with DLAG was implemented. I have two major criticisms 1) unfair lag specification, and 2) unfair latent comparison. 1) The authors state \"for SPIRE we additionally incorporated lag-augmented input features ... DLAG was run in its standard form without lags.\" This would suggest that, despite the point of DLAG being that it can handle lags, was placed at a disadvantage. Am I misunderstanding what the authors are saying here? 2) DLAG was fit with 3 shared latents while SPIRE was fit with 3 shared latents per region (meaning 6 latents). This would provide SPIRE with twice as many variables with which to achieve higher CCA with the true data. This makes their claims of superior performance highly dubious."}, "questions": {"value": "- To make this paper acceptable the simulated data benchmark would have to be made more rigorous and include nonlinear methods as outlined above. \n- The authors mistakenly state that the original pCCA paper by Bach & Jordan (2005) does not distinguish shared from private variability, but this is not accurate. This is in fact very likely the first paper to do so and is regularly cited as such. I would edit the text to reflect this.\n- The size of Figure 2 is unreasonably small. Please resize. \n- However, Figure 2 also doesn't appear helpful. It seems that the point the authors are making is that SPIRE has better alignment than DLAG but this does not come through in the presented figure at all by eye.\n\nConceptual note:\n The shared variables are aligned between the two models and kept distinct from private latents with a orthogonality constraint. To me this appears to be one of the major distinctions of this model from comparable methods in that, rather than modeling a single set of latent variables, it enforces a degree of alignment between the shared modes of each model. However, the authors do not make a strong argument for why this ought to be the right approach. Why should it be this way and not have a single set of shared latents? Is it still fair to call them \"shared\" when they are not actually shared but simply aligned? Indeed, one could titrate how aligned you want them to be so that it's not clear at all how \"shared\" these latents will be for any given application. Please expand on this."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Bw0br2yYKF", "forum": "uTJ7jlK4Op", "replyto": "uTJ7jlK4Op", "signatures": ["ICLR.cc/2026/Conference/Submission8071/Reviewer_xN51"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8071/Reviewer_xN51"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8071/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761801603462, "cdate": 1761801603462, "tmdate": 1762920062817, "mdate": 1762920062817, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a latent factors analysis method for intracranial recordings that emphasize 1) nonlinear encoder / decoders, and 2) disentangling of shared and region-private latents. The method uses RNN (GRU) encoder and decoders while the time-varying latents are enforced to have orthogonal and aligned components. The method is validated against simulated data with GT latents, and applied to a dataset of DBS-implanted intracranial recordings to find area-specific and shared latents that can be used to decode stimulation frequency in unseen data."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- The paper presents a nice and elegant method with fairly straightforward components (RNNs, linear projections onto latents, etc.) and cleverly designed losses.\n- The manuscript is clearly and concisely written imo, and in general of high quality.\n- I commend the use of simulated data with groundtruth, and interesting real data applications."}, "weaknesses": {"value": "- While the framework is nice, I’m not convinced of its value, both in terms of methodological or scientific contribution. In other words, the primary contribution is that it presents a novel nonlinear and disentangled latent analysis method, applied to human intracranial data. But it’s quality / accuracy and scientific insight remains limited, as a standalone contribution and relative to existing works.\n- The majority of experimental results are essentially to validate the retrieval of shared vs. private latents. The simulation experiments with GT is commendable, but SPIRE shows marginally (if at all) better performance than the one baseline on shared latents, which is arguably its primary appeal. It’s great that the method is applied to real data, but most of the results (Fig4-6) show various versions of the statement that shared latents are more similar across regions than private latents and that reconstruction is better with both sets of latents. This is to some extent circular, as the loss functions are designed to enforce this, so the fact that this is confirmed is great, but I’m uncertain what the proposed value is?\n- on the neuroscience side, the main proposed insight is that stimulation frequency can be better decoded better from shared latents than from private latents, and hence argues for the value of such a decomposition in revealing distributed network activity. It’s a nice result that the shared latents inferred during rest is informative of unseen stimulation data (though obviously the classifier is trained), but there are some caveats to this: first, this difference is a function of the classifier, and cannot make a general statement based on RF without other baselines. Second, can we also expect to decode stimulation setting in the raw data? Does decoding perform better with data from multiple locations? If so, one could essentially make the same argument about distributed network modulation, but without any latent analysis. Third, and more generally, imo the paper lacks conceptual clarity as to what the shared vs. private latents are suppose to represent. In other words, had the analysis in Figure 7 shown the opposite trend, one could have similarly written a posthoc sensible explanation.\n- As a result, while it’s a neat method and nicely presented with interesting data, imo the paper does not demonstrate its value in general nor for neuroscience, i.e., with respect to the claimed contributions in the intro and discussion. Perhaps the authors could design alternative experiments with real data that show the validity and value of the partitioned latents relative to *some* kind of groundtruth or at least biologically knowledge, e.g., about interregional differences or communication, or even a simulation experiment where the latents are not explicitly defined, but nevertheless retrieved given some knowledge about the system, such as a multi-regional RNN with block diagonal connectivity (just as an example)."}, "questions": {"value": "- are the GRU encoder and decoder run bidirectionally (acausal)? If so, how does causal encoding and decoding impact performance?\n- what is the physiological interpretation of shared vs. private (or cross-regional vs. region-specific) dynamics in terms of neural activity? For example, shared input, monosynaptic connections, or something else? More concretely, how does this map to the simulation experiment setting in Section 4?\n- how to determine the loss weights (i.e., data-specific lambdas)? This seems to be important for actual applications and should be mentioned in the main text\n- line 206: could you expand on this? It does not seem fair to provide lagged inputs to SPIRE but not DLAG?\n- line 274: “analyses were performed at the hemisphere level, as most patients were implanted bilaterally” could you clarify this? Is it missing a “…NOT implanted bilaterally”? Otherwise why not look at the cross-hemisphere interaction as potential shared latents?\n- line 276: why not downsample to lower rate when there is a 50Hz lowpass (effectively 100Hz sampling rate)?\n- How consistent are the retrieved latents for the same subject e.g., across different recording days? If that’s not available, how far in time were the heldout test data (e.g., line 315), or are they simplify randomly interleaving 0.5s windows from the entire dataset? How about reconstruction accuracy during the stimulation periods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KUYwLndb6R", "forum": "uTJ7jlK4Op", "replyto": "uTJ7jlK4Op", "signatures": ["ICLR.cc/2026/Conference/Submission8071/Reviewer_YCWL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8071/Reviewer_YCWL"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8071/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761906232022, "cdate": 1761906232022, "tmdate": 1762920062453, "mdate": 1762920062453, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new multi-encoder autoencoder model called SPIRE for multi-region neural data analysis. It can decompose latent into shared latent subspace and private subspace for each region. The model exhibits good and reliable latent encoding and reconstruction on deep brain stimulation data."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "* The model is intuitive and well presented.\n* Experiments show that the proposed model outperforms the baseline DLAG."}, "weaknesses": {"value": "* The model seems intuitive, but a little bit simple. The appreciated part to me is the alignment for the shared latent.\n* The comparisons are not comprehensive, since I believe the discovered latent has no interpretability. There is no ground truth for the real-world data. Therefore, it is hard to validate whether such a VAE model is useful in neuroscience, since we care about what dose the latent mean and how it is useful for understanding the neural data. I think authors can at least use a linear/affine transformation to align each latent subspace to some non-neural artifacts (e.g., behavior in some datasets) to show the validity of the latent.\n* There is no theoretical uniqueness property in such a model, even when such a lot of constraints are added to the target function. This makes the interpretability or the usefulness of such a model even harder.\n* Extending the model to more regions is theoretically naive, but practically difficult, since the shared parts combination grows in $2^R$, which in practice hurts the model's applicability on multiple regions.\n* Since the encoder is GRU, I doubt the latent can really be disentangled into several groups."}, "questions": {"value": "* Why not directly require the shared latent subspace to be just one thing? What's the consideration of splitting them and then aligning them during training? Implementing such a model and other variants is easy and can be viewed as intermediate baselines.\n* What would be the similarity scores between the privates in two regions, and between the shared from region 1 to the private from region 2, in Figure 5 (a)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qJheIOvgZe", "forum": "uTJ7jlK4Op", "replyto": "uTJ7jlK4Op", "signatures": ["ICLR.cc/2026/Conference/Submission8071/Reviewer_oSFr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8071/Reviewer_oSFr"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission8071/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968958275, "cdate": 1761968958275, "tmdate": 1762920059779, "mdate": 1762920059779, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}