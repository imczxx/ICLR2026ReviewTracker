{"id": "EBOPczQtCS", "number": 24396, "cdate": 1758356424275, "mdate": 1759896768389, "content": {"title": "Guarding a Needle in the Haystack: A Real-Time Policy-Following Streaming Video Guardrail", "abstract": "With the rapid growth of video generative models, robust guardrails are more critical than ever to ensure both video content safety, which prevents the proliferation of harmful material (e.g., sexual or self-harm), and video generation security, which defends against adversarial attacks on video generation models (e.g., jailbreak prompts or unsafe video injection). While recent multimodal large language model (MLLM) based guardrails have advanced through reasoning and video understanding, they still face significant limitations. In particular, they rely on frame subsampling, which is unreliable for precise long-term monitoring. In addition, they lack support for real-time streaming and incur high overhead due to inefficient token usage. To address these challenges, we propose StreamGuard, the first real-time, policy-following streaming guardrail for long-form videos. To precisely identify unsafe frames hidden in long videos, StreamGuard efficiently inspects the input video in streaming form to localize unsafe content with high precision. To enable real-time streaming, StreamGuard employs an efficient asynchronous inference stack that parallelizes safety analysis across ingested events while simultaneously encoding and detecting incoming frames, achieving fine-grained, frame-level monitoring with low latency. In addition, considering the lack of benchmarks that reflect real-world long-form video risks, we introduce two benchmark datasets: (1) Safe2Shot, with over 4K unsafe videos annotated at the frame level, capturing needle-in-the-haystack cases where harmful content appears in only a few frames; and (2) AdvVideo-Bench, which includes both TV2V and TV2T components targeting the video and text modalities respectively, designed to evaluate guardrail resilience against video-centric multimodal jailbreaks. Extensive experiments show that StreamGuard outperforms state-of-the-art guardrails by 19.7% on both Safe2Shot and AdvVideo-Bench, and by 10.6% across five existing benchmarks, while reducing token and time costs by 23.5%.", "tldr": "StreamGuard, the first real-time, policy-following streaming guardrail and two benchmark datasets: (1) Safe2Shot (2) AdvVideo-Bench", "keywords": ["Video Guardrail", "Video Content Safety", "Streaming Guardrail"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/487e77ee162202c46fe2e5c57956ff4e277d2255.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes StreamGuard, a real-time, policy-following streaming guardrail for long-form videos. They inspect the input video in streaming form to localize unsafe content with high precision, and employ a efficient asynchronous inference stack to achieve fine-grained, frame-level monitoring with low latency. Two benchmark dataset, Safe2Shot and AdvVideo-Bench have been proposed to evaluate the defense performance."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "1.\tStreamGuard processes videos in a streaming manner, labeling every frame to avoid sampling losses, improving the detection performance.\n\n2.\tTwo-stage training with SFT across frames improves alignment and reduce failures under adversarial conditions.\n\n3.\tStreamGuard outperforms baselines on existing benchmarks, demonstrating superior performance."}, "weaknesses": {"value": "1.\tDataset curation details for TV2V adversarial prompts are restricted to \"conceptual level,\" without code or full prompts, which limits verification and raises concerns on fairness in benchmark creation.\n\n2.\tAblations are mentioned but not detailed with quantitative results in the main text, e.g., impact of removing GRPO or streaming on specific metrics.\n\n3.\tThe hyperparameters of $L_{SFT}$ are $\\lambda_1$, $\\lambda_2$ and $\\lambda_3$ for frame loss, event loss and final loss respectively, but lack of discussions on how to choose these values and no ablation studies or sensitivity analyses here.\n\n4.\tThe line space of each Section and Subsection is too narrow. It is acceptable to use some command to adjust the space (like vspace in LaTeX), but this doesn’t mean the excessive change in order to satisfy 9 pages limit."}, "questions": {"value": "1.\tHow does your method perform on traditional T2V adversarial datasets like T2VSafetyBench[a]?\n\n2.\tAre code and datasets publicly available for reproducibility, including full annotations?\n\n3.\tHow does StreamGuard handle real-time scenarios such as network delays and incomplete streams?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "upHHGJs2j8", "forum": "EBOPczQtCS", "replyto": "EBOPczQtCS", "signatures": ["ICLR.cc/2026/Conference/Submission24396/Reviewer_L4Tt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24396/Reviewer_L4Tt"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24396/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761220741921, "cdate": 1761220741921, "tmdate": 1762943071472, "mdate": 1762943071472, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents StreamGuard, a system designed to safeguard real-time streaming video by identifying unsafe content through a multi-level policy alignment approach. The authors propose a framework that incorporates Teacher-forcing Supervised Fine-Tuning (SFT) across three levels: frame-level, event-level, and final-level. This is intended to ensure a fine-grained alignment at the frame level, event summary at the event level, and a consolidated decision-making mechanism at the final level.\nThe proposed system is evaluated across several benchmarks with the results demonstrating competitive performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The multi-level alignment, specifically integrating frame-level, event-level, and final-level processing, is a novel way to improve the performance of video safety systems.\n2. The paper evaluates the system on several benchmarks, showing improvements in accuracy and F1 score on datasets like TV2T and TV2V, which is an important contribution."}, "weaknesses": {"value": "1. Although the paper discusses Teacher-forcing SFT across levels, it does not clearly present an ablation study isolating the contributions of frame-level, event-level, and final-level processing in the context of system performance (Perhaps I haven't found relevant analysis; if I have, please point it out.).\n\n2. How does the proposed defense method perform against adaptive attacks? Is it effective in defending against such attacks?\n\n3. The authors do not provide accessible code, data, specific experimental details (such as resources required for model training and parameter configurations), or failure case analyses, which negatively impacts the reproducibility of the experiment and hinders a deeper understanding of the work.\n\n4. The authors should provide a detailed description of the differences between the SAFESHOT benchmark and Video-SafetyBench, VidSafe, et al."}, "questions": {"value": "The questions can be found in the Weaknesses section above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "de9IQDOeGB", "forum": "EBOPczQtCS", "replyto": "EBOPczQtCS", "signatures": ["ICLR.cc/2026/Conference/Submission24396/Reviewer_ZuRt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24396/Reviewer_ZuRt"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24396/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761796927149, "cdate": 1761796927149, "tmdate": 1762943071290, "mdate": 1762943071290, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work introduces STREAMGUARD, a real-time guardrail system for streaming videos. The paper argues that existing multimodal moderation systems miss harmful content due to frame subsampling, offline pipelines with blocking latency, and weak policy following. To solve these issues, the authors propose a streaming architecture with frame-level labeling, event-based contextual resets, and asynchronous inference so that explanation generation does not block incoming frame processing. The method further uses a two-stage alignment procedure that combines supervised fine-tuning with reinforcement learning from verifiable rewards to strengthen policy consistency. The paper also releases two datasets: SAFE2SHOT, which focuses on brief unsafe spans in long videos, and ADVVIDEO-BENCH, which contains adversarially perturbed cases for both video-to-video and video-to-text jailbreaks. Experiments show gains on long-video safety benchmarks, adversarial settings, and runtime latency compared to strong baselines"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The work identifies a concrete and meaningful gap: moderation systems often lose signal due to subsampling and blocking decoding, especially when unsafe frames occur only briefly. The authors support this claim with an explicit streaming design and a realistic use case: long-form video moderation with adversarial pressure. The proposed method is tailored to this objective, offering frame-exact labeling and parallel execution. The dataset design also aligns tightly with the problem setup, and the empirical evaluation is extensive, covering both normal and adversarial cases. Results indicate clear improvements in both accuracy and latency, suggesting that the solution is practical for high-throughput applications. The work is also careful in describing alignment training and real-world deployment considerations, which increases credibility."}, "weaknesses": {"value": "While the contribution is technically sound, the approach builds on known components—streaming MLLM execution, context resets, and RL-based policy alignment. The novelty mainly lies in integrating these ideas in a moderation pipeline rather than advancing a new learning principle.\n\nSpecific policy categories and event definition rules appear heuristic and could benefit from more theoretical analysis or failure case breakdowns. \n\nIt would also strengthen the work to include ablations comparing against different frame rates or memory window strategies to verify that the performance gains truly stem from the streaming mechanism rather than from scale or dataset advantage. \n\nThe method assumes reliable annotation and clear unsafe spans; how it handles ambiguous or culturally sensitive borderline content could be discussed more."}, "questions": {"value": "The paper states that missing a few frames may hide unsafe content, but it does not quantify how performance changes when frame rate varies. Can you report results across different sampling rates to validate frame-exact necessity?\n\nADVVIDEO-BENCH focuses on prompt-based and transformation attacks reported in industry practice. How would the method handle adaptive attackers who target the specific streaming reset mechanism?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "c0JD7wl4dK", "forum": "EBOPczQtCS", "replyto": "EBOPczQtCS", "signatures": ["ICLR.cc/2026/Conference/Submission24396/Reviewer_mM3s"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24396/Reviewer_mM3s"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24396/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761891054038, "cdate": 1761891054038, "tmdate": 1762943071107, "mdate": 1762943071107, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces STREAMGUARD, a real-time, policy-following video moderation system designed to accurately detect unsafe content, such as violence and pornography, in long-form videos. Compared to traditional methods, STREAMGUARD utilizes streaming video analysis to avoid the information loss caused by frame sampling and employs parallel event reasoning to significantly improve processing efficiency. Additionally, the system enhances robustness against adversarial attacks through multi-level policy alignment training. To validate its effectiveness, the paper introduces two new benchmark datasets, SAFE2SHOT and ADVVIDEO-BENCH, and experimental results demonstrate that STREAMGUARD outperforms existing state-of-the-art methods in both accuracy and efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. STREAMGUARD uses real-time streaming processing, without relying on frame sampling, ensuring that every frame in the video stream is accurately annotated.\n2. The effectiveness of the method has been validated through experiments.\n3. Ablation studies have demonstrated the validity of each component."}, "weaknesses": {"value": "1. The layout is too tight. In some places, two lines of text are almost overlapping, such as on lines 152-153 and 211-212.\n\n2. Many papers have already explored video modality safety, such as [1-7]. However, the author does not discuss these works at all in the related work section (including many others not listed here).\n\n   [1] Safree: Training-free and adaptive guard for safe text-to-image and video generation\n\n   [2] T2Vs Meet VLMs: A Scalable Multimodal Dataset for Visual Harmfulness Recognition\n\n   [3] T2vsafetybench: Evaluating the safety of text-to-video generative models\n\n   [4] SafeVid: Toward Safety Aligned Video Large Multimodal Models\n\n   [5] Protecting your video content: Disrupting automated video-based LLM annotations\n\n   [6] Videojail: Exploiting video-modality vulnerabilities for jailbreak attacks on multimodal large language models\n\n   [7] SEA: Low-Resource Safety Alignment for Multimodal Large Language Models via Synthetic Embeddings\n\n   [8] From Evaluation to Defense: Advancing Safety in Video Large Language Models\n\n3. STREAMGUARD is trained based on datasets, rather than employing adaptive defense mechanisms. As a result, it may lack generalization when facing previously unseen risk patterns."}, "questions": {"value": "see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "U4TNK2e75D", "forum": "EBOPczQtCS", "replyto": "EBOPczQtCS", "signatures": ["ICLR.cc/2026/Conference/Submission24396/Reviewer_9vxC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24396/Reviewer_9vxC"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24396/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984144411, "cdate": 1761984144411, "tmdate": 1762943070856, "mdate": 1762943070856, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}