{"id": "JhziZbaefH", "number": 9106, "cdate": 1758111364142, "mdate": 1762997670026, "content": {"title": "Online Multimodal Learning with Human-in-the-Loop", "abstract": "We study the online multimodal learning (OML) problem, wherein a model is not frozen at any point in time but instead dynamically adapts its structure and parameters to learn new multimodal concepts and associations without forgetting the learned ones throughout its lifetime. To address this challenge, we propose a brain-inspired neural network with a hierarchical and modular architecture, named OML. Based on the characteristics of different hierarchies and modules, we design different types of artificial neuron models. The network includes ascending, descending, and lateral pathways, which ensure that all modalities can cooperate and interact with each other during online learning. Additionally, we develop a reference extraction algorithm that autonomously identifies the precise features to which a word refers. During online learning, the network performs conflict checking between the current input and the knowledge already learned from previous data. If a conflict occurs, the network is capable of posing appropriate questions to the user and updating itself based on the user's answers. All the designs make our method do learning like the way humans do. Experimental results demonstrate that our method can effectively handle the online multimodal learning.", "tldr": "", "keywords": ["Multimodal learning", "online learning", "human-in-the-loop learning", "reference understanding"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/47b518ed880824d14521847413e52bc2a063eff5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a multimodal network architecture capable of continuous learning. It achieves continuous learning through dynamic adjustments to the architecture and avoids forgetting existing knowledge when acquiring new knowledge. The proposed method is built on three network layers: Feature Neurons (FN) for handle distinct features of each modality; Unimodal Association Neurons (UAN) for enable the understanding of unimodal information concepts; and Multimodal Association Neurons (MAN) for synchronize cross-modal information. The architecture distinguishes and recognizes different concepts through bidirectional pathways between the three layers and lateral pathways within the same layer. During the continuous learning process, the network is continuously refined to address four typical human-in-the-loop conflict scenarios, thereby realizing online learning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.The network is rain-Inspired and have Well-Designed Architecture. Drawing inspiration from how the human brain processes multimodal information, the paper designs a three-layer network architecture. Through the \"ascending-descending-lateral\" pathway design, it achieves the association and processing of multimodal information. The network architecture is clearly defined and logically sound, with each layer and pathway fulfilling a specific functional role that aligns with the cognitive mechanism of multimodal information integration.  \n\n2.Comprehensive Experimental Validation of Feasibility. The paper verifies the feasibility of its method through experiments conducted in both closed and open environments. And in open environments, the experimental results show that the proposed method outperforms other approaches in continuous learning."}, "weaknesses": {"value": "1.Limited Experimental Scope. Current experiments primarily rely on domain-specific datasets and lack validation on more generalized or domain-specific multimodal datasets.\n2.Lack of Ablation Studies; Validation of Key Method Components Needed. The paper fails to validate the effectiveness of certain core components through ablation studies. Specific gaps include: No comparison of experimental results under different hyperparameter settings; No analysis of the impact of lateral connections in the network architecture on model performance.\n3.The feature selection rules for unimodal data, especially images, lack universality. \n4. Inadequate Description of Human-in-the-Loop Conflict Handling and Continuous Learning Details. The descriptions of human-in-the-loop conflict handling and continuous learning processes are insufficiently detailed."}, "questions": {"value": "1.Expansion of Comparative Experiments on Additional Datasets Recommended\n2.More ablation studies: like Compare models with and without lateral connections to clarify the role of lateral pathways in feature generalization.  \n3.Key figures, like Fig. 2, needs to be redrawn."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cAxW3EDjBF", "forum": "JhziZbaefH", "replyto": "JhziZbaefH", "signatures": ["ICLR.cc/2026/Conference/Submission9106/Reviewer_o2ai"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9106/Reviewer_o2ai"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9106/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761474638340, "cdate": 1761474638340, "tmdate": 1762920805090, "mdate": 1762920805090, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "hCKByvMKdn", "forum": "JhziZbaefH", "replyto": "JhziZbaefH", "signatures": ["ICLR.cc/2026/Conference/Submission9106/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9106/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762997669330, "cdate": 1762997669330, "tmdate": 1762997669330, "mdate": 1762997669330, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a multimodal learning model for online learning, avoiding catastrophic forgetting and using human-in-the-loop. The model is evaluated on two datasets: Fruit and HomeF."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "-\tOnline multimodal learning is a timely and still under-explored topic."}, "weaknesses": {"value": "-\tTheoretical assumptions: this paper makes a very strong assumption about the structure of the features given by unimodal pre-trained models. They assume a disentanglement between them (some of them would encode “shape”, others would encode “color” …). This is currently no clear evidence that foundation models such as SAM, CLIP or DINOv3 fulfil this assumption. \n-\tValidation of the model and benchmarking data: I struggled until the very end of the paper to understand a clear use-case of the proposed model. The issue with the current experimental setup is that it assumes the concepts are unknown to the model before training. Considering the simplicity of the concepts considered (e.g. common fruits or objects), and the fact that the authors used foundation models as pre-trained backbones (trained on web-scale data including most of the “simple” concepts), I believe the model is not learning anything new in its representation. There are no experiments showing that the trained model outperforms simple linear probes on top of the pre-trained backbones in the manuscript. Regarding the datasets used, they are very small (less than 30 objects) and not standard. I would expect a detailed description of these datasets and a justification of why they are more relevant than classical benchmarks in the field (e.g. HowTo100M, AudioSet, AV-Speech, etc…). Finally, no comparison is made with multimodal LLMs, which are currently leading the field. \n-\tAblation study: the network introduced on top of the pre-trained backbones is very complex, with a lot of ad-hoc choices (e.g. ascending/descending activation functions for feature neuron, association neuron, multimodal association neuron…). I would expect at least an ablation study on each of the component to justify its utility. Other fusion architectures (more common and simpler such as Transformer) should also be compared. \n-\tTraining and losses: since the authors mentioned “ascending” and “descending” pathways of the information between neurons, I am wondering how the network is trained. This is not mentioned in the original manuscript so I would assume a standard gradient-descent algorithm. If it is the case, I am wondering what is the loss function and how the descending pathway could be concretely implemented when performing the backpropagation.   \n-\t(Minor) The mathematical notations are very uncommon and unclear during the exposition of the model. I would expect less indexes in the variables to clarify the text."}, "questions": {"value": "Please, refer to the weaknesses detailed above for more context on the questions listed below:\n\n- Theoretical assumption: do you have papers or experiments suggesting this assumption holds in foundation models ? \n- Training and losses: what is the training strategy ? What loss is optimized ? How the \"descending pathway\" is implemented in practice ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "4gbA4DWAUe", "forum": "JhziZbaefH", "replyto": "JhziZbaefH", "signatures": ["ICLR.cc/2026/Conference/Submission9106/Reviewer_xt4H"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9106/Reviewer_xt4H"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9106/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761843647531, "cdate": 1761843647531, "tmdate": 1762920804421, "mdate": 1762920804421, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the problem of online multimodal learning and proposes a brain-inspired neural network named OML, which adopts a hierarchical and modular design. Specifically, OML is composed of multiple hierarchical components, including feature neurons, unimodal association neurons (UANs), and multimodal association neurons (MANs). The model integrates ascending, descending, and lateral pathways to facilitate cooperative and interactive learning across modalities in an online setting. Experiments are conducted on the multimodal datasets within the Fruit category and demonstrate that OML achieves superior performance compared to SOTA methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "+ The paper is well-motivated and technically sound, addressing an important problem in online multimodal learning.\n+ The proposed OML framework introduces an interesting and intuitive idea inspired by human cognitive mechanisms for learning new multimodal concepts and new associations across multiple modalities in an online manner.\n+ The proposed OML framework can detect conflict between the current input and the learnt ones, and check with the users for correctness.\n+ The experiments demonstrate the superiority of the proposed method over SOTA methods in the online multimodal learning task."}, "weaknesses": {"value": "- The paper is difficult to follow due to the heavy use of mathematical notations. Many notations are similar or insufficiently explained, and their definitions are scattered throughout the text, forcing readers to frequently refer back and significantly reducing readability.\n- One concern is the scalability to a broader range of multimodal tasks. The model adds new concepts when no similar ones are found in memory and no conflicts exist. However, in real-world settings with highly diverse domains and abundant concept variations, it is uncertain how well this mechanism can extend or adapt.\n-The experimental validation is limited to a relatively simple dataset (Fruits), which restricts the assessment of OML’s generalization ability to more complex and diverse domains (e.g., animals, furniture, or other domains).\n- The robustness to noisy or mispaired data seems to be weak. When neither the visual nor the auditory input is recognized, the model introduces new MANs and pathways, which could lead to incorrect concept formation if the input pairs are mismatched. Moreover, the framework lacks a mechanism to correct or unlearn such erroneous associations once they are established."}, "questions": {"value": "Please address the concerns mentioned in the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "urJB6atECP", "forum": "JhziZbaefH", "replyto": "JhziZbaefH", "signatures": ["ICLR.cc/2026/Conference/Submission9106/Reviewer_vTXW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9106/Reviewer_vTXW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9106/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966676872, "cdate": 1761966676872, "tmdate": 1762920804009, "mdate": 1762920804009, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces OML, a hierarchical neural network designed for online multimodal learning, which allows the model to continuously learn new concepts and associations without forgetting previously learned ones. The network's key features include a \"conflict check'' mechanism that identifies discrepancies between new inputs and existing knowledge, and the ability to interactively query a human user for clarification when such conflicts occur. The model also employs a ``reference extraction algorithm'' to determine which specific features, e.g., color vs. shape, a word refers to. Experiments demonstrate that OML avoids catastrophic forgetting in open-ended learning environments and outperforms other methods in tasks requiring precise feature referring and the addition of new modalities."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper studies the problem of multimodal continual learning, which is an important topic for practical deployment consideration.\n2. The experimental results demonstrate the effctiveness of the proposed method over included baselines."}, "weaknesses": {"value": "1. The paper's presentation is unsatisfactory, particularly in positioning the proposed work. The authors fail to explicitly identify their approach as continual learning, instead discussing it under the broader category of multimodal learning. This imprecision undermines both the Introduction and Related Work sections, which lack sufficient depth and focus. The inadequate framing suggests the manuscript has not been thoroughly refined and polished.\n\n2. The proposed algorithm exhibits insufficient innovation. The method follows a relatively common approach in continual learning known as Parameter Isolation, such as dynamic architecture expansion. This strategy is established in the continual learning literature but is not clearly acknowledged and discussed for the differences with the proposed method.\n\n3. The experimental evaluation lacks adequate baseline methods for assessing performance in continual learning scenarios. The authors should include a more comprehensive set of state-of-the-art continual learning methods for comparison. \n\n4. The experimental section does not specify whether the reported results represent averages over multiple runs or single-run outcomes. This information is crucial for assessing the stability and reliability of the model's performance, particularly in the continual learning setting where variability across learning sequences can be significant.\n\n5. Another key consideration in continual learning methods is the efficiency of model updates. However, this paper provides no evaluation or comparison of update efficiency, which represents a significant gap in the experimental analysis. Such computational cost are essential metrics for practical continual learning systems and should be thoroughly assessed."}, "questions": {"value": "Please refer to the above weakness for details."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Jbpvx4NPZB", "forum": "JhziZbaefH", "replyto": "JhziZbaefH", "signatures": ["ICLR.cc/2026/Conference/Submission9106/Reviewer_W4ES"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9106/Reviewer_W4ES"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9106/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762011614240, "cdate": 1762011614240, "tmdate": 1762920803714, "mdate": 1762920803714, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}