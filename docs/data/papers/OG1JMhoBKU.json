{"id": "OG1JMhoBKU", "number": 12475, "cdate": 1758208086556, "mdate": 1759897507375, "content": {"title": "LogiStory: A Logic-Aware Framework for Multi-Image Story Visualization", "abstract": "Generating coherent and communicative visual sequences, such as image sequences and videos, remains a significant challenge for current multimodal systems. Despite advances in visual quality and the integration of world knowledge, existing models still struggle to maintain logical flow, often resulting in disjointed actions, fragmented narratives, and unclear storylines. We attribute these issues to the lack of attention to visual logic, a critical yet underexplored dimension of visual sequence generation that we define as the perceptual and causal coherence among characters, actions, and scenes over time. \nTo bridge this gap, we propose a logic-aware multi-image story visualization framework, LogiStory.\nThe framework is built around the central innovation of explicitly modeling visual logic in story visualization. To realize this idea, we design a multi-agent system that grounds roles, extracts causal chains, and verifies story-level consistency, transforming narrative coherence from an implicit byproduct of image generation into an explicit modeling objective. This design effectively bridges structured story planning with visual generation, enhancing both narrative clarity and visual quality in story visualization.\nFurthermore, to evaluate the generation capacity, we construct LogicTale, a benchmark comprising richly annotated stories, emphasizing causal reasoning, and visual logic interpretability.\nWe establish comprehensive automatic and human evaluation protocols designed to measure both visual logic and perceptual quality. \nExperiments demonstrate that our approach significantly improves the narrative logic of generated visual stories. This work provides a foundational step towards modeling and enforcing visual logic in general image sequence and video generation tasks.", "tldr": "We propose LogiStory, a logic-aware story visualization framework that enhances visual and narrative coherence via multi-agent planning and logic verification. We also introduce LogicTale for evaluation.", "keywords": ["Visual Storytelling", "Multi-Image Sequence Generation", "Story Planning", "Visual Logic Consistency", "Causal Reasoning", "Narrative Coherence"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fd9023ea64a618b314b3ab00cbadf216001cbab7.pdf", "supplementary_material": "/attachment/bc3f3bda6323afd95a110bcb773b8cabfe57cc07.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a logicaware multi-image story visualization framework, LogiStory. The framework is built around the central innovation of explicitly modeling visual logic in story visualization. This paper also introduces LogicTale, a benchmark comprising richly annotated stories, emphasizing causal reasoning, and visual logic interpretability."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- This paper introduces LogicTale, a new benchmark comprising richly annotated stories based on not only classical stories but also original stories, to validate on new stories.\n- This paper also proposes a logicaware multi-image story visualization framework, LogiStory to address the challenges of visual consistency and logical coherence in a series of story visualizations by constructing a new benchmark dataset. The results show high performance of LogiStroy on LogicTale.\n- LogiStroy was evaluated on ViStoryBench-Lite to assess the generalizability of the framework. Ablation studies are also included to evaluate each module."}, "weaknesses": {"value": "- The framework is composed of a complex pipeline based on a multi-agent system. \n- The evaluation dimensions using LogiStory and the focus points of the agents are closely related, which raises the possibility that the framework may be somewhat dependent on the evaluation aspects."}, "questions": {"value": "- It was stated that \"no existing benchmark systematically measures whether a visual sequence, either image-based or video-based, successfully communicates the intended story in a logically coherent manner,\" but VinaBench[1] is a benchmark dataset that considers commonsense links and visual consistency as visual narrative generation.\n\n[1] VinaBench: Benchmark for Faithful and Consistent Visual Narratives（CVPR2025）\n\n- Will the benchmark dataset, source code, and checkpoints be made publicly available?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MbxaGmmqyf", "forum": "OG1JMhoBKU", "replyto": "OG1JMhoBKU", "signatures": ["ICLR.cc/2026/Conference/Submission12475/Reviewer_wuEE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12475/Reviewer_wuEE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12475/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761651573697, "cdate": 1761651573697, "tmdate": 1762923352441, "mdate": 1762923352441, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a significant and well-known challenge in visual sequence generation: the lack of logical and causal coherence. The authors argue that while current models excel at generating high-fidelity images, the resulting sequences often fail as narratives, presenting disjointed actions and fragmented storylines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The problem proposed in this paper is convincing. The motivation of the paper is very clear. It correctly identifies a key gap in generative models—moving beyond single-image fidelity to narrative coherence. The explicit modeling of \"visual logic\" is a significant conceptual contribution.\n\n- The creation of the LogicTale benchmark is a valuable contribution to the community."}, "weaknesses": {"value": "- The proposed framework is complex, involving three distinct planner agents, a global causal graph, a state recorder, a local memory buffer, and a two-stage verification loop.\n\n- The scale of the benchmark is too small to fully evaluate the method."}, "questions": {"value": "- I am curious about the computational cost required to generate a story. How many refinement steps (either full regeneration or editing) are typically required per story? Does this number vary significantly with the 'Hard' difficulty stories?\n\n- How robust is this LogicMiner agent to variations in narrative style? Does it perform equally well on highly implicit causality (e.g., \"The dog, remembering his master, felt sad\") versus the explicit physical causality shown in the examples (e.g., \"crow put pebbles into the cup,\" -> \"rising water level\" )?\n\n- The baseline naming in the results is slightly inconsistent. Section 5.1 lists GPT-4-image-1 as a closed-model baseline. However, Table 1 lists GPT4o-+GPT-image-1 , and Section 5.2.1 discusses the performance of GPT-4o. Could you clarify if these are the same model, or if GPT40-+GPT-image-1 implies a pipeline using two different models?\n\n- The qualitative results are very strong. To help the community understand the current boundaries of LogiStory, would it be possible to include a qualitative example of a failure case, perhaps from one of the 'Hard' stories? This would provide valuable context for the acknowledged limitation in \"high-entity scenarios\"."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Zi14n6Yx1h", "forum": "OG1JMhoBKU", "replyto": "OG1JMhoBKU", "signatures": ["ICLR.cc/2026/Conference/Submission12475/Reviewer_dd8Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12475/Reviewer_dd8Q"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12475/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761826533805, "cdate": 1761826533805, "tmdate": 1762923351790, "mdate": 1762923351790, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents LogiStory, a framework for generating multi-image visual stories with a focus on logical coherence. The authors introduce the concept of \"visual logic\" and propose a multi-agent system to plan the narrative, combined with verification modules to refine the generated images. To evaluate their approach, they construct a new benchmark, LogicTale. The paper is well-written, and the problem it addresses is both interesting and relevant to the community."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.  **Interesting and Important Task:** The paper successfully highlights \"visual logic\" as a critical dimension in visual storytelling. This focus enriches the task by moving beyond per-image quality to sequence-level narrative coherence, which is an important and challenging problem.\n\n2.  **Effective Framework Design:** The proposed framework, with its planning and verification stages, appears to be an effective solution to the problem identified. The qualitative results demonstrate its capability to produce more logically consistent visual narratives compared to several strong baselines.\n\n3.  **Contributions of a New Benchmark:** The introduction of the LogicTale benchmark is a valuable contribution. It provides a dedicated resource for evaluating narrative logic, and the paper's experiments on this benchmark effectively showcase the performance of the proposed method."}, "weaknesses": {"value": "1.  **Limited Novelty in Core Methodology:** While the overall system is well-engineered, the primary contribution appears to be the careful orchestration of existing, powerful models (LLMs, MLLMs, and diffusion models like Flux) into a sophisticated pipeline. The novelty in terms of fundamental model architecture or learning paradigms seems limited. \n\n2.  **System Complexity and Robustness Concerns:** The framework's effectiveness seems heavily dependent on the consistent and reliable performance of each component model (e.g., the agents). As a multi-stage pipeline, it is susceptible to error propagation, where an issue in an early stage could negatively impact the entire sequence. Additionally, this cascaded design naturally incurs significant computational overhead and latency, which could be a practical concern.\n\n3.  **Fairness of Experimental Comparison:** The experiments compare LogiStory, a highly customized pipeline for this specific task, against end-to-end models like GPT-4o and Gemini. This comparison, while informative, may not be entirely fair, as the proposed method leverages the combined strengths of multiple specialized models. It would be beneficial to discuss or explore fairer comparison settings, perhaps by comparing against other modular pipelines or by breaking down the performance gains attributable to each component."}, "questions": {"value": "My main questions are related to the weaknesses detailed above. In addition, I would like to ask the following:\n\n1. **Robustness of the MLLM-based evaluation metrics:**  For instance, during the VQA-based `Narrative Causality` assessment, how can we distinguish between failures of the \"evaluator\" MLLM and genuine logical flaws in the generated images? Have you conducted any analysis on the reliability of the evaluator models themselves?\n\n2.  The Global Causal Verifier relies on a pre-constructed causal graph. How does the framework handle stories with very complex, non-linear, or ambiguous causal structures?\n\nI would be open to raising my score should the authors address the concerns noted above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3OvVZoF0pX", "forum": "OG1JMhoBKU", "replyto": "OG1JMhoBKU", "signatures": ["ICLR.cc/2026/Conference/Submission12475/Reviewer_GhPS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12475/Reviewer_GhPS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12475/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761915580300, "cdate": 1761915580300, "tmdate": 1762923351485, "mdate": 1762923351485, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the concept of \"visual logic\" to address the challenge of generating causally and perceptually coherent visual story sequences. The authors define visual logic as the perceptual and causal coherence among characters, actions, and scenes over time. To tackle this, they propose `LogiStory`, a framework composed of two main parts:\n1.  **Logic-Aware Multi-agent System:** This system performs structured narrative planning. It uses three agents (`SceneCrafter`, `LogicMiner`, `ShotPlanner`) to decompose a story text $S$ into character/object definitions $E$, extract a causal chain of key events $K$, and plan a sequence of detailed visual shot specifications $P = \\\\{p_1, ..., p_T\\\\}$.\n2.  **Visual Logic Enhancement Module:** This module enforces coherence during the generation of the image sequence $I = \\\\{I_1, ..., I_T\\\\}$. It includes:\n    *   A **Local Causal Monitor** that checks step-by-step narrative plausibility by calculating a causal score $\\\\psi_t = C_p(I_t | M_{t-1})$ based on a memory buffer $M_{t-1}$.\n    *   A **Global Causal Verifier** that uses a story-level causal graph $G_{causal}$ to validate state transitions and guide an image refinement process based on predefined thresholds $\\\\tau_1$ and $\\\\tau_2$.\n\nTo facilitate development and evaluation, the authors construct `LogicTale`, a new benchmark of 60 stories with rich annotations for causal events. They also propose a comprehensive evaluation protocol that measures \"visual logic\" and perceptual quality. Experiments show that `LogiStory` significantly outperforms strong open-source and closed-source baselines, particularly in metrics related to narrative logic and readability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.  **Novel and Important Problem Formulation:** The paper's primary strength is its formalization and focus on \"visual logic.\" This provides a clear, principled target for a key failure mode of current generative models—the lack of narrative and causal coherence in sequences.\n2.  **Well-Designed and Interpretable Framework:** `LogiStory` is a thoughtfully engineered system. The multi-agent planner provides an interpretable intermediate representation, and the dual-level verification (local and global) robustly enforces logical consistency.\n3.  **Comprehensive and Rigorous Evaluation:** The experimental evaluation is a major strength. The authors compare against a wide range of powerful baselines, including top-tier commercial models, and use a combination of automatic and human studies for robust validation.\n4.  **Creation of a Valuable Benchmark:** `LogicTale` is a significant contribution in its own right, enabling the community to move beyond simple frame-level metrics and systematically evaluate the storytelling capabilities of generative models.\n5.  **Exceptional Clarity and Presentation:** The paper is written with outstanding clarity. Complex ideas are explained intuitively, and the high-quality figures and detailed appendix make the work easy to understand and reproduce."}, "weaknesses": {"value": "1.  **Scale of the LogicTale Benchmark:** The most apparent weakness is the scale of the `LogicTale` benchmark (60 stories). While the authors justify this with a saturation analysis, a larger dataset would provide stronger evidence for the generalizability of the findings.\n2.  **Reliance on MLLMs for Automatic Evaluation:** The automatic evaluation protocol for core visual logic metrics relies on judgments from MLLMs, which raises concerns about potential evaluation bias (an \"LLM-evaluating-LLM\" loop). While mitigated by high correlation with human ratings, this is a methodological limitation.\n3.  **Complexity and Latency:** `LogiStory` is a multi-stage pipeline involving several LLM/MLLM calls, which likely entails significant computational cost and latency. A discussion on the framework's efficiency and robustness to component failures would be beneficial.\n4.  **Insufficient Ablation of Refinement Mechanism:** The paper states that refinement is done via \"image editing tools\" for scores in the range $[\\\\tau_1, \\\\tau_2)$. A more detailed analysis or ablation of this step (e.g., frequency of use, comparison to simple regeneration) would strengthen the paper."}, "questions": {"value": "1.  **On Evaluation and Potential Bias:** Did you experiment with different families of MLLMs for evaluation (e.g., using an open-source model to evaluate proprietary model outputs) to test the robustness of the evaluation scores?\n2.  **On the `LogicMiner`'s Robustness:** The `LogicMiner` agent is crucial for constructing the causal graph. How robust is its capability to infer implicit events, especially for subtle logic? What are its common failure modes, and how does the framework handle an incorrect causal graph?\n3.  **On Verifier Interaction:** In Table 3, the `Instance Consistency` score for \"Ours (w/ local)\" is 4.24, while for \"Ours (w/ both)\" it is 4.23. This is a minor, perhaps insignificant, difference. Could you offer any insight into why adding the `Global Causal Verifier` might not strictly improve this specific metric?\n4.  **On the Refinement Process:** Regarding the image refinement step triggered when $\\\\psi_t \\\\in [\\\\tau_1, \\\\tau_2)$, could you provide statistics from your experiments on the frequency of this action (accept vs. refine vs. regenerate)? What is the computational overhead of this step compared to a simple regeneration?\n5.  **On Scalability:** How do you envision the framework scaling to more complex narratives with many characters, parallel plotlines, or non-linear temporal structures? Would the current causal graph representation be sufficient?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hz3joNIzLr", "forum": "OG1JMhoBKU", "replyto": "OG1JMhoBKU", "signatures": ["ICLR.cc/2026/Conference/Submission12475/Reviewer_oUdB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12475/Reviewer_oUdB"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12475/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761987913017, "cdate": 1761987913017, "tmdate": 1762923350766, "mdate": 1762923350766, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}