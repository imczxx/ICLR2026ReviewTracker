{"id": "bbuxDoRD2D", "number": 15311, "cdate": 1758250178799, "mdate": 1759897314317, "content": {"title": "Efficient Spatially-Variant Convolution via Differentiable Sparse Kernel Complex", "abstract": "Image convolution with complex kernels is a fundamental operation in photography, scientific imaging, and animation effects, yet direct dense convolution is computationally prohibitive on resource-limited devices. \nExisting approximations, such as simulated annealing or low-rank decompositions, either lack efficiency or fail to capture non-convex kernels.\nWe introduce a differentiable kernel decomposition framework that represents a target spatially-variant, dense, complex kernel using a set of sparse kernel samples. Our approach features (i) a decomposition that enables differentiable optimization of sparse kernels, (ii) a dedicated initialization strategy for non-convex shapes to avoid poor local minima, and (iii) a kernel-space interpolation scheme that extends single-kernel filtering to spatially varying filtering without retraining and additional runtime overhead.\nExperiments on Gaussian and non-convex kernels show that our method achieves higher fidelity than simulated annealing and significantly lower cost than low-rank decompositions. Our approach provides a practical solution for mobile imaging and real-time rendering, while remaining fully differentiable for integration into broader learning pipelines.", "tldr": "This work introduces a differentiable framework for decomposing complex kernels into optimized sparse layers, enabling high-performance, spatially-varying filtering via a filter-space interpolation scheme.", "keywords": ["Kernel Approximation", "Differentiable Filtering", "Spatially-Varying Convolution", "Efficient Image Processing"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/139ac3378e6de29fd4199f86295540db432cee28.pdf", "supplementary_material": "/attachment/2547517ca8f2a7ac2de8000f1d543baac6ec81df.zip"}, "replies": [{"content": {"summary": {"value": "Image convolution with large and complex kernels is computationally heavy. This paper follows a line of research seeking to reduce computational costs through kernel decomposition, using an approximation that achieves both expressibility and efficiency. The paper proposes a method for initializing a differentiable set of sparse kernels and a kernel-space interpolation method for spatially varying kernels. In both single-kernel and spatially-varying-kernel applications, the proposed method shows improvements in speed, quality, and sample efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Consistent and strong performance improvement over baselines across two different sets of experiments (single kernel and spatially varying kernel).\n- Well-written paper, easy to follow and understandable with proper figures."}, "weaknesses": {"value": "- **Role of initialization in optimization**: The relationship between initialization and optimization, which appears central to the paper, could be emphasized more clearly. Considering the components affecting both single- and spatially-varying kernel cases, the initialization of the sparse kernel set seems to be a core contribution. Other concepts, such as sparse kernel sets and Dirac delta function-based optimization, have been explored in prior work. Therefore, it is plausible that the improved results primarily stem from the proposed initialization. The paper would be strengthened by an analysis from an optimization perspective, explaining why existing methods struggle, how the proposed initialization addresses these issues, and how it leads to better performance—potentially supported by optimization curves.\n- **Limited experiments**: Adding a comparison for single-kernel filtering (i.e., applying the kernels directly to images, not just approximating them) would offer a more complete evaluation of the method’s effectiveness."}, "questions": {"value": "- Could the authors provide more insight from an optimization perspective on why the proposed sparse kernel set initialization outperforms existing methods? For example, how it alleviates issues in previous approaches and leads to better convergence or performance, potentially supported by optimization curves?\n- For Fig. 7 in the appendix, why do the curves for 'Ours 32 x 4' and 'PST 32 x 4' fluctuate instead of showing a monotonic downward trend?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rqK7ybST1B", "forum": "bbuxDoRD2D", "replyto": "bbuxDoRD2D", "signatures": ["ICLR.cc/2026/Conference/Submission15311/Reviewer_1x3B"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15311/Reviewer_1x3B"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15311/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761510849602, "cdate": 1761510849602, "tmdate": 1762925609517, "mdate": 1762925609517, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a gradient-based optimization strategy to learn a sequence of sparse convolutional kernels whose sequential application approximates a large, dense convolutional kernel using far less computation than the standard dense convolution. The main innovation in implementing this idea is an initialization strategy for the positions of the sparse (nonzero) components in each of the sequential sparse filters, which is fairly heuristic (balancing fit with the target kernel and leveraging of kernel support expansion via repeated convolution) yet empirically effective. This idea is also extended to spatially varying convolutional kernels, e.g. to model a realistic point spread function as it varies across the field of view. This is done by pre-training a set of basis filters (each of which uses sequential sparse convolution) and then combining these basis filters with spatially varying weights."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Figure 1a is a compelling illustration of the main idea of the method, approximating a dense (e.g. Gaussian) kernel with fairly large spatial extent as a sequence of sparse kernel convolutions whose net computational cost is far less than the cost of a standard convolution with the dense kernel.\n\nI appreciate that the experiments seem to be fair (or more than fair) towards the baselines, in the sense that equal or greater parameters and computation time were afforded to the baselines as to the proposed method. However, I am not an expert in the kernel approximation literature so I take the appropriateness of the chosen baselines at face value.\n\nFigure 5’s illustration of efficient spatially varying filtering is particularly compelling."}, "weaknesses": {"value": "There are aspects of the presentation that could be improved:\n- The abstract describes “convolution with complex kernels”--at this point in the paper, it is unclear whether “complex” means “real plus imaginary” or “complicated”. More generally, the abstract does not clearly explain the task being solved, specifically whether the dense, spatially-varying kernel to be approximated is known in advance or unknown and to be inferred from measurements (after reading the rest of the paper, it seems the former is the goal). This should be made clear early on.\n- Section 2.3 summarizes a bunch of related papers, but does not explain their limitations or their relationship with the proposed method. \n- The Charbonnier L1 loss in equation 11 is not defined.\n- The font sizes in figures 3 and 4 are too small. It might be preferable to choose one Gaussian scale for the main paper so that the figures could be larger and arranged with PST in one row and “ours” in the other, making the figure easier to interpret (the other Gaussian scale could be shown in the supplement if there is not enough space in the main text). Both sets of figures also include a green and red visualization in the top left of each subfigure (perhaps an error map?) that is not described. Figure 4 also has a number (perhaps a measure of computation time?) in the bottom right of each subfigure, that is not described. Figure 4 caption says “our approach (blue)” but I do not see any blue in the figure.\n\nIn terms of the method itself, the main limitation is that it requires knowledge of the target dense filter, for example by calibration. For settings where the kernel is not known or is difficult to calibrate, it would be preferable to be able to jointly solve for the (spatially varying) PSF and apply it efficiently. The primary obstacle to using the proposed method for that goal is that the initialization strategy for the sparse kernels requires knowledge of the dense kernel. I’d at least like to see this limitation mentioned/discussed, even if addressing it is beyond the scope of this paper."}, "questions": {"value": "As the focus is mainly on improving the speed at which a convolutional kernel can be applied to an image, I wonder what is the computational overhead of pre-optimizing a sparse sequence of filters?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JtfDp09Njy", "forum": "bbuxDoRD2D", "replyto": "bbuxDoRD2D", "signatures": ["ICLR.cc/2026/Conference/Submission15311/Reviewer_BSUK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15311/Reviewer_BSUK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15311/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761850457667, "cdate": 1761850457667, "tmdate": 1762925608847, "mdate": 1762925608847, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper formulates the efficient convolution problem as an optimization problem involving a few \"layers\" of sparse discrete convolution operators that are applied in succession. This differentiable formulation enables gradient-based optimizers to find sparse filters that approximate target convolutions by matching their impulse response to the target. The resulting method is quick to optimize, quick to run, and uses little runtime memory. The authors further propose a robust initialization scheme which they verify improves the optimization quality via ablations. Additionally, they propose an time-and memory-efficient way to allow for spatially varying convolutions -- albeit only allowing for a 1D parameter value -- by linearly interpolating between pre-computed \"basis\" sparse filters where the interpolation weights are determined by the per-pixel parameter value. Overall, the paper presents an effective, simple-to-implement way of performing efficient discrete image convolutions."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "- Good-looking results! The supplementary video shows the proposed sparse convolutions producing results visually indistinguishable from the ground-truth.\n- Speed and memory requirements are both greatly improved from competing efficient convolution approaches.\n- Simple to implement on desktop GPUs or mobile platforms (though pseudocode or code would be appreciated)"}, "weaknesses": {"value": "Since (I believe) the optimization problem in eq. (11) is non-convex in the (offset, weight) parameters, partly due to the dependence of one layer's input on the previous layer's outputs, it's unclear to me how robust the optimization is with respect to vastly different number of samples, and number of layers, or how well it works with even more intricate point-spread functions. If the authors included more robustness tests and described how they tuned (if at all) the optimization hyperparameters such as the optimizer and learning rates, I would find the results much more convincing. \n\n(Minor weakness) Unclear how well linear interpolation will work with multi-dimensional parameter values: naively, the number of basis filters will need to grow exponentially in D, the dimensionality. On the other hand, only having one spatially-varying parameter value feels limiting to me."}, "questions": {"value": "In addition to latency/FPS numbers, can you also provide peak VRAM or CPU RAM usage numbers? This seems important to me because being more memory efficient is one of the method's advantages. \n\nHave you considered second-order-ish optimizers? In many cases the number of parameters sounds small enough that it's probably tractable. But then the optimization is also probably not-so-convex.\n\nMinor typos/suggestions:\nI believe most of the citations in the paper should be of the form \\citep instead of \\citet. \nAt L283, it's not clear how the actual interpolation weights are decided from P(x, y)\nL341 says \"single GPU with computational power equivalent to an NVIDIA RTX 4090.\" I'm guessing that it's just an L40S, RTX 6000 Ada, or a RTX 4090D? I think it's okay to omit the details, but it'd be helpful to include the VRAM capacity.\nL347 is probably talking about a \"Snapdragon\" 8 Gen 3? The \"Snapdragon\" is missing from the text\nIn Fig. 4 \"ring\", any idea how \"Ours 24×4\" looks better than \"Ours 36×4?\" Is it just due to random initialization?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7CMV9Pshcs", "forum": "bbuxDoRD2D", "replyto": "bbuxDoRD2D", "signatures": ["ICLR.cc/2026/Conference/Submission15311/Reviewer_jzA7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15311/Reviewer_jzA7"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15311/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761868079728, "cdate": 1761868079728, "tmdate": 1762925608294, "mdate": 1762925608294, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work addresses a significant limitation in practical applications for spatially varying blur effects in computation photography using  image convolution with kernels. Usually Gaussian kernel is considered a standard kernel. However, Gaussian kernels are slow on computationally low-end devices (due to their dense M^2 complexity). To encounter, this paper proposes layer-wise filtering where a kernel is represented by L layers, where each layer has a kernel K with only N samples. Each kernel K is applied to an image resulting in much smllaer number of weights compared to M^2 weights in an ordinary dense kernel of pixel footprint M^2."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Propose a robust and fast approach to perform image convolutions\n- Decouples filter generation from the  spatial resolution by introducing filter space interpolation\n- The idea is simple and effective\n- Results are very convincing."}, "weaknesses": {"value": "- The paper needs to do a bit more job in explaining the relation wrt A-trous filters or max-pooling like approaches used in U-Nets for increasing the receptive field of kernels.\n\n- Please always mention how to read different metric values (higher is better or lower is better). \n\n- There are no theoretical guarantees provided that explains why layered kernels would be robust in general. \n\nPlease see my questions below that also directly highlight my concerns."}, "questions": {"value": "- How do you obtain a blur intensity map that is conditioned for the filter generation process? \n- How the whole process of structuring a filter as layers different from a convolution followed by e.g, apply max pooling to an image and then applying the same filter to the image? It will automatically increases the receptive field of the kernel without any additional cost to computing kernel weights\n- What is the similarity of the approach to the A-trous filters where the number of learnable parameters remain the same despite the receptive field?\n- How the kernels adapt the anisotropy of the signal? What if you want nice anisotropic bokeh effect for artistic purposes?\n- What are “filter objects” in L291? \n- It is not clear what objects are interpolated? Is it the interpolation between the trained parameters \\alpha_k?\n- I would like more explanation on the implementation details. How the optimization works? You convolve a kernel with a Dirac function, this gives you an image with a single non-zero pixel. This image is then matched to a target image with a target kernel applied to a Dirac function. Is my understanding correct?\n- Also, how this idea of layered kernels different from what is used in CNNs or U-Nets?\n\nFigure 1 should appear early in the paper (on the second page), or better as a teaser on the first page."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WKvEWTHpWj", "forum": "bbuxDoRD2D", "replyto": "bbuxDoRD2D", "signatures": ["ICLR.cc/2026/Conference/Submission15311/Reviewer_cyNF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15311/Reviewer_cyNF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15311/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995465863, "cdate": 1761995465863, "tmdate": 1762925607830, "mdate": 1762925607830, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}