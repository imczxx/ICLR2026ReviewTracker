{"id": "4jECZ8epaB", "number": 13972, "cdate": 1758226248617, "mdate": 1763692648910, "content": {"title": "A Tale of Two Problems: Multi-Objective Bilevel Learning Meets Equality Constrained Multi-Objective Optimization", "abstract": "In recent years, bilevel optimization (BLO) has attracted significant attention for its broad applications in machine learning.\nHowever, most existing works on BLO remain confined to the single-objective setting and rely on the lower-level strong convexity assumption, which significantly restricts their applicability to modern machine learning problems of growing complexity.\nIn this paper, we make the first attempt to extend BLO to the multi-objective setting under a relaxed lower-level general convexity (LLGC) assumption.\nTo this end, we reformulate the multi-objective bilevel learning (MOBL) problem with LLGC into an equality constrained multi-objective optimization (ECMO) problem.\nThis transformation yields a single-level formulation that is more amenable to algorithm design while preserving the optimal solutions of the original MOBL problem.\nHowever, ECMO itself is a new problem that has not yet been studied in the literature, with no existing results on its algorithmic design or theoretical analysis, and without a formally established convergence metric.\nTo address this gap, we first establish a new Karush–Kuhn–Tucker (KKT)-based Pareto stationarity as the convergence criterion for ECMO algorithm design.\nBased on this foundation, we propose a weighted Chebyshev (WC)-penalty algorithm that achieves a finite-time convergence rate of $\\mathcal{O}(ST^{-\\frac{1}{2}})$ to KKT-based Pareto stationarity in both deterministic and stochastic settings, where $S$ denotes the number of objectives, and $T$ is the total iterations.\nMoreover, by varying the preference vector over the $S$-dimensional simplex, our WC-penalty method systematically explores the Pareto front.\nFinally, solutions to the ECMO problem translate directly into solutions for the original MOBL problem, thereby closing the loop between these two foundational optimization frameworks.\nWe verify the efficacy of our approach through experiments on multi-objective data weighting in reinforcement learning from human feedback (RLHF) reward model training and large language model (LLM) alignment.", "tldr": "", "keywords": ["Multi-objective optimization", "Bilevel optimization", "Preference."], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bc1bcabf9230835bf6580d449f4c333a07ab3be5.pdf", "supplementary_material": "/attachment/018213e6c23767e01e1c11cf1c41b448ae7c0fa6.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses the challenging Multi-Objective Bilevel Learning (MOBL) problem under the relaxed Lower-Level General Convexity (LLGC) assumption, overcoming limitations of prior work relying on restrictive strong convexity. The authors propose an elegant reformulation of MOBL into an Equality Constrained Multi-Objective Optimization (ECMO) problem, establishing the first rigorous theoretical foundation for this novel problem class. Key contributions include defining KKT-based Pareto stationarity as the convergence criterion for ECMO and developing the Weighted Chebyshev Penalty (WC-Penalty) algorithm, which achieves a finite-time convergence rate of \\(O(ST^{-1/2})\\) under standard assumptions."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper's primary strength lies in its innovative theoretical framework, which elegantly transforms the challenging LLGC-MOBL problem into an ECMO formulation, circumventing the ill-defined hyper-gradient issue under general convexity. The establishment of KKT-based Pareto stationarity as a rigorous convergence criterion for ECMO resolves a critical gap in the literature, while the WC-Penalty algorithm provides the first finite-time convergence guarantee (\\(O(ST^{-1/2})\\)) for this problem class."}, "weaknesses": {"value": "The algorithm's practical utility is hampered by insufficient guidance on tuning critical parameters $u$, $v$, and $\\eta$, as the theoretical scaling $u = v = \\Theta(T^{1/4})$ and $\\eta = \\Theta(T^{-1/4})$ is impractical for fixed computational budgets, with no heuristics provided for implementation. Computational scalability remains unaddressed, as the per-iteration cost involves gradients for all $S$ objectives and $q$ constraints (including Hessians $\\nabla^2_{yy} g(x,y)$), which could become prohibitive for high-dimensional problems or large $S/q$. Experimental validation is limited to small-scale data weighting tasks, lacking evaluation on high-dimensional parameters (e.g., full LLM fine-tuning), large sample sizes, or problems with many objectives/constraints where the $O(ST^{-1/2})$ degradation would be evident. The baseline comparison is narrow, omitting recent state-of-the-art LLGC-BLO methods and general constrained multi-objective optimizers, leaving the relative advantage of the ECMO approach under-evaluated. Results rely solely on visual Pareto front comparisons without quantitative metrics (e.g., Hypervolume) or statistical significance testing, and critical ablations (e.g., WC vs. linear scalarization, penalty formulation alternatives) are entirely missing.\n\nThe theoretical foundation relies on an overly restrictive Assumption 2 ($\\sigma_{\\min}(\\nabla h(z)) \\geq \\sigma > 0$ globally), which is unlikely to hold in complex non-convex problems and contradicts the paper's motivation of relaxing LLSC for broader applicability, as it imposes stringent non-degeneracy conditions on $\\nabla^2_{yy} g(x,y)$. The proof of Theorem 3 contains significant gaps: controlling the complementary slackness term $[\\min\\{\\omega_s, \\rho - \\lambda_s f_s(z)\\}]_{s \\in [S]}$ requires non-trivial analysis of slack variables $\\delta_s$ that is inadequately addressed, and the construction/bounding of dual variables $\\omega_t, \\nu_t$ (not computed by the algorithm) is relegated to the appendix without justification. The KKT residual metric in Definition 5 is mathematically imprecise, as $\\min\\{\\omega_s, \\rho - \\lambda_s f_s(z)\\} \\leq \\epsilon$ does not guarantee complementary slackness $\\omega_s (\\rho - \\lambda_s f_s(z)) \\approx 0$. Key insights, such as counterexamples invalidating the intuitive KKT condition guess ($\\nabla F(z)\\alpha + \\nabla h(z)v = 0$), are buried in Appendix C rather than highlighted in the main narrative to motivate the rigorous WC-scalarization approach. While minor, the practical handling of the $f_s(z) > 0$ assumption in Theorem 2 (e.g., constant selection in experiments) is also underdiscussed. Please correct me if I was wrong."}, "questions": {"value": "Please refer to the above weakness.\n\nI would be willing to raise my score if the authors could provide detailed discussions and address my concerns above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RSuSNJTaor", "forum": "4jECZ8epaB", "replyto": "4jECZ8epaB", "signatures": ["ICLR.cc/2026/Conference/Submission13972/Reviewer_QNZA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13972/Reviewer_QNZA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13972/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760713704726, "cdate": 1760713704726, "tmdate": 1762924472180, "mdate": 1762924472180, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a new theoretical and algorithmic framework for solving the Multi-Objective Bilevel Learning (MOBL) problem, without relying on the commonly assumed Lower-Level Strong Convexity (LLSC) condition.\nThe authors propose a transformation of the MOBL problem, under the assumption of general convexity at the lower level only, into an Equality-Constrained Multi-Objective Optimization (ECMO) problem. Building on this transformation, they develop a new theoretical characterization of Pareto stationarity for ECMO. To achieve this, they employ the Weighted-Chebyshev scalarization technique and demonstrate a correspondence between the scalarized WC solutions and the Pareto-optimal solutions of the ECMO problem."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The paper is clearly and well-written.\nThe proposed method is innovative and highly relevant to the field.\nThe authors develop a novel theoretical characterization of Pareto stationarity for ECMO.\nThey provide a rigorous convergence proof for their method."}, "weaknesses": {"value": "While Assumption 2 is indeed weaker than the strong convexity assumption, I believe it remains quite restrictive.\nThe paper lacks large-scale experiments."}, "questions": {"value": "Please address the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8OzPfB0Z3P", "forum": "4jECZ8epaB", "replyto": "4jECZ8epaB", "signatures": ["ICLR.cc/2026/Conference/Submission13972/Reviewer_w2WP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13972/Reviewer_w2WP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13972/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761753582563, "cdate": 1761753582563, "tmdate": 1762924471469, "mdate": 1762924471469, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper first studies the multi-objective bilevel learning (MOBL) problem under the lower-level general convex (LLGC) assumption. Further, the authors formulate the MOBL problem into an equality constrained multi-objective optimization (ECMO) problem, which is more amenable to algorithm design while preserving the optimal solutions of the original MOBL problem. However, a new Karush–Kuhn–Tucker (KKT)-based Pareto stationarity is proposed as the convergence metric for the ECMO problem. Lastly, the designed weighted Chebyshev (WC)-penalty algorithm achieves a finite-time convergence rate of $\\mathcal{O}(S/T^{\\frac{1}{2}})$ to KKT-based Pareto stationarity in both deterministic and stochastic settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The presentation is pretty organized with the help of roadmaps.\n2. It is critical that this paper proposes a new Pareto stationary point for the MOBL problems, as the common definition for unstrained MOO does not hold. \n3. It is true that the MOBL problem under the LLGC assumption is first studied, and the KKT-based method is novel and important."}, "weaknesses": {"value": "1. The authors should double-check the proof and notations. For example, in the proof of Theorem 1, the same typo occurs a few times where $\\epsilon f_s(\\tilde{z})^\\top d$ should be $\\epsilon\\nabla f_s(\\tilde{z})^\\top d$. Then I did not understand why $\\epsilon\\nabla f_s(\\tilde{z})^\\top d + o(\\epsilon)<0$ though we have $\\epsilon\\nabla f_s(\\tilde{z})^\\top d<0$.\n2. When applying the transformation in the stochastic setting, are there any special problems?\n3. In Theorem 5, the choice of batch size seems to be too large that both $\\mathcal{B}$ and $\\mathcal{T}$ are at the order of $\\mathcal{O}(T^{\\frac{5}{4}})$. Then the sample complexity will be much higher than MoCo.\n\nI would like to raise my score if the questions are resolved."}, "questions": {"value": "Please check the weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XP5ryPs7go", "forum": "4jECZ8epaB", "replyto": "4jECZ8epaB", "signatures": ["ICLR.cc/2026/Conference/Submission13972/Reviewer_VYjJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13972/Reviewer_VYjJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13972/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761841045125, "cdate": 1761841045125, "tmdate": 1762924471044, "mdate": 1762924471044, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on multi-objective bi-level optimization under lower lower-level generally convex (LLGC) setting. The key contribution is that the problem is reformulated to an equivalent equality-constrained multi-objective (ECMO) optimization problem. The paper defines a KKT-based Pareto-stationarity metric using weighted Chebyshev (WC) scalarization, and solves this ECMO problem via a single-loop projected gradient method. The effectiveness of the proposed method is justified by both theoretical analysis and experimental results."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper relaxes the LLSC assumption to LLGC in bilevel optimization, and addresses the problem by reformulating it into an equality-constrained multi-objective optimization (ECMO) problem. This formulation is clean and novel.\n2. It defines a KKT-based Pareto stationary metric, and provides a finite-time convergence guarantee for both deterministic and stochastic settings.\n3. Experiments demonstrate that the proposed method can explore the Pareto front, outperforming the existing baselines."}, "weaknesses": {"value": "1. The entire theoretical framework builds on the LLGC assumption, where the lower level is generally convex. However, the experiments in Section 5 apply it to multi-objective reward/alignment training, where the lower level is obviously nonconvex. There seems to be a gap.\n2. The comparison against ITD and SOBA seems to be more a test of WC vs. LS scalarization than a test of the underlying optimization algorithm. LS may be ineffective in exploring the Pareto front. Could your WC-Penalty framework be combined with ITD or SOBA? Or, could those baselines be adapted using WC scalarization for a fairer comparison?"}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tis7PwgojP", "forum": "4jECZ8epaB", "replyto": "4jECZ8epaB", "signatures": ["ICLR.cc/2026/Conference/Submission13972/Reviewer_mEXP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13972/Reviewer_mEXP"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13972/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761973942510, "cdate": 1761973942510, "tmdate": 1762924470498, "mdate": 1762924470498, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}