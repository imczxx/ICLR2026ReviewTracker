{"id": "s9t2FJVsBH", "number": 11156, "cdate": 1758191369169, "mdate": 1763720688824, "content": {"title": "ProofFlow: A Dependency Graph Approach to Faithful Proof Autoformalization", "abstract": "Proof autoformalization, the task of translating natural language theorems and proofs into machine-verifiable code, is a critical step for integrating large language models into rigorous mathematical workflows. Current approaches focus on producing executable code, but they frequently fail to preserve the semantic meaning and logical structure of the original human-written argument. To address this, we introduce ProofFlow, a novel pipeline that treats structural fidelity as a primary objective. ProofFlow first constructs a directed acyclic graph (DAG) to map the logical dependencies between proof steps. Then, it employs a novel lemma-based approach to systematically formalize each step as an intermediate lemma, preserving the logical structure of the original argument. To facilitate evaluation, we present a new benchmark of 184 undergraduate-level problems, manually annotated with step-by-step solutions and logical dependency graphs, and introduce ProofScore, a new composite metric to evaluate syntactic correctness, semantic faithfulness, and structural fidelity. Experimental results show our pipeline sets a new state-of-the-art for autoformalization, achieving a ProofScore of 0.545, substantially exceeding baselines like full-proof formalization (0.279), which processes the entire proof at once, and step-proof formalization (0.046), which handles each step independently. Our pipeline, benchmark, and score metric are open-sourced to encourage further progress at https://anonymous.4open.science/r/ProofFlow-351E.", "tldr": "", "keywords": ["Autoformalization", "Large Language Models", "Dependency Graph", "Lean (Formal Language)", "Structural Fidelity", "Semantic Faithfulness"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c2fe05d4f93ba3e88164129e0c9d7017e847a3ea.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper focuses on the task of proof autoformalization, distinguishing it from automated theorem proving. The key difference is:\n\nAutomated Theorem Proving: A prover constructs a verifiable proof from a given formal statement.\n\nProof Autoformalization: The model is given both the natural language statement and its proof, and must translate this proof into a formal language while preserving its structure.\n\nThe paper introduces ProofFlow, a pipeline that utilizes a DAG (Directed Acyclic Graph) to ensure the final translated proof accurately preserves the logical dependencies between the original proof steps. This pipeline was evaluated on a new benchmark, where it demonstrated good performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Regarding originality, this paper tackles the under-explored problem of proof autoformalization, specifically focusing on the requirement that the translated proof preserve its structure. This aspect is seldom noticed in previous ATP papers. Moreover, their proposal to use a DAG to address this task is of great novelty.\n\nThe paper also provides comprehensive explanations and evaluations of its idea and results. The overall quality and clarity are good, and the evaluations demonstrate that their pipeline achieves good performance."}, "weaknesses": {"value": "No significant weaknesses."}, "questions": {"value": "Do you think it is possible to train a model that can faithfully translate proofs into lean (not relying on your pipeline)? Is it possible to use your pipeline to curate training data for the training of proof formalizer?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "F2OXbvb6H0", "forum": "s9t2FJVsBH", "replyto": "s9t2FJVsBH", "signatures": ["ICLR.cc/2026/Conference/Submission11156/Reviewer_hcof"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11156/Reviewer_hcof"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11156/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761574237677, "cdate": 1761574237677, "tmdate": 1762922321469, "mdate": 1762922321469, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces PROOFFLOW, a three-stage pipeline for the proof autoformalization. The pipeline first constructs a directed acyclic graph (DAG) to represent the logical structure of the NL proof (Graph Builder), then translates each node into Lean 4 code (Formalizer), and finally generates tactics to complete the formal proof (Tactic Completer). To support this research, the authors also present two new contributions: PROOFFLOWBENCH, a benchmark of 184 undergraduate-level problems, and PROOFSCORE, a composite metric designed to evaluate the syntactic, semantic, and structural fidelity of the formalized output. The experimental results demonstrate that PROOFFLOW achieves a PROOFSCORE of 0.545, significantly outperforming the baseline methods considered."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Systematic Pipeline Design: The paper presents a well-structured methodology. The PROOFFLOW pipeline thoughtfully deconstructs the complex task of autoformalization into manageable stages. The work is commendably thorough, extending beyond the pipeline itself to include the development of a new benchmark and a tailored evaluation metric.\n\n- Novel \"Lemma Approach\": A key contribution is the clear conceptual distinction between the conventional low-level \"Tactic Approach\" and the paper's high-level \"Lemma Approach.\" By demonstrating the superiority of preserving the proof's structure through intermediate lemmas, the paper offers valuable insights that could guide future research in faithful autoformalization.\n\n- Integrated Error Analysis: The inclusion of an error detection system is a significant strength. This mechanism goes beyond simple pass/fail metrics by attempting to diagnose the source of failure, attributing it to the formalizer, the tactic completer, or a potential flaw in the original NL proof. This diagnostic capability is a valuable feature for practical applications."}, "weaknesses": {"value": "- Limited Evaluation Scope: The empirical validation is confined to the newly introduced PROOFFLOWBENCH. The omission of established benchmarks such as miniF2F and ProofNet, which also contain problems with NL proofs, makes it difficult to contextualize the performance of PROOFFLOW within the broader landscape of autoformalization research. A more robust evaluation would compare the proposed method against baselines on these widely recognized datasets.\n\n- Potential Metric Subjectivity and Lack of Validation: The proposed PROOFSCORE metric relies on an \"LLM-as-a-judge\" to assess semantic faithfulness, introducing a significant risk of subjectivity and unreliability. The evaluation is contingent on the specific LLM employed, and the paper provides no validation for this judge. The absence of an analysis measuring inter-rater reliability (i.e., consistency across different LLMs or against human experts) weakens confidence in the reported scores and the conclusions drawn from them.\n\n- Lack of Transparency and Potential for Data Contamination: The appendix notes that ground-truth dependency graphs for PROOFFLOWBENCH were generated by LLMs before human verification. The paper fails to specify whether the models and prompts used for this data generation are distinct from those used in the pipeline's Graph Builder stage. If they are not, this constitutes a form of data contamination, as the model would be evaluated on a task that closely mirrors its own data generation process. Furthermore, the complete omission of the prompts used for both the pipeline and the metric evaluation is a critical lapse in transparency that hinders the reproducibility of this work."}, "questions": {"value": "In the \"Structural Fidelity\" evaluation (line 297), the assessment appears to be based on a per-node check of dependencies. Have the authors considered a more holistic assessment of the entire proof structure, for instance, by employing graph structural similarity metrics?\n\nIn the experimental setup (lines 399-404), the paper defines \"thinking\" and \"non-thinking\" modes with different model configurations for the Formalizer and Tactic Completer stages. Could the authors elaborate on the rationale for selecting these specific model combinations? What hypotheses about model capabilities motivated these distinct configurations? From my understanding, I think it's just about using Gemini-2.5-Pro and Gemini-2.5-Flash in Graph Builder, while the model selection for Formalizer and Tactic Completer should be the same."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9KlE87WNQw", "forum": "s9t2FJVsBH", "replyto": "s9t2FJVsBH", "signatures": ["ICLR.cc/2026/Conference/Submission11156/Reviewer_VRSK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11156/Reviewer_VRSK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11156/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761905784990, "cdate": 1761905784990, "tmdate": 1762922320420, "mdate": 1762922320420, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents ProofFlow, a DAG-based framework for faithful proof autoformalization that decomposes natural language proofs into lemma nodes and translates them into Lean 4 via LLMs. It introduces ProofScore, a composite metric for syntactic, semantic, and structural quality, and a new dataset (184 undergraduate proofs). Experiments show its pipline outperforms Full-Proof and Step-Proof in accuracy and structural fidelity."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThis paper introduces an appealing DAG-based, lemma-driven approach that preserves the logical structure of natural language proofs while improving interpretability and consistency.\n2.\tIt proposes ProofScore, a new metric capturing syntactic correctness, semantic faithfulness, and structural fidelity, providing a more rigorous evaluation.\n3.\tExperiments demonstrate improvements with ProofFlow, achieving a ProofScore of 0.545 compared to 0.123 (Full-Proof) and 0.072 (Step-Proof), validating its effectiveness and generalizability."}, "weaknesses": {"value": "1. The Formalizer stage contributes to 32–47% of failures due to semantic mismatches between natural language and Lean 4 code, suggesting that its efficiency remains limited.\n2. Semantic faithfulness is evaluated through subjective LLM judgments without human verification or inter-rater reliability, which may introduce bias and reduce objectivity.\n3. Experiments are restricted to undergraduate-level proofs (average 8.4 nodes per proof, covering elementary topics), leaving the method’s generalizability to research-level or large-scale mathematical corpora untested."}, "questions": {"value": "Please refer to the Weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gfA5kbjkls", "forum": "s9t2FJVsBH", "replyto": "s9t2FJVsBH", "signatures": ["ICLR.cc/2026/Conference/Submission11156/Reviewer_aiML"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11156/Reviewer_aiML"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11156/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926546842, "cdate": 1761926546842, "tmdate": 1762922319518, "mdate": 1762922319518, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The idea of this paper is to autoformalize proofs faithfully, meaning the semantic structure of the proof is maintained rather than just the correctness. The authors provide a new formalization pipeline called ProofFlow, in which they decompose the proof into a DAG where each node is a proof step, and edges indicate dependency. They also introduce scoring system to evaluate faithfulness (ProofScore), and a benchmark dataset of undergrad problems. They also conduct experiments to support their claims."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "The paper introduces a novel approach to proof autoformalization which enforces structural fidelity. The authors make a good case for why this is an important problem, and why their proposed method would do so (if effective). Furthermore, the provided dataset and software seems like a useful contribution to the autoformalization/ATP community. Additionally, their pipeline and scoring metric both seem like reasonable and inuitive approaches to the problems."}, "weaknesses": {"value": "I think while your method has merit, the comparisons to previous methods is not exactly fair. You are using a un-finetuned Gemini to formalize and prove proofs/steps for the previous methods, whereas ProofFlow uses much stronger, (nearly) state-of-the-art autoformalization/ATP models in the Goedel models. While this might be tricky for Full Proof (since Goedel models are not trained for proof-autoformalization), I think a more fair comparison for Step Proof would be \n\n1. Break down the proof into steps using the same model as you used for GraphBuilder\n2. Prove each step using Goedel Formalizer/Prover\n\nIn this way you're normalizing for the strength of the model to ensure you're comparing the method. Without this (or another way to ensure the model strength doesn't affect performance), the performance gain is difficult to believe. \n\nSecondly, ProofFlow requires significantly more computation than previous methods, which is a limitation of the work. I believe it would benefit from some analysis on computationally demanding elements of the pipeline (e.g., how many iterations is usually required to make a valid DAG in the GraphBuilder step?). This would offer some avenues for improvement to mitigate this limitation."}, "questions": {"value": "L192: This approach assumes each proof step depends on all preceding steps, a simplification that can lead to unintended consequences.\n\nFigure 2: L3 typo, should be ^2 I think. Also, it seems to me that L3 is entirely redundant. Why not simply use L2 and L5 to get to L6? Is this a fault of the system(s) used? Possibly showing the full informal proof would be helpful.\n\nFigure 5: Could be the case that multiple errors occured, i.e. a NL statement error could be hidden behind a tactic completer error. Does this happen?\n\n* I'm confused on the ProofScore metric. When you say syntactic correctness, my understanding is that you are just concerned about whether a statement passes the Lean compiler, regardless of the \"fidelity\" to the original informal statement. For example, is \"theorem abc : True := by trivial\" considered syntactically correct?\n\n* I'm also not sure how to interpret the ProofScore metric. I think showing some examples of proofs with various proof scores would be useful to help readers understand how the numbers vary."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GfQcQqVaob", "forum": "s9t2FJVsBH", "replyto": "s9t2FJVsBH", "signatures": ["ICLR.cc/2026/Conference/Submission11156/Reviewer_2CoE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11156/Reviewer_2CoE"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11156/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762033175669, "cdate": 1762033175669, "tmdate": 1762922319180, "mdate": 1762922319180, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Response to Reviewer Feedback and Manuscript Revisions"}, "comment": {"value": "We sincerely thank the reviewers for their insightful comments and constructive feedback.\n\nWe confirm that we have addressed all individual reviewer questions directly within their respective submission boxes. In addition, we have updated our manuscript  to incorporate the suggested changes and clarifications.\n\nAll section references provided in our individual responses correspond to this newly revised version of the manuscript. Due to the short character limit imposed on the individual reviewer response boxes, we were constrained to provide only a very succinct reply in some cases. \n\nWe are keen to provide any further details or clarification that may be needed to fully address any remaining concerns.\n\n---------------------------------\n**Summary of Main Manuscript Modifications**\n\nThe key modifications and new analyses incorporated into the revised manuscript are summarized below:\n\n- Enhanced Comparative Study (R1-W1): We updated our comparison against the FullProof and StepProof methods by utilizing the specialized Goedel-Prover-V2-32B model in their \"thinking\" modes for a fair comparison. Table 1 and Table 3 reflect these new results. A significant performance gap remains in the ProofScore evaluation: FullProof (thinking) achieved 0.279 while our ProofFlow DAG pipeline (thinking) achieved 0.545.\n\n- Detailed Computational Efficiency Analysis (R1-W2): We added a new Appendix Section A.7 (and Table 8) and a paragraph in Section 6.2 with detailed computational diagnostics. The analysis confirms the Tactic Completer is the primary bottleneck, consuming 81–89% of the total execution time. We highlight in Section 6.2 that the DAG structure inherently enables extensive parallelization of the Formalizer and Tactic Completer stages.\n\n- Error Analysis and Semantic Strictness (R2-W1, R2-W2): We clarified that the high error rate at the Formalizer stage is due to strict semantic scoring and current LLM limitations, not the core ProofFlow architecture. A manual audit confirmed many rejected \"mismatches\" are mathematically valid formalizations flagged due to structural/notational divergences. We further validated the reliability of our LLM-powered metric, ProofScore, in Appendix A.2.3.\n\n- Generalizability and Benchmark Expansion (R2-W3, R3-W1):\n\n    - miniF2F Evaluation: We performed a Pass@5 evaluation on a 50-problem subset of the miniF2F test set. This evaluation confirmed that the conclusions regarding the relative performance of different pipeline configurations hold on this established benchmark. We noted that accuracy was universally higher on miniF2F compared to PROOFFLOWBENCH, indicating miniF2F is an easier benchmark.\n\n    -  Research Level evaluation: We included an evaluation on a small sample of the research-level FrontierMath benchmark. We discussed that Graph Builder is highly generalizable, but the Formalizer/Tactic Completer performance depends on LLM and MathLib maturation.\n\n- Data Contamination Clarification (R3-W3): We clarified that no data contamination risk exists because the ground truth DAGs were not used in this project, and a separate model was used for ProofScore evaluation.\n\n----------\n\nWe look forward to further discussion and incorporating your valuable feedback to improve our paper.\n\nBest regards,\n\nThe Authors"}}, "id": "B4EHZmxwoe", "forum": "s9t2FJVsBH", "replyto": "s9t2FJVsBH", "signatures": ["ICLR.cc/2026/Conference/Submission11156/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11156/Authors"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission11156/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763717547961, "cdate": 1763717547961, "tmdate": 1763717547961, "mdate": 1763717547961, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}