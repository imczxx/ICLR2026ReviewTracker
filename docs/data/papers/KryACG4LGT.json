{"id": "KryACG4LGT", "number": 3287, "cdate": 1757394190474, "mdate": 1759898097660, "content": {"title": "Learning without Memorizing Considered Infeasible: Rethinking Memorization in LLMs", "abstract": "Memorizing when learning is considered undesirable for two distinct reasons: first, from a privacy perspective, memorization raises concerns about potential leakage of sensitive information in training data. Second, from a learning perspective, memorization raises concerns of sub-optimal learning and over-fitting. In this paper, we rethink measures of memorization in large language models (LLMs). We find that existing *measures of memorization*, namely recollection-based and counterfactual measures, are designed to capture privacy concerns, but they ignore optimal learning concerns. We propose a new memorization measure, called *contextual memorization* that captures LLMs tendency to locally over-fit some strings in the training data before others, over multiple epochs of training.\n\nApplying these measures when training LLMs leads us to two striking conclusions. First, a systematic analysis of all the measures shows that our new measure avoids a major pitfall of prior measures, by distinguishing context-based recollection from memorization-based recollection of a training string. Using our measure, we revisit prior reported instances of training data memorization by real-\nworld LLMs and find that many instances can be explained away by contextual learning-based recollection, i.e., the prior memorization reports are likely exaggerated. Second, we find that when LLMs learn a language optimally, they inevitably end up *memorizing* some portions of the training data. We support our conclusion with extensive experiments training 18 LLMs from 6 model families to learn a variety of formal languages.", "tldr": "A study to critically assess different memorization measures and their implications in large language models, particularly on determining whether learning without memorization is feasible and whether the privacy risks of memorization are exaggerated.", "keywords": ["Memorization Measures in LLMs", "Memorizaton and Learning", "Privacy risks of Memorization"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/263fd1b3fc51bb3b6e88f223870de58d1f2291b0.pdf", "supplementary_material": "/attachment/ee4e44e9be4060d8b516f629cbc84af2260dcd08.zip"}, "replies": [{"content": {"summary": {"value": "The paper is concerned about memorization in large language models (LLMs) and its implications for privacy and learning. It critiques existing measures of memorization, which are primarily recollection-based and counterfactual, arguing that they often conflate memorization with contextual learning. The authors propose a new measure called \"contextual memorization\" that better distinguishes between these two phenomena. They conduct extensive experiments with multiple LLMs across various formal languages. From these experiments, they claim two main findings: (1) learning a language without any memorization is infeasible, and (2) current assessments of LLM memorization are likely exaggerated. Particularly, they find that many instances of privacy risk study where LLMs memorize training under recollection-based measures can be explained by contextual learning instead."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The paper considers an important and timely topic, given the increasing use of LLMs and concerns about privacy and memorization.\n- The paper presents many results, including a few quite interesting ones. For instance, Figure 2 compares different memorization measures and shows that they can lead to different conclusions about when a string starts to be memorized; Figure 5 shows that training data deduplication does not reduce the band of epochs when strings in a low entropy language are memorized.\n- Section 3.1 is helpful in understanding the differences between various memorization measures considered in this paper.\n- The empirical evaluation is extensive, covering 18 LLMs across 6 model families and multiple formal languages."}, "weaknesses": {"value": "- It is difficult for me to fully follow the paper. This is partly because the paper presents many results, but connects them only loosely. The technical sections (Sections 3, 4, and 5) are three separate works, among which, seven disjoint RQs (I assume this means research questions) are asked and answered. These research questions, as well as their respective findings, although valuable on their own, do not seem to all serve the same purpose of validating the main claims of the paper. For example, RQ5, \"Increasing training dataset size improves optimal learning, but do we risk memorizing more training strings (due to more repeated strings)?\" is interesting, but it is not clear how it relates to the main claims of the paper. The overall structure and organization of the paper could be improved a lot.\n- Some of the claims are not substantiated well. Since the paper proposes the new measure of contextual memorization, it is important to establish cases where this measure is more accurate than existing measures, especially the very similar counterfactual memorization measure. I assume Lines 273 to 288 are trying to do this, but I don't find the arguments very convincing. It is true that contextual memorization imposes a stricter threshold than counterfactual memorization, and it is also true that the motivations and the empirical behaviors for the two measures are different. But it is not clear why these differences make contextual memorization a better measure at least in some cases. \n- A non-negligible portion of the results are presented in unclear ways. I'll give two examples *among many*.\n    - Figure 1 looks like a real run of training instead of an illustration, but its related settings are never mentioned throughout the paper. Should I consider this figure a general trend that one should always expect to see? Otherwise, why is it chosen to be here?\n    - In Lines 445 to 458, what exacly was the experiment setting? What does \"accuracy\" mean in this experiment? How do you generate the reference model $M_{ref}$? \"If a string memorized by $M$ is generated by $M_{ref}$ with equal or higher recollection, it is unlikely to be contextually memorized.\" - Is that validated somewhere? How is \"accuracy\" of $M_{ref}$ an upper bound of the optimal contextual accuracy?\n\nOverall, although the paper presents a lot of results, with some interesting ones, it is difficult for me to follow the paper and be convinced by its main claims. I think the paper needs a major revision to improve its structure and organization, as well as to better substantiate its claims."}, "questions": {"value": "- Most of the figures contain error bars, how are those computed? Does that come from multiple runs of training? If so, how many runs?\n- What is the amount of tokens used for training a model for the formal languages you use?\n\n### Minor comments\n\n- Line 166: \"Gemma (Team et al., 2024)\" seems problematic with the author name.\n- Line 207: I recommend writing $D \\ni s$ instead of $s \\in D$, since $s$ is fixed and $D$ is a set that varies.\n- Line 329: I believe the correct notation is $\\mathbb{E}_{s \\sim D} [\\cdot]$ instead of $\\mathbb{E}_{s \\in D} [\\cdot]$."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dtdmKGbMJc", "forum": "KryACG4LGT", "replyto": "KryACG4LGT", "signatures": ["ICLR.cc/2026/Conference/Submission3287/Reviewer_Qw3D"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3287/Reviewer_Qw3D"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3287/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760577970448, "cdate": 1760577970448, "tmdate": 1762916648386, "mdate": 1762916648386, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors \n- propose a minor variant of counterfactual memorization they term \"contextual memorization\"\n- compare recollection-based memorization and counterfactual memorization to their new contextual memorization\n- use these different notions of memorization to understand questions like how quickly strings are memorized during learning and whether reported memorized strings contain privacy-sensitive PII"}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "It's clear that the authors have put in good effort towards this paper."}, "weaknesses": {"value": "## Title:\n\n- I’m not keen on the phrasing of “considered infeasible”. Considered by who? Based on reasonable evidence and meaningful evidence? There is ambiguity concerning whether you (the authors) are advocating this or attacking this?\n\n## Abstract\n\n- “Measures of memorization ignore optimal learning concerns” -> Some measures do, sure, but others don't. I don’t see papers like “Scaling Laws and Interpretability of Learning from Repeated Data” (https://arxiv.org/abs/2205.10487), which explicitly shows in the context of language modeling that memorizing a subset of data can be harmful. I’m not affiliated, but it seems directly relevant to showing that memorization is harmful.\n- nit: What does “before” mean in the sentence “... that captures LLMs tendency to locally overfit some strings in the data before during multiple epochs of training.”? Before what?\n- nit: Stylistically, I don’t like the newline character in the middle of the abstract. The ICLR instructions are clear: “The abstract must be limited to one paragraph.”\n- “Second, we find that when LLMs learn a language optimally, they inevitably end up memorizing some portions of the training data” -> I think to myself, surely these authors will cite the famous Feldman paper (https://arxiv.org/abs/1906.05271) about how memorization is necessary for achieving close-to-optimal generalization error? But I couldn’t find a reference for this paper\n\n## Introduction\n\n- I’m a fan of conceptual schematics. It might be helpful to the reader to add a conceptual subfigure to communicate what contextual memorization is.\n- Figure 1 is too tiny. \n- Figure 1 doesn’t label in the legend what the dashed and dotted blue and red lines are.\n- Figure 1’s caption doesn’t provide adequate information. The reader does not know which models these are, what the data is, what the loss is measured on, etc. If this is meant to be a schematic, it should be labeled as such. \n- The thought experiment doesn’t seem to crisply communicate the essence of contextual memorization. I actually think a simpler example from privacy makes more sense. For example, a model may produce PII (e.g., credit card info) but that same PII appears earlier in the sequence, so has the model “memorized” the PII or is it just referring back a page?\n- The paragraph “Comparing with Counterfactual Measures” and Figure 1 seems focused on separating contextual from counterfactual memorization. I’m not quite sure that’s a strategic move? Your focus should be on making sure the reader understands your contextual memorization, not a comparison against counterfactual memorization.\n- After rereading the paper, I feel like Counterfactual Memorization distracts from (what I understand is) your main point that in-context learning can appear as “memorization” under current metrics.\n- I’m unclear about what the difference is between in-context learning and contextual memorization.\n- I’m also amazed that (as best as I can tell) “in-context learning” (ICL) does not appear in your manuscript and no ICL papers have been cited. Am I misunderstanding contextual memorization - does it have no connection to ICL?\n- The definition of Contextual Memorization doesn’t appear till Page 5. Since this notion is so central to your work, I think it should be stated much earlier.\n\n## Section 2\n\n- Lines 133-134 “prior studies proposing memorization measures avoided carefully examining the training dynamics of the model.” I think that this inaccurately describes the field. Other memorization papers have certainly looked at learning dynamics. The two that immediately spring to mind are Biderman et al. 2023 Emergent and Predictable Memorization in Large Language Models and Duan et al. 2025 Uncovering Latent Memories in Large Language Models.\n- Line 149-150 “We choose formal grammar based languages because they can be fully learned without any memorization.” I think Strobl et al. 2024 What Formal Languages Can Transformers Express? A Survey and Bhattamishra et al. 2020 On the Ability and Limitations of Transformers to Recognize Formal Languages show that there are grammar-based languages that cannot be learned. Unless we’re considering a restricted subset of languages, I think this statement is incorrect.\n\n## Appendix E\n\n- Batch size is typically given in the number of tokens, and so “batch size is 8” is difficult to interpret; presumably this means that the number of sequences per optimizer step is 8? But what is the sequence length? \n- If the tokens per optimizer step is not constant, how does it vary?\n- If the number of epochs is held fixed but the training dataset sizes are varied, then these comparisons are not isoFLOP; is that correct? If so, it’ll be tricky to know whether whatever differences are found are indeed attributable to the experimental conditions or to other factors such as overtraining and optimization.\n- How is tokenization handled? Do you extend the vocabulary with new unique tokens for the grammar? Or do you use the model’s tokenizers for each language without adapting it?\n\n## Section 3\n\n- Lines 185-186: I haven’t seen previous papers use cross entropy loss as a measure of memorization, and the cited Mao et al. 2023 does not mention memorization (as best as I can tell). I think it’d be good to use more “standard” measure(s) of memorization. See Section 2 of Xiong et al. 2025 The Landscape of Memorization in LLMs for a list of commonly used memorization metrics (no affiliation with the paper - I just thought they provide a nice comprehensive list of various memorization metrics in the literature)\n- Equation 2: **At this moment, I realize that I have misunderstood what contextual memorization means.** To me, the mental model I had in my head was something along the lines: If the model’s context is string s = “John Smith’s email is X. What is John Smith’s email? ”, then if the model greedily decodes X, this would qualify as memorization but it isn’t really because the model is just using its context. Note: this doesn’t necessarily mean the model was or was not trained on s. The definition of contextual memorization in  equation (2) is quite different from this. It instead says: what is the smallest difference in loss between a model trained on this datum and models not trained on this datum.\n- **I’m now very confused what “context” means in contextual memorization. Does it have any connection to the context window of a model? If not, what is the context in contextual memorization?**\n- I now realize that Contextual memorization is a very slight variant on Counterfactual memorization, merely adding a $\\min_e$\n- In Section 3.2, the second and third findings (lines 273 and 282, respectively) seem like thinking in a vacuum (I wanted to say intellectual masturbation but am trying to elevate my language). What is the importance of these two findings? Why should anyone care? It seems like you’ve proposed a new metric that is a slight variation of a previous metric I’ve never heard of, and are going on about how these two metrics are related to one another without drawing any substantial conclusions.\n- The takeaway statement on line 280 seems trivially obvious: “Different measures can disagree on the start and order of memorization.” If they didn’t disagree, then why would the field have like 10+ metrics for memorization?\n\n- **Disclaimer: At this point, I’m pretty checked out of this paper. It comes across as much ado about nothing. If there’s a reason why this matters, conceptually or empirically, I don’t feel like I’ve encountered it yet.**\n\n## Section 4\n\n- Line 337 to 340: “Since contextual and counterfactual memorization are related (Lemma 1), we henceforth compare between contextual and recollection-based memorization.” gave me whiplash. We spent the first 6 pages making a hullabaloo about contextual vs counterfactual memorization, and then say “They’re basically super similar, so let’s just omit one.” It undermines the paper’s position that these metrics are meaningfully different.\n\n## Section 6\n\n- The transition to RQ6 is abrupt. I don’t know how this fits into the overall narrative or earlier results.\n- I don’t see mention of what defines “privacy-sensitive PII” or how the authors made the classification of whether memorized strings do (or do not) contain privacy-sensitive PII.\n- The use of a proxy model (in this section, OLMo-1B) seems unjustified, theoretically or empirically. Sure, one _can_ do this, but whether it approximates contextual memorization (or how well) is not substantiated."}, "questions": {"value": "- Please see Weaknesses.\n\n- One additional aspect that was unclear to me: the Abstract and Introduction claim to use 18 LLMs across 6 model families. When I look at the figures and tables in the main text, I don't see any mention of the model families. Could you please clarify the relevance of this claim? I understand that Appendix E includes the model families (Qwen, Gemma, Llama 3 - without citations by the way) but I don't understand the role that these families play in the main text. This detail seems almost irrelevant?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "J5OY4dSE2T", "forum": "KryACG4LGT", "replyto": "KryACG4LGT", "signatures": ["ICLR.cc/2026/Conference/Submission3287/Reviewer_w7jk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3287/Reviewer_w7jk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3287/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761516164220, "cdate": 1761516164220, "tmdate": 1762916647930, "mdate": 1762916647930, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper motivates a new notion of memorization LLMs which dissects rote memorization vs \"learning\" (i.e. generalization). Towards this, they introduce \"contextual memorization\" that measures minimum difference between loss on target string s when trained w/ and w/o it over multiple epochs (the min is taken of differences over epochs). The paper discusses several implications of this notion and its results."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- I think this is an important problem to dissect memorization from generalization\n- The paper has covered most of relevant prior related work that I'm aware of."}, "weaknesses": {"value": "See questions"}, "questions": {"value": "- How do you define what a string is? Does it have a minimum or maximum length? If not, a single token is valid entry? How does this translates into epoching? \n- Line 148-150 \"...We choose formal grammar based languages because they can be fully learned without any memorization.\" Can you unpack this? Is this true? Because that does not make sense to me, please share your justification and preferably a cite for this.\n- What is the motivation of reduction (min) over multi epoching on a dataset? I would just call it training longer, since epoching is dataset sample size specific. It is unclear what entails single epoch in LLM training. The entire paper is too dependent on this and for me, an epoch over sample of target distribution (training data) is too arbitrary measure.\n- RQ4 is not an RQ since it is already answered by cited work.\n- The main takeaway from the paper is \"learning is infeasible without memorization\" uses \"contextual memorization\" to show this by \"by differentiating between context-based recollection and memorization-based recollection\". After reading the paper, I think the term memorization is super overloaded and it has made it difficult to follow the claim. It seems its kind of cat and mouse game. I'm unsure if this is writing that is ambigous or the claims made as well."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NUjlV3yn7r", "forum": "KryACG4LGT", "replyto": "KryACG4LGT", "signatures": ["ICLR.cc/2026/Conference/Submission3287/Reviewer_hoWX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3287/Reviewer_hoWX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3287/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762052469000, "cdate": 1762052469000, "tmdate": 1762916647711, "mdate": 1762916647711, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}