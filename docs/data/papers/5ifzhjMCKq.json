{"id": "5ifzhjMCKq", "number": 16903, "cdate": 1758270128151, "mdate": 1759897211118, "content": {"title": "Guidance Watermarking for Diffusion Models", "abstract": "This paper introduces a novel watermarking method for diffusion models. It is based on guiding the diffusion process using the gradient computed from any off-the-shelf watermark decoder. The gradient is guided further using different image augmentations, increasing robustness to attacks against which the decoder was not originally robust, without retraining or fine-tuning. The methodology effectively allows to convert any post-hoc watermarking scheme into a scheme embedding the signal during the diffusion process. We show that this approach is complementary to watermarking techniques modifying the variational autoencoder at the end of the diffusion process. We validate the methods on different diffusion models and detectors. The watermarking guidance does not significantly alter the generated image for a given seed and prompt, preserving both the diversity and quality of generation.", "tldr": "We propose an in-diffusion watermarking method that guides the generative process using any watermark detector.", "keywords": ["watermarking", "image generative AI"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e335bcea65b10502014ac6e5e36941c05ef4bc6a.pdf", "supplementary_material": "/attachment/e64e5e51bfaf55b21b38f80d69fd9aa72c711957.zip"}, "replies": [{"content": {"summary": {"value": "This work proposes a guidance module that could be applied during the diffusion process to embed a watermark. It relies on a pretrained watermark decoder/detector (such as Stable Signature) to compute the loss that is needed for the guidance. The main idea is to add a gradient term to the noise during each diffusion step and the gradient term is computed with respect to the watermark. It gives experimental results to show the effectiveness of this method."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "+ The guidance module could strengthen existing pretrained baseline watermarking method such as Stable Signature and VideoSeal, as shown in their experiments in Table 1. More importantly, it extends baselines to be more robust agains unknown augmentations.\n\n+ Experimental results on various diffusion models are provided: SD2, Flux, and Sana."}, "weaknesses": {"value": "- With all those formulas floating around, it is challenging to grasp the whole picture of this work and the additional contribution they bring to existing watermarking pipeline. (See my suggestion below)\n\n- Choice of the guidance strength hyperparameter adds complexity to the watermarking application.\n\n- It is not completely fair to claim that your work \"does not necessitate any retraining of the diffusion model\" and compare against TreeRing and GaussianShading (both trainning-free), when your method actually relies on a well-trained watermark detector (e.g., Stable Signature).\n\n- The robustness results are not consistently better than GaussianShading in Table 2."}, "questions": {"value": "- I am confused about the Motivations section. If your motivation is that the spectral signature could be exploited to remove the watermark, why not address this issue in your evaluation?\n\n- Explain more on why the right pattern is better than the left in Figure 1.\n\n- A system view (probably a system/pipeline figure) is necessary to understand their method and the additional module/steps they bring into the watermark embedding/detection pipeline, e.g., compared to the baseline Stable Signature.\n\n- It is not very clear how detection/decoding is performed. Maybe (7) gives some info on detection, but what about decoding? How do we get the watermark message from an image?\n\n- In Table 1, is any image attack used in the evaluation for robustness? If so, what are they? If not, you should add robustness comparison with SSign and VS in the Table 2.\n\n- The basic image distortions in Table 2 seem not sufficient, more to add: e.g., gaussian blur, rotation.\n\n- Confused about your claim: \"ours does not require extra steps for decoding making it up to 50 times faster at detection\ntime.\" I think this is also because the decoding procedure is not clearly explained in the paper. For GuassinShading/TreeRings, we need to convert an image to latent noise for detection. Are u claiming that your method does not require such conversion? If so, how do you directly extract watermark from an image?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "V1I0Ami35O", "forum": "5ifzhjMCKq", "replyto": "5ifzhjMCKq", "signatures": ["ICLR.cc/2026/Conference/Submission16903/Reviewer_jcck"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16903/Reviewer_jcck"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16903/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761018974532, "cdate": 1761018974532, "tmdate": 1762926933637, "mdate": 1762926933637, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new image watermarking method that enables converting an existing post-processing watermarking method into an in-generation watermarking method using only an existing decoder, without introducing significant changes to the watermarked image."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.\tCompared to existing post-generation and in-generation watermarking methods, the proposed approach offers improvements in watermark bit capacity.\n2.\tFrom the methodological point of view, the paper provides a practical means of converting post-processing watermarking approaches into in-generation ones."}, "weaknesses": {"value": "1.\tIt’s unclear what motivates the authors to propose this method. The writing of the introduction should be revised to explicitly show this.\n2.\tIt is unclear whether the method performs semantic watermarking or adds fixed content-unaware perturbations, as similar in-generation watermarking methods like Tree-Ring and Gaussian Shading have been found out to be adding fixed perturbations [1]. Since the proposed method is also an in-generation watermarking method, the authors should use a fixed watermarking key and test under [1]’s removal method to show whether or not the proposed watermark is content-aware.\n\n[1] Yang et al., “Can simple averaging defeat modern watermarks,” in NeurIPS 2024."}, "questions": {"value": "1.\tFor bold results presented in Table 1, would it be possible to also report the corresponding watermark decoding bit accuracy values? This could align the metric with most existing works and facilitate comparison."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cXIS2B9wwG", "forum": "5ifzhjMCKq", "replyto": "5ifzhjMCKq", "signatures": ["ICLR.cc/2026/Conference/Submission16903/Reviewer_WTJb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16903/Reviewer_WTJb"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16903/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761373103519, "cdate": 1761373103519, "tmdate": 1762926933251, "mdate": 1762926933251, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This study introduces a technique utilizing guidance to incorporate watermarks into the diffusion-based image creation workflow. By sourcing the guidance from an existing watermark decoder, it adapts after-the-fact watermarking approaches into on-the-fly methods that work seamlessly with various guided generation systems. The evaluations assert that it achieves durable watermarking while preserving the visual fidelity and meaning of the images."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Employing guidance strategies to enable in-generation watermark integration within diffusion frameworks opens up a compelling avenue for exploration. \n2. The system's capacity to merge established after-the-fact watermarking methods with guided  generation processes offers significant utility in application. \n3. Overall, the manuscript is structured effectively and easy to follow."}, "weaknesses": {"value": "1.\tFor embedding watermarks in individual images, the approach imposes an excessively high computational burden. Conducting complete denoising operations to derive guidance at every noise level far surpasses the time required for standard generation (as evidenced in Appendix E). This greatly hampers its applicability to extensive image production scenarios.\n2.\tThe tuning complexity prevents the method from being a true 'plug-and-play' solution. As illustrated in Appendix B, Figure 6, setting the guidance strength ($\\omega$) too high can introduce severe visual artifacts into the generated image, necessitating careful calibration for different models and decoders."}, "questions": {"value": "1.\tThe proposed method relies on a public, off-the-shelf decoder to compute gradients. Does this imply that an attacker, upon obtaining a watermarked image, could actively erase the watermark by computing and applying an 'adversarial' or 'reverse' guidance gradient aimed at minimizing the decoder's output (i.e., a white-box adaptive attack)?\n2.\tRegarding the 'fast guidance' experiments in Section 5.5, were the results (e.g., \"G-VS last 15\") obtained by applying *both* the 'step reduction' (simplification 1) and the 'gradient approximation' ($\\nabla_{z_{0}}$ instead of $\\nabla_{z_{t}}$, simplification 2) strategies simultaneously? If so, what is the respective contribution of each simplification strategy to the observed performance degradation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CtcIkXs0sm", "forum": "5ifzhjMCKq", "replyto": "5ifzhjMCKq", "signatures": ["ICLR.cc/2026/Conference/Submission16903/Reviewer_wPqL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16903/Reviewer_wPqL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16903/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762079427540, "cdate": 1762079427540, "tmdate": 1762926932910, "mdate": 1762926932910, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a method that embeds digital watermarks directly during the diffusion sampling process. The approach leverages gradients from pretrained watermark decoder to guide the diffusion model toward generating images that the decoder recognizes as watermarked. It embeds the watermark during generation using a cosine-based loss that aligns decoder features with a target watermark vector, and aggregates gradients across image augmentations to enhance robustness to unseen attacks. No need to retrain the decoder."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The method is general and retraining-free. It can transform any existing post-hoc watermark decoder into an in-generation embedding scheme without retraining either the decoder or the diffusion model.\n2. The method is empirically validated on multiple diffusion models and decoders.\n3. The method has a unified formulation for multi-bit and zero-bit watermarking."}, "weaknesses": {"value": "1. The approach requires a pretrained differentiable watermark decoder (e.g. stable signature). Its performance and the statical guarantees are bound by the robustness and isotropy of that decoder's feature space. If the decoder is biased or unavailable, the framework can't work.\n2. The attack scope is narrow. The experiments focus on standard image augmentations (JPEG, crop, brightness). Other relevant attacks like regeneration attacks, adversarial attacks should also be tested.\n3. No ablation on guidance scheduling. The method mentions turning on guidance only for the last diffusion steps (section 4.5). But there is little analysis on how the choice of step $T_w$, clipping thresholds, or gradient aggregation method affects detectability or quality."}, "questions": {"value": "1. All experiments are conducted on latent diffusion model. I'm wondering its effectiveness  on pixel-based diffusion models."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GLgwO9fb0B", "forum": "5ifzhjMCKq", "replyto": "5ifzhjMCKq", "signatures": ["ICLR.cc/2026/Conference/Submission16903/Reviewer_7E16"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16903/Reviewer_7E16"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16903/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762880131617, "cdate": 1762880131617, "tmdate": 1762926932536, "mdate": 1762926932536, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}