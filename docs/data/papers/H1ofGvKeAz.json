{"id": "H1ofGvKeAz", "number": 21788, "cdate": 1758321764067, "mdate": 1759896902844, "content": {"title": "Grounding the Ungrounded: A Spectral-Graph Framework for Quantifying Hallucinations in multimodal LLMs", "abstract": "Hallucinations in LLMs—especially in multimodal settings—undermine reliability. We present a rigorous, information-geometric framework in diffusion dynamics that quantifies hallucination in MLLMs: model outputs are embedded spectrally on multimodal graph Laplacians, and gaps to a truth manifold define a semantic-distortion metric. We derive Courant–Fischer bounds on a temperature-dependent hallucination energy and use RKHS eigenmodes to obtain modality-aware, interpretable measures that track evolution over prompts and time. This reframes hallucination as measurable and bounded, providing a principled basis for evaluation and mitigation.", "tldr": "We propose an energy-based, temperature-controlled spectral hypergraph framework for multimodal LLMs that quantifies hallucinations, yields KL-calibrated Rayleigh–Ritz bounds, and proves diffusion-time decay.", "keywords": ["Multimodal large language models", "Hallucination detection", "Hallucination quantification", "Energy-based models", "Spectral graph theory", "Hypergraph Laplacian", "Graph signal processing", "Diffusion kernel (heat kernel)", "Rayleigh–Ritz bounds", "KL divergence calibration", "Temperature scheduling", "Semantic distortion", "Cross-modal alignment", "RKHS / kernel methods"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/60736423993eb64eb969b38b784225d5da30de36.pdf", "supplementary_material": "/attachment/ec71a7262662d7320c540026cbc0e306bc9b6824.pdf"}, "replies": [{"content": {"summary": {"value": "The paper proposes a rigorous theoretical framework that reframes hallucination as a measurable and bounded phenomenon. By embedding model outputs on multimodal graph Laplacians and modeling their divergence from a truth manifold as a spectral energy, the authors derive Courant–Fischer bounds and temperature-dependent decay dynamics that quantify how hallucination evolves over time. Using a KL-smoothed, reference-free semantic distortion score and energy-based modeling within RKHS, the framework unifies information geometry, diffusion processes, and graph theory. Experiments across COCO, VQAv2, and AudioCaps with multiple model stacks show consistent improvements over entropy- and margin-based baselines. While the method is mathematically elegant and modality-interpretable, it is complex, computationally heavy, and tested only on modular pipelines, leaving questions about scalability and practical integration into real-world MLLMs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Modality-Aware and Interpretable. The method handles text, vision, and audio jointly using a product kernel representation. \n\nReference-Free Metric. Unlike dataset-based hallucination detection, this method does not require external ground truth, making it suitable for open-domain or partially verifiable tasks."}, "weaknesses": {"value": "Strong Hyperparameter Dependence. Requires tuning of several sensitive parameters.\n\nLack of Comparison with Practical Mitigation Methods. No comparison against RLHF, Contrastive decoding, attention fix methods."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "wU1LijefFa", "forum": "H1ofGvKeAz", "replyto": "H1ofGvKeAz", "signatures": ["ICLR.cc/2026/Conference/Submission21788/Reviewer_Srkz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21788/Reviewer_Srkz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21788/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761796754550, "cdate": 1761796754550, "tmdate": 1762941932069, "mdate": 1762941932069, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the problem of hallucination in multimodal large language models (MLLMs) by proposing a principled, information-geometric framework for quantitative measurement. Unlike prior heuristic or annotation-based methods, the approach embeds model outputs on multimodal graph Laplacians and measures their deviation from a truth manifold as a semantic-distortion metric.\nUsing diffusion dynamics and RKHS eigenmodes, the authors derive Courant–Fischer bounds on a temperature-dependent “hallucination energy,” providing interpretable, modality-aware measures that evolve over prompts and time. Experiments across multiple MLLM configurations (e.g., CLIP, Whisper, T5, BLIP) validate the theoretical results, showing consistent spectral behavior under varying temperatures."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The study of hallucination in LLMs and MLLMs is an important and timely research topic.\n\n2. This work provides a theoretical grounding for hallucination quantification, offering valuable insights and potential guidance for future research in this area.\n\n3. The open-sourced codebase enhances reproducibility and supports further validation by the community."}, "weaknesses": {"value": "As I am not familiar with the theoretical aspects, my assessment focuses mainly on the experimental design and empirical evaluation:\n\n1. The experimental setup does not fully align with the paper’s claim. Although the authors aim to address hallucination in LLMs/MLLMs, the experiments only involve traditional multimodal models such as BLIP, CLIP, Whisper, and T5, rather than modern autoregressive LLMs like Qwen-Audio/VL/Omni or the GPT-4/5 series. This limitation significantly constrains the paper’s potential impact and generalizability.\n\n2. The effectiveness of the proposed method remains uncertain. As shown in Table 1, the improvement is relatively modest, with around 3% on simpler tasks such as captioning. Its applicability and scalability to more complex reasoning tasks or stronger LLM backbones remain unclear.\n\n3. I'm also curious about the efficiency. For both autoregressive and non-autoregressive models, does the proposed framework introduce additional inference overhead or reduce generation speed compared to the original model?"}, "questions": {"value": "Please see the weaknesses part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "abZsylUMQ1", "forum": "H1ofGvKeAz", "replyto": "H1ofGvKeAz", "signatures": ["ICLR.cc/2026/Conference/Submission21788/Reviewer_hBmJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21788/Reviewer_hBmJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21788/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761835868379, "cdate": 1761835868379, "tmdate": 1762941931810, "mdate": 1762941931810, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a theoretical and quantitative framework for measuring hallucinations in multimodal large language models (MLLMs).\nThe authors model hallucination as a measurable deviation from a “truth manifold” within a multimodal RKHS, where model outputs are represented as nodes on a multimodal graph. Specifically, the paper presented 1. a KL-calibrated semantic distortion score that serves as a reference-free metric for hallucination; 2. a multimodal energy-based formalism; 3. a spectral decomposition of hallucination energy through eigenmodes of a multimodal Laplacian."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper aims to quantify hallucination via information metrics, which is a novel perspective.\n\n2. The paper aims to define measure from mathematical formulations, which paves the way for rigorous evaluations and analysis."}, "weaknesses": {"value": "1. There is a general lack of motivation for the development of formulations in the paper. While $K_g$ appears in early set-ups, all subsequent developments are built on $K$. The paper neither discuss how $K$ and $K_g$ are different in practical LLM usages, nor provide clues on how $K$ is obtained in experiments (is it dependent on the specific LLM, training data or evaluation data?), making the definition of hallucination idealized and not connected to practice.\n\nFurthermore, the paper does not exhibit the need for introducing information metrics to quantify hallucination at the cost of computation complexity. Namely, why cannot hallucination be simply quantified as a mean Hilbert distance between MLLM generations and $K$? There is a general lack of discussion for the properties and necessities for the measure it proposed.\n\n2. In presenting the theorems, there is a lack of logic flow and therefore the reader are prone to get confused. For both Theorem 1 and theorem 2, there are hidden assumptions are not explicitly presented before the theorem, (for instance line 977 in the proof of Theorem 1; for theorem 2 how the energy form in (8) is linked to (10) as a polynomial form of the embeddings), which makes the theorems very confusion. Upon reading the theorem, the reader cannot understand what is needed to be proved in the theorem, making the statements lacking in mathematical rigor.\n\n3.  The measure in Theorem 1 is not a mathematically natural measure as it incorporates the truncation operator ([]+) in its calculation, making the measure not continuous in space. While the paper claims that the measure is $=0$ on $K$ and $>0$ outside $K$, the proof can only show that the untruncated measure is $<0$ on $K$, therefore given the continuous nature of the function, the claim is highly likely unreliable and there must also be $x\\not\\in K$ for which $d(x)=0$.\n\n4. For Section 5, despite the paper decomposes the energy into eigenspaces and shows bounds in terms of the spectrum, there is a lack of analysis on the actual scale and shape of spectrums for real MLLMs. Therefore the reader cannot get useful messages, conclusion or insights from the establish of formulations and derivations. First, the Courant–Fischer bounds are given to the hallucination energy, and there is still a large gap between energy and observables like hallucination rates or sematic distances. Second, some unmeasurable coefficients (m(t) , M(t) for instance) are introduced to present the result, whose shape we cannot know in practice. Third, the time is a confusion factor in the analysis as it does not correspond to the real time in MLLM applications, and the read cannot know what assumptions are made w.r.t. time."}, "questions": {"value": "Please refer to the weakness part for questions.\n\nIn section 5: why is there \"time\" in the analysis? Is it the annealing process of an MLLM whose parameters are left unchanged? How does it relates to practical MLLM behaviors?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sC5wo5fq26", "forum": "H1ofGvKeAz", "replyto": "H1ofGvKeAz", "signatures": ["ICLR.cc/2026/Conference/Submission21788/Reviewer_U1EW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21788/Reviewer_U1EW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21788/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762233510180, "cdate": 1762233510180, "tmdate": 1762941931580, "mdate": 1762941931580, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a theory-backed, modality-aware framework to quantify hallucination as a continuous quantity rather than a binary label. The core statistic is a KL-smoothed semantic distortion $d^{(\\varepsilon,h)}_{\\text{sem}}$ that is $0$ on an admissible set $K$ of “grounded” outputs for a prompt and $>0$ off $K$, obtained by contrasting a $K$-restricted smoother with an unconditional smoother. On top of this, the authors build a multimodal hypergraph over outputs and define a hallucination energy via a spectral graph-Laplacian formulation, with Courant–Fischer bounds providing theoretical envelopes for the energy. They evaluate across three datasets (COCO Captions, VQAv2, AudioCaps) and three inference stacks, reporting AUROC/AUPRC against uncertainty baselines (entropy, max-prob, margin) and visualizing energy surfaces versus $\\varepsilon$ and temperature. Results indicate consistent gains over baselines and empirical consistency with the spectral bounds, while practical details (how $K$ is constructed/normalized per dataset, tighter bound diagnostics, and artifact completeness) remain under-specified in the main text."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "•\tClear positioning: gap = no theory-backed, modality-aware framework that quantifies hallucinations.\n\n•\tProposes a KL-smoothed semantic distortion $d^{(\\varepsilon,h)}_{\\text{sem}}$ that is $0$ on an admissible set $K$ and $>0$ off $K$, via a $K$-restricted vs. unconditional smoother (Eq. 6).\n\n•\tHypergraph construction is naturally multimodal, yields a hallucination energy, and admits CF bounds.\n\n•\tEmpirically validates theory (three datasets × three stacks) and outperforms baselines (AUROC/AUPRC).\n\n•\tMathematical development is careful: assumptions explicit, derivations clear, measurability addressed."}, "weaknesses": {"value": "1.\t**Primary weakness:** Dense formalism buries the practical message—what problems does this framework actually solve, and under what conditions should practitioners prefer it over standard uncertainty baselines? Also, please explain how the mathematical assumptions for the theorems (beyond “g-free” which is adequately explained) are translated to real world scenarios.\n2.\t“Reference-free” vs. operational $K$: Reconcile the “independent-of-$g$” claim with the use of a finite admissible set $K$ and selector $\\Pi_K$. Add a short subsection on what is observable, assumed, and estimated **and how this connects to plausible practical scenarios.** Also, please explain the advantage of a continuous (not binary) hallucination quantity.\n3.\t$K$ construction & labeling unclear: Specify $K(p)$ per dataset (COCO captions; VQAv2 normalized unique answers; AudioCaps references) and provide the exact normalization/tokenization for membership. \n4.\tBaselines: Describe each competitor in the main text, and why this choice of competitors suffices.\n5.\tEmpirical Bounds:  In Fig. 3 the CF planes appear loose and the explored $\\varepsilon$ range seems narrow. Justify ranges and report quantitative gap-to-bound stats (median/percentiles) and their relation to errors.\n6.\tUnclear mathematical roadmap: Add a one-paragraph roadmap (“first…, then…, finally…”). A symbol table is adviseable too.\n7.\tEquation numbering issues: In Sec. 5.3 numbering appears misaligned (mirrors appendix). Please fix.\n8.\tConclusion takeaways. Distill actionable guidance, e.g. where this fits; when energy vs. score is most predictive. Add practical takeaways to method: default choices for $\\varepsilon, h, T_t$, etc.\n9.\tPlease perform literature check. For instance, I could not verify “Spectral characterization of hallucination in large language models.” This may even undermine authenticity of writing. Please clarify."}, "questions": {"value": "See weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "k3Fo3WY2lQ", "forum": "H1ofGvKeAz", "replyto": "H1ofGvKeAz", "signatures": ["ICLR.cc/2026/Conference/Submission21788/Reviewer_4vEN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21788/Reviewer_4vEN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21788/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762277520754, "cdate": 1762277520754, "tmdate": 1762941931190, "mdate": 1762941931190, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}