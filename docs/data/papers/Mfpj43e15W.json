{"id": "Mfpj43e15W", "number": 1116, "cdate": 1756843223596, "mdate": 1763478280281, "content": {"title": "ReSWD: ReSTIR‘d, not shaken. Combining Reservoir Sampling and Sliced Wasserstein Distance for Variance Reduction.", "abstract": "Distribution matching is central to many vision and graphics tasks, where the widely used Wasserstein distance is too costly to compute for high dimensional distributions. The Sliced Wasserstein Distance (SWD) offers a scalable alternative, yet its Monte Carlo estimator suffers from high variance, resulting in noisy gradients and slow convergence. We introduce Reservoir SWD (ReSWD), which integrates Weighted Reservoir Sampling into SWD to adaptively retain informative projection directions in optimization steps, resulting in stable gradients while remaining unbiased. Experiments on synthetic benchmarks and real-world tasks such as color correction and diffusion guidance show that ReSWD consistently outperforms standard SWD and other variance reduction baselines.", "tldr": "Combining Reservoir Sampling and Sliced Wasserstein Distance for Variance Reduction for various matching applications.", "keywords": ["Sliced Wasserstein Distance", "Variance Reduction", "Weighted Reservoir Sampling", "Color matching", "Distribution matching", "Optimal Transport"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/564c4837f0537fbf7912189c498ad04ac796c51c.pdf", "supplementary_material": "/attachment/32d02adfdb4886096c329b61497d2c762db47db3.zip"}, "replies": [{"content": {"summary": {"value": "The paper “ReSWD: ReSTIR’d, Not Shaken” introduces Reservoir Sliced Wasserstein Distance (ReSWD), a variance-reduced and unbiased variant of the Sliced Wasserstein Distance (SWD) for efficient distribution matching in high-dimensional settings. By integrating Weighted Reservoir Sampling (WRS), a technique inspired by real-time rendering (ReSTIR), ReSWD adaptively retains projection directions that contribute most to the loss, leading to smoother gradients and faster convergence without bias. The method employs time-decay weighting, effective sample size control, and reuses informative directions across optimization steps. Experiments on synthetic benchmarks, color correction, and diffusion model guidance demonstrate that ReSWD consistently outperforms standard SWD and existing variance reduction approaches, improving both accuracy and computational stability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Novel integration of rendering and optimal transport: ReSWD creatively bridges computer graphics (ReSTIR) and machine learning (SWD), introducing a new, cross-disciplinary variance reduction method.\n\n2. ReSTIR provides stable and low-variance gradients while remaining unbiased, directly improving optimization speed and robustness.\n\n3.  Across both synthetic and real-world tasks (color correction and diffusion guidance), ReSWD shows consistent and measurable performance gains over SWD and prior baselines.\n\n4. The method adds minimal computational overhead compared to SWD but achieves substantial improvements in convergence and stability.\n\n5. ReSWD can be plugged into any optimization pipeline involving SWD, making it useful for computer vision, graphics, and generative modeling tasks.\n\n6.  The reservoir sampling framework provides an intuitive way to focus computation on the most informative directions, improving interpretability and control."}, "weaknesses": {"value": "1. Dependency on hyperparameters: The performance relies on careful tuning of parameters such as reservoir size, number of new directions, and time-decay constant, which may vary across tasks.\n\n2. Initial warm-up lag: During early optimization, ReSWD may perform slightly worse than standard SWD until the reservoir becomes well populated, introducing a short initial slowdown.\n\n3. Added implementation complexity: While computational cost is low, integrating the reservoir update and WRS mechanism adds code complexity compared to the simplicity of vanilla SWD."}, "questions": {"value": "1. Can we use Quasi-Monte Carlo for reservoir construction? It seems that Weighted Reservoir Sampling  is an orthogonal techniques to existing variance reduction approaches for SWD. If the author agrees with my comments, some discussion should be added to the paper.\n\n2. Sliced Wasserstein distance can be computed for unequal sample sizes (see Section 2.3 in [1]). Why, then, is it necessary to make the sample sizes equal? This approach may lead to faster computation; however, I wonder whether the performance of applications would change if we did not resample to obtain equal sample sizes. The authors should also mention that the Sliced Wasserstein distance can be computed for any discrete distributions after equation (1) and cite the relevant works to avoid potential misunderstandings about the applicability of SWD.\n\n3. Self-normalized weights are similar to the Sampling Importance Resampling approach in energy-based sliced Wasserstein [2]. The authors wrote that \"This remains an unbiased MC estimate of $\\mathbb{E}_\\theta [W_p]$\" (line 228). Is $\\theta$ is still uniform distributed?\n\n[1] \"An Introduction to Sliced Optimal Transport\", Khai Nguyen\n\n[2] \"Energy-based Sliced Wasserstein Distance\", Nguyen et al."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Kf3nLkwS9e", "forum": "Mfpj43e15W", "replyto": "Mfpj43e15W", "signatures": ["ICLR.cc/2026/Conference/Submission1116/Reviewer_a2rM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1116/Reviewer_a2rM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1116/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760887718583, "cdate": 1760887718583, "tmdate": 1762915683463, "mdate": 1762915683463, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "We like to thank all reviewers for their feedback. We address each concern in a direct comment. The reviewers found that the key idea of “keeping `good’ directions for SWD gradient descent seems intuitive and useful” (3dAY, a2rM) with a2rM specifically highlighting the “Novel integration of rendering and optimal transport”. They also note that we “demonstrated the advantages of ReSWD on both real-world applications and synthetic distribution matching problems” (d1cU, Mt3n, Kxjt, a2rM). The method achieves “consistent empirical gains over standard SWD, QMC, and control variates” (Mt3n, d1cU, a2rM). They also remark that we provide a “good selection of experiments” (Mt3n, Kxjt, 3dAY, a2rM) and Kxjt specifically highlights the benefits of “Color Decision List, which greatly improves controllability for subsequent manual edits”. Furthermore, the paper is “well-written and the key challenge is clear” (3dAY, Kxjt) and 3dAY specifically emphasizes the explanatory video in the supplements. \n\nWe hope to alleviate most concerns in this rebuttal and that the reviewers will raise their scores accordingly. We have already incorporated the changes into the next revision of our manuscript."}}, "id": "H5Dic1GO0K", "forum": "Mfpj43e15W", "replyto": "Mfpj43e15W", "signatures": ["ICLR.cc/2026/Conference/Submission1116/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1116/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1116/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763478036177, "cdate": 1763478036177, "tmdate": 1763478036177, "mdate": 1763478036177, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Sliced Wasserstein estimates enable comparison of high-dimensional distributions and are often used as loss functions in gradient-based optimization. Their computation relies on Monte Carlo approximation through random projections. In recent years, there has been growing interest in the 'smart' selection of projection directions. The authors contribute to this line of work by introducing a Monte Carlo sampling scheme tailored for optimization that reuses projection directions found to be informative during training."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The key idea of keeping `good’ directions for SWD gradient descent seems intuitive and useful.\n- The key ideas are well-explained and the visualized.\n- The paper is well-written and the key challenge is clear.\n- The experiments are suitable for the method in question\n- The authors added a nice explanatory video in the supplementary material"}, "weaknesses": {"value": "- The reported quantitative improvements over standard SWD are very minor.\n\n- While the authors mention alternatives to standard Monte Carlo SWD, they mostly do not compare against it. There exist numerous spherical slicing schemes that should be compared against, see\n\t- Quasi-monte carlo for 3d sliced Wasserstein (Nguyen et al, 2023)\n\t- Fast summation of radial kernels via QMC slicing (Hertrich et al, 2024)\n\t- Energy-based sliced Wasserstein distance (Nguyen & Ho, 2023)\n\t- A User's Guide to Sampling Strategies for Sliced Optimal Transport (Sisouk et al, 2025)\n\t- MaxSliced Wasserstein, Repulsive Monte Carlo, ….\n\n- Generally, I would not consider color matching as the `ideal’ application for such experiments as the success mostly depends on the color palette, e.g., “RGB” vs “HGL” vs “HSV” et.\n\n- The paper relies heavily on a few visual examples, which take up a lot of space. However, visual differences between most methods are very minor.\n\n- The main idea is mainly a straightforward application of the ideas in (Efraimidis & Spirakis, 2006)\n\n- Code is missing\n\nConclusion:\nWhile the idea is intuitive and potentially useful, I feel as if the reported experiments do not support the clear advantage of the method. Moreover, the extensive research on the 'smart' selection of slicing directions has not really been covered."}, "questions": {"value": "- Figure 2 shows “Calculate Loss $W_p^p$. Do you mean `Calculate Loss SWD’? Both formulations make sense, but it might be useful to add “1D $W_p^p$” to avoid confusion if it actually is $W_p^p$”.\n\n- In Section 3, the cardinality of X is set to $n_X$ and $n_Y$ for Y, but in Eq. (1) it is assumed that $n=n_X =n_Y$. If $n_X\\neq n_Y$ a more general formula is needed. \n \n- The statement ‘The SWD is an unbiased estimate of the true Wasserstein distance’ (line 159) is incorrect. I assume that you refer to the true SWD distance and the numerical estimator?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jedvo1Ux9C", "forum": "Mfpj43e15W", "replyto": "Mfpj43e15W", "signatures": ["ICLR.cc/2026/Conference/Submission1116/Reviewer_3dAY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1116/Reviewer_3dAY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1116/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761652239121, "cdate": 1761652239121, "tmdate": 1762915683328, "mdate": 1762915683328, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The n authors noted that while various variance reduction techniques exist for Monte Carlo (MC) estimators, they are not widely used for distribution matching objectives. They created a new estimator called Reservoir SWD (ReSWD). They  draw inspiration from a rendering technique called ReSTIR and a sampling algorithm called Weighted Reservoir Sampling (WRS) and adapt WRS to the Sliced Wasserstein Distance (SWD) setting."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1) Their method reduces stochastic variance, preserves unbiasednes and leads to faster and more robust optimization.\n\n2)  They demonstrated the advantages of ReSWD on both real-world applications (color correction and color diffusion guidance) and synthetic distribution matching problems, showing it outperforms the standard SWD and other baseline methods\n\n3) Their method demonstrates the scalability"}, "weaknesses": {"value": "1) The method concentrates on directions where the distributions are \"most dissimilar.\" There is a risk that the optimizer could over-optimize for these specific directions in the reservoir at the expense of the overall distribution match.\n\n2)The method concentrates on directions where the distributions are \"most dissimilar.\" There is a risk that the optimizer could over-optimize for these specific directions in the reservoir at the expense of the overall distribution match.\n\n3)The text emphasizes that the estimator preserves unbiasedness. This is a theoretical strength for the value of the distance estimate. However, in optimization, what matters most are the gradients?\n\n4) The method seems more complex than standard SWD. It requires correctly implementing the WRS algorithm and integrating it with the gradient update process."}, "questions": {"value": "1) The WRS process adds per-step overhead. Was there a measurable trade-off where this overhead outweighed the benefits of variance reduction, especially in the early stages of optimization or for very simple problems?\n\n\n2) Why choose WRS over other variance reduction techniques like control variates or stratified sampling adapted for this setting?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "25ncAjpeyr", "forum": "Mfpj43e15W", "replyto": "Mfpj43e15W", "signatures": ["ICLR.cc/2026/Conference/Submission1116/Reviewer_d1cU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1116/Reviewer_d1cU"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1116/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761913986043, "cdate": 1761913986043, "tmdate": 1762915683214, "mdate": 1762915683214, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper combines Weighted Reservoir Sampling (WRS) and the Sliced Wasserstein Distance (SWD) to propose ReSWD. SWD, introduced to mitigate the curse of dimensionality, still suffers from noisy gradients and slow convergence when used as a loss function in optimization scenerios. This drawback is caused by the high variance of SWD's Monte Carlo estimator. By adaptively retaining the projection directions that are most dissimilar between the two distributions, ReSWD significantly reduces variance while preserving unbiasedness. The experiments presented in the paper show that ReSWD not only surpasses the standard SWD across various tasks, but also outperforms previous SOTA benchmarks on real-world tasks such as color matching and color-guided diffusion image generation."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. ReSWD addresses real-world color matching problems from the perspective of distribution matching, providing a more data efficient and stable solution to such applications. ReSWD enables the authors to tackle the color matching problem using the Color Decision List, which greatly improves controllability for subsequent manual edits.\n\n2. The paper incorporates good practices from prior works, such as Bitterli et al., 2020 and Elnekave & Weiss (2022), facilitating ReSWD's ESS-based reservoir resets and handling of unequal sample counts.\n\n3. The paper is clearly and thoroughly presented. Section 3.1 includes a concise yet precise definition of the problem and highlights the limitations of SWD. Section 3.2 introduces the proposed method in a well-structured, step-by-step manner, accompanied by a clear and detailed pseudocode for its algorithm."}, "weaknesses": {"value": "1. Table 1 and 3 show the superiority of ReSWD over SWD. However, the performance gap between the two methods seems relatively small, especially for real-world tasks like color matching. It would be very helpful for readers to better assess the effectiveness of ReSWD if visual results of the standard SWD are given in Figure 5 and 6.\n\n2. Both line 217 of the main text and line 11 of Algorithm 1 state that the *smallest* K keys should be kept. However, based on the definition for $k(\\theta)$ given in the paper and the fact $u \\sim \\mathcal{U}(0,1)$, it appears to me that the *largest* K keys should be kept. I would be glad to revise my assessment if the authors can clarify this point and demonstrate why the smallest keys are correct in this context.\n\n3. According to Algorithm 1, it appears time-decay reweighted keys $\\tilde{k_i}$ are not actually used and are overwritten at line 9. If my interpretation is incorrect, I would appreciate clarification from the authors. Again, I would be glad to revise my assessment in that case.\n\n4. The last row (# Candidates = 56) shows the lowest time per step (1.85s) in Table 2. However 1.91ms and 1.92 ms are marked as fastest instead.\n\n5. If I understand correctly, Figures 6 shows ReSWD outputs generated with SD3.5 while the results of Lobashev et al. (2025) are generated with SDXL. The comparison may not be fair. The visual comparison would be more appropriate if the same SD model is used for both methods, as demonstrated in Table 4's first two rows."}, "questions": {"value": "1. Methods like chatGPT's new image generation model and Gemini's nano banana have shown impressive re-lighting performance recently. I wonder if the authors have tried to compare ReSWD's color matching results with these methods?\n\n2. Lines 420-421: why a SDS-style gradient stopping \"does not have any influence on the guidance\"? Could the authors give expression of the gradient, similar to equation (3) in \"DREAMFUSION: TEXT-TO-3D USING 2D DIFFUSION\"?\n\n3. See 2 and 3 in the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ctVLRZxT6z", "forum": "Mfpj43e15W", "replyto": "Mfpj43e15W", "signatures": ["ICLR.cc/2026/Conference/Submission1116/Reviewer_Kxjt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1116/Reviewer_Kxjt"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1116/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761958341568, "cdate": 1761958341568, "tmdate": 1762915683070, "mdate": 1762915683070, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ReSWD, a Sliced Wasserstein Distance estimator that reduces gradient variance in optimization by reusing informative projection directions via Weighted Reservoir Sampling, inspired by ReSTIR. At each step, the method evaluates a pool of K (reservoir) + M (new) directions, keeps K survivors using WRS keys and computes a self-normalized estimate. A time-decay factor and ESS-based resets adapt to non-stationarity and prevent weight collapse. Empirically, ReSWD improves optimization stability and final quality across synthetic distribution matching, color correction, and diffusion color guidance, with modest runtime overhead. The idea is simple and broadly applicable. However, theoretical guarantees (especially unbiasedness under multi-item WRS, time decay, and self-normalized weighting) are insufficiently justified."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "(i) The paper offers a simple, practical variance-reduction mechanism for SWD that is easy to integrate in differentiable pipelines\n\n(ii) The paper shows consistent empirical gains over standard SWD, QMC, and control variates on synthetic and real tasks\n\n(iii) The paper has a good selection of experiments for color correction with a Color Decision List and diffusion guidance"}, "weaknesses": {"value": "(i) Limited analysis of gradient variance reduction (no quantitative gradient variance or convergence-rate studies)\n\n(ii) Although SDXL variants are reported, fairness could be clearer (model was switched to SD3.5 and the optimizer was changed)\n\n(iii) Missing baseline against Max-SW, which the authors claim is closely related (see related work section)\n\n(iv) Evaluation largely in low-dimensional color spaces (d=3) and lacks tests on higher-dimensional feature embeddings\n\n(v) Some design choices lack sensitivity analysis beyond fresh-candidate ablation\n\n(vi) The paper could benefit from more detailed derivations"}, "questions": {"value": "In addition to the weaknesses outlined in points (i-vi), I present the following questions for the authors to address:\n\n(1) Please provide a formal derivation of the estimator: What are the exact inclusion probabilities under WRS for K>1, and how do they justify the weighting scheme in equation (7)?\n\n(2) How do time-decay and ESS resets affect consistency? Are there any theoretical bounds?\n\n(3) The paper argues about the stability of gradients. Can you report gradient variance (or signal-to-noise) over training steps vs. SWD/QMC?\n\n(4) How does ReSWD perform with higher-dimensional features?\n\n(5) Could you include Max-SW as a baseline, and clarify trade-offs vs. your approach?\n\n(6) In diffusion guidance, can you isolate the contribution of ReSWD from other changes (optimizer, gradient stop) on the same base model with identical settings?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "SbFjEr9O34", "forum": "Mfpj43e15W", "replyto": "Mfpj43e15W", "signatures": ["ICLR.cc/2026/Conference/Submission1116/Reviewer_Mt3n"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1116/Reviewer_Mt3n"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission1116/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761983748995, "cdate": 1761983748995, "tmdate": 1762915682949, "mdate": 1762915682949, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}