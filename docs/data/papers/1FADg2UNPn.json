{"id": "1FADg2UNPn", "number": 8428, "cdate": 1758082959616, "mdate": 1759897784546, "content": {"title": "Refining Specs For LLM-Based RTL Agile Design", "abstract": "Large language models (LLMs) are increasingly employed to assist in agile register-transfer-level (RTL) hardware design. This is a labor-intensive stage in developing FPGA-based acceleration services or prototyping ASICs, and successful automation can largely shorten the development cycle. However, benchmarks are reporting a relatively low functional correctness rate when generating simple modules of less than 100 LOC (in Verilog), questioning the practicality of current LLMs in complex real-world designs.\n\nThis paper points out that this low accuracy is affected by using low-quality descriptions as prompts in both training datasets and benchmarks. First, the testbench (TB) strictly enforces behaviors that are absent from the natural language descriptions (NLDs), leading to false negatives. Second, existing automatically generated NLDs are usually too detailed in implementation, which is not suitable for both training and benchmarking. We show by experiment that, when provided with detailed specifications, general-purpose LLMs can achieve a high pass@5 rate (89\\% on RTLLM, 96\\% on VerilogEval-Human) without expensive finetuning or post-generation self-fixing. This implies that LLMs are enough capable of generating small RTL modules in action. Our tools can improve the quality of existing and future LLM-for-RTL datasets, and assist agile RTL designers to create qualified specifications.", "tldr": "LLM-refined specs can help LLM RTL design agents to achieve over 90% pass@5 rate on RTLLM and VerilogEval benchmarks.", "keywords": ["prompt engineering", "LLM assisted design", "RTL design", "benchmark"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0c4e2ead2063b7e1140a32faa209d31698e677f0.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses the low functional accuracy of large language models (LLMs) in register-transfer-level (RTL) hardware design. The author presents an insightful perspective: the primary reason for the low accuracy is not the model's limitations, but rather the poor quality of the natural language descriptions (NLDs) used in existing benchmark tests. This issue is particularly evident in the mismatch between NLDs and the ground truth behavior, leading to false negatives, as well as overly detailed descriptions. To tackle this problem, the author proposes the \"Refined Spec\" paradigm, emphasizing the importance of providing clear, well-structured specification documents that focus on behavioral descriptions. Experimental results indicate that the quality of input specifications is crucial for the performance of LLMs in RTL design applications."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Novel insights. The paper shifts the research focus from the costly fine-tuning of large language models (LLMs) to the quality of input specifications (prompts), which offer greater engineering value. This finding is fundamentally important for advancing the practical application of LLMs in hardware design.\n\nEffective Guidance. The paper not only identified the problem but also provided a clear structure for a \"refined specification\" comprising six key components for future dataset creators and RTL engineers, which has significant practical value."}, "weaknesses": {"value": "The details of the automated generation tool are lacking. A core contribution of the paper is the proposed LLM-driven specification refinement toolchain. However, the specific prompts used for these tools, the detailed internal reasoning steps, and the descriptions of the automated workflows are too brief. This absence of essential information significantly undermines the reproducibility of the research findings.\n\nThe quantitative support for complex designs is lacking. While the author references the potential of complex tasks such as FFT and Conv2d, there is a notable absence of detailed quantitative pass@k rates for these large-scale, multi-module tasks. The available data are confined to simple modules, hindering a clear demonstration of this method's generalization capability in addressing complex real-world problems."}, "questions": {"value": "Scale capacity. Please provide detailed quantitative pass@k rates for complex tasks such as FFT or Conv2d to demonstrate the effectiveness of this method and its ability to be extended to large-scale designs.\n\nData leakage. Please discuss how to ensure that, during the generation of the refining specification, the GPT-4 used does not indirectly utilize the ground truth values of the original benchmark that may be present in the pre-training data.\n\nGeneralization. Can the specification's validity generalize across models, including open-source and closed-source models such as the Llama series and Claude?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uw3UKI0Ouo", "forum": "1FADg2UNPn", "replyto": "1FADg2UNPn", "signatures": ["ICLR.cc/2026/Conference/Submission8428/Reviewer_mB8U"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8428/Reviewer_mB8U"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8428/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761646315414, "cdate": 1761646315414, "tmdate": 1762920322579, "mdate": 1762920322579, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "Thank you for your comprehensive comments and suggestions. A revision of the paper, according to these suggestions, will be submitted after we finish the generalizability experiments, introducing additional models for both spec and code generation. While this may take some time, we can answer some of the questions based on existing results or theoretical considerations. We will soon comment on the reviews individually."}}, "id": "OGgL2bwtMV", "forum": "1FADg2UNPn", "replyto": "1FADg2UNPn", "signatures": ["ICLR.cc/2026/Conference/Submission8428/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8428/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8428/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763034930775, "cdate": 1763034930775, "tmdate": 1763034930775, "mdate": 1763034930775, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the low functional correctness of LLM-generated RTL designs, positing that this inaccuracy primarily stems from the poor quality and ambiguity of input specifications (specs). The authors identify two critical shortcomings in existing specifications: first, they are often too vague, leading to functional mismatches with golden models (GMs) and numerous false negatives during testing; second, some are overly detailed, effectively serving as direct translations of the implementation, which fail to properly evaluate the LLM’s high-level design capability. To address these issues, this work proposes a new framework for refining specifications by explicitly incorporating essential information such as I/O semantics, formulas, and sequential features, thereby minimizing behavioral discrepancies between the spec and the GM. Empirical results confirm the efficacy of this approach: when provided with these high-quality specs, general-purpose LLMs achieve substantially improved performance, with GPT-4 attaining a pass@5 score of 89.0% on RTLLM and 96.0% on VerilogEval-Human, suggesting that current LLMs are sufficiently capable of generating small RTL modules given precise requirements."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The problem addressed in this work is of considerable importance, as enhancing the accuracy of LLM-generated RTL designs could substantially shorten the hardware development cycle. This study’s primary contribution lies in its insightful shift in perspective, revealing that the low functional accuracy of LLM-generated RTL designs stems primarily from the poor quality of input specifications (specs). The identified phenomenon, i.e., the mismatch between specs and golden models (GMs), provides a crucial and actionable insight for constructing more reliable benchmarks and datasets in the future. Building on this diagnosis, the authors propose a simple yet effective solution: a refined specification framework that explicitly incorporates essential sequential and semantic features. The experimental results are compelling, demonstrating that with these refined specifications, general-purpose LLMs, e.g., GPT-4, achieve significantly improved performance in RTL design generation."}, "weaknesses": {"value": "While the main idea of this paper is insightful, several weaknesses diminish its overall academic rigor and impact. Foremost, the manuscript contains numerous typographical and grammatical errors (*e.g.*, the undefined acronym “LOC” in the Abstract and grammatical issues such as “their capability have...” on Line 34), which indicate a lack of thorough internal review and undermine the paper’s professional presentation. In addition, for ICLR submissions, the Abstract must be limited to a single paragraph, but the current version spans multiple paragraphs. Furthermore, the overall formatting and adherence to conference standards are suboptimal. The authors frequently misuse citation commands (*e.g.*, employing `\\citet` where `\\citep` is required by ICLR style) and omit mandatory or strongly recommended statements regarding ethics, reproducibility, and LLM usage.\n\nFrom a technical standpoint, the novelty appears limited. The proposed specification format, which primarily extends existing structures by incorporating sequential and semantic features, represents an incremental improvement, particularly since the authors themselves acknowledge its structural similarity to the manually constructed RealBench format. While employing an LLM-based converter to refine specifications adds convenience, the refinement methodology itself appears technically straightforward and may not meet the innovation threshold expected at ICLR.\n\nMoreover, the experimental validation lacks robustness and completeness. Evaluating the method on only two general-purpose LLMs restricts the generalizability of the findings, and the absence of discussion regarding the unexpected decline in Qwen-2.5-Coder’s pass@1 score (Table 1) introduces ambiguity that weakens the credibility of the central claim. To substantiate their conclusions, the authors should include additional experiments across a broader range of models, including those fine-tuned specifically for RTL generation.\n\nFinally, the Related Work section is insufficiently detailed. Although key dataset papers such as MG-Verilog, CodeV, and CraftRTL are cited, the authors fail to provide a substantive comparative discussion of these works’ data construction methodologies relative to their own LLM-based specification refinement. This omission represents a missed opportunity to situate the contribution within the broader landscape and to clarify its distinct advantages and limitations."}, "questions": {"value": "1. The paper presents a contradictory tension regarding the appropriate level of detail in specifications. On one hand, it argues that specifications should be \"not detailed in implementation\" and over-detailed NLDs are detrimental to benchmarking (Section 3.2). On the other hand, the proposed refinement requires the inclusion of highly specific information like \"sequential features\", \"formulas\", and precise \"I/O signal semantics\" (Section 3.3). What is the precise boundary or heuristic distinguishing beneficial, function-defining semantic detail (which the LLM requires) from detrimental, implementation-dictating detail (which confuses the LLM)? Clarifying this \"balancing point\" is crucial for future users of the specification framework.\n2. Table 2 shows that adding theoretically helpful components, such as examples (`Spec-cases`) and implementation briefs (`Spec-full`), actually decreases performance relative to the minimal `Spec-basic` configuration. This raises the question of what constitutes the best practical specification format. A more thorough ablation study is needed to determine which sub-components (e.g., Declaration, Behavior details, Sequential features, I/O details) are individually most beneficial.\n3. The current application of the \"converter\" tool relies on the existence of a golden model (GM) to identify missing requirements and correct misalignments between the specification and the GM/Testbench. If a designer or dataset curator wishes to apply the specification refinement methodology to a large-scale training dataset where GMs are *not* available, how should the refinement process be executed? Will models fine-tuned purely on a refined training dataset (without a debugging loop) demonstrate the same magnitude of performance improvement observed during benchmarking?\n4. The paper highlights the difficulty fine-tuned models have with high-level tasks despite training on low-level examples (Section 3.2). Notably, DeepRTL[1] employs a curriculum learning strategy, training on low-level prompts before proceeding to high-level ones. Could a similar curriculum approach mitigate the challenge identified in this work? Additionally, given the focus on better alignment between code and natural language, how does the structure and content of the final refined specification compare to the natural language descriptions constructed by DeepRTL, MG-Verilog, or CraftRTL? A detailed comparison is needed to establish novelty in this crowded research area.\n    \n    [1] Liu, Y., Changran, X. U., Zhou, Y., Li, Z., & Xu, Q. DeepRTL: Bridging Verilog Understanding and Generation with a Unified Representation Model. In *The Thirteenth International Conference on Learning Representations*.\n    \n5. The main results demonstrate performance gains for general-purpose LLMs (GPT-4 and Qwen2.5-Coder) when using the refined specification. To confirm the robustness and broader applicability of the refined specification, have the authors evaluated their specifications with LLMs specifically fine-tuned for RTL generation (*e.g.*, the CodeV-R1 or CraftRTL models mentioned in Table 1)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Oe88uqyPj1", "forum": "1FADg2UNPn", "replyto": "1FADg2UNPn", "signatures": ["ICLR.cc/2026/Conference/Submission8428/Reviewer_3WLA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8428/Reviewer_3WLA"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8428/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761730542625, "cdate": 1761730542625, "tmdate": 1762920322187, "mdate": 1762920322187, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the impact of natural language specification (NLD) quality on the performance of large language models (LLMs) for register-transfer-level (RTL) hardware code generation tasks. The authors identify sources of functional failures in existing benchmarks, attributing many to ambiguous or over-detailed prompts rather than core LLM architectural limits. They propose tools and a guided workflow to generate well-structured, human-friendly specs, demonstrate how improved specs can drastically boost LLM code correctness (e.g., GPT-4 pass@5 up to 96% on VerilogEval-Human), and analyze the interplay between spec configurations and empirical results."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Through targeted case studies, the paper documents how functional errors in generated RTL code are often due to missing or misaligned requirement details in the NLDs, not the inability of LLMs to handle the tasks.\n- The experiments show that proper specs can raise GPT-4 performance from ~55% to over 96% pass@5 on key benchmarks. This is an impressive improvement achieved with minimal additional annotation cost.\n- The tools—evaluator, converter, and creator—are practical. Detailed guides and templates are provided, demonstrating reproducibility and immediate usability for both dataset creators and practitioners."}, "weaknesses": {"value": "- The main contribution is in process/tooling/template and benchmarking methodology; there is no new LLM architecture, optimization method, or theoretical framework. While impactful in improving practical results, the intellectual advancement is more incremental and process-focused rather than fundamental.\n- Although the converter/creator tools are claimed to automate spec generation, the actual failure cases, limits of LLM-assistance for complex sequential logic, and required human intervention are only anecdotally illustrated. There is arguably an overestimate of how easily these tools can scale\n- The experiments focus mainly on GPT-4 (with some Qwen2.5 comparisons). Robustness to other LLMs, out-of-domain specs, dataset noise, or alternative code synthesis settings is underexplored.\n- There is no explicit discussion of code/data/method availability. While the methodology could be reconstructed from the paper, an explicit open-sourcing statement or link would help adoption.\n- While the work attributes errors to false negatives due to behavioral/mismatch in specs vs. testbenches, quantitative breakdowns (percentages, confusion matrices, etc.) across all classes of failures are sparse. The manual investigation in Section 3.1 notes \"over 30%\" FNs but lacks further statistical rigor."}, "questions": {"value": "- Please provide more detailed error/diagnostic analysis for false negatives/positives across RTLLM and VerilogEval—could you present confusion matrices or breakdowns by error type to clarify which failures are fixable by spec alone?\n- Are there plans to release your evaluator/converter/creator tools and enriched benchmarks, and if so, under what license?\n- Can the authors offer empirical insights (e.g., via ablation/connectivity experiments) into how well the methodology generalizes to other LLMs (e.g., Gemini, LLama)? Does the gain from spec refinement persist across backbone LLMs?\n- How practically usable is the creator tool for large/enterprise-scale RTL projects, especially for spec aspects that cannot be easily inferred without significant human domain expertise?\n- Beyond functional correctness, what is the observed impact of improved specs on physical design metrics (e.g., timing, power, area) if any? Do more precise specs bias LLMs toward certain microarchitectures or synthesis results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "B4VsiyymcO", "forum": "1FADg2UNPn", "replyto": "1FADg2UNPn", "signatures": ["ICLR.cc/2026/Conference/Submission8428/Reviewer_9Vxd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8428/Reviewer_9Vxd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8428/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761833888800, "cdate": 1761833888800, "tmdate": 1762920321843, "mdate": 1762920321843, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the crucial but overlooked role of natural language descriptions/specifications (NLDs/specs) in LLM-based register-transfer-level (RTL) hardware design automation. It points out systematic shortcomings in current benchmarks, where low-quality, ambiguous, or over-detailed task descriptions suppress LLM performance and induce false negatives in code validation. Through extensive analysis and case studies, the authors develop an LLM-based refined spec creation pipeline (including evaluator, converter, and creator tools) that produces clearer, appropriately scoped specs, empirically enabling large general-purpose LLMs (e.g., GPT-4) to achieve markedly higher pass@5 rates on standard Verilog code generation benchmarks without additional fine-tuning or self-fixing. The work further demonstrates that this approach improves LLM performance even on more complex design tasks and provides actionable tools for dataset creators and engineers."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The motivation of this paper (specification failures) is insightful and is analyzed with concrete case studies (Section 3.1/3.2);\n2. A systematic methodology for specification refinement backed by the development of practical LLM-powered evaluator, converter, and creator tools is proposed;\n3. Convincing experimental results is provided: general-purpose LLMs like GPT-4, provided only with high-quality specs (not fine-tuned on hardware data or reliant on expensive post-generation self-fixing), can achieve comparable performance to existing works."}, "weaknesses": {"value": "1. According to Table 1, only Qwen-Coder and GPT-4 were tested under the new NLDs. I suggest that the authors evaluate this specification refinement methodology on additional general-purpose LLMs and specialized RTL generation models to demonstrate its generalizability;\n2. In the Abstract, the authors claim that “this low accuracy is affected by using low-quality descriptions as prompts in both training datasets and benchmarks.” However, the paper provides no discussion on the issues related to training datasets. Furthermore, applying the proposed specification refinement method to these training datasets (1) poses greater challenges, as the RTL code therein is often fragmentary or erroneous and does not constitute a golden model (GM), and (2) may not intuitively yield benefits for enhancing model performance."}, "questions": {"value": "Please refer to the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0Uxhh6PkU3", "forum": "1FADg2UNPn", "replyto": "1FADg2UNPn", "signatures": ["ICLR.cc/2026/Conference/Submission8428/Reviewer_19Jy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8428/Reviewer_19Jy"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8428/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761878023808, "cdate": 1761878023808, "tmdate": 1762920321340, "mdate": 1762920321340, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}