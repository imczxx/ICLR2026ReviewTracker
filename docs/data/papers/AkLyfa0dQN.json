{"id": "AkLyfa0dQN", "number": 17379, "cdate": 1758275245895, "mdate": 1759897178799, "content": {"title": "ID-Cloak: Crafting Identity-Specific Cloaks Against Personalized Text-to-Image Generation", "abstract": "Personalized text-to-image models allow users to generate images of new concepts from several reference photos, thereby leading to critical concerns regarding civil privacy. Although several anti-personalization techniques have been developed, these methods typically assume that defenders can afford to design a privacy cloak corresponding to each specific image. However, due to extensive personal images shared online, image-specific methods are limited by real-world practical applications. To address this, we are the first to investigate the creation of identity-specific cloaks (ID-Cloak) that safeguard all images belong to a specific identity. Specifically, we first model an identity subspace that preserves personal commonalities and learns diverse contexts to capture the image distribution to be protected. Then, we craft identity-specific cloaks with the proposed novel objective that encourages the cloak to guide the model away from its normal output within the subspace. Extensive experiments show that the generated universal cloak can effectively protect the images. We believe our method, along with the proposed identity-specific cloak setting, marks a notable advance in realistic privacy protection.", "tldr": "", "keywords": ["Adversarial perturbations", "customized diffusion models", "privacy protection"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ff57e06d2fa6ce73fcecb9beca6e6f31a5520613.pdf", "supplementary_material": "/attachment/c1036cb52cc7d673030d0d0b40aa170c305b3cbc.zip"}, "replies": [{"content": {"summary": {"value": "In this paper, the authors propose an anti-personalization approach that creates identity-specific cloaks (ID-Cloak) designed to safeguard all images belonging to a particular identity. The proposed approach consists of two stept. First, they model an identity subspace that preserves personal commonalities and learns diverse contexts to capture the image distribution to be protected. Second, they craft identity-specific cloaks with the proposed novel objective that encourages the cloak to guide the model away from its normal output within the subspace. Extensive experiments (both qualitative and quantitative) show that their approach achieves robust protection across all images of an identity using a single universal mask."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Here are the paper's strength:\n- the paper is well-written and well-documented\n- the proposed approach is novel and scientifically sound (a novel protection paradigm)\n- the review of the state of the art covers most of the relevant literature in the field\n- the experimental evaluation is extended and confirms the starting hypothesis"}, "weaknesses": {"value": "Here are the paper's weaknesses:\n- While the empirical results are convincing, the authors should provide more formal justification why the learned subspace generalizes effectively across unseen identity sample\n- The experimental validation is currently limited to face datasets. To establish the proposed approach's generalizability, it is essential to demonstrate its effectiveness on other personalized domains (e.g. objects, artwork).\n- Some aspects require an improved clarity and a more detailed explanation, like the following statement in section 3.2.1 (lines 195-197): \"This formulation shifts the focus from complex image distributions to a more structured and interpretable text-based representation. Specifically, it allows us to model the protected identity’s image distribution by focusing on a semantically meaningful subspace in the text embedding space.\""}, "questions": {"value": "Besides the weaknesses mentioned above, here is the list of my other concerns:\n- Eq. 7: The left hand side of the equation should be $\\delta^*$, since it is the result of an optimization process. Furthermore, it should be made consistent with eq. 1\n- In order to avoid confusion, in algorithm 2, please change the letter N (training iterations) by other letter, since you used N before to refer to the number of anchor points.\n- You claim you model a Gaussion distribution from 4 anchor points. Is this enough?\n- How sensitive is the protection performance to the number of anchor points or the dimensionality of the modeled identity subspace? \n- Can you provide more intuition or analysis on why the Gaussian identity subspace effectively captures both core identity and contextual diversity?\n- Could you show visualizations or quantitative metrics (e.g., PSNR, LPIPS) demonstrating that the added cloak remains imperceptible to human observers while still being effective against personalization attacks?\n- Have you identified any situations where the method fails to provide sufficient protection (e.g., unusual lighting, occlusion, or profile faces)? What might cause these failures? \n- When adapting image-specific baselines into their “universal” variants, how do you ensure a fair comparison with ID-CLOAK?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "uvnZGVH0dI", "forum": "AkLyfa0dQN", "replyto": "AkLyfa0dQN", "signatures": ["ICLR.cc/2026/Conference/Submission17379/Reviewer_RMKR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17379/Reviewer_RMKR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17379/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761563938939, "cdate": 1761563938939, "tmdate": 1762927288180, "mdate": 1762927288180, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ID-Cloak, a practical privacy defense for personalized text-to-image models. Instead of crafting image-specific perturbations, it learns an identity-specific universal cloak from only a few images. The key idea is to model an identity subspace in the text embedding space (a Gaussian built from prompt-tuned anchors) to approximate all images of the person, and then optimize a universal perturbation that forces the diffusion model to deviate from its normal outputs within this subspace. Experiments on CelebA-HQ and VGGFace2 show stronger and more transferable protection than adapted image-specific baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper tackles a very realistic and high-impact problem: moving from “protecting a single posted image” to “protecting an identity across many current and future images.” This identity-level setting is much closer to how photos actually appear and spread on social platforms, and it addresses the core scalability gap in prior image-specific cloaking methods.\n2. The shift from doing adversarial perturbation directly in image space to first constructing an identity subspace in the text/semantic embedding space is conceptually elegant. By operating over the semantic region corresponding to “this person,” the method aims to protect not just the few available photos but the whole semantic neighborhood that personalized T2I models would try to learn.\n3. The experimental section is reasonably comprehensive: it compares against adapted image-specific baselines, evaluates different prompts, includes cross-model / cross-personalization transfer, and shows that the proposed identity-aware formulation gives more stable protection than prior work."}, "weaknesses": {"value": "1. The core assumption “identity subspace is equal to a Gaussian estimated from 4 images” feels under-justified. With such a small sample, the distribution is very sparse, and it is unclear whether it can really cover hard real-world variants of the same person (extreme pose, strong makeup, occlusion, unusual lighting, profile views). The paper should either validate the coverage or relax the parametric assumption.\n2. The evaluation mostly measures “did the generated face become worse / less identifiable,” but it does not report imperceptibility / usability on the original shared image. In practice, users want to post aesthetically normal photos, not visibly perturbed ones. Without reporting distortion budgets, perceptual scores, or even human judgments on the cloaked inputs, the deployability of the method is hard to assess.\n3. The generalization is still narrow: results are shown on SD 1.5 / 2.1 and a small set of personalization pipelines. To claim identity-level protection in the wild, it would be important to test on a more recent, higher-capacity model such as SDXL and SDv3 to show the approach is not tied to one latent-diffusion family or certain text encoder(s)."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VxQDnPF1Sn", "forum": "AkLyfa0dQN", "replyto": "AkLyfa0dQN", "signatures": ["ICLR.cc/2026/Conference/Submission17379/Reviewer_JiPu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17379/Reviewer_JiPu"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17379/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761881583984, "cdate": 1761881583984, "tmdate": 1762927287882, "mdate": 1762927287882, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ID-Cloak, a method for identity-specific privacy protection against malicious personalized text-to-image (T2I) generation. Unlike prior image-specific defenses that require crafting a unique perturbation per image, ID-Cloak learns a single universal cloak per identity from a few reference images. The core idea involves modeling an identity subspace in the text embedding space using a Gaussian distribution over anchor embeddings derived from the reference images. A universal perturbation is then optimized to maximize divergence between the model’s output on clean vs. cloaked images within this subspace. Experiments show strong performance across datasets (VGGFace2, CelebA-HQ), personalization methods (DreamBooth, LoRA, Textual Inversion), and cross-model transfer."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The shift from image-specific to identity-specific protection is well-motivated and addresses a critical scalability bottleneck in real-world deployment, where users may have hundreds of public images.\n\n2. The use of a learned identity subspace in the text embedding space is a smart way to implicitly model the distribution of all possible images of a person without requiring explicit data augmentation.\n\n3. The paper includes comprehensive experiments: comparison with strong baselines extended to universal variants. Robustness to prompt variation, model transfer, and personalization techniques. Ablation studies validating design choices.\n\n4. The O(1) cost for protecting n images is a significant practical advantage over O(n) image-specific methods."}, "weaknesses": {"value": "1. While the paper claims to be the “first” to investigate identity-specific cloaks, [1] already proposed a person-specific universal perturbation for face recognition protection. Similarly, Universal Adversarial Perturbations (UAPs) have been studied extensively in classification and face recognition [2,3]. The paper’s core idea—learning a single perturbation per class/identity—is not fundamentally new, though its application to personalized T2I misuse is timely.\n\n2. The identity subspace is modeled as a simple Gaussian over prompt-tuned embeddings—a reasonable but not highly innovative choice. The optimization objective (maximizing noise prediction discrepancy) is a standard adversarial loss adapted to diffusion models, similar in spirit to Anti-DreamBooth and MetaCloak.\n\n3. Experiments are limited to face images; generalization to objects or styles (beyond a small WikiArt experiment) is unclear.\n\n4. The “identity subspace” is learned using the same model (SD v2.1) used for attack evaluation, which may overstate effectiveness in black-box settings.\n\n5. Human perceptual studies are absent; BRISQUE/SER-FIQ are imperfect proxies for visual quality.\n\n[1] OPOM: Customized Invisible Cloak towards Face Privacy Protection\n[2] Universal Adversarial Perturbations\n[3] Enhancing Generalization of UAP through Gradient Aggregation"}, "questions": {"value": "1. How does ID-Cloak fundamentally differ from OPOM, which also learns a single identity-specific perturbation for privacy? The related work section mentions OPOM only in passing under UAPs but does not engage with its identity-specific formulation.\n\n2. The identity subspace assumes that all images of a person can be modeled by a Gaussian in text embedding space. How sensitive is performance to this assumption? Have you tried more flexible distributions (e.g., mixture models, normalizing flows)?\n\n3. The proposed method requires fine-tuning the full model (U-Net + text encoder) in the identity learning stage (Sec. B). This is computationally heavy (~50 mins). Can this be avoided (e.g., using only Textual Inversion)? why the Custom Diffusion or similar personalization methods are not used? they are pretty fast methods.\n\n4. For tuning-free personalization methods like IP-Adapter or PhotoMaker, your results (Table 12) show only modest degradation. Do you believe a different defense strategy is needed for these architectures?\n\n5. Why you did not tried newer SD or DiT based methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Ptya14A7i6", "forum": "AkLyfa0dQN", "replyto": "AkLyfa0dQN", "signatures": ["ICLR.cc/2026/Conference/Submission17379/Reviewer_vz9Z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17379/Reviewer_vz9Z"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17379/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762001772700, "cdate": 1762001772700, "tmdate": 1762927287469, "mdate": 1762927287469, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses privacy risks posed by personalized text-to-image (T2I) models (e.g., DreamBooth), where malicious users can generate fake images from personal photos. The paper proposes ID-Cloak—the first identity-specific universal cloak that protects all images of a single identity using only a few (e.g., 4) reference images. Its workflow has two key steps: Identity Subspace Modeling and Cloak Optimization. Experiments approve the effectiveness of the proposed method."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Paradigm Shift from Image-Specific to Identity-Specific Protection: It pioneers the transition from inefficient \"image-level\" cloaks (one per image, as in prior works like Anti-DreamBooth) to \"identity-level\" universal cloaks.\n2. Data Efficiency with Minimal Input Requirement: ID-Cloak only needs a small set of reference images to generate a cloak that protects all images of the target identity.\n3. This paper is well-written."}, "weaknesses": {"value": "1. Insufficient Targeting for Tuning-Free Personalization Methods: While ID-Cloak shows some defensive effect against tuning-free methods, its core design focuses on tuning-based techniques.\n2. Trade-off Dilemma in Perturbation Budget: The method relies on a perturbation budget (η) that requires balancing protection strength and visual imperceptibility.\n3. The experiments only under standard conditions. There is no testing on extreme scenarios, such as low-quality reference images (blurred, occluded, or low-light)."}, "questions": {"value": "1. Insufficient Targeting for Tuning-Free Personalization Methods: While ID-Cloak shows some defensive effect against tuning-free methods, its core design focuses on tuning-based techniques.\n2. Trade-off Dilemma in Perturbation Budget: The method relies on a perturbation budget (η) that requires balancing protection strength and visual imperceptibility.\n3. The experiments only under standard conditions. There is no testing on extreme scenarios, such as low-quality reference images (blurred, occluded, or low-light)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "k73CyQYzqg", "forum": "AkLyfa0dQN", "replyto": "AkLyfa0dQN", "signatures": ["ICLR.cc/2026/Conference/Submission17379/Reviewer_gcn4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17379/Reviewer_gcn4"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17379/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762424995050, "cdate": 1762424995050, "tmdate": 1762927287076, "mdate": 1762927287076, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}