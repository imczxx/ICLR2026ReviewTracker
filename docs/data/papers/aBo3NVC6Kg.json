{"id": "aBo3NVC6Kg", "number": 10910, "cdate": 1758184575507, "mdate": 1759897621424, "content": {"title": "One Graph Can Generalize: Graph-guided Structural Transfer for Source-free Open-set Domain-adaptive Object Detection", "abstract": "Domain Adaptive Object Detection (DAOD) aims to transfer detection capabilities from a labeled source domain to an unlabeled target domain with different visual characteristics. Despite recent advances, existing DAOD methods face significant limitations: they typically operate under closed-set assumptions, require simultaneous access to source and target data, and struggle to differentiate between domain-shifted known objects and genuinely novel categories. To address these real-world challenges, we reformulate the DAOD problem by explicitly considering three distinct shifts: domain distribution shift (\\textit{Shift [i]}), open-set class shift (\\textit{Shift [ii]}), and source-free transfer shift (\\textit{Shift [iii]}). We propose GraphGen , a unified graph-based framework that simultaneously tackles all three shifts by modeling structural relationships between objects, enabling knowledge transfer without source data access through dynamically updated graphs that capture cross-domain similarities. The framework integrates specialized modules for graph-based feature alignment, novelty discovery, and self-regularization to comprehensively address the challenges of source-free open-set domain adaptation. Experiments on benchmark datasets demonstrate that GraphGen outperforms state-of-the-art methods, with significant improvements in novel class discovery while maintaining strong performance on known categories.", "tldr": "", "keywords": ["Domain Adaptive Object Detection (DAOD); Source-Free Open-Set Learning; Graph-Based Knowledge Transfer"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6c1bcbad0a6c936f9609686186ac2446589d3b81.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper targets object detection under the joint stresses of (i) cross‑domain distribution shift, (ii) open‑set class shift (unknowns at test time), and (iii) source‑free adaptation (no source data during adaptation).  The proposed framework, GraphGen, builds graphs over target‑domain object proposals to model instance‑level relations and introduces three modules aligned with the three shifts: cross‑domain graph alignment with a cyclic‑consistency term, graph‑guided novelty discovery using class prototypes and an entropy‑aware novelty score, and graph‑aware self‑regularization via a teacher–student EMA scheme with strong/weak augmentations and graph‑space consistency.  The overall loss combines detection with the three graph‑oriented regularizers, and training warms up with domain alignment before adding the other two components.  Experiments on Cityscapes→Foggy Cityscapes and Pascal VOC→Clipart report improvements in known‑class mAP (mAP_b), novel‑class recall (AR_n), and open‑set metrics (WI, AOSE) over several re‑implemented baselines under a source‑free setting, plus ablations per module and qualitative visualizations."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Ambitious problem setting: Addressing source‑free + open‑set + domain shift jointly is important for realistic deployments where proprietary source data is unavailable and target classes are not closed. \n\nModular design mapped to problem factors: The three modules (graph alignment, novelty discovery, self‑regularization) correspond neatly to the three shifts, providing a clear conceptual story for the approach. \n\nSimple, reproducible primitives (in principle): Graph conv on proposal features, cosine‑affinity adjacency with degree normalization, EMA teacher–student, entropy‑modulated novelty score, and contrastive learning are all standard components combined coherently. \n\nBroad metrics and datasets: Evaluation uses mAP_b, AR_n, WI, AOSE on two domain shifts (weather/style) with multiple unknown‑class configurations (“inst‑sem”, “hom‑sem”, “freq‑dec”, “freq‑inc”), which is a welcome breadth. \n\nQuantitative gains: On Cityscapes→Foggy, GraphGen improves over re‑implemented baselines across several configurations (e.g., “inst‑sem” with 3/4/5 unknowns), and also shows gains on VOC→Clipart with 6/8/10 unknowns. \n\nAblations and qualitative evidence: There are per‑module ablations (Table 3) and figures illustrating detection under fog and cross‑domain matching/matrices, supporting claims beyond headline numbers."}, "weaknesses": {"value": "Novelty relative to prior graph‑based DAOD appears incremental and insufficiently differentiated. Prior work has already used graph/bipartite structures for DAOD (e.g., dual bipartite graph learning), and this paper’s key “newness” is the combination with open‑set + source‑free constraints; however, the methodological distinctions versus earlier graph‑based DAOD and recent source‑free open‑set detection are not rigorously articulated (what can GraphGen do that those cannot, beyond composing known ingredients?). \n\nPotential internal inconsistencies and unclear modeling details.\nThe text says adjacency encodes “semantically similar or spatially related objects,” but ω_{ij} uses only cosine similarity in feature space without any spatial term; the spatial claim is therefore unsupported as written. \nThe contrastive loss refers to a Hilbert‑space inner product ⟨·,·⟩_H without defining a different space than standard Euclidean embeddings; this reads like gratuitous terminology rather than a meaningful design choice. \nThe novelty score multiplies max‑probability with (1 − H(p)), but H is not normalized by log|Ω_b|; the scale of entropy thus depends on the number of known classes, making thresholding τ_{unknown} fragile across datasets. \n\nSource‑free assumption blurred by visualizations and narrative. Figure 5 illustrates cross‑domain correspondences with paired Cityscapes and Foggy images, which presupposes access to source images during analysis; the paper does not explain whether the source imagery is used only for visualization, and if so, how this squares with the strict source‑free protocol.\n\nHyperparameter selection and fairness are under‑specified.\nThe paper states “All hyperparameters are chosen via grid search”, but under source‑free unlabeled target, what criterion was optimized and on which split (no labeled target is allowed)? The risk of oracle‑style tuning is non‑trivial and not addressed. \n\nBaselines like OW‑DETR are not source‑free; the paper says all methods are re‑implemented under source‑free settings, but provides no detail on how each baseline was modified, nor validation that the modifications preserve their intended behavior, raising fairness concerns. \n\nReporting and consistency issues in results and nomenclature.\nThe paper sometimes refers to the method as GODA and elsewhere as GraphGen, suggesting editorial lapses and potential copy/paste from earlier drafts. \n\nTable 3 ablation numbers (e.g., WI, AOSE) do not obviously match the scale/patterns in Table 1 for the same scenario, and the text duplicates the ablation description twice, which undermines confidence in careful reporting.\n\nFigures reference DDETR [60] but the bibliography numbering and citation details are unclear (e.g., Detectron2 is cited; DDETR is not clearly itemized), making it difficult to verify comparisons.\n\nComputational complexity, stability, and scalability are not addressed.\nBuilding a dense affinity matrix over N proposals induces O(N²) cost per image; the paper does not report runtime, memory, or the number of proposals used during graph operations.\nNo variance or multi‑seed runs are reported; open‑set pseudo‑labeling is notoriously unstable, and the sensitivity to thresholds (τ_{known}, τ_{unknown}, τ_{nov}), EMA decay α, and prototype momentum τ is unknown. \n\nEvaluation scope may omit stronger modern alternatives.\nThe study evaluates against open‑world/DAOD baselines, but open‑vocabulary or vision‑language detectors (even if not source‑free) are relevant reference points for unknown detection, and a discussion/experiment clarifying why those are out of scope would strengthen the claim of state‑of‑the‑art. \n\nTheoretical justification is thin. Claims that cyclic consistency “prevents drift,” graph propagation “bridges the domain gap,” and contrastive grouping captures “structural patterns” are plausible but not theoretically or empirically isolated via targeted diagnostics (e.g., measuring structure preservation, failure cases)."}, "questions": {"value": "Fair source‑free baselines: How exactly were OW‑DETR, PETS, LODS, SF‑OSDA adapted to be source‑free? Please specify replacements for any steps that normally use source data, including pseudo‑label filtering, training schedules, and hyperparameter tuning; ideally, release the re‑implementation details or code. \n\nHyperparameter tuning without labels: With grid search on unlabeled target, what objective guided selection (e.g., teacher consistency, confidence proxy, energy metrics)? How did you avoid peeking at labeled target data or test sets when picking τ_{known}, τ_{unknown}, τ_{nov}, λ’s, α, and τ? \n\nSource‑free integrity of visualizations: In Figure 5, were source images used only for illustration, or do they influence any part of training/evaluation (e.g., correspondence mining)? If only for illustration, please state this explicitly and ensure no leakage during training. \n\nAdjacency design: You claim spatial relations are captured, yet ω_{ij} uses only cosine similarity of embeddings. Did you try spatial terms (IoU overlap, relative geometry) in ω_{ij}? If not, can you clarify how the current formulation captures spatial structure beyond what the backbone already encodes? \n\nEntropy scaling: Since H(p) is unnormalized, thresholds for novelty depend on the number of known classes. Did you evaluate normalized entropy (H/ log K) or temperature scaling to stabilize τ across datasets? Please share sensitivity plots. \n\nComplexity and scaling: What is the per‑image runtime/memory for graph construction and GCN passes (as a function of proposals N)? What proposal counts do you use at training vs. inference? Any pruning or k‑NN sparsification applied to Ω? \n\nAblation clarity and consistency: Table 3 is repeated in the text and some numbers (WI/AOSE) seem inconsistent with Table 1 for ostensibly similar settings. Can you reconcile the discrepancies and provide mean ± std over multiple random seeds? \n\nEMA and schedule: You note α is “typically 0.99” but use α=0.9; what is the impact of α and the warm‑up then add‑modules schedule on stability and final metrics? Please include an ablation figure. \n\nPrototype maintenance in open‑set: Updates for prototypes p_k and variances v_k rely on class assignments—how do you avoid confirmation bias when pseudo‑labels are wrong, especially under heavy domain shift? Any debiasing (e.g., class‑balanced sampling, prototypical confidence, EMA of prototypes separate from EMA of weights)? \n\nScope against open‑vocabulary detectors: Even if not source‑free, why are open‑vocabulary baselines (as upper/lower bounds) omitted? Can you at least discuss how GraphGen’s unknown handling compares conceptually to energy‑based/OVD unknown scoring?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "hc6HYNGC48", "forum": "aBo3NVC6Kg", "replyto": "aBo3NVC6Kg", "signatures": ["ICLR.cc/2026/Conference/Submission10910/Reviewer_9L8M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10910/Reviewer_9L8M"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10910/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761179479544, "cdate": 1761179479544, "tmdate": 1762922114101, "mdate": 1762922114101, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a highly challenging and practical problem: Source-Free, Open-Set, Domain-Adaptive Object Detection (SF-OS-DAOD). The authors clearly decompose this problem into three key challenges (Shift i, ii, iii) and propose a unified framework, GraphGen, to systematically tackle them. The core contribution of this paper is the proposal to use graphs to model structural relationships between objects, positing that these relationships are more domain-invariant than visual features themselves, thereby enabling knowledge transfer without source data."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The core idea—transferring \"structural relationships\" rather than \"visual features\"—is highly insightful. Using a graph as a medium to capture and transfer this high-order information is a significant innovation that distinguishes it from traditional adversarial alignment or pseudo-labeling methods.\n2. The GraphGen framework is elegant and complete. The three key modules (Cross-domain Graph Alignment, Graph-guided Novelty Discovery, Graph-aware Self-regularization) clearly and respectively correspond to the three challenges (Shift i, ii, iii) defined by the authors. This \"divide and conquer\" then unified optimization strategy is methodologically sound.\n3. The paper consistently outperforms existing SOTA methods across multiple settings (varying numbers of novel classes). As shown in Tables 1 and 2, GraphGen achieves significant improvements in detecting both known (mAPb) and unknown (ARn) categories. The exhaustive ablation studies (Table 3) also clearly demonstrate the necessity and effectiveness of each component."}, "weaknesses": {"value": "1. The paper does not detail how the nodes $\\mathcal{V}$ (i.e., object query embeddings) in the graph $\\mathcal{G}=(\\mathcal{V},\\mathcal{E})$ are selected. Are they from all the proposals from the RPN? Or only high-confidence objects? Is the graph built per-image or across a batch of multiple images? \n2. Graph-based methods (especially those requiring N x N similarity matrices and graph convolution) are often computationally expensive. Object detection is itself a speed-sensitive task. The paper completely omits a discussion of the added computational overhead (e.g., training time, inference speed/FPS) of GraphGen compared to baselines. \n3. The method introduces multiple key hyperparameters (e.g., $\\lambda_1, \\lambda_2, \\lambda_3, \\gamma, \\tau_{known}, \\tau_{unknown}$, etc.). The paper states they were \"chosen via grid search\" but lacks a sensitivity analysis for these choices."}, "questions": {"value": "The core motivation is that \"structural relationships\" (e.g., spatial proximity of cars and pedestrians) are more invariant than visual features. However, in Section 3, the graph construction (Eq. 1) is based on the cosine similarity between \"object query embeddings\" $z_i$ produced by the feature extractor F. But, this is a \"feature similarity graph,\" which reflects similarity in visual feature space more than physical or semantic structural relationships."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XflVrqSzca", "forum": "aBo3NVC6Kg", "replyto": "aBo3NVC6Kg", "signatures": ["ICLR.cc/2026/Conference/Submission10910/Reviewer_uECX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10910/Reviewer_uECX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10910/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761545775050, "cdate": 1761545775050, "tmdate": 1762922113748, "mdate": 1762922113748, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposed a novel DAOD method to alleviate three common domain-shift problems. The method is novel, and the environmental results indicate that it can outperform previous work."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. The paper is well-structured and easy to follow.\n2. The fables are clear to read, and the experiments demonstrate the effectiveness of the new proposed modules.\n3. The motivations are clearly stated.\n4. The ablation studies are sufficient."}, "weaknesses": {"value": "1. Why the 3 types of domain shift can be solved simultaneously? Any clues why they have no repellency? This is not clearly stated in the first section.\n2. Line 101: SFDA abbreviation should be presented here before referencing it.\n3. Caption of Figure1,2,3. Figure 2 can be better if they are some explanation of how to read the figure, instead of a summary of the high-level idea. e.g. what is NC loss and IOR loss?\n4. Weak connection between the content and Figure 2, making the figures hard to read."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No"}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hoj7qjPDpC", "forum": "aBo3NVC6Kg", "replyto": "aBo3NVC6Kg", "signatures": ["ICLR.cc/2026/Conference/Submission10910/Reviewer_biRg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10910/Reviewer_biRg"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10910/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761870492423, "cdate": 1761870492423, "tmdate": 1762922113384, "mdate": 1762922113384, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper begins by outlining the limitations of conventional Domain Adaptive Object Detection (DAOD) methods and introduces a Graph-Guided Structural Transfer (GAST) framework for Source-Free Open-Set Domain-Adaptive Object Detection (SFOSD).\nGAST employs a graph-based representation of category relationships to facilitate structural knowledge transfer in the absence of source data, combining a graph encoder with an uncertainty-aware detection head to enhance cross-domain generalization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1、The paper extends DAOD to the source-free open-set setting (SFOSD), which is closer to real-world deployment where source data cannot be retained and unknown classes appear at test time.\n2、An uncertainty-aware detection head integrates unknown handling inside the detector, enabling joint optimization of localization/classification with unknown separation and yielding a more principled open-set treatment."}, "weaknesses": {"value": "1、The distinction from Open-Set Domain Adaptation methods that use structure/uncertainty is not made concrete.\n2、No formal argument or representation analysis showing why graph propagation reduces domain discrepancy or improves unknown separation in SFOSD.\n3、Missing discussion on computational overhead (graph size, message passing cost) and runtime compared to baselines."}, "questions": {"value": "1、What are the FLOPs of the graph module at different class counts? \n2、How sensitive is performance to graph sparsity/degree and to mistakes in edge formation? \n3、Can you provide a theoretical or at least quantitative representational analysis showing that graph propagation reduces domain discrepancy or improves cluster compactness for unknowns?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Eg0zYEnmWN", "forum": "aBo3NVC6Kg", "replyto": "aBo3NVC6Kg", "signatures": ["ICLR.cc/2026/Conference/Submission10910/Reviewer_JAiN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10910/Reviewer_JAiN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10910/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762175009778, "cdate": 1762175009778, "tmdate": 1762922113020, "mdate": 1762922113020, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}