{"id": "DBUZoxt9Ns", "number": 10511, "cdate": 1758174312591, "mdate": 1763632750349, "content": {"title": "LumiRAG: A Unified Multimodal RAG Large Model Bridging Text and Image Retrieval", "abstract": "Retrieval-Augmented Generation (RAG) enhances large language models' ability to leverage external knowledge. However, existing models remain limited in their unified understanding and generation of text and multimodal retrieved content. We present LumiRAG, a suite of Qwen2.5-based models achieving strong RAG capabilities across modalities through systematic fine-tuning with high-quality data. Our approach comprises three key components: (1) Human-synthetic hybrid dataset with adaptive domain harvesting, dual-source generation, and multi-layer quality control, producing 520K samples across text RAG, multimodal tasks, and expert-annotated dialogues; (2) Three-stage progressive instruction tuning that unifies supervised fine-tuning, context-augmented instruction tuning, and reinforcement learning with Optimized-DAPO for stepwise performance alignment; (3) Cross-modal reinforcement learning framework employing reward shaping and stabilized training to jointly optimize retrieval accuracy and generation quality. Extensive evaluations on ChatRAG-Bench, long-form summarization benchmarks (CNN/DailyMail, XSum), MMRAG-Bench, and MMTAB demonstrate that LumiRAG substantially outperforms open-source and proprietary baselines, establishing new state-of-the-art performance across diverse modalities and task types. Model weights, datasets, and evaluation code will be open-sourced to support reproducibility and future research.", "tldr": "LumiRAG: A unified multimodal RAG system that achieves state-of-the-art performance across text and visual retrieval tasks through progressive instruction tuning and cross-modal reinforcement learning", "keywords": ["retrieval-augmented generation; reinforcement learning; large language models ; multimodal models"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/26f55a2a7db333659cd99337e8d5549152a88094.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper collects a large-scale RAG training dataset of 880k samples (including human-created, synthetic, and open-source data), proposes a three-stage training strategy, and modifies the DAPO algorithm to obtain LumiRAG-Qwen2.5(-VL) based on the Qwen2.5(-VL) model. The model is evaluated on multiple benchmarks such as the text-only ChatRAG and the multimodal MMRAG-Bench, demonstrating competitive performance over existing LLMs and MLLMs."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. According to the ablation results in Table 2, the proposed three-stage training data and strategy yield notable performance improvements over the adopted baselines.\n2. As shown in Table 4, the trained multimodal model demonstrates generalization on the text-only benchmark."}, "weaknesses": {"value": "1. This paper has many unclear expression problems. Specifically: (1) The source of the collected dataset is not explained, such as which public datasets are included in the open source data? (2) Since the work focuses on RAG, what retrieval model is used, and from which knowledge base is the retrieval performed? (3) The definitions of the terms in L199 (\"LM, cross-modal alignment, and contrastive loss\") and in L211–L212 (\"q and $c_i$\", as well as \"LM, retrieval relevance, factual consistency, and ranking loss\") are missing and should be explicitly specified. (4) The data quality control process in Section 3.1.3 is overly abstract, lacking details about the design pipeline and how the scores are computed.\n2. Although the title claims to \"bridge text and image retrieval\", the actual implementation trains text-only and multimodal RAG models separately, rather than integrating the two functionalities into a unified model.\n3. (1) Based on Table 2, the proposed DS-DAPO method achieves only marginal improvement over DAPO. Are there any additional advantages beyond the performance gain? (2) Given that the goal is to verify the effectiveness of DS-DAPO, why are the experiments in Figure 3 conducted on the mathematical reasoning dataset AIME 2024 instead of an RAG dataset?\n4. Since the target scenario is RAG, comparisons should be made with specialized RAG models such as Search-R1 rather than general-purpose LLMs/MLLMs, and evaluations should include standard RAG benchmarks such as TriviaQA, PopQA, HotpotQA, and 2Wiki (text-only), as well as InfoSeek and Enc-VQA (multimodal)."}, "questions": {"value": "My main concerns have been outlined in the Weaknesses. I would be happy to engage in further discussion with the authors to clarify the motivation and methodological design of this work."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ma3QHjR1Sa", "forum": "DBUZoxt9Ns", "replyto": "DBUZoxt9Ns", "signatures": ["ICLR.cc/2026/Conference/Submission10511/Reviewer_ugZa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10511/Reviewer_ugZa"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10511/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761492803044, "cdate": 1761492803044, "tmdate": 1762921796549, "mdate": 1762921796549, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "LumiRAG proposes a unified retrieval‑augmented generation framework that bridges text and vision, built on Qwen2.5 backbones and trained through a multi‑stage pipeline. The work combines a large human‑synthetic hybrid dataset, progressive instruction tuning, and a reinforcement learning algorithm (DS‑DAPO) designed to stabilize optimization and improve sample utilization. Empirically, the models are evaluated across conversational text RAG (ChatRAG‑Bench), long‑form summarization, multimodal RAG (MRAG‑Bench, MMRAG), and tabular reasoning (TABMWP, FeTaQA). Reported results show the 7B variant outperforming strong 70B baselines on ChatRAG and the 32B variant exceeding closed‑source systems (e.g., GPT‑4o, Claude 3.5) on several multimodal benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper’s originality lies less in inventing entirely new architectures and more in integrating known components into a coherent pipeline that spans modalities. Three aspects stand out: the progressive training blueprint that explicitly unifies text and multimodal RAG; a large, diversified human‑synthetic dataset with explicit preference data; and the DS‑DAPO reinforcement learning variant targeted at common failure modes in GRPO‑style training. While multimodal RAG and RLHF are active areas, the paper’s combination is constructive and practically relevant, moving beyond fragmented training toward a single framework."}, "weaknesses": {"value": "1. The paper’s core claim is “unified multimodal RAG,” yet retrieval specifics are limited. It remains unclear how contexts are encoded and indexed across text, images, and tables, how chunking/windowing is configured, and how cross‑modal candidates are scored and fused. \n\n2. DS‑DAPO filters uniformly correct/incorrect prompts and resamples high‑pass‑rate items to complete batches. While efficient, this may bias training toward already “easy” or popular prompts and reduce exposure to rare, hard cases.\n\n3. Minor inconsistencies appear (e.g., “MMTAB” vs “MMTab”). Cleaning these improves readability. Clearly define loss terms ($L_{align}$, $L_{modal}$) and the retrieval‑aware components in Stage 2."}, "questions": {"value": "1. What encoders are used for text, images, and tables, and how are candidates fused across modalities during reranking? Do you employ cross‑modal late fusion or shared embedding spaces in production evaluation?\n\n2. The paper claims 52.91% training efficiency improvement. How is this measured (steps per second, time to target accuracy, sample utilization)? On which hardware and batch settings?\n\n3. How is the 31% reduction computed for multimodal tasks? Please provide the metric definition, sampling protocol, and human evaluation rubric.\n\n4. Can you enumerate data sources and licenses, and confirm that evaluation corpora (e.g., CNN/DailyMail, XSum, MRAG‑Bench) are excluded from training and synthetic generation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "PWmPfx4hA9", "forum": "DBUZoxt9Ns", "replyto": "DBUZoxt9Ns", "signatures": ["ICLR.cc/2026/Conference/Submission10511/Reviewer_VX75"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10511/Reviewer_VX75"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10511/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761790761895, "cdate": 1761790761895, "tmdate": 1762921795913, "mdate": 1762921795913, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a unified framework for multimodal retrieval-augmented generation (RAG) built on Qwen2.5 models. The work addresses limitations in existing RAG systems through three main contributions: (1) a hybrid dataset combining 63K human-annotated and 457K synthetic samples with quality scores of 9.0-9.2/10 and 7.8-8.1/10 respectively; (2) a three-stage progressive training pipeline (supervised fine-tuning → context-enhanced instruction tuning → reinforcement learning); and (3) DS-DAPO, a novel RL algorithm that improves training efficiency by 52.91% over standard DAPO. The authors demonstrate that LumiRAG-Qwen2.5-7B outperforms 70B parameter models, while the 32B variant surpasses GPT-4o and Claude 3.5 on multimodal benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.\tExtensive evaluation across multiple benchmarks\n2.\tClear ablation studies demonstrating progressive improvements\n3.\tRigorous comparison with open-source and closed-source baselines\n4.\tThoughtful reward function design for both text-only and multimodal RAG\n5.\tComprehensive empirical validation\n6.\tPractical and efficient dataset construction methodology\n7.\tDS-DAPO innovation. Strong efficiency gains \n8.\tWell-organized structure and clear section delineation\n9.\tComprehensive figure illustrating the training pipeline\n10.\tThoughtful progressive training design\n11.\tCross-modal consistency across text and multimodal tasks"}, "weaknesses": {"value": "1.\tAdaptive threshold α (Eq. 6) manually calibrated per task—limited generalization\n2.\tLimited theoretical justification for DS-DAPO’s faster convergence\n3.\t“52.91% efficiency improvement” metric unclear and undefined\n4.\tQuality scores (e.g., 9.2/10) lack explanation of computation methodology\n5.\tNo computational cost analysis despite dataset construction rate claims (∼5K samples/hour)\n6.\tCohen’s κ mentioned but scoring dimensions not defined\n7.\tHyperparameter sensitivity not analyzed (α, β, learning rate, batch size, etc.)\n8.\tFigure 3 shows DS-DAPO dynamics on only one task—no broader analysis\n9.\tNo statistical significance testing or confidence intervals in results\n10.\tComparison limited to DAPO—missing other RL baselines (e.g., PPO variants)\n11.\tSome baselines (GPT-4o, Claude 3.5) not optimized for RAG, weakening comparisons\n12.\t“Hallucination reduction” claim not rigorously supported\n13.\tNo detailed error analysis of LumiRAG’s failure cases\n14.\tReproducibility concerns—no concrete release timeline or repo link\n15.\tMissing key implementation details (hardware, training time, parameters)\n16.\tWriting is dense and occasionally unclear; key claims underexplained\n17.\tSome parameters (α, β, F1_baseline) introduced without sensitivity analysis\n18.\tComponent losses not clearly defined when first introduced\n19.\tFrequent jumps between text-only and multimodal sections without clear distinction"}, "questions": {"value": "1.\tCan you provide the complete rubric for the quality scores? What specific dimensions are evaluated, and how are they weighted?\n2.\tHave you tested DS-DAPO on tasks beyond math reasoning? Does the efficiency gain hold across different domains?\n3.\tHow sensitive are results to the α threshold in Equation 6? Can you provide an ablation varying α ± 0.1 on a few tasks?\n4.\tWhat are the actual training times and GPU requirements for each stage? How does total compute compare to training baseline models?\n5.\tWhat types of queries does LumiRAG consistently fail on? Are there systematic biases or limitations?\n6.\tBeyond dataset annotation, have you conducted human preference studies comparing LumiRAG outputs to baselines?\n7.\tHow do you ensure visual and textual representations remain aligned throughout RL training? Any metrics tracking representation drift?\n8.\tWhat happens if you use simpler reward functions, for example, just F1 without thresholding or adaptive scaling? How much does reward design matter?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics review needed."}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4J048OeVGE", "forum": "DBUZoxt9Ns", "replyto": "DBUZoxt9Ns", "signatures": ["ICLR.cc/2026/Conference/Submission10511/Reviewer_ctuE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10511/Reviewer_ctuE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10511/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761954298360, "cdate": 1761954298360, "tmdate": 1762921795584, "mdate": 1762921795584, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a unified framework (LumiRAG) for retrieval-augmented generation (RAG) across text and multimodal modalities. LumiRAG leverages a large human-synthetic hybrid dataset and a three-stage progressive training pipeline to systematically develop capabilities from instruction-following to context integration and human preference alignment. In addition, the paper proposes DS-DAPO, which dynamically samples prompts and completes batches to maintain stable optimization while improving training efficiency. Extensive experiments on ChatRAG-Bench, MRAG-Bench, MMRAG, MMTAB, and summarization benchmarks show that LumiRAG significantly outperforms both open- and closed-source baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **Comprehensive evaluation and significant performance:** The experiments are well-designed and comprehensive, and LumiRAG demonstrates promising performance. Moreover, LumiRAG illustrates that smaller open-source models can match or even surpass GPT-4o-level performance on multimodal RAG tasks. \n\n- **Systematic framework and well-designed training pipeline:** The paper addresses a complete RAG pipeline with thoughtful orchestration of data curation, multi-stage training, and RL optimization. The three-stage progressive training, from SFT to RL with DS-DAPO, shows clear empirical benefits and is well-motivated and systematic. In addition, the ablations clearly demonstrate steady gains at each stage."}, "weaknesses": {"value": "- **Limited novelty and marginal gains of DS-DAPO:** Although DS-DAPO is an efficiency-oriented modification of DAPO, the underlying RL foundation largely builds on existing methods (GRPO, DAPO). It feels more like a hyperparameter tuning exercise over DAPO. In addition, the main ablation in Table 2 shows a relatively small gain over standard DAPO (60.49 vs. 60.02). \n\n- **Ablation on reward design:** While reward functions for text and multimodal RAG are described in detail, ablation results isolating their effects, such as with or without adaptive α/β parameters, are missing."}, "questions": {"value": "1. The introduced hybrid dataset is a cornerstone of this work. Could you provide an ablation study on the data composition?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "apwY4NBcXS", "forum": "DBUZoxt9Ns", "replyto": "DBUZoxt9Ns", "signatures": ["ICLR.cc/2026/Conference/Submission10511/Reviewer_fYto"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10511/Reviewer_fYto"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10511/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979067067, "cdate": 1761979067067, "tmdate": 1762921795051, "mdate": 1762921795051, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}