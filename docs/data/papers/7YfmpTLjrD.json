{"id": "7YfmpTLjrD", "number": 21841, "cdate": 1758322549232, "mdate": 1759896900452, "content": {"title": "Procrustes Projection Alignment for Multi-View Graph Representation and Reusable ML Models", "abstract": "When a graph is massive or when observability and privacy constraints prevent access to the entire topology, ML models must be trained using only partial information related to the topology.  Such models lack reusability when the same graph is specified using a different partial set of measurements or  on different  subgraphs.   We present an approach to make node representations comparable across different graph views produced from the same underlying  topology, and use it with Graph Embedding Neural Networks (GENNs)  on the OGBN-products benchmark dataset to evaluate its effectiveness.    The topology of the graph or a subgraph is captured using the distance to a very small set of anchor nodes, resulting in a view of the graph that depends on the anchors.   The dimensionality of these measurements is even further reduced using SVD, and the resulting topology coordinates are used  in a GENN scheme.  Reusing this model  to make predictions on different views of the graph does not produce accurate results.   By using a Procrustes transform to align a very small set of reference nodes  in views obtained from different sets of anchors, we demonstrate that the models trained on one view can make predictions on the graph based on a different view with about the same accuracy.   We also show that the proposed method is accurate when the different  views  are obtained from different subgraphs with some overlap. The approach requires only a few reference nodes, is compatible with any neural network classifier, and is particularly suitable for privacy-sensitive or federated settings where only projections or a small set of reference nodes can be shared.", "tldr": "We address the problem of ML for graphs, where training data is obtained from one view of the graph, and the trained NN model is reused on other views of the graph without retraining.", "keywords": ["graph embedding neural networks (GENN)", "graph coordinates", "graph analytics", "network embedding", "graph neural networks (GNN)"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4b7b0a7f564fb2c687a2b7b037a4ea97c4206b43.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses the challenge of making graph neural network models reusable across different views of the same graph. The authors propose using Procrustes transformation to align node embeddings derived from different anchor-based views, enabling a model trained on one view to make predictions on other views without retraining.  The methodology involves three key steps: (1) computing topology coordinates (TCs) by selecting a small set of anchor nodes (less than 0.05% of total nodes), calculating distances from all nodes to these anchors, and applying SVD for dimensionality reduction; (2) using Procrustes analysis to estimate an orthogonal transformation that aligns embeddings from different views based on a small reference set (less than 0.5% of nodes); and (3) applying this transformation to enable cross-view model transfer. The authors validate their approach on the OGBN-Products dataset through two experimental phases. Phase 1 demonstrates that models trained on one anchor set can achieve comparable accuracy on different anchor sets after Procrustes alignment (test accuracy dropping only from 0.7714 to approximately 0.76 after alignment, compared to 0.10 without alignment). Phase 2 extends this to subgraphs with 30% random node removal, showing the method maintains effectiveness even with partial graph coverage."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper demonstrates several strengths in its execution and presentation. First, it addresses a practical problem in distributed and privacy-sensitive graph learning scenarios. The motivation is well-articulated: in real-world applications, complete graph access is often impossible due to privacy regulations, access restrictions, or computational constraints. The focus on enabling model reuse across different partial views without requiring centralized data or extensive retraining directly responds to these practical challenges.The experimental design is methodical and well-structured. The two-phase approach provides a logical progression from controlled experiments (Phase 1: complete graph with different anchor sets) to more realistic scenarios (Phase 2: subgraphs with node removal). This progression effectively isolates variables and builds confidence in the approach incrementally. The visualization of topology coordinates before and after Procrustes alignment provides intuitive evidence of the alignment effectiveness, showing how different views can be brought into a common coordinate frame.The computational efficiency of the proposed method is a significant practical advantage. Using only 1,000 anchor nodes and 1,000 reference nodes for alignment represents minimal overhead. The closed-form Procrustes solution requires no iterative optimization, making it substantially faster than methods requiring retraining or complex alignment procedures. The paper effectively demonstrates that 10-100 topology coordinates capture 99.45-99.65% of the variance, showing that the dimensionality reduction is efficient without substantial information loss.The empirical results are convincing within the tested scope. The dramatic difference between aligned and non-aligned embeddings clearly demonstrates the necessity and effectiveness of the Procrustes transformation. The consistency of results across multiple anchor sets suggests the approach is not sensitive to specific anchor choices, which is important for practical deployment."}, "weaknesses": {"value": "The paper's limitation is its lack of fundamental technical novelty. Each component of the pipeline relies on well-established methods:\nTopology coordinates are not new to this work. The authors explicitly cite Qin et al. (2023) for the coordinate system and acknowledge it as the foundation of their approach. Computing distance matrices and applying SVD/PCA for dimensionality reduction has been standard practice in graph embedding literature for years. The use of anchor-based distance measurements similarly appears in network coordinate systems and has been explored in the context of sensor networks and graph analysis. \nProcrustes analysis for alignment is a classical technique dating back to Schönemann (1966), as the authors cite. The application of Procrustes to graph embeddings is also not novel—the paper cites Peng et al. (2021) who used orthogonal Procrustes for knowledge graph embeddings, and Andreella et al. (2023) for matrix similarity assessment. The related work section reveals multiple prior applications of Procrustes in graph contexts, undermining claims of novelty in the alignment approach itself.\nThe combination of these techniques, while useful, represents incremental engineering rather than algorithmic innovation. The paper essentially applies a known alignment method to a known embedding approach for a specific use case (anchor-based views). This is valuable engineering work, but it doesn't introduce new mathematical frameworks, theoretical insights, or algorithmic contributions. \nAlso the paper provides no theoretical analysis of when or why the Procrustes alignment should work."}, "questions": {"value": "1. Under what theoretical conditions does orthogonal Procrustes alignment accurately preserve the geometric structure and predictive information of graph embeddings across different anchor-based views?\n\n2. How does the proposed Procrustes alignment method compare quantitatively against existing cross-graph transfer learning, multi-view graph learning, and federated graph neural network approaches on diverse benchmark datasets?\n\n3. What is the relationship between anchor set size, reference set size, embedding dimensionality, and alignment quality, and how do these parameters affect downstream task performance across different graph scales and structural properties?\n\n4. How robust is the Procrustes alignment approach to realistic graph heterogeneity, including non-overlapping node sets, directed and weighted edges, dynamic graph evolution, varying node/edge feature distributions, and adversarial anchor selection?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics concerns have been identified in the work."}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "7OdYATXK8i", "forum": "7YfmpTLjrD", "replyto": "7YfmpTLjrD", "signatures": ["ICLR.cc/2026/Conference/Submission21841/Reviewer_c8Hx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21841/Reviewer_c8Hx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21841/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761410815699, "cdate": 1761410815699, "tmdate": 1762941951373, "mdate": 1762941951373, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of cross-view model reuse in graph machine learning, where node classifiers trained on one graph view (defined by a specific anchor set or subgraph) should be applicable to other views without retraining. The authors propose a Procrustes-based orthogonal alignment method to make node embeddings from different views comparable. Using topology coordinates derived from anchor-node distances, they demonstrate that a simple rotation transformation estimated from a small reference node set can effectively align embeddings across views. Experiments on OGBN-Products show that models trained on one view maintain accuracy when applied to aligned embeddings from other views, whereas direct cross-view application fails completely."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "(1) The paper creatively applies Procrustes analysis to align graph embeddings from different anchor-based views, a setting not extensively studied in prior work.\n\n(2) The approach is lightweight, requires no labels for alignment, and has direct relevance to federated and distributed graph learning.\n\n(3) The authors show that their method works effectively in both full-graph and subgraph settings, with significant gains over the no-alignment baseline."}, "weaknesses": {"value": "(1) The paper only compares against a \"no alignment\" baseline. It does not evaluate against other embedding methods or alignment techniques, making it difficult to assess the relative merit of the proposed approach.\n\n(2) Experiments are conducted only on one dataset (OGBN-Products) and one task (node classification). Broader evaluation across datasets and tasks is needed to establish generalizability.\n\n(3) The paper relies entirely on empirical validation and lacks theoretical analysis."}, "questions": {"value": "(1) Can you add comparative experiments against state-of-the-art graph embedding and alignment methods to better demonstrate the relative effectiveness of your approach?\n\n(2) Could you evaluate the method on more diverse datasets and tasks to further validate its generalizability?\n\n(3) Could you provide a theoretical analysis?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vuHhye2lJG", "forum": "7YfmpTLjrD", "replyto": "7YfmpTLjrD", "signatures": ["ICLR.cc/2026/Conference/Submission21841/Reviewer_imen"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21841/Reviewer_imen"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21841/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761620596320, "cdate": 1761620596320, "tmdate": 1762941950868, "mdate": 1762941950868, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method for aligning node representations across different anchor-based graph views or subgraphs derived from the same underlying topology. The authors employ distance-based topology coordinates (TCs) combined with orthogonal Procrustes alignment to enable model reuse and cross-view generalization under settings where graph observability is limited due to privacy or scale. The work is motivated by practical challenges and is clearly presented. However, the paper lacks theoretical depth, rigorous novelty justification, and analytical evaluation."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "(1) The paper addresses a realistic and timely issue: training graph models under partial observability or privacy constraints, and reusing them across different subgraph views.\n(2) The proposed framework (distance matrix + PCA + Procrustes) is simple, transparent, and easy to replicate, which facilitates interpretability and reproducibility."}, "weaknesses": {"value": "(1) Orthogonal Procrustes alignment and cross-view embedding matching have been well studied in previous work (e.g., Peng et al., 2021; Andreella et al., 2023). The proposed method applies existing ideas in a new context but lacks a substantial methodological innovation.\n(2) The paper provides no error bounds, stability guarantees, or theoretical justification for the effectiveness of Procrustes alignment in this context. It remains unclear why low-dimensional principal components derived from partial distance matrices can sufficiently capture global topological structure.\n(3) Experiments rely solely on the OGBN-Products dataset. The absence of diverse benchmarks (e.g., citation, social, or knowledge graphs) undermines claims of generalizability. No baseline comparisons are provided with established methods for graph alignment or transfer learning."}, "questions": {"value": "(1) Could the authors offer further theoretical or empirical justification clarifying why the low-dimensional principal components obtained from local graph views are sufficient to capture and represent the global topological structure?\n(2) Do the authors expect their approach to generalize to graphs of different domains or scales (e.g., citation networks, social graphs, or knowledge graphs)? If so, what properties of the proposed method ensure this generalizability?\n(3) Could the authors comment on how their approach compares against other graph alignment or transfer-learning methods such as GraphBridge, GWL, or ALIGNN? Even a qualitative or computational comparison would help contextualize the claimed advantages."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "kC0kb5zcRR", "forum": "7YfmpTLjrD", "replyto": "7YfmpTLjrD", "signatures": ["ICLR.cc/2026/Conference/Submission21841/Reviewer_FGTR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21841/Reviewer_FGTR"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21841/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761640098082, "cdate": 1761640098082, "tmdate": 1762941950629, "mdate": 1762941950629, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}