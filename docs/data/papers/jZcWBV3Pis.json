{"id": "jZcWBV3Pis", "number": 4902, "cdate": 1757792929124, "mdate": 1759898006215, "content": {"title": "Evaluating the Robustness of Chinchilla Compute-Optimal Scaling", "abstract": "Hoffman et al. (2022)'s Chinchilla paper introduced the principle of compute-optimal scaling, laying a foundation for future scaling of language models.\nIn the years since, however, valid concerns about Chinchilla have been raised: wide confidence intervals, discrepancies between its three approaches, and incongruities with other scaling laws.\nThis raises a critical question for the field: Can practitioners still rely on Chinchilla's prescriptions?\nOur work demonstrates the answer is yes.\nWe begin by uncovering that the model parameters central to Chinchilla's analyses were ambiguous: three interpretations are possible, with relative differences between different interpretations of model parameters as high as 15.2\\%.\nWe find that, perhaps surprisingly, which model parameters are used for the analyses do not meaningfully affect key results: the scaling law estimates and the compute-optimal tokens-to-parameter ratio.\nIndeed, under one interpretation, the tokens-to-parameter ratio becomes more constant with the target compute budget.\nWe then ask how distorted the Chinchilla model parameters \\textit{could} have been without meaningfully affecting the key results.\nBy deliberately perturbing model parameters in four structured ways, we find that key Chinchilla results are most sensitive to additive or systematic errors, which can alter the otherwise flat \ntrend of the optimal tokens-to-parameter ratio, but overall, Chinchilla's key results withstand sizable perturbations.\nAltogether, our findings offer the field renewed confidence in Chinchilla as a durable guide for scaling language models.", "tldr": "We investigate the robustness of Chinchilla compute-optimal scaling for language models", "keywords": ["scaling laws", "compute-optimal scaling", "language models", "large language models", "robustness analysis"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a891a99220f75c4408a3031a1a5f11788de2fe62.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "In this paper authors perform a sensitivity analysis of \"Chinchilla\" [1] scaling laws of LLMs (approach 3 - parametric $L(N,D)$ fit), that prescribed a compute-optimal token-to-parameters (TTP) ratio being constant. The authors perturbed model parameter count $N$ in 4 systematic ways (multiplicative, additive, systematic bias, log-normal noise) and re-fitted Chinchilla scaling laws on the perturbed data. They find out that Chinchilla's constant optimal TTP ratio holds to some extent with both multiplicative and with added noise and in general Chinchilla's prescriptions are reliable.\n\n1. Hoffmann, Jordan, et al. \"Training compute-optimal large language models.\" arXiv preprint arXiv:2203.15556 (2022)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Analyzed the ambiguity in Chinchilla's model parameters count.\n- Systematic model parameters perturbations like additive term, don't affect main Chinchilla claims - constant token-to-parameter ratio.\n- The paper is well written and concise."}, "weaknesses": {"value": "### Weaknesses\n\n- The main weakness of this work is the lack significance. In the abstract and the introduction, authors lay out the motivations behind this paper: can Chinchilla's prescribed token-to-parameter ratio be trusted? Unfortunately, the paper answers this question only partially: if we have a systematic error in counting model parameters, the compute optimal TTP will likely be constant. However, the paper doesn't give any insight whether Chinchilla's initial $L(N,D)$ functional form, from which the optimal TTP ratio is derived from, is reliable in the first place. Handful of recent works looked into other functional forms and/or approaches that prescribe other TTP ratios [1,2,3]. Despite, the findings presented in the paper being valid and important, I don't think the analysis is deep enough and the paper's insights add to our understanding of compute optimal scaling of LLMs.\n\n### References\n\n1. McLeish, Sean, et al. \"Gemstones: A model suite for multi-faceted scaling laws.\" arXiv preprint arXiv:2502.06857 (2025).\n2. Li, Houyi, et al. \"Farseer: A Refined Scaling Law in Large Language Models.\" arXiv preprint arXiv:2506.10972 (2025).\n3. Hu, Shengding, et al. \"Minicpm: Unveiling the potential of small language models with scalable training strategies.\" _arXiv preprint arXiv:2404.06395_ (2024)."}, "questions": {"value": "- What data was used for the fits? What was number of points and $N\\times D$ combinations?\n- Are the wide confidence intervals in chinchilla due to systematic errors (i.e. noise in the model parameters estimation)? \n- How the predictions of Chinchilla change with perturbations? E.g. how the $L(N,D)$ extrapolation changes with perturbation on larger compute budgets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "5sQitjtfL0", "forum": "jZcWBV3Pis", "replyto": "jZcWBV3Pis", "signatures": ["ICLR.cc/2026/Conference/Submission4902/Reviewer_LUM4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4902/Reviewer_LUM4"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4902/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761742343089, "cdate": 1761742343089, "tmdate": 1762917750451, "mdate": 1762917750451, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper analyses Chinchilla scaling law's robustness w.r.t. the model parameters. It does two experiments: (1) reran the Chinchilla fit with two different interpretations of model parameter counts, besides the Chinchilla one; (2) introduce synthetic error / perturbation to model parameter counts to test for the robustness of the Chinchilla fit. The paper found that in both experiments, the Chinchilla scaling law does not meaningfully change and Chinchilla scaling law are most sensitive to additive or systematic errors, but overall, Chinchilla’s key results withstand sizable perturbations."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well written and is focused on one problem. Robustness of the scaling laws is an important problem as it affects its predictive power."}, "weaknesses": {"value": "1. While robustness of Chinchilla scaling law is an important problem, I believe the paper would be greatly strengthened it is more based on real-world use cases of the Chinchilla scaling law, so that findings can guide practice. Currently, it is more theoretical studies. For example,\n\n1-1: the first experiment consider three possible model parameters counts: Chinchilla's reported model parameters, best fit, and standard formula. I feel instead of best fit, the choice of model parameters could be based on how people actually count model parameters, for example according Kaplan et al, Hoffmann et al, whether embedding weights are included, whether efficient implementation of operators that reduces parameters are considered.\n\n1-2: The second experiment is based on synthetic perturbations of model parameters, while such robustness understanding is helpful, I believe it would be made more practically helpful if the analysis is based on realistic variation in how people count parameters.\n\n2. I am curious and hope the authors could elaborate in revision, what previous works have also analysed the model parameters count aspect of the neural scaling law (Kaplan, Chinchilla, or others), what are their findings, and how this work compares to them and finds anything novel. For example, Porian et al also discusses different model parameters counts in detail in their table 2 and Appendix B in Appendix, conducts experiments with two different kinds of models counts and compare them in Figure 1 and 7, and found \"limited difference\" in scaling laws. Elaborating this point in paper would help readers better position this work in context. I note that while line 48 ~ 53 mentions existing works, the discussion do not more specifically touch on experiments & findings related to model counts and robustness. \n\n- Porian, Tomer, et al. \"Resolving discrepancies in compute-optimal scaling of language models.\" Advances in Neural Information Processing Systems 37 (2024): 100535-100570.\n\n3. I encourage the authors to describe more details how existing works count parameters, like in Kaplan et al, Hoffman et all, and other works. This helps readers understand where the descripency is in the real world. Appendix B in Porian et al would be a good example. \n\n4. I wonder how exactly Hoffman et al calculates mode counts? I understand this information might be missing from the original paper. But I also read from Appendix B in Porian et al that \"Hoffmann et al. [25] account for both linear and attention layers in their\nFLOP computation essentially using Neff in their first two estimation approaches. However, their third approach appears to ignore the attention FLOPs and also count the embeddings parameters,i.e., setting N′ = N + dv.\" It would be very helpful if the authors understand how Hoffman calculates model parameters and also describe in main paper. And then, the best fit model count will not be necessary."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6iHsJRQwnc", "forum": "jZcWBV3Pis", "replyto": "jZcWBV3Pis", "signatures": ["ICLR.cc/2026/Conference/Submission4902/Reviewer_7rMq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4902/Reviewer_7rMq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4902/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761974695909, "cdate": 1761974695909, "tmdate": 1762917749379, "mdate": 1762917749379, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In spirit of number of previous works, the paper revisits the Chinchilla scaling law study, noting that model parameter counts used in Chinchilla’s analysis are ambiguous, which leads to question how the perturbations in model param counts would impact important conclusions from the study like the claimed token to parameter (TTP) ratio (heuristics of ~20 tokens-per-parameter) in which many practitioners arguably still trust. \n\nTo answer this question, authors first investigate three interpretations how Chinchilla study may have determined the model params - i) via Table A9 from original study (original reported params) ii) via using standard formula for transformer arch param numbers (standard params) and iii) via a best fit formula used by authors that comes close to reported params (best fit). Authors find that despite relative error of up to 15.2\\% in param numbers between those sets, the parametric fit L(N,D) and the resulting $D_{opt}/N_{opt} (C)$ fits do not differ substantially. \n\nFurther, authors conduct a perturbation study to test how sensitive the scaling law fits are to various errors in model param estimation. Authors distort the parameter counts of the original Chinchilla’s experiments in four structured ways: multiplicative scaling, additive offsets, systematic geometrical bias, log-normal noise. They then re-fit the parametric loss L(N,D) and examine how the implied compute-optimal TTP shifts. The reported finding is that for multiplicative and random‐noise perturbations the TTP fit remains rather stable, while for additive or systematic bias perturbations the TTP fit slope can change significantly. Overall, the authors draw the conclusion that Chinchilla’s core result — estimates for compute-optimal TTP ratio $D_{opt}/N_{opt}$ — is robust to various potential errors in parameter counting. The authors state thus that while Chinchilla’s experimental data has ambiguities, the guidance it gives for practitioners is still valid."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The paper addresses an important issue: how much does misspecification of model parameter counts might affect the validity of derived scaling laws, focusing on Chinchilla case as the one still very much relevant for practitioners.\n* Three alternate parameter interpretations is a convincing study showing the insensitivity of the scaling law fits to moderate (~15 %) parameter disagreements.\n* The perturbation framework containing the four types of perturbation (multiplicative, additive, systematic bias, log-normal noise) covers realistic modes of parameter‐miscounting (e.g., whether embeddings/attention/FFN are fully counted, rounding, etc).\n* The paper is clearly written: it explains well the motivation, methodology and results."}, "weaknesses": {"value": "1. Main weakness in my opinion is the strong claim of Chinchilla conclusions eg with regard to TTP estimates being good guidance for practitioners following the conducted study. In my opinion, the paper convincingly shows that possible perturbations of model param numbers do not alter substantially scaling law fit as conducted in Chinchilla study. However, it does not make clear whether the conclusions from those fits are justifiable. Eg if we look at Fig 2, the D/N fits show high uncertainty, making especially for larger scale compute region above $10^{22}$ unclear what TTP estimate to take. It appears that even the slope of D/N fit might change from negative to positive, making a strong difference for TTP conclusions on larger scales. While this is not the deficit of the current work and is inherited from Chinchilla design, I think the statement abour relying on const 20 TTP is confusing, as the study does not deal with repairing this particular deficit of original Chinchilla work.\n\n2. I think as the study deals with effect of model param perturbations only, one has to be again cautious to make a general statement about Chinchilla hints to be reliable - as also further elements of the study, eg dataset composition nature etc, can be in same way source of changing the important trends as model param perturbation, which is though not checked by the study.\n\n3. There is no enough detail about the data used for the current study. It seems that authors rely on previous work done by Besiroglu et al to extract the data from original Chinchilla plots, but it is nowhere mentioned.\n\n4. It is not clear why authors rely only on Chinchilla data to make a case for TTP recommendation testing. Eg, Llama 3 reports also offer numerous datapoints that were used to fit scaling laws and it would be good to understand whether TTP estimation there leads to same or different results as in Chinchilla, which would provide for practitioners more consistency if both were aligned in their recommendations derived from scaling law fits.\n\n5. It seems there is not a clear validation of scaling law fits, eg using held out points, to make sure that obtained fits actually retain the sufficient quality. This was also not performed in original Chinchilla study, validation there was arguably done by using three different approaches and observing similar trends. Here authors use only Approach 3, parametric loss fit, and there should be a way to show that obtained fits are actually to be trusted.\n\n6. I think some relevant citations are missing. Eg FarSeer https://arxiv.org/abs/2506.10972 or https://arxiv.org/abs/2410.11840"}, "questions": {"value": "1. Can the authors point to exact data they are using to conduct their scaling law fits?\n2. Can the authors provide any evidence that scaling law fits they obtain are of sufficient quality, eg by conducting MSE/prediction error measurements on held out points?\n3. Can the authors elaborate on studies like FarSeer https://arxiv.org/abs/2506.10972 that indicate that Chinchilla style compute optimal TTP advice might be entirely off for the larger compute scales? Would that affect the message of the current work?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yJ1HF2ME9M", "forum": "jZcWBV3Pis", "replyto": "jZcWBV3Pis", "signatures": ["ICLR.cc/2026/Conference/Submission4902/Reviewer_PX56"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4902/Reviewer_PX56"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4902/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762125463541, "cdate": 1762125463541, "tmdate": 1762917749037, "mdate": 1762917749037, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the definitional ambiguity surrounding model parameters within the Chinchilla study. The analysis demonstrates that while the relative error among the three distinct parameter computation methods is substantial , the resulting impact on the final, compute-optimal data-to-parameter ratio is found to be negligible."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "A significant strength of this work lies in its compelling research perspective, which undertakes a rigorous analysis of a previously existing, yet imprecisely defined, theory. The experimental design is thorough, providing robust validation for the conclusions drawn. Furthermore, the manuscript is exceptionally well-written, demonstrating a high degree of clarity and fluency."}, "weaknesses": {"value": "* Objectively, the research findings of this paper offer a comparatively limited marginal contribution. \n* Furthermore, despite the highly insightful nature of the original Chinchilla work, its practical application value within the industry remains constrained."}, "questions": {"value": "Relative to the widely cited $\\sim 20:1$ Chinchilla scaling ratio, the training token counts for current open-source large language models (LLMs) such as Qwen's 1B to 32B parameter series are consistently maintained at over 1 Trillion tokens. Does this training regimen constitute excessive training (over-training), and, crucially, is it an appropriate scale for exploring current scaling laws? Specifically, what guidance does this observed practice offer regarding the determination of optimal hyperparameters?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jfW2nxUmEH", "forum": "jZcWBV3Pis", "replyto": "jZcWBV3Pis", "signatures": ["ICLR.cc/2026/Conference/Submission4902/Reviewer_RqTP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4902/Reviewer_RqTP"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4902/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762454468858, "cdate": 1762454468858, "tmdate": 1762917748625, "mdate": 1762917748625, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}