{"id": "Kgcbzb9CZO", "number": 16545, "cdate": 1758265834528, "mdate": 1759897233950, "content": {"title": "Towards Better Generalization via Distributional Input Projection Network", "abstract": "As overparameterized models become increasingly prevalent, training loss alone offers limited insight into generalization performance. While smoothness has been linked to improved generalization across various settings, directly enforcing smoothness in neural networks remains challenging. To address this, we introduce Distributional Input Projection Networks (DIPNet), a novel framework that projects inputs into learnable distributions at each layer. This distributional representation induces a smoother loss landscape with respect to the input, promoting better generalization.\nWe provide theoretical analysis showing that DIPNet reduces both local smoothness measures and the Lipschitz constant of the network, contributing to improved generalization performance. Empirically, we validate DIPNet across a wide range of architectures and tasks, including Vision Transformers (ViTs), Large Language Models (LLMs), ResNet and MLPs. Our method consistently enhances test performance under standard settings, adversarial attacks, out-of-distribution inputs, and reasoning benchmarks.\nWe demonstrate that the proposed input projection strategy can be seamlessly integrated into existing models, providing a general and effective approach for boosting generalization performance in modern deep learning.", "tldr": "", "keywords": ["distributional learning", "generalization"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/79475ee4e3268b89444334e0c18f75dada518be5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors proposed to improve the robustness and generalization performance by adding Gaussian noise to the intermediate representations. Some general theoretical analysis and preliminary experimental results partially demonstrate the claims."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Not clear."}, "weaknesses": {"value": "* Idea is not completely new. The idea is quite similar to [1], although [1] may not be well recognized. \n\n[1] Yu, Xiaowei, et al. \"Noisynn: Exploring the impact of information entropy change in learning systems.\" arXiv e-prints (2023): arXiv-2309.\n\n* So many random assumptions appeared in the derivation. First of all, what's the advantage for introducing $\\eta$ in (1). This is a quite specific parameterization with a strong assumption on $\\eta$. The variational inference part is only used to approximate the log-likelihood but if at the very beginning there are no points to introduce $\\eta$, there are no support for this method. \n\n* So many tuning parameters ($\\alpha, \\beta, \\lambda$). And the stability constraint has no theoretical support. In practice these parameters are competing with each other so how can we find the optimal setup and is this optimal setup over-fitting to specific problems?\n\n* Training cost is significantly high, as we need to do multi-pass for each data sample.\n\n* Theorem are basically meaningless and requires implicit assumptions. For example, probability density is not guaranteed to be smooth but Theorem 1 implicitly requires this. Theorem 2 and 3 only shows there exists some probability measure $\\mathcal{P}$, but how can we guarantee the $\\mathcal{P}$ used in the proposed methods really improves? The proof only means we \n\n* Proof is not rigorous. For example, in proof of Theorem 2 and 3, we focus on norm square which should be related to $b^2$ and $s^2$. Also, this $\\eta$ is very likely to condition on $x$ (hidden in the claim that let $\\mathcal{P}$ as a uniform distribution with support measurement $\\zeta C$). This is far away from the claim in the methodology.\n\n* Experiments is only on CIFAR-100 and GSM-8K, which is quite small-scale. The authors does not mention if this evaluation is fair under the same training budget. And I'm also wondering if these are orthogonal to the known methods, say if we already apply different kinds of augmentation methods, does this method still work?"}, "questions": {"value": "Just echo the weakness part:\n\n* Relationship to the existing work.\n* More rigorous justification of the method.\n* More convincing experimental results."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "sZZqMlDGKs", "forum": "Kgcbzb9CZO", "replyto": "Kgcbzb9CZO", "signatures": ["ICLR.cc/2026/Conference/Submission16545/Reviewer_doar"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16545/Reviewer_doar"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16545/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760630718507, "cdate": 1760630718507, "tmdate": 1762926625851, "mdate": 1762926625851, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Distributional Input Projections, where Gaussian perturbations are injected at intermediate layers and their parameters are learned. The goal is improved generalization through smoother representations."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper is generally well-written and easy to follow. The authors run experiments on multiple architectures and tasks (MLPs, CNN/ViT, a language model), indicating an effort toward broader validation. Some empirical gains are visible, suggesting the idea could have regularization benefits. The attempt to connect generalization behavior to smoothness properties is conceptually aligned with robust learning literature."}, "weaknesses": {"value": "1. Misrepresentation of randomized smoothing literature. The manuscript repeatedly refers to “random smoothing” and incorrectly attributes adversarial training to Cohen et al. (2019). Cohen et al. established Gaussian randomized smoothing certificates using Neyman–Pearson and did not perform adversarial training. Salman et al. later connected smoothing to Lipschitz control, but this distinction is blurred or incorrect in multiple places. Example: Line 239: “and adversarial training (Cohen et al., 2019)”, this is factually wrong. Line 330: RS reduced to just adding noise; this misses the certified robustness objective.\n2. Limited novelty and unclear conceptual contribution. Adding learnable Gaussian noise inside networks is close to existing stochastic regularization methods (variational dropout, noisy layers, Bayesian features). Without a formal guarantee or structural insight, the contribution appears incremental. Distillation ablates the sampling at inference, which suggests much of the benefit may stem purely from stochastic training effects.\n3. Theory is not rigorous enough for the claims. Theorems rely on smoothness assumptions that do not reflect practical deep nets (non-smooth activations, unknown Lipschitz constants). No certified robustness or provable Lipschitz improvement is established, unlike in the proper RS literature. Consequently, the theoretical section does not convincingly support the narrative.\n4. Empirical evidence is insufficient. Results are limited to small-scale datasets. For generalization claims, ImageNet-level evaluation is expected. Variance across seeds is missing, and LLM results show minimal gains under a single training regime. There is no adversarial evaluation, despite repeatedly referencing adversarial robustness."}, "questions": {"value": "Please address the weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "s00pxKXiZD", "forum": "Kgcbzb9CZO", "replyto": "Kgcbzb9CZO", "signatures": ["ICLR.cc/2026/Conference/Submission16545/Reviewer_E9Va"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16545/Reviewer_E9Va"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16545/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761811959688, "cdate": 1761811959688, "tmdate": 1762926625155, "mdate": 1762926625155, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Distributional Input Projection Networks (DIPNet), a framework that projects inputs at each layer into learnable distributions rather than fixed feature vectors. This induces smoother loss landscapes with respect to inputs and improves generalization. The authors provide theoretical analysis showing reductions in local smoothness measures and the Lipschitz constant. DIPNet is evaluated across diverse architectures—ViTs, LLMs, ResNets, and MLPs—and shows consistent gains in test accuracy, robustness to adversarial attacks, out-of-distribution data, and reasoning tasks. The method is modular and can be integrated into existing networks without major architectural changes."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Comprehensive experiments across state-of-the-art vision and language models.\n2. Strong theoretical grounding linking distributional projection to smoothness and generalization.\n3. Improves not only standard generalization but also robustness to adversarial, OOD, and reasoning benchmarks."}, "weaknesses": {"value": "1. Although motivated by smoothness, the intuition behind why distributional projection helps over simpler regularization is not fully disentangled.\n2. The method introduces substantial computational overhead, and its effectiveness appears to rely heavily on distillation, raising concerns about efficiency and practicality in large-scale training."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MlGMR3bktj", "forum": "Kgcbzb9CZO", "replyto": "Kgcbzb9CZO", "signatures": ["ICLR.cc/2026/Conference/Submission16545/Reviewer_rdjf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16545/Reviewer_rdjf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16545/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761975261282, "cdate": 1761975261282, "tmdate": 1762926624677, "mdate": 1762926624677, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes DIPNet, which turns each layer’s deterministic input into a learnable Gaussian distribution \nthe model samples per-layer “particles” and averages forward trajectories to make predictions. The authors claim this distributional input projection smooths the loss landscape, lowers Lipschitz/smoothness measures, and thereby improves generalization. They provide analyses showing bounded Lipschitz and reduced smoothness for the distributionally smoothed function, add a stability penalty on output variance, and report gains across vision (ViTs on CIFAR-100 under various training-time attacks) and LLM reasoning"}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The per-layer Gaussian projection with k-trajectory averaging integrates cleanly; the implementation steps are clearly stated.\n- Proofs that smoothing can bound the Lipschitz constant and reduce second-order smoothness support the generalization narrative (I have not fully verified the proofs).\n- The paper includes comprehensive setups and supportive ablation studies."}, "weaknesses": {"value": "- The paper is poorly written and needs reorganization. Please add informative captions to all tables/figures and avoid pasting raw W&B screenshots; re-plot with consistent styling and legible axes/legend.\n- The method is computationally expensive, which requires m forward passes per example.\n- Reported fine-tuned results appear lower than widely reported pretrained baselines on GSM8K (e.g., Qwen2.5-3B ≈ 79.1; Llama-3.1-8B ≈ 84.5, per the Qwen 2.5 paper).\n- Marginal improvements over other simple baselines (<1% ViT-Small/ViT-Base/LM experiment) while being much more expensive"}, "questions": {"value": "- Please report FLOPs and wall-clock time (training and inference) versus baselines, for several k values. Include memory usage and throughput.\n- There appears to be a mismatch between your reported GSM8K accuracy and official/commonly reported numbers. Please double-check evaluation protocols.\n- Ensure comparisons against strong, compute-matched baselines (e.g., single-pass counterparts with similar wall-clock) and clarify whether any baseline benefits from additional augmentation or ensembling."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "KovOkVqRjo", "forum": "Kgcbzb9CZO", "replyto": "Kgcbzb9CZO", "signatures": ["ICLR.cc/2026/Conference/Submission16545/Reviewer_pgJG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16545/Reviewer_pgJG"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16545/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762884557251, "cdate": 1762884557251, "tmdate": 1762926624097, "mdate": 1762926624097, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}