{"id": "I43IOiimO6", "number": 16917, "cdate": 1758270211498, "mdate": 1763772081074, "content": {"title": "CARL: Preserving Causal Structure in Representation Learning", "abstract": "Cross-modal representation learning is fundamental for extracting structured information from multimodal data to enable semantic understanding and reasoning. However, current methods optimize statistical objectives without explicit causal constraints, where nonlinear mappings can introduce spurious dependencies or eliminate critical mediators, leading to representation-induced structural drift that undermines the reliability of causal inference. Therefore, establishing theoretical guarantees for causal invariance in cross-modal representation learning remains a foundational challenge. To this end, we propose Causal Alignment and Representation Learning (CARL), which explicitly embeds causal structure preservation constraints into cross-modal alignment objectives. Specifically, CARL introduces a multi-consistency loss architecture that jointly optimizes conditional independence preservation and information bottleneck regularization to balance cross-modal compression with critical variable retention, ensuring low-density modalities are not masked by high-density reconstruction demands. We further incorporate monotonic alignment consistency loss to establish correspondence between semantic similarity and representation distance through Spearman correlation, and Markov boundary preservation loss to maintain identifiability conditions including backdoor, frontdoor, and instrumental variable criteria in the shared representation space. In synthetic experiments with known causal ground truth, CARL achieves state-of-the-art performance in preserving conditional independence patterns and maintaining causal query identifiability under structural uncertainty. Real-world validation on Human Phenotype Project data reveals that CARL successfully preserves causal structures between fundus vascular representations and cardiovascular events, demonstrating its capacity for reliable cross-modal causal inference in complex biomedical applications.", "tldr": "", "keywords": ["Structure-preserving Constraints", "Representation Learning"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3b6b13f773ecddb0797475eb4294cb83d966b205.pdf", "supplementary_material": "/attachment/429e88ccc8b5eb0ec3f760c75fd2f1613f860ae4.pdf"}, "replies": [{"content": {"summary": {"value": "This paper proposes a method for preserving known causal structures (e.g., mediation) in cross-modal representation learning. The approach leverages the independence relation implied by mediation, $T⊥Y^{*}| M$, to design a mutual-information-based loss that enforces the mediation causal structure. The authors validate the effectiveness of the method on a synthetic dataset and further estimate causal effects on the Human Phenotype Project (HPP) data, which align with causal modeling under mediation assumptions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "⦁\tThe experiments are comprehensive. In particular, the design of the synthetic dataset is well-documented in the appendix.\n⦁\tThe model architecture and implementation details are clearly described, which enhances reproducibility."}, "weaknesses": {"value": "⦁\tThe claimed contribution regarding the preservation of causal structure in cross-modal representation learning appears somewhat overstated. First, the modalities are limited to tabular and image data. Second, the assumed causal structure is restricted to mediation. The core loss functions conditional independencies preservation $\\mathcal{L}{CI}$ and Markov boundary retention $\\mathcal{L}{MBR}$ are heavily dependent on a predefined causal structure.\n⦁\tThe authors seem to assume a causal graph under mediation. If such prior knowledge is unavailable, can the assertion of “preservation of causal structure” be generalized to unknown causal graphs? Without knowledge of the causal graph, how would one ensure preservation of the causal structure?\n⦁\tThe method design is rather straightforward. Employing mutual information to enforce conditional independence has been widely explored in causal representation learning, and Modal Alignment Consistency is also a common idea in cross-modal representation learning."}, "questions": {"value": "⦁\tThere seems to be an issue with some \\ref{} in the appendix, as they do not correctly link to Section ABC. Section ABC in appendix appeared twice.\n⦁\tIn the $I^M$ and $I^Y$ settings, the causal relationship visualizations in the appendix show weak correlations in some cases, with small $R^2$ values. In particular, for the Rotation transformation, the results hardly reflect the conclusions stated by the authors. Could the authors clarify this discrepancy? Moreover, the statement “These visualizations serve as an empirical confirmation of the dependencies and conditional independencies specified by our ground-truth SCM” is somewhat misleading, since the visualizations only verify dependencies. Why not empirically test $T⊥Y | M$ on the synthetic data?\n⦁\tRegarding the real-world HPP dataset, it is unclear what the causal effect of the learned latent representations signifies. Could these causal effects not be directly estimated from the observed data? How large is the discrepancy between the causal effects estimated in the latent space and those from the true causal effects? Please provide quantitative results."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "PJS8HRk2Nm", "forum": "I43IOiimO6", "replyto": "I43IOiimO6", "signatures": ["ICLR.cc/2026/Conference/Submission16917/Reviewer_enbA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16917/Reviewer_enbA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16917/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761918079216, "cdate": 1761918079216, "tmdate": 1762926943931, "mdate": 1762926943931, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents CARL, a framework for learning cross-modal representations that are intended to preserve causal structure. The paper introduces the notion of Causal Structure Preservation (CSP) consisting of three conditions, which are enforced during training via three distinct loss terms. The authors show that under consistency and other assumptions, joint optimisation of these loses ensures CSP. CARL demonstrates applications to real-world cross modal data. The presented theoretical framework along with experiments is promising. However, the presentation of the paper needs to be improved."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "- The problem of preserving latent causal structure is very interesting.\n- Cross modal data is a challenging scenario with significant real-world applications. The paper demonstrates applications to medical data.\n- The method is compared with other baselines on synthetic data and it shows superiority in preserving causal structure."}, "weaknesses": {"value": "**Clarity concerns**\n\nThe main concern I find in this paper is presentation and clarity. In its current form I needed to jump back and forth between sections and between main text and appendix to understand even the basic setup. This makes the work very difficult to evaluate in terms of correctness and novelty. Please find below some recommendations.\n  - The contents of the paper could be organised to ease the flow of the paper and improve clarity.\n    - The paper starts with a presentation of the datasets used. It is very interesting to mention applications at the start, but I believe an improvement would be to first introduce the problem setup, and then connect it to the real-world application.\n      - In this line, I found it confusing that Figure 1 already introduces notation {X, M, Y}, as covariates, mediators, and outcomes. However, the concrete formalisation comes into Section 3.\n      - Also here, in Figure 2, the 3 setups (IM, IY, and DUAL) are mentioned, which are briefly described in section 3, and are explained in detail in section 4.1.\n      - Similarly, Theorem 2.1 in Section 3.1 depends on loss terms that are only introduced in Section 4.2. This forces the reader to jump forwards and backwards to understand the theorem.\n    - Consider the following organisation: \n      - Have a section with problem setting where (i) some initial  motivation is presented (cross-model CRL for HPP applications), (ii) the problem setup is presented with all its elements (that would be section 3 and 4.1),  (iii) when introducing concepts such as mediators, treatments, link them to the HPP example, and (iv) present the formalisation of CSP with high-level intuitions linking to HPP as well.\n      - Present the methodology section (loss functions and strucutre discovery).\n      - Present the theoretical guarantees.\n  - The notation introduced in this paper is very heavy, with some elements not discussed clearly, making it difficult to follow when reading. The main text should be self-contained, with details in the appendix. However, I believe the paper introduces notation in the main text with explanations in Appendix, and this impacts presentation significantly.\n      - In section 3, I is used for images, but I(.,. |.) also denotes conditional mutual information.\n      - Assumption 2 (line 176) introduces new notation (a, b, \\eta) which is not explained.\n      - Definition 2.1 introduces the Spearman correlation without citation.\n      - Theorem 2.1 introduces notations O_P(\\cdot) which are not explained, and loss functions which are discussed in later sections.\n      - The monotonic alignment consistency (Equation (3)), introduces semantic labels a, which have not been introduced before. Please provide intuition.\n      - Equation (4) groups discussed loss functions, along with 3 additional terms “align”, “style”, “IB”, which are not discussed in the main text.\n- Section 4 needs revision in terms of citations and clarity:\n  - For example, since the loss functions are not novel themselves, citations should be accompanied for clarity. This also helps the reader what is novel in the presented methodology.\n  - Section 4.3 is very hard to follow, and it is not clear whether the idea is novel or it is derivative from previous work. I believe the idea is to present some analysis in which the causal structure can be recovered from latents. However, there are no notations to understand where the metrics come from, or intuitions for the steps to show consistency guarantees.\n    - Lines 327-333: Is this a known result? Can you provide a citation, or formalise a statement in a theorem if it is novel?\n  - Section 4.4 lists theoretical properties. For clarity, the corollary should be read as a formal standalone statement with proof, and not as a paragraph.\n- The Appendix section contains repeating labels from line 1718 (Label ordering goes back to A).\n\n**Theoretical correctness**\n\nThe theoretical results of this paper are very difficult to follow. This does not mean that the results are incorrect. However, the current presentation does not allow the reader to follow the logic intuitively. Please find details below:\n  - Section 3.1 contains incorrect labels for definitions and theorems.\n  - Some intuitions for the CSP principle should be explained after Definition 2.1. Intuitively from my understanding is to ensure that learned latents preserve structure. Now, why are conditions (i-iii) sufficient/necessary for this idea to hold? I believe this would significantly improve the presentation of \\epsilon-CSP.\n  - The Definitions and Theorems lack clear structure, and don’t include standalone statements or results.\n    - Theorem 2.1 introduces the result in lines 201-204, and continues with additional remarks. The remarks should be separate from the theoretical statement.\n    - Theorem 2.2: Lines 218-219 are additional remarks that should be outside of the theoretical statement.\n  - Equations in Theorems 2.1, 2.2, are inline, making them hard to follow. Some of these equations are introduced with an explanation in Section 4. Consider moving the presentation of these equations before the theoretical statements.\n  - I briefly checked the proofs in the Appendix, and I find them very hard to follow.\n    - At least a proof sketch should accompany the main theorems and corollary presented in the main paper to intuitively explain how CSP is achieved. How are Assumptions A.5, and A.8.2 utilised to show CSP by minimising the loss function?\n      - For example, to verify this I first read A.5 and A.8.2, then I jumped to C.8, then to theorem B.2.1, which refers to a list of assumptions from A.8. The proof requires to jump back and forth across the document several times, which makes it hard to follow.\n    - Assumption A.5 assumes consistency. This sounds like a very strong assumption. Is this standard? I believe this assumption is very important for CSP to be achieved, and therefore it should be discussed.\n    - There are some Lemmas with missing proofs in the Appendix. If the results are known, please provide concrete citations.\n    - I consider the appendix should be organised so that the theoretical framework can be followed more intuitively. For example, consider introducing a proof strategy first, and then explain the intuition behind each of the Lemmas.\n\n**Comments on experiments**\n\n- The experiments on synthetic data seem to have been reported on one seed. Please provide additional random seeds (3-5) with ranges in the Appendix tables to ensure robustness of your claims.\n- The interpretability of real-world data seems interesting. However, it does not show CARL’s superiority. An additional baseline (e.g. CausalVAE), with a results comparison would improve the stance of the paper for interpretability gains of the proposed method."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yp3ROcdSLy", "forum": "I43IOiimO6", "replyto": "I43IOiimO6", "signatures": ["ICLR.cc/2026/Conference/Submission16917/Reviewer_i8uF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16917/Reviewer_i8uF"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16917/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762012518664, "cdate": 1762012518664, "tmdate": 1762926943580, "mdate": 1762926943580, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a set of causal structure preservation principles and practical approaches to address the causal invariance problem in cross-modal scenarios. The approach has been validated on multimodal biomedical dataset HPP and synthetic hand-digit datasets, showing promising performance gains."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "+ The problem of causal structure preservation is practically important especially in the cross-modal scenarios. This paper has made a fundamental exploration and proposed a principled approach to this problem.\n+ This paper presents both theoretical analysis and empirical study on real or synthetic data. Especially, experimental results could show clear performance gains through ablation study and parameter sensitive analysis. \n+ The paper is well structured and has clearly stated the research challenges, proposed approaches, and core contributions."}, "weaknesses": {"value": "- Unclear claim. For the contemporary cross-modal representation approaches like CLIP, ALIGN, and ImageBind, it is encouraged to provide  literature or empirical results to support the claim that they cannot guarantee the three mentioned causal properties (conditional independence, Markov boundaries, identifiability conditions). Besides, for each of these properties, it’s suggested to explain with an example to correlate with CIB, MAC, or CIC, as they closely correspond to the key technical contributions in this paper.\n\n- Experimental Discussion. Structure-preservation evaluation showed that CARL method could keep a CSI metric of 1.0 under varying sample size and noise level, and baselines only achieved 0.25 CSI. It could be better to discuss this metric more to help understand why these superior performances come from the monotonic alignment constraint that maintains semantic-geometric correspondance (as claimed in Sec. 5.2).\n\n- Missed Ablation Study. Given that the overall loss consists of a regularizer R that has cross-modal alignment loss, style consistency loss, and IB loss, why are the latter two terms not considered in ablation study in Table 2? This is important as the paper's Abstract explicitly mentioned the IB regularization as a key component."}, "questions": {"value": "- About the CSP principle. What are the advantages of the proposed CSP principle in Sec. 3.1 in the field of cross-modal causal invariance? And how does each principle motivate/guide the development of the proposed approaches?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ACj5uob61B", "forum": "I43IOiimO6", "replyto": "I43IOiimO6", "signatures": ["ICLR.cc/2026/Conference/Submission16917/Reviewer_8ef8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16917/Reviewer_8ef8"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16917/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762137230782, "cdate": 1762137230782, "tmdate": 1762926943268, "mdate": 1762926943268, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a cross-modal representation learning framework named CARL, designed to address the issue that optimizing purely statistical objectives can disrupt underlying causal structures. CARL jointly optimizes three structure-preserving losses—Conditional Independence Preservation, Markov Boundary Preservation, and Monotonic Alignment Consistency—to ensure that the learned representation space retains the causal structure of the original data. The authors validate the approach on synthetic datasets and a real-world Human Phenotype Project (HPP) dataset, and provide theoretical guarantees showing that causal queries remain identifiable in the representation space."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1 First systematic treatment of cross-modal causal structure preservation, formalizing the CSP principle and the three core challenges.\n\n2 Introduces the ε-CSP definition, a attainability/consistency theorem, and a theorem for preserving identifiability of causal queries, providing rigorous guarantees.\n\n3 The three losses are well motivated and complementary, balancing conditional independence with information retention.\n\n4 Synthetic and real data jointly verify effectiveness, robustness, and interpretability.\n\n5 Successfully recovers known medical causal pathways on the HPP dataset, showcasing potential in complex biomedical scenarios."}, "weaknesses": {"value": "1 Although the appendix contains detailed proofs, the main text could better explain some theoretical results (e.g., an intuitive reading of the error bounds) to improve readability.\n\n2 While experiments span synthetic and real data, they do not include larger-scale cross-modal benchmarks (e.g., vision-language tasks), limiting the demonstration of generalization.\n\n3 In the DUAL configuration the method avoids using both image modalities simultaneously, which may limit information utilization in certain practical settings."}, "questions": {"value": "1 Have the authors considered evaluating CARL on larger-scale cross-modal tasks (e.g., CLIP-style vision-language alignment) to assess generalization?\n\n2 CARL trains multiple independent predictors with cross-validation. Has its scalability on large-scale data been evaluated?\n\n3 For highly imbalanced modality-information densities (e.g., image vs. text), can CARL still effectively prevent the lower-density modality from being overshadowed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SZUUSLtvS2", "forum": "I43IOiimO6", "replyto": "I43IOiimO6", "signatures": ["ICLR.cc/2026/Conference/Submission16917/Reviewer_DeFu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16917/Reviewer_DeFu"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16917/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762796247286, "cdate": 1762796247286, "tmdate": 1762926942957, "mdate": 1762926942957, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}