{"id": "y6je0oiwEg", "number": 24969, "cdate": 1758362597251, "mdate": 1763245795491, "content": {"title": "Datatype tagging and prompt alignment: a recipe for boosting LLMs on algorithmic tasks", "abstract": "This paper contributes toward strengthening the bridge between LLMs as programmers and classical ideas in programming languages (PL). Specifically, we show that aligning prompts with *typed programs* enables even small models to reliably emit one-line Python code. We present a simple yet effective recipe consisting of three key ingredients: (i) inline datatype tagging for prompt and code; (ii) a fine-tuned dual-head GPT-2-small with an auxiliary span probe over the prompt; and (iii) a fixed decoder that enforces a finite-state grammar, validates AST shape, and repairs outputs deterministically.\nOn a stratified GPT-4o based dataset that covers primitives such as $\\texttt{add}$, $\\texttt{subtract}$, $\\texttt{max}$, $\\texttt{min}$, and $\\texttt{sort}$, the decoder alone raises execution accuracy by over 40\\% (from $0.58$ to $0.82$)! For counting and repeated addition, prompts map deterministically to single expressions (for example, $\\texttt{s.count('r')}$ and $\\texttt{sum([1]*100)}$), yielding near-zero errors within coverage. Our approach runs on a single GPU, and presents a proof-of-concept on how \"datatype-aware tokenization'' and \"grammar-first decoding,'' among other ideas inspired by PL, improve reliability, coverage, and quality at low cost.", "tldr": "We describe a compact recipe that aligns prompts with a typed program space and reliably emits a single legal Python expression. This helps LLMs align with algorithmic intents more easily and provides a quickfix boost to their algorithmic abilities", "keywords": ["tokenizers", "datatype tagging", "algorithmic alignment", "LLMs and coding", "LLMs and arithmetic", "algebra"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/e602014cb454e6dbbbe1e10286eff0c34b3d6e28.pdf", "supplementary_material": "/attachment/629b909f2a7011fc619b8e430ada97509e8df6b5.zip"}, "replies": [{"content": {"summary": {"value": "This paper evaluates if natural language utterances with tagged data types can be converted one-line Python snippets by a small language model using constrained decoding. During training, a separate model head predicts properties of the predicted tokens with the aim of stabilizing training. The authors claim that constrained decoding improves performance from 0.58 to 0.82—the only two performance metrics mentioned in this paper."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The idea of leveraging small models to perform simple tasks can reduce the impact of ML on computational resources."}, "weaknesses": {"value": "This paper only considers a *very* simple domain-specific language and provides no details on how sample problems were generated. Based on the few samples in the paper, I am surprised that a fine-tuned GPT-2 model only achieves 58%, which raises significant concerns about the quality (and size) of the data.\n\nThe paper assumes that user prompts are annotated with data types. Again, given the simplicity of the presented tasks, I would not expect these tags to be relevant in the input.\n\nThere is very little information on the dataset, such as number of elements or generation process. I would expect most modern LLMs to achieve (near) perfect scores on these simple tasks. I also expect that any sufficiently large and qualitative dataset will cause any modern SLM to be fine-tunable to achieve very high scores—even without constrained decoding.\n\nThere are virtually no experiments and results. There's no ablation on the effect of the explicit data types, of the span probe (besides a very vague *stabilizes training*)."}, "questions": {"value": "Were any experiments performed to validate the three hypotheses, and what were the results?\nWhat is the size of the dataset?\nHow do other (baseline) large (and even small) language models perform on this dataset?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Scko46cC0p", "forum": "y6je0oiwEg", "replyto": "y6je0oiwEg", "signatures": ["ICLR.cc/2026/Conference/Submission24969/Reviewer_FWAP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24969/Reviewer_FWAP"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24969/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761864244510, "cdate": 1761864244510, "tmdate": 1762943267014, "mdate": 1762943267014, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "APzyfkewTp", "forum": "y6je0oiwEg", "replyto": "y6je0oiwEg", "signatures": ["ICLR.cc/2026/Conference/Submission24969/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24969/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763245794733, "cdate": 1763245794733, "tmdate": 1763245794733, "mdate": 1763245794733, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a proof-of-concept technique of using concepts in PL such as type aware tokenization, token tagging, and constraint decoding to aid LLM’s capability of handling small arithmetic tasks. The work achieves this by introducing type-specific tokens into the vocabulary, using a dual-head LM for tagging, and constructing a DFA for constraint decoding. The paper finds that all of these techniques help achieve higher accuracy and even near-zero failure rate on one type of arithmetic task. The paper also presents a theoretical analysis of the constraint decoding."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The paper shows a neat way of combining programming language techniques with LM\n- The idea of adding type tags to the prompt is novel"}, "weaknesses": {"value": "- The presentation of the paper is somehow confusing, with poorly explained techniques and also many newly coined terms (like “datatype-aware tokenization” and “grammar-first decoding”)\n- The evaluation part of the paper is very hand-waiving. Although the paper describes the setup and the findings, the data curation process for both the training dataset and the benchmark is not explained in the paper. Also, the only quantitative analysis of the evaluation result are two numbers (0.58, 0.82), making the claims in the findings somehow vague.\n- There is no ablation study in the paper. Constraint decoding is a well known technique for boosting models’ performance. However it is not known from the paper itself whether the improvement comes from constraint decoding or the other two techniques.\n- Although the paper is only a PoC on a very simple task, there are no clear way of applying the techniques described in this paper to actual problems since the techniques require modification of the user prompt to include type information, which is known to be very hard since type deduction is very difficult."}, "questions": {"value": "- How are the training dataset and the benchmark curated?\n- How is the model’s performance without the constraint decoding?\n- How unstable is the model’s training without the probing? Are there qualitative studies showing the probing’s effectiveness?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "WPeXntoX4K", "forum": "y6je0oiwEg", "replyto": "y6je0oiwEg", "signatures": ["ICLR.cc/2026/Conference/Submission24969/Reviewer_kBAL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24969/Reviewer_kBAL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24969/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761898840762, "cdate": 1761898840762, "tmdate": 1762943266225, "mdate": 1762943266225, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- This paper addresses the brittleness of Large Language Models (LLMs) on simple algorithmic and arithmetic tasks.\n\n- The method integrates ideas from programming languages (PL) to make even small models reliable on these tasks:\n* Inline Datatype Tagging: Making datatypes explicit in the prompt and code\n* Fine-tuning a GPT-2-small model with a main code-generation head and an auxiliary \"span probe\" head (used only during training) to help the model locate important tokens.\n* A constrained decoding process that enforces a finite-state grammar (DFA), validates the output's Abstract Syntax Tree (AST) shape, and includes a deterministic \"canonicalizer\" to repair outputs."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well written and clearly structured.\n\n- A major strength of the proposed method is achieving high reliability using a very small model (GPT-2-small)."}, "weaknesses": {"value": "- The primary weakness is the method's limited scope. The authors are transparent about this - \"We handle one line integer arithmetic and list operations\". The entire evaluation is based on just five simple skills: add, subtract, max, min, and sort.\n\n- The paper's main quantitative claim (0.58 to 0.82 accuracy) is based on a \"stratified held out suite of 60 GPT-40 prompts\". An evaluation set of N=60 is exceptionally small and insufficient to make robust claims, even within the paper's narrow scope. This small sample size makes it difficult to know if the results are statistically significant or generalizable."}, "questions": {"value": "- The test prompts were generated by GPT-4o. How robust is the method to diverse, real-world user phrasings that may be ambiguous (e.g., \"take 5 from 12\" vs. \"what is 12 minus 5\")?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7VkuQ1HXUU", "forum": "y6je0oiwEg", "replyto": "y6je0oiwEg", "signatures": ["ICLR.cc/2026/Conference/Submission24969/Reviewer_Mn4M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24969/Reviewer_Mn4M"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24969/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762225784066, "cdate": 1762225784066, "tmdate": 1762943265940, "mdate": 1762943265940, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a method of using inline type tagging and grammar-constrained decoding to improve code generation performance on small models for the proposed simple one-line Python tasks. They show that fine-tuning GPT-2-small with their method can achieve much better results."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Shows that typing and constraint decoding help even for small models like GPT-2-small"}, "weaknesses": {"value": "- The experiment is restricted to specific one-line Python settings which are not practical, and it is not clear how to make it work on more practical settings that involve non-regular languages\n- Lack of comparison to other simple baselines. For example, how does the model perform with more fine-tuning data? How large does the model need to be to solve this task? Can you try a more recent model like Qwen-3 1.7B instead of GPT-2?"}, "questions": {"value": "- Can you show some error analysis? What are some examples of problems that get solved by using the method? And what are some examples of problems that still cannot be solved?\n- At line 241, it says \"Datatype tags help\" and states some advantages of using it. Can you provide quantitative experimental results showing that datatype tags help in the performance?\n- At line 252: \"With grammar, AST, and the canonicalizer at inference, end accuracy is comparable or slightly higher, so the probe mainly aids stability and diagnostics rather than test time capacity.\" Can you provide concrete experimental setup and results to back this claim?\n- Does the method generalize to cover Python expressions or any real-world programming language expressions and not be restricted like the toy setting proposed here?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "hzX3gcgZ54", "forum": "y6je0oiwEg", "replyto": "y6je0oiwEg", "signatures": ["ICLR.cc/2026/Conference/Submission24969/Reviewer_bifH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24969/Reviewer_bifH"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24969/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762237355049, "cdate": 1762237355049, "tmdate": 1762943264352, "mdate": 1762943264352, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}