{"id": "ybmX4yvtGK", "number": 9651, "cdate": 1758132643159, "mdate": 1759897706383, "content": {"title": "QUANTIFYING KNOWLEDGE:A BAYESIAN FRAMEWORK FOR LLM-DRIVEN CLASSIFICATION", "abstract": "Integrating domain-specific knowledge into machine learning models is a critical challenge, especially in complex classification tasks where data features are ambiguous. This paper introduces a general framework, LLM-Enhanced Bayesian Model Combination (LLM-BMC), which leverages large language models (LLMs) to incorporate structured domain knowledge into a Bayesian model combination process, dynamically refining classification probabilities. We present a rigorous mathematical formulation of the λ parameter, which quantifies the influence of domain knowledge on model predictions, and validate its effectiveness through information gain analysis and convergence studies. Our framework systematically improves classification performance, particularly in scenarios with overlapping features or heterogeneous populations. As a demonstration case, we apply the framework to single-cell classification, where it excels in handling overlapping markers for different classes. This work provides a formal mathematical bridge between data-driven predictions and structured domain reasoning, establishing and empirically validating a principled methodology for knowledge-intensive classification.", "tldr": "", "keywords": ["Bayesian Model Combination Large Language Models Domain Knowledge Integration Classification Information Gain"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/12d2d15dbef25354d48bb65a853b9c75cc010fed.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces **LLM-Enhanced Bayesian Model Combination**, or LLM-BMC, a framework designed to integrate structured domain knowledge generated by large language models into probabilistic classification. Unlike black-box or point-estimate classifiers, the central premise is a Bayesian updating rule that iteratively tweaks an initial probability distribution, such as from an ensemble model, using a set of \"structured arguments\". The influence of these arguments is weighted by a quality function $q(A, c)$, where $A$ is the argument set and $c$ is the specific class of interest. A parameter $\\lambda$, the normalized information gain from the arguments, is introduced. An approximate theoretical relationship between this parameter and classification error reduction is derived. The framework is validated on a single-cell classification case study, where it appears to outperform baseline models and shows confirmatory evidence for the theoretical relationship between information gain and classification error."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors derive an approximate relationship $P_e^\\text{after} \\approx (1 - \\lambda) P_e^\\text{before}$ and then demonstrate, in Figure 2, a near-perfect linear correlation between the theoretical prediction and the observed error reduction. This seems like a strong result.\n\n2. The proposed formal mechanism for integrating structured arguments from LLMs into a probabilistic model appears novel, and is a nice mirror to chain of thought reasoning in the context of uncertainty quantification, which is an active and emerging area of research.\n\n3. The actual use of the LLM in the case study (detailed in the appendices) involves using a language model for text generation and structured data extraction, these data then being fed into a deterministic formula. This seems more robust than common designs in this area, where the LLM is simply asked to output a quality score directly.\n\n4. In the case study, the method appears to show a performance improvement over baselines on a nontrivial real-world task."}, "weaknesses": {"value": "1. The central weakness of the paper is its claim to be a \"general framework\". However, it goes off the rails relatively quickly with reference to and dependence on a highly specific application in transcriptomics. Only one implementation of the framework's quality function $q(A, c)$ is given—in the appendix—and it is quite complex, relying on external databases and a certain level of domain knowledge. In principle this might be OK if the paper offered guidance on how researchers in other domains could construct or adapt a similar quality function for their purposes, but it does not appear to do so, making the framework not so general or reproducible (outside this niche) after all.\n\n2. Experimental results in Section 3 are given only as single point estimates (esp. Tables 1 & 2, Figure 3) without quantification of uncertainty (i.e. the mean and standard deviation over multiple runs with different random seeds or calls to the nondeterministic LLM and other models with random initialization). This makes it impossible to determine if the reported improvements over baselines are statistically significant or their range of natural stochastic variation.\n\n3. The paper is densely written, illogically structured and difficult to follow. The titular \"LLM\" is not formally discussed until Section 2.7, after 5 pages of model-agnostic mathematical formalism, rather *burying the lede*. A reader should not have to wait this long to understand the central component of the paper.\n\n4. Conversely, the paper repeatedly and from an early stage (including in the abstract) refers to \"the $\\lambda$ parameter\", which is odd for two reasons:\n\n    - If it is indeed a novel contribution, then the meaning of this symbol is opaque to the reader before it has been formally introduced.\n\n    - According to Eq. 3, $\\lambda = I(C; A|X)/H(C|X)$ is simply the standard normalized information gain, meaning it is not a novel contribution after all and the repeated branding of \"the $\\lambda$ parameter\" risks coming across as self-aggrandizing.\n\n5. **Minor**: many $\\LaTeX{}$ macros are used incorrectly throughout the paper, including failure to include textual superscripts in `\\text{}` or `\\mbox{}` within Math mode (but not always, e.g. Figure 2 caption) and improper use of in-text rather than parenthetical citations. Abbreviations are introduced (e.g. \"LLMs\" in the abstract) and then not re-used. The text is at times verbose and repetitive, with many terms introduced symbolically and in prose at the same time, reintroduced multiple times, or involving excessive of adjectives, indicative of LLM-based text generation. Axis labels and titles in Figure 3 are too small and difficult to read, and the colour legend is not complete nor is it colourblind friendly"}, "questions": {"value": "1. How do the authors propose a practitioner in a different domain should construct a valid $q(A, c)$?\n2. Can the authors provide a justification for the specific form of the probability modifier $f(A, c)$ in Eq. 7?\n3. Why frame the normalized information gain as \"the $\\lambda$ parameter\"?\n4. Why is the role of LLMs introduced so late?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MepscOAfDR", "forum": "ybmX4yvtGK", "replyto": "ybmX4yvtGK", "signatures": ["ICLR.cc/2026/Conference/Submission9651/Reviewer_EZof"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9651/Reviewer_EZof"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9651/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761830961873, "cdate": 1761830961873, "tmdate": 1762921178374, "mdate": 1762921178374, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- This paper proposes the LLM-Enhanced Bayesian Model Combination (LLM-BMC), a general framework that integrates structured arguments or domain knowledge from large language models into a Bayesian model combination process for classification.  \n- The core components of LLM-BMC include: (1) a modified Bayesian update rule that incorporates structured arguments via a probability modifier function; (2) a parameter **λ** based on normalized information gain; (3) a quality function to evaluate structured arguments.\n- The case study of single-cell classification provides strong empirical validation of LLM-BMC, confirming its practical utility in resolving ambiguous classification cases."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- This paper offers a knowledge-augmented classification framework that systematically integrates structured domain knowledge from LLMs into a probabilistic classification process. The core is a modified Bayesian update rule that dynamically refines probabilities based on iteratively presented, quality-weighted arguments. The integration of LLM-based argumentation with Bayesian model combination is innovative. \n- This paper designs a quantifiable, multi-component quality function $q(A,c)$ that decomposes argument assessment into Specificity, Mechanistic Clarity, and External Evidence Support, replacing simple scoring.\n- The authors demonstrate the effectiveness of this framework on a single-cell classification task, showing performance gains. The high correlation between the reduction in prediction error and observation error validates the theoretical relationship."}, "weaknesses": {"value": "- The framework is presented without clarifying some key technical details, making the value of the work less convincing. For example, the paper does not detail how the LLM is used to generate the arguments. Nor does it introduce the details of argument analysis using the textual processing techniques. The appendix mentions that the framework uses a set of text processing techniques like NER, dependency parsing etc., whose details are simply omitted. The omission of these technical details makes the so-called \"LLM-driven classification\" approach quite unclear.\n- The proposed framework may need to be tested on a harder task, since the baseline results are already pretty competitive. \n- The framework assumes argument effects are conditionally independent given the class in Section 2.6. However, arguments generated by LLM may cite overlapping evidence or sources, violating this assumption. The paper acknowledges this but does not explore ways to mitigate it.\n- While the framework is general, demonstrating the quality function $q(A,c)$ requires extensive domain engineering (e.g., gene databases, pathway ontologies) and global parameters ($\\alpha$, $\\beta$, and quality weights) are required to be well-calibrated for the specific domain. This paper does not discuss how to apply it to broader domains (e.g., social sciences), which limits its generalizability.\n- Minor issues: In the introduction, the description of existing methods lacks citation support. In addition, in Section 2.3.2, the view that an approximately linear relationship between the Bayesian error rate and the conditional Shannon entropy is accurate in the fine-tuning stage of classification is lacking citation support."}, "questions": {"value": "- Could you reveal more details about the LLM-driven techniques? Do you generate code from LLM or directly generate the numerical results of the argument quality? How does LLM introduce errors in these processes? Why is the knowledge considered structured, but the example argument at line 756 shows a paragraph written in natural language?\n- How sensitive is the framework to correlated arguments? Could you provide an experiment where redundant or contradictory arguments are injected to test the robustness of the proposed approach?\n- The quality function relies heavily on carefully curated biological databases. How would you instantiate $ q(A,c) $ in other domains, for example legal document classification?\n- The values $\\alpha = 0.8, \\beta = 0.6$ are empirical values as introduced in the paper. Are these values robust across datasets? How are these hyperparameters learned?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3fWVoxeBso", "forum": "ybmX4yvtGK", "replyto": "ybmX4yvtGK", "signatures": ["ICLR.cc/2026/Conference/Submission9651/Reviewer_WeV8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9651/Reviewer_WeV8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9651/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761910704799, "cdate": 1761910704799, "tmdate": 1762921178008, "mdate": 1762921178008, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a framework, LLM-Enhanced Bayesian Model Combination (LLM-BMC), which incorporates domain knowledge via large language models into Bayesian model combination. In this context, a specific parameter is introduced to capture the relative information gain from integrating domain knowledge and a theoretical relationship between this parameter and the expected reduction in classification error is derived. Furthermore, a quality function is proposed to decompose the assessment of domain knowledge into quantifiable components. Finally, LLM-BMC is applied to the case of single-cell classification, where it is shown to handle overlapping markers for different classes."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "(+) A principled framework is introduced to incorporate domain knowledge via large language models into Bayesian model combination.\n(+) A theoretical result connecting the relative information gain from integrating domain knowledge and the expected reduction in classification error is derived.\n(+) A function is designed to decompose domain knowledge into quantifiable components.\n(+) The operation of the proposed framework is illustrated in the case of single-cell classification."}, "weaknesses": {"value": "(-) The main technical contribution of the paper is a modified Bayes' update rule.\n(-) It is unclear how LLMs are used to generate the arguments and/or how argument quality is evaluated in this context.\n(-) Determining the exact form of the components of the proposed quality function seems like a quite elaborate process, and there is no guidance how this can be accomplished for different applications.\n(-) In the experimental setup section, there is no discussion why certain values for the hyperparameters were selected. In addition, results are presented for the single-cell classification demonstration case, but are not discussed.\n(-) Sections like A.2.3 (Detailed calculation example) does not seem to add value, since it assumes some values for the different components of the quality metric but does not give any intuition about the different components and how they can be determined in another application."}, "questions": {"value": "1. The description of the framework starts with assuming a set of arguments. However, what is missing in the description is what such an argument looks like, how they are generated by LLMs, and whether these arguments are related to each other, e.g., the relationship between A^(t) and A^(t-1)?\n\n2. Is Eq. (8) proposed by the authors or a well-known established relationship? Irrespective of the answer to this question, what justifies that this decomposition is appropriate for quality assessment of an argument?\n\n3. It seems that s(), m() and e() in Eq. (8) depend on the application. Determining the form of the functions seems like quite an elaborate process. Can you provide guidance of how this can be accomplished in practice for any other application?\n\n4. For the experiments presented in Section 3, can you provide some more information about the PBMC dataset, the classification goal, and how arguments were generated and why (including how many arguments and what they looked like). A discussion of the results presented in Figure 3 and the choice of hyperparameter values are currently missing.\n\n5. Can you elaborate about the approximate linearity assumption? Specifically, when does this assumption hold in practice? In the case it does not hold for a specific application, what are the implications of integrating domain knowledge into Bayesian model combination.\n\n6. Looking at the Hellman-Raviv bound, it is unclear to me in which regimes, P_{e}^* <= \\frac{1}{2\\ln 2} H(C|Z), and how such information theoretic driven regimes are translated into application specifics. This seems to also relate to the approximate linearity assumption and the value of the parameter \\kappa that depends on problem specifics.\n\nNot a question, but a request: Please rethink the paper presentation. I had to go back and forth between the main text and appendices multiple times to understand the proposed framework and any key results."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "OnVQBkHfGN", "forum": "ybmX4yvtGK", "replyto": "ybmX4yvtGK", "signatures": ["ICLR.cc/2026/Conference/Submission9651/Reviewer_bx6u"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9651/Reviewer_bx6u"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9651/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761936224494, "cdate": 1761936224494, "tmdate": 1762921177763, "mdate": 1762921177763, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose an approach for iteratively correcting a predictive model's output $p(c|X)$ using LLM-generated predictions. In particular, given a predictive model that outputs $p(c|X)$, they propose to prompt an LLM to generate predictions $A$ (referred to as \"arguments\") along with a \"quality score\" $q(A,c)$ that measures how well $A$ is supported by assuming $c$ as the true class, and use these LLM outputs as \"likelihood\" terms to update $p(c|X)$. Theoretical justification for the work is provided by analyzing the connections between the information gain, conditional on LLM-based corrections, and prediction error, and the proposed method is validated on a single-cell dataset. In comparison to simple baselines, the proposed approach resulted in accuracy improvements on the cell-type classification task considered."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- The paper considers an important problem of incorporating domain knowledge into ML models using LLMs.\n- The writing is generally clear and easy to follow, albeit with some systematic issues on how the proposed approach is framed."}, "weaknesses": {"value": "- I believe that there are some systematic issues with how the proposed approach is being framed. The name \"Bayesian model combination (BMC)\" (which is also different from \"Bayesian model averaging (BMC)\") seems to be a misnomer; BMC refers to a specific setting where one is concerned with also learning the weights of different ensemble components via Bayes' rule [1], which this paper does not seem to be doing. In my understanding, this approach concerns updating the predictive distribution output by a model with LLM-generated predictions (as noted in my summary), and does not even require that the initial model that one starts with to be an ensemble model. I suppose one could argue that the fact that LLM-generated predictions are being combined with a data-driven model can be viewed as some kind of model combination, but I think this paper could benefit from clarifying how exactly this work extends prior works on BMC.\n- While not motivated in the same manner, there are certainly other prior works that attempt to incorporate LLM predictions or outputs into data-driven methods, including e.g., [2,3]. There are no comparisons to such methods in the experiments, and I think these works should also be compared to and be discussed in the Related Works section. Discussion of connections to other works can certainly be improved.\n- The proposed approach is limited to classification settings.\n- Experimental validation is only performed on a single dataset, using a small number of relatively simple baselines. It is also unclear whether the baselines underwent sufficient hyperparameter optimization. The results do not seem to account for statistical uncertainty resulting from randomness in e.g., model training, dataset splits, and prompting and no error bars are present. Moreover, to demonstrate the effectiveness of incorporating domain knowledge, I think harder datasets should also be considered (baselines like Logistic Regression and XGBoost already achieve relatively high accuracy).\n- While it may suffice as a proof of concept, the evaluation is only done using GPT-4o. For practical insights, additional experiments that show how sensitive this approach is to different families of LLMs and different prompting strategies should also be considered. Moreover, I would imagine that the best choice of weights used for defining the \"quality\" function in Equation (8) can noticeably vary across these settings. However, I do not see a clear discussion of how these weights have been and should be selected.\n\nReferences:\n[1] Turning Bayesian Model Averaging into Bayesian Model Combination (Monteith et al., 2011)\n[2] LLM-Select: Feature Selection with Large Language Models (Jeong et al., 2024)\n[3] LLM-Lasso: A Robust Framework for Domain-Informed Feature Selection and Regularization (Zhang et al., 2025)"}, "questions": {"value": "- It is not obvious to me why the proposed approach is frequently discussed with an ensemble model as the starting point. In my understanding, the proposed approach can still be applied to non-ensemble models. Can the authors elaborate on this?\n- How are the weights for the quality function ($\\alpha$, $\\beta$, $w_s$, $w_m$, and $w_e$) determined in Section 3.1? Were these selected based on the validation set somehow? Can the authors clarify this process?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "w36YX6GbYn", "forum": "ybmX4yvtGK", "replyto": "ybmX4yvtGK", "signatures": ["ICLR.cc/2026/Conference/Submission9651/Reviewer_si5D"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9651/Reviewer_si5D"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9651/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762118841634, "cdate": 1762118841634, "tmdate": 1762921177387, "mdate": 1762921177387, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}