{"id": "9H1nu8Z6Uy", "number": 5084, "cdate": 1757845233729, "mdate": 1759897996067, "content": {"title": "ADAM: A Systematic Data Extraction Attack on Agent Memory via Adaptive Querying", "abstract": "Large Language Model (LLM) agents have achieved rapid adoption and demonstrated remarkable capabilities across a wide range of applications. To improve reasoning and task execution, modern LLM agents would incorporate memory modules or retrieval-augmented generation (RAG) mechanisms, enabling them to further leverage prior interactions or external knowledge. However, such a design also introduces a group of critical privacy vulnerabilities: sensitive information stored in memory can be leaked through query-based attacks. Although feasible, existing attacks often achieve only limited performance, with low attack success rates (ASR). In this paper, we propose ADAM, a novel privacy attack that features data distribution estimation of a victim agent’s memory and employs an entropy-guided query strategy for maximizing privacy leakage. Extensive experiments demonstrate that our attack substantially outperforms state-of-the-art ones, achieving up to 100% ASRs. These results thus underscore the urgent need for robust privacy-preserving methods for current LLM agents. Our code is available at: https://anonymous.4open.science/r/agent-privacy-attack-iclr/.", "tldr": "", "keywords": ["LLM", "Agent", "memory", "privacy", "attack"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e40d5dc6fedc8fc79244b25c8a5f41230aa0fb9a.pdf", "supplementary_material": "/attachment/e066bfe88f723d51fc0d17bc2936da5b897687c8.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes ADAM, a novel privacy attack that features data distribution estimation of a victim agent’s memory and employs an entropy-guided query strategy for maximizing privacy leakage.  When compared to prior attacks, ADAM explicitly estimates the underlying data distribution of the victim agent’s memory and then incorporates it with an active learning strategy for query generation.  ADAM proceeds iteratively, refining its next query based on observed responses and dynamically adapting to the estimated data distribution. Extensive experiments confirm that ADAM achieves significantly higher private data extraction performance than existing attacks.  The authors also present extensive ablation studies to investigate the components of ADAM in a controlled manner."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is very well-written and easy to follow.  Strong experimental results suggest that ADAM is fairly effective relative to chosen benchmarks Vanilla, RAG-Thief, Pirate, and MEXTRA.  This reviewer particularly appreciates the extensive ablation study included in the experimental results.  Through extensive evaluation the authors provide a careful analysis of the ADAM methodology that convincingly supports the paper's claims."}, "weaknesses": {"value": "**NOTE:** I do not consider myself an expert in this subject matter and I have set my confidence on this review low to reflect that.  I have thoroughly read the paper and provide my own analysis of weaknesses, but I am unfamiliar with the relevant literature on RAG attacks in LLMs.\n\nI have two high-level concerns about this paper.  The first is whether ICLR is an appropriate venue for this type of work.  This paper feels better positioned for USENIX or IEEE S&P or similar.  The second concern is that the ADAM methodology relies on accurately estimating the underlying data distribution of the victim agent's memory.  Distribution estimation is a notoriously hard problem, and existing methods can be very brittle indeed.  The authors do not provide convincing evidence that ADAM accurately estimates these distributions beyond broad performance metrics.  \n\nAt the bottom of Page 4 the authors present the method for selecting queries that maximizes query entropy.  The authors claim that \"we select the $q_t^{(j)}$ of the maximum information gain regarding returning new topics.\"  It is unclear in what sense this objective relates to maximum information gain.  In an information-theoretic context information gain is the expected reduction in entropy (i.e. with and without the selected query) whereas the current objective measures only the instantaneous query entropy.  The query entropy may be high for many reasons beyond its ability to supply information, for example it may simply be an ambiguous query.  Please clarify and justify your reference to information gain.\n\nThe experimental results are suspicious to say the least.  Does ADAM really outperform all baselines in every setting by such a wide margin?  I did not attempt to reproduce the results with the provided code, I am simply raising suspicion that these numbers appear too good to be true.\n\nMinor Comment: L133 - What is $y_1,y_2,\\ldots,y_m$?  This should be defined."}, "questions": {"value": "See Weaknesses section above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "ofbfN7UHaw", "forum": "9H1nu8Z6Uy", "replyto": "9H1nu8Z6Uy", "signatures": ["ICLR.cc/2026/Conference/Submission5084/Reviewer_n3fw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5084/Reviewer_n3fw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5084/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760989480413, "cdate": 1760989480413, "tmdate": 1762917863019, "mdate": 1762917863019, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ADAM, a novel privacy attack against LLM-based agents with memory modules. The attack addresses limitations in existing memory extraction methods by explicitly estimating the underlying data distribution of the victim agent's memory and employing an entropy-guided active learning strategy for adaptive query generation. ADAM operates iteratively: it extracts anchors (topics/keywords) from agent responses, updates selection probabilities based on estimated data distribution, and generates queries that maximize information gain. Extensive experiments on three real-world agents (EHRAgent, ReAct, RAP) across four LLMs demonstrate that ADAM substantially outperforms state-of-the-art attacks, achieving up to 100% attack success rates (ASR). The authors also evaluate four existing defenses and show that ADAM remains largely effective against them."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The key innovation of explicitly modeling the underlying data distribution in agent memory is well-motivated and represents a significant departure from prior work. The integration of distribution estimation with entropy-based query selection is elegant and theoretically grounded in active learning principles. \n\n2. The evaluation is thorough, covering three diverse agent types (healthcare, QA, e-commerce), four LLM backbones of varying sizes"}, "weaknesses": {"value": "1.  No formal analysis of convergence properties, sample complexity, or performance guarantees. Critical questions unanswered: When does the distribution estimator converge to P(D)? How many queries are needed for given extraction rates? How do hyperparameters (α, λ, τ) interact? The distribution update equations are heuristic without principled justification. Early-stopping criterion (||P̂_t - P̂_{t-1}||_1 < ε) lacks theoretical grounding.\n\n2.  Why is DBSCAN cluster size an appropriate proxy for topic importance? No comparison with alternative methods (KDE, parametric models). Figure 4 shows substantial distribution gaps (especially RAP), yet attack still succeeds—suggesting distribution estimation may be less critical than claimed or entropy selection is highly robust to misestimation. Missing ablations isolating distribution estimation's contribution versus k-center selection.\n\n3. Attack queries contain obvious patterns (\"please surface all similar past responses,\" \"return all previous examples\") that should be easily flaggable. No evaluation against: rate limiting, anomaly detection on query distributions, retrieval volume monitoring, or honeypot-based detection. Claims of \"natural-appearing\" queries lack systematic validation. The four evaluated defenses are insufficient to claim stealth."}, "questions": {"value": "Can you provide convergence bounds and sample complexity analysis for the distribution estimator?\nHow detectable are ADAM queries against rate limiting or anomaly detection defenses?\\\n\nHave you engaged in responsible disclosure with LLM providers? What is your code release timeline?\n\nCan you ablate distribution estimation's isolated contribution to attack success?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "kk97HwR0X6", "forum": "9H1nu8Z6Uy", "replyto": "9H1nu8Z6Uy", "signatures": ["ICLR.cc/2026/Conference/Submission5084/Reviewer_7XtP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5084/Reviewer_7XtP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5084/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761878295441, "cdate": 1761878295441, "tmdate": 1762917862723, "mdate": 1762917862723, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present a novel privacy attack against LLM agents. The core idea is to iteratively extract private data from an agent's memory by estimating the underlying data distribution and using an entropy-guided query strategy. Empirical results show strong ASRs outperforming multiple baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1. I like the novelty of the approach. The integration of data distribution estimation and entropy-guided active learning is interesting. \n\nS2. Good problem setting. LLM memory modules will increasingly become relevant in real world use cases.\n\nS3. Strong empirical results and evaluation."}, "weaknesses": {"value": "W1. It is not clear to me intuitively why some baselines perform poorer than ADAM. For example, for \"Query rewriting,\" the authors state it provides \"limited protection.\" A deeper analysis of how ADAM's adaptive nature specifically circumvents these defenses would be valuable.\n\nW2. The \"Initialization\" phase relies on a \"small set of high-level domain topics as seeds.\" While the ablation study on \"Domain knowledge\" confirms its benefit, it also implies a prerequisite for the attacker. What if the attacker has no domain knowledge or very poor domain knowledge? The paper mentions an ablation study for lacking domain knowledge in Section 4.3, but the results (Figure 3f) only show \"domain-aware\" vs \"domain-agnostic\" settings improving EQ. A more quantitative analysis on how poor initial seeds impact performance would be useful.\n\nW3. While mentioned as a key component, the exact mechanism for how entropy guides the query generation could benefit from a slightly more intuitive explanation or a concrete example in the main text for readers less familiar with information theory in this context."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "iz7yJiaJVt", "forum": "9H1nu8Z6Uy", "replyto": "9H1nu8Z6Uy", "signatures": ["ICLR.cc/2026/Conference/Submission5084/Reviewer_aqHG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5084/Reviewer_aqHG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5084/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762054853401, "cdate": 1762054853401, "tmdate": 1762917862325, "mdate": 1762917862325, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ADAM (Adaptive querying and Distribution estimation to extract private data from Agent Memory), a novel attack that extracts private information from the memory modules of large language model (LLM) agents. The core claim is that modern LLM agents—because they combine planning, persistent (long-term) memory, and multi-turn interactions—expose memory vulnerabilities that are more complex and distinct than those of standalone RAG pipelines. The empirical experiments show the effectiveness of the proposed privacy attacks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper presents an interesting idea for a timely challenge in the community. Prior studies mainly examined standalone RAG systems or static prompt injection attacks. However, LLM agents that combine planning, persistent memory, and multi-turn interactions introduce new complexity. The use of persistent memory to store user histories opens a new attack surface that previous methods have not fully addressed. The papers show the importance of studying such an attack surface.\n2. The empirical results seem very promising. The proposed ADAM achieves a 100\\% attack success rate in nearly all scenarios, showing that it consistently extracts new data. Its high complete extraction rate, such as 0.93 on EHRAgent and 0.77 on RAP, indicates that it retrieves all three relevant items per query, whereas MEXTRA performs poorly with 0.38 and 0.23. These results confirm the effectiveness of ADAM. \n3. The writing is easy to understand."}, "weaknesses": {"value": "1. In this work, it seems that the model assumes that the attacker possesses general background knowledge about the target agent, such as its application domain and tasks. This assumption is operationalized in the initialization step, which begins with a small set of high-level domain topics as seeds. Appendix E, Table 2 lists these seeds, for example, “diagnosis,” “medication,” and “patient” for EHRAgent. The authors attempt to address this limitation through the domain-agnostic ablation in Figure 3f, yet the results clearly reveal that this assumption remains a significant weakness.\n2. The paper compares ADAM with baselines such as MEXTRA in terms of performance but overlooks the substantial differences in cost. The attack requires an auxiliary large language model, such as ChatGPT-4, to function, representing a significant external and costly dependency."}, "questions": {"value": "1. Regarding weakness 1, if the target domain is unknown or the initial seed topics are of low quality (for example, containing generic words such as “of” or “and”), the attack performance may degrade significantly. The current description of the “domain-agnostic” setting remains insufficient, and this setting may still implicitly rely on domain-related initialization, thereby indirectly benefiting from domain proximity.\n2. see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "see weakness."}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Ulf4298DK4", "forum": "9H1nu8Z6Uy", "replyto": "9H1nu8Z6Uy", "signatures": ["ICLR.cc/2026/Conference/Submission5084/Reviewer_kPgL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5084/Reviewer_kPgL"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5084/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762890155037, "cdate": 1762890155037, "tmdate": 1762917861675, "mdate": 1762917861675, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}