{"id": "KgYsCrPMJU", "number": 20902, "cdate": 1758311546695, "mdate": 1759896953022, "content": {"title": "Stateful Multi-Agent Evolutionary Search for Unit Test Generation", "abstract": "Recent work explores agentic inference-time techniques to perform structured, multi-step reasoning. However, stateless inference often struggles on multi-step tasks due to the absence of persistent state. Moreover, task-specific fine-tuning or instruction-tuning often achieve surface-level code generation but remain brittle on tasks requiring deeper reasoning and long-horizon dependencies. To address these limitations, we propose **stateful multi-agent evolutionary search**, a training-free framework that departs from prior stateless approaches by combining (i) persistent inference-time state, (ii) adversarial mutation, and (iii) evolutionary preservation. We demonstrate its efffectiveness in automated unit test generation through the generation of edge cases. We generate robust edge cases using an evolutionary search process, where specialized agents sequentially propose, mutate, and score candidates. A controller maintains persistent state across generations, while evolutionary preservation ensures diversity and exploration across all possible cases. This yields a generalist agent capable of discovering robust, high-coverage edge cases across unseen codebases. Experiments show our stateful multi-agent inference framework achieves substantial gains in coverage over stateless single-step baselines, evaluated on prevalent unit-testing benchmarks such as HumanEval and TestGenEvalMini and using three diverse LLM families - Llama, Gemma, and GPT. These results indicate that combining persistent inference-time state with evolutionary search materially improves unit-test generation.", "tldr": "", "keywords": ["Inference-time compute", "evolutionary search", "multi-agent systems", "non-Markovian state", "unit test generation", "code agent", "code generation"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6053d9cc63f4b9691191922848973804ca839247.pdf", "supplementary_material": "/attachment/8b7c365896b334dbc39305ad3113b1f12411a36b.pdf"}, "replies": [{"content": {"summary": {"value": "This paper introduces a stateful multi-agent evolutionary search approach for unit test generation. A controller maintains a state that contains edge cases, mutations, coverage information, exception information and reward history. There are 4 agents involved for each inference round (Actor, Adversary, Critic, Executor). The Actor introduces new edge cases for improving the coverage for the Executor; the Adversary mutates the test to test the robustness; the Critic computes the reward and gives information to the Controller for the next round. The authors conduct experiments on 2 datasets (HumanEval, TestGenEvalMini) and show the improvement against multi-shot and CoT prompting. The main contribution of this paper is providing a new rewarding algorithm to unit tests and injecting them into the inference prompt to gradually improve the quality of unit tests."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Introduces an explicit state representation and controller for reasoning across inference rounds.\n\nDivide unit test generation into 2 stages: generate edge cases first, then synthetic unit tests in the final run based on existing edge cases.\n\nAn empirical evaluation on the methods that shows a moderate improvement compared to 2 general prompting strategies."}, "weaknesses": {"value": "Missing ablation study for the formal state $S$. It’s uncertain how the 5 variables in $S$ individually contribute to the performance. It is questionable whether the LLM can actually interpret all of these variables, or if comparable results could be achieved using only a subset of the feedback signals.\n\nThe controller feedback is underspecified. Although the paper defines $S_n$ is the aggregation of prior variables from iterations $1$ to $n-1$. But it’s unclear how this information is serialized or fed back into the Actor prompt. Also, Several formal elements (like exception signal) are not concretely described or exemplified. It’s hard for readers to fully understand the design.\n\nThe baseline comparison is weak. The paper evaluates only against simple prompting strategies (few shots with or without CoT), without comparing with recent LLM-based unit-test generation frameworks. It is unsurprising that a task-specific, curated pipeline outperforms naive prompting. Demonstrating advantages over stronger, existing baselines would be more convincing.\n\nThe evaluations are not in depth enough. The reported improvements are moderate, and there is no failure or error analysis to reveal where the proposed method can have more chance to succeed or fail. A comprehensive failure analysis should be included to provide insight to people to further research on it."}, "questions": {"value": "What is the precise format of {feedback_summary} passed to the Actor? Please provide a concrete template and one real example from your runs.\n\nWhat is the value of $K$ (the top-K value at line 291) in your experiments? Does choosing different numbers for $K$ affect the overall performance?\n\nIt’s uncertain why Llama-70B performs better than other models. Could you clarify why Llama benefits more from the proposed approach? Is there any quantitative evidence for your explanation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NPlI9lcnHu", "forum": "KgYsCrPMJU", "replyto": "KgYsCrPMJU", "signatures": ["ICLR.cc/2026/Conference/Submission20902/Reviewer_WrSr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20902/Reviewer_WrSr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20902/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761547950947, "cdate": 1761547950947, "tmdate": 1762999999059, "mdate": 1762999999059, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a \"stateful\" multi-agent workflow for LLM-based unit-test generation.\nThe workflow includes an actor to generate candidate edge cases, an adversary to generate code mutants, a critic to compute rewards, an executor, and a controller to maintain the running environment and states.\nThe system is evaluated on HumanEval and a small multi-repo benchmark (TestGenEvalMini). The results are mixed."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Effort on an important, timely task.\nThe unit test generation is an important problem. The paper targets LLM-assisted unit test generation with measurable signals (coverage, mutation, exceptions). This is a promising path.\n\n- Reproducible engineering and transparent execution pipeline.\nEvaluations run in a sandboxed Docker/MCP setup with clear tool orchestration, which aids replication and future extensions."}, "weaknesses": {"value": "The paper claims to \"unify (i) multi-agent reasoning, (ii) adversarial mutation and reward shaping, and (iii) evolutionary preservation with persistent state.\" \nHowever, prior multi-agent systems already maintain explicit memory/state across steps [1, 2], which makes the proposed \"persistent state\" look conceptually close to existing agent memory rather than a substantive advance.\nThe paper's \"state\" is passed to the Actor but is not shown to confer superiority over established memory-equipped agents.\n\nOn HumanEval, the method is merely comparable to six inference-time baselines, offering little evidence of advantage.\nOn TestGenEvalMini, Figure 2 shows that with GPT-o4-mini and Gemma-2-27B, the proposed system (SUT) is worse on branch coverage than baselines.\nFor efficiency, there is no apples-to-apples cost comparison vs. baselines.\nGiven Figure 3 shows that many tasks need multiple iterations, while baselines are single-shot, few-shot prompts, one of the concerns is efficiency.\n\n\nThe only dataset where advantages are emphasized is TestGenEvalMini, which is small and raises concerns about its representativeness (48 tasks, 6 repos). The argument that Mini is representative relies on structural metrics in Table 1 that do not capture semantic difficulty or behavioral diversity, so the generality of the conclusions is uncertain.\n\n\nThe authors claimed an \"Adversarial mutation\". \nHowever, it is implemented via Cosmic-Ray, i.e., a fixed-operator mutation-testing toolchain rather than a learned/adaptive adversary, with fixed mutators and configuration, and mutants are effectively state-independent, without interaction with the Actor and the state. \nThis makes a questionable \"Adversarial mutation\" claim, and makes this work more like a follower of the original actor–critic-style search, but not AGAC as the authors claimed.\n\n\nThe method has several moving parts, yet no ablation studies are reported to isolate where gains (if any) come from or how sensitive results are to hyperparameters, mutation budget, or archive size.\n\nThe baseline design appears incomplete. Although the paper emphasizes stateful multi-agent methods, it does not include comparisons with non-stateful multi-agent approaches, which readers would naturally expect. Furthermore, while the introduction discusses a range of prior agent-based work and highlights their limitations, none of these agent approaches are incorporated into the baseline for empirical comparison.\n\n---\n\n1. Wang, Junyang, et al. \"Mobile-agent-v2: Mobile device operation assistant with effective navigation via multi-agent collaboration.\" Advances in Neural Information Processing Systems 37 (2024): 2686-2710.\n2. Hong, Sirui, et al. \"MetaGPT: Meta programming for a multi-agent collaborative framework.\" The Twelfth International Conference on Learning Representations. 2023."}, "questions": {"value": "Table 3 does not seem to be mentioned in the paper's content. Why are the numbers different from Figure 2? Like Llama-70B/SUT/Branch is 76 in Figure 2, but 16.55% in Table 3?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DexYdRmplS", "forum": "KgYsCrPMJU", "replyto": "KgYsCrPMJU", "signatures": ["ICLR.cc/2026/Conference/Submission20902/Reviewer_uL2C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20902/Reviewer_uL2C"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20902/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761578841910, "cdate": 1761578841910, "tmdate": 1762999998568, "mdate": 1762999998568, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a stateful multi-agent evolutionary search framework to enhance automated unit test generation with LLMs. Unlike prior stateless inference or task-specific fine-tuning approaches that struggle with long-horizon reasoning and diverse case discovery, the proposed method integrates persistent inference-time state, adversarial mutation, and evolutionary preservation in a training-free setting. Specialized agents iteratively propose, mutate, and evaluate test cases, while a controller maintains state across generations to guide the search toward robustness and diversity. Experiments on HumanEval and TestGenEvalMini demonstrate gains in test coverage."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is easy to understand.\n\nThe paper works on test generation, an important problem and a key technique to facilitate automatic code generation. The results are demonstrated to outperform baselines in terms of code coverage."}, "weaknesses": {"value": "The evaluation focuses only on coverage; no results on bug detection capability or code generation improvement results are reported. Coverage reflects only the quality of test inputs, not test oracles. It is recommended that the authors report the results on bug detection rate using the generated tests, either on mutants or on LLM-generated faulty versions. \n\nThe novelty of the framework is unclear. The approach seems to be a multi-agent framework, which has been explored before in code generation. More discussion is needed regarding the difference between this framework and previous multi-agent frameworks in coding tasks.\n\nThe cost of the approach is not reported. While the paper acknowledges the high cost, it is recommended that the cost to be calculated, reported, and compared in the evaluation."}, "questions": {"value": "What is the cost of the approach?\n\nWhat is the bug detection rate of the generated tests?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PCJBl4puSs", "forum": "KgYsCrPMJU", "replyto": "KgYsCrPMJU", "signatures": ["ICLR.cc/2026/Conference/Submission20902/Reviewer_Vxm7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20902/Reviewer_Vxm7"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20902/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761928196212, "cdate": 1761928196212, "tmdate": 1762999999060, "mdate": 1762999999060, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a test-time multi-agent framework that searches and identifies edge cases for unit test generation. They claim they are the first paper that uses the current state of the agent to produce edge cases. They provide results showing the improvement of their SUT method over baseline methods on HumanEval and TestGenEvalMini."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The proposed is novel and tackles the important issue of finding edge cases for code generation\n\nThey provide their own version of HumanEval and TestGenEvalMini with edge-case traces"}, "weaknesses": {"value": "I have quite a few issues with the writing:\n\n-Figure 1 has too small of text to easily read, hurting clarity and presentation\n\n-Definition 1 of state is unclear. Specifically what are mutation scores, coverage scores, and exception signals. They have not been defined yet, so putting them in the tuple to represent the state creates confusion for the reader\n\n-The line spacing between the Related Work heading is too large, taking up significant page space\n\n-Algorithm 1 can be reformatted to save space. In some cases there are empty lines (L294) and some lines can be combined (296 & 297)\n\n-L251-266 describing TestGenEvalMini can  be compressed and most details can be moved to Appendix.\n\n-SUT acronym is not mentioned until L355 and it was unclear that system-under test was the proposed approach until the caption of Figure 2. This should be mentioned in the methodology section."}, "questions": {"value": "Question:\n\nIs there any work that uses the term “persistent state”? I have never seen than term used. From reading the paper, it seems equivalent to “current state”\n\nSuggestions:\n\nMove Figure 3 so it’s not in the middle of the conclusion section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "R3jhDEdOsc", "forum": "KgYsCrPMJU", "replyto": "KgYsCrPMJU", "signatures": ["ICLR.cc/2026/Conference/Submission20902/Reviewer_JAVq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20902/Reviewer_JAVq"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20902/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995789414, "cdate": 1761995789414, "tmdate": 1762983747573, "mdate": 1762983747573, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a test-time multi-agent framework that searches and identifies edge cases for unit test generation. They claim they are the first paper that uses the current state of the agent to produce edge cases. They provide results showing the improvement of their SUT method over baseline methods on HumanEval and TestGenEvalMini."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The proposed is novel and tackles the important issue of finding edge cases for code generation\n\nThey provide their own version of HumanEval and TestGenEvalMini with edge-case traces"}, "weaknesses": {"value": "I have quite a few issues with the writing:\n\n-Figure 1 has too small of text to easily read, hurting clarity and presentation\n\n-Definition 1 of state is unclear. Specifically what are mutation scores, coverage scores, and exception signals. They have not been defined yet, so putting them in the tuple to represent the state creates confusion for the reader\n\n-The line spacing between the Related Work heading is too large, taking up significant page space\n\n-Algorithm 1 can be reformatted to save space. In some cases there are empty lines (L294) and some lines can be combined (296 & 297)\n\n\n-L251-266 describing TestGenEvalMini can  be compressed and most details can be moved to Appendix.\n\n-SUT acronym is not mentioned until L355 and it was unclear that system-under test was the proposed approach until the caption of Figure 2. This should be mentioned in the methodology section.\n\nUPDATE: Sorry, I realized a portion of my review was not entered during initial submission. To provide more feedback to authors and to justify my score:\n-Figure 2 states that the SUT method achieves strong coverage, outperforming baselines such as COT but other for Gemma and GPT-4o show a different story branch, and the discussion in L420 is too vague or general. A stronger error analysis would provide a more satisfying explanation\n-Table 2 and 3 show barely improvement over baselines, usually less than < 2 %"}, "questions": {"value": "Question:\n\nIs there any work that uses the term “persistent state”? I have never seen than term used. From reading the paper, it seems equivalent to “current state”\n\nSuggestions:\n\nMove Figure 3 so it’s not in the middle of the conclusion section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "R3jhDEdOsc", "forum": "KgYsCrPMJU", "replyto": "KgYsCrPMJU", "signatures": ["ICLR.cc/2026/Conference/Submission20902/Reviewer_JAVq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20902/Reviewer_JAVq"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20902/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995789414, "cdate": 1761995789414, "tmdate": 1763048873735, "mdate": 1763048873735, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}