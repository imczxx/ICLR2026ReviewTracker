{"id": "BPNK5HDEMh", "number": 23705, "cdate": 1758347389854, "mdate": 1759896800732, "content": {"title": "Prot2RNA: A Diffusion Language Model for Protein-Conditioned mRNA Coding Sequence Generation", "abstract": "The redundancy of the genetic code, where multiple codons encode the same amino acid, creates a vast design space for messenger RNA (mRNA) sequences. Synonymous codon choices significantly affect mRNA stability, structure, translation efficiency, and immunogenicity, all critical for mRNA therapeutics and synthetic biology. We present Prot2RNA, a diffusion language model that generates mRNA coding sequences conditioned on a target protein. Prot2RNA uses a two-stage training approach: the model is pretrained using masked diffusion modeling over separate sets of human protein and mRNA coding sequences, learning representations for both biological modalities in a shared space. Subsequently, the model is finetuned to generate codon sequences using target protein sequences as prompts.\nProt2RNA was trained on human data and evaluated on a held-out set of highly expressed mRNA transcripts that are sequentially different from the training set. The results demonstrate that our diffusion-based codon optimization model outperforms existing methods in codon-level accuracy, alignment with biologically meaningful properties, and its ability to generate sequence profiles that closely mirror codon usage patterns in highly expressed wild-type human mRNAs. Unlike other deep learning models that primarily learn codon usage frequency, Prot2RNA implicitly learns biologically relevant codon preferences, providing a strong foundation for protein-aware mRNA design.", "tldr": "Prot2RNA is a diffusion language model that generates protein-conditioned mRNA coding sequences and learns codon preferences and other biological features of highly expressed transcripts.", "keywords": ["mRNA design", "Codon optimization", "Diffusion language model"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fa0086f601b1e8d419829e2f87aea158d98aaaf7.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Here, the authors introduce Prot2RNA, a diffusion model that generates mRNA coding sequences conditioned on protein sequences. The model addresses the redundancy of the genetic code by learning how synonymous codon choices affect stability, translation, and expression, rather than relying on frequency-based optimization. Prot2RNA is trained in two stages. First, it undergoes masked diffusion pretraining on separate sets of protein and mRNA sequences to learn shared representations across modalities. Second, it is finetuned on paired protein–mRNA data, using the protein as a prompt while iteratively denoising masked RNA tokens to generate complete coding sequences. The finetuned variant (Prot2RNA-FT2) achieves the highest codon-level accuracy (0.616) among tested baselines, including CodonBERT, CodonTransformer, LinearDesign, and Trias. Generated sequences maintain GC content near 56% and CAI around 0.8, closely matching wild-type human transcripts, while avoiding over-optimization toward GC-rich codons. The authors also propose a Fréchet distance metric to measure the similarity between generated and real coding sequences. Prot2RNA yields the lowest divergence from natural mRNAs and best preserves local codon usage patterns, as shown through MinMax profile analyses.\n\nOverall, Prot2RNA captures both global and local codon preferences relevant to expression efficiency, outperforming previous deep learning and heuristic codon optimization methods. The paper concludes that while the model does not yet integrate untranslated regions or RNA structural dynamics, it establishes a strong foundation for protein-aware mRNA design and future biologically integrated generative modeling."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "-The paper provides an exceptionally clear and well-elaborated introduction, setting up the biological and computational context in a way that feels both rigorous and accessible.\n\n-I find that the ablation studies are thorough and thoughtfully designed, giving real insight into how model choices and training strategies affect biological realism and performance.\n\n-The authors have made the code, datasets, and model weights openly available, which is commendable and greatly helps to reproduce the work."}, "weaknesses": {"value": "-The evaluation metrics focus primarily on codon-level accuracy and compositional similarity, which really does not directly translate to improved biological expression or experimental performance.\n\n-The authors give limited attention to other determinants of mRNA expression, like untranslated regions, RNA secondary structure, or ribosome dynamics, which could further validate the model’s biological relevance.\n\n-While the application is strong, the computational innovation is very incremental, as the diffusion framework largely builds on existing masked diffusion formulations without major theoretical extensions. \n\n-The discussion of potential overfitting to synonymous codon patterns could be expanded, particularly to clarify how the model avoids simply memorizing human codon bias rather than learning transferable principles of expression.\n\nAlthough Prot2RNA achieves relatively good results on computational benchmarks, it lacks experimental validation for the generated mRNA, which is my main concern. It also lacks other *in silico* biological validations including half-life, ribosomal load, etc. to better demonstrate the effectiveness of such method. The contribution would better be suited for journal with further experiments included instead of as a conference main track paper. I encourage the authors to perform experimental, wet-lab validation before submitting this work.\n\nThe authors also miss key citations:\n- **Cosine mask rate scheduling:** FusOn-pLM (Vincoff, 2025);\n- **Protein-conditioned mRNA design:** mRNAutils (Patel, 2025);\n- **Other discrete Diffusion models:** MDLM (Sahoo, 2024)"}, "questions": {"value": "- Line 158 \"high quality CDS\", please add hyperlink to appendix so the definition is easier to follow\n\n- Line 214, for pretraining the random chopping is harmless. During finetuning, if random cropping were applied inconsistently between the two modalities, could it break alignment between codons and amino acids? The authors need to justify this.\n\n- The training setup predicts the original RNA sequence given the protein, but it’s unclear how this mechanism directly models synonymous codon substitution or optimization. Since the RNA tokens are reconstructed deterministically, the model effectively memorizes codon frequencies conditioned on amino acids rather than learning a transformation or preference over synonymous variants. If synonymous codon usage is a central goal, an analysis over synonymous sets would strengthen the claim.\n\n- The multimodal alignment seems to rely solely on concatenation with shared positional encodings. Have the authors considered alternative fusion strategies, such as joint embedding projection or cross-attention between modalities, instead of simple concatenation?\n\n- How easy it is to train protein vs mRNA -- do they converge as quickly?\n\n- Line 246, the authors do not provide a clear justification for why one-step denoising suffices, nor do they compare against multi-step or continuous-time diffusion formulations that might improve sample diversity or fidelity.\n\n- The hypothesis proposed in **Result 4.1** about codon preservation and expression level can only be validated through experiment. Naming it as \"accuracy\" is misleading as the metric appears to measure token-level overlap between generated and reference codons, which primarily reflects reconstruction fidelity rather than true biological quality. Furthermore, the notion of “similarity” is not rigorously defined. It remains unclear whether the model produces novel codon variants or merely regenerates sequences from the training distribution. An analysis of sequence novelty would be required to substantiate this claim.\n\n- The statement in **Result 4.2** *\"reflecting natural codon usage where high expression is not driven solely by codon bias, but a range of other factors, as previously shown\"* contradict the hypothesis proposed in **Result 4.1** that capturing codon preservation does predict expression.\n\n- For **Result 4.3** the proposed benchmark metrics is problemetic as the [CLS] tokens from different models reside in distinct latent spaces with incompatible scales and semantics. The authors should either project all sequences into a shared encoder space or clarify how inter-model embedding distances can be meaningfully interpreted.\n\n- For **Result 4.4**, $\\mathrm{MINMAX}$ measures the difference in codon frequency distributions relative to highly expressed transcripts, not true codon optimization or functional adaptation. Lower distances could reflect memorization of training statistics rather than meaningful synonymous substitutions, raising concerns that the metric conflates similarity with optimization. Clarifying whether this measure capture genuine adaptation or mere distribution alignment and overfit would strengthen the claims."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "BA1pUiivMS", "forum": "BPNK5HDEMh", "replyto": "BPNK5HDEMh", "signatures": ["ICLR.cc/2026/Conference/Submission23705/Reviewer_aGVJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23705/Reviewer_aGVJ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23705/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761488940807, "cdate": 1761488940807, "tmdate": 1762942775929, "mdate": 1762942775929, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Prot2RNA, a diffusion-based transformer model that given a protein sequence, it generates mRNA coding sequences. The model is trained in two stages- firstly, a masked diffusion pre-training on protein and mRNA sequences separately followed by fine-tuning on paired protein-mRNA data with high expressing pairs. In-silico experiments are conducted to compare Prot2RNA with other baselines to evaluate its benefits. The authors claim and demonstrate that Prot2RNA generates biologically realistic coding sequences that align well with respect to metrics such as codon adaptation index (CAI) and GC content."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The codon optimization problem being studied in the paper is relevant for the bioinformatics community and for mRNA based drug design. The combinatorial space of mRNAs coding for same protein makes it costly to find the best mRNA experimentally. Utilising data-driven ML methods for this problem is quite sensible. \n2. The proposed method technically is sensible and given the general pre-training, the fine-tuning stage make sense. The chosen baselines are also adequate and the presented results with respect to CAI and GC content are convincing.\n3. The paper is well-written and easy to follow."}, "weaknesses": {"value": "Although the paper describes the motivation, methodology and results clearly, there are some major gaps which I describe below.\n\n1. **Weak Biological/Mechanistic Plausibility and Unsubstantiated Claim:** \n\na) The paper’s core claim, positioned in the introduction, is that it overcomes the limitations of traditional codon optimization methods (such as optimizing Codon Adaptation Index) by capturing codon-expression relationships that these metrics fail to fully encapsulate. While the paper reports improved metrics such as CAI and GC content, demonstrating in-silico biological plausibility, it critically fails to provide any novel, biologically-grounded evidence that its method has actually learned the complex, non-linear codon-expression relationships it claims to model. The same argument the authors use against traditional methods—that optimizing CAI does not guarantee high expression—holds true for this work. From a biology standpoint as well, it is a well-known fact that CAI and other metrics are known to be weakly correlated with translational efficiency (see [1], [2] as some examples for well-established evidence).\n\nb)  Related to (a), the argument that fine-tuning on high-expression mRNA-protein pairs will enforce the model to learn to predict high-expressing mRNAs is not guaranteed. In general, during fine-tuning, the degree to which a large pre-trained model adapts to a new, specific task (like predicting high expression) is dependent on factors such as the size and distribution of the fine-tuning dataset, the magnitude of the learning rate, and the degree of catastrophic forgetting of the original pre-training task (see [3], [4], [5], [6], [7] for few works demonstrating this). The model's adaptation is an empirical outcome, not a theoretical certainty. Therefore, without a strong theoretical or empirical explanation that goes beyond simply fine-tuning, the claim remains an unsubstantiated hypothesis. I understand that empirical validation is near impossible without doing any wet-lab experiments but that is a major problem with multiple prior works (including some of the baselines mentioned in this work). Few works such as LinearDesign have used wet-lab experiments to substantiate their claim and without it this paper just becomes another paper which claims to produce high expression mRNA without any evidence for the same. I believe adding this would substantially improve the paper for next version. In the absence of this, providing strong theoretical guarantees for the impact of fine-tuning would be helpful. The authors have not shown what is learned, only that the generated sequences score well on the same low-correlation metrics they themselves rightly criticize.\n\n2.  **Limited Methodological Novelty and Unclear Performance Gains:** \n\na) The paper references a “masked diffusion” framework but lacks a clear probabilistic formulation (e.g., noise schedule, Markov process definition unless I missed it) but it appears to me that the proposed masked diffusion process appears to be a direct and straightforward adaptation of works such as LLaDA (Nie et al., 2025), DPLM (Wang et al., ICML 2024) applied to discrete sequences. The novelty is limited to applying this known machine learning paradigm directly to the task of codon optimization. \n\nb) Moreover from an algorithmic standpoint, the use of a diffusion model, which predicts masked tokens iteratively (a key difference from single-shot prediction models like traditional Masked Language Models such as CodonTransformer or Autoregressive Transformers), does not automatically translate to performance gains in sequence generation. Looking broadly at the NLP literature, currently the benefits of diffusion transformers over standard Autoregressive (AR) or Masked Language Model (MLM) based transformers in general Language Modeling are an area of active research, and diffusion models have not shown substantial performance gains over MLM or AR transformers for discrete data, unlike for continuous data (Although slightly old, but still relevant blogpost [7] and other works such as [8], [9], [10]). So theoretically, I wonder if Prot2RNA performing better compared to non-diffusion transform counterparts such as CodonTransformer is because of difference in model architecture, pre-training and fine-tuning data rather than because of mechanics of diffusion itself. The authors fail to provide a conceptual or theoretical reason why the iterative refinement of a diffusion model is particularly well-suited for the biophysical constraints of codon optimization, as opposed to a single-shot prediction. In works such as LLaDA as well which the authors build on, the AR and diffusion models are evaluated under same protocol to make the comparison fair and there as well, it is not always empirically clear that diffusion transformer models are always better than non-diffusive transformer models and often performs comparably.\n\nc) Furthermore, fine-tuning stage for codon optimization is also proposed in CodonTransformer where they also fine-tune the model on highly expressing genes. If the architecture type (e.g., Transformer), pre-training data and scale, and fine-tuning data were equalized between this diffusion-based approach and a non-diffusion model like CodonTransformer, I wonder if the iterative diffusion process would offer any significant performance benefit. This could act as an ablation to motivate the use of diffusion models empirically since the only difference from prior works such as CodonTransformer is using a diffusion model for multi-step denoising over conceptually single-step denoising with MLM/AR based transformers. \n\n\n3. **Issue with experiment on Codon-Level Accuracy:** This sequence-level experiment/metric is somewhat trivial and can be misleading. Codon-level accuracy (matching wild-type codons) is an inadequate metric because the genetic code is synonymous. Exact codon matching is unnecessary for function and does not correlate with expression. This metric can primarily reward memorization or overfitting to the training data and can unfairly penalize models such as LinearDesign which prioritize functional (structural) features over sequence identity, thus confounding model quality with design intent.\n\nThe authors define the test set as \"highly expressed native sequences\" and assert that high codon overlap with these sequences implies high expression potential. I fear that this is a circular and self-fulfilling prophecy: the model is rewarded for statistically reproducing high-expression patterns already present in the data, not for demonstrating an independent, generalizable ability to predict expression. Without a control experiment that correlates codon accuracy with an independent measure of expression (e.g., protein yield), this metric is inconclusive and favors memorization over generalization.\n\n[1] Link Between Individual Codon Frequencies and Protein Expression: Going Beyond Codon Adaptation Index, 2024 \n\n[2] Limitations of codon adaptation index and other coding DNA-based features for prediction of protein expression in Saccharomyces cerevisiae, 2004\n\n[3] On the Importance of Data Size in Probing Fine-tuned Models, ACL 2022\n\n[4] Unveiling the Secret Recipe: A Guide For Supervised Fine-Tuning Small LLMs, 2024\n\n[5] An Empirical Study of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning, 2023\n\n[6] Revisiting Catastrophic Forgetting in Large Language Model Tuning, EMNLP, 2024\n\n[7] Diffusion language models, https://sander.ai/2023/01/09/diffusion-language.html\n\n[8] Large Language Diffusion Models, ICML 2025\n\n[9] DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models, ICLR 2023\n\n[10] Latent Diffusion for Language Generation, NeurIPS 2023"}, "questions": {"value": "The following questions are a reformulation of what I described in Weaknesses section.\n\n1. Fine-tuning on highly expressed mRNA-protein pairs is claimed to improve generation of high-expression sequences. Could you explain theoretically or empirically how fine-tuning guarantees this adaptation? \n2. Given that CAI and GC content are known to correlate weakly with expression, how do you justify using these metrics as primary evidence for biological relevance? Could the observed improvements be merely reproducing codon usage frequencies rather than capturing true expression determinants?\n3. The masked diffusion framework appears similar to prior work in LLaDA or DPLM. Can you clarify what is novel about your diffusion formulation specifically for codon optimization?\n4. Iterative diffusion over masked tokens is proposed as a key architectural choice. Could you provide a conceptual or theoretical justification for why this multi-step refinement is particularly suited to modeling codon constraints or translation efficiency, as opposed to single-shot MLM or autoregressive models like CodonTransformer given that in language modeling diffusion transformers are known to perform comparably to non-diffusion transformers?\n5. Given that the key difference between Prot2RNA and baselines such as CodonTransformer is diffusion transformer vs non-diffusion transformer and since prior works in NLP have shown under identical settings, these models perform comparably, did you perform any controlled ablation comparing Prot2RNA to a standard Transformer (e.g., CodonTransformer) using identical pre-training, architecture size, and fine-tuning data? If so, what performance gains are directly attributable to the diffusion process rather than other confounding factors?\n6. Codon-level accuracy is used as a metric, but exact codon matching is not biologically necessary and may favor memorization over functional generalization. Can you provide any results showing that higher codon-level accuracy actually correlates with translation efficiency or protein expression?\n8. The test set consists of highly expressed native sequences. How do you ensure that high codon overlap with this set is not simply rewarding memorization or reproducing training distribution biases? Have you considered testing on out-of-distribution proteins or low-expression sequences to validate generalization?\n9. For models like LinearDesign that optimize structural or stability features rather than codon identity, codon-level accuracy penalizes their objective. How do you justify the metric comparison across models with fundamentally different design goals? Would functional metrics (e.g., translation efficiency, mRNA stability) provide a more meaningful comparison?\n10. Have the authors considered wet-lab validation or in-vitro translation assays to substantiate claims regarding high-expression mRNA generation? Even small-scale experiments could strengthen the biological claim substantially and would differentiate the work as methods-wise, this work is rather similar to prior works as discussed in Weaknesses section.\n11. How sensitive are Prot2RNA’s results to the choice of fine-tuning dataset size or masking schedule? Could differences in these hyperparameters explain the reported performance improvements rather than the diffusion modeling per se?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "1UUIMImFX5", "forum": "BPNK5HDEMh", "replyto": "BPNK5HDEMh", "signatures": ["ICLR.cc/2026/Conference/Submission23705/Reviewer_SWB8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23705/Reviewer_SWB8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23705/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761837113988, "cdate": 1761837113988, "tmdate": 1762942775712, "mdate": 1762942775712, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper developed diffusion language models (DLM) for human mRNA coding sequence generation. The generated sequences preserve similar codon patterns as in highly expressed natural transcripts for target proteins. Following the architecture design of LLaDa, a well-known DLM, the authors conducted two-stage training after curating a high-quality human protein-mRNA pair dataset. Evaluations by some biologically meaningful metrics proved the efficacy of trained DLM in approximating the distributions of highly expressed codons."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors constructed a high-quality dataset comprising over 100,000 human protein–mRNA sequence pairs. The models were trained exclusively on human data without incorporating signals from other species.\n2. The study adapted the architecture of state-of-the-art discrete diffusion language models for mRNA codon generation.\n3. The paper is well organized, and the flow of ideas is generally coherent. There are not many grammatical errors throughout the manuscript."}, "weaknesses": {"value": "1. Some potential baselines are missing.\n\n- It is not clearly stated in the paper why the paper adopted parallel diffusion models rather than autoregressive (AR) GPT-like paradigm. Could you please explain the reasons and possibly add a AR baseline comparison if plausible? \n\n- It seems that the baselines listed in the paper are not deep generative models which approximate the distribution of mRNA codon. E.g, CodonBERT is an understanding model using cross-attention mechanism to align protein and codons, which is similar to CLIP. Although I agree that most existing work about applying diffusion models or autoregressive models for biological sequence generation is about non-coding RNA (ncRNA)/ UTR or even DNA [1][2], it would be good to explore whether these methods can be also used for mRNA generation with certain changes on tokenizers (possibly nucleotide -> codons) like the authors said in line 100-102. \n\n2. The goal of coding sequence generation is not clear to me. The paper says \"synthesize new coding sequences that maximize expression efficiency\". But I am confused by the metrics used in the paper. It seems that the metrics like CAI or codon-level accuracy mostly reflect how close the generated sequences and wild natural highly expressed sequences are in terms of codon distributions. Is the goal to be closer to natural sequence distribution or maximize the expression efficiency?\n\n   If it is latter, would it be possible to provide some direct proxies of expression efficiency as metrics like Mean Ribosome Loading (MRL) [4] and Translation Efficiency (TE) [5] measured on UTR sequences?\n\n3. Some statements about experiment results are not sound or well supported by the evidence. \n- In line 306-307, it is said that “This improvement underscores the benefit of finetuning on highly expressed sequences.” But the retrieval improvement from 0.612 to 0.616 does not convince me.\n- Regarding the CAI results, would the model be better if it has higher CAI values or resembles CAI distribution of wild sequences?\n- The authors gave detailed analyses to every method including different baselines. But I feel like the strengths of the proposed new method should be highlighted more and comparisons with other methods could be condensed. For now, the analyses about CAI and GC are not that informative. \n- In the conclusion section, the authors mentioned \"biologically relevant balance between expression optimization and sequence fi-\ndelity.\" It is not clear which metrics are reflective of expression optimization and which metrics are indicative of sequence fidelity. \n\n\n[1] Zhao, et al. GenerRNA: A generative pretrained language model for de novo RNA design.\n\n[2] Zhang, et al. RNAGenesis: A Generalist Foundation Model for Functional RNA Therapeutics.\n\n[3] Li, et al. Latent Diffusion Model for DNA Sequence Generation. \n\n[4] Sample, et al. Human 5’ utr design and variant effect prediction from a massively parallel\ntranslation assay. Nature biotechnology, 37(7):803–809, 2019.\n\n[5] Cao, et al. High-throughput 5’ utr engineering for enhanced protein production in non-viral gene therapies. Nature\ncommunications, 12(1):4138, 2021."}, "questions": {"value": "1. Due to limit of context window, the paper cut off the sequences whose lengths are longer than 1022 codons. Could you please show the length distribution of the original collected dataset to prove that the training data covers the dominant sequence length range.\n2. line 472 \"Prot2RNA captures more nuanced synonymous codon preferences\". What does \"preferences\" actually mean?\n3. Would it be better to add mask indicative function into (1) and (2), like $1(x_i=M)$ in LlaDa paper? \n4. In line 260, what does \"less-to-more masking\" strategy mean? does it mean less to more noise (masking)? It would be better to clearly state the direction of process, i.e., either forward diffusion process or backward diffusion process."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "aE9iahw25j", "forum": "BPNK5HDEMh", "replyto": "BPNK5HDEMh", "signatures": ["ICLR.cc/2026/Conference/Submission23705/Reviewer_jC16"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23705/Reviewer_jC16"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23705/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984611758, "cdate": 1761984611758, "tmdate": 1762942773957, "mdate": 1762942773957, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose Prot2RNA, a diffusion language model for generating mRNA coding sequences conditioned on target proteins. The model is trained in two stages: masked diffusion pretraining on separate human protein and mRNA sequences, then finetuning on protein-mRNA pairs where the protein serves as an unmasked prompt. Sequences are generated through iterative denoising with learnable masking schedules. The authors evaluate on ~2,912 highly expressed test sequences using codon-level accuracy, CAI, GC content, and positional codon usage metrics, comparing against several baseline methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors curated and cleaned a large number of human protein-mRNA pairs from NCBI RefSeq and GENCODE with rigorous filtering criteria, and commit to making the dataset, code, and model weights publicly available, which will benefit the community.\n2. Training exclusively on human coding sequences is well-motivated for the stated therapeutic mRNA applications.\n3. The paper includes ablations examining model scale, positional encoding strategies, masking schedule functions, and number of denoising steps, providing insight into which architectural decisions matter.\n4. Applying masked diffusion language models to protein-conditioned mRNA generation is a creative methodological contribution."}, "weaknesses": {"value": "0. **No experimental validation of generated sequences.** The paper lacks any wet-lab experiments demonstrating that generated sequences actually improve protein expression, mRNA stability, or other functional properties. Wet-lab proof would be the ultimate evidence of the viability of the proposed approach. This is an expected limitation of the work that must be stated, however, I do not take it into account in my evaluation.\n\n\n1. **Circular evaluation logic undermines validity.** The model is trained to mimic highly expressed sequences and evaluated by measuring similarity to highly expressed sequences, which tests memorization rather than whether the learned patterns genuinely improve expression. This circular reasoning provides no evidence that generated sequences would actually perform better than alternatives.\n\n\n2. **Questionable choice of primary metric.** Codon-level accuracy (exact matching to wild-type) is treated as the key success metric, but there's no evidence that exactly replicating wild-type codons is optimal or that alternative synonymous codon choices couldn't achieve equal or better expression. The metric conflates similarity with quality.\n\n\n3. **Inconsistent training paradigm lacks justification.** During pretraining the model receives either protein or RNA sequences separately, while during finetuning it processes concatenated protein-RNA pairs. This fundamental architectural inconsistency is not explained or justified, and no ablation studies compare against unified approaches (classic seq2seq models, concatenated pretraining throughout, ESM3-like joint pretraining, etc.).\n\n\n4. **Insufficient explanation of evaluation metrics.** The paper uses multiple metrics (CAI, GC content, MinMax profiles, Frechet distance) with only brief name mentions and no detailed explanation of what they measure, how they are calculated, their biological significance, or why they are appropriate for evaluating codon optimization quality. The manuscript would greatly benefit of adding a section with detailed explanations and discussion on the metrics.\n\n\n5. **Weak test set dissimilarity claims.** Clustering at 80% sequence identity still allows substantial similarity between training and test proteins, selecting \"smallest clusters\" may introduce systematic biases toward unusual or short sequences, and the characterization of test sequences as \"sequentially dissimilar\" is overstated.\n\n\n6. **Misleading presentation of statistical rigor.** The paper reports results from a single run with fixed seed 42 (stated explicitly in Reproducibility Statement), yet presents box-and-whisker plots throughout that create an illusion of statistical robustness. These plots show inter-sequence variability across test examples from that single run, not inter-run variability across different random initializations, meaning there are no confidence intervals for model performance, no way to assess whether observed differences between methods are statistically significant versus artifacts of the particular random seed, and no evidence that results would replicate with different initializations.\n\n\n7. **Inconsistent use of CAI.** The simple CAI-max baseline achieves codon accuracy (0.466) competitive with CodonBERT (0.477) and approaching CodonTransformer (0.502), yet this strong performance from a deterministic rule-based method raises unaddressed questions about whether the added model complexity is justified. At the same time, the authors cite evidence that CAI doesn't consistently correlate with expression (Vogel et al., 2010) yet still benchmark against CAI-maximization and uses CAI as an evaluation metric. This is an inadequate baseline comparison, or a fundamental tension about what actually matters for optimization.\n\n\n8. **Absence of diversity and novelty analysis.** The model uses deterministic argmax decoding to generate exactly one sequence per protein, despite the introduction emphasizing the \"vast design space\". There is no exploration of multiple diverse high-quality candidates, no sampling strategies (temperature, top-k, nucleus), no measurement of inter-sequence diversity, and no assessment of whether generated sequences are novel or memorized from training data. This limits practical utility since therapeutic applications would benefit from multiple candidates for empirical testing, provides no way to validate whether the model learns underlying codon preference distributions versus memorizing single solutions, and offers no evidence about design space coverage or whether better alternatives exist nearby.\n\n\n9. **Comparison against domain-expert-designed sequences or validated therapeutic constructs would strengthen the work.**\n\n\n10. **Questionable Frechet distance metric design.** The proposed Frechet distance uses CodonBERT embeddings to measure semantic similarity, but if CodonBERT performs poorly at codon optimization (as the paper's own results suggest), why should its learned embeddings capture the relevant semantic properties for evaluation?\n\n\n11. **Overfitting concerns from high accuracy.** Achieving high codon-level accuracy (>61%) with relatively similar train/test splits (90% vs 80% identity clustering) suggests the model may be memorizing training patterns rather than learning generalizable codon optimization principles."}, "questions": {"value": "1. What sample sizes were used to calculate the Frechet distance, how was this justified as sufficient? Can the authors provide the reference FD value between the held-out test set and a random sample of the same size from the training data (preferably, computed multiple times for statistics) to establish a meaningful scale?\n\n2. What justifies the median TPM > 5 cutoff for \"highly expressed\" sequences, how sensitive are results to this choice, and has this threshold been validated against expression in therapeutically relevant cell lines?\n\n3. Can the authors provide CodonBERT results with its original post-processing enabled, since removing amino acid preservation safeguards may create an unfair disadvantage compared to other methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yAYoRlTVKN", "forum": "BPNK5HDEMh", "replyto": "BPNK5HDEMh", "signatures": ["ICLR.cc/2026/Conference/Submission23705/Reviewer_GGiz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23705/Reviewer_GGiz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23705/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762304745013, "cdate": 1762304745013, "tmdate": 1762942773691, "mdate": 1762942773691, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}