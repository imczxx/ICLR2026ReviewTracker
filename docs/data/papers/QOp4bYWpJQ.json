{"id": "QOp4bYWpJQ", "number": 15899, "cdate": 1758256784742, "mdate": 1763736623703, "content": {"title": "Universality of Many-body Projected Ensemble for Learning Quantum Data Distribution", "abstract": "Generating quantum data by learning the underlying quantum distribution poses challenges in both theoretical and practical scenarios, yet it is a critical task for understanding quantum systems. A fundamental question in quantum machine learning (QML) is the universality of approximation: whether a parameterized QML model can approximate any quantum distribution. We address this question by proving a universality theorem for the Many-body Projected Ensemble (MPE) framework, a method for quantum state design that uses a single many-body wave function to prepare random states. This demonstrates that MPE can approximate any distribution of pure states within a 1-Wasserstein distance error. This theorem provides a rigorous guarantee of universal expressivity, addressing key theoretical gaps in QML. For practicality, we propose an Incremental MPE variant with layer-wise training to improve the trainability. Numerical experiments on clustered quantum states and quantum chemistry datasets validate MPE's efficacy in learning complex quantum data distributions.", "tldr": "A proof for universal approximation theorem to express quantum data distribution", "keywords": ["universality approximation theorem", "quantum data distribution", "many-body projected ensemble"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9d36b585e518f6a5ca99f6af2bf43b23f5b873f8.pdf", "supplementary_material": "/attachment/62194ce64679ba913974939204d29683fa1481fc.zip"}, "replies": [{"content": {"summary": {"value": "This paper focuses on learning quantum data distributions via the Many-Body Projected Ensemble (MPE). The main claim is a universality theorem: for any target distribution over n-qubit pure states, there exists an MPE-based, parameterized distribution Q_theta that approximates it within a 1-Wasserstein error epsilon. The paper also proposes an incremental training variant of MPE to mitigate the barren plateaus issue. Conceptually, the work reframes measurement-induced ensembles as generative learners. The presentation is clear and mathematically consistent. However, the technical novelty is largely compositional, and the approach requires sample and resource scalings that appear exponential in the support dimension. The incremental training strategy is also known and heuristic and lacks theoretical guarantees.\n\nFor the current manuscript, my overall score is 4, though my true assessment would be around 5 if such an option existed. If the main concerns discussed below are properly addressed, I would be willing to increase the score."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1) Treating MPE as a quantum generative model is insightful and physically interpretable. It connects quantum statistical geometry with learning objectives.\n\n2) The paper gives explicit upper bounds on the required number of training samples and ancilla qubits for achieving an epsilon-approximation to arbitrary target distribution. Specifically, they show that the number of samples N scales as O((1/epsilon)^{O(D)}) and the required ancilla qubits n_a = ceil(log2 N). This term provides useful insight into the resource requirements of MPE-based learning, although the scaling is exponential.\n\n3) The structure and presentation are easy to follow, and the writing is generally clear."}, "weaknesses": {"value": "1) The framework presumes N training states sampled from Q_t with N ~ (1/delta)^D (delta = epsilon/2), where D is the support dimension of the target distribution. Even if D is linear in the number of qubits, N grows exponentially in D. Hence the approach is requiring exponential numbers of training states and impractical beyond small systems. \n\n2) Sampling relies on measuring ancilla qubits with n_a = ceil(log2 N). The outcome space is size 2^(n_a) ~ N, and probabilities may be highly nonuniform. This induces sparsity and requires many repetitions to cover modes, making the sampling statistically inefficient.\n\n3) Theorem is compositional with limited technical novelty. The main result essentially combines known ingredients: i) standard epsilon-net covering bounds for pure-state manifolds, and ii) known properties of MPE/random-state generation. The paper’s main contribution lies in presenting a polished synthesis that unifies these ingredients into a single “universality” statement. However, it appears that the work does not introduce new bounds, metrics, or proof techniques.\n\n4) The incremental freezing/expansion strategy resembles known layerwised training used in variational quantum circuits [1]. \n\n5) The paper sometimes reads as if universality implies practical learnability. It does not. An existential approximation theorem does not give polynomial-time learnability or polynomial-sample guarantees.\n\n[1] Skolik A, McClean J R, Mohseni M, et al. Layerwise learning for quantum neural networks. Quantum Machine Intelligence, 2021, 3(1): 5."}, "questions": {"value": "1) Could the authors add some empirical scaling plots of epsilon or D to show the efficiency beyond the theoretical exponential bounds?\n\n2) Which parts of Theorem 4.1 and its supporting lemmas are genuinely new beyond combining epsilon-net discretization with existing MPE properties? A precise positioning against prior work would strengthen the claim of novelty.\n\n3) Are there theoretical results supporting that incremental/layerwise training mitigates the barren plateaus issue? If not, can the authors provide experiments that isolate the benefit of incremental training over standard training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ym8C2tlEsb", "forum": "QOp4bYWpJQ", "replyto": "QOp4bYWpJQ", "signatures": ["ICLR.cc/2026/Conference/Submission15899/Reviewer_RVq8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15899/Reviewer_RVq8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15899/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761031779614, "cdate": 1761031779614, "tmdate": 1762926114099, "mdate": 1762926114099, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors show a universal approximation theorem for a QML model known as the Many-body projected ensemble. It also proposes an incremental version of the model that shows some evidence of avoiding barren plateaus."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is well written and has good experiments along with the theory."}, "weaknesses": {"value": "While the paper has good results, I am not sure if universality result for a very specific QML architecture clears the bar for publication at a top ML conference like ICLR. May be a more specialized QML venue is more ideal."}, "questions": {"value": "1. In the paper the authors use both the idea of a density matrix and also that of distributions over pure states? Aren't they the same thing? For instance the density matrix $\\int_{\\psi} Q(\\psi) \\ket{\\psi}\\bra{\\psi} $ should be the same as the distribution Q over all pure states. I understand that two different distributions can give the same density matrix. However, any observable that you estimate from a quantum device sampling from such a distribution should be modeled by the density matrix.\n\n2. Suppose we want to prepare some $\\rho = \\sum_i \\lambda_i \\ket{\\phi_i}\\bra{\\phi_i}$ on the $M$ system. We can always purify this $\\rho$ to be a pure state of the M + A system, $\\ket{\\psi} = \\sum_{i} \\sqrt{\\lambda_i}\\ket{i}\\ket{\\phi_i}$. Now from the universality of parametric quantum circuits, we know that there exists a PQC to prepare this purified state. To get the desired distribution over pure states we only need to measure the qubits in A. Does the universality results in the paper give any improvement over this naive procedure? \n\n3. The theory defines $W_1$ using trace distance between states (Def. 3.1), but eq(11) computes an OT objective with a different kernalized metric. Please clarify the relationship between the experimental metric and the theorem’s and whether any bound relates them.\n\n4. Could you explain how you were able to go from an approximate construction in Lemma 4.3 to an exact construction in Lemma 4.4?\n\n5. Is there any good justification for why the incremental method avoids barren plateaus? Can you show that in these methods the gradient does get suppressed by noise?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nI10kebI7u", "forum": "QOp4bYWpJQ", "replyto": "QOp4bYWpJQ", "signatures": ["ICLR.cc/2026/Conference/Submission15899/Reviewer_FDfx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15899/Reviewer_FDfx"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15899/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761943922644, "cdate": 1761943922644, "tmdate": 1762926113696, "mdate": 1762926113696, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The topic of this paper is about quantum machine learning. Authors consider using the many-body projected ensemble as a parameterized quantum model to learn the distribution defined over n-qubit pure states. The main claim is that this model provided by the authors is the universality of approximation. Authors also implement some numerical experiments to support this claim."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Many quantum machine learning papers are lack of theoretical guarantee, and due to the lack of good quantum hardware, it is hard to valuate the real performance. In this work, the author provide the proof for the universality of approximation, which provide some theoretical guarantee to the model."}, "weaknesses": {"value": "However, the universality of approximation, is not really important for the quantum machine learning model, especially for the NISQ-friendly type. What matters is about the classical simulability, efficient training guarantee, size of parameters, quantum advantage... Especially many papers show negative results in recent years, I think these are more important to discuss, which is not covered by the authors. For example, the distribution generated by the many-body projected ensemble is purely classical, is there any potential that this can have any more advantage? I do not feel positive towards this question, and hope the authors could clarify this more clearly. I understand and know that this model has recently been actively studied in the quantum many body field. For the training, it is also not that clear whether it will be efficient. From the numerical result, I feel right now it is not that efficient. I also hope the authors could clarify more on this."}, "questions": {"value": "I have already mentioned in the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TVjkHKQNY5", "forum": "QOp4bYWpJQ", "replyto": "QOp4bYWpJQ", "signatures": ["ICLR.cc/2026/Conference/Submission15899/Reviewer_P9Nz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15899/Reviewer_P9Nz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15899/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761970400442, "cdate": 1761970400442, "tmdate": 1762926112992, "mdate": 1762926112992, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a fundamental and significant open question in Quantum Machine Learning (QML): whether a parameterized quantum model can universally approximate any distribution of quantum data. The authors provide an affirmative answer by proving a universality theorem for the Many-body Projected Ensemble (MPE) framework in Theorem 4.1. \n\nFurthermore, recognizing that this universal construction is not guaranteed to be efficient, the authors also propose a practical variant, \"Incremental MPE\". This method uses a layerwise training strategy to build the model iteratively, a technique designed to mitigate the barren plateau problem and reduce resource requirements for NISQ devices. This practical framework is then validated numerically on two tasks: a synthetic multi-cluster quantum distribution and a real-world quantum chemistry distribution derived from the QM9 dataset."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- Fundamental Theoretical Contribution: The primary strength of this paper is its main theorem. The question of universality is a cornerstone of any machine learning field, and providing a rigorous answer for quantum generative models is a significant achievement. This result provides a solid theoretical foundation for MPEs as a new class of quantum generative models.\n\n- Clear Empirical Validation: The experiments in Section 6 serve their purpose well. They are not intended to be state-of-the-art on a major benchmark, but rather to validate that the practical Incremental MPE framework can indeed learn non-trivial, multi-modal quantum distributions (Fig 2a) and real-world data (Fig 2b). The results clearly show the model learning, as all metrics ($W_1$, MMD, Vendi) improve with a moderate number of layers."}, "weaknesses": {"value": "- Scope Limited to Pure States: The entire framework and theorem are limited to distributions over pure states. A fully general quantum generative model would also need to handle mixed states (density operators), which are the norm in noisy systems or when data comes from a subsystem. This is noted as a direction for future work but is a clear limitation of the current theorem.\n\n- Efficiency of the Universal Construction: The most significant limitation, which the authors commendably state in the conclusion, is the gap between universality and efficiency. The proof relies on a number of ancilla qubits $n_a = \\lceil \\log_2 N \\rceil$, where $N$ is the covering number of the $\\epsilon/2$-net (Lemma 4.2). This covering number $N$ can scale exponentially with the effective dimension of the state space $D$ (Eq. 3). Therefore, the universal constructor is not, in general, efficient (i.e., it may require an exponential number of qubits and gates)."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "tkXIkNWK59", "forum": "QOp4bYWpJQ", "replyto": "QOp4bYWpJQ", "signatures": ["ICLR.cc/2026/Conference/Submission15899/Reviewer_zS2q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15899/Reviewer_zS2q"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15899/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762103733218, "cdate": 1762103733218, "tmdate": 1762926112584, "mdate": 1762926112584, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}