{"id": "0NC4Y1sYrz", "number": 9941, "cdate": 1758151076510, "mdate": 1759897684050, "content": {"title": "Usage-Aware Sentiment Representations in Large Language Models", "abstract": "Large language models (LLMs) can encode high-level concepts as linear directions in their representation space, and sentiment has been studied in this framework. However, probe-derived sentiment directions often vary substantially across datasets, thereby compromising reliability for downstream applications. Prior work addresses this issue with distributional methods such as Gaussian subspaces, which improve reliability but trade off direct interpretability of linguistic meaning. In this paper, we propose a usage-aware sentiment representation framework that grounds sentiment variability in linguistic usage factors such as tone, topic, context, and genre, which are drawn from linguistic research. \nOur framework operates at two complementary levels of analysis: At the axis level, we construct sentiment directions from both pooled and usage-specific data to investigate the role of usage in shaping sentiment representations. At the neuron level, we provide a finer view by distinguishing usage-invariant neurons that consistently encode sentiment from usage-sensitive neurons whose contributions vary across usages.\nExperiments indicate that usage-aware sentiment representation enhances reliability, improving both classification accuracy and controllability of sentiment steering. Finally, preliminary experiments with audio LLMs suggest that our framework generalizes beyond text, pointing toward cross-modal applicability.", "tldr": "Modeling sentiment  in LLMs through usage factors improves reliability and interpretability.", "keywords": ["sentiment analysis; interpretability; representation learning"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a3b03179b5f23984083e757fe5ca69b53f7ccb6d.pdf", "supplementary_material": "/attachment/949a27575466287b341bd49311e214337412ca19.zip"}, "replies": [{"content": {"summary": {"value": "In this paper, the authors investigate how sentiment is represented in Large Language Models (LLMs). They argue that a single, universal sentiment \"direction\" is insufficient and propose a \"usage-aware\" framework that incorporates linguistic factors like tone, topic, context, and genre. They train linear probes on both a pooled dataset and usage-specific datasets, showing that combining these probes leads to marginally improved sentiment classification performance. They also analyze sentiment at the neuron level, identifying \"usage-invariant\" and \"usage-sensitive\" neurons. Finally, they demonstrate that these derived axes can be used for activation steering, and that the component of a usage-axis orthogonal to the main sentiment axis can modulate stylistic elements without altering the core sentiment."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "See below"}, "weaknesses": {"value": "## Overall Rating\nI recommend rejecting this paper. I found the paper very difficult to follow, with key methodological details unclear. Based on my current understanding, the core results are either marginal performance gains that are not particularly surprising, or novel claims that lack rigorous evidence. I am open to the possibility that I have misunderstood key aspects of the work and would welcome clarification from the authors, but in its current state, I cannot recommend acceptance.\n\n## Major Comments\n\n*The following are things that, if adequately addressed, may change my score.*\n\n1.  **Methodological Clarity:** The paper is difficult to parse due to a lack of clarity on crucial methodological points, making it harder to interpret the results.\n    *   **\"Usage-Specific\" Datasets:** The concept of a \"usage-specific\" dataset is core to the paper but is not clearly defined until the appendices (line 675). The main text should precisely explain how these datasets are constructed and how they make a particular usage factor salient for a sentiment classification task. My initial assumption was that a \"tone\" probe would be trained on data of a single tone, or to predict tone itself. Instead, it appears a single probe is trained on a collection of texts with varied tones, with the hope that tone is the most salient differentiating factor.\n    *   **\"Main+Sub\" Combination:** The paper's central results rely on a \"Main+Sub\" axis combination (e.g., Table 1, line 217), but this operation is never defined. Assuming it is vector addition, this is not a standard or principled method for combining probe directions, and its meaning is unclear. The paper should define this operation and justify its use before any conclusions can be drawn from it.\n\n2.  **Limited Significance of Classification Results:** The main quantitative result—that \"Main+Sub\" axes slightly outperform the \"Main\" axis alone—is not particularly surprising. I do not find this result surprising. Supervised methods like linear probing generally perform better when the training data is more similar to the evaluation data. By creating more specialized probes and combining them, it is expected that they would better cover the nuances of diverse evaluation sets, leading to marginal gains. \n\n3.  **Confounded Geometric Analysis:** The authors claim that because the \"main axis lies within the usage subspace\" (lines 413-417), sentiment is \"largely shaped by usage-conditioned variation.\" This conclusion is built on a confounded experimental design. The \"main\" probe was trained on the union of the datasets used for the usage-specific probes. It is therefore tautological that the resulting \"main\" vector would be well-approximated by the span of the usage vectors. Even if it were constructed with separate datasets, this observation does not rule out the simpler hypothesis that there is a single primary sentiment direction and the usage-specific probes are merely noisy measurements of it.\n\n4.  **Qualitative Steering Evidence is Unconvincing**: The idea that steering with the orthogonal component of a usage axis can alter style without changing sentiment (Table 5, line 388) is potentially interesting. However, the qualitative examples provided are not compelling enough to serve as strong evidence. The effect seems subtle, and it is difficult to judge its consistency and magnitude from a few examples. The authors do not state whether these examples were cherry-picked or selected randomly. To be compelling, this claim requires a rigorous, large-scale evaluation, for example using an LLM judge to rate sentiment and stylistic attributes across a randomized set of prompts, to demonstrate a statistically significant and meaningful effect."}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ahW0bskfZH", "forum": "0NC4Y1sYrz", "replyto": "0NC4Y1sYrz", "signatures": ["ICLR.cc/2026/Conference/Submission9941/Reviewer_3raM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9941/Reviewer_3raM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9941/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761164986635, "cdate": 1761164986635, "tmdate": 1762921392049, "mdate": 1762921392049, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors investigate how sentiment is represented in Large Language Models (LLMs). They argue that a single, universal sentiment \"direction\" is insufficient and propose a \"usage-aware\" framework that incorporates linguistic factors like tone, topic, context, and genre. They train linear probes on both a pooled dataset and usage-specific datasets, showing that combining these probes leads to marginally improved sentiment classification performance. They also analyze sentiment at the neuron level, identifying \"usage-invariant\" and \"usage-sensitive\" neurons. Finally, they demonstrate that these derived axes can be used for activation steering, and that the component of a usage-axis orthogonal to the main sentiment axis can modulate stylistic elements without altering the core sentiment."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "See below"}, "weaknesses": {"value": "## Overall Rating\nI recommend rejecting this paper. I found the paper very difficult to follow, with key methodological details unclear. Based on my current understanding, the core results are either marginal performance gains that are not particularly surprising, or novel claims that lack rigorous evidence. I am open to the possibility that I have misunderstood key aspects of the work and would welcome clarification from the authors, but in its current state, I cannot recommend acceptance.\n\n## Major Comments\n\n*The following are things that, if adequately addressed, may change my score.*\n\n1.  **Methodological Clarity:** The paper is difficult to parse due to a lack of clarity on crucial methodological points, making it harder to interpret the results.\n    *   **\"Usage-Specific\" Datasets:** The concept of a \"usage-specific\" dataset is core to the paper but is not clearly defined until the appendices (line 675). The main text should precisely explain how these datasets are constructed and how they make a particular usage factor salient for a sentiment classification task. My initial assumption was that a \"tone\" probe would be trained on data of a single tone, or to predict tone itself. Instead, it appears a single probe is trained on a collection of texts with varied tones, with the hope that tone is the most salient differentiating factor.\n    *   **\"Main+Sub\" Combination:** The paper's central results rely on a \"Main+Sub\" axis combination (e.g., Table 1, line 217), but this operation is never defined. Assuming it is vector addition, this is not a standard or principled method for combining probe directions, and its meaning is unclear. The paper should define this operation and justify its use before any conclusions can be drawn from it.\n\n2.  **Limited Significance of Classification Results:** The main quantitative result—that \"Main+Sub\" axes slightly outperform the \"Main\" axis alone—is not particularly surprising. Supervised methods like linear probing generally perform better when the training data is more similar to the evaluation data. By creating more specialized probes and combining them, it is expected that they would better cover the nuances of diverse evaluation sets, leading to marginal gains. \n\n3.  **Confounded Geometric Analysis:** The authors claim that because the \"main axis lies within the usage subspace\" (lines 413-417), sentiment is \"largely shaped by usage-conditioned variation.\" This conclusion is built on a confounded experimental design. The \"main\" probe was trained on the union of the datasets used for the usage-specific probes. It is therefore tautological that the resulting \"main\" vector would be well-approximated by the span of the usage vectors. Even if it were constructed with separate datasets, this observation does not rule out the simpler hypothesis that there is a single primary sentiment direction and the usage-specific probes are merely noisy measurements of it.\n\n4.  **Qualitative Steering Evidence is Unconvincing**: The idea that steering with the orthogonal component of a usage axis can alter style without changing sentiment (Table 5, line 388) is potentially interesting. However, the qualitative examples provided are not compelling enough to serve as strong evidence. The effect seems subtle, and it is difficult to judge its consistency and magnitude from a few examples. The authors do not state whether these examples were cherry-picked or selected randomly. To be compelling, this claim requires a rigorous, large-scale evaluation, for example using an LLM judge to rate sentiment and stylistic attributes across a randomized set of prompts, to demonstrate a statistically significant and meaningful effect."}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ahW0bskfZH", "forum": "0NC4Y1sYrz", "replyto": "0NC4Y1sYrz", "signatures": ["ICLR.cc/2026/Conference/Submission9941/Reviewer_3raM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9941/Reviewer_3raM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9941/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761164986635, "cdate": 1761164986635, "tmdate": 1763293033851, "mdate": 1763293033851, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "# Summary\nThis paper proposes a Usage-Aware affective representation framework to address the instability of probed sentiment directions across datasets, which harms downstream reliability. The authors attribute this variability to linguistic usage factors—such as tone, topic, context, and genre—and introduce two complementary analyses:\n\n- Axis Level: A usage-invariant axis is derived as the intersection of sentiment axes from aggregated and usage-specific data, capturing core affective signals.\n- Neuron Level: Neurons are classified as usage-invariant or usage-sensitive for fine-grained interpretation."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "# Strengths\n1. The paper explicitly identifies the reliability issue of probe-derived sentiment axes in cross-dataset applications and innovatively links this problem to linguistic \"usage\" factors, offering a theoretically grounded explanation for variability in representation learning.\n\n2. The framework conducts complementary analyses at both the axis and neuron levels. The intersection operation at the axis level is the core contribution addressing cross-dataset consistency, while the distinction at the neuron level provides a fine-grained understanding of the model’s internal mechanisms."}, "weaknesses": {"value": "# Weaknesses\n1. This is the biggest barrier to the practical deployment of the framework. The core of the method—computing the intersection between usage-specific axes and the invariant axis—relies heavily on fine-grained, high-quality labels of usage factors (e.g., tone, genre, topic) in the training data. In real-world scenarios, acquiring such detailed, multi-dimensional annotations is extremely costly, difficult to label consistently, and prone to low inter-annotator agreement. This severely limits the method’s potential for real-world adoption and scalability.\n\n2. The paper introduces four usage dimensions—genre, tone, context, and topic—but does not sufficiently justify their mutual exclusivity or independence. For example, tone and genre may be highly correlated (e.g., tweets often inherently carry an informal tone). Without theoretical or empirical evidence demonstrating that these dimensions can be treated as orthogonal, decomposing sentiment representations along them risks conflating interdependent factors, potentially inflating the perceived benefit of usage-specific axes.\n\n3. The authors should analyze the distribution of usage factors across the benchmark datasets. It is possible that the observed performance gains stem not from the proposed method itself, but from alignment between the usage distributions in the training data and those in the evaluation benchmarks.\n\n4. Although probes are trained at every layer, the paper only reports aggregated results and does not investigate which layers benefit most from usage-specific axes. Understanding how usage-aware sentiment signals evolve across model depth would significantly strengthen the interpretability of the representations and provide practical guidance for deployment (e.g., which layer to use for feature extraction).\n\n5. typos: page 16, line 831, \"We use instruction-tuned versions of three popular decoder-only LLMs.\" repeat."}, "questions": {"value": "Refer to Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "BfxVGN93k0", "forum": "0NC4Y1sYrz", "replyto": "0NC4Y1sYrz", "signatures": ["ICLR.cc/2026/Conference/Submission9941/Reviewer_4QNq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9941/Reviewer_4QNq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9941/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761541704352, "cdate": 1761541704352, "tmdate": 1762921391708, "mdate": 1762921391708, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a linguistically grounded framework for modeling sentiment representations in LLMs through usage-aware axes. By decomposing sentiment into usage-specific factors and analyzing both axis- and neuron-level behaviors, the study enhances interpretability and reliability."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The core idea grounds sentiment variability in explicit linguistic usage factors, offering a highly interpretable framework for LLM sentiment analysis, superior to distributional methods that sacrifice linguistic meaning.\n\n2. The usage-aware axes achieved a substantial average improvement in cross-domain sentiment classification accuracy, demonstrating superior robustness and transferability."}, "weaknesses": {"value": "1. The core dataset is synthetically generated by ChatGPT-4.0, which risks introducing model-induced biases and may fail to capture the subtle linguistic nuances of natural human-generated text.\n\n2. The analysis is restricted to four predefined usage factors (tone, topic, context, genre), neglecting other key influences on sentiment variability, such as sarcasm or cultural context."}, "questions": {"value": "Please see the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics review needed."}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "UUynLnS2Dg", "forum": "0NC4Y1sYrz", "replyto": "0NC4Y1sYrz", "signatures": ["ICLR.cc/2026/Conference/Submission9941/Reviewer_AZkL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9941/Reviewer_AZkL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9941/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761667760884, "cdate": 1761667760884, "tmdate": 1762921391407, "mdate": 1762921391407, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed a usage-aware sentiment representation framework for LLMs that grounds sentiment variability in linguistic usage factors such as tone, topic, context, and genre. \n\nThe approach was motivated by two limitations of existing methods: the instability of sentiment directions extracted via linear probes, and the lack of interpretability in distributional representations such as Gaussian subspaces. \n\nThe authors introduced a two-level analysis: (1) at the axis level, constructing both pooled and usage-specific sentiment directions to examine how linguistic usage influences representational reliability; and (2) at the neuron level, differentiating usage-invariant from usage-sensitive neurons to reveal finer-grained encoding patterns. \n\nEmpirical results showed that usage-aware sentiment representations improve both classification accuracy and controllability of sentiment steering."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The work addresses a feasible limitation of current sentiment representation extraction methods: linear probes lack reliability, while more complex methods lack interpretability. \n\nThe authors showed that the natural variability and interpretability of sentiment lie in linguistic usage factors and designed a two-level framework to capture higher-quality sentiment representations, through sentiment-guided axis construction and neuron-level analysis. \n\nThe writing is clear and logically structured, and the experimental design is coherent, complete, and solid. The application of fine-grained representation analysis to the sentiment domain appears original and contributes meaningfully to decoding factors that contribute to sentiment-based interpretability in LLMs."}, "weaknesses": {"value": "It is not particularly surprising for me that extracting separate linear probes for different usage-specific axes yields more specialized representations that perform better at classification and steering. This essentially demonstrates that representations separated by linguistic patterns possess greater predictive power for sentiment.\n\nThis raises some concerns about conceptual novelty. While the framework provides a linguistically motivated decomposition of sentiment axes, it mainly repackages an established idea—linear disentanglement by conditioning on auxiliary attributes—into a sentiment-specific context. Prior studies on domain adaptation and representation disentanglement (e.g., Blitzer et al., 2007 (https://aclanthology.org/P07-1056.pdf); Hewitt & Manning, 2019 (https://aclanthology.org/N19-1419.pdf)) have already shown that task-specific subspaces can improve generalization. To strengthen the contribution, the authors may provide a clearer theoretical justification of what “usage-awareness” adds beyond such conditional probing and what do the results imply."}, "questions": {"value": "1. What do your results imply about the role of linguistic usage factors in sentiment interpretability? Do the axis- and neuron-level analyses jointly suggest that usage factors causally structure sentiment representations in LLMs, or mainly correlate with them? Adding such discussion could be beneficial.\n\n2. Can you provide causal evidence that “usage-invariant” and “usage-sensitive” neurons drive predictions rather than merely correlate with them? Further analyses using targeted neuron ablations, activation patching, or causal mediation methods could strengthen the causal claims."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jr85HAXFQW", "forum": "0NC4Y1sYrz", "replyto": "0NC4Y1sYrz", "signatures": ["ICLR.cc/2026/Conference/Submission9941/Reviewer_125c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9941/Reviewer_125c"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9941/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761865323711, "cdate": 1761865323711, "tmdate": 1762921391118, "mdate": 1762921391118, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}