{"id": "IysKdBVQ6y", "number": 23684, "cdate": 1758347170235, "mdate": 1759896801594, "content": {"title": "Improving Complex SQL Generation for Text-to-SQL by Addressing Semantic Blind Spots in Pending SQL Components", "abstract": "In recent years, significant advancements in large language models (LLMs) have greatly propelled the development of Text-to-SQL tasks. However, due to the token-by-token sequential generation mechanism employed by these models, they encounter a “semantic blind spot” problem with respect to pending SQL components—the parts of the SQL query yet to be generated. Specifically, language models are unable to effectively utilize the semantic information of these pending SQL components during the generation of the final SQL query, which poses considerable challenges for generating complex SQL statements. To address this issue, we propose a novel thought process based on SQL components pre-generation and design a maximum connected subtree matching reward mechanism leveraging the SQL abstract syntax tree (AST) to improve the accuracy of local component generation. Extensive experiments demonstrate that, under comparable model parameter scales, our training approach achieves significant advantages, effectively enhancing the generation of complex SQL queries. Our method attains an execution accuracy (EX) of 65.78% on the BIRD-dev dataset and achieves state-of-the-art (SOTA) performance on the Spider-syn datasets.", "tldr": "", "keywords": ["Large Language Models", "Text-to-SQL", "Reinforcement Learning", "Group Relative Policy Optimization", "Abstract Syntax Tree"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b35b160b706513a403f109266f5de95dc40bdbca.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "In this paper, the authors identify a semantic blind spot in conventional Text-to-SQL generation methods. They argue that auto-regressive generation, often based on reasoning approaches like Chain-of-Thought (CoT), fails to account for upcoming SQL components, leading to errors in complex query generation. To address this, the authors propose a novel generation framework that first measures the complexity of the target SQL query. For low-complexity queries, the model employs a standard auto-regressive approach. However, for high-complexity queries, it adopts a method that pre-generates individual SQL components before integrating them into the final statement. This strategy is inspired by how humans compose complex SQL, such as nested queries, by first constructing parts of the query and then combining them.\n\nTo train a model to operate in this manner, the authors utilize reinforcement learning (RL) fine-tuning with the GRPO algorithm. They design a sophisticated reward system comprising four distinct functions: a Reasoning Steps Reward(with sub-rewards for complexity analysis and component pre-generation), an AST Matching Reward (which compares the generated SQL's Abstract Syntax Tree to the ground truth), an Execution Reward, and a Format Reward. Notably, the AST matching process incorporates a normalization step to handle discrepancies arising from aliases or differing orders, ensuring a more accurate reward calculation.\n\nThe authors evaluate their method on several Text-to-SQL benchmarks, including BIRD, SPIDER, SPIDER-SYN, and SPIDER-REAL. The proposed model achieves performance that is comparable to or surpasses state-of-the-art methods based on open-source LLMs, achieving SOTA results on SPIDER-SYN. A key finding is the model's strong generalization capability, as it was trained exclusively on the BIRD training set yet performed well on other benchmarks.\n\nThe paper includes a thorough set of empirical analyses. An ablation study on the reward functions demonstrates that the pre-generation reward significantly improves performance, particularly on challenging queries. The authors also provide a detailed analysis of the complexity analysis module, comparing its performance against several baselines . Furthermore, they demonstrate the method's versatility by applying it to diverse Large Language Models (LLMs), showing consistent performance improvements across all evaluated models. Their analysis also covers the impact of different matching reward functions (no matching, n-gram, and AST matching), confirming the superiority of the proposed AST-based approach. Finally, an ablation study on the reward function weights is detailed in the appendix."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- **Novel Problem Formulation and an Intuitive Solution:** The paper clearly articulates a significant limitation of standard auto-regressive models in Text-to-SQL generation, which it terms the \"semantic blind spot\". This is a well-grounded and reasonable critique based on practical SQL implementation. The proposed solution, inspired by human cognition, involves hierarchically generating SQL components before assembling them. This approach presents a more plausible and rational generation process for complex queries compared to purely auto-regressive methods.\n    \n- **Strong Generalization Performance and Thorough Experimental Analysis:** The authors convincingly demonstrate the strong generalization capabilities of their method. The paper is supported by a comprehensive set of experiments, including detailed ablation studies on the reward functions, the complexity analysis module, the matching method, and the reward weights. The analysis is further strengthened by showing consistent performance gains across various base LLM architectures.\n    \n- **Adherence to Conference Guidelines:** The authors have provided clear and commendable statements on Ethics, Reproducibility, and the Use of LLMs, following the conference's recommendations."}, "weaknesses": {"value": "- **Clarity and Presentation:** The manuscript could benefit from a thorough round of proofreading and revision to improve its overall quality and clarity. I identified several areas for improvement:\n    \n    - **Typographical and Formatting Errors:** The text contains several typographical errors (e.g., ”semantic…” instead of “semantic…” in line 52) and inconsistent formatting, such as missing spaces in citations (e.g., 'SPIDER-SYN(...)' in line 256) and appendix references (e.g., 'appendixD.2' in line 262).\n        \n    - **Undefined Terminology and Missing Citations:** Several key terms are introduced without proper explanation or citation upon their first appearance. For instance:\n\t    - The SPIDER benchmark (line 92) and the GRPO algorithm (line 99) are mentioned without initial references or brief descriptions.\n\t    - The \"Spider dataset’s method\" for complexity classification (line 174) should be briefly explained.\n\t    - Technical terms such as IDF (line 197) and VES (line 260) should be clearly defined for the reader.\n\t    - The rationale for evaluating on SPIDER-SYN and SPIDER-REAL (line 256) is not provided, leaving their specific purpose and relevance unclear.\n        \n- **A Dichotomous Approach to a Continuous Problem:** The proposed method relies on a binary classification of queries into \"simple\" and \"complex,\" applying distinct generation processes to each. However, query complexity is inherently a spectrum rather than a dichotomy. This rigid, two-pronged approach may lack the scalability to handle extremely complex queries that might require a more deeply nested generation process (e.g., \"pre-generation of pre-generated components\"). A discussion of this limitation, perhaps in a dedicated \"Limitations\" section, would strengthen the paper."}, "questions": {"value": "- For simple queries where pre-generation is not performed, is the pre-generation reward simply set to zero?\n    \n- The pre-generation reward increases with the number of components generated. What was the motivation for this design choice? How does this reward function avoid incentivizing the model to generate unnecessarily verbose or redundant components?\n    \n- Could the authors elaborate on the specific characteristics of the SPIDER-SYN and SPIDER-REAL benchmarks compared to the standard SPIDER dataset? Why were these specific benchmarks chosen to validate the model's robustness?\n    \n- As a minor formatting suggestion, should Appendices A and B be moved to appear after the main references, in accordance with the author guidelines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xuRHyMpOxo", "forum": "IysKdBVQ6y", "replyto": "IysKdBVQ6y", "signatures": ["ICLR.cc/2026/Conference/Submission23684/Reviewer_H8Vy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23684/Reviewer_H8Vy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23684/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761645796040, "cdate": 1761645796040, "tmdate": 1762942763876, "mdate": 1762942763876, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper identifies a clear and intuitive problem with existing Text-to-SQL models and proposes a novel, multi-part solution to address it. The core idea is to change the model's reasoning process to first pre-generate individual SQL components before assembling the final query, thereby solving the \"semantic blind spot\". This is trained using a sophisticated reinforcement learning strategy featuring a novel AST-based reward"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper's core premise, the \"semantic blind spot\", is a significant and well-articulated insight. The authors correctly observe that the standard, token-by-token generation process is unlike how humans write complex SQL. The analogy of a human writing an inner query first and then building the outer query around it is a powerful justification for their approach.\n2. The proposed \"SQL components pre-generation\" reasoning paradigm  is a logical and creative solution to the identified problem. By having the model first generate the independent semantic components, it effectively provides the necessary context for the model to use when constructing the final, complex query, mitigating the blind spot."}, "weaknesses": {"value": "1. The \"SQL Components Pre-generation Reward\" is based on generating a minimum number of components (e.g., 2 for moderate, 3 for challenging). This rule-based reward could potentially be \"hacked\" by the model, which might learn to generate multiple incorrect or useless components just to satisfy the count and receive the reward. While the AST matching reward would counteract this by giving low scores to bad components, the pre-generation reward itself is not directly tied to the quality or utility of the components. \n2. The performance of the complexity analysis module feels like a potential weak link. The F1 scores for prediction (0.77, 0.75, 0.87)  are not exceptionally high. The paper argues this is a good thing, suggesting the model learns a more nuanced complexity \"beyond just component count\". However, this could also be a post-hoc justification. An error in this initial step (e.g., misclassifying a complex query as \"simple\") would cause the model to skip the pre-generation step entirely, leading to the very \"semantic blind spot\" problem this paper aims to solve.\n3. The authors acknowledge this in their conclusion. While AST matching is superior to n-gram matching, it is not a complete solution for semantic equivalence. Two SQL queries can be logically identical (e.g., a JOIN vs. a correlated subquery in the WHERE clause) but have completely different ASTs. The current normalization (removing aliases, sorting AND nodes)  is a good first step, but this reward mechanism may still unfairly penalize valid, alternative SQL queries."}, "questions": {"value": "1. The proposed reasoning paradigm is a multi-step process, which will inherently increase inference latency and computational cost compared to a single-pass generation. The paper critiques another method (Rex-SQL) for its high cost  but does not provide any analysis of its own method's overhead, which is a key practical consideration, especially in RL training."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dlBeCH6Kkh", "forum": "IysKdBVQ6y", "replyto": "IysKdBVQ6y", "signatures": ["ICLR.cc/2026/Conference/Submission23684/Reviewer_TWiP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23684/Reviewer_TWiP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23684/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761888489494, "cdate": 1761888489494, "tmdate": 1762942763621, "mdate": 1762942763621, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a key limitation in LLMs for complex Text-to-SQL tasks, which the authors term the \"semantic blind spot.\" This problem arises because LLMs generate SQL queries sequentially, token-by-token, making them unable to utilize information from parts of the query that have not yet been generated. To address this, the authors propose a two-stage reasoning approach: the model first analyzes query complexity and, for complex cases, pre-generates independent SQL components. These components then inform the second stage, where the final SQL query is constructed. Training uses reinforcement learning with an AST–based reward system that scores structural correctness via maximum connected subtree matching, offering greater robustness than text-based evaluation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1: The paper presents a novel viewpoint on a familiar issue in sequential generation by conceptualizing it as a “semantic blind spot.” Although breaking tasks into smaller components is not a new idea, the particular approach of first generating independent SQL elements and then combining them—guided by an advanced AST-based reward system—represents a creative and revitalized direction within the Text-to-SQL field.\n\nS2: The methodological approach is sound and well-justified. The proposed two-stage reasoning process, beginning with complexity analysis and proceeding to component pre-generation, directly addresses the identified problem. The use of RL with a custom AST-matching reward is a robust choice for guiding the model to produce structurally correct and independently meaningful SQL fragments.\n\nS3: The experimental design is rigorous, particularly the demonstration of cross-dataset generalization (training on BIRD, evaluating on SPIDER), which speaks to the robustness of the learned strategies rather than mere dataset overfitting. The detailed ablation studies further enhance the quality by systematically isolating the contributions of different components of the proposed method."}, "weaknesses": {"value": "W1:\nThe paper introduces a “semantic blind spot” and proposes “SQL component pre-generation” to address it. However, its approach—decomposing queries into smaller parts and recombining them—closely parallels existing Chain-of-Thought and task decomposition methods. The distinction between the proposed method and prior intermediate-step generation strategies remains unclear.\n\nW2:\nThe paper reports strong generalization by training on BIRD and testing on SPIDER. This may stem from BIRD’s inherent complexity rather than the method itself. Stronger evidence would come from reverse generalization—training on SPIDER and testing on BIRD—to assess transferability from simpler datasets.\n\nW3:\nWhile effective, the method adds costly training steps: complexity analysis, SQL pre-generation, and AST-based reward computation. The paper lacks analysis of the additional computational overhead, such as training time, GPU consumption, or inference latency."}, "questions": {"value": "Q1: The entire \"pre-generation\" strategy is predicated on the initial \"complexity analysis\" step, which determines if a query is \"simple,\" \"moderate,\" or \"challenging.\" Table 4 reveals that the F1 scores for this classification are modest (ranging from 0.77 to 0.87). This implies that a significant number of queries will be misclassified. Can the authors provide a detailed error analysis of this module?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gZbKprhyEo", "forum": "IysKdBVQ6y", "replyto": "IysKdBVQ6y", "signatures": ["ICLR.cc/2026/Conference/Submission23684/Reviewer_mVHC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23684/Reviewer_mVHC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23684/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997924425, "cdate": 1761997924425, "tmdate": 1762942763416, "mdate": 1762942763416, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge faced by large language models (LLMs) in generating complex SQL queries from natural language, specifically identifying a “semantic blind spot” problem: during sequential generation, LLMs have limited access to semantic information pertaining to pending SQL components, making it hard to accurately assemble complex queries. To mitigate this, the authors propose a complexity-guided SQL components pre-generation paradigm, whereby the model first generates independent semantic SQL components explicitly before rendering the final SQL query. This process is guided via reinforcement learning, employing the GRPO framework with a bespoke reward structure. Central to the approach is a maximum connected subtree matching reward mechanism based on SQL Abstract Syntax Trees (ASTs), which offers structurally informed, fine-grained feedback."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is clearly written, and the figures are easy to understand.\n\n2. The discussion on semantic blind spots in pending SQL components is meaningful and highlights a real limitation in current LLM-based SQL generation.\n\n3. Compared to existing methods focusing on improving LLM SQL reasoning, the proposed maximum connected subtree matching reward mechanism is novel."}, "weaknesses": {"value": "1. The main concern is that the proposed method only delivers marginal improvements and is sometimes even weaker than the baselines. As shown in Table 1, the method only achieves the best results on SPIDER-SYN, while on the other four datasets, it underperforms compared to the baselines. Since all baselines use LLMs of the same scale, the lower accuracy calls into question the effectiveness of the proposed framework.\n\n2. The authors claim the method addresses the challenge of generating complex SQL statements, but they do not evaluate on Spider2, which is more complex compared to BIRD and SPIDER. Instead, they mostly use the simpler Spider and its extensions for evaluation. This raises doubts about the method’s ability to handle truly complex SQL queries.\n\n3. Data in real SQL scenarios is different from public datasets and often lacks gold SQL queries. The proposed method depends on gold SQL-based AST construction and reward modeling, which casts doubt on its real-world usability and practicality.\n\n4. The paper lacks a discussion and comparison with a relevant baseline: Alpha-SQL: Zero-Shot Text-to-SQL using Monte Carlo Tree Search, which uses MCTS to improve the SQL reasoning abilities of local LLMs."}, "questions": {"value": "Please check the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "p51woj8DiV", "forum": "IysKdBVQ6y", "replyto": "IysKdBVQ6y", "signatures": ["ICLR.cc/2026/Conference/Submission23684/Reviewer_jJZB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23684/Reviewer_jJZB"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23684/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762009345429, "cdate": 1762009345429, "tmdate": 1762942762975, "mdate": 1762942762975, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}