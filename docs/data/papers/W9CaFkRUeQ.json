{"id": "W9CaFkRUeQ", "number": 9823, "cdate": 1758142169402, "mdate": 1759897693511, "content": {"title": "LLMAD-mini: Efficient Distilling Hierarchical Chain-of-Thought for Interpretable Log Anomaly Reasoning and Detection using Large Language Model", "abstract": "Log anomaly detection is critical for system reliability, yet most existing methods focus only on binary detection without providing explanations or identifying root causes, which limits their usefulness in production environments. To address these challenges, we propose LLMAD-mini, a lightweight LLM-based model that combines knowledge distillation with Low-Rank Adaptation (LoRA) fine-tuning to deliver strong reasoning and comprehensive log understanding. Large language models (LLMs) with human-interpretable descriptions can be tuned for specialized logs via supervised fine-tuning, but the high cost of training and deployment remains a major barrier. To achieve efficient adaption on small in-domain dataset on LLMs, we introduce a hierarchical Chain-of-Thought mechanism that significantly enhances reasoning capability with limited data. Evaluated on different system log datasets, LLMAD-mini surpasses traditional anomaly detection methods in detection accuracy and provides far better reasoning than much larger LLMs. Notably, it achieves a 3.2× improvement on reasoning quality compared to a LLM with 30× more parameters. Furthermore, our experiments on out-of-domain logs demonstrate LLMAD-mini’s ability to generalize across diverse systems with the improvement of 40% of accuracy on anomaly detection and improve the Bleu-4 from 0.01 to 0.49 while diagnosing failures, making it a practical and efficient solution for real-world deployment.", "tldr": "", "keywords": ["Chain-of-Thought", "Knowledge Distillation", "Large Language Model", "Anomaly Detection"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/545ca96a6f880f2d4f5c75e6930ce9c31c8ca7fa.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents LLMAD-mini, a method for efficient and interpretable log anomaly detection. The core innovation lies in using knowledge distillation to transfer a \"hierarchical Chain-of-Thought\" (CoT) reasoning capability from a large teacher LLM (like GPT-4) to a compact, fine-tuned student model. The proposed hierarchical CoT decomposes log analysis into four progressive stages: Event-wise, Stage-wise, Pattern, and Indicator CoT, aiming to capture the complex, non-sequential nature of system failures. The model is fine-tuned using Low-Rank Adaptation (LoRA), making it efficient to train and deploy. The authors demonstrate state-of-the-art performance on in-domain (OpenStack) and promising generalization on out-of-domain (HDFS) logs, outperforming both traditional methods and much larger LLMs in detection accuracy and, notably, the quality of generated explanations."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1，The paper provides strong, quantitative evidence of its effectiveness. LLMAD-mini achieves a near-perfect F1-score (0.97) on in-domain data, convincingly surpassing both traditional models and much larger LLMs. More impressively, it demonstrates remarkable out-of-domain generalization (0.72 F1 on HDFS) without any retraining. \n\n2，The model's primary output is not just a binary label but a structured, human-interpretable reasoning trace. The massive improvements in explanation quality (e.g., 41x in Rouge-2 for root cause analysis) are arguably as important as the detection accuracy."}, "weaknesses": {"value": "1， The literature review omits key recent works that are directly relevant to its core contributions. \n\n1.a.The concept of hierarchical reasoning in LLMs is advanced by works like GOT (Graph of Thoughts: Solving Elaborate Problems with Large Language Models), which frames problem-solving as a graph of interconnected thought steps. The presented hierarchical CoT is a specific instance of this broader idea. The failure to cite and differentiate from GOT weakens the claim of novelty for the overall hierarchical reasoning structure. \n\n1.b. In the specific domain of LLMs for log analysis, recent works like LogRAG: Semi-Supervised Log-based Anomaly Detection with Retrieval-Augmented Generation directly address similar challenges of interpretability and domain adaptation. Not comparing against such methods leaves the reader uncertain whether the performance gains are due to the hierarchical CoT or could be achieved by other emerging paradigms like RAG.\n\n2. This limitation impacts the validity of the paper's central claim of strong generalization. While the HDFS dataset provides an out-of-domain test, the ecosystem of system logs is vastly more diverse (e.g., distributed databases, microservices, embedded systems). Robustness across a wider array of log formats and system types is required to substantiate the claim that the model learns \"fundamental system principles.\" Without this, the results may be overfitted to the characteristics of cloud infrastructure and distributed file system logs.\n\n3. The proposed four-level hierarchy is central to the method, but its design is presented as-is. An ablation study (e.g., removing Pattern CoT or Indicator CoT) is necessary to demonstrate that each level contributes uniquely to the final performance. Without it, it is unclear if the full complexity is warranted or if a simpler hierarchy would suffice.\n\n4. The case study, while illustrative, is qualitative. There is no quantitative metric to evaluate the correctness of the reasoning trace itself, only its similarity to the teacher's output (via BLEU, ROUGE)."}, "questions": {"value": "1. The concept of hierarchical reasoning in LLMs shares a clear conceptual similarity with frameworks like Graph of Thoughts (GOT), which generalizes reasoning into a graph structure. Could you discuss how your hierarchical CoT differs from or builds upon such prior work on advanced reasoning structures? Specifically, what is the justification for a fixed four-level hierarchy versus a more flexible, graph-like reasoning process?\n\n2. In the domain of LLM-based log anomaly detection, several recent works have proposed methods for improved interpretability and handling of domain-specific knowledge. Notably, LogRAG uses Retrieval-Augmented Generation for a similar goal. Could you explain why these works were not included in your related work or empirical comparison? Have you considered a comparison with such methods to better delineate the unique advantages of your knowledge distillation approach versus RAG-based approaches?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dxrwnVr0U3", "forum": "W9CaFkRUeQ", "replyto": "W9CaFkRUeQ", "signatures": ["ICLR.cc/2026/Conference/Submission9823/Reviewer_x56h"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9823/Reviewer_x56h"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9823/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761879188439, "cdate": 1761879188439, "tmdate": 1762921308541, "mdate": 1762921308541, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes LLMAD-mini, a compact LLM-based framework for interpretable log anomaly detection. It uses knowledge distillation from a large teacher LLM (e.g., GPT-4) to train a smaller student model (8B parameters) with a novel hierarchical Chain-of-Thought (CoT) reasoning structure (event-wise, stage-wise, pattern, and indicator levels). The model is fine-tuned using LoRA and evaluated on OpenStack and out-of-domain HDFS logs. It reports strong performance in both anomaly detection (F1=0.97 in-domain) and reasoning quality (e.g., 3.2× higher BLEU-4 than much larger LLMs), with claims of efficiency and generalization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1. Proposes a domain-tailored hierarchical reasoning structure that aligns well with the multi-level nature of system logs. \nS2. Shows compelling empirical gains in both detection accuracy and automatic reasoning metrics over strong baselines, including very large LLMs.  \nS3. Highlights the practical advantage of a lightweight, trainable model (2 hours on one GPU) suitable for real-world deployment.  \nS4. Includes out-of-domain evaluation (HDFS), suggesting some degree of generalization beyond the training distribution. \nS5. Provides a detailed case study that illustrates the reasoning process concretely."}, "weaknesses": {"value": "W1. Teacher-generated CoT data lacks transparency: no details on prompt design, few-shot examples, or validation of teacher output quality.  \nW2. Small dataset size (450 sequences) limits the robustness of conclusions; results may not generalize to larger or noisier log corpora. \nW3. Evaluation relies solely on automatic metrics (BLEU, ROUGE) for reasoning quality, which are known to correlate poorly with human judgment, especially for technical explanations. \nW4. Out-of-domain evaluation is limited to a single dataset (HDFS); broader cross-system generalization remains unproven."}, "questions": {"value": "1. How were the teacher LLM’s CoT traces validated for correctness and completeness? Were they manually checked?\n2. Would performance degrade significantly with fewer training sequences (e.g., <100)? \n3. How sensitive are the results to the choice of base model (Qwen3-8B)? Would the approach work with even smaller models (e.g., 1B)?\n4. Have you considered human evaluation (e.g., with SREs) to assess the usefulness of the generated explanations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8rx9pNwuHA", "forum": "W9CaFkRUeQ", "replyto": "W9CaFkRUeQ", "signatures": ["ICLR.cc/2026/Conference/Submission9823/Reviewer_mhAc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9823/Reviewer_mhAc"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9823/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761886349918, "cdate": 1761886349918, "tmdate": 1762921308144, "mdate": 1762921308144, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper develops a two llm framework for log anomaly detection. This is a simple application paper of LLMs on log anomaly detection problem."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper demonstrates improvements on all fronts of testing, accuracy and F1 scores are better. Bleu-4 score is better. On every table, with the HDFS dataset the scores are better.\n\n- The paper is easy to read and well explained."}, "weaknesses": {"value": "- The paper puts together many components well available in a simple way and demonstrates improvement.\nBeyond that, there is nothing interesting in the paper. \n\n- The ideas of chain of thought and hierarchical Reasoning is presented in a hand wavy manner and does not constitute for any novel insights."}, "questions": {"value": "I neither like nor hate the paper. The paper is well below the novelty threshold for a premier conference in my opinion. However, I will not fight acceptance if other reviewers think the paper has merit."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Q7mC8ego0x", "forum": "W9CaFkRUeQ", "replyto": "W9CaFkRUeQ", "signatures": ["ICLR.cc/2026/Conference/Submission9823/Reviewer_PS1U"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9823/Reviewer_PS1U"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9823/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761922758807, "cdate": 1761922758807, "tmdate": 1762921307704, "mdate": 1762921307704, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes LLMAD-mini, a lightweight log anomaly detection model that addresses limitations of traditional methods (lack of interpretability, poor generalization) and large language models (LLMs, high deployment costs, weak domain adaptation). The model combines knowledge distillation (transferring reasoning from large \"teacher\" LLMs like GPT-4) with Low-Rank Adaptation (LoRA) fine-tuning and a novel hierarchical Chain-of-Thought (CoT) mechanism (event-wise, stage-wise, pattern, and indicator CoT)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The work demonstrates originality through creative integration of existing techniques for a specialized domain. The hierarchical CoT mechanism addresses a key limitation of linear CoT (insufficient for non-sequential log anomaly causality) by decomposing reasoning into four complementary stages.\n2. The experimental design is rigorous and comprehensive. The authors use two distinct datasets (OpenStack for in-domain, HDFS for out-of-domain) to evaluate both detection performance (Precision/Recall/F1) and reasoning quality (Bleu-4/Rouge metrics), addressing key gaps in prior work.\n3. The work addresses critical real-world challenges for system reliability. Traditional log anomaly methods fail to provide actionable insights (e.g., root causes), while large LLMs are impractical for deployment—LLMAD-mini resolves both by delivering interpretable, accurate, and efficient detection. Its cross-domain generalization (40% accuracy improvement on HDFS logs) is particularly impactful for production environments with heterogeneous systems."}, "weaknesses": {"value": "1. The paper presents the hierarchical CoT as a unified mechanism but does not evaluate the contribution of individual components (event-wise, stage-wise, pattern, indicator CoT). It is unclear whether all four stages are necessary, or if some are redundant. \n2. Insufficient Discussion of Dataset Bias and Generalization Boundaries. The OpenStack dataset is curated to include only \"complete instance lifecycles\" (filtering 80% of raw data), which may introduce bias toward well-structured log sequences. Real-world logs often contain incomplete traces, noise, or non-lifecycle-related events—how would LLMAD-mini perform on unfiltered, messy logs?\n3. While the paper includes baselines like LogBERT (a BERT-based fine-tuned model) and general-purpose LLMs, it does not compare to recent LLM-based log anomaly methods that use fine-tuning or prompt engineering with domain adaptation. \n4. The paper highlights high performance but does not analyze the model’s failure cases. For example: Are there specific anomaly types (e.g., subtle performance degradations vs. catastrophic failures) where LLMAD-mini struggles? Does the model’s reasoning trace contain errors even when classification is correct? How does the model handle log sequences with ambiguous anomalies (e.g., events that could be normal or anomalous depending on context)?"}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MPJ7erGDCA", "forum": "W9CaFkRUeQ", "replyto": "W9CaFkRUeQ", "signatures": ["ICLR.cc/2026/Conference/Submission9823/Reviewer_4oma"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9823/Reviewer_4oma"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9823/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761964218419, "cdate": 1761964218419, "tmdate": 1762921307318, "mdate": 1762921307318, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}