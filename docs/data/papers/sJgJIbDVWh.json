{"id": "sJgJIbDVWh", "number": 18262, "cdate": 1758285741391, "mdate": 1759897115800, "content": {"title": "Scalable Graph Kernels with Continuous Attributes", "abstract": "We introduce the Neighborhood Subgraph Pairwise Path Kernel (NSPPK), a scalable\nand interpretable graph kernel for attributed graphs. NSPPK compares\nneighborhoods connected through unions of shortest paths and directly integrates\ncontinuous node features without discretization. This yields explicit, sparse\nembeddings where graph similarities reduce to a single dot product. Feature\nextraction scales near-linearly, parallelizes efficiently, and is fully\ndeterministic. Across six benchmarks with continuous attributes, NSPPK achieves\nthe best average rank among graph kernels and frequently matches or outperforms\nmodern GNNs—without any training or hyperparameter tuning. By combining\nscalability, interpretability, and expressive power, NSPPK offers a practical\nalternative for graph learning in low-data or reproducibility-critical settings.\nIts advantage lies in working robustly when data is scarce, yet scaling efficiently\nto hundreds of thousands of graphs when data is abundant.", "tldr": "We propose NSPPK, a scalable graph kernel that enriches neighborhood features with path connectors and integrates continuous attributes directly, yielding explicit embeddings that rival or surpass GNNs without training or hyperparameter tuning.", "keywords": ["Graph kernels", "Continuous node attributes", "Scalable graph learning", "Explicit graph embeddings"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ffd1f3f1b89be35f4ca95466a31307ab4ccc01f3.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents a graph kernel which generalizes the NSPDK kernel [1] and improves its expressive power. Unlike the NSPDK kernel, which considers only the distance between two nodes of a graph, the proposed kernel also takes into account the subgraph induced by the shortest paths connecting those two nodes. The kernel is evaluated on 6 small-scale and 1 large-scale graph classification dataset. The results indicate that the proposed kernel achieves high classification accuracies on the small-scale datasets and is competitive with the baselines.\n\n[1] Costa, F., & De Grave, K. Fast neighborhood subgraph pairwise distance kernel. In ICML'10."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The presented empirical results demonstrate that the proposed NSPPK kernel can achieve high classification accuracies on the node-attributed graph classification benchmark datasets, as it outperforms the other kernels on 2 out of the 6 considered datasets and the graph neural networks on 4 out of the 6 datasets. \n\n- The example in Figure 1 serves as a motivation for the proposed kernel and demonstrates that it can produce features distinct from those of the NSPDK kernel from which it draws inspiration. Furthermore, the NSPPK kernel outperforms NSPDK in the empirical evaluation.\n\n- The authors demonstrate that, due to the explicit feature maps that it produces, the kernel can be applied to very large datasets containing hundreds of thousands of samples."}, "weaknesses": {"value": "- The presentation in Section 4 is unclear in several places. In particular, Subsection 4.3, which describes the features produced by the kernel, lacks clarity and would benefit from revision. It is difficult for the reader to understand what the features of $f_G^\\theta$ correspond to. Also Subsection 4.5 needs to be revised since it is not clear how continuous features are exactly handled by the kernel. \n\n- The authors show that the proposed kernel produces features which are not produced by the NSPDK kernel. However, I would suggest they also provide two non-isomorphic graphs which are both embedded to the same feature vector by NSPDK, but to different feature vectors by the proposed kernel.\n\n- As discussed above, the proposed kernel outperforms the baseline kernels on 2 out of the 6 datasets. However, the improvements offered by the proposed kernel are only marginal (less that 1% absolute difference in average accuracy).\n\n- The NSPPK can also compute explicit feature vectors for graphs whose nodes are assigned discrete labels. The paper would be strengthened if the authors also evaluated the kernel on benchmark datasets that contain such graphs (e.g., MUTAG, NCI1). As these datasets are well-studied, such an evaluation would clarify whether the kernel can compete with state-of-the-art approaches.\n\n- The hyperparameters $R$ and $D$ cannot take large values since this will largely increase the computational complexity of the kernel. Furthermore, the complexity analysis presented in Subsection 4.6 seems incomplete since it does not consider the time to compute the neighborhood pair hash (which requires the rooted graph hash, etc.)"}, "questions": {"value": "Why aren't Tables 1 and 2 merged into a single Table? It is clear to me that the results of Table 1 are produced by the SVM classifier and those of Table 2 by XGBoost, but I would suggest the authors merge the two Tables and use two rows for the proposed kernel (one row for each classifier) or just report the results produced by SVM."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Bg4fvhGUaD", "forum": "sJgJIbDVWh", "replyto": "sJgJIbDVWh", "signatures": ["ICLR.cc/2026/Conference/Submission18262/Reviewer_49hc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18262/Reviewer_49hc"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18262/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761410915845, "cdate": 1761410915845, "tmdate": 1762927986830, "mdate": 1762927986830, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces the Neighborhood Subgraph Pairwise Path Kernel (NSPPK), a scalable and interpretable graph kernel designed for attributed graphs. NSPPK extends the NSPDK kernel by enriching the structural context through unions of shortest-path neighborhoods and directly integrating continuous node features without discretization. The method produces explicit, sparse graph-level embeddings that allow efficient similarity computation and scales near-linearly in the number of nodes and edges."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper presents a well-motivated extension of NSPDK that meaningfully increases expressiveness by incorporating shortest-path unions and continuous features.\n\nNSPPK yields explicit sparse graph embeddings, making similarity evaluation efficient (single dot product) and enabling easy downstream application with classical classifiers."}, "weaknesses": {"value": "Although the method is positioned as scalable, it is not compared against recent GNNs explicitly designed for large-scale settings (e.g., GraphSAINT, Cluster-GCN), nor against more recent graph transformer models such as GraphGPS. These baselines are directly relevant for claims regarding scalability and competitiveness.\n\nFigure 4 shows that many NSPPK+classifier combinations either degrade in accuracy or do not significantly improve runtime relative to GNNs, except for the XGBoost pairing. A deeper discussion is needed to explain why certain classifier pairings behave poorly.\n\nThe “training-free” claim may be somewhat overstated, as classification performance still depends on training a downstream model (e.g., XGBoost, logistic regression). Clarifying this distinction would improve the positioning of the work."}, "questions": {"value": "The experimental setup states that GPU clusters with A100s were used, which seems a lot given the model size is small. Could you clarify whether any part of NSPPK relies heavily on GPU acceleration, or if this was only for baselines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rXDE2CBogl", "forum": "sJgJIbDVWh", "replyto": "sJgJIbDVWh", "signatures": ["ICLR.cc/2026/Conference/Submission18262/Reviewer_iBo3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18262/Reviewer_iBo3"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18262/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761885223648, "cdate": 1761885223648, "tmdate": 1762927986401, "mdate": 1762927986401, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the Neighborhood Subgraph Pairwise Path Kernel (NSPPK), a hash-based graph kernel extending NSPDK by augmenting neighborhood pairs with unions of shortest paths and by directly integrating continuous attributes. The method produces explicit, sparse feature embeddings that support efficient similarity computation via a single dot product. Experiments show near-linear scalability and competitive accuracy across six small graph benchmarks and the large-scale OGB-molpcba dataset. The presentation is clear, and the proposed feature extraction pipeline is reproducible and well-documented. However, the methodological difference from NSPDK remains moderate, and the paper would benefit from stronger conceptual framing and analysis."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- The paper offers a clear, implementation-ready description of a scalable graph kernel that can serve as a deterministic baseline for graph learning tasks.\n- The hash-based feature construction is explained with care, and the algorithmic complexity is well analyzed.\n- The empirical evaluation is extensive and includes ablations and runtime studies, illustrating the method’s practical utility and scalability."}, "weaknesses": {"value": "- Since one of NSPPK’s key claims is direct handling of continuous node attributes, the paper could clarify how NSPPK differs from the latest work, like MMD-GK (ICLR 2024), SWWL (AISTATS 2024), Distributional Shortest-Path Graph Kernels (TKDE 2025), etc.\n\n- The main technical idea, augmenting NSPDK with unions of shortest paths, is a natural extension. Yet to strengthen its originality, the authors could more clearly identify the theoretical implications of the connector structure. For instance, does it increase expressivity beyond the 1-WL limit? Under what structural conditions does the union-of-paths representation lead to new graph distinctions? A short analysis or theorem along these lines would make the contribution more substantial.\n\n- While the ablation shows that the connector improves performance, it is unclear why or when it helps. Perhaps some qualitative case studies or a visualization of connector-induced subgraphs would make this component more interpretable."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NL09kSceoX", "forum": "sJgJIbDVWh", "replyto": "sJgJIbDVWh", "signatures": ["ICLR.cc/2026/Conference/Submission18262/Reviewer_wKc1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18262/Reviewer_wKc1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18262/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761903780854, "cdate": 1761903780854, "tmdate": 1762927985670, "mdate": 1762927985670, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces the Neighborhood Subgraph Pairwise Path Kernel (NSPPK), a novel, graph kernel designed to compare attributed graphs. The main contributions of NSPPK are its ability to use continuous attributes without discretization and its use of a structural feature that combines local neighborhoods with the union of shortest paths. NSPPK enables fast, deterministic similarity calculations and achieves competitive performance on several benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The primary strength of this model is the balance of performance and efficiency. It is a highly practical and deterministic method, unlike deep GNNs. It demonstrates a sample efficiency outperforming them on medium-sized benchmarks without extensive hparam tuning."}, "weaknesses": {"value": "- The paper promotes the use of a single, fixed set of hyperparameters (e.g., $R=1, D=4, R'=1$) across all experiments (no per-dataset tuning) However, these parameters likely represent an optimal configuration for the specific characteristics of biological and chemical graphs. The paper does not include a sensitivity analysis to show how performance changes when these parameters are varied, nor does it benchmark against graphs with fundamentally different structures (e.g., social or financial networks). These \"magic numbers\" might not be universally robust for a new domain could undermine the claim of being a training-free, highly generalized approach.\n- The complexity of the NSPPK feature extraction is dependent on the node degree, which suggests that the method's efficiency advantage may be restricted to the sparse graphs typically found in the tested biological or chemical domains. The paper fails to provide essential dataset statistics like the average/maximum degree, and it avoids benchmarking on large, dense graphs (such as specific social or financial network datasets). In these settings, the claimed near-linear scalability may quickly degrade, potentially making the kernel less practical than suggested.\n- The paper's literature survey focuses on graph kernel and is weak in acknowledging and citing key related works that leverage multi-scale structural encoding or subgraph patterns. It would be nice if the authors can acknowledge them including … \n  - HDSE: Enhancing Graph Transformers with Hierarchical Distance Structural Encoding\n  - ELENE: Improving Subgraph-GNNs via Edge-Level Ego-Network Encodings\n  - SPSE: Simple Path Structural Encoding for Graph Transformers\n  - WLKS: Generalizing Weisfeiler-Lehman Kernels to Subgraphs\n  - G3N: $\\mathscr{N}$-WL: A New Hierarchy of Expressivity for Graph Neural Networks\n  - SEAL: Link Prediction Based on Graph Neural Networks\n  - Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks\n- The assertion that NSPPK is interpretable is not evaluated with a qualitative analysis. Since the method aggregates continuous node attributes into hash buckets, the resulting feature vector represents a complex sum of attributes over various, possibly colliding, substructures. This lack of clear, direct feature-to-substructure correspondence introduces a form of ambiguity that is simply a different type of black-box.\n- While the authors state that NSPPK is designed to handle continuous edge attributes, the paper does not provide their integration with attributes other than nodes. More importantly, all reported experimental results and benchmarks focus solely on node-attributed graphs. The authors can choose between (1) narrowing down the scope to the node-attr model or (2) providing the edge-attr model and benchmark.\n- The paper's argument for the superior discriminative power of NSPPK is largely empirical, relying on a single visual example (Figure 1) to show its advantage over NSPDK. The work lacks a formal theoretical proof defining its exact expressive power."}, "questions": {"value": "- Why is the font somewhat different from other iclr submissions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "67Va8KqxeY", "forum": "sJgJIbDVWh", "replyto": "sJgJIbDVWh", "signatures": ["ICLR.cc/2026/Conference/Submission18262/Reviewer_vjJF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18262/Reviewer_vjJF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18262/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761956585704, "cdate": 1761956585704, "tmdate": 1762927984968, "mdate": 1762927984968, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}