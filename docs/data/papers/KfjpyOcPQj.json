{"id": "KfjpyOcPQj", "number": 6560, "cdate": 1757988965486, "mdate": 1759897907900, "content": {"title": "Reducing Class-Wise Performance Disparity via Margin Regularization", "abstract": "Deep neural networks often exhibit substantial disparities in class-wise accuracy, even when trained on class-balanced data—posing concerns for reliable deployment. While prior efforts have explored empirical remedies, a theoretical understanding of such performance disparities in classification remains limited. In this work, we present Margin Regularization for performance disparity Reduction ( $MR^2$ ), a theoretically principled  regularization for classification by dynamically adjusting margins in both the logit and representation spaces. Our analysis establishes a novel margin-based, class-sensitive generalization bound that reveals how per-class feature variability contributes to error, motivating the use of larger margins for ''hard'' classes. Guided by this insight,$MR^2$ optimizes per-class logit margins proportional to feature spread and penalizes excessive representation margins to enhance intra-class compactness.\nExperiments on seven datasets—including ImageNet—and diverse pre-trained backbones (MAE, MoCov2, CLIP) demonstrate demonstrate that our $MR^2$ not only improves overall accuracy but also significantly boosts ''hard'' class performance without trading off ''easy'' classes, thus reducing the performance disparities. Codes are available in Supplementary Materials.", "tldr": "We propose MR^2, a theorical grounded margin regularization framework that reducing class-wise performance gap without sacrificing overall accuracy, validated across seven datasets including ImageNet, and foundation models like MAE, MoCov2, and CLIP.", "keywords": ["image classification", "class-wise performance gap"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d2151ac81c510b5e2ff351252e1d597b17620b91.pdf", "supplementary_material": "/attachment/556d96037eeaba275e1fcc486b318ced442d8dd7.zip"}, "replies": [{"content": {"summary": {"value": "The paper presents MR$^2$, a novel objective function for training DNNs with reduced inter-class performance disparity and improved generalization. The MR$^2$ objective consists of a margin scaled cross-enropy loss and representation regularization term for encouraging intra-class feature compactness. It's shown that the proposed methods is connected to logit margin loss and contrastive learning and can tighted generalization bound. Extensive experimental results on image classification are provided to validate the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper addresses a largely overlooked issue: inter-class performance disparity under class-balanced setting.\n2. The paper provideds extensive theoretical analysis to justify the proposed method by linking it to $\\gamma$-margin loss and generalization bound.\n3. Comprehensive experimental results are presented."}, "weaknesses": {"value": "1. The loss in Eq. 1 can be regarded as cross-entropy loss with class-dependent temperature scaling. Temperature scaling has been studied a lot in knowledge distillation and model calibration. It's better to discuss and compare with some of those methods such as [1].\n2. In experiments, it's better to compare with more methods that promote class separability, such as [2], [3] and [4].\n3. The statement \"hard classes ... to such classes\" in Line 137~140 seems to assume that $||\\hat{\\mu}_y||$ is roughly constant across all classes so the margin mainly depends on $||\\hat{s}_y||$. It's better to provide evidence to support that $||\\hat{\\mu}_y||$ roughly stays constant across classes.\n4. All experiments on ImageNet are based on fine-tuning. It's better to provide some results for training from scratch on ImageNet, even just for small models such as ResNet-18 and ViT-tiny.\n5. It's mentioned that advanced augmentation strategies are avoided in experiments. However, it's better to show results with those augmentations to show the effectiveness of the proposed method when combined with modern augmentaion settings.\n\n[1] K. Xu et al. Feature Normalized Knowledge Distillation for Image Classification. ECCV 2020.\n[2] Y. Wen et al. A discriminative feature learning approach for deep face recognition. ECCV 2016.\n[3] W. Wan et al. Rethinking Feature Distribution for Loss Functions in Image Classification. CVPR 2018.\n[4] EH. Yang et al. Conditional mutual information constrained deep learning for classification. TNNLS 2025."}, "questions": {"value": "1. Would it be better to make $\\gamma$ trainable after initialization according to Eq. 1?\n2. In Fig. 5, how can $\\bar{c}$ be 0? This will lead to a \"dividing by 0\" error in Eq. 1."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "N0IT3jMGPB", "forum": "KfjpyOcPQj", "replyto": "KfjpyOcPQj", "signatures": ["ICLR.cc/2026/Conference/Submission6560/Reviewer_dj7P"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6560/Reviewer_dj7P"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6560/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761689660024, "cdate": 1761689660024, "tmdate": 1762918899859, "mdate": 1762918899859, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This study aims to address the problem of class disparity that arises in classification under balanced settings. To this end, the authors propose regularizers that control the margins in both the logit and representation spaces, assigning larger margins to more challenging classes to achieve balance in the error bound. Furthermore, the paper provides theoretical evidence supporting the effectiveness of the proposed approach through well-formulated theorems and corresponding proofs. In addition, extensive empirical evaluations across various datasets, including fine-grained datasets, as well as architectures such as CLIP, demonstrate the effectiveness of the proposed method"}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "* By providing background on the class disparity problem—an increasingly critical issue in modern classification settings—and analyzing its underlying causes, this study effectively establishes the motivation for addressing this problem\n\n* The study also supports the validity of the proposed approach with solid theoretical analysis, comprising precisely stated theorems and corresponding proofs\n\n* Furthermore, extensive experiments conducted on a wide range of datasets, including fine-grained benchmarks, and on architectures such as CLIP, confirm the robustness of the proposed approach. Ablation studies (e.g., main component analysis, effect of $\\bar{c}$ and $\\lambda$) also demonstrate its effectiveness"}, "weaknesses": {"value": "**W1.** As illustrated in Eq. 13 (lines 286–291), there exists a trade-off between the first and second terms depending on the value of $\\gamma$. Although this trade-off is bounded through Corollary 1, further tuning of the coefficient $\\bar{c}$ is still required. This remains a tuning issue, in combination with another hyperparameter $\\lambda$, which increases the overall burden of hyperparameter tuning.\n\n**W2.** The proposed approach indirectly verifies its effectiveness in addressing the class disparity problem through performance improvement. However, it would be more convincing to more directly validate whether the margins for hard classes have indeed increased, using metrics such as the class margin introduced in [R1].\n\n**W3.** The related work section provides a thorough review of not only other works on class disparity but also long-tail learning, which is a similar area of work in that it focuses on controlling class margins. However, despite the presence of conceptually related approaches in hyperspherical learning—such as those that separately control the margins between classes and samples or adjust margins according to sample difficulty, as shown in [R1,R2]—the paper does not include a survey or discussion of hyperspherical learning.\n\n\n[R1] Zhou et al., Learning Towards the Largest Margins, ICLR 2022\n\n[R2] Son et al., Difficulty-aware Balancing Margin Loss for Long-tailed Recognition, AAAI 2025"}, "questions": {"value": "**Q1** (w.r.t **W1**). Ablation studies on CIFAR-100 using ResNet-32 were conducted to examine hyperparameter tuning; however, since they are limited to a single dataset, providing additional insights could help alleviate concerns about tuning sensitivity. For instance, is there any guideline on how to adjust hyperparameter values—such as increasing or decreasing them—depending on the number of samples or labels?\n\n**Q2.** Although the proposed method shows improved performance compared to other approaches across various experiments, the class disparity still appears to remain severe. Could the authors provide a more detailed explanation of why the issue has not been completely resolved, along with potential limitations or directions for future work to address it?\n\n**Q3.** How many times were the experiments conducted with different random seeds? To address concerns about potential cherry-picking and demonstrate the robustness of the results across different random environments, please provide this information.\n\n\n**Things to improve the paper that did not impact the score**:\n\n* (lines 022-023) typo: \"demonstrate demonstrate\"\n\n* (line 800) In Eq. 39, $a'\\_{y}$ and $b'\\_{y}$ newly appear without being mentioned or defined (it seems a typo error for $a\\_{y'}$ and $b\\_{y'}$)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NSWlLKYRd5", "forum": "KfjpyOcPQj", "replyto": "KfjpyOcPQj", "signatures": ["ICLR.cc/2026/Conference/Submission6560/Reviewer_5Lxp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6560/Reviewer_5Lxp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6560/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990570016, "cdate": 1761990570016, "tmdate": 1762918899498, "mdate": 1762918899498, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a Margin loss for the balanced datasets, which tries to balance the variance in hard classes by using a larger margin. The margin loss is theoretically explained by proving a bound on the Rademacher complexity. Experiments have been provided on numerous datasets such as CIFAR-100, Pets, ImageNet etc."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Paper introduces a theoretically motivated solution to the problem.\n\n2. The paper is well structured with relevant experiments."}, "weaknesses": {"value": "1. Experiments are done on an older setup: I find that the experiments are done on older SOTA setups. The newer setups, like Sharpness Aware Minimization (SAM) [R1], WideResNets, have not been considered for comparison. Hence, the performance reported for datasets like CIFAR-10 and ImageNet is much lower than the current SoTA. Further, the margin-based algorithms like LDAM, compared with MR2, perform much better when compared to SAM [R2].\n\n2. Missing Comparison: There are some contrastive learning methods that use Supervised Labels, like SupCon. As MR2 also uses lables it would be better to compare with them. It would be great to see some comparison with SotA (State-of-the-Art) frameworks in mind. \n\n3. Novelty: I find the novelty of the paper to be a little limited, as I found an existing paper that talks about balancing the feature across classes [R3]. Further, a lot of the theoretical ideas are similar to those presented in Cortes et al. 2025 [R4].\n\n[R1] Foret, Pierre, et al. \"Sharpness-aware minimization for efficiently improving generalization.\" arXiv preprint arXiv:2010.01412 (2020).\n\n[R2] Rangwani, Harsh, Sumukh K. Aithal, and Mayank Mishra. \"Escaping saddle points for effective generalization on class-imbalanced data.\" Advances in Neural Information Processing Systems 35 (2022): 22791-22805.\n\n[R3] Zhong, Ke, et al. \"Class-Center-Based Self-Knowledge Distillation: A Simple Method to Reduce Intra-Class Variance.\" Applied Sciences 14.16 (2024): 7022.\n\n[R4] Cortes, Corinna, et al. \"Balancing the scales: A theoretical and algorithmic framework for learning from imbalanced data.\" arXiv preprint arXiv:2502.10381 (2025)."}, "questions": {"value": "Could the authors explain the difference in theoretical ideas from Cortes et al. (2025)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HPK2kWL8Ws", "forum": "KfjpyOcPQj", "replyto": "KfjpyOcPQj", "signatures": ["ICLR.cc/2026/Conference/Submission6560/Reviewer_aWLX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6560/Reviewer_aWLX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6560/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762114661735, "cdate": 1762114661735, "tmdate": 1762918899168, "mdate": 1762918899168, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this work, the authors propose a margin-based regularization framework to mitigate performance disparities between “hard” and “easy” classes that persist even when the training data are class-balanced. They begin by empirically showing that class-wise accuracy differences correlate with disparities in feature variance and margin distribution across classes. Building on this observation, the authors introduce a modification to the cross-entropy loss composed of two complementary terms: a logit-level margin regularizer that adaptively scales per-class margins based on feature variability, and a representation-level regularizer that enforces intra-class compactness by minimizing the spread of embeddings around each class mean.\n\nThe paper then provides theoretical analysis, first deriving an upper bound on the standard cross-entropy loss via their margin-regularized formulation, and subsequently identifying the optimal hyperparameter configuration that minimizes this bound. The analysis is further extended to normalized embedding spaces—commonly used in contrastive and transformer architectures—showing similar generalization guarantees and optimal margin design.\n\nFinally, the authors conduct extensive experiments, training from scratch on smaller datasets such as CIFAR-100 and fine-tuning or linearly probing large pre-trained models on ImageNet and other fine-grained datasets. Across all cases, the proposed method improves the accuracy of “hard” classes without degrading, and sometimes even enhancing, performance on “medium” and “easy” classes. The authors also include ablations showing the robustness of their results to the choice of hyperparameters."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is clearly written, and the ideas it explores are relevant to our broader understanding of optimization. The theoretical outline is well presented and easy to follow, and the experimental setup is generally sound and consistent with prior work. The proposed approach makes a meaningful contribution by improving performance on hard classes without hurting the easier ones, leading to a more balanced overall accuracy across classes."}, "weaknesses": {"value": "**W1)**: I believe this work, given its focus on margin geometry and embedding compactness, overlooks a closely related and highly relevant area known as Neural Collapse (Papyan et al., 2020). This phenomenon shows that in over-parameterized networks—such as those considered in this paper—class embeddings tend to collapse to a single prototype per class with maximal inter-class separation as training progresses. Subsequent works have analyzed Neural Collapse under class imbalance (Behnia et al., 2023), supervised contrastive losses (Kini et al., 2023), and in relation to generalization and transfer learning (Galanti et al., 2021). Even more recently, Neural Collapse principles have been extended to other domains such as federated learning, where margin adjustment inspired by NC has been proposed to address class imbalance (Li et al., 2025).\n\nFrom a theoretical standpoint, if we follow the Neural Collapse arguments, the regime where $ ||s_y|| \\to 0$  would eventually reduce the proposed loss to standard cross-entropy, since the representation compactness term becomes inactive and the per-class margins converge. This connection appears important but is not acknowledged or discussed in the paper. While the authors do a solid job referencing prior work on logit adjustment and class-wise accuracy imbalance, they omit this major line of research that directly studies how margin-controlled and embedding-controlled objectives influence model geometry and generalization. I would be interested to see the authors comment on this relation during the discussion period, given the conceptual overlap between their margin regularization intuition and the Neural Collapse framework. Much of the NC work struggles with how to relate the geometry of features during training to generalization and much of the theoretical upper bound for optimal geometry struggle in practice on improving test performance.\n\n**W2)**: While the authors primarily focus on the margins of hard versus easy classes, their evaluation relies solely on accuracy as the performance metric. Although the reported improvements are clear and likely related to the margin and embedding-spread–based logit adjustments, additional experimental analysis would help solidify these claims. In particular, it would be useful to visualize how the margins and the $s_y$ parameter evolve during training under their objective. Without such analysis, it remains unclear how much of the observed improvements stem from the proposed margin regularization itself versus other implicit effects of regularization."}, "questions": {"value": "**Q1:**  \nIn line 289, the authors mention that overtly increasing the value of the margin parameter is not desirable and may lead to a higher empirical margin. Could the authors expand on this point and provide a more precise theoretical explanation? I find this statement somewhat unclear. A related follow-up question is how, according to the proposed loss terms, simply reducing the inter-class spread parameter $s_y$ to zero would not already minimize the overall loss objective.  \n\n**Q2:**  \nWhy do the authors not evaluate their method under class imbalance settings? From my reading of the results, the imbalance scenario should conceptually produce a similar difference in margin distribution as the one discussed here. This relationship has been explicitly examined in the Neural Collapse literature (Fang et al., 2021). Furthermore, given that the ImageNet dataset already exhibits some class imbalance, wouldn’t the improvements observed on it indirectly reflect performance under imbalance? Am I correct to assume that classical ImageNet is indeed imbalanced?  \n\n**Q3:**  \nWere the experiments involving other architectures and loss formulations conducted only in the fine-tuning stage, rather than full training? If so, do the authors believe that training from scratch on harder benchmarks such as ImageNet with their loss formulation would yield noticeable improvements?  \n\n**Q4:**  \nRegarding the representation margin term, is this component designed to enforce a balance on the value of $\\bar{s}$—that is, to keep it small but non-zero? Could the authors elaborate on this point or clarify whether any part of their theoretical analysis addresses the optimal regime or equilibrium value of this term?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "6RnRMjdQDM", "forum": "KfjpyOcPQj", "replyto": "KfjpyOcPQj", "signatures": ["ICLR.cc/2026/Conference/Submission6560/Reviewer_MUKn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6560/Reviewer_MUKn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6560/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762149248566, "cdate": 1762149248566, "tmdate": 1762918898869, "mdate": 1762918898869, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}