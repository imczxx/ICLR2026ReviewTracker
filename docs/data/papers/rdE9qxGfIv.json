{"id": "rdE9qxGfIv", "number": 14334, "cdate": 1758232923057, "mdate": 1759897376616, "content": {"title": "Enhancing Complex Symbolic Logical Rea­soning of Large Language Models via Sparse Multi-Agent Debate", "abstract": "Large language models (LLMs) struggle with complex logical reasoning. Previous work has primarily explored single-agent methods, with their performance remains fundamentally limited by the capabilities of a single model. To our knowledge, this paper first introduce a multi-agent approach specifically to enhance the logical reasoning abilities of LLMs.  Considering the respective strengths and weaknesses of symbolic and natural language reasoning, we propose a multi-agent framework where individual agents reason in both symbolic and natural languages and then engage in a debate. To ensure the accuracy of symbolic translation, we also leverage multiple agents to translate and debate in different symbolic languages. Due to the prohibitive communication and token costs of multi-turn interactions, we further propose an adaptive sparse communication strategy to ensure efficiency. Specifically, our method prunes unnecessary communication by assessing the agent confidence and information gains, allowing each agent to selectively maintain its memory with others' most valuable outputs to help generate answers. Extensive experiments demonstrate that not only our multi-agent debate framework outperforms previous methods in logical reasoning tasks, but also our sparse communication approach outperforms the fully-connected communication with 25% token costs reduced, improving both effectiveness and efficiency.", "tldr": "", "keywords": ["Logical Reasoning", "Symbolic AI", "Multi-agent System", "Large Language Models"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/96534fbd759081101c076e5b06e5569d8fe25aed.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The manuscript proposes a sparse multi-agent debate framework that first translates natural-language logical questions into three symbolic languages (LP, FOL, SAT) via agent debate, then lets symbolic and natural-language agents debate the answers, finally voting on the result. An adaptive communication gate prunes low-value inter-agent messages. Experiments on three logical-QA benchmarks report accuracy improvements over a leaderboard that has already reached a degree of saturation."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Table 1 shows +0.92 pp average gain over the fully-connected multi-agent baseline on GPT-4, demonstrating that merging symbolic and NL reasoning is more accurate than either alone.\n\nTable 3 ablation adding each solver (LP→SAT→FOL) steadily lifts accuracy (88.06 % → 95.44 %), confirming that diversity of symbolic systems matters.\n\nAlgorithm 1 (Appendix E) gives reproducible pseudo-code, enhancing technical soundness."}, "weaknesses": {"value": "The experiments are confined to three English synthetic datasets—all of which have already reached saturation. Their small size further undermines the significance of the findings, and no evidence is provided for performance on natural text, whether from specialized domains (e.g., legal, medical) or multilingual contexts.\n\nTable 1 presents performance percentages without accompanying variance estimates (e.g., standard deviation, confidence intervals). Given the dataset’s size, small discrepancies in reported performance could easily be attributed to random noise rather than meaningful differences.\n\nNo token cost comparison is provided against two critical baselines: human-only reasoning, or single-agent Chain-of-Thought (CoT) operating within the same budget. This makes the \"token saving\" claim questionable, as the reference point for comparison remains unspecified.\n\nNo timing analysis: how often do Pyke/Prover9/Z3 timeout?\n\nEq. (1) introduces a preference score but no lemma guarantees that pruning preserves consensus or convergence. No ablation on λ beyond a single value (1.0).\n\nI'm concerned with the prompt sensitivity. Appendix F shows one fixed prompt per role; no robustness check with alternative prompt wordings.\n\nGPT-4 and Claude may have seen ProofWriter during pre-training; no sanitisation check is mentioned."}, "questions": {"value": "Suggestions:\nRun pipeline on FOLIO multilingual, Chinese LogiQA-V2 and LogiEval-Hard; report delta and failure rates.\nRepeat main experiments with three prompt seeds; report mean and std-dev in Table 1."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "BLicwMGZYt", "forum": "rdE9qxGfIv", "replyto": "rdE9qxGfIv", "signatures": ["ICLR.cc/2026/Conference/Submission14334/Reviewer_Q5K8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14334/Reviewer_Q5K8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14334/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760615598489, "cdate": 1760615598489, "tmdate": 1762924758432, "mdate": 1762924758432, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a sparse multi-agent debate framework  to improve the performance of large language models in complex symbolic logic reasoning tasks. This approach combines the advantages of symbolic language (SL) and natural language (NL) reasoning: multiple agents translate the question into different formal logics (LP, FOL, SAT) and optimize the translation through debate. The SL and NL agents then debate and vote on the final answer over multiple rounds. To improve efficiency, the authors design an adaptive sparse communication mechanism, which reduces token consumption while improving accuracy.\n\nMy opinion may be negative at this stage, if the author can address my concerns, I will increase my score."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Achieved very good performance on multiple data sets, with many indicators reaching 100%.\n\n2. The experiments are very substantial, and a large number of experiments are done to verify the performance and efficiency of the proposed method."}, "weaknesses": {"value": "1. The paper repeatedly states that LLMs struggle with complex logical reasoning. However, the metrics shown in Table 1 are all very high, which appears inconsistent with this claim. Moreover, I am curious about the results of directly testing the LLMs—i.e., having the LLM answer the questions without any additional framework—as such baseline results might better support the authors’ argument.\n\n2. While most of the metrics in Table 1 are high, the proposed method does not achieve significant improvements over the baseline. The numerical metrics indicate that all three datasets appear simple, with 100% accuracy achieved multiple times, making the experiment less than convincing.\n\n3. The paper uses the latest powerful baseline models. Does this mean that the method proposed in this paper has high requirements for the base model? Is it applicable to those ordinary models or smaller models such as qwen 2.5 7B?"}, "questions": {"value": "1. Is there a more challenging dataset now? This is necessary to verify the effectiveness of the method in this paper.\n\n2. How is the confidence score obtained in sparse communication?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "x94K6aqD94", "forum": "rdE9qxGfIv", "replyto": "rdE9qxGfIv", "signatures": ["ICLR.cc/2026/Conference/Submission14334/Reviewer_awiG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14334/Reviewer_awiG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14334/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760700735155, "cdate": 1760700735155, "tmdate": 1762924757976, "mdate": 1762924757976, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce a multi-agentic debate system to elicit logical reasoning in LLMs, by integrating symbolic and natural language reasoning. They do this through translating natural language to symbolic language using multiple agents, with the refinement process done through agentic debate. For reasoning, the symbolic output from the translation stage and natural language are used to determine an output through majority voting. To enhance computational efficiency, the authors use a sparse communication strategy within the debate framework."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The use of general purpose (i.e. GPT) and reasoning-enhanced (i.e. deepseek) LLMs helps the reader understand the generalizability of the proposed approach. \n- The results are impressive, as they achieve 100% across several set-ups. \n- The number of baselines used to compare to the proposed approach is sufficient, showcasing the true performance capability of the framework. \n- The use of an adaptive sparse communication strategy to enhance computational efficiency is a very important advantage of this framework."}, "weaknesses": {"value": "- The whole pipeline depends on the translation quality in the first stage. There is some missing validation of the symbolic translations to enhance the validity of the pipeline. \n- The majority-vote process could highlight systematic biases if multiple agents share similar pretraining biases or translation tendencies."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xZnAUgjyLn", "forum": "rdE9qxGfIv", "replyto": "rdE9qxGfIv", "signatures": ["ICLR.cc/2026/Conference/Submission14334/Reviewer_UAB7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14334/Reviewer_UAB7"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14334/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761756084869, "cdate": 1761756084869, "tmdate": 1762924757620, "mdate": 1762924757620, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a two-stage, sparse multi-agent debate framework to improve complex logical reasoning with LLMs by explicitly combining symbolic-language (SL) and natural-language (NL) paradigms: multiple agents first translate an NL problem into diverse SL formalisms (LP, FOL, SAT) and refine these translations via debate; then SL-solver agents (Pyke/Prover9/Z3 results verbalized) and NL-reasoning agents (e.g., CoT, Plan-and-Solve) debate for several rounds before a majority vote determines the answer. To curb the high cost of multi-agent discussion, the authors introduce an adaptive sparse communication mechanism that gates interactions using a preference score mixing agent confidence and information gain (cosine dissimilarity), coupled with selective memory updates. Experiments on ProntoQA, ProofWriter (depth-5 subset), and BIG-Bench LogicalDeduction across GPT-4, Claude 3.7 Sonnet, and DeepSeek-V3 report new SOTA accuracies while reducing token usage compared to strong single- and multi-agent baselines, with ablations showing gains from both the translation-stage debate and heterogeneous SL+NL agent composition."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Novel combination of symbolic and natural-language reasoning in a multi-agent debate.\n- Sparse-communication mechanism effectively reduces token cost with minimal accuracy loss.\n- Strong empirical performance and ablation studies across several reasoning benchmarks."}, "weaknesses": {"value": "- The paper’s two main ideas extend well-known patterns (multi-agent debate; sparse topologies like SparseMAD/CortexDebate) rather than fundamentally rethinking them; the conceptual gap from past methods looks narrow.\n- No theoretical framework proving that the proposed agents can perform valid NL to FOL/LP/SAT translation.\n- With heterogeneous agents, simple majority voting can entrench shared biases or spurious agreement.\n- Critical components (e.g., $C_i^d$, Algorithm 1) are under-defined or inconsistent.\n- Lack of significance testing and limited evaluation scope on real-world reasoning tasks."}, "questions": {"value": "Please concretely differentiate your contributions from recent multi-agent debate and sparse/topology papers (methodologically, not just empirically). Could you add an ablation that (a) removes the SL-NL cross-paradigm stage and (b) replaces your sparse gating with a strongest prior baseline, to quantify each idea’s standalone lift?\n\nHow often do translation mistakes occur, and how does the system recover when all SL agents share the same systematic error?\n\nPlease include sensitivity analyses for λ and the similarity metric, and compare majority vote against confidence-weighted or learned adjudicators."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Fb4bwNDg3B", "forum": "rdE9qxGfIv", "replyto": "rdE9qxGfIv", "signatures": ["ICLR.cc/2026/Conference/Submission14334/Reviewer_DhnF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14334/Reviewer_DhnF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14334/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761954150976, "cdate": 1761954150976, "tmdate": 1762924757203, "mdate": 1762924757203, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}