{"id": "yI79EvEm8G", "number": 5727, "cdate": 1757929774529, "mdate": 1762994756500, "content": {"title": "Adversarial Shallow Watermarking", "abstract": "Recent advances in digital watermarking make use of deep neural networks for message embedding and extraction. They typically follow the \"encoder-noise layer-decoder''-based architecture. By deliberately establishing a differentiable noise layer to simulate the distortion of the watermarked signal, they jointly train the deep encoder and decoder to fit the noise layer to guarantee robustness. As a result, they are usually weak against unknown distortions that are not used in their training pipeline. In this paper, we propose a novel watermarking framework to resist unknown distortions, namely Adversarial Shallow Watermarking (ASW). ASW utilizes only a shallow decoder that is randomly parameterized and designed to be insensitive to distortions for watermarking extraction. During the watermark embedding, ASW freezes the shallow decoder and adversarially optimizes a host image until its updated version (i.e., the watermarked image) stably triggers the shallow decoder to output the watermark message. During the watermark extraction, it accurately recovers the message from the watermarked image by leveraging the insensitive nature of the shallow decoder against arbitrary distortions. Our ASW is training-free, encoder-free, and noise layer-free. Experiments indicate that the watermarked images created by ASW have strong robustness against various unknown distortions. Compared to the existing \"encoder-noise layer-decoder'' approaches, ASW achieves comparable results on known distortions and better robustness on unknown distortions. Code is available in the supplementary material.", "tldr": "", "keywords": ["Digital watermarking", "adverisarial perturbation"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/7d6d21814f890ebe62441a09527e0b6c2577378d.pdf", "supplementary_material": "/attachment/080b6267ae44f5afeae45e5e4bf2e26bf6e2b8df.zip"}, "replies": [{"content": {"summary": {"value": "Prior encoder–noise layer–decoder deep watermarking models are robust to training-time distortions but generalize poorly to unknown distortions. To address this, the paper proposes Adversarial Shallow Watermarking (ASW). Unlike prior art, ASW does not require an encoder or a noise layer; and unlike traditional LDW methods that optimize a model via backprop, ASW optimizes the image itself: with a single shallow decoder and adversarial optimization, it produces a watermarked image that stably triggers the decoder. Experiments suggest strong robustness to various unknown distortions."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. Figures are clear; the abstract and introduction are easy to follow.\n\n2. ASW provides a feasible approach to tackle the weakness of deep learning–based watermarking under unknown distortions."}, "weaknesses": {"value": "1.\tThe decoder-only + adversarial watermarking idea is not new (e.g., LISO [1]), and there is no direct comparison with LISO. LISO reports 3 bpp embedding capacity, while this paper uses 0.00018 bpp. Although robustness is the focus here, the source of robustness in ASW remains unclear. Adversarial examples are typically fragile, yet the adversarially-generated watermarked images here appear highly robust—this contradiction lacks systematic analysis and evidence, which weakens the impact. (The current bpp is too small; please also try the common 64 bits—3×128×128 (~0.0013 bpp) setting used by MBRS/FIN for a fairer comparison.)\n\n2.\tSection 3.1 Empirical Investigation uses a highly limited setup that does not properly construct known vs unknown:\n\n    a) M and \\overline{M} are complementary. Inevitably, regardless of how n^+ and n^- are sampled, their cosine similarity is 0 due to disjoint supports.\n\n    b) This design is still essentially Gaussian noise (insufficient to represent real-world distortions). With a fixed mask M, the model tends to rely on always-undistorted pixels during training; when tested with the complementary mask, those relied-upon pixels are entirely replaced by distorted pixels, so generalization will collapse.\n\n    c) Given (a) and (b), the setup is too simple to support the current claims.\n\nAdditionally, relying only on HiDDeN and only on Gaussian variants is insufficient. Please select some distortions as known and others as unknown for a more faithful evaluation.\n\n3.\tTheorem 1 in §3.2 has a very narrow scope (additive noise), whereas the paper targets broad unknown distortions. There is a lack of both theoretical and empirical analysis for non-additive distortions (e.g., geometric, JPEG compression, filtering).\n\n4.\ta) The citations in §2.1 contain repetitions/errors and need correction.\nb) Figure 5 should be Table 5.\n\n[1] Chen X, Kishore V, Weinberger K Q. Learning iterative neural optimizers for image steganography. ICLR 2022."}, "questions": {"value": "1. What are the exact noise layer settings used for HiDDeN / MBRS / FIN? What are their default noise layers? Did you use single or combined noise layers?\n\n2. The paper focuses on robustness to unknown distortions, and its main way to build robust watermarked images is an adversarial-example procedure. However, adversarial examples are typically fragile, yet the images generated here show broad robustness. The paper does not provide a clear and sufficient explanation or analysis for the source of this robustness.\n\n### Major technical concern: BER under matched settings is significant higher than prior work\n\n**Metric clarification.** In the released code, the variable named `acc` actually computes the **bit error rate (BER)**:\n```python\nacc = len(torch.nonzero((model(x)>0).float().view(-1) != wm.view(-1))) / wm.numel()\n```\n\nThis counts the fraction of mismatched bits; thus acc = 0.17 means 17% BER (not 83% accuracy). I report “acc” below as BER for clarity.\n\n\nMatched configuration vs. MBRS/FIN. I re-ran the authors’ supplementary code, changing only three parameters to match MBRS/FIN: image size = (3,128,128), payload = 64 bits, and weight of criterion_img to 10. All other hyper-parameters were left as in the authors’ script.\n\nMy findings (BER, lower is better). Under JPEG q=50, prior work reports very low BER at good image quality:\n\n\t•\tFIN: PSNR 47.21 dB, BER 0.29%\n\n\t•\tMBRS: PSNR 42.04 dB, BER 1.35% \n\nWith the authors’ code (size & payload changed to match MBRS/FIN), I obtain:\n\n\t•\tAverage PSNR = 33.41 dB (max 38.34 / min 24.44)\n\n\t•\tJPEG q=50: BER = 17.19%\n\n\t•\tFor reference:\n\n\t•\tJPEG q=70: 11.51% BER\n\n\t•\tJPEG q=60: 15.06% BER\n\nConclusion from reproduction. Even after aligning resolution and payload length to match the baselines, BER remains much higher than MBRS/FIN, and PSNR is ~9–14 dB lower. The gap is substantial and persists across standard distortions.\n\nWhy I regard the comparison as not credible/fair.\n\nThe method is presented as “robust without training (generating) with a noise layer,” but there is no principled explanation for how adversarially optimizing against a fixed decoder—without modeling the channel—would yield broad robustness. The empirical results from my run do not support such a claim under matched settings."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No"}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "OstbpP9CUV", "forum": "yI79EvEm8G", "replyto": "yI79EvEm8G", "signatures": ["ICLR.cc/2026/Conference/Submission5727/Reviewer_f8wQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5727/Reviewer_f8wQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5727/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760670900587, "cdate": 1760670900587, "tmdate": 1762918223120, "mdate": 1762918223120, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "As the first author of the paper, I sincerely thank the Area Chair and the Reviewers of our paper. Given the low rating of my paper, I have decided to withdraw it.\n\nThe reviewers were highly professional, providing us with valuable feedback on various aspects, including method design, paper writing, spelling errors, and experimental design. They also pointed out the issues we had avoided with sharp insights.\n\nWe will revise our paper according to the reviewers' comments and submit it to another conference/journal.\n\nFinally, I would like to express my gratitude once again to all of you. It is your efforts that have helped improve our paper!"}}, "id": "0FF5MLbUWY", "forum": "yI79EvEm8G", "replyto": "yI79EvEm8G", "signatures": ["ICLR.cc/2026/Conference/Submission5727/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5727/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762994755485, "cdate": 1762994755485, "tmdate": 1762994755485, "mdate": 1762994755485, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ​​Adversarial Shallow Watermarking (ASW)​​, a novel framework designed to address the limitation of existing Learning-based Deep Watermarking (LDW) methods, which exhibit poor robustness against ​​unknown distortions​​ not encountered during training."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well written and easy to follow, with a clear and logical structure.\n\n2. The experimental design is comprehensive, and the results effectively demonstrate the validity and robustness of the proposed approach."}, "weaknesses": {"value": "1. The main concern lies in the efficiency of image generation. Traditional methods typically train an encoder–decoder pair, while this paper innovatively proposes to directly optimize the watermark image. However, compared with previous approaches that can rapidly generate a large number of watermarked images, ASW requires significantly more time for image generation, which may limit its practicality. Moreover, the manuscript does not discuss this issue; it only compares training time, which makes the comparison somewhat unfair.\n\n2. The proposed method adopts an optimization strategy similar to adversarial noise generation, but the experiments on distortions do not include evaluations against adversarial defense methods, which would have been important for a complete assessment.\n\n3. Although using a shallow decoder seems to improve robustness against distortions, there is an evident trade-off in terms of imperceptibility. The proposed method does not clearly outperform existing approaches in this regard.\n\n4. The captions of Figure 4 and Figure 5 appear to contain some inconsistencies or potential errors."}, "questions": {"value": "1. Could the authors provide a more detailed analysis of the generation efficiency of ASW compared with conventional encoder–decoder–based watermarking methods?\n\n2. The paper only reports training time, while the actual image generation process might be the more critical factor in practical applications. Could the authors clarify why the comparison focuses solely on training time rather than total processing time (training + generation)? Would including generation efficiency alter the conclusions?\n\n3. The paper shows that using a shallow decoder enhances robustness to distortions, but may reduce imperceptibility. Could the authors elaborate on how they balance this trade-off? Is there a systematic way to adjust network depth or regularization strength to optimize both properties simultaneously?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "J7o6HRAN0D", "forum": "yI79EvEm8G", "replyto": "yI79EvEm8G", "signatures": ["ICLR.cc/2026/Conference/Submission5727/Reviewer_RySq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5727/Reviewer_RySq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5727/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761633315655, "cdate": 1761633315655, "tmdate": 1762918222376, "mdate": 1762918222376, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel watermarking framework called Adversarial Shallow Watermarking (ASW), designed to resist unknown distortions. Unlike existing deep neural network-based watermarking methods, ASW only uses a shallow, fixed decoder for both watermark embedding and extraction. This decoder is highly robust to perturbations in the input, enabling it to resist various unseen distortions. During watermark embedding, ASW iteratively adjusts the host image through an adversarial optimization strategy until its updated version reliably triggers the shallow decoder to output the watermark. Experimental results show that ASW effectively embeds and extracts the watermark under both known and unknown distortions, outperforming existing deep watermarking methods in terms of robustness."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper presents a novel and original approach to digital watermarking, specifically through the Adversarial Shallow Watermarking (ASW) framework. The originality lies in its departure from traditional deep learning-based watermarking methods, introducing a shallow decoder that is robust against various unknown distortions. This is a significant contribution as it addresses limitations in previous approaches, which often fail to handle unseen distortions effectively.\n2. The paper demonstrates clarity and structure reasonably well. The overall structure is clear, and the chapter arrangement effectively communicates the core ideas and experimental results. \n3. Regarding data and experimental design, the paper's experimental setup is generally reasonable, and the ASW method is validated through experimental data."}, "weaknesses": {"value": "1. There are writing errors in the paper, particularly in section 5.1, where “Table 5” should be “Figure 5,” and in Table 3, where \"Cropput\" should be \"Cropout.\" Although these errors do not fully impact the conclusions, they undermine the rigor of the paper, particularly in terms of accuracy in detail. \n2. There is an inconsistency in the data presented in the paper. Specifically, in Table 3, the Bit Error Rate (BER) for Cropout 0.75 is 12.47%, but in Figure 6 (k), the data presents a different result. This inconsistency could lead to misunderstandings of the experimental results or cause doubts about the credibility of the paper. \n3. Compared to some existing methods (e.g., MBRS and FIN), ASW shows slightly inferior watermark image quality. Particularly when the watermarked image has not undergone any distortion, ASW scores lower in visual quality compared to some deep learning methods. \n4. ASW's Performance on Known Distortions (e.g., JPEG Compression):The experiments show that ASW performs worse than some specially trained deep watermarking methods when dealing with known distortions like JPEG compression. While ASW demonstrates strong robustness against unknown distortions, its adaptability to known distortions like JPEG compression is relatively weak."}, "questions": {"value": "1. Does different sampling initialization of the decoder significantly impact the final watermark extraction results?\n2. Can you further elaborate on why the shallow decoder is so effective in resisting distortions and successfully decoding watermark information? Is there a theoretical basis or mechanism to explain this phenomenon?\n3. Please supplement the performance of the proposed method under real-world distortions, such as screen captures and social media compression.\n4. Technically speaking, this article bears a strong resemblance to FNNS[1]. Please outline the similarities and differences between them, along with a performance comparison.\n\n[1] Kishore V, Chen X, Wang Y, et al. Fixed neural network steganography: Train the images, not the network[C]//International conference on learning representations. 2021."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "da4OvEkHp3", "forum": "yI79EvEm8G", "replyto": "yI79EvEm8G", "signatures": ["ICLR.cc/2026/Conference/Submission5727/Reviewer_jVTv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5727/Reviewer_jVTv"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5727/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761796216010, "cdate": 1761796216010, "tmdate": 1762918221200, "mdate": 1762918221200, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed a novel watermarking framework to resist unknown distortions, namely Adversarial ShallowWatermarking (ASW), which utilizes only a shallow decoder that is randomly parameterized and designed to be insensitive to distortions for watermarking extraction. This method is training-free, encoder-free, and noise layer-free.  The reported experimental results indicate that the watermarked images created by ASW have strong robustness against various unknown distortions."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "（1）Conduct empirical studies and analyses to reveal the limitations of the existing LDW methods；\n\n（2）Propose a novel watermarking framework, ASW, which is training-free, encoder-free, and noise-layer-free；\n\n（3） Despite having no prior knowledge of the distortions, the ASW is able to produce high-quality watermarked images with strong robustness against almost all types of distortions\n\n（4）Demonstrate the feasibility of utilizing a single decoder for watermark embedding and extraction, providing a new perspective for future watermark design"}, "weaknesses": {"value": "（1）The Method section lacks a framework diagram for the entire methodology, which hinders comprehension.\n（2）Has the first AvgPool layer in the decoder undergone ablation? What happens if it's removed?\n（3）How does the number of layers in a decoder affect decoding accuracy?\n（4）The watermark capacity is too small, seriously limiting its practicality. \n（5）What would happen if the watermark capacity were increased? (Of course, the host image size could also be expanded accordingly.)\n（6）The comparison method is outdated; newer approaches should be introduced."}, "questions": {"value": "See the Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Wjswuvy4SY", "forum": "yI79EvEm8G", "replyto": "yI79EvEm8G", "signatures": ["ICLR.cc/2026/Conference/Submission5727/Reviewer_WDok"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5727/Reviewer_WDok"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5727/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761901715435, "cdate": 1761901715435, "tmdate": 1762918219262, "mdate": 1762918219262, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}