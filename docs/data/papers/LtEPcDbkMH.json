{"id": "LtEPcDbkMH", "number": 22824, "cdate": 1758335895224, "mdate": 1759896844357, "content": {"title": "Unanchoring the Mind: AI-Guided Counterfactual Reasoning for Rare Disease Diagnosis", "abstract": "Diagnosing rare diseases remains a persistent challenge, often hindered by cognitive anchoring: once clinicians settle on a common diagnosis, alternative-especially rare-explanations are often dismissed. To address this, we propose a human - centered counterfactual reasoning framework using a Denoising Autoencoder (DAE) to simulate what - if diagnostic scenarios that disrupt clinicians’ initial assumptions. Our model uniquely and jointly learns (1) the true distribution of diseases and symptoms, and (2) human diagnostic behavior, revealing critical gaps between medically possible and clinically considered diagnoses. By strategically perturbing latent patient representations, it generates contrastive counterfactuals that highlight rare but plausible conditions—conditions typically overlooked due to cognitive bias. Unlike traditional decision - support tools, our system proactively suggests rare diseases not because they are statistically probable, but because they are cognitively neglected. Evaluated on three rare disease datasets, our approach outperforms standard machine learning classifiers in detecting rare conditions while maintaining strong performance on common diagnoses. Beyond boosting accuracy, it fosters hypothesis - driven reasoning, enhancing both diagnostic precision and clinician learning.", "tldr": "", "keywords": ["Counterfactual Reasoning", "Rare Disease Diagnosis", "Autoencoder"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6644841bebf16e3d8ac21fe4e8b1900356cf840a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposed a denoising autoencoder (DAE) to address cognitive anchoring for human clinician diagnosis thought perturbing latent patient space to generate contrastive counterfactuals about potential rare diseases. This paper has tested the proposed methods on three private datasets and one public rare disease dataset."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- This paper points out an interesting cognitive anchoring behavior for human clinician diagnosis. \n- It has contextualized the cognitive anchoring for rare disease diagnosis that they share similar and common symptoms.\n- It tests the proposed methods on three private datasets and one public rare disease dataset."}, "weaknesses": {"value": "- It is unclear about the effectiveness of the propose methods, even it outperforms on AUC score, but there might exist high false positives for rare disease prediction, how to reduce false positives can be a huge challenge. This paper did not provide details to discuss false positive issues.\n- This paper did not choose the fair baseline methods, because it uses contrastive learning and several other loss functions, it should make sense to compare with the same prediction methods using contrastive learning. \n- The human evaluation looks vague and general, did not have rigorous rubric to measure the effectiveness and difference."}, "questions": {"value": "- can you provide more details about the false positive cases and how you are going to address false positive cases for your prediction.\n- when you provide counterfactuals, are these counterfactuals similar for one specific rare disease?\n- evaluation is critical, especially clinical evaluation, clinical soundness, please conduct rigorous clinical evaluation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "RhnPh3Kmyv", "forum": "LtEPcDbkMH", "replyto": "LtEPcDbkMH", "signatures": ["ICLR.cc/2026/Conference/Submission22824/Reviewer_6P3K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22824/Reviewer_6P3K"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22824/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761710931651, "cdate": 1761710931651, "tmdate": 1762942401497, "mdate": 1762942401497, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a DAE-based generative framework to combat cognitive anchoring in rare disease diagnosis. The model is designed to generate counterfactuals that challenge a clinician's initial assumptions. Its main novelty lies in a dual-predictor architecture that jointly learns to predict the ground-truth diagnosis (AI predictor) and a clinician's likely diagnosis (human predictor) from a shared latent space. The \"cognitive gap\" between these two is explicitly modeled via a sparse attention mechanism and a dedicated loss term. Counterfactuals are generated by perturbing the latent representation in a direction that maximizes the diagnostic uncertainty of the simulated human model, thereby surfacing rare but plausible alternative diagnoses. The authors evaluate their method on one public and three private datasets, using a combination of ML metrics, LLM-based assessment, and expert clinician feedback to demonstrate its effectiveness."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper tackles a well-recognized and highly impactful problem in clinical medicine—cognitive bias in diagnosis. The framing of the solution as a human-AI collaborative tool to \"unanchor the mind\" is compelling and conceptually sophisticated.\n\n2. The central idea of a dual-predictor model that explicitly simulates a human's diagnostic process to identify and target cognitive gaps is highly innovative. The counterfactual generation mechanism, which optimizes for the human model's uncertainty, is elegant and psychologically well-motivated."}, "weaknesses": {"value": "1. Reproducibility Issues: The paper's empirical claims are built almost entirely on private datasets (3 out of 4). For a top-tier machine learning conference, where verifiable and reproducible results are paramount The contribution of curating the data is noted, but it does not absolve the authors of the responsibility to provide a basis for the community to verify their claims. The promise of releasing a data simulator in the future is irrelevant to the evaluation of the current submission. Without access to the data, the impressive results in Figures 2 and Table 2 are essentially unverifiable and rarely meaningful to the community.\n\n2. The entire framework hinges on the model's ability to simulate a \"human doctor's diagnosis\" (Y_human). However, this is based on \"the clinician’s recorded label\". This is a gross oversimplification that borders on being conceptually unsound. There is no single \"human\" model of diagnosis. This label could be from a world-class expert or a junior resident; it could be an initial guess or a post-consultation final diagnosis. The model is not learning \"human cognitive bias\"; it is learning to mimic the labeling behavior of a small, specific, and undefined group of clinicians present in a private dataset. This undermines the central scientific claim of the paper.\n\n3. Unscientific Evaluation of Counterfactuals: The paper presents a \"LLM-Human Dual Quantitative Evaluation,\" but this evaluation is weak and lacks rigor.\n\nLLM Evaluation: Using an LLM to \"evaluate\" clinical plausibility is not a scientifically valid method. LLMs are known to hallucinate and produce text that is plausible but factually incorrect, especially in expert domains. The prompt in Figure 6 is also highly leading, effectively telling the model the desired outcome. This part of the evaluation is, at best, an interesting anecdote and, at worst, scientific theater.\n\nHuman Evaluation: The evaluation by \"clinical experts\" is presented without any necessary detail. How many experts? What was their specialty? What was the exact protocol? Were they blinded to the AI's original prediction? What was the inter-rater reliability? Without these details, the claim of \"doctor-based evaluation\" is unsubstantiated.\n\n4. Overly Complex and Brittle Model: The final loss function (Eq. 7) is a weighted sum of six distinct terms. This introduces at least five hyperparameters that need careful tuning. While the authors describe a grid search, such complexity raises serious concerns about the model's brittleness and the generalizability of the reported results. It is unclear if this performance can be achieved on a new dataset without an exhaustive and potentially dataset-specific tuning process."}, "questions": {"value": "1. The validity of your entire framework rests on the Y_human variable. Can you provide a precise definition of this label? Specifically: who provided the label (level of expertise), at what stage of the diagnostic process was it recorded (initial vs. final), and how do you justify that learning from these specific labels allows you to model a generalizable \"human cognitive bias\"?\n\n2. Your claim of clinical utility relies on expert evaluation. Can you provide the full protocol for this evaluation, including the number of reviewers, their qualifications, the instructions they were given, and the quantitative results (e.g., scoring, inter-rater agreement)?\n\n3. The non-reproducibility of this work is a critical issue. Given that 75% of your datasets are private, how can the scientific community trust or build upon your results? Why should this paper be accepted at ICLR without the possibility of independent verification?\n\n4. The optimization in Eq. 8 to find \\theta z* is central to your method. This is a non-concave optimization problem. Can you describe the algorithm used, its stability, and how sensitive the quality of the generated counterfactuals is to the hyperparameters of this optimization (e.g., step size, number of steps, \\epsilon)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3BfcDgbC5p", "forum": "LtEPcDbkMH", "replyto": "LtEPcDbkMH", "signatures": ["ICLR.cc/2026/Conference/Submission22824/Reviewer_Yqjw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22824/Reviewer_Yqjw"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22824/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761811914114, "cdate": 1761811914114, "tmdate": 1762942400981, "mdate": 1762942400981, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a counterfactual framework that adopts a Denoising Autoencoder (DAE). The jointly learns the distribution of true diagnostic labels and human diagnostic behavior. The proposed framework generates counterfactuals that highlight rare but plausible conditions, whereby in some cases they may be clinically ignored, but plausible."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "•\tThe real world evaluation is particularly valuable.\n•\tThe ability for the propose DAE approach as to existing works based on AE/VAE ensures handling of noisy/incomplete data, this is particularly common in medical data.\n•\tThe idea itself, to my knowledge is novel. The combination of a human predictor and AI predictor seems valuable to incorporate a cognitive aspect of counterfactual generation.\n•\tThe quantitative results favour the proposed method."}, "weaknesses": {"value": "•\tThe definition of the human label seems mildly ambiguous, as there is little information about the collection of the label. The setting of the label would be critical to the effectiveness of the proposed framework. Thus, understanding when to best collect data to facilitate the framework would be ideal.\n•\tCognitive anchoring is a strong assumption. One would think that humans can observe what is not contained in the data. For example a medical expert may observe physical reactions or patient well-being. This would not be a form of bias, but instead useful observables. It is unclear how the mitigation of these considerations would be addressed – consequently, I think actionability is something that needs to be considered in such method, whereas this is not discussed.\n•\tSelection of the baseline hyperparameters is unclear.\n•\tThere is no clear evaluation against counterfactual desiderata. Whilst validity and proximity (I’m unsure if plausibility is the correct term here) are implicit to the evaluation, a broader spectrum of desiderata are not discussed in detail."}, "questions": {"value": "How did the authors select hyperparameters for competing benchmarks (e.g. $\\lambda_S$ and $\\lambda_{cf}$ as per the CF-VAE paper)?\nAt what point was the human label collected within these datasets? (e.g. initial vs final diagnosis)\nThe quality of this label seems fundamental to the effectiveness of the approach. Do the authors have any guidance or recommendation on in medical settings, which point this label should be collected – is there a guidance on collection to make best use of the approach in real-world deployment?\nCould the authors please expand on the rationale for maximising human uncertainty?\nIs actionability / actionable guidance considered in counterfactual generation? Aligning with the weakness of assumed cognitive anchoring, whereas it could be observational details that sway a medical professionals’ decisions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cfbsg0W4k7", "forum": "LtEPcDbkMH", "replyto": "LtEPcDbkMH", "signatures": ["ICLR.cc/2026/Conference/Submission22824/Reviewer_DxeW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22824/Reviewer_DxeW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22824/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761874979440, "cdate": 1761874979440, "tmdate": 1762942400652, "mdate": 1762942400652, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a masked denoising autoencoder (mDAE) that learns a 32-dimensional latent space from partially observed clinical feature vectors and augments it with (i) a sparsity-regularized “human” head guided by a learned mask m, (ii) an AI prediction head for\nrare/common disease discrimination, (iii) a contrastive loss to keep rare-disease latents distinct from common-disease latents, and (iv) a “cognitive gap” loss that penalizes gradients aligned with the human attention mask so the AI attends to evidence clinicians may\nunder-use. Counterfactual samples are then generated in latent space for three scenarios: completion of missing features, resolving AI-human disagreement, and proposing alternatives under high human uncertainty. Experiments on four rare-disease datasets (Gitelman, Acromegaly, HCM, GPA) include 10-run mean±std AUCs and ablation assessments removing individual loss terms; a figure explores class-imbalance robustness versus baselines; and a dual evaluation of counterfactuals by an LLM and clinicians is presented."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper targets an important and not very studied setting (rare-disease diagnosis with missing data and cognitive anchoring) and proposes a conceptually coherent system that couples an imputation-capable mDAE with losses that are each motivated by the task: an L1\nmask promotes sparse “human” attention consistent with limited cognitive bandwidth; a contrastive term counteracts rare-class collapse; and the cognitive-gap penalty operationalizes the aim of nudging the AI toward evidence clinicians underweight. The method considers precise loss definitions and an explicit staged curriculum, making reproduction plausible. The empirical section reports multi-dataset 10-run AUCs with ablation results that show substantial performance decrease when removing the human/mask or AI losses, as an evidence that the\nfull objective is needed. The paper also presents class-imbalance stress tests and clear latent-space visualizations add qualitative intuition\nthat complements the metrics. The evaluation of counterfactuals using both clinicians and an LLM is an interesting and apparently effective strategy, since it takes into account cost constraints while still considering human judgment"}, "weaknesses": {"value": "The performance evaluation is based on AUCs, but considering that we are talking about rare-events, AUC/accuracy may be\ninsensitive to low prevalence. For instance, the paper does not report PR-AUC or calibration as suggested by related work (Juba & Le, 2019), which weakens some performance claims. The statement that lower RMSE implies higher plausibility is not really demonstrated, since RMSE is a proximity measure, sensitive to feature scaling/types, and it does not consider basic clinical constraints (ranges, binarity, thresholds/monotonicities). Counterfactual assessment needs to be improved because distance and label flips does not seem to be enough to evaluate its robustness and faithfulness. It is not clear which LLM was used, as well as its associated settings, and clinician evaluation relevant details are not provided, such as number of professionals per case, blinding, and inter-rater agreement. As it is, it is not clear to what extent the paper is reproducible and the validity of human evaluation. The paper also claims that the gap loss enable the AI system to consider features that clinicians do not employ frequently , but there is no direct demonstration of an off-mask shift (e.g., change in\nfeature importance/gradients relative to the mask) or of reduced anchoring in behavior. Further, ablations presented just ground the need for classification. The paper should improve its statistical analysis, which is currently limited to reporting mean +/- SD across runs without confidence intervals or simple significance tests vs. baselines. Finally, the HCM dataset is quite small and the control group consists only of patients with another specific rare disease, limiting the validity of the results."}, "questions": {"value": "- Could you report PR-AUC and calibration metrics in addition to AUC, and discuss how results change across different prevalence settings?\n- Could you provide a brief check that counterfactual edits are both faithful (influence the decision) and plausible (respect basic clinical constraints), and clarify how RMSE is computed over mixed feature types?\n- Could you provide details on which LLM, temperature and seed were used?\n- Could you provide more information about the clinician evaluation (number of raters, blinding, inter-rater agreement)?"}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety", "Yes, Potentially harmful insights, methodologies and applications", "Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "details_of_ethics_concerns": {"value": "This work uses sensitive clinical data for diagnostic-support modeling. Please (i) list IRB/ethics approvals and data-use agreements per cohort; (ii) affirm de-identification and whether any PHI was sent to external services (including the LLM used as a judge - if\ncloud-hosted, disclose safeguards or run locally); (iii) clarify sharing plans (code, weights, and any public/synthetic datasets), ensuring no leakage of private data; (iv) discuss automation bias and the risk that counterfactuals may be over-trusted or misinterpreted,\nproposing UI/usage guidance and clinician-in-the-loop guardrails; and (v) acknowledge narrow controls (e.g., HCM vs. ATTR) to avoid over-generalization in deployment."}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nivM83hBdK", "forum": "LtEPcDbkMH", "replyto": "LtEPcDbkMH", "signatures": ["ICLR.cc/2026/Conference/Submission22824/Reviewer_cxgP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22824/Reviewer_cxgP"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22824/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762082093233, "cdate": 1762082093233, "tmdate": 1762942400191, "mdate": 1762942400191, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}