{"id": "U3RZZSLv1l", "number": 16675, "cdate": 1758267532479, "mdate": 1759897225833, "content": {"title": "StateEnsemble: Neural State Chain-based Dynamic Model for Complex Motor Sequence Decoding", "abstract": "Brain-computer interfaces (BCIs) have paved the way for motor function rehabilitation and reconstruction. However, accurate movement decoding is still a challenging problem, especially for complex movements. Recent studies discovered that motor sequences, particularly complex ones, are encoded through a chain of neural states, each corresponding to a movement fragment. While this neural basis could facilitate more accurate neural decoding for complex movements, existing neural decoders fall short in modeling state-level sequential information. Here, we propose a neural state chain-based dynamic model (StateEnsemble), which explicitly models the neural state transition process to perform state-dependent neural decoding. We evaluated the proposed approach with intracortical neural signals recorded from the human motor cortex during handwriting. Experimental results demonstrated that our approach can effectively capture the underlying neural state transition patterns during handwriting, and achieve significant improvements in decoding performance. The proposed StateEnsemble approach can be beneficial for diverse neural decoding tasks and facilitate high-performance BCIs.", "tldr": "", "keywords": ["state space model", "bayesian filter", "neural decoding", "brain computer interface"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0524a91bf24ad14a31fc5e7362357ea6b9818733.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents a new approach to neural decoding under non-stationary conditions, based on a State-Ensemble Neural State-Space Model. The proposed framework extends standard state-space models by incorporating additional latent variables that capture slowly varying or non-stationary dynamics. The authors formulate a probabilistic ensemble of states, where each ensemble component evolves according to a learned transition model and contributes to the observation likelihood through a neural decoder. This structure allows the model to represent time-varying relationships between neural signals and latent behavioral states, while maintaining a coherent probabilistic interpretation. The paper validates the method on both synthetic datasets and real neural recordings, demonstrating improved robustness to non-stationarity and enhanced decoding performance compared to conventional Kalman-based and neural state-space baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper presents a mathematically sound and principled method for neural decoding that explicitly models non-stationarity while building on well-established state-space model formulations. By integrating neural network components into a state-space architecture, the proposed framework effectively combines model-based structure with data-driven flexibility, providing a natural mechanism to adapt to distributional shifts in neural data.\nThe empirical section is well executed and supports the theoretical claims convincingly, with experiments conducted on both simulated and real neural datasets. The results consistently show improved decoding accuracy and stability over competing approaches. The presentation is clear, with strong mathematical rigor complemented by good conceptual explanations and experimental validation."}, "weaknesses": {"value": "While the approach is well-formulated, the core idea of introducing additional state variables to handle non-stationarity is not entirely novel. Similar strategies have been explored in augmented-state Kalman filters and adaptive filtering literature, where time-varying parameters are embedded within an extended state representation. The paper would benefit from positioning its contribution more explicitly with respect to these prior works, clarifying what is truly new in the proposed state-ensemble formulation.\nAdditionally, the notation used in equation (5) is somewhat confusing: the augmented state transition is expressed using a function g(⋅) that is described as a conditional distribution function, whereas the remainder of the state-space model is formulated using deterministic mappings (e.g., f(⋅)). This notational inconsistency may obscure the conceptual distinction between stochastic modeling and deterministic dynamics, and should be clarified."}, "questions": {"value": "In equation (13), is the relation presented an approximation (e.g., due to variational inference or an independence assumption), or should it in principle be an equality derived directly from the Markovian structure of the state-space model? Clarifying this point would help in understanding the scope and accuracy of the inference procedure."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "pjpqdVb4Ci", "forum": "U3RZZSLv1l", "replyto": "U3RZZSLv1l", "signatures": ["ICLR.cc/2026/Conference/Submission16675/Reviewer_y2Bo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16675/Reviewer_y2Bo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16675/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761831919371, "cdate": 1761831919371, "tmdate": 1762926732567, "mdate": 1762926732567, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on accurate movement decoding and introduces StateEnsemble, a neural state chain based model. It models the sequential relationships between neural states to perform state-dependent neural decoding. The authors analyze both simulated experiments and a handwriting task, demonstrating that the method outperforms baseline approaches in handwriting trajectory decoding."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The authors propose a novel method focusing on neural state decoding, with a clearly stated contribution. The experimental results on both simulated and handwriting data are promising and include comparisons with eight different baselines, demonstrating a thorough evaluation. The authors also clearly discuss the method’s limitations and potential impacts. The work is reproducible, with a detailed description of the algorithm, experimental setup, and baseline methods."}, "weaknesses": {"value": "The main weaknesses of this work are organization and experiments.\n\nThe introduction lacks emphasis on the importance and applications of neural decoders. The background information and related work are scattered across different sections, which reduces the paper’s clarity and flow and makes it difficult to grasp the overall contributions of the method. Figure captions are not self-contained, and referencing appendix figures within the main text disrupts the flow.\n\nAlthough the experiments on simulated data and neural signals are promising, the evaluation is limited, lacking comparisons with existing methods on larger, multi-participant datasets.\n\nPlease see the questions section for detailed suggestions related to both organizational and experimental weaknesses."}, "questions": {"value": "**Organization and Presentation**\n\n- The Introduction Section could be improved by focusing more on the importance of neural decoders, including examples of tasks and applications. This would help emphasize the motivation and significance of the study.\n\n- The background information is spread across several sections, including Methods (the StataEnseble model section) and Experiments. It would improve the flow and clarity to organize the discussion of existing approaches and related work either within the Introduction or in a separate Background section. This could also improve the flow in the method section.\n\n- Independent and descriptive figure captions would improve clarity. For example, including an explanation of the model framework directly in the caption of Figure 1 would strengthen the presentation. \n\n- The presentation of appendix figures within the Experiments section should be changed. For example, Sections 3.2 and 3.3 refer to supplementary figures and explain them in the main text. These figures should either be moved entirely to the supplement with appropriate references in the main text, or incorporated into the main paper.\n\n**Experiments**\n\n- Does the handwriting dataset contain data from only a single participant? If yes, although the simulated and handwriting task results are promising, experiments using datasets with multiple participants are needed to better evaluate the method’s performance and contributions.\n\n- Could the authors evaluate and compare their method with existing approaches on other public datasets that include multiple participants, such as those by Crell et al. [1] and Pei et al. [2]?\n- What other tasks could this method be applied to?\n\t\n\nAlso, although the details on reproducibility are sufficient, it would be beneficial to the community if the authors could share the code in the future.\n\n[1] Crell, Markus R., and Gernot R. Müller-Putz. \"Handwritten character classification from EEG through continuous kinematic decoding.\" Computers in Biology and Medicine 182 (2024): 109132.\n [2] Pei, Leisi, Marieke Longcamp, Frederick Koon-Shing Leung, and Guang Ouyang. \"Temporally resolved neural dynamics underlying handwriting.\" NeuroImage 244 (2021): 118578."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "b4KtzG76hE", "forum": "U3RZZSLv1l", "replyto": "U3RZZSLv1l", "signatures": ["ICLR.cc/2026/Conference/Submission16675/Reviewer_xhh6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16675/Reviewer_xhh6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16675/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761854820484, "cdate": 1761854820484, "tmdate": 1762926732177, "mdate": 1762926732177, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work describes a method of state-space based decoding using neural states and a transition graph applied a BCI handwriting task."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- Figure 1 and overall framework explanation was clear. \n- It is a conceptually nice, clean framework: a series of states and a graph connecting them."}, "weaknesses": {"value": "- Discussion of comparisons to other state-based approaches are lacking (e.g., Mamba, other dynamical modeling of latent neural dynamics using e.g. HMMs, switching LDSs, ...).  Qi 2019, 2022 is insufficient. \n- The method description makes it hard to identify the novelty given how established neural state space models are. The use of DyEnsemble, and the whole section there doesn't appear novel (eqns 9-13). \n- Figure 2 forces the reader to compare colors across matrices. Can a more direct metric be used as well? MSE is mentioned briefly but isn't in the main results. \n- The use of Kendall tau distance assumes a lot \"If the state transition graphs learned from these two groups are similar, it would suggest the presence of transition patterns in the neural state transition processes during handwriting tasks\".  A more direct metric here would strengthen this analysis. \n- Table 1 doesn't make clear which values are significantly different. Variances seem to heavily overlap. \n- Results are very limited: limited comparison models, limited datasets as benchmarks (there are other animal and human handwriting and motor tasks available), limited metrics for evaluation, limited explanations for the performance (e.g., only compared with and without the state chain)."}, "questions": {"value": "- How well does the assumption (\"We assume that the functional mapping between the neural signal and movement trajectory is stable within a state, while distinct among different states.\") hold up in practice?  (Line 153).\n- How well does this scale to longer chains? 10 appeared to be the maximum. Other work uses up to hundreds or thousands of states."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "hcBrLl6fyQ", "forum": "U3RZZSLv1l", "replyto": "U3RZZSLv1l", "signatures": ["ICLR.cc/2026/Conference/Submission16675/Reviewer_pNHD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16675/Reviewer_pNHD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16675/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761954319624, "cdate": 1761954319624, "tmdate": 1762926730767, "mdate": 1762926730767, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces StateEnsemble, a novel neural decoding framework designed to improve brain–computer interface (BCI) performance, particularly for complex motor sequences such as handwriting. The key idea is to model motor control as a sequence of neural states (a “state chain”), with each state corresponding to a specific fragment of movement. Unlike traditional decoders or dynamic models that do not explicitly account for neural state transitions, StateEnsemble models the transition graph between neural states and uses it as a prior during decoding. The model is evaluated using (1) simulated data experiments, which show improved estimation of neural states and movement trajectories, and (2) human intracortical neural recordings from an imagined Chinese handwriting task. The results demonstrate higher decoding accuracy (R² = 0.3887) compared to Kalman Filter, LSTM, and Transformer baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.Introduces the idea of explicitly modeling neural state transitions as a graph prior—a promising direction for addressing neural nonstationarity in BCIs.\n\n2.Includes both simulated and real intracortical data, lending credibility to the empirical findings.\n\n3.The state transition graph provides interpretable insights into structured neural activity sequences, such as those involved in handwriting."}, "weaknesses": {"value": "1.Although the approach is interesting, the scope of the work may be relatively narrow.\n\n2.The method relies largely on existing components, and the theoretical contribution appears limited.\n\n3.Most baseline comparison methods were published prior to 2024.\n\n4.Despite the inclusion of a Reproducibility Statement, code and data availability are not clearly specified.\n\n5.All real-data experiments are conducted on a single tetraplegic participant performing a specific handwriting task, leaving generalization to other subjects or tasks untested."}, "questions": {"value": "1.Will you release the source code?\n\n2.Can you include more recent SOTA baselines for comparison?\n\n3.Can the method be evaluated on additional subjects or related tasks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N.A."}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nvo9SvEEyC", "forum": "U3RZZSLv1l", "replyto": "U3RZZSLv1l", "signatures": ["ICLR.cc/2026/Conference/Submission16675/Reviewer_2Fiu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16675/Reviewer_2Fiu"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16675/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762324737202, "cdate": 1762324737202, "tmdate": 1762926730165, "mdate": 1762926730165, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}