{"id": "zQhJSohBUl", "number": 8535, "cdate": 1758090130801, "mdate": 1759897778042, "content": {"title": "Multi-Level Regression for Nonlinear Contextual Bandits and RL: Second-order and Horizon-free Regret Bounds", "abstract": "Recent works have established second-order regret bounds for nonlinear contextual bandits. However, these results exhibit a suboptimal dependence on the complexity of the function class. To close this gap, we propose a novel algorithm featuring a multi-level regression structure. This method partitions data by their uncertainty and variance, then performs separate regressions on each level, enabling adaptive, instance-dependent learning. Our method achieves a tight second-order regret bound of $\\tilde{O}\\Big(\\sqrt{d_\\mathcal{F} \\log N_\\mathcal{F} \\sum_{t\\in[T]} \\sigma_t^2} + R d_\\mathcal{F} \\log N_\\mathcal{F}\\Big)$, which matches the theoretical lower bound. Here, $d_\\mathcal{F}$ and $\\log N_\\mathcal{F}$ represent the Eluder dimension and log-covering number of the reward function class $\\mathcal{F}$, $\\sigma_t^2$ is the unknown variance of the reward at round $t$, and $R$ is the range of rewards. The proposed algorithm is computationally efficient assuming access to a regression oracle. We further extend our framework to model-based reinforcement learning, achieving a regret bound that is both second-order and horizon-free. The underlying multi-level regression technique is of independent interest and applicable to a broad range of online decision-making problems.", "tldr": "", "keywords": ["Bandit", "Reinforcement Learning"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1801e7862c1140d79c2257e0f6672e62248c76f7.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a multi-level regression (MLR) framework (ADALEVEL + weighted regressions) for nonlinear contextual bandits with unknown, heteroscedastic variance, yielding the algorithm UCB-MLR. The key idea is to partition data by both uncertainty and estimated variance, run separate regressions per level, and aggregate optimistic UCBs. Under standard realizability plus an auxiliary assumption on the squared-reward model, the paper proves a second-order regret, matching prior lower bounds in the main term. The framework is extended to model-based RL, giving a horizon-free, second-order regret bound under an additional variance-of-variance assumption."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "A good theoretical contribution:\n\n1. Close a know gap: main term scales as $\\sqrt{d_F}$, matching the lower bound in bandit setting.\n\n2. Use a regression oracle and shows how to compute the uncertainty measure $D_F$ via binary search with $\\tilde{O}(1)$ oracle calls."}, "weaknesses": {"value": "1. Lack of empirical studies. Even though this paper is a theoretical work, I still think it is proposing a novel algorithm. That means the feasibility and practical evidence are critical to include. I don't think the paper needs lots of simulation and experiments but some experiment to show the performance and show the theoretical insight (to guide the practical use case) are required to be a satisfied paper. \n\n2. Subsequence from above point, since there is no practical results, I don't see how to choose or set the (hyper)parameters for the algorithms. I am concerned about the feasibility. For example, the choice of $\\alpha$, $\\tilde{\\alpha}$, $gamma$, $\\tilde{gamma}$ and constant $R$ and confidence scales $\\beta_{t, \\ell}$ etc. For theory, parameters are fully specified in the appendix (but some require unknown complexity terms). A short “practical tuning” section would improve usability.\n\n3. RL extension assumptions: the RL bound adds a variance-of-variance condition (and deterministic rewards), which may be restrictive; more concrete families where this holds would help."}, "questions": {"value": "1. Why using the non-standard assumption for $y_t^2$? Please provide concrete distributional families (beyond sub-Gaussian) where $Var[y^2|X] \\leq c_V^2 R^2 Var[y|x]$ holds, and examples where it fails. How sensitive are your bounds/algorithms to violations?\n\n2. In Eq 4.2, there is $g \\in F$ but earlier introduce a distinct class. I assume it is a typo? or do you intend to state $F = G$ in the analysis? If $G \\neq F$, how do $d_G$, $\\log N_G$ enter computation and tuning?\n\n3. What concrete F families admit the weighted-regression oracle in near-linear time and allow efficient evaluation of $D_F$ via binary search (e.g., RKHS with kernel ridge, GLMs)? Any hardness results if $F$ is a deep net class?\n\n4. For the RL extension, please restate the exact variance-relation assumption and give examples (e.g., linear mixture MDPs with bounded features) where it holds; can you weaken it without losing horizon-free behavior?\n\n5. Lemma 4.3 uses a covering-net union bound with weights bounded by $W$. Under ADALEVEL, do we always have $W \\leq 1$? Please point to the exact place in property 1 that enforces this bound."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6H4ZMXIvK7", "forum": "zQhJSohBUl", "replyto": "zQhJSohBUl", "signatures": ["ICLR.cc/2026/Conference/Submission8535/Reviewer_xoVH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8535/Reviewer_xoVH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8535/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761767583894, "cdate": 1761767583894, "tmdate": 1762920394715, "mdate": 1762920394715, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Common Response QA1"}, "comment": {"value": "We respond to the technical questions raised by multiple reviewers here.\n\n**Q1** Under what conditions does the variance relation $\\text{Var}[y^2] \\le c_v^2 R^2 \\text{Var}[y]$ hold, and how large is the constant $c_v$?\n\n**A1** While we included $c_v$ as a variable parameter in our guarantee, we realized after submission that $c_v \\le 2$ always holds for any bounded reward distribution, so we can drop this term and the corresponding assumptions from our results. Specifically, for any random variable $y \\in [0, R]$, we have:\n$$\n\\text{Var}[y^2] = \\mathbb{E}[(y^2 - \\mathbb{E}[y^2])^2] \\le \\mathbb{E}[(y^2 - \\mathbb{E}[y]^2)^2] \\le 4R^2 \\mathbb{E}[(y - \\mathbb{E}[y])^2] = 4R^2 \\text{Var}[y].\n$$\nHere, the first inequality follows from the property that the expectation minimizes the squared error, and the second holds because $|y^2 - \\mathbb{E}[y]^2| = |y - \\mathbb{E}[y]| \\cdot |y + \\mathbb{E}[y]| \\le 2R |y - \\mathbb{E}[y]|$. Consequently, for the variance assumptions in contextual bandits (Assumption 3.2) and RL (Assumption 3.5), we have $c_v \\le 2$.\nWith this constant established, the final regret bound for contextual bandits simplifies to:\n$$\n\\tilde{O}\\left(\\sqrt{d_\\mathcal{F} \\log N_\\mathcal{F} \\sum_{t \\in [T]}\\sigma_t^2} + \\max\\left\\\\{1, \\sqrt{\\frac{d_\\mathcal{G} \\log N_\\mathcal{G}}{d_\\mathcal{F} \\log N_\\mathcal{F}}}\\right\\\\} R d_\\mathcal{F} \\log N_\\mathcal{F}\\right).\n$$"}}, "id": "3EpMdbGojg", "forum": "zQhJSohBUl", "replyto": "zQhJSohBUl", "signatures": ["ICLR.cc/2026/Conference/Submission8535/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8535/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8535/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763698791554, "cdate": 1763698791554, "tmdate": 1763698791554, "mdate": 1763698791554, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors propose a multi-level regression framework for nonlinear contextual bandits and model-based RL. The key algorithmic idea is ADALEVEL, which partitions data using both a per-point uncertainty proxy and an online-learned variance upper bound; separate weighted regressions are run per level and actions are chosen by the minimum across level-wise UCBs. A central technical ingredient is a Bernstein/Freedman-style concentration lemma for nonlinear regression that decouples variance from uncertainty, fixing the $\\sqrt{d_F}$ gap that persisted in prior nonlinear multi-layer analyses. For bandits, UCB-MLR achieves a second-order regret\n$\\tilde O(\\sqrt{d_F \\log N_F \\sum_t \\sigma_t^2} + \\max(1,C) R d_F \\log N_F)$\nwith $C=\\max(1,c_v)\\sqrt{(d_G \\log N_G)/(d_F \\log N_F)}$, matching the known lower bound in the main term under standard realizability. For RL, the same multi-level idea combined with value-targeted regression yields an instance-dependent, horizon-free bound\n$\\tilde O(\\sqrt{d_F \\log N_F \\mathrm{Var}^\\*_K} + \\max(1,c_v) d_F \\log N_F)$."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper studies nonlinear contextual bandits with unknown variances, where prior multi-layer methods incurred an extra $\\sqrt{d_F}$ in the leading term. The decoupled Bernstein bound together with variance-aware leveling removes this and reaches the minimax-tight second-order rate, resolving a standing gap and aligning with the spirit of the linear case. The adaptive leveling idea is clean and potentially reusable in other online learning settings. The paper is clearly written and the approach is easy to follow."}, "weaknesses": {"value": "The lower-order term in the bandit regret depends on the second-moment modeling through $C$. When $d_G \\log N_G \\gg d_F \\log N_F$, this term scales like\n$\\tilde O(R \\cdot \\max(1,c_v)\\sqrt{(d_F \\log N_F)(d_G \\log N_G)})$\nrather than purely $d_F \\log N_F$. While I do not have a concrete instance where $d_G \\log N_G$ dominates, this dependence is a side effect of learning the variance via a separate class and may leave a (lower-order) gap in unfavorable modelings.\n\nMinor typos and suggestions:\n- In Equation (4.2), the squared-target regression for $g$ should minimize over $\\mathcal G$ (not $\\mathcal F$).\n- In Line 8 of Algorithm 1, to align with Assumption 3.2, ADALEVEL should receive $c_v R \\bar \\sigma_t$ (or state $R=1$ after normalization).\n- The paper uses both $l$ and $\\ell$ as level indices for the $\\mathcal F$- and $\\mathcal G$-branches; consider renaming one of them for readability."}, "questions": {"value": "- What is the exact definition of $d_P$ when comparing to distributional/transition-model baselines? It would be helpful to state this explicitly in the introduction alongside Tables 1.\n- The paper assumes the second moment is realizable. While common in recent work, is this assumption necessary here? In RL, could one leverage the structure of $V^2$ directly (e.g., via clipped/Catoni-style targets) to avoid a separate modeling burden while keeping horizon-free rates?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2PZMsVPpM3", "forum": "zQhJSohBUl", "replyto": "zQhJSohBUl", "signatures": ["ICLR.cc/2026/Conference/Submission8535/Reviewer_rGUp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8535/Reviewer_rGUp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8535/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761877860710, "cdate": 1761877860710, "tmdate": 1762920394326, "mdate": 1762920394326, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Common Response QA2 1/2"}, "comment": {"value": "**Q2** Why is the second-order realizability assumption ($g\\_* \\in \\mathcal{G}$) necessary in contextual bandit problems, and how does it relate to previous work?\n\n**A2**\n### Necessity of the assumption\n\nTo establish tight second-order regret bounds in the nonlinear contextual bandit setting, accurate variance estimation is crucial. Therefore, we require the realizability of the second-order moment ($g_* \\in \\mathcal{G}$) to tractably estimate the variance.\n\nEliminating this assumption while maintaining a $\\sqrt{d_\\mathcal{F}}$-depended regret remains a highly challenging open question, which we leave for important future work."}}, "id": "exun1zlIzj", "forum": "zQhJSohBUl", "replyto": "zQhJSohBUl", "signatures": ["ICLR.cc/2026/Conference/Submission8535/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8535/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8535/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763698918996, "cdate": 1763698918996, "tmdate": 1763698918996, "mdate": 1763698918996, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a unified Multi-Level Regression (MLR) framework for both contextual bandits and model-based reinforcement learning with general function approximation. The framework leverages multi-level uncertainty partitioning and weighted regression to jointly estimate rewards and higher-order variance information. The authors claim three main advantages: (1) instance-dependent regret bounds, (2) second-order exploration guarantees, and (3) horizon-free regret in RL settings. The paper demonstrates theoretical benefits compared to prior work such as Huang et al. (2024) and Wang et al. (2025), particularly achieving improved computational tractability while maintaining strong statistical guarantees. Regret analyses, confidence bounds, and computational complexity are rigorously addressed."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Theoretical generality and unification\nThe proposed multi-level regression framework is conceptually appealing and unifies several strands of variance-aware learning in contextual bandits and RL under a single analytical blueprint. The results meaningfully extend horizon-free and instance-dependent learning beyond linear mixture MDPs.\n\nImprovement over closely related approaches\nThe paper offers a more favorable combination of assumptions, regret guarantees, and computational efficiency compared to:\nHuang et al. (2024): avoids suboptimal dependencies on higher-order value moments\nO-MBRL (Wang et al., 2025): avoids requiring access to the full transition distribution\nThe work achieves a strong balance between theory and algorithmic feasibility."}, "weaknesses": {"value": "1.Strong realizability assumptions limit practicality\nThe requirement that both the mean reward function \\*f\\* and the variance model \\*g\\* lie in known hypothesis classes is quite restrictive—especially in model-based RL, where model misspecification often induces compounding errors. The feasibility of estimating higher-order variance surrogates in realistic environments is not adequately addressed.\n\n2.Insufficient explanation of the multi-level mechanism\nThe ADALEVEL component and level partitioning strategy play a central role but lack conceptual intuition. It remains unclear: why this particular partitioning is necessary, how level granularity influences performance, what happens under noisy or misclassified uncertainty estimates. The methodological novelty therefore feels underspecified.\n\n3.Lack of empirical evaluation\nThe submission provides no experiments to validate computational advantages or regret improvements in practice. For a venue like ICLR, this severely weakens the impact—especially given that comparable works demonstrate sample-efficient performance empirically.\n\n4.Limited discussion of highly related prior research\nWhile the paper cites key works (Ye et al., 2025; Huang et al., 2024; Zhao et al., 2023), the comparative analysis is mostly surface-level. It would be beneficial to more explicitly quantify: the precise statistical gaps closed relative to each approach, the behavior of MLR under approximate function classes.\n\n5.Exposition challenges\nPresentation is dense and relies heavily on appendix proofs. Several key insights are obscured by technical details, making the core contribution harder to appreciate for general RL readers.\n\nThis paper follows previous works problem, lacking problem novelty."}, "questions": {"value": "see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "B8g5STD8j2", "forum": "zQhJSohBUl", "replyto": "zQhJSohBUl", "signatures": ["ICLR.cc/2026/Conference/Submission8535/Reviewer_WtmF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8535/Reviewer_WtmF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8535/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761902998845, "cdate": 1761902998845, "tmdate": 1762920393900, "mdate": 1762920393900, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Common Response QA2 2/2"}, "comment": {"value": "### Relationship with prior works\n\nOur assumption is a middle ground bridging linear and fully distributional approaches. While we make stronger assumptions than the linear bandits in [1], our setting addresses the significantly harder problem of general function approximation. Crucially, our assumption is strictly weaker than [2], who assume realizability of the full reward distribution $\\mathcal{P}$. In contrast, we only assume realizability of the first two moments, $\\mathcal{F}$ and $\\mathcal{G}$, which are automatically induced by $\\mathcal{P}$. Furthermore, the extra $d_\\mathcal{G}$-related term appears only in the lower-order term not scaling with $\\sqrt{T}$.\n\nTo rigorously demonstrate that our assumption is weaker, we establish a relationship between our complexity measures ($d_\\mathcal{F}, N_\\mathcal{F}, d_\\mathcal{G}, N_\\mathcal{G}$) and the distributional complexity ($d_\\mathcal{P}, N_\\mathcal{G}$). Since $\\mathcal{P}$ is a collection of distributions, we consider the Hellinger Eluder dimension.\n\n**Definition (Hellinger Eluder Dimension).** For a model class $\\mathcal{P} \\subset \\mathcal{X} \\to \\Delta(\\mathbb{R})$, let $d_\\mathcal{P}(\\alpha)$ be the length of the longest sequence $(x_i, P_i, P'_i)$ where $P_i, P'_i \\in \\mathcal{P}$ satisfy $\\sum\\_{j<i} H^2(P_i(x_j), P'_i(x_j)) \\le \\alpha^2$ but $H^2(P_i(x_i), P'_i(x_i)) > \\alpha^2$. Here, $H(P, Q)$ denotes the Hellinger distance: $H^2(P,Q) = \\frac{1}{2} \\int (\\sqrt{dP(x)} - \\sqrt{dQ(x)})^2$.\n\nRoughly speaking, this replaces Euclidean distance with Hellinger distance in the standard Eluder dimension definition. The moment classes $\\mathcal{F}$ and $\\mathcal{G}$ are induced from $\\mathcal{P}$ as\n\\begin{aligned}\n\\mathcal{F} &= \\\\{f: \\mathcal{X} \\to \\mathbb{R}: | \\exists P \\in \\mathcal{P}, f(x) = \\mathbb{E}\\_{y \\sim P(x)}[y]\\\\},\\\\\\\\\n\\mathcal{G} &= \\\\{g: \\mathcal{X} \\to \\mathbb{R}: | \\exists P \\in \\mathcal{P}, g(x) = \\mathbb{E}\\_{y \\sim P(x)}[y^2]\\\\}.\n\\end{aligned}\n\n**Core Inequality: Hellinger Dominates Moments**\nHellinger distance controls the distance between moments for bounded variables. Using the relation between Total Variation (TV) and Hellinger distance, $TV(P,Q) \\le \\sqrt{2} H(P,Q)$, we have:\n\\begin{aligned}\n|f_P - f_Q| &= |\\int y (dP - dQ)| \\le R \\cdot TV(P,Q) \\le \\sqrt{2}R \\cdot H(P,Q),\\\\\\\\\n|g_P - g_Q| &= |\\int y^2 (dP - dQ)| \\le R^2 \\cdot TV(P,Q) \\le \\sqrt{2}R^2 \\cdot H(P,Q).\n\\end{aligned}\n\n**Relationship between Covering Numbers**\nSince Hellinger distance dominates moment distance, an $\\epsilon$-cover of $\\mathcal{P}$ induces an $O(\\epsilon)$-cover of $\\mathcal{F}$ and $\\mathcal{G}$. Thus, $\\log N_\\mathcal{F} \\le \\log N_\\mathcal{P} $ and $\\log N_\\mathcal{G} \\le \\log N_\\mathcal{P}$.\n\n**Relationship between Eluder Dimensions**\nSince the Hellinger distance is a stronger metric, if a sequence of contexts $x_1​,…,x_t​$ is independent with respect to the mean, i.e., we can predict past means well but fail on the current mean, it must also be independent with respect to the Hellinger distance, because failing on the mean implies a large Hellinger distance.\n\nIn other words, the complexity of learning the distribution upper-bounds the complexity of learning its moments. Consider two distributions $P_1, P_2$ with the same mean but different variances (e.g., a peak vs. a flat distribution). They are indistinguishable in $\\mathcal{F}$ ($f_1(x) = f_2(x)$) but distinguishable in $\\mathcal{P}$ ($H(P_1, P_2) > 0$). An algorithm learning $\\mathcal{P}$ must resolve this uncertainty, whereas an algorithm learning $\\mathcal{F}$ assumes it is resolved. Thus, a sequence of points can be independent with respect to $\\mathcal{P}$ while being dependent with respect to $\\mathcal{F}$. Consequently, $d_\\mathcal{F} \\le d_\\mathcal{P}$ and $d_\\mathcal{G} \\le d_\\mathcal{P}$.\n\n**Conclusion**\nSubstituting these relationships into our regret bound (Theorem 4.2), the lower-order term satisfies:\n$$\nR \\sqrt{d_\\mathcal{F} \\log N_\\mathcal{F} d_\\mathcal{G} \\log N_\\mathcal{G}}) \\le R d_\\mathcal{P} \\log N_\\mathcal{P}.\n$$\nThis confirms that when $\\mathcal{P}$ has finite Eluder dimension and covering number, our bound matches the state-of-the-art distributional result of [2] while remains valid in broader settings where full distributional realizability may not hold.\n\n[1] Zhao, Heyang, et al. \"Variance-dependent regret bounds for linear bandits and reinforcement learning: Adaptivity and computational efficiency.\" The Thirty Sixth Annual Conference on Learning Theory. PMLR, 2023.\\\n[2] Wang, Kaiwen, et al. \"More Benefits of Being Distributional: Second-Order Bounds for Reinforcement Learning.\" International Conference on Machine Learning. PMLR, 2024."}}, "id": "FL5dVOAxgt", "forum": "zQhJSohBUl", "replyto": "zQhJSohBUl", "signatures": ["ICLR.cc/2026/Conference/Submission8535/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8535/Authors"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8535/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763698959513, "cdate": 1763698959513, "tmdate": 1763698959513, "mdate": 1763698959513, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This submission claims to shave a $\\sqrt{d}$ factor in the variance-dependent regret bound for learning bandits and episodic MDPs with general function approximation under various additional assumptions, especially the known uniform upper bound on the reward variance. The proposed algorithm employ an algorithmic peeling technique for both the second and forth order moments, whose analysis relies on a newly established martingale concentration for nonlinear online regression with uniform noise upper bound."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The proof is well-written.\n- This is the first work under general function approximation claiming to be able to nearly recover the tight dimension dependency for linear bandits and linear mixture MDPs. And the recovery of Zhao et al. (2023) in the MDP setting is faithful and correct."}, "weaknesses": {"value": "- The outline from Lemma 4.3 to Theorem 4.2 is strictly weaker than Zhao et al. (2023) in the linear case because Zhao et al. (2023) does not need the uniform upper bound $\\sup_{t} \\sigma_t$ to be known to the agent.\n- Table 1 is misleading. Actually, Zhao et al. does not need this assumption involving $c_v$, which means to have an apple-to-apple comparison, the second term in the authors' regret bound (for linear bandits) should scale with $R^2$ instead of $R$.\n- The authors omit the dependency w.r.t. $\\mathcal{G}$ here. But it is crucial to notice that $\\mathcal{G}$ does NOT have an apple-to-apple counterpart in Zhao et al. (2023). Since $g_* \\in \\mathcal{G}$ essentially models $f_*^2(x_t) + \\mathrm{Var}[\\epsilon_t | x_t]$, and $\\mathrm{Var}(\\epsilon_t|x_t)$ can have very complex dependency w.r.t. $x_t$, which is allowed and is NOT modeled using an additional Eluder dimension in Zhao et al. (2023), the regret bound in this table might be considered misleading or an overclaim, unless the authors can propose a concrete upper bound of $d_\\mathcal{G}$ in the setting of Zhao et al. (2023)"}, "questions": {"value": "- In the MDP setting, if the authors' total reward is bounded by $1$ in each episode, the $c_v$ in Assumption 3.5 can be just $c_v=2$ following the Lemma E.7 in https://arxiv.org/pdf/2407.15007, right?\n- In the MDP setting, since the authors are only peeling the second and the forth moments, is it possible to follow the spirit of [The proof of Lemma 3.2 in https://arxiv.org/pdf/2407.15007] to bypass the tedious high-order expansion arguments in Appendix C.2 and Appendix D?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ceLJ02PJg0", "forum": "zQhJSohBUl", "replyto": "zQhJSohBUl", "signatures": ["ICLR.cc/2026/Conference/Submission8535/Reviewer_xHti"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8535/Reviewer_xHti"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8535/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762439138741, "cdate": 1762439138741, "tmdate": 1762920393611, "mdate": 1762920393611, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}