{"id": "xiKtlg1jED", "number": 10874, "cdate": 1758183783277, "mdate": 1763698049751, "content": {"title": "PartCo: Part-Level Correspondence Priors Enhance Category Discovery", "abstract": "Generalized Category Discovery (GCD) aims to identify both known and novel categories within unlabeled data by leveraging a set of labeled examples from known categories. Existing GCD methods primarily depend on semantic labels and global image representations, often overlooking the detailed part-level cues that are crucial for distinguishing closely related categories. In this paper, we introduce PartCo, short for Part-Level Correspondence Prior, a novel framework that enhances category discovery by incorporating part-level visual feature correspondences. By leveraging part-level relationships, PartCo captures finer-grained semantic structures, enabling a more nuanced understanding of category relationships. Importantly, PartCo seamlessly integrates with existing GCD methods without requiring significant modifications. Our extensive experiments on multiple benchmark datasets demonstrate that PartCo significantly improves the performance of current GCD approaches, achieving state-of-the-art results by bridging the gap between semantic labels and part-level visual compositions, thereby setting new benchmarks for GCD. Code will be made publicly available.", "tldr": "We present PartCo, a framework that uses part-level visual cues to enhance Generalized Category Discovery, achieving state-of-the-art performance with seamless integration into existing methods.", "keywords": ["Generalized Category Discovery"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0b5aa39df07faec971e630b309785baca66f8cd8.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper tackles the task of generalized category discovery - given a labelled training set up some categories learn a model to automatically cluster an unlabelled test set which contains both seen and unseen categories. Particularly this paper focuses on part-level correspondence aiming to capture relationships between categories in terms of shared components/parts to aid generalized category discovery. This is achieved by performing PCA on DINO features to obtain fine-grained features and then clustering these features into parts. The resulting part-level features can then be integrated into existing GCD methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is generally well-presented, with visuals that effectively aid understanding of the proposed approach.\n***\n\n- The idea of leveraging object parts for GCD is interesting and particularly relevant for fine-grained scenarios where category discovery is more realistic and challenging.\n***\n\n- The method is well-motivated, making good use of the richer feature representations available in DINO beyond the CLS token.\n***\n\n- The evaluation includes both generic and fine-grained datasets, demonstrating reasonable generality of the approach.\n***\n\n- The proposed framework is flexible and can be combined with different existing GCD methods, increasing its potential applicability.\n***\n\n- The use of DINOv3 features is appreciated as it helps keep the experiments aligned with the current state of the field.\n***\n\n- The comparison between implicit and explicit part-level learning in Table 4 is a nice inclusion and provides some insight into the benefits of the explicit formulation."}, "weaknesses": {"value": "- An existing work in GCD also uses part-level correspondence [A]. The difference to this work in terms of approach and performance needs to be made clear\n***\n\n- It remains unclear whether explicit part modelling is necessary. Could similar benefits be achieved simply by removing background features? Including a “single-part” or “foreground-only” variant in the ablation (e.g., Figure 7) would help clarify this.\n***\n\n- It would be useful to better understand how the method performs on more challenging or long-tailed datasets such as Herbarium. While Herbarium and Oxford Pets are tested in the supplementary material, the comparison is only made against SimGCD. This feels incomplete, especially since other works such as SelEX and Flipped Classroom report results on these datasets and include more extensive baselines.\n***\n\n- SelEX is no longer the current state of the art on fine-grained datasets as this paper claims since there are newer works in GCD [A,B,C,D] with [A,B,C] all demonstrating to outperform Selex. Therefore framing comparisons primarily against selex  misrepresents the true standing of the proposed method. These newer works should be added in the comparison.\n***\n\n- While the proposed approach performs well on the fine-grained datasets, outperforming all methods compared to, the results are more mixed on the generic datasets where on some metric FlipClass outperforms.\n- I don't think this is a major issue as the performance is still strong, however it would have been interesting to see if better results could be achieved by combining the proposed approach and FlipClass\n***\n\n[A] Dai et al. Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement. CVPR 2025.\n***\n[B] Liu et al. Hyperbolic Category Discovery. CVPR 2025.\n***\n[C] Tang et al. Dissecting Generalized Category Discovery: Multiplex Consensus under Self-Deconstruction. ICCV 2025.\n***\n[D] Xu et al. A Hidden Stumbling Block in Generalized Category Discovery: Distracted Attention. ICCV 2025."}, "questions": {"value": "- Comparison to [A]: Could the methodological and numerical difference to [A] be clarified?\n***\n\n- Necessity of parts: Could the reported improvements be explained by background suppression rather than true part reasoning? Have you tested a variant using only a single (foreground) part to isolate this effect?\n***\n\n- More challenging datasets: Why are other baselines (e.g., Flipped Classroom, SelEX) omitted from the comparisons on Herbarium and Oxford Pets, given that results for these datasets are already publicly available?\n***\n\n- Further comparisons: Why are more recent methods e.g. [A,B,C,D] omitted from the state-of-the-art comparison?\n***\n\n- Understanding features: DINOv2 consistently outperforms DINOv3 in your experiments. Can you provide an explanation or hypothesis for this surprising trend?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VV5RpvV9Pj", "forum": "xiKtlg1jED", "replyto": "xiKtlg1jED", "signatures": ["ICLR.cc/2026/Conference/Submission10874/Reviewer_rMXF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10874/Reviewer_rMXF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10874/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761310507215, "cdate": 1761310507215, "tmdate": 1762922088014, "mdate": 1762922088014, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General response of Submission 10874 by Authors"}, "comment": {"value": "#### We thank all reviewers, **R1 (#bQ1m)**, **R2 (#nFJh)**, **R3 (#fJDg)**, and **R4 (#rMXF)** for their thoughtful and constructive feedback, and in particular, for recognizing the key contributions of our well motivated work in Generalized Category Discovery (GCD). Across the reviews, there is broad agreement on the strong motivation and key insight presented in our work, i.e., **(1)** the importance of incorporating explicit part-level learning for GCD (all reviewers). **(2)** Moreover, several reviewers positively highlighted both our simple, genuinely plug-and-play, and effective framework design (R1, R3, R4), **(3)** Its strong performance gains across different baseline models and strong robustness and generalizability across datasets (all reviewers), **(4)** as well as our well-written paper and clear exposition (R2, R4).\n\n#### We have carefully addressed all comments in the rebuttal (organized by reviewer and question index **R{reviewer}.{question}**, e.g., **R1.1**, **R3.6**, etc.), and we have revised the paper accordingly. **The supplementary material can be found in the same PDF as the main paper**, immediately following the References section. We are happy to address any remaining concerns.\n\n#### Below, we summarize the major updates made to the paper (All revisions are marked in blue) during the discussion period: \n- #### **Main paper, Tables 1 and 2:** Added comparisons with 11 recent works published in ICLR’25 [a], CVPR’25 [b, c, d], ICCV’25 [e, f, g], TMM [h], ICML’25 [i], NeurIPS’25 [j, k]), per R1 (**R1.1**), and R4 (**R4.4**). Also added new baselines SPTNet and FlipClass for PartCo (R2, **R2.1**).\n- #### **Main paper, Table 4:** Added an ablation on the balancing factor, addressing R1 (**R1.3**) and R3 (**R3.7**).\n- #### **Supplementary, Section S3.4:** Added experiments with a CLIP backbone [l,m,n,o] (R3, **R3.2**).\n- #### **Supplementary, Section S3.5, Table I:** Added analysis on choosing 1st- vs 2nd-order correspondence labels (R3, **R3.3**).\n- #### **Supplementary, Section S2.3:** Added computational overhead details (R3, **R3.4**).\n- #### **Supplementary, Section S3.5, Table H:** Added analysis of part-label quality and effectiveness (R3, **R3.5**).\n- #### **Supplementary, Section S1:** Expanded related work and clarified differences from concurrent works (R4, **R4.1**).\n- #### **Supplementary, Section S3.6:** Justified the use of explicit part-level correspondence learning (R4, **R4.2**).\n\n#### References\n- #### [a] Liu, Yuanpei, and Kai Han. \"Debgcd: Debiased learning with distribution guidance for generalized category discovery.\" In ICLR. 2025.\n\n- #### [b] Dai, Qiyuan, et al. \"Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement.\" In CVPR. 2025.\n\n- #### [c] Peng, Zhengyuan, et al. \"MOS: Modeling Object-Scene Associations in Generalized Category Discovery.\" In CVPR. 2025.\n\n- #### [d] Liu, Yuanpei, Zhenqi He, and Kai Han. \"Hyperbolic category discovery.\" In CVPR. 2025.\n\n- #### [e] Xu, Qiyu, et al. \"A hidden stumbling block in generalized category discovery: Distracted attention.\" In ICCV. 2025.\n\n- #### [f] Cao, Xinzi, et al. \"AllGCD: Leveraging All Unlabeled Data for Generalized Category Discovery.\" In ICCV. 2025.\n\n- #### [g] Tang, Luyao, et al. \"Dissecting generalized category discovery: Multiplex consensus under self-deconstruction.\" In ICCV. 2025.\n\n- #### [h] Wang, Enguang, et al. \"Learning Part Knowledge to Facilitate Category Understanding for Fine-Grained Generalized Category Discovery.\" IEEE Transactions on Multimedia. 2025.\n\n- #### [i] Liu, Duo, et al. \"Generalized Category Discovery via Reciprocal Learning and Class-Wise Distribution Regularization.\" In ICML. 2025.\n\n- ##### [j] He, Zhenqi, Yuanpei Liu, and Kai Han. \"Seal: Semantic-aware hierarchical learning for generalized category discovery.\" In NeurIPS. 2025.\n\n- #### [k] Han, Jizhou, et al. \"Unleashing the Power of Neural Collapse: Consistent Supervised-Unsupervised Alignment for Generalized Category Discovery.\" In NeurIPS. 2025.\n\n- #### [l] Zheng, Haiyang, et al. \"Textual knowledge matters: Cross-modality co-teaching for generalized visual class discovery.\" In ECCV. 2024.\n\n- #### [m] Wang, Enguang, et al. \"Get: Unlocking the multi-modal potential of clip for generalized category discovery.\" In CVPR. 2025.\n\n- #### [n] Ouldnoughi, Rabah, Chia-Wen Kuo, and Zsolt Kira. \"Clip-gcd: Simple language guided generalized category discovery.\" arXiv preprint arXiv:2305.10420. 2023.\n\n- #### [o] Yang, Muli, et al. \"Consistent prompt tuning for generalized category discovery.\" International Journal of Computer Vision. 2025.\n\n- #### [p] He, Zhenqi, Yuanpei Liu, and Kai Han. \"Category Discovery: An Open-World Perspective.\" arXiv preprint arXiv:2509.22542. 2025."}}, "id": "YrcQnibIYn", "forum": "xiKtlg1jED", "replyto": "xiKtlg1jED", "signatures": ["ICLR.cc/2026/Conference/Submission10874/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10874/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10874/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763698180756, "cdate": 1763698180756, "tmdate": 1763698180756, "mdate": 1763698180756, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces PartCo, a framework that enhances Generalized Category Discovery (GCD) by incorporating part-level correspondence priors extracted from ViT patch tokens."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Clear motivation for why part-level information helps GCD, especially for fine-grained categories with shared global features but different local compositions\n- Simple and effective approach that leverages existing foundation models without requiring additional annotations or complex architectural changes\n- Genuinely plug-and-play—demonstrated compatibility with multiple GCD baselines (SimGCD, SelEx, SPTNet, etc.) with consistent improvements"}, "weaknesses": {"value": "- The novelty is somewhat limited. Using patch tokens from foundation models to extract fine-grained features is increasingly common. The specific formulation of first and second-order correspondences is the main technical contribution, but this feels incremental.\n\n- The reliance on DINO features for correspondence labels means PartCo inherits DINO's biases and limitations. If DINO fails to capture relevant part correspondences (e.g., due to severe occlusion or unusual viewpoints), PartCo will struggle. This dependency is acknowledged in limitations but not thoroughly analyzed.\n\n- The choice of second-order correspondence is not well-justified theoretically. Why stop at second-order? Have you tried third-order or higher? Is there a principle for selecting the order, or is it empirical?\n\n- Limited analysis of failure cases or when part-level features don't help. The paper shows PartCo improves performance on average, but are there categories or scenarios where it hurts? For example, what about categories distinguished by global shape rather than local parts?\n\n- Computational cost analysis is incomplete. How much does PartCo add to training time and memory? The paper mentions it's \"lightweight\" but doesn't provide concrete numbers or scalability analysis.\n\n- The part correspondence labels are treated as pseudo-ground-truth, but their quality is not validated. How accurate are these correspondences? Some analysis comparing against manually annotated part correspondences (available in CUB) would strengthen the paper.\n\n- The paper claims part-level features help with novel category discovery, but the analysis mostly focuses on fine-grained datasets where this is intuitive. The gains on ImageNet and CIFAR are smaller, suggesting limited benefit for coarse-grained categories. This limitation deserves more discussion."}, "questions": {"value": "1. Have you validated the quality of correspondence labels against ground-truth part annotations in CUB? What's the alignment accuracy?\n\n2. Why second-order specifically? Can you provide ablations on first-order only, second-order only, and third-order to justify this choice?\n\n3. How does PartCo perform when the foundation model (DINO) fails to capture good part correspondences? Can you show failure cases?\n\n4. What is the computational overhead? Please provide training time, memory usage, and FLOPs comparisons.\n\n5. For coarse-grained categories (ImageNet, CIFAR), the gains are modest. Can you analyze which types of categories benefit from part-level features and which don't?\n\n6. How sensitive is PartCo to the hyperparameter λp (correspondence loss weight)? The ablation shows some variation but doesn't analyze why certain values work better for different datasets.\n\n7. The attention maps show PartCo focuses on parts, but how does this translate to better novel category discovery specifically? Can you show examples where part-level features helped correctly cluster novel categories that global features confused?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TN1UzNyTgs", "forum": "xiKtlg1jED", "replyto": "xiKtlg1jED", "signatures": ["ICLR.cc/2026/Conference/Submission10874/Reviewer_fJDg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10874/Reviewer_fJDg"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10874/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761504624873, "cdate": 1761504624873, "tmdate": 1762922087647, "mdate": 1762922087647, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a new learning framework for Generalized Category Discovery (GCD) by integrating explicit part-level visual feature correspondences. In contrast to traditional GCD methods, the proposed approach enhances category understanding and discovery by leveraging compositional object features. Experimental results on benchmark datasets demonstrate that the method achieves improved performance in most cases."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation of the paper is clear, and the content is easy to understand.\n2. The idea of incorporating explicit part-level visual feature correspondences is interesting.\n3. The experimental results indicate that the proposed method outperforms existing approaches across different benchmark datasets in most scenarios."}, "weaknesses": {"value": "1. The technical novelty appears somewhat limited, particularly as the work is built upon the existing SimGCD framework.\n2. The generalization capability of the method has not been fully validated, as only two baseline methods are tested. Evaluation with more benchmark methods is recommended.\n3. Most existing GCD methods use pre-trained models different from DINOv2 and DINOv3, making it difficult to fairly compare the results with those reported in original studies. It is suggested to maintain consistency in the pre-trained model for a more equitable comparison."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CovTJwbRJl", "forum": "xiKtlg1jED", "replyto": "xiKtlg1jED", "signatures": ["ICLR.cc/2026/Conference/Submission10874/Reviewer_nFJh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10874/Reviewer_nFJh"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10874/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761981449859, "cdate": 1761981449859, "tmdate": 1762922087207, "mdate": 1762922087207, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel framework, PartCo that introduces a part-level correspondence prior to improve category discovery by leveraging fine-grained visual relationships beyond global image features. It integrates seamlessly with existing GCD methods and enhances both supervised and unsupervised learning through a novel part-level contrastive loss. Experiments across multiple benchmarks show significant accuracy gains and state-of-the-art performance, validating its effectiveness and adaptability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "(1) The proposed method, PartCo,  effectively integrates part-level visual priors into existing GCD frameworks, enhancing fine-grained category discrimination without altering model architecture.\n\n(2) It consistently achieves state-of-the-art performance across multiple benchmark datasets, demonstrating strong robustness and generalizability."}, "weaknesses": {"value": "Related works are not discussed properly. More recent works are needed to be cited.\n\n(1) Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement, CVPR 2025\n\n(2) Hyperbolic Category Discovery, CVPR 2025\n\n(3) Cdad-net: Bridging domain gaps in generalized category discovery, CVPR 2024\n\n(4) MOS: Modeling Object-Scene Associations in Generalized Category Discovery, CVPR 2025"}, "questions": {"value": "(1) Is the selection of between 1st- and 2nd-order labels dataset-dependent? How could you decide the best in general?\n\n(2) What are the effects of the hyperparameters i.e. PCA threshold $\\tau$ and the balancing factor $\\lambda_{b}$, as these are empirically chosen?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rpEt1I6iNi", "forum": "xiKtlg1jED", "replyto": "xiKtlg1jED", "signatures": ["ICLR.cc/2026/Conference/Submission10874/Reviewer_bQ1m"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10874/Reviewer_bQ1m"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10874/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762207109948, "cdate": 1762207109948, "tmdate": 1762922086815, "mdate": 1762922086815, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}