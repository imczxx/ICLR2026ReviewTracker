{"id": "7aO0YLtXb6", "number": 16183, "cdate": 1758261126805, "mdate": 1759897256016, "content": {"title": "From Muon to Gluon: Bridging Theory and Practice of LMO-based Optimizers for LLMs", "abstract": "Recent developments in deep learning optimization have brought about radically new algorithms based on the Linear Minimization Oracle (LMO) framework, such as ùñ¨ùóéùóàùóá and ùñ≤ùñºùóÇùóàùóá. After over a decade of ùñ†ùñΩùñ∫ùóÜ's dominance, these LMO-based methods are emerging as viable replacements, offering several practical advantages such as improved memory efficiency, better hyperparameter transferability, and most importantly, superior empirical performance on large-scale tasks, including LLM training. However, a significant gap remains between their practical use and our current theoretical understanding: prior analyses (1) overlook the layer-wise LMO application of these optimizers in practice, and (2) rely on an unrealistic smoothness assumption, leading to impractically small stepsizes. To address both, we propose a new LMO-based framework called ùñ¶ùóÖùóéùóàùóá, capturing prior theoretically analyzed methods as special cases, and introduce a new refined generalized smoothness model that captures the layer-wise geometry of neural networks, matches the layer-wise practical implementation of ùñ¨ùóéùóàùóá and ùñ≤ùñºùóÇùóàùóá, and leads to state-of-the-art convergence guarantees. Our experiments with NanoGPT and CNN confirm that our assumption holds along the optimization trajectory, ultimately closing the gap between theory and practice.", "tldr": "Novel layer-wise smoothness assumption provides a more realistic theoretical basis for LMO-based optimizers, leading to adaptive stepsizes.", "keywords": ["Optimization", "Deep Learning", "Muon", "Generalized Smoothness"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/98dd5d8a88c31bbc7ac57ca3678b1de70c9934a8.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces Gluon, a generalized linear minimization oracle (LMO) optimization method that unifies Muon, Scion, and SGD as specific instances. The authors define an extension of the concept of L-smoothness of the loss landscape, and derive convergence bounds for Gluon based on the smoothness parameters. By assuming the bounds are tight, one can estimate the optimal learning rates after observing a training run, and these closely match those found through hyperparameter searches. This suggests that the generalized smoothness formulation provides a more accurate description of the loss landscape than classical L-smoothness, and offers a principled alternative to ad hoc tuning of per-layer step sizes."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Gluon unifies existing theory surrounding other LMO optimizers, and is able to provide generalized bounds that specialize into known bounds for specific cases.\n- Gluon offers a way to estimate the best possible learning rates from observation of a finished training run."}, "weaknesses": {"value": "- Learning rate estimation from observing a training run hinges on a crucial assumption that bound (4) is saturated, which I do not find to be plausible in practice.\n- Not very much empirical evidence is given to show that the modified smoothness model accurately describes the loss landscape.\n- Not very much empirical evidence is given to show that the modified smoothness model of the loss landscape, which the analysis is based upon, is a better description than classical L-smoothness, for deep learning tasks. Some learning rates match across theory and experiment, but that's it.\n- A training run must be done first, at the same scale, in order to estimate the best possible learning rates. Other methods relying on scaling laws only require having a previous run at a smaller scale in order to predict the best learning rates at a larger scale.\n- To obtain learning rates from a past training run, one must estimate the smoothness parameters by presuming saturation of Inequality (4). Even if we ignore the accuracy of the saturation assumption, the method in Equation (10) used to estimate terms of Inequality (4) is not very sound. Saturation of Inequality (4) requires the value calculated by Equation (10) to be as high as possible, whereas Equation (10) is likely to produce a value as low as possible, since learning trajectories tend to proceed down the smoothest directions of a loss landscape on most iterations. The bound (4) will probably end up too loose and the smoothness parameters recovered by presuming tightness will be unreliable."}, "questions": {"value": "- Is there any more evidence that the theory matches experiment? For example to test the validity of Assumption 1: after you estimate $L_i^0$ and $L_i^1$ by experiment, can you adverserially try to pick $X$ and $Y$ to break Assumption 1, but only ever manage to saturate the bound and never break it, showing that the assumption is accurate and faithful to the shape of the loss landscape?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6k4UpAkf0E", "forum": "7aO0YLtXb6", "replyto": "7aO0YLtXb6", "signatures": ["ICLR.cc/2026/Conference/Submission16183/Reviewer_sxLL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16183/Reviewer_sxLL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16183/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760555737816, "cdate": 1760555737816, "tmdate": 1762926347131, "mdate": 1762926347131, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Gluon, a unifying, layer-wise LMO-based optimizer framework within which Muon and Scion are special cases. They claim to bridge the gap between theory and practice by proposing a layer-wise (L_0,L_1)-smoothness assumption that allows them to prove convergence in the stochastic optimization setting using step sizes that do not shrink with the number of training iterations. The authors claim that this is more realistic than previous work for two reasons: (a) trajectory smoothness varies significantly from layer to layer when training neural networks, and (b) learning rates that are inversely proportional to the number of steps quickly become too small to be realistic in practice. Empirically, the paper validates the smoothness model and step-size structure with NanoGPT-124M trained on FineWeb and a CNN trained on CIFAR-10, showing that their proposed smoothness model tracks closely with the observed trajectory smoothness. They also find that per-layer radii used in Scion correlate with their theoretically suggested magnitudes."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is well written. It is easy to understand the contributions of the paper, and their relation to previous work is made clear.\n- The introduction of layer-wise smoothness is an improvement upon existing work. \n- The introduction of realistic step sizes in the proof is a clear improvement. \n- I appreciate the empirical validation of assumption 1 in figures (1) and (2).\n- While I have limited experience with proving convergence, I did read through the math in the paper and did not notice any mistakes. However, I did not check the proofs."}, "weaknesses": {"value": "- While I appreciate that the paper bridges the theory-practice gap with more realistic assumptions than previous work, I still struggle to understand how the current theory can ‚Äúlead to guiding practical choices‚Äù, touted as the main goal of theory on line 164. Could the authors elaborate on why this is the case?\n- The experiments are small-scale, which is not generally a concern for a theoretical paper that doesn't make claims about empirical performance. However, you do claim to bridge the theory-practice gap with more realistic assumptions, but you only validate these at a smaller scale and only for a subset of layers in the network(Figs 1,2,5,6,7,8,9,10). I think the paper would be significantly stronger if you did something along the lines of the following:\n\n\n(a) Validate your layer-wise smoothness assumptions hold, at least at the beginning of training, across a few larger model scales (maybe 500M and 1B parameters) to get an idea of the trend.\n\n\n(b) Provided aggregate statistics across all layers in the model (e.g., to get a summary for the main paper). For example, you could show curves reporting how many layers satisfy the assumption across the entire model instead of reporting a single layer."}, "questions": {"value": "- What is small k in Table 1? I assume this was omitted because k is included in the radius and momentum formula. I still think it would be clearer to provide intuition as to what it controls. \n- Decoupled weight decay is critical for achieving strong performance [1,2], but it doesn‚Äôt feature in your framework or existing convergence analysis, from my understanding. Do your rates still apply when using decoupled weight decay?\n- Line 472 possible typo: finetuning ‚Üí HP search \n\n\n\n[1][Decoupled Weight Decay Regularization]\n\n[2][Muon is Scalable for LLM Training]"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UHxyFOdN35", "forum": "7aO0YLtXb6", "replyto": "7aO0YLtXb6", "signatures": ["ICLR.cc/2026/Conference/Submission16183/Reviewer_oV9Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16183/Reviewer_oV9Q"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16183/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761946788871, "cdate": 1761946788871, "tmdate": 1762926346538, "mdate": 1762926346538, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper claims that prior theoretical analyses are flawed because: 1) they overlook the practical \"layer-wise\" implementation of these optimizers, using a simplified \"global\" update, and 2) they rely on the standard L-smoothness assumption, which is unrealistic for deep learning and leads to theoretically impractical stepsizes.\nTo solve this, the authors propose Gluon, a generalized layer-wise LMO framework, and a layer-wise $(L^0, L^1)$-smoothness assumption. Under this assumption, they provide convergence guarantees. The key result is that their deterministic analysis yields an adaptive layer-wise stepsize. Their experiments on NanoGPT and a CNN validate that their smoothness assumption is a good empirical fit and that their theoretically-derived stepsizes match the relative magnitudes of layer-wise learning rates found in Scion."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper proposes a layer-wise $(L^0,L^1)$-smooth method for Muon/Scion type of optimizers.\n2. The empirical validation in the paper shows that the proposed smoothness model is a close fit for the \"trajectory smoothness\" observed during training.\n3. It's interesting to see that the theory predicts the layer-wise stepsize ratios that align with the previous work found through tuning."}, "weaknesses": {"value": "1. The paper claims that its layer-wise analysis as a key novelty over Scion, since Scion uses a 'global' update. I think it's a misunderstanding. If I understand correctly, Scion is also a layer-wise framework. It achieves per-layer control by per-layer radius for scaling individual layer norms.\n2. The paper's novel adaptive, layer-wise stepsize is derived only for the deterministic setting (Theorem 1). For the stochastic analysis (Theorem 2), the paper reverts to a standard non-adaptive, decaying stepsize.\n3. Although the authors claim that Gluon is an _adaptive_ optimizer, I'm not sure if it's true. The \"adaptive\" stepsize in line 293 from Theorem 1, is impractical because it requires a priori knowledge of the $L^0_i$ and $L^1_i$ constants for every layer. It looks like this paper finds these constants through running the experiment at first and then fit them into another run. Could Gluon adjust $t_i^k$ during training to achieve real adaptive method? (Correct me if my understanding is wrong.) \n4. I notice that there is another paper [1] also analyzes a $(L^0,L^1)$-smoothness model. It may be not very accurate to say \"all existing analyses... are built on the classical $L$-smoothness assumption\". Could the authors discuss the difference between this paper?\n\n[1] Thomas Pethick, Wanyun Xie, Mete Erdogan, Kimon Antonakopoulos, Tony Silveti-Falls, and Volkan Cevher. \"Generalized Gradient Norm Clipping & Non-Euclidean $(L_0, L_1)$-Smoothness.\" arXiv preprint arXiv:2506.01913 (2025)."}, "questions": {"value": "1. Is it possible to extend both theory and experiments to the version with weight decay?\n2. I notice that the authors use a constant learning rate. Is this necessary for getting approximate $L^0_i$ and $L^1_i$ or other empirical results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TFop5af6a8", "forum": "7aO0YLtXb6", "replyto": "7aO0YLtXb6", "signatures": ["ICLR.cc/2026/Conference/Submission16183/Reviewer_zkaX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16183/Reviewer_zkaX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16183/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761974667443, "cdate": 1761974667443, "tmdate": 1762926346074, "mdate": 1762926346074, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Gluon, a layer-wise Linear Minimization Oracle (LMO) optimizer unifying Muon/Scion‚Äìstyle updates. It replaces global LMOs with per-layer LMOs and analyzes convergence under a new layer-wise (L_0, L_1)-smoothness assumption. In the deterministic case it yields adaptive per-layer step radii and O(1/\\sqrt{K})-stationarity, and in the stochastic case with momentum it gives O(1/K^{1/4}). Experiments on NanoGPT-124M (FineWeb) and a CNN on CIFAR-10 claim that the assumption tracks measured ‚Äútrajectory smoothness,‚Äù and that theory-suggested layerwise learning-rate scales align with tuned Scion settings."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Methodology is motivated and presented clearly: how Muon/Scion arise as Gluon special cases and why layer-wise LMOs matter computationally. The Algorithm 1 description and per-layer ball LMOs are easy to follow.\n\n2. Convergence analysis for Gluon is provided, and the proofs are easy to follow in the appendix."}, "weaknesses": {"value": "1. The experimental parts need to be strengthened: all experiments presented in section 5.1 and 5.2 are performed on quite small-scale model. Since the vanilla muon is claiming better performance than AdamW when training on LLMs, I think there should at least be some experiments for larger models to demonstrate the effectiveness of Gluon, other than just CNN on CIFAR10.\n\n2. Evaluation of methods focuses on validation loss curves. I would expect a more comprehensive evaluation on memory overhead / running time, to understand the tradeoff between performance, memory, and time for Gluon.\n\n3. The convergence in Theorem 2 requires specific decay laws $t_{k,i}\\propto k^{-3/4}$, $\\beta_k = 1- 1/\\sqrt{(k+1)}. However, I think the advantage of the proposed gluon lies in the adaptive per-layer radii that are practically attractive. \n\n4. I suggest quantifying inexact LMO effects: add ablations varying SVD truncation rank / sign approximations and report the loss in performance and any stability changes. Also, to make the theoretical parts more solid, there could be some analysis over error-aware descent."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hhxRH188Ls", "forum": "7aO0YLtXb6", "replyto": "7aO0YLtXb6", "signatures": ["ICLR.cc/2026/Conference/Submission16183/Reviewer_BX3o"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16183/Reviewer_BX3o"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16183/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762031156094, "cdate": 1762031156094, "tmdate": 1762926344532, "mdate": 1762926344532, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}