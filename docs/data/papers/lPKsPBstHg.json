{"id": "lPKsPBstHg", "number": 6229, "cdate": 1757960113333, "mdate": 1759897928010, "content": {"title": "Think Before You Diffuse: Infusing Physical Rules into Video Diffusion", "abstract": "Recent video diffusion models have demonstrated their great capability in generating visually-pleasing results, while synthesizing the correct physical effects in generated videos remains challenging. The complexity of real-world motions, interactions, and dynamics introduce great difficulties when learning physics from data. In this work, we propose DiffPhy, a generic framework that enables physically-correct and photo-realistic video generation by fine-tuning a pre-trained video diffusion model. Our method leverages large language models (LLMs) to infer rich physical context from the text prompt. To incorporate this context into the video diffusion model, we use a multimodal large language model (MLLM) to verify intermediate latent variables against the inferred physical rules, guiding the model’s gradient updates accordingly. MLLM’s textual output is transformed into continuous signals. We then formulate a set of training objectives that jointly ensure physical accuracy and semantic alignment with the input text.  Additionally, failure facts of physical phenomena are corrected via attention injection. We also establish a high-quality physical video dataset containing diverse phyiscal actions and events to facilitate effective finetuning. Extensive experiments on public benchmarks demonstrate that DiffPhy is able to produce state-of-the-art results across diverse physics-related scenarios. Code and data will be made available post-review.", "tldr": "We propose DiffPhy, a generic framework that enables physically-correct and semantically coherent video generation by fine-tuning a pre-trained video diffusion model.", "keywords": ["Video Diffusion", "Video Generation", "Physical Commensense"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/abed66725f92f4403a0e6585ebdac7432376d20d.pdf", "supplementary_material": "/attachment/dd73e8deab01feb18bdae06f4f6ecc4dca24d57c.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents DiffPhy, a framework aimed at improving the physical realism of text-to-video (T2V) diffusion models. While existing models excel at generating visually high-quality videos, they often ignore physical laws such as gravity, force, and motion consistency. DiffPhy addresses this gap by introducing a physics-aware fine-tuning paradigm that integrates reasoning from Large Language Models (LLMs) and Multimodal LLMs (MLLMs). The LLM first performs chain-of-thought reasoning on text prompts to infer relevant physical attributes, phenomena, and enhanced contextual descriptions. The MLLM then verifies whether the generated video aligns with these inferred rules, producing differentiable supervision signals that guide the diffusion model’s updates. The training combines three main objectives—physical phenomena loss, physical commonsense loss, and semantic consistency loss—and further employs an attention-injection mechanism to correct physically implausible generations.\n\nTo support this learning process, the authors construct a new dataset, HQ-Phy, consisting of roughly 8,000 real-world videos emphasizing physical interactions and realistic motion. Through extensive experiments on VideoPhy2 and PhyGenBench benchmarks, DiffPhy demonstrates measurable gains over several open and closed-source baselines, including Wan 2.1-14B, Kling, and CogVideoX. Both automated and human evaluations show that the proposed method produces videos with higher semantic alignment and stronger physical plausibility. Overall, the paper provides a technically coherent and empirically validated approach for enhancing diffusion-based video generation with explicit physical reasoning, offering a meaningful step toward bridging the gap between visual fidelity and physical correctness, though some improvements remain moderate in magnitude."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper is clearly written and logically organized. Each component of the proposed framework—LLM reasoning, MLLM verification, loss formulation, and failure-aware refinement—is explained in a step-by-step manner, supported by intuitive figures (e.g., Figure 2 and Figure 7). The motivation for combining symbolic reasoning with diffusion training is easy to follow, making the work accessible to both machine learning and vision audiences.\n2. By infusing physical rules into video diffusion, the paper addresses one of the most pressing limitations of current T2V systems—the lack of physical realism and commonsense consistency. This direction has high potential impact not only for video generation but also for downstream domains such as robotics simulation, digital content creation, and physics-based reasoning benchmarks. The work can be viewed as a meaningful step toward unifying generative AI with structured world modeling. Overall, the contribution is both timely and relevant to the evolving landscape of physics-informed generative models.\n3. The introduction of the HQ-Phy dataset represents an additional and meaningful contribution. By curating approximately 8 000 real-world videos covering diverse physical interactions—such as gravity-driven motion, collisions, and fluid dynamics—the authors address a key limitation of existing benchmarks, which are often synthetic or too small to support effective fine-tuning. HQ-Phy provides valuable training material for future research in physics-aware video generation and helps bridge the current data gap in real-world physical phenomena. This dataset substantially strengthens the paper’s practical impact and long-term significance to the community."}, "weaknesses": {"value": "1. The discussion in Section 2 (Video Physics Reasoning) is relatively narrow. It mainly contrasts simulator-based and representation-learning approaches but overlooks a growing line of research that leverages post-training or preference optimization techniques to enhance physical reasoning in generative models. Recent works such as [1-3] are highly relevant and should be discussed. These studies demonstrate that physics awareness can also be introduced during post-training, offering an important comparative context for DiffPhy.\n2. The method is only evaluated on a single backbone (Wan 2.1-14B). Although this model is a strong open-source baseline, improvements demonstrated on one architecture do not fully establish the generality or robustness of the proposed framework. To make the empirical evidence more convincing, DiffPhy should be applied to additional diffusion backbones to verify that the approach generalizes across different architectures and data. \n3. In lines 221–223, the authors state that they decode the predicted latent clip $x_t\\in R^{m\\times c\\times h \\times w}$ at a sampled timestep $t$ into pixel space for MLLM evaluation. However, for larger $t$, these intermediate latents are typically highly noisy and lack meaningful semantic structure. It remains unclear how an MLLM can reliably evaluate alignment or physical correctness from such noisy decoded clips. Without additional clarification or ablation showing the sensitivity of the evaluation to timestep noise, this procedure may introduce unstable or unreliable supervision signals.\n4. This paper strongly depends on physical reasoning ability of LLM and MLLM. Therefore, the entire framework implicitly assumes that the underlying LLM and MLLM possess strong physical reasoning and evaluation capabilities. However, the paper does not include any diagnostic experiments or analysis to validate this assumption. If these models fail to accurately reason about or judge physical phenomena, the provided feedback could be misleading, thereby undermining the claimed improvements. A more systematic assessment of how the quality of the LLM/MLLM affects the overall performance would strengthen the paper’s empirical credibility.\n\n[1] Ipo: Iterative preference optimization for text-to-video generation\n\n[2] Pisa experiments: Exploring physics post-training for video diffusion models by watching stuff drop\n\n[3] RDPO: Real Data Preference Optimization for Physics Consistency Video Generation"}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nXRE8iCc4Y", "forum": "lPKsPBstHg", "replyto": "lPKsPBstHg", "signatures": ["ICLR.cc/2026/Conference/Submission6229/Reviewer_YtuE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6229/Reviewer_YtuE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6229/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761192649320, "cdate": 1761192649320, "tmdate": 1762918559428, "mdate": 1762918559428, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studied the problem of how to enhancing physical rule adherence for video generation model, the method is not hard to follow:   \n1) analyze user prompt with an LLM to explicitly describe what physical attributes and phenomina would be involved in the video, this part is referred as \"think/reason\" in the paper;   \n2) adopt an MLLM to score the generated video's quality w.r.t the \"physical attributes and phenomina\" described by LLM before;   \n3) fine-tune the video generation model (Wan2.1-14B) by the supervision with the MLLM and LLM combo."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Most part of the paper is clearly written. However, the method is problematic, which will be detailed below."}, "weaknesses": {"value": "First of all, using LLM/MLLM as supervision to finetune an image/video generation model has a long history, and is definitely not a novel idea. But this doesn't mean that there's little we can contribute under such common \"framework\", more problems are that authors didn't give enough detail descriptions for multiple critical parts of the method, which is listed in the following \"Questions\" section. This would make the contribution of the paper not solid enough to meet the standard of ICLR.   \n\nApart from the wearkness stated above, the paper lacked thorough survey of related works in section 2. Actually there're already tons of physical rule related video generation works, for example, \"WISA: World Simulator Assistant for Physics-Aware Text-to-Video Generation\" (https://arxiv.org/abs/2503.08153) , \"PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video Generation\"(https://arxiv.org/abs/2509.20358), to name a few."}, "questions": {"value": "1. Page 5, \"Physical phenomena alignment\" part: the paper stated that *\"during training, at a sampled timestep t, we decode the predicted latent clip $x_t ∈ R^{m×c×h×w}$ with m frames into a pixel space video $v_t$\"*.  There'd be two questions: 1) since we're talking about diffusion model here, does this means the \"decoded\" video $v_t$ would be noised?  then the judge accuracy of the following MLLM would be compromised, won't this be a problem? 2) to get around of \"MLLM compromised\" problem, a common remedy is to decode the $v_t$ only at a quite late time step, the paradox here is that at the later part of diffusion steps, only visual details can be changed, shape deformity as well as disobedience to physical rules would have already happened here. Lack of detail discussion here makes either the training or the results questionable.  \n\n2. Page 5, \"Failure-Aware Refinement\" part: the paper stated that *For a \"not matched\" fact $f_i$, we introduce an additional module to inject attention*. Does this mean 1) there would be multiple $f_i$ facts? 2) the additional module is one for all the facts or would it be necessary one additional module for each fact? 3) if there's only one addtional module, how does it work when there're multiple not matched facts to learn and when there's no fact to learn?\n\n3. For the MLLM used in the paper, authors didn't present any analysis on how the MLLM model performs on the physical attributes and physical phenomina scoring tasks. This part is quite critical for the contribution of the paper since the proposed LLM+MLLM supervision framework is not novel."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "HReEbq1qq4", "forum": "lPKsPBstHg", "replyto": "lPKsPBstHg", "signatures": ["ICLR.cc/2026/Conference/Submission6229/Reviewer_AzsP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6229/Reviewer_AzsP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6229/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761551847702, "cdate": 1761551847702, "tmdate": 1762918559048, "mdate": 1762918559048, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the problem of generating physically plausible videos using text-to-video diffusion models The proposed method, DiffPhy, fine-tunes a pretrained video diffusion model with guidance from LLMs and Multimodal LLMs. LLM first infers physical context from the text prompt, and an MLLM evaluates the generated video against these physical rules. The MLLM’s feedback is converted into a continuous differentiable score that supervises the diffusion model, encouraging alignment with physical laws. A failure-aware refinement module further injects attention based on detected physical inconsistencies. Experiments on physics-oriented benchmarks show improved physical plausibility and semantic alignment compared to existing models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper proposes a reasonable integration of textual reasoning and multimodal verification to encourage physically consistent video generation, extending prior work on language-guided diffusion with an additional physics-aware supervision signal. The proposed continuous score estimator provides a practical way to incorporate non-differentiable LVLM feedback into gradient-based fine-tuning. The failure-aware refinement further introduces an interesting idea of using detected failure cases as textual cues to guide attention."}, "weaknesses": {"value": "**1) Incomplete Related Work & Baseline Coverage**  \nWhile the “Video Physics Reasoning” subsection is conceptually relevant, the cited works mainly focus on traditional physics simulation or early neural reasoning models, rather than recent diffusion-based approaches that explicitly address physical consistency in video generation. Incorporating more recent studies such as **PhyT2V [1]** and **Yang et al. [2]** would strengthen the connection between DiffPhy and the current landscape of physics-aware video diffusion. Also, the baseline comparison could be expanded to include these contemporary methods.\n\n**2)  Insufficient Comparison with Alignment-Based Methods**  \nThe paper does not adequately position its approach within the growing literature on alignment-based fine-tuning frameworks that leverage LVLM feedback (or more broadly, reward-model signals) for diffusion model adaptation (e.g., VADER [3]). While the proposed continuous score estimator provides a differentiable way to incorporate feedback, it remains unclear how this approach compares to or improves upon existing reward-based and preference-alignment methods in terms of training stability, supervision efficiency, or performance. A more systematic discussion or experimental comparison would help clarify the method’s advantages and situate it more clearly within this line of work.\n\n**3) Uncertain Effectiveness of Failure-Aware Refinement**  \nThe proposed failure-aware refinement introduces an interesting idea of using MLLM-identified failure cases as textual feedback to guide attention. However, this mechanism ultimately relies on the possibility that conditioning on such failure cues helps the model focus on physically inconsistent regions, rather than providing any guarantee of actual correction. Since the feedback is binary and lacks spatial-temporal grounding, it is unclear whether this refinement truly fixes the underlying physical inconsistencies or simply injects additional noise. Moreover, the paper does not include an ablation isolating this component during training, making it even more difficult to assess its actual impact. It would also be helpful to include inference-time ablations comparing this refinement against simpler alternatives, such as seed resampling, to demonstrate that the proposed strategy offers tangible advantages beyond random variation.\n\n**4) Citation Format**  \nCitation references are not consistently enclosed in parentheses throughout the paper.\n\n[1] *PhyT2V: LLM-Guided Iterative Self-Refinement for Physics-Grounded Text-to-Video Generation*  \n[2] *Towards Physically Plausible Video Generation via VLM Planning*  \n[3] *Video Diffusion Alignment via Reward Gradients*"}, "questions": {"value": "See the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "tTq6QI3GLt", "forum": "lPKsPBstHg", "replyto": "lPKsPBstHg", "signatures": ["ICLR.cc/2026/Conference/Submission6229/Reviewer_pvJs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6229/Reviewer_pvJs"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6229/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761858258103, "cdate": 1761858258103, "tmdate": 1762918558642, "mdate": 1762918558642, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DiffPhy, a framework to improve the physical realism of video diffusion models.The method first uses a Large Language Model (LLM) to \"think\" about the input prompt, reasoning about physical laws, entities, and phenomena to create a set of physical rules and an \"enhanced prompt\". Experiments show DiffPhy achieves SOTA results on physics-based benchmarks, VideoPhy2 and PhyGenBench."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper tackles a well-known and critical limitation of modern VDMs: their failure to adhere to basic physical laws, which breaks realism.\n- The \"Think before you diffuse\" paradigm is an intuitive and strong conceptual contribution. The use of an LLM for high-level physical reasoning to generate supervisory signals for a VDM is a novel training strategy.\n- The creation and release of the HQ-Phy dataset (8,000 curated, real-world videos labeled with physical phenomena) is a valuable contribution to the community, as existing datasets were often synthetic or for evaluation only."}, "weaknesses": {"value": "- The proposed training paradigm appears to be extremely computationally expensive. More computation and time cost analysis is needed here.\n- The entire method's effectiveness is contingent on the quality of the MLLM used for supervision. The paper itself notes in its limitations section that MLLMs \"struggle to interpret videos\" and their outputs can be \"shallow or generic.\" This raises a significant concern: if the MLLM is an imperfect evaluator (which is also suggested by the discrepancy between model-based and human-based scores), is DiffPhy simply learning to overfit to the specific biases of the VideoCon-Physics evaluator? How can we be sure it's learning generalizable physical rules rather than just optimizing for this specific MLLM's scoring function?"}, "questions": {"value": "Overall, this paper presents a novel and well-executed framework for a challenging and important problem. The idea of using an MLLM as a \"physics verifier\" inside the diffusion training loop is a significant methodological contribution, and the strong empirical results validate its effectiveness. While I have concerns regarding the training scalability and the method's reliance on the quality of the MLLM supervisor, the novelty and strong results marginally outweigh these weaknesses. I am leaning towards acceptance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0lKAUr0rnl", "forum": "lPKsPBstHg", "replyto": "lPKsPBstHg", "signatures": ["ICLR.cc/2026/Conference/Submission6229/Reviewer_myHY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6229/Reviewer_myHY"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6229/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761975082879, "cdate": 1761975082879, "tmdate": 1762918558279, "mdate": 1762918558279, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}