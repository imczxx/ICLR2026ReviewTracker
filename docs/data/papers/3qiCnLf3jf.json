{"id": "3qiCnLf3jf", "number": 24953, "cdate": 1758362364211, "mdate": 1763553272003, "content": {"title": "Best-of-Infinity: Asymptotic Performance of Test-Time Compute", "abstract": "We study best-of-$N$ for large language models (LLMs) where the selection is based on majority voting. In particular, we analyze the limit $N \\to \\infty$, which we denote as best-of-$\\infty$. While this approach achieves impressive performance in the limit, it requires an infinite test-time budget. To address this, we propose an adaptive generation scheme that selects $N$ based on answer agreement, thereby efficiently allocating inference-time computation. Beyond adaptivity, we extend the framework to weighted ensembles of multiple LLMs, showing that such mixtures can outperform any individual model. The optimal ensemble weighting is formulated and efficiently computed as a mixed-integer linear program. Extensive experiments demonstrate the effectiveness of our approach.", "tldr": "", "keywords": ["LLM", "test-time compute", "majority voting", "LLM ensemble"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ce36a79ae9a13eda55310d64c97eaba7b74bb121.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper studies a test-time-scaling instance, where N answers are first generated by 1 LLM, and then one answer is selected by majority vote. The authors propose and analyze an algorithm that adaptively adjust number of answers to mitigate the overall LLM generation cost, which later is extended to the case where the N answers are generated by multiple LLMs (i.e., an LLM ensemble). Experiments using real-world LLMs are conducted to justify the results."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Test-time-scaling is a timely topic, and its research impact may potentially last for a long time.\n\n\n- The paper is well-written and easy to follow.\n\n\n-The proposed majority vote approach is generic enough to be applied to a range of problems."}, "weaknesses": {"value": "- The technical contributions are limited. The main contribution, Algorithm 1, simply views the LLM generated answers as samples from some unknown distributions and then estimates the uncertainty from the drawn samples to decide whether to go further or not. The theorems and lemmas all seem very straightforward too. See my questions for more details.\n\n- Both majority-vote and LLM ensemble has been extensively studied in the literature. However, the paper ignores many (important) papers and fails to position itself appropriately. See my questions for more details.\n\n- Motivations with open-source models: One main reason developers and researchers would use majority-vote is black-box access to the LLM models. Otherwise, instead of majority vote over multiple answers, one can simply fine-tune the model weights to optimize the performance. Hence, showing the performance with black-box LLM models (e.g., GPT-5 or at least GPT-5-mini) is essential to demonstrate the practical usefulness of Algorithm 1.\n\n- The empirical results appear to be statistically insignificant and outdated due to dataset selections, and thus is hardly convincing that the proposed Algorithm 1 is efficient and effective.  See my questions below."}, "questions": {"value": "- Where is the finite-sample analysis? Theorem 1 analyzes the asymptotic performance of Algorithm 1, i.e., showing it converges to best-of-infinity when the budget goes to infinity. This is not quite useful, as the standard majority-vote using N samples also converges to best-of-infinity as N goes to infinity. What is useful is the finite-sample analysis, i.e., the convergence rate of Algorithm 1 compared with majority-vote with the same number of samples.\n\n- Why is the choice of Dirichlet process in Algorithm 1? As far as I understand, the purpose of Dirichlet process in Algorithm 1 is to offer a prior distribution for uncertainty estimation. There are several possible prior options, and I am not convinced that Dirichlet process is the simplest or optimal. At least one should provide some ablation study on the choices of the prior distribution.\n\n- \"The equation 8 is equivalent to the following MILP\". How could an equation be the same as an optimization problem? Do the authors mean \"maximizing equation 8\"?\n\n- Many closely related papers are completely ignored. For example, [J. Li et al 2025] and [L. Chen et al 2025] have already studies the case of majority vote with many generations and offered detailed analysis and empirical experiments. A. Huang studies how to optimize the best-of-n approach from a theoretical aspect. F. Wang studies almost the exactly same problem and proposes a similar algorithm to improve sample efficiency. The novelty and technical contributions cannot be easily accessed without clearly positioning the paper in the fruitful literature. \n\nJ. Li et al, More Agents Is All You Need, 2025.\nL. Chen et al, Are More LLM Calls All You Need? Towards Scaling Laws of Compound Inference Systems, 2025.\nA. Huang et al, Is Best-of-N the Best of Them? Coverage, Scaling, and Optimality in Inference-Time Alignment, 2025.\nF. Wang et al, DynScaling: Efficient Verifier-free Inference Scaling via Dynamic and Integrated Sampling, 2025.\n\n- The empirical results are based on only 3 datasets, namely, AIME(2024+2025), GPQA, and MATH500. While relevant, GPQA and MATH500 have been released for a while and often considered contaminated. AIME (2024 or 2025), on the other hand, only contains 30 questions, making it extremely hard to draw any significant conclusions. Large-scale experiments are essential for statistically significant conclusions.\n\n- What is the training runtime cost? Obtaining the optimal weights for LLM ensemble is via solving an MILP, which can be extremely expensive. What solvers are used in the experiments? How fast/slow are them?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "muybRgNdS3", "forum": "3qiCnLf3jf", "replyto": "3qiCnLf3jf", "signatures": ["ICLR.cc/2026/Conference/Submission24953/Reviewer_jczD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24953/Reviewer_jczD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24953/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760987894844, "cdate": 1760987894844, "tmdate": 1762943259750, "mdate": 1762943259750, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies adaptive repeated sampling methods for more compute-efficient test-time scaling. This paper also proposes a new approach to learning optimal weighting for multi-LLM ensemble based on mixed-integer linear programing."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The research topic is important and well motivated.\n\n- The proposed methods are grounded with principled analysis.\n\n- The experiments show that the proposed methods lead to performance improvement."}, "weaknesses": {"value": "## Main weaknesses\n- I find some terminologies in the paper confusing or inappropriate:\n  - Test-time compute: Whenever an LLM is used in the test-time, the compute should be categorized as test-time compute. Based on my understanding, this submission indeed focuses on test-time scaling (TTS), or different methods of scaling up test-time compute. Therefore, test-time scaling should be the right term to use (e.g., in the title), and this terminology has been widely adopted in existing papers [1].\n  - Best-of-$N$: In early works on test-time scaling, best-of-$N$ specifically refers to selecting the best generation trajectory with an external verifier -- either an oracle or a learned verifier [2,3]. \"Majority voting\", to the best of my knowledge, is a different method from best-of-$N$ in existing studies [3,4]. After all, majority voting cannot select the single \"best\" response from $N$ candidates -- it just returns an output answer based on consensus. The focus of this paper is purely on majority voting and I cannot agree that this is a \"variant\" of \"best-of-$N$\". Besides, I think [2,3,4] -- [4] in particular -- are all very relevant to this work and should be discussed.\n\n[1] s1: Simple test-time scaling\n\n[2] Large Language Monkeys: Scaling Inference Compute with Repeated Sampling\n\n[3] Inference Scaling Laws: An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models\n\n[4] Are More LLM Calls All You Need? Towards Scaling Laws of Compound Inference Systems\n\n- The exposition of the method part lacks clarity:\n  - Algorithm 1 is not even self-contained. The input $\\alpha$ is not explicitly used. Moreover, the approximation of $\\mathrm{BF}(n)$ lies in the center of the analysis in Section 2. The algorithm needs to elaborate on it rather than calling the function without any explaination.\n  - Line 182 mentions that $\\mathbb{P}(H_1\\mid \\mathcal D (n))$ can be estimated using Monte Carlo methods. More details on the method are anticipated, especially when the answer space is large or even infinite.\n  - The \"algorithm\" in Theorem 1 is very vague. Is it the presented Algorithm 1? Is $\\mathrm{BF}(n)$ approximated? Should the result also rely on a large number of Monte Carlo samples?\n  - In Equation (8), the notation is wired. People naturally expect $f(\\\\{a_q\\\\})$ is defined for a single problem $q$ but it is indeed for the entire problem set. Why not denote it by $f{\\mathcal Q)$?\n\n\n## Nits\n- Lines 28-30: `\\citet` $\\to$ `\\citep`.\n- Line 175: When $n$ is sufficiently large compared with $\\alpha$ $\\to$ When $n\\gg \\alpha$.\n- Line 201: AIME problem solutions can be 0.\n- Line 222: The \"=\" should be $\\in$ since the maximizer is not necessarily unique."}, "questions": {"value": "- Can you give some examples of the base distributions $H$ when the answer space is infinite?\n\n- The MILP in Lemma 4 assumes access to $p_{i,j}^q$. How is that implemented in practice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2lBeVJules", "forum": "3qiCnLf3jf", "replyto": "3qiCnLf3jf", "signatures": ["ICLR.cc/2026/Conference/Submission24953/Reviewer_XSCw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24953/Reviewer_XSCw"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24953/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761360791460, "cdate": 1761360791460, "tmdate": 1762943259450, "mdate": 1762943259450, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work investigates test-time scaling of large language models (LLMs) via majority voting. The authors analyze the infinite-sample limit of accuracy and propose an instance-level dynamic compute allocation method based on answer agreement. They also consider weighted ensembles of multiple LLMs and formulate a mixed-integer linear program to determine optimal weights. Experiments are conducted to validate the proposed analysis and methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed dynamic compute allocation method based on answer agreement is sensible, intuitive, and straightforward to implement.  \n- The release of a dataset containing LLM-generated responses may be useful to researchers studying LLM test-time scaling."}, "weaknesses": {"value": "- The procedure for optimizing the weights in the LLM ensemble is unclear. In particular, it appears that the same data is used for both optimization and evaluation, which would amount to \"training on test data\" and thus compromise the validity of the results.  \n- Some theoretical results (e.g., Theorem 1 and Lemma 1) are relatively obvious and could be better presented by briefly summarizing the key insights in the main text, with full details and formal notation moved to the appendix.  \n- \"Experiment Set 5\" on page 9 seems out of place, as it compares standard majority voting with other test-time scaling methods, none of which is directly related to the proposed methodology or analysis.  \n- The discussion on asymptotic performance may give the impression that majority voting's accuracy increases monotonically with the number of samples, which is not always correct. This paper misses an important related work [1] demonstrating that the accuracy curve can exhibit diverse behaviors.  \n\n  [1] Are More LLM Calls All You Need? Towards the Scaling Properties of Compound AI Systems (NeurIPS 2024)  \n\n- Minor issues:  \n  - Line 184: replace “the algorithm” with “Algorithm 1.”  \n  - Footnote 4 on page 5 seems redundant and could be removed.  \n  - Table captions should be placed above the tables, per ICLR format guidelines.  \n  - Line 482 contains a grammatical error: “we have verified robust across LLMs and problem sets”.  \n  - Table 6 has missing entries without explanation."}, "questions": {"value": "- How is asymptotic accuracy computed in the experiments? In the first plot of Figure 1, there is a noticeable gap between asymptotic accuracy and empirical accuracy at $N$ as large as 1000; how should this be interpreted?  \n- Regarding terminology: literature convention generally considers majority voting and best-of-N as separate methods (as far as I can tell), whereas this paper treats majority voting as a special case of best-of-N. Nonetheless, I do not object strongly to this choice if other reviewers think this is fine."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ut4mibK3iG", "forum": "3qiCnLf3jf", "replyto": "3qiCnLf3jf", "signatures": ["ICLR.cc/2026/Conference/Submission24953/Reviewer_6Yj4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24953/Reviewer_6Yj4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24953/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761983074858, "cdate": 1761983074858, "tmdate": 1762943259214, "mdate": 1762943259214, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The apparel provides an early stopping mechanism for sampling in the majority-voting algorithm in the LLMs to achieve the same performance as the infinite-budget case with finite generations. The mechanism maintains a Drichlet Process posterior over output distribution and stops according to the Bayes factor. Also, the paper studies the optimal weighting for LLM ensembles in the infinite budget case."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is written rigorously with an accurate language. The paper is mostly easy to follow.\n\nThe introduced early stopping mechanism can be very impactful in practice \n\nI find the ensemble problem very interesting and novel. \n\nThe experiments are extensive and cover many models and benchmarks. The algorithms work well across all settings."}, "weaknesses": {"value": "I mostly have two major concerns about the paper;\n\n1. It appears to me that the Drichlet stopping criteria highly resembles the work of [1]. I am not aware of the full details of that paper and would appreciate a comparison by the authors. However, it looks like both model the problem as a dirichlet process and stop using a threshold. This reduces the novelty of this part of the paper.  \n\n2. The ensemble method seems to depend on the knowledge of the ground truth answers. The matrix in the constraint in equation 13 depends on the ground truth answer. If this is true, it severely reduces the practicality of this part of the paper. \n\n\nMore minor issues:\n\n3. In a footnote, It is mentioned that the method can be applied to infinite possible final answers (which is the case in MATH500) problems. But it breaks the approximation in equation 6. More clarification about the applicability to this setting strengthens the paper. \n\n4. As a reference point, it would be informative to compare the stopping criteria with an oracle one. The oracle could be stopping at the moment the output becomes and remains correct. \n\n\n\n[1] [Let’s Sample Step by Step: Adaptive-Consistency for Efficient Reasoning and Coding with LLMs](https://aclanthology.org/2023.emnlp-main.761/) (Aggarwal et al., EMNLP 2023)"}, "questions": {"value": "1. I could not follow the line 117 derivation and would appreciate more explanations. There might be typo there. To me, it should be\n\n$$\n\\mathbb{P}(H_1 \\mid \\mathcal{D}(n)) \\approx \\Pr[X_1 \\ge \\max_{i \\ne 1} X_i,\\, X \\sim \\mathrm{Dirichlet}(N_1, N_2, \\ldots, N_{s(n)}, \\alpha)].\n$$\n\nAlso, the assumption is that the probability of all $A_i$ together (instead of just A1) is zero under H."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JkEMf3gJr9", "forum": "3qiCnLf3jf", "replyto": "3qiCnLf3jf", "signatures": ["ICLR.cc/2026/Conference/Submission24953/Reviewer_CXnE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24953/Reviewer_CXnE"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24953/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762264876787, "cdate": 1762264876787, "tmdate": 1762943258951, "mdate": 1762943258951, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Overall Response"}, "comment": {"value": "Dear Reviewers and AC,\n\nWe appreciate the reviewer’s comments. We would like to respectfully point out that the review focuses primarily on the adaptive stopping aspect, which is only a part of our contributions. Our main contribution lies in characterizing the best-of-$\\infty$ (infinite-sample) performance of LLM ensembles and formulating it via MILP optimization. Adaptive sampling is introduced only as a practical method to approximate this infinite-sample performance under finite computation.\n\nImportantly, most of the suggested citations are about a single LLM and none of them provides such a characterization of the infinite-sample limit on the LLM ensemble, which implies the novelty of our work. \n\nWe answer each of the reviewers' questions in the corresponding replies."}}, "id": "i9VAx84D1y", "forum": "3qiCnLf3jf", "replyto": "3qiCnLf3jf", "signatures": ["ICLR.cc/2026/Conference/Submission24953/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24953/Authors"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission24953/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763533236447, "cdate": 1763533236447, "tmdate": 1763533236447, "mdate": 1763533236447, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}