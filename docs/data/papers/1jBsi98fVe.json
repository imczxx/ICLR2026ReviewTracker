{"id": "1jBsi98fVe", "number": 13568, "cdate": 1758219291270, "mdate": 1759897427999, "content": {"title": "Latent Denoising Makes Good Visual Tokenizers", "abstract": "Despite their fundamental role, it remains unclear what properties could make tokenizers more effective for generative modeling. We observe that modern generative models share a conceptually similar training objective---reconstructing clean signals from corrupted inputs, such as signals degraded by Gaussian noise or masking---a process we term denoising. Motivated by this insight, we propose aligning tokenizer embeddings directly with the downstream denoising objective, encouraging latent embeddings that remain reconstructable even under significant corruption. To achieve this, we introduce the Latent Denoising Tokenizer (l-DeTok), a simple yet highly effective tokenizer trained to reconstruct clean images from latent embeddings corrupted via interpolative noise or random masking. Extensive experiments on class-conditioned (ImageNet 256x256 and 512x512) and text-conditioned (MSCOCO) image generation benchmarks demonstrate that our l-DeTok consistently improves generation quality across six representative generative models compared to prior tokenizers. Our findings highlight denoising as a fundamental design principle for tokenizer development, and we hope it could motivate new perspectives for future tokenizer design. \nOur code and models will be publicly available.", "tldr": "We find training tokenizers with latent denoising objectives significantly improve their generative performance across different and diverse generative models.", "keywords": ["Image Tokenizer", "Image Generative Models", "Representation Learning"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/27a2c89835af780692834f7a8e956d8a4820f7f4.pdf", "supplementary_material": "/attachment/4ad87c7705761f5098f4eab0b32db67b5bac0a60.zip"}, "replies": [{"content": {"summary": {"value": "This paper focuses on training more effective visual tokenizers for subsequent generative modeling. Motivated by the shared denoising nature of current generative models, it incorporates the denoising objective into tokenizer training to align its embedding with downstream generative models. Specifically, this work introduces Latent Denoising Tokenizer (l-DeTok), a simple yet highly effective tokenizer trained to reconstruct clean images from latent embeddings corrupted via interpolative noise or random masking. Comprehensive experiments on various settings and types of generative models validate the effectiveness and generalization of the trained tokenizers."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1. This paper is well-motivated and easy to follow. It aligns tokenizer embeddings with the downstream denoising objective in generative modeling.\n2. The writing of this paper is clear, and the expressions are polished and elegant. I appreciate this point.\n3. The proposed method and spirit are general and robust, which is applicable to a wide spectrum of generative models.\n4. The paper provides comprehensive experiments and ablations to validate the superiority of the proposed method."}, "weaknesses": {"value": "1. How much additional computational overhead does the proposed denoising mechanism introduce compared with conventional tokenizer training? Detailed comparisons should be presented.\n2. How do the performance gains vary across various tokenizer and generative model sizes? (results with different sizes of both tokenizer and generators)"}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "77Fgq7VXyp", "forum": "1jBsi98fVe", "replyto": "1jBsi98fVe", "signatures": ["ICLR.cc/2026/Conference/Submission13568/Reviewer_pDBk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13568/Reviewer_pDBk"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13568/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761725249079, "cdate": 1761725249079, "tmdate": 1762924166175, "mdate": 1762924166175, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Latent Denoising Tokenizer (l-DeTok), a visual tokenizer trained to reconstruct clean images from corrupted latent embeddings using interpolative Gaussian noise and random masking during tokenizer training. The authors demonstrate that it leads to consistent gains for both non-autoregressive and autoregressive models. Extensive experiments on ImageNet and MS-COCO across two resolutions support the claim that a simple, intuition-driven denoising objective can yield broadly useful tokenizer embeddings that transfer across generative paradigms."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Generalizes across AR and non-AR generators.\n- The same tokenizer improves both diffusion-based (non-AR) and autoregressive models without architectural changes, indicating that the denoising-aligned latent space is broadly compatible with diverse generation mechanisms.\n\n2. Simple and practical method such that no external encoder alignment or semantic distillation required.\n- While recent approaches emphasize semantics distillation from powerful pretrained vision models, l-DeTok shows that a lightweight, corruption-robust training objective can match (or surpass) such methods without explicitly aligning to external encoders.\n\n3. Drop-in usability and clear training signal.\n- The method is easy to implement, and the paper provides a clear heuristic that practitioners can readily apply."}, "weaknesses": {"value": "Regarding with Related work, please add the following references.\n- Zhao et al., ε-VAE: Denoising as Visual Decoding.\n- Tschannen et al., Generative Infinite-Vocabulary Transformers.\n- Kim et al., Efficient Generative Modeling with Residual Vector Quantization-Based Tokens."}, "questions": {"value": "1. Discrete extension of the method.\n- Given that the corruption scheme includes random masking, which is naturally defined in discrete token spaces (masking or replacing code indices), how well would the approach extend to discrete tokenizers such as VQ or RVQ? A brief discussion of potential pitfalls, such as codebook collapse, corruption schedule design and any small-scale evidence may extend the scope of the contribution.\n\n\n2. Orthogonality to aggressive compression and compact regimes.\n- Recent work indicates that aggressive latent compression, such as approximately 32 tokens or adaptive-length tokenization, can improve both quality and efficiency. Is the proposed denoising-aligned training orthogonal to these compression strategies, and does combining them yield further gains? In particular, beyond the reported configuration with patch size 16 and latent dimension 16, are there results at more compact representation?\n\nReferences\n- Yu et al., 2024. An Image is Worth 32 Tokens for Reconstruction and Generation\n- Duggal et al., 2025. Adaptive Length Image Tokenization via Recurrent Allocation"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8evOX6l0vS", "forum": "1jBsi98fVe", "replyto": "1jBsi98fVe", "signatures": ["ICLR.cc/2026/Conference/Submission13568/Reviewer_gSib"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13568/Reviewer_gSib"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13568/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977352631, "cdate": 1761977352631, "tmdate": 1762924165822, "mdate": 1762924165822, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a continuous VAE tokenizer that incorporates a denoising prior. The core idea is to corrupt the latent representations by injecting Gaussian noise or applying masking, and then training the tokenizer to reconstruct the original, uncorrupted latents. This design aims to address the discrepancy between the objectives of tokenizer training and subsequent image generative modeling, thereby improving the \"denoisability\" of the VAE latent space. The authors provide extensive experiments that effectively validate the proposed denoising tokenizer. Additionally, the paper presents several interesting empirical findings, including comparisons between random and fixed masking, as well as interpolative versus additive noise."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is well-motivated, addressing the critical challenge of aligning the training objectives of visual tokenizers and generative models.\n- The proposed method is simple yet effective. The strategy of injecting interpolative or masking noise is conceptually sound and well-justified.\n- The methodology and implementation details are presented with clarity, making the work easy to understand and reproduce.\n- The experimental evaluation is extensive and well-structured, providing strong empirical support for the paper's claims."}, "weaknesses": {"value": "- Convergence and scalability: A potential concern is the training convergence. While the denoising objective complements the pixel-reconstruction loss, it is plausible that learning to reconstruct from corrupted latents could slow down convergence compared to a vanilla baseline. It would be beneficial for the authors to provide an analysis of the training speed and computational overhead. Furthermore, a discussion on the scalability of the proposed method to larger models and datasets would strengthen the paper.\n\n- Distribution of noise level: The paper appears to use a uniform distribution for the noise level factor \\tau. Drawing inspiration from recent diffusion-based methods (e.g., SD3), which have shown that non-uniform timestep sampling can improve performance, it would be interesting to investigate whether a non-uniform sampling strategy for \\tau could offer similar benefits for the proposed tokenizer."}, "questions": {"value": "see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "f8rVKJILrS", "forum": "1jBsi98fVe", "replyto": "1jBsi98fVe", "signatures": ["ICLR.cc/2026/Conference/Submission13568/Reviewer_BHYG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13568/Reviewer_BHYG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13568/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996395206, "cdate": 1761996395206, "tmdate": 1762924165473, "mdate": 1762924165473, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the Latent Denoising Tokenizer, a visual tokenizer framework designed to explicitly align with the denoising objectives common to modern generative models. The authors propose training tokenizers to reconstruct images from latent representations subjected to strong interpolative noise and/or random masking, departing from traditional pixel-reconstruction VAE objectives. By doing so, $l$-DeTok aims to produce latent embeddings that are robust and reconstructable under significant corruption, which theoretically matches the requirements of downstream denoising-centric generative models. Empirical evaluation covers six prominent generative models—both autoregressive and non-autoregressive—across ImageNet and MS-COCO text-to-image settings, demonstrating that $l$-DeTok yields consistent improvements over standard, semantics-distilled, and convolutional tokenizers."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is motivated by an accurate and under-discussed observation: modern generative models, regardless of architecture, are fundamentally denoising systems. Training tokenizers with explicit latent corruption (interpolative noise, masking) is a clean conceptual shift that breaks with the tradition of mere pixel-wise autoencoding. This alignment is theoretically meaningful and empirically justified.\n\n- The authors benchmark $l$-DeTok across a broad spectrum of generative models, on both class-conditional (ImageNet) and text-conditional (COCO) tasks. Baselines include state-of-the-art semantics-distilled tokenizers (e.g., VA-VAE, MAETok), standard VAE-style tokenizers, and convolutional tokenizers. These comparisons are fair, with well-matched training recipes and strong ablations.\n\n- The authors provide clear, actionable analysis of the key components of $l$-DeTok. For instance, Figure 2 and Figure 3 dissect the importance of interpolative versus additive noise and the effects of constant versus randomized masking ratio on FID/IS. This isolates the impact of each design choice, giving both insight and reproducibility.\n\n- Strong Generalization and Architectural-Agnosticism: The improvements hold for both Transformer-based and CNN-based tokenizers, as shown in Section A.5, and do not depend on external semantics distillation resources—important for domains lacking large vision encoders."}, "weaknesses": {"value": "- Lack of Theoretical Analysis Regarding Optimality or Limitations: The empirical link between denoising-aligned tokenizers and improved downstream performance is clear, but the theoretical rationale is underdeveloped. For example, there is no formal analysis or proof of why interpolative over additive noise leads to strictly more robust or generative-friendly latents (as claimed in Section 5.1.1). While Figure 2 empirically demonstrates this, a mathematical discussion (e.g., in terms of mutual information or denoising risk) would strengthen the scientific value.\n\n- Training/Test Distribution Discrepancy and Impact: Section A.3 (in APPENDIX) raises the training/inference mismatch issue: since the decoder is trained primarily on heavily corrupted inputs but, in deployment, must reconstruct from nearly clean latents, there is a risk of distribution shift. While decoder fine-tuning helps (see Figure A.1, Figure A.2), the paper might understate the downside: performance gains appear to hinge in part on decoder adaptability, not just the quality of the encoder's latents. The extent to which this is a fundamental limitation (versus an optimization artifact) is not fully explored.\n\n- Potential Over-Claims on \"Semantics Distillation Independence\": The abstract and body at times appear to overemphasize $l$-DeTok’s superiority or independence compared to semantics distillation. However, Section A.4 shows that adding semantics distillation to $l$-DeTok further improves performance—especially for non-AR models—sometimes even surpassing pure denoising. This suggests the two are complementary rather than exclusive. The paper should be more circumspect in presenting $l$-DeTok as a replacement, rather than a supplement, to semantics-based approaches.\n\n- The evaluation should be benchmarked against more powerful and contemporary VAEs, such as the SD3-VAE or Flux-VAE. The currently used SD-VAE is an outdated and underperforming baseline due to its 4-channel latent space. A more meaningful and fair comparison would be against a modern 16-channel VAE. This is a crucial point, as we have observed a concerning trend in recent tokenizer research where comparisons are made against the old SD-VAE to inflate perceived performance gains. Such a comparison is not a fair assessment of the proposed method's true capabilities."}, "questions": {"value": "Please refer to Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "eziOAaqCBR", "forum": "1jBsi98fVe", "replyto": "1jBsi98fVe", "signatures": ["ICLR.cc/2026/Conference/Submission13568/Reviewer_71cM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13568/Reviewer_71cM"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13568/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762147636912, "cdate": 1762147636912, "tmdate": 1762924164679, "mdate": 1762924164679, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}