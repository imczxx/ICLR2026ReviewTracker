{"id": "gMc5Qa45ia", "number": 25435, "cdate": 1758368034334, "mdate": 1759896721183, "content": {"title": "DynamicRank LoRA: Real-Time Adaptive Fine-Tuning \\\\ for Code Models via Token-Level Importance and Loss Landscape Awareness", "abstract": "\\begin{abstract}\nWe propose \\textbf{DynamicRank LoRA}, a novel fine-tuning mechanism for code models that dynamically adjusts the rank of low-rank adaptation (LoRA) matrices in real-time, addressing the limitations of static rank configurations in conventional LoRA. The proposed approach combines two fundamental ingredients: token level importance scoring: the structural importance of their input tokens and loss landscape aware rank adaptation: rank modulation, which can be adjusted with information about gradient dynamics and curvature. High importance tokens, namely syntax keywords or variable names, will result in rank increases to get finer grain patterns, and flat loss regions, to reduce rank for faster convergence. The mechanism is tightly coupled with transformer architectures, and makes use of attention weights and gradient norms to \"plasma\" LoRA matrices through truncated SVD through training. We apply DynamicRank LoRA in the framework of a GPT-3.5-turbo where dense layers in the feed-forward blocks are replaced with those of adaptive-rank LoRA pairs modulated by a lightweight MLP. This design allows the model to very well balance the speed and precision of adaptation between the various combinations of input complexity, e.g. verbose or terse code, and task requirements, i.e. bug fixing, code generation, etc. Experimental results show that DynamicRank LoRA is more efficient and accurate for fine-tuning compared to fixed-rank baselines, especially under the need of fast adaptation to inhomogeneous code structures. The two-fold rank modulation technology and the transformer-specific integration of the methodology distinguishes it from previous works to provide a scalable solution for real time code model customization without compromising the latency.\n\\end{abstract}", "tldr": "", "keywords": ["Real-Time Adaptive Fine-Tuning"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/da473586ea64c99f5a828a62e17a734bfc042785.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "DynamicRank LoRA is a novel fine-tuning method for code models that dynamically adjusts the rank of LoRA rank in real time, overcoming the rigidity of fixed-rank LoRA. It integrates token-level importance scoring and loss-aware rank adaptation to modulate ranks based on input structure and gradient dynamics. High-importance tokens (e.g., syntax keywords, variable names) trigger finer-grained adaptation, while flat loss regions lead to lower ranks for faster convergence."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "1. I find that the motivation and methodological direction of this paper are reasonable. The work proposes a meaningful improvement over fixed-rank LoRA, such as the design of token importance scores.\n2. DynamicRank LoRA implements a lightweight control mechanism based on attention weights and gradient statistics, imposing minimal additional overhead on the base model."}, "weaknesses": {"value": "1. The formatting of the paper needs improvement, including line breaks in the title, the formatting of the abstract submitted to the system, and incorrect citations in Section 5.1. The current state of the paper is **significantly below the standard of most submitted manuscripts**, and it is still far from being ready for publication.\n2. It is unclear whether the proposed method is specific to code models. The authors could clarify which optimizations are code-model-specific and which are general-purpose. Additionally, a discussion or analysis of the method’s performance on more general models would be valuable.\n3. The model architecture is not clearly described. Were the experiments conducted on GPT-3.5-turbo? If so, how was DynamicRank LoRA implemented given that the model is not open-source? If GPT-OSS was used, which size version was employed?\n4. The experiments should be conducted on a wider range of models and model sizes to validate the generalizability and compatibility of the proposed method."}, "questions": {"value": "Please refer to the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5TIpIWgIbG", "forum": "gMc5Qa45ia", "replyto": "gMc5Qa45ia", "signatures": ["ICLR.cc/2026/Conference/Submission25435/Reviewer_dKaQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25435/Reviewer_dKaQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25435/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761626049124, "cdate": 1761626049124, "tmdate": 1762943431696, "mdate": 1762943431696, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces DynamicRank LoRA, a novel extension of Low-Rank Adaptation (LoRA) for large code models. Instead of using a fixed rank, DynamicRank LoRA dynamically adjusts the LoRA rank in real time based on token-level importance and loss landscape awareness. The authors propose a dual-factor rank modulation mechanism that uses (1) attention-based token importance to capture structural salience in code and (2) gradient-norm and curvature-based feedback to modulate rank according to optimization difficulty. They integrate this adaptive mechanism into transformer architectures via truncated SVD reshaping of LoRA matrices, apply it to GPT-3.5-turbo fine-tuning, and evaluate on code-related benchmarks (CodeXGLUE, HumanEval, APPS). Experiments show improved performance and efficiency over fixed-rank LoRA and AdaLoRA baselines."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper identifies a valid limitation of static-rank LoRA and attempts to address it with adaptive rank control.\n2. The writing is mostly clear and the structure follows standard ICLR conventions.\n3. Including both token-level and optimization-level signals is conceptually appealing and aligns with recent trends in adaptive parameter-efficient tuning."}, "weaknesses": {"value": "1. The idea of dynamic or adaptive rank allocation in LoRA is not new. Prior works such as AdaLoRA already explore rank adaptation based on parameter importance or gradient statistics. The proposed “dual-factor” method appears incremental and lacks a clear conceptual advance over these.\n2. The paper does not provide any theoretical justification, stability analysis, or complexity bound for dynamic rank modulation. The SVD-based reshaping process is described heuristically.\n3. The experiments are conducted on limited datasets and with a single model (GPT-3.5-turbo). No comparison is made against other recent dynamic fine-tuning methods. The gains reported are small and within typical variance.\n4. The title and abstract emphasize “real-time adaptive fine-tuning,” but no latency benchmarks or true online adaptation experiments are presented. The results are all from offline fine-tuning, contradicting the “real-time” claim."}, "questions": {"value": "1. Can you provide quantitative evidence for “real-time” efficiency (e.g., adaptation latency, wall-clock time)?\n2. How sensitive is performance to the token importance threshold τ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PrM3MP25ZB", "forum": "gMc5Qa45ia", "replyto": "gMc5Qa45ia", "signatures": ["ICLR.cc/2026/Conference/Submission25435/Reviewer_btuN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25435/Reviewer_btuN"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25435/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926381829, "cdate": 1761926381829, "tmdate": 1762943431260, "mdate": 1762943431260, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DynamicRank LoRA for code models, where the LoRA rank is adapted in real time using two signals: (i) token-level importance derived from attention and gradient statistics, and (ii) loss-landscape signals (gradient norm / Hessian trace) to up-/down-scale capacity during fine-tuning. The implementation targets FFN layers and uses a lightweight controller (with Gumbel-Softmax) to sample ranks and a truncated-SVD step to reshape LoRA matrices when the rank changes. Experiments on CodeXGLUE, HumanEval, and APPS report modest but consistent gains in CodeBLEU and a “bug-fix accuracy,” along with lower memory/training time than fixed-rank LoRA baselines. The idea is intuitive and practically appealing for heterogeneous code workloads, but the paper’s empirical setup and method specification leave several important gaps."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- Practical dual-factor adaptation: combining token-importance (attention + gradients) with loss-landscape cues to modulate rank is a clear, implementation-minded idea for non-uniform code inputs.\n- Promising efficiency/quality trade-off: reported improvements over fixed-rank LoRA with similar or lower compute/memory indicate the approach could be useful in latency-sensitive, mixed-difficulty code tasks."}, "weaknesses": {"value": "- Novelty vs. prior art is under-argued: the relationship to AdaLoRA/DyLoRA/Rank-Adaptor is not crisply positioned; what is fundamentally new beyond combining known signals and moving them into a controller?\n- Methodological clarity issues: the token-importance formulas appear duplicated/inconsistent, the loss-based scaling mixes and without clear normalization or stability analysis, and controller training/objective are underspecified; SVD frequency and hysteresis are not detailed.\n- Experimental rigor is weak: “GPT-3.5-turbo” fine-tuning is unclear, dataset/task splits and metrics (e.g., HumanEval pass@k) are non-standard or underspecified, tables lack variance/seeds and absolute memory/latency numbers, and several references/descriptions appear incomplete or error-prone."}, "questions": {"value": "- Rank update: how are $\\eta,\\ \\epsilon$ chosen in $r_{t+1}=\\mathrm{clip}\\big(r_t+\\eta\\,f(\\|\\nabla_\\theta L\\|^2,\\ \\mathrm{tr}(H))+\\epsilon\\big)$ to prevent oscillation across layers?\n- Curvature: how many Hutchinson probes estimate $\\mathrm{tr}(H)$ per step, and what is the measured overhead vs. baseline?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MM9goK6lsI", "forum": "gMc5Qa45ia", "replyto": "gMc5Qa45ia", "signatures": ["ICLR.cc/2026/Conference/Submission25435/Reviewer_xtgL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25435/Reviewer_xtgL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25435/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986681725, "cdate": 1761986681725, "tmdate": 1762943431005, "mdate": 1762943431005, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes DynamicRank LoRA, a novel fine-tuning method for code models that dynamically adjusts the rank of LoRA matrices in real-time based on two complementary signals: token-level importance (derived from attention weights) and loss landscape dynamics (from gradient norms and curvature). The method increases rank for high-importance tokens like keywords and variable names to capture fine-grained patterns, while reducing rank in flat loss regions to accelerate convergence. Implemented using a lightweight MLP controller and truncated SVD for efficient rank reshaping, it adds less than 5% computational overhead while integrating seamlessly with transformer architectures. Experiments on code benchmarks (CodeXGLUE, HumanEval, APPS) show DynamicRank LoRA achieves the best performance while using 30% less memory and 28% less training time compared to fixed-rank LoRA baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper focused on an interesting direction, dynamically adjusting the rank of LoRA in real-time training process. \n\n2. The paper provides a novel solution for the dynamic LoRA training in code models."}, "weaknesses": {"value": "1. I am thinking the motivation of this paper. In my opinion, code generation is a very challenging tasks and we usually need to use a high rank LoRA to achieve a comparable performance with full fine-tuning. So I'm not sure whether code task is a great application for the dynamic LoRA teste.\n\n2. The proposed method uses Hessian Trace and SVD. In my opinion, these methods are usually time-consuming and can provide additional more time cost. I think the authors can provide more details on that. \n\n3. The experiments are not thorough enough. (1) The paper mainly focused on BLEU-4 and CodeBLEU. I hope the authors can provide more results on HumanEval(+) and MBPP (+). (2) The paper should also provide the results on full fine-tuning, which can help people the performance gap between LoRA and fine-tuning. (3) The paper should provide more results of various pre-trained models."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "kBqOqrS6PT", "forum": "gMc5Qa45ia", "replyto": "gMc5Qa45ia", "signatures": ["ICLR.cc/2026/Conference/Submission25435/Reviewer_SgvF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25435/Reviewer_SgvF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25435/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762141959899, "cdate": 1762141959899, "tmdate": 1762943430640, "mdate": 1762943430640, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}