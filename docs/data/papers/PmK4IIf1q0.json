{"id": "PmK4IIf1q0", "number": 5566, "cdate": 1757920300869, "mdate": 1759897967722, "content": {"title": "TAS-GS: Integrating Topology, Appearance and Semantics for Sparse-View 3D Gaussian Splatting", "abstract": "We present TAS-GS, a  framework that extends 3D Gaussian Splatting (3DGS) to sparse-view reconstruction by integrating topology, appearance and semantic priors.  TAS-GS addresses key challenges of sparse-view 3DGS, including structural fragility, texture incoherency, and loss of fine details, through three modules: (i) a topology-aware graph regularizer that prunes floaters and bridges structural gaps, (ii) a GNN-based appearance propagation module that refines textures in weakly supervised regions, and (iii) a semantic-rarity and boundary-aware modulator that preserves fine details and underrepresented categories. All modules are applied only during training, and the final representation remains fully compatible with the standard 3DGS rasterizer. Extensive experiments on LLFF and Mip-NeRF 360 show that TAG-GS consistently outperforms state-of-the-art NeRF- and Gaussian-based methods across a wide range of sparsity levels. Ablation studies further confirm the effectiveness of each component in improving both quantitative metrics and perceptual quality. Our code is available at https://anonymous.4open.science/r/56165123.", "tldr": "We propose TAS-GS, a topology, appearance, and semantic prior guided extension of 3D Gaussian Splatting that enables robust sparse-view reconstruction with sharper structures and more faithful textures.", "keywords": ["sparse-view novel view synthesis、3D Gaussian Splatting"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/455714ff0ade1a0aaaaa429d054264f2782ba5de.pdf", "supplementary_material": "/attachment/2e6f30f13259bf8fb7b6a6918e4ec6f4810ca77d.zip"}, "replies": [{"content": {"summary": {"value": "This work focuses on sparse-view 3D Gaussian Splatting reconstruction. By introducing topology, appearance, and semantic priors, the authors claim that this method achieves better performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This work is well-written with clear descriptions.\n\n2. Experiments on LLFF and Mip-NeRF 360 show that TAS-GS consistently outperforms state-of-the-art NeRF- and Gaussian-based methods."}, "weaknesses": {"value": "1. Overall, this work introduces some heuristic methods to mitigate the weak supervision caused by sparse views. Compared to previous works, the authors claim to introduce additional semantic priors, yet this additional regularization does not bring much new insight to 3DGS-related works[1].\n\n[1] See In Detail: Enhancing Sparse-view 3D Gaussian Splatting with Local Depth and Semantic Regularization\n\n2. Due to the numerous heuristic designs in the paper, the authors introduce a large number of hyperparameters (over 10) in Eq. 3,4,6,9,12,14. The selection of these hyperparameters is important, yet the paper provides little discussion on this.\n\n3. From the qualitative experiments in the paper, it can be seen that the improvement of TAS-GS over previous works is limited, especially for some detailed parts.\n\n4. The paper lacks discussion on training efficiency and optimization convergence curves. This is important for evaluating the effectiveness of introducing these priors.\n\n5. The experimental setup in the paper is not clear. For example, it lacks a detailed description of the baseline model. I suspect that the baseline model used is not vanilla 3DGS.\n\n6. In the comparative experiments, the authors did not apply the proposed method to NeRF-based experiments, so the performance comparison with NeRF-based related works may be unfair."}, "questions": {"value": "1. Does the computational complexity of the proposed topology-aware graph regularizer depend on the number of Gaussians? Does increasing the number of Gaussians lead to a corresponding increase in graph nodes?\n\n2. How are the training views selected, and are they consistent with existing methods in Tables 2-3?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6P35ED6y47", "forum": "PmK4IIf1q0", "replyto": "PmK4IIf1q0", "signatures": ["ICLR.cc/2026/Conference/Submission5566/Reviewer_t3qW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5566/Reviewer_t3qW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5566/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761394584974, "cdate": 1761394584974, "tmdate": 1762918139898, "mdate": 1762918139898, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a method for sparse-view 3DGS problem. It first introduces a set of rule-based strategies to prune and fill the primitive structure. Then it uses a GNN to predict the bias of SH and alpha for refinement and a score to control the prune. Finally, it relies on an off-the-shelf segmentation model to extract the semantics and edges to enhance the losses. Experiments are conducted on two datasets of LLFF and MipNeRF 360 and show some performance improvement according to the reports."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Some performance improvements are shown."}, "weaknesses": {"value": "- Introducing graph for topology is not a new idea for 3DGS. Some existing works have already introduced and well discussed building graph to structure the primitives, like SAGS [1]. Especially, SAGS also uses GNN to estimate the primitives' attributes for refinement, and fill the points based on structure information. Meanwhile, this paper failed to discuss its relation and difference to this tightly related previous works.\n\n- The motivation and rationale are strange and not solid. 1) Simply based on the manually set thresholds and rules to prune and fill the Gaussians is not new and adaptive across scenes. It's a strong artificial prior that lacks robustness and methodology value. It can also destroy correct structures and fill the truly empty regions unexpectedly, due to the lack of solid theory support. 2) It's weird why regions with rare classes should be focused on. The 3DGS reconstruction is a semantic-free process and treats all the pixels equally. There is no reason to pay more attention to somewhere only because it is rare in semantics in the view. \n\n- Evaluations are insufficient. The authors only evaluate their method on two datasets LLFF and MipNeRF 360, which is significantly fewer than in previous works, like its base method NexusGS, that include at least two other important datasets DTU and Blender. Besides, qualitatively, the shown results are limited only to the rendering RGB images, which can not verify the critical geometry quality. Also, no video samples were provided. The claimed contributions regarding topology, floater, and structure completeness can not be verified.\n\n- Quantitative results are doubtful. While the authors failed to give the details about the experiments, they copied part of the results from FSGS's paper in Table 3. Therefore, I assume the authors conducted the experiment of MipNeRF 360 under the corresponding 1/8 resolutions. While the other metrics of the baselines remain the same, the performance of FSGS (21.70 0.674 0.323) is significantly worse than in its paper (23.70 0.745 0.220), which is much better than this work. From the reviewer's experience, the latter performance is reproducible. This is a critical credibility problem.\n\n- Moreover, this work did not compare to some earlier open-source works like CoR-GS [2] and DropGaussian [3], which surpass this work in most experiments of 6-view, 9-view LLFF, and the MipNeRF 360 experiments. \n\n- The efficiency is lacking. Especially, considering this work is built upon NexusGS and has plenty of new components, it's essential to evaluate its training overhead to verify if there is any actual improvement or just performance-efficiency overhead.\n\n- Ablation study shows only marginal improvements are brought by the complex and bloated new components. In Figure 3, it's shown that $L_{opacity}$ and Topology contribute most, which are 1) irrelevant to this work, and 2) not solid in methodology and not clear in implementation details. In figure 4, I can not observe any obvious difference between the baseline to the end method.\n\n- More details should be provided. So far, there are still many details lacking about the process and hyperparameters used in each experiment. These are essential to evaluate the quality of this work.\n\n- Representation is poor in Section 4. 1) Nearly all the definitions of the hyperparameters can not be found when they first appear. And plenty of notations are used without any statements, unless the reader refers to the appendix. Besides, some notations like $\\alpha_c$ and $\\hat \\delta ^{app}$ don't have any definition of its meaning throughout the paper. 2) While Section 3 defines $p$ to represent the Gaussian center, and $x$ for the query point, they are used inconsistently in the equation between Eq (4) and (5). Such inconsistency also exists in many other places. 3) Where are the $\\Delta SH$ and $\\Delta \\alpha$ come from? They only appear in the Figure 1 but can not be found in any other places. In this paper, the opacity is represented in $o$ and SH coefficients are in $k$. Are they the same? 4) Why do some equations have no number marked in Section 3 and 4?\n\n\n[1] Ververas, Evangelos, et al. \"Sags: Structure-aware 3d gaussian splatting.\" European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2024.\n\n[2] Zhang, Jiawei, et al. \"Cor-gs: sparse-view 3d gaussian splatting via co-regularization.\" European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2024.\n\n[3] Park, Hyunwoo, Gun Ryu, and Wonjun Kim. \"Dropgaussian: Structural regularization for sparse-view gaussian splatting.\" Proceedings of the Computer Vision and Pattern Recognition Conference. 2025."}, "questions": {"value": "See the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "GIZ6q7mavq", "forum": "PmK4IIf1q0", "replyto": "PmK4IIf1q0", "signatures": ["ICLR.cc/2026/Conference/Submission5566/Reviewer_Z5K4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5566/Reviewer_Z5K4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5566/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761559672106, "cdate": 1761559672106, "tmdate": 1762918139473, "mdate": 1762918139473, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes TAS-GS, a topology–appearance–semantics aware framework that tackles the challenging task of sparse-view novel view synthesis. The method introduces (i) a topology-aware graph regularizer, (ii) a GNN-based appearance propagation module, and (iii) a semantic-rarity and boundary-aware modulation strategy. Experiments on LLFF and Mip-NeRF360 demonstrate improvements over several state-of-the-art baselines. While conceptually coherent, some heuristic design choices raise concerns about stability and potential artifacts in cluttered scenes."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The method is conceptually complete, integrating topology, appearance, and semantic priors into a unified framework for sparse-view reconstruction.\n2. Experimental results show consistent improvement over baselines across multiple datasets.\n3. The paper is overall well-written and should be easy to follow."}, "weaknesses": {"value": "1. The grouping of Gaussians is mainly driven by geometric proximity (via Mahalanobis k-NN). In cluttered regions, Gaussians from different objects may be assigned to the same group, potentially affecting downstream computations.\n2. The inter-component bridging and intra-component filling operations rely on heuristic rules that may also introduce artifacts, especially when different structures are close in 3D. I would suggest showing results on the **counter** scene from the Mip-NeRF 360 dataset or other complex scenes, which contain many closely arranged objects and represent a more challenging, cluttered scenario for evaluating such heuristics.\n3. The visual differences in the LLFF 3-view ablation results are limited. Do the authors have more compelling visualizations to highlight the improvements contributed by each component?\n4. Since the method trains on top of NexusGS for 30k iterations, could the authors report training time or computational overhead to better contextualize the improvement relative to the additional cost?"}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "b4pXciFjtA", "forum": "PmK4IIf1q0", "replyto": "PmK4IIf1q0", "signatures": ["ICLR.cc/2026/Conference/Submission5566/Reviewer_d65r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5566/Reviewer_d65r"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5566/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761726942327, "cdate": 1761726942327, "tmdate": 1762918139170, "mdate": 1762918139170, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces TAS-GS, a training-time framework to strengthen sparse-view 3D Gaussian Splatting by integrating three priors: (i) a topology-aware graph regularizer that prunes floaters and repairs gaps via Mahalanobis k-NN, bridging, and hole filling; (ii) a GNN-based appearance propagation that refines opacity/SH with visibility-adaptive residuals and survival scores; and (iii) a semantic-rarity/boundary modulator that upweights losses on rare classes and edges from pseudo-labels. All additions keep the final representation 3DGS-compatible. On LLFF and Mip-NeRF360 with few views, TAS-GS outperforms NeRF and recent 3DGS variants, with ablations confirming each module’s impact and a noted limitation under very low view overlap."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Integrates topology, appearance, and semantics in a unified, training-only framework for sparse-view 3DGS—an original and well-motivated combination that removes inference-time overhead while addressing key failure modes (floaters, gaps, texture incoherence).\n- Technical quality is solid: clear graph construction (Mahalanobis k-NN), principled hole detection/repair, a visibility-adaptive GNN with teacher-free losses, and a simple yet effective semantic rarity/boundary reweighting; accompanied by complexity analysis and thorough ablations.\n- Writing and presentation are clear and structured, with precise algorithms, equations, and schedules that make the method reproducible and easy to implement atop standard 3DGS."}, "weaknesses": {"value": "- Semantic pseudo-label dependency and robustness  \nSRB relies on a frozen segmenter (OneFormer) that may be unreliable on novel scenes; report sensitivity to segmentation noise, and try alternative sources (e.g., SAM edges, class-agnostic boundaries).\n\n- GNN design choices and alternatives insufficiently justified  \nThe choice of GATv2, feature set, and visibility-adaptive blending lacks comparisons; include variants (GCN/EdgeConv/EGNN) and analyze cost–accuracy trade-offs and the necessity of the teacher-free invisible loss.\n\n- Scope limited to static, small-scale scenes  \nThe method does not address dynamics or large unbounded scenes; discuss extensions (e.g., time-aware topology with temporal consistency, chunked/topo-local graph building for large scenes) and provide at least preliminary scaling tests on larger reconstructions.\n\n- Missing cross-dataset generalization and robustness tests  \nEvaluate on additional benchmarks (e.g., Tanks&Temples, DTU sparse splits, Objaverse subsets) and report robustness across varying noise in SfM initialization, camera pose errors, and different sparsity patterns (clustered vs. uniformly spaced views)."}, "questions": {"value": "- How do you decide when to perform inter-component bridging versus intra-component filling beyond the label count heuristic on $\\mathcal{I}_{\\partial}$? Could you add a photometric or epipolar-consistency gate (e.g., multi-view color/feature agreement along the candidate segment) to reduce false bridges in low-overlap scenes?\n- The invisible “teacher-free” loss and the doubling of $\\beta$ for invisible nodes are central. Could you provide an analysis of stability (e.g., does it cause texture leaking across occlusions)? What happens if you remove the 2× factor or learn $\\beta$ per-node via a small MLP conditioned on visibility and view geometry?\n- How is $\\tau_s$ chosen and how sensitive are results to $\\tau_s$ and $\\tau_{prune}$? Does the survival score correlate with structural importance (e.g., graph centrality, view coverage)?\n- Since OneFormer may be unreliable on out-of-domain scenes, did you try class-agnostic edges (e.g., Canny/SAM boundaries) for the boundary term and class-frequency priors from the training set for rarities?\n- You claim full 3DGS compatibility. Are there any hidden dependencies at test time (e.g., needing cached survival scores or semantic maps)?\n- Results are on LLFF and Mip-NeRF360. Could you evaluate on a third dataset (e.g., Tanks&Temples or DTU sparse subsets) and on different sparsity patterns (clustered vs. uniform camera placements)? Also, how does the method behave with pose noise or imperfect SfM initialization?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gIHxOUIb9o", "forum": "PmK4IIf1q0", "replyto": "PmK4IIf1q0", "signatures": ["ICLR.cc/2026/Conference/Submission5566/Reviewer_nPhd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5566/Reviewer_nPhd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5566/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762088475740, "cdate": 1762088475740, "tmdate": 1762918138581, "mdate": 1762918138581, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}