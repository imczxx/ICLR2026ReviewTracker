{"id": "DUe1AFKQBG", "number": 12960, "cdate": 1758212107010, "mdate": 1759897474100, "content": {"title": "Diffusion Meta-Prompts for Foundation Models", "abstract": "Parameter-efficient fine-tuning techniques, such as prompting, are now popular to adapt foundation models to many tasks. In this paper, we introduce a diffusion-based approach to model the distribution of learned foundation models prompts. Specifically, we propose a $\\textbf{Diffusion Meta-Prompt (DMP)}$ model that generates prompts conditioned on text or prompt embeddings, and can be used to prompt both vision-language models and diffusion models for image synthesis. DMPs have several advantages: improved generalization of learned prompts; memory and runtime efficiency by eliminating the need to store and search over large repositories of prompts or LoRA weights; multiple applications ranging from  open-set classification, to personalization or attribute control of image synthesis; support for operations like subject and concept composition, novel subject generation, negative prompting, and editing without explicit training. For open-set classification, DMP improves base-to-new class generalization, achieving upto $\\textbf{3}$% average gain across 11 datasets with gains as high as $\\textbf{7.8/5.4}$% on specific datasets such as Eurosat/UCF101 respectively.  DMP also enhances domain, cross-dataset and cross-task generalization with $\\sim$$\\textbf{6-12}$% improvement for hierarchical classification task. For image synthesis tasks, DMP improves generalization and prompt compliance by $\\textbf{1.4}$ points as measured by CLIP score and reduces storage requirements by $\\textbf{91}$% while improving runtime efficiency by $\\textbf{92}$% over retrieval methods.", "tldr": "We propose Diffusion Meta-Prompts (DMP), a diffusion-based method that generates prompts for foundation models with better memory, runtime efficiency and generalization across domains, tasks, and concepts.", "keywords": ["Diffusion", "Meta-learning", "Prompt learning", "Prompt tuning", "few-shot classification"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/49e6ab48fc6c45f56e894e4e5819e3f808522ef1.pdf", "supplementary_material": "/attachment/767e5309f53ca8b75baaeaf2d0b1a7fc3ffd4dd9.zip"}, "replies": [{"content": {"summary": {"value": "In this work, the authors propose Diffusion Meta-Prompts (DMP), a diffusion-based framework that models the distribution of learned prompts to generate task-conditioned prompts for foundation models, aiming to enhance generalization and efficiency across diverse tasks. Instead of fine-tuning model weights or training task-specific adapters, DMP learns a set of meta prompts in the latent or textual embedding space that guide the diffusion process during sampling."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-organized and easy to follow.\n\n2. The proposed DMP framework is presented as a general approach applicable to multiple modalities and tasks, including classification, personalization, and image synthesis, which demonstrates versatility.\n\n3. The code is attached, making the method reproducible."}, "weaknesses": {"value": "1. The idea of modeling prompt distributions via generative models is not truly new. Prior works [1-3] have already explored meta-learning or generative approaches for prompts. The paper’s contribution over these is unclear and incremental.\n\n2. The paper’s related work and experiments fail to include comparisons with existing generative or meta-learning–based prompt tuning methods, such as [1–3]. limiting the evaluation of the proposed DMP framework against relevant state-of-the-art approaches.\n\n3. The initialization strategy of the prompt repository is not clearly described.\n\n4. The paper does not include an ablation study on the number of prompts stored in the prompt repository. It remains unclear how sensitive the method is to this design choice or how to balance generation quality against computational cost.\n\n5. Although the paper includes a discussion of limitations, it does not present concrete failure cases or qualitative examples, making it difficult to understand the method’s robustness boundaries and potential failure modes.\n\n[1] Prompt Learning via Meta-Regularization. Park, J. et al., CVPR 2024.\n[2] Patch-Prompt Aligned Bayesian Prompt Tuning for Vision-Language Models. Liu, X. et al., UAI 2024.\n[3] Gradient-regulated meta-prompt learning for generalizable vision-language models. Wang, J. et al., CVPR 2023."}, "questions": {"value": "1. Proposition 1 assumes that the repository contains *n* i.i.d. prompts for each condition *y*. Given that prompts are typically correlated or template-based, how realistic is this assumption, and how would the theoretical guarantee change if the prompts are not truly i.i.d.?\n\n2. In Figure 9, the prompts generated by DMP appear to form clustered patterns in the embedding space. Could the authors explain what these clusters represent?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FzGPL6ZHG5", "forum": "DUe1AFKQBG", "replyto": "DUe1AFKQBG", "signatures": ["ICLR.cc/2026/Conference/Submission12960/Reviewer_fRKq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12960/Reviewer_fRKq"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12960/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761568665268, "cdate": 1761568665268, "tmdate": 1762923717104, "mdate": 1762923717104, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work introduces a diffusion-based approach to model the distribution of learned foundation models prompts. The approach generates\nprompts conditioned on text or prompt embeddings, and is suitable for both VLM and image generation models. The method is evaluated across a plethora of tasks, showing improvements compared to the baseline."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Straightforward but interesting approach for prompting\n- Evaluation for multiple type of tasks\n- Generally, good improvements against the baselines and included approaches\n- The included theoretical backing is a plus"}, "weaknesses": {"value": "- Novelty wise, what are the conceptual difference compared to similar works that perform diffusion for prompting: \"Prompt Diffusion Robustifies Any-Modality Prompt Learning, 2024\", \"Diff-prompt: Diffusion-driven prompt generator with mask supervision, 2025\" etc ? \n- Many of the comparison made are against CoOp, which while a pioneering work, its performance is now surpassed by many other approaches.  How would the results from Table 3,7,Fig. 3,4 etc on top of TAC?\n- The spacing across the paper is aggressively adjusted, making it harder to read (ex: Fig. 3-5 and Tab. 5-7 are nearly overlaping and and conjoined with the rest to the text, same on top of section 4 etc).\n- Missing comparisons with state-of-the-art: [A,B,C,D,e etc], with some of these methods significantly surpassing the present baseline either on a dataset level, or globally (e.g: [D]).\n- Similarly, for diffusion models (e.g: [F])\n\n[A] Hierarchical Variational Test-Time Prompt Generation for Zero-Shot Generalization, Wu et al, CVPR 2025\n[B] LASP: Text-to-Text Optimization for Language-Aware Soft Prompting of Vision & Language Models, Bulat et al, CVPR 2023\n[C] Consistency-guided prompt learning for vision-language models, Roy et al, ICLR 2024\n[D] PromptKD: Unsupervised Prompt Distillation for Vision-Language Models, Li et al, CVPR 2024\n[E] DPC: Dual-Prompt Collaboration for Tuning Vision-Language Models, Li et al, CVPR 2025\n[F] Contrastive Test-Time Composition of Multiple LoRA Models for Image Generation, Meral et al, CVPR 2025"}, "questions": {"value": "- What is the training of the presented method vs prior work (e.g. CoOp, TAC etc) ?\n- The visual results quality looks somewhat poor, perhaps because the diffusion model used? are there any combination with better generators to understand how well it works?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "uTYCaEms7Q", "forum": "DUe1AFKQBG", "replyto": "DUe1AFKQBG", "signatures": ["ICLR.cc/2026/Conference/Submission12960/Reviewer_jZN5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12960/Reviewer_jZN5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12960/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761867112632, "cdate": 1761867112632, "tmdate": 1762923716789, "mdate": 1762923716789, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a generative approach for prompt-learning, whereby a sampling distribution is learned and used to sample a prompt from a query. The authors rely on training a diffusion model that can decode a prompt from noise, conditioned on a particular query, and which is learned using a large pool of prompts available for different methods. Contrary to existing prompt-tuning techniques, in the proposed DMP the generative model is learned from a pool of available prompts rather than from fine-tuning the prompt embeddings to a particular task."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The idea of training a generative method for prompt generation in the text domain rather than in the continuous domain of embeddings as in existing methods is appealing from the perspective that generated prompts are semantically complete and can hint on how the models need prompting from a human perspective. \n\nThe results are competitive, showing that the proposed approach is supported by the results."}, "weaknesses": {"value": "The paper is loosely written and lacks consistency. The authors refer to the literature in a rather unprofessional way with sentences like \"we train CLIP following the respective papers\", what papers? this needs to be more specific. \n\nThe authors refer to the choice of diffusion in the introduction but this choice is not justified experimentally. Why not other generative approaches? Some simpler alternatives can outperform diffusion for constrained tasks like prompt generation. \n\nI am not sure if I understood this so please correct me in the rebuttal if I did so. The method aims at sampling prompts from a prompt distribution that is learned over a set of discrete prompts. In other words, while existing prompt learning approaches learn continuous representations for particular models, the DMP learns from the pool of prompts, without regard to how these perform on the downstream tasks. This amounts to generating combinations of prompt that are likely to generalize less than the continuous counterparts to new tasks. For example, in Bayesian Prompt Learning (a reference the authors missed in the paper: \"Derakhshani et al. Bayesian prompt learning for image-language model generalization, ICCV'23\") one can sample new prompts after being learned through backpropagation from the model's error in a set of specific datasets. BPL shows to generalize to new classes without the need of retraining so I believe the authors should consider comparing both theoretically and experimentally against it. \n\n\nIn Section 3.1 it is mentioned that the models are trained \"for several prompt tuning methods such as CoOp\". I might have missed that bit, but I didn't get how these methods are combined with the proposed DMP. I would like to ask the authors to explain this clearly."}, "questions": {"value": "I have included my questions above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zhXNIRJGrW", "forum": "DUe1AFKQBG", "replyto": "DUe1AFKQBG", "signatures": ["ICLR.cc/2026/Conference/Submission12960/Reviewer_Vpu4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12960/Reviewer_Vpu4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12960/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761914726204, "cdate": 1761914726204, "tmdate": 1762923716416, "mdate": 1762923716416, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focues on the prompt generation and proposes the Diffusion Meta-Prompt (DMP) to train a conditional generator via diffusion models to directly output the prompt embeddings from the description input. One of the core ideas of DMP is to view the prompts of specific tasks as a distribution in the embedding space, and employ a diffusion model to learn such prompt distribution. To do this, DMP first collects the (description, prompt) pairs from the base prompt tuning methods, and then train a conditional generator by the denosing loss in diffusion. The resulting generator can directly output the prompt given a testing description. Results on image clasification and editing tasks show the improvements of DMP over the base models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1), The idea of directly training a diffusion model to generate prompts is novel to the prompt-tuning community, and the results of the proposed model clearly demonstrate the effectiveness of this motivation.\n\n2), DMP is well-motivated by integrating prompt tuning with generative modeling. By viewing prompts as distributions in the embedding space, the learned DMP exhibits strong generalizability and transferability to unseen tasks.\n\n3), The authors conducted extensive experiments to evaluate the proposed model, and all the results consistently support its underlying motivation."}, "weaknesses": {"value": "1), One of the main concerns lies in the relatively small improvements shown in Table 4. Since DMP is trained based on the outputs of the base model, this dependency may limit its overall performance.\n\n2), The authors provide various visualization results to demonstrate the effectiveness of DMP. However, it would be helpful to also include quantitative results to substantiate the improvements in image generation quality.\n\n3), What are the main technical differences between DMP and Neural Network Diffusions [1,2,3]? They appear to share a similar idea of generating parameters through diffusion models.\n\n4), DMP can be viewed as an enhancement stage that refines the outputs of a base model using diffusion processes. Recent studies have leveraged Large Language Models (LLMs) to refine textual prompts in word space [4,5]. The authors are encouraged to discuss in detail how DMP differs from such approaches. Including additional comparative results would also strengthen the paper.\n\n[1] Neural network diffusion\n\n[2] Conditional lora parameter generation. \n\n[3] Difflora: Generating personalized low-rank adaptation weights with diffusion\n\n[4] AWT: Transferring Vision-Language Models via Augmentation, Weighting, and Transportation\n\n[5] PRewrite: Prompt Rewriting with Reinforcement Learning."}, "questions": {"value": "Please see the Weakness above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tYV0eM6N9c", "forum": "DUe1AFKQBG", "replyto": "DUe1AFKQBG", "signatures": ["ICLR.cc/2026/Conference/Submission12960/Reviewer_zqwL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12960/Reviewer_zqwL"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12960/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762054184213, "cdate": 1762054184213, "tmdate": 1762923716073, "mdate": 1762923716073, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}