{"id": "h06l9w1clt", "number": 508, "cdate": 1756743225915, "mdate": 1759898256509, "content": {"title": "Locality-aware Parallel Decoding for Efficient Autoregressive Image Generation", "abstract": "We present Locality-aware Parallel Decoding (LPD) to accelerate autoregressive image generation. Traditional autoregressive image generation relies on next-patch prediction, a memory-bound process that leads to high latency. Existing works have tried to parallelize next-patch prediction by shifting to multi-patch prediction to accelerate the process, but only achieved limited parallelization. To achieve high parallelization while maintaining generation quality, we introduce two key techniques: (1) Flexible Parallelized Autoregressive Modeling, a novel architecture that enables arbitrary generation ordering and degrees of parallelization. It uses learnable position query tokens to guide generation at target positions while ensuring mutual visibility among concurrently generated tokens for consistent parallel decoding. (2) Locality-aware Generation Ordering, a novel schedule that forms groups to minimize intra-group dependencies and maximize contextual support, enhancing generation quality. With these designs, we reduce the generation steps from 256 to 20 (256×256 res.) and 1024 to 48 (512×512 res.) without compromising quality on the ImageNet class-conditional generation, and achieving at least 3.4× lower latency than previous parallelized autoregressive models.", "tldr": "", "keywords": ["Efficient Autoregressive Image Generation", "Parallel Decoding"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bc7180d3996726e7e68d8be5e2026c1b5f2bec31.pdf", "supplementary_material": "/attachment/d73d0c6ff37cc8209cdfe4ab14acef3b0b6f85f1.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes Locality-aware Parallel Decoding (LPD), an efficient method for parallel autoregressive image generation. By introducing position query tokens, it enables flexible, location-independent parallel decoding, while a locality-aware generation order improves consistency and quality. Experiments show that LPD achieves comparable or better image quality with up to 10× fewer generation steps and 3–4× faster decoding speed."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Here are the main strengths of the paper:\n\nSignificant Speedup – LPD greatly reduces the number of decoding steps (up to 10–20× fewer) while maintaining or improving image quality.\n\nHigh-Quality Generation – The locality-aware scheduling preserves spatial coherence, producing consistent and detailed images even under high parallelism.\n\nFlexible Decoding Framework – The position query token design allows generation in arbitrary orders, enabling diverse tasks like inpainting and outpainting without retraining.\n\nStrong Empirical Validation – Extensive experiments on ImageNet (256×256 and 512×512) demonstrate clear improvements in both FID and latency over prior autoregressive baselines."}, "weaknesses": {"value": "The paper is technically strong and the proposed method is clearly effective for autoregressive image generation. However, I think the evaluation could be further strengthened by extending it beyond ImageNet. In particular, it would be interesting to test the method on text-conditioned generation at higher resolutions (e.g., 1024²) to see whether the parallel decoding and locality assumptions still hold under more complex, long-range dependencies.\nMoreover, applying LPD to video generation or temporal sequence modeling could highlight its scalability in spatiotemporal domains. Even a small-scale video experiment (e.g., UCF-101) would make the paper more convincing in terms of generality and impact."}, "questions": {"value": "see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LVQcKISZ4x", "forum": "h06l9w1clt", "replyto": "h06l9w1clt", "signatures": ["ICLR.cc/2026/Conference/Submission508/Reviewer_axY1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission508/Reviewer_axY1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission508/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761275380916, "cdate": 1761275380916, "tmdate": 1762915534711, "mdate": 1762915534711, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Locality-aware Parallel Decoding (LPD) with two techniques to accelerate autoregressive image generation. First, Flexible Parallelized Autoregressive Modeling leverages position-aware query tokens to indicate the tokens to be generated, enabling arbitrary generation ordering and degrees of parallelization. Second, a Locality-aware Generation Ordering is proposed to minimize mutual dependencies during parallel generation. Experiments on ImageNet 256$\\times$256 and 512$\\times$512 demonstrate the effectiveness of the proposed LPD."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed Flexible Parallelized Autoregressive Modeling overcomes the constraint of a fixed generation order by allowing images to be synthesized in an arbitrary sequence. This capability holds the potential for discovering more effective generation orders in the future.\n2. When equipped with the proposed Locality-aware Generation Ordering strategy, LPD demonstrates improved FID scores and greater generation efficiency on the ImageNet dataset.\n3. The paper is easy to read and the figures are informative."}, "weaknesses": {"value": "1. The paper's core algorithm (Algorithm 1) is presented in the appendix. While space constraints are understandable, the most critical algorithm should ideally be included in the main text, or at the very least, its underlying principles should be explained there.\n2. The computational cost of the model increases compared to traditional fixed-order autoregressive models due to the use of additional positional query tokens. However, an analysis of this overhead is absent from the paper.\n3. In line 208, the authors state that in previous methods, \"tokens generated within the same parallel step are produced independently of one another.\" However, the paper does not rigorously analyze the issue of conditional independence in LPD's parallel sampling. It appears that while LPD ensures visibility among all target positions predicted concurrently, it may not fully resolve the underlying conditional independence of the parallel-generated tokens. A theoretical justification for this aspect would be beneficial.\n4. The authors train the LPD model for 450 and 500 epochs on ImageNet at 256×256 and 512×512 resolutions, respectively. In contrast, most baseline methods (e.g., LlamaGen, PAR, and NAR) are trained for only 300 epochs. This discrepancy in training budgets may lead to an unfair comparison."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "loPV4OHH2f", "forum": "h06l9w1clt", "replyto": "h06l9w1clt", "signatures": ["ICLR.cc/2026/Conference/Submission508/Reviewer_mUfX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission508/Reviewer_mUfX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission508/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761703450123, "cdate": 1761703450123, "tmdate": 1762915534610, "mdate": 1762915534610, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method to accelerate AR visual generation, which is typically bottlenecked by sequential token prediction and memory bandwidth. It introduces two core innovations: (1) Flexible Parallelized Autoregressive Modeling, which allows arbitrary generation order and parallel prediction using learnable position query tokens and (2) Locality-aware Generation Ordering, a scheduling strategy that groups spatially related tokens to minimize dependencies and maximize contextual support. These techniques reduce generation steps dramatically and achieve at least 3.4× lower latency than prior parallel AR models without compromising image quality on ImageNet benchmarks."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "The paper conducts a genuinely deep analysis of the key factors that affect both performance and generation quality in parallel autoregressive decoding (e.g., group size, dependency structure, attention visibility), and then turns those observations into a coherent, end-to-end parallelization method rather than a single heuristic component.\n\nThrough careful comparisons with recent parallel AR implementations (e.g., encoder–decoder style SAR/ARPG and decoder-only RANDAR), the authors show that their design, especially the “mutual visibility among concurrently generated tokens + cache only generated tokens” part, is not just faster but architecturally better motivated, and they support this with latency as well as quality numbers.\n\nThe paper is very readable: the motivation is clearly laid out, figures are aligned with the text (the attention-mask figures in particular), and the training vs. inference formulations are described in a way that makes reproduction and reimplementation realistic even for non-authors."}, "weaknesses": {"value": "Experiments are limited to image generation; since current AR models are increasingly used for multimodal I/O (image–text, video tokens, layout, even audio tokens), it would strengthen the claim of “general AR parallelization” to show at least one non-image setting (e.g., CLIP-conditioned image tokens, image+text joint decoding, or video latents).\n\nThe paper does not compare against the newest AR acceleration lines such as speculative decoding, speculative Jacobi-style decoding, or draft/verify variants; even a small-scale experiment would help position LPD as complementary vs. strictly better.\n\nWhile there is throughput analysis at batch 64, the work does not fully characterize memory consumption and scaling beyond that point; since the method introduces extra query tokens and fused encode–decode steps, reporting peak GPU memory and how it scales with batch size and resolution would make the efficiency story more convincing."}, "questions": {"value": "Could the proposed LPD framework be extended or adapted to multimodal generation (e.g., image–text, video, or audio tokens)? Given its reliance on spatial locality, how might token dependencies behave for non-visual modalities?\n\nHow would LPD compare in efficiency and quality against speculative decoding or speculative Jacobi decoding? Including at least one experiment could clarify whether LPD complements or surpasses these methods.\n\nSince the fusion of encoding and decoding steps introduces additional query tokens, could you quantify peak GPU memory usage and performance scaling with batch size and resolution (beyond batch 64)?\n\nThe method partially decouples context and generation tokens. Could the authors clarify how this affects the probabilistic consistency of the AR factorization (Eq. 2 in the paper)? In addition, the paper highlights speedups, but how does varying the group size quantitatively affect image fidelity and diversity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VBx0wQFrlJ", "forum": "h06l9w1clt", "replyto": "h06l9w1clt", "signatures": ["ICLR.cc/2026/Conference/Submission508/Reviewer_Gaej"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission508/Reviewer_Gaej"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission508/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982793438, "cdate": 1761982793438, "tmdate": 1762915534264, "mdate": 1762915534264, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Locality-aware Parallel Decoding (LPD), a method designed to speed up autoregressive image generation. LPD uses two key techniques—Flexible Parallelized Autoregressive Modeling for arbitrary parallelization and Locality-aware Generation Ordering for quality enhancement—and reduces generation steps significantly (e.g., 256 to 20 for 256×256 images) on ImageNet while cutting latency by at least 3.4× compared to prior parallel models."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* Sound Method Design：The learnable position query tokens decouple context modeling from decoding, enabling generation at arbitrary target positions and boosting flexibility. The exploration of two locality principles, particularly the second one, offers meaningful insights for the community.\n\n* Strong Performance：The method achieves clear reductions in generation steps and latency with good quality."}, "weaknesses": {"value": "1. Overclaimed Contributions in Writing\n\n   - For \"Flexible Parallelized Autoregressive Modeling\", decoder-only works like PAR/ZipAR/NAR already treat previously decoded tokens as KV Cache and the queries are decoded in parallel ensuring the mutual visibility among tokens generated concurrently; the key difference lies only in LPD’s position query tokens (enabling arbitrary target positions), which should be clarified to avoid overstating contributions.\n   - For \"Locality-aware Generation Ordering\", the first principle is well-studied (Sec. 3.2 descriptions can be simplified), while the second principle (\"low proximity among concurrent tokens\") has been explored by Wang et al. (2024b) and Besnier et al. (2025)—its underexploration in prior work needs more detailed explanation in Sec. 3.2.\n\n2. Insufficient Ablation Studies\n   - Sensitivity analysis of critical thresholds $\\tau$ and $\\rho$ is missing, despite their importance to query position performance.\n   - A key ablation is absent: for Flexible Parallelized AR Modeling (excluding adaptive generation order), testing whether replacing query tokens with LPD’s \"position query tokens\" would clarify the source of performance gains.\n\n3. Confusing Details\n    - Inference process ambiguity: It is unclear if sampled tokens need a forward pass to store KV Cache, and if this can be done in the final decoding step.\n   - Figure 3 confusion: The figure shows queries attending only to the latest decoded tokens, conflicting with the claim that queries causally attend to all previously generated tokens.\n\n4. Minor Structural Issue：The dynamic generation order, a core technical contribution, should be included in the main text."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MZCLZEONMi", "forum": "h06l9w1clt", "replyto": "h06l9w1clt", "signatures": ["ICLR.cc/2026/Conference/Submission508/Reviewer_z7UP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission508/Reviewer_z7UP"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission508/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762079247088, "cdate": 1762079247088, "tmdate": 1762915534127, "mdate": 1762915534127, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}