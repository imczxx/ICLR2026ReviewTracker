{"id": "wbIYlFCPPq", "number": 2715, "cdate": 1757219377574, "mdate": 1759898131905, "content": {"title": "Provably Efficient High-Order Flow Matching in Pixel Space", "abstract": "We introduce high-order PixelFlow (HopeFlow), which is the first cascade flow model that learns both pixel‑space velocity and acceleration fields end‑to‑end, lifting image generation beyond the limitations of purely first‑order supervision. By incorporating second‑order dynamics, HopeFlow aligns mid‑horizon dependencies and high‑curvature regions, yielding markedly smoother, more stable transport trajectories. The model trains directly on raw pixels—no VAE encoder‑decoder is required—and remains computationally affordable. We prove that the HopeFlow model is computable by a $\\mathsf{TC}^0$ class of threshold circuits, which operate with constant depth $O(1)$ and a polynomial number of gates $\\mathrm{poly}(n)$. Moreover, by replacing exact attention with approximate attention layers, the end‐to‐end HopeFlow inference runs in almost quadratic time.", "tldr": "", "keywords": ["Generative Model", "Flow Matching", "Diffusion"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d5eab501d4f58aa25a7c9a7f01bd22ee7d55ca57.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "HopeFlow is the  cascade flow model that jointly learns both pixel-space velocity and acceleration fields in an end-to-end manner. By incorporating second-order dynamics, it better aligns mid-horizon dependencies and high-curvature regions, leading to smoother and more stable transport trajectories during image generation."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The paper provides a rigorous theoretical framework for high-order flow matching in pixel space, extending prior first-order methods. The related work is well-organized and sufficient to position the approach within existing diffusion and flow-based generative modeling literature."}, "weaknesses": {"value": "A major weakness of this paper is the complete absence of empirical experiments or quantitative evaluations. Without any empirical evidence, it is impossible to assess whether the proposed theoretical framework offers practical benefits over existing methods."}, "questions": {"value": "See the Weaknesses section regarding the absence of experiments and empirical evidence."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "aL3ZdbVmtJ", "forum": "wbIYlFCPPq", "replyto": "wbIYlFCPPq", "signatures": ["ICLR.cc/2026/Conference/Submission2715/Reviewer_252L"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2715/Reviewer_252L"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2715/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761407632708, "cdate": 1761407632708, "tmdate": 1762916341042, "mdate": 1762916341042, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper’s contribution lies in proposing a model architecture that learns both velocity and acceleration fields for image generation. The authors provide formal proofs showing that the proposed architecture belongs to the uniform TC⁰ circuit complexity class, suggesting provable efficiency and parallelizability."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The proposed idea of incorporating acceleration is conceptually interesting and may offer smoother generation trajectories.\nThe paper is mathematically detailed and ambitious."}, "weaknesses": {"value": "1. There is no experiments, visual results, or empirical evidence. It reads more like a theoretical report than a balanced ICLR paper.\n2. Writing is quite dense and formal, which makes it hard for general ML readers to follow the intuition or motivation.\n3. Some sections (especially on circuit complexity) feel disconnected from the generative modeling goal."}, "questions": {"value": "1. Can the authors include experimental or visual results to demonstrate the claimed improvements?\n2. Consider providing a short intuitive overview before the more formal sections to guide readers through the technical content."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "k7IJTWyFyh", "forum": "wbIYlFCPPq", "replyto": "wbIYlFCPPq", "signatures": ["ICLR.cc/2026/Conference/Submission2715/Reviewer_G4sF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2715/Reviewer_G4sF"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2715/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761889813827, "cdate": 1761889813827, "tmdate": 1762916340833, "mdate": 1762916340833, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes the high-order pixel flow model HopeFlow, which is the first cascading flow model for end-to-end learning velocity field and acceleration field in pixel space. The model breaks through the limitations of the existing first-order supervision method. By integrating the characteristics of second-order dynamics, it effectively aligns the medium-range dependency and high-curvature region, and generates a smoother and more stable transmission trajectory."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Simplicity of end-to-end pixel-level generation: Abandoning the VAE encoder-decoder structure relied upon by latent variable diffusion models, HopeFlow directly performs multi-scale cascading flow matching in the original pixel space, avoiding information loss and additional computational overhead caused by latent variable space, while supporting end-to-end joint optimization, enhancing the model's interpretability and flexibility in tuning.\n\n2. Innovation in high-order dynamics modeling: To address the trajectory instability issue caused by PixelFlow's modeling of only first-order velocity fields, HopeFlow introduces for the first time second-order acceleration fields into pixel-level flow matching. By jointly supervising velocity and acceleration, it provides explicit curvature guidance for high-curvature regions, significantly improving the smoothness and consistency of generated trajectories, and filling the gap in high-order dynamics modeling in existing flow matching methods."}, "weaknesses": {"value": "1. Complementary comprehensive quantitative evaluation: add standard generation model metrics such as FID, IS, LPIPS, and compare with current models such as SD-XL, FLUX, etc., on public datasets like ImageNet, CIFAR-10, to clearly demonstrate HopeFlow's advantages in generation quality.\n\n2. Lack of ablations and visualizations. I believe more figures and ablation experiments on public datasets can further improve this work."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "9CXEfMEGng", "forum": "wbIYlFCPPq", "replyto": "wbIYlFCPPq", "signatures": ["ICLR.cc/2026/Conference/Submission2715/Reviewer_yvy3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2715/Reviewer_yvy3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2715/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761974338887, "cdate": 1761974338887, "tmdate": 1762916340528, "mdate": 1762916340528, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}