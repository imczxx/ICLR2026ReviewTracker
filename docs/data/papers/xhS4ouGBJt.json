{"id": "xhS4ouGBJt", "number": 7301, "cdate": 1758014922855, "mdate": 1763099640096, "content": {"title": "Spectral Norm Variance Regularization for Balanced Layer-Wise Dynamics in Training Deep Neural Networks", "abstract": "While deep neural networks (DNNs) are widely adopted in machine learning applications, addressing the systematic imbalance in their layer-wise training dynamics, manifested as discrepancies in learning behavior between earlier and deeper layers, remains a continuous research challenge for improving generalization ability. In this work, we propose spectral norm variance regularization (SNVR) to promote balanced layer-wise dynamics in training DNNs. The spectral norm of a hidden layer, corresponding to the largest singular value of its weight matrix, serves as a proxy for how well the layer has been trained. We introduce a regularization term that penalizes the variance of spectral norms across layers of the same type and incorporate it directly into the learning objective. SNVR requires no strong assumptions about network architecture or learning objective, and its use involves hyperparameter tuning only for controlling the regularization strength. Moreover, it does not significantly increase computational cost, since spectral norms can be efficiently approximated via the power iteration method. Experimental results on multiple benchmark datasets with various network architectures demonstrate that SNVR improves generalization performance compared with baseline methods. Further analyses of layer-wise spectral densities, gradient norms, and information plane provide additional evidence of its balancing effect.", "tldr": "Achieving balanced layer-wise dynamics through direct regularization on the variance of spectral norms across layers.", "keywords": ["Layer-wise Balancing", "Spectral Norm Variance Regularization", "Deep Neural Network"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/9d6bde3d44631014270c6a14743c3bd2c75e7f64.pdf", "supplementary_material": "/attachment/5d8cb6890a24ef111365dbd2ba7b71571b2c3daa.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes a new regularization/normalization technique that aims at combating uneven training across (nested) layers: The idea is to estimate the spectral norm of each weight matrix (implemented conveniently using a few cycles of power-iteration) and penalize the spectral norm, i.e., the magnitude of the largest eigenvalue, in order to obtain a more equal training. This could also be seen as an implicit learning rate scheduler.\nThe method works well in practice (tested on common, smaller image recognition benchmarks). The margin to other methods does not seem to be big, but there seems to be a consistent performance improvement, and one would not expect huge jumps for these types of techniques. The paper also provides some analysis and potential explanation; I personally would see some issues here (see below)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is well written and the method is easy to understand. The idea is well motivated, although I think that the rather straightforward motivation is missing a few subtle but crucial aspects. I do think that it is plausible that this method would indeed help in getting more performance out of the training process, but not for the reason the paper suggests (I will explain this in the next section). The results are good. Although one could always ask for more (data sets, architectures, experiments), I am willing to believe that one sees a small improvement when used as a drop-in add-on, which is nonetrivial to obtain at the current state of the art. This aspect (a new method that actually seems to help, and is not terribly difficult to implement and use) seems to be the main strength of the paper in my opinion, and one could consider acceptance."}, "weaknesses": {"value": "My main issue with the paper is the explanation for the effect: The authors claim to address the uneveness of training across multiple network layers, and I would agree with this assessment in my understanding of the situation. However, the effects of uneven training, which I would broadly frame as \"gradient magnitude explosions\", depend decisively on the architecture employed: First of all, tests are performed with networks with shortcut connections (ResNet and descendants), which dampen these effects through the shortcuts: Here, deeper paths are down-weighted so that the issues with nesting deep hierarchies of layers are rather mild, empirically and theoretically. As a side note at this point: I think that it would be very insightful to repeat the benchmarks with a non-residual network such as VGG-19 (with and without BN), or a ResNet with shortcuts turned off, which greatly accentuates the effect and shows more clearly whether training speed disparities are kept under control.\nSecond, and more importantly, the networks considered employ batch-normalization (or layer-norm), which has the known and unintuitive effect of counteracting the balancing of the gradient magnitude achieved by the initialization (such as He-init for ReLU, or its analogon for other nonlinearities). As shown in [Yang et al., ICLR 2019] (\"A Mean Field Theory Of Batch Normalization\"), the magnitude of gradients explodes exponentially towards the input layers (this can be understood more easily/intuitively by just repeating the He-deriviation with the shifts of the BN-statistics, as shown for example in a blog post by K. Luther, 2020). At the same time, batch normalization induces a scale invariance on the weights, i.e., scaling the whole matrix (and its top eigenvalue) up does not change its effect; in contrast, under fixed learning steps, the effective learning speed actually becomes lower. This effect has been studied by several recent papers (I am aware of recent one from Göpel et al. at ICML 2024 that also cites earlier work on this matter); in particular, this leads to a jo-jo effect where the bottom layers first overshoot in magnitude and then effectively freeze in the next step. This would not be visible by looking only at the layer norms without taking gradient magnitudes into account. It has also been shown that this negative feedback loop leads to an eventual equalization, which can be reached in practice by the LARS-strategy, weight normalization, or small (well-controlled) step-sizes, all of which being (again, unintuitively) essentially equivalent due to the weight-scale symmetry induced by BN. Without BN, exploding gradients can also happen, but in my understanding these are artifacts of disparities in in- and out-degrees of linear layers which makes it impossible to choose a good intialization. (There is more to this; see for example \"deep kernel shaping\" and the classic \"dynamical isometry\" papers [Xiao et al. ICML 2018].)\n\nWhat I would guess is happening (I am not very sure though, as this is a big area full of subtle effects, and my personal knowledge and experience is limited to a small corner of it) is the following: While the disparities in effective learning steps can be mitigated with existing techniques such as LARS or the similar (weight decay can also play a role here, as it can \"unfreeze\" layers, when parametrized well, even without normalization), there is also the effect of a successive loss of dimensionality (stacks of linear layers lead to a concentration of the overall singular value spectrum of their concatenation, and this is hard to avoid, again see \"dynamical isometry\"). It seems plausible to me (although I did not do a careful analysis at this point), that penalizing the top singular value would have an (additional) equalizing effect on the spectrum of the whole stack of layers, unlike the techniques that just adjust layer-wise weightnorms/learning rates. That in turn could be responsible for an improvement in performance.\n\nI would like to emphasize that the last part is mostly speculation; my criticism is that the effect of normalization (BN in ResNet and LN in ConvNext) and short-cut connections is not explored in the analysis part, and that one could probably examine and explain more deeply what is going on. I am not very convinced by the information bottleneck argument – is there some reference showing that this is indeed a crucial effect? My understanding has been that this has been rather hypothetical so far, but I might have easily missed something important here (in that case, it would be good to emphasize this in the text).\n\nIn summary, I my impression is that this is a method with \"potentially some potential\", which is nontrivial for these matters, but the paper would benefit from a bit more work on the analysis side. Note: My confidence that I understood everything correctly is moderate to low, as there are many subtleties and I only know a small excerpt of the literature."}, "questions": {"value": "Did you try a deep network without shortcuts / residual connections? If your idea is correct, the improvement should be much more dramatic here (and if so, that would strengthen the paper a lot, even if this is rare in practice).\nDid you try out networks with and without normalization layers? More generally, are the effects of normalization important for the (understanding of the) proposed method?\nDid the method haven an influence of the overall spectral behavior of the network (expected variability SVD of the Jacobian of the overall network at training points)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "5AuSoqKQiA", "forum": "xhS4ouGBJt", "replyto": "xhS4ouGBJt", "signatures": ["ICLR.cc/2026/Conference/Submission7301/Reviewer_F9Fn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7301/Reviewer_F9Fn"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7301/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761608059297, "cdate": 1761608059297, "tmdate": 1762919418935, "mdate": 1762919418935, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "We sincerely thank all the reviewers for their valuable time and feedback. After careful consideration, we believe that our paper is not yet ready for publication and have decided to withdraw the submission. We will carefully review the suggestions and work to improve our manuscript. Thank you again for your understanding."}}, "id": "xGxkSYOOPx", "forum": "xhS4ouGBJt", "replyto": "xhS4ouGBJt", "signatures": ["ICLR.cc/2026/Conference/Submission7301/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7301/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763099639070, "cdate": 1763099639070, "tmdate": 1763099639070, "mdate": 1763099639070, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a novel regularization method based on penalizing the variance of the spectral norm across hidden layers in neural networks, to alleviate pathological issues in training deep layers in neural networks. The authors explain how to efficiently compute the loss term and evaluate it over fully-connected and convolutional layers. The method is evaluated on the CIFAR-10, CIFAR-100, TinyImageNet, STL-10 and Food-101 datasets, with models including ResNet-18, 34 and Conv2NeXt-T."}, "soundness": {"value": 1}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "* The paper is very well written, and in a very accessible manner.\n* The background is especially well written, with some excellent references, and was really a joy to read.\n* The method outlined is intuitive\n* The authors address the issue of computational cost well\n* The authors do explore the hyper parameters (two main ones associated with the SNR and SNVR loss terms)"}, "weaknesses": {"value": "While the methodology is very well motivated and explained, the empirical analysis and results are overall unfortunately poor and unconvincing, and there are obvious missing ablations:\n* The results are demonstrated only on relatively small and shallow image classification models --- this is especially surprising given the motivation of the work on addressing issues with learning deep layers. I will note that even using an extremely deep ResNet model for CIFAR-10 would be more convincing.\n* Despite the authors claims, in Table 1, it's clear that the improvements in generalization for the deeper/larger models are actually within variance, as compared to the shallower models (e.g. ResNet 18). This is the opposite of what would be expected given the motivation of the method.\n* Given the computational resources the authors used for the experiments (i.e. a 40GB A100), it's not obvious why results on even modest models/datasets (ResNet-50/ImageNet) were used, never mind much deeper and larger Vision Transformer models.\n* There is no ablation shown explaining for example why the SNR loss term is needed, and what the relative impact of the presence of the SNR vs. SNVR loss terms are (aside from the loss hyperparameter sweep). This is especially relevant as the weighting for the SNR term is 0.01 vs. 1.0 for SNVR, a stark difference.\n* The ResNet models used are modified ImageNet models, not CIFAR-10/100 models. Not clear why the authors did not use the ResNet models actually designed for CIFAR-10 from the ResNet paper (i.e. ResNet-20,-32,-44,-56,-110 or 1202)\n* The authors optimize the hyper parameters for their method (SNVR), while using default hyper parameters optimized in a different data/model setting for the baselines, clearly putting the baselines at a disadvantage.\n* Having four different loss terms can be problematic for hyper parameter optimization, although I believe one of these (WD) is just standard weight decay unless I'm misunderstanding it.\n\nMinor feedback:\n* When discussing \"groups\" in the context of filter groups in ConvNeXt models, perhaps use the term \"filter groups\" instead as it will not be obvious to most people what this means/that it's not the more general usage of the term.\n* Might be better to explicitly define or use $\\mathbf{v}$ in equation 2 before it's used, unless I've missed the definition. It becomes more clear in context later though."}, "questions": {"value": "* Why is the SNR term required? Are there any ablation results demonstrating the relative impact of having the SNR term or not is (and for that matter the SNVR term).\n* Why are results on deeper models not evaluated? Are there computational constraints in the methodology not explained in the paper/that I missed that makes these infeasible to run?\n* Would the results be better in models not using skip connections or normalization (i.e. batch norm) as all the models used do use both I believe?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "f4N43VRVe6", "forum": "xhS4ouGBJt", "replyto": "xhS4ouGBJt", "signatures": ["ICLR.cc/2026/Conference/Submission7301/Reviewer_nxpH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7301/Reviewer_nxpH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7301/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761948660772, "cdate": 1761948660772, "tmdate": 1762919418426, "mdate": 1762919418426, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Spectral Norm Variance Regularisation (SNVR), a method that introduces a regularisation term which penalises the variance of spectral norms among hidden layers that are of the same type. The method aims to encourage the spectral norms of all similar layers to maintain a consistent magnitude throughout the training process, thereby promoting more balanced learning dynamics across layers."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Intuitive Idea: The core idea of using variance as a metric for balance is highly intuitive.   \n2. Low Computational Cost: The implementation complexity is low, as the spectral norms can be approximated efficiently using the power iteration method. \n3. Broad Applicability: The method does not rely on strong assumptions about the network architecture or the learning objective, suggesting it could be applied widely."}, "weaknesses": {"value": "1. Justification of the Core Assumption: The central hypothesis, that all layers of the same type should have similar spectral norms, is not sufficiently explored or justified. The paper relies more on empirical validation than on a discussion of the theoretical grounding or potential limitations of this assumption.   \n2. Generalisability of SNVR: The paper's experiments are confined to a limited scope, focusing on small to medium-scale vision datasets like CIFAR-10/100 and STL-10. The models used, such as ResNet-18/34 and Conv2NeXt-T, are also relatively small convolutional networks. A key limitation is the absence of validation on more demanding benchmarks. The effectiveness of SNVR has not been tested on: Large-scale datasets, such as ImageNet-1k or Non-convolutional architectures, such as Vision Transformers (ViTs) or Large Language Models (LLMs). This narrow experimental setup makes it difficult to assess the scalability and general applicability of SNVR.   \n3. Missing Setting: In the paper, SNVR is always used in combination with SNR. This leaves a significant gap, as there is no study to demonstrate the standalone effect of SNVR. If SNVR must be used with SNR, the paper lacks a deep explanation for why this dependency exists.  \n4. Grouping Strategy: The strategy for grouping layers is fixed by layer type. This choice is not deeply justified over other potential strategies, and the paper does not explore the method's sensitivity to how layers are grouped."}, "questions": {"value": "1. Could you provide a more in depth theoretical argument as to why the spectral norms of all layers of the same type should be uniform? Are there any architectures or tasks where the optimal state might involve a systematic variation in spectral norms? In such cases, could forcing uniformity via SNVR potentially restrict the model's performance?  \n2. Do you have any empirical results to suggest that SNVR is applicable and effective for large scale datasets, models and other architectures, such as Transformers?  \n3. Is it essential for SNVR to be used with SNR? Could you provide ablation experiments that isolate the contribution of SNVR? If the combination is necessary, what is the theoretical or empirical reasoning for this?    \n4. How sensitive is the SNVR method to the choice of grouping strategy? Could this grouping be made data driven or even learnable?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "iREZtbMvtz", "forum": "xhS4ouGBJt", "replyto": "xhS4ouGBJt", "signatures": ["ICLR.cc/2026/Conference/Submission7301/Reviewer_wGMP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7301/Reviewer_wGMP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7301/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761957349045, "cdate": 1761957349045, "tmdate": 1762919417854, "mdate": 1762919417854, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Spectral Norm Variance Regularization (SNVR), which adds a regularization term penalizing the variance of spectral norms across layers of the same type to achieve more balanced layer-wise training dynamics. The authors claim that SNVR encourages uniform learning progress across layers, improves generalization, and does not increase computational cost. Experiments on several small-scale vision benchmarks (CIFAR, TinyImageNet, STL, Food-101) with ResNet and Conv2NeXt architectures are presented, along with some analyses on spectral densities, gradient norms, and information planes."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The charts are beautifully presented, the paper is formatted correctly, and the color scheme is pleasing.\n\nThe proposed regularization term is simple to implement and easily integrates with existing training pipelines.\n\nThe overall presentation is clear, and the method is computationally lightweight."}, "weaknesses": {"value": "The derivation from Eq. (6) to Eq. (7) is not rigorous. The paper does not show how the gradients of the regularization terms are propagated into the parameter updates — it simply inserts them into the update rule without mathematical justification.\n\nThe coefficients $\\lambda_{WD}$, $\\lambda_{SNR}$, and $\\lambda_{SNVR}$ appear in both the coupled and decoupled optimization settings, but their physical meaning and scaling relationship in these two contexts are never clarified.\n\nThe concept of Layer-Wise balance has been extensively explored in optimizers, OOD generalization, catastrophic forgetting, and feature design. Thus, the claimed novelty here appears limited.\n\nThe experimental networks are too simple. Using only ResNet and Conv2NeXt is far from sufficient to support the claimed general applicability.\n\nThe compared methods are quite outdated — the latest ones are from 2023. There has been a large body of research on layer-wise and training dynamics topics in the past three years, even in mainstream AI conferences, which are not discussed or compared.\n\nThe improvements in all tables are extremely small, mostly within the range of random variance.\n\nFigure 4 claims that “SNVR does not increase training time,” but the paper does not specify the time units, whether the batch size is consistent, or report variance across runs.\n\nThe ablation study is incomplete: it does not show the results of using SNVR alone, SNR alone, or their combination."}, "questions": {"value": "Please refer to Weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0JNd0lgL2j", "forum": "xhS4ouGBJt", "replyto": "xhS4ouGBJt", "signatures": ["ICLR.cc/2026/Conference/Submission7301/Reviewer_feNq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7301/Reviewer_feNq"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7301/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761985668731, "cdate": 1761985668731, "tmdate": 1762919417503, "mdate": 1762919417503, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}