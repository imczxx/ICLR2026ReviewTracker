{"id": "E68dgQUzrC", "number": 8421, "cdate": 1758082673609, "mdate": 1759897784793, "content": {"title": "Open-Set Semantic Gaussian Splatting SLAM with Expandable Representation", "abstract": "This work enables everyday devices, e.g., smartphones, to dynamically capture open-ended 3D scenes with rich, expandable semantics for immersive virtual worlds. While 3DGS and foundation models hold promise for semantic scene understanding, existing solutions suffer from unscalable semantic integration, prohibitive memory costs, and cross-view inconsistency. To respond, we propose Open-Set Semantic Gaussian Splatting SLAM, a GS-SLAM system augmented by an expandable semantic feature pool that decouples condensed scene-level semantics from individual 3D Gaussians. Each Gaussian references semantics via a lightweight indexing vector, reducing memory overhead by orders of magnitude while supporting dynamic updates. Besides, we introduce a consistency-aware optimization strategy alongside a Semantic Stability Guidance mechanism to enhance long-term, cross-view semantic consistency and resolve inconsistencies. Experiments demonstrate that our system achieves high-fidelity rendering with scalable, open-set semantics across both controlled and in-the-wild environments, supporting applications like 3D localization and scene editing. These results mark an initial yet solid step towards high-quality, expressive, and accessible 3D virtual world modeling. Our code will be publicly released.", "tldr": "", "keywords": ["3D Gaussian Splatting", "Dense Semantic SLAM", "3D Scene Representation"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1228f1b14abcdae6a09c361b7776f4a94a2385a9.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper, \"Open-Set Semantic Gaussian Splatting SLAM with Expandable Representation“, introduces a system designed to enable everyday devices like smartphones to capture and reconstruct 3D scenes with rich, open-set semantics. The core idea is to integrate an expandable semantic feature pool with a Gaussian Splatting SLAM (GS-SLAM) framework. This feature pool decouples scene-level semantics from individual 3D Gaussians, using lightweight indexing vectors to reduce memory overhead and support dynamic updates of semantics. The system also incorporates a consistency-aware optimization strategy and a Semantic Stability Guidance mechanism to improve cross-view semantic consistency."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The paper presents a compelling and timely contribution at the intersection of dense SLAM, 3D Gaussian splatting, and open-vocabulary semantic understanding. \n\nThe work demonstrates high originality through several key innovations: \n\n1. Expandable Semantic Feature Pool: Rather than embedding high-dimensional semantic features directly into each Gaussian (which is memory-prohibitive), the authors propose a shared, dynamic, and expandable semantic feature pool. Each Gaussian references semantics via a lightweight indexing vector. This design is both novel and pragmatic—it decouples scene-level semantics from per-point storage, enabling scalability and dynamic updates. \n\n2. Open-Set Semantic Integration in SLAM: While prior SLAM systems typically handle closed-set semantics (e.g., fixed object categories), this work enables open-set semantic understanding—supporting queries like “fruit in plastic bag” or “xbox”—by leveraging foundation models (e.g., CLIP) within a real-time SLAM pipeline. This bridges a critical gap between foundation model capabilities and real-world 3D reconstruction. \n\n3. Consistency-Aware Optimization: The paper introduces a dual mechanism—an Intra-Inter Semantic Consistency Objective (via contrastive learning) and Semantic Stability Guidance (via cosine-similarity-based reweighting)—to enforce cross-view and temporal semantic coherence. This addresses a fundamental limitation of naively lifting 2D foundation model outputs into 3D without considering geometric consistency."}, "weaknesses": {"value": "1. While the paper claims to reduce memory overhead \"by orders of magnitude\" (line 037) through the expandable semantic feature pool, the memory footprint analysis in Table 5 and Table 10 still shows significant memory usage, particularly as the semantic feature dimension ($D_s$) or pool size ($L$) increases. For real-time applications on \"everyday devices (e.g., smartphones)\" (line 025), the current memory requirements might still be prohibitive.\n\n2. The runtime analysis in Table 8 shows that the proposed method incurs an \"approximately 8% – 21% additional time overhead\" compared to SplaTAM and LoopSplat. While this might be acceptable for some applications, achieving truly real-time performance on mobile devices for complex scenes with continuous semantic updates remains a challenge. The paper mentions that the \"additional computational overhead stems from semantic assignment from Fp\" and the consistency objectives.\n\n3. The paper states that the system \"demonstrates limited robustness in highly dynamic or large-scale (e.g., city-level) environments\" (lines 1150-1151). This is a significant limitation for a SLAM system designed for \"in-the-wild 3D scenes\" (line 026). While the Semantic Stability Guidance mechanism is introduced to mitigate semantic ambiguity, a more thorough analysis of its effectiveness in highly ambiguous or dynamic scenarios would be beneficial.\n\n4. The system relies on pre-trained 2D foundation models like CLIP [11] or SAM [12] for semantic distillation. While this is a common approach, the performance and generalizability of the system will be inherently tied to the capabilities and biases of these underlying models. The paper mentions that the framework is not dependent on \"any specific semantic extraction method\" (line 826), but the choice of these models can still impact the quality of the semantic representations."}, "questions": {"value": "See the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "0jI8LPthrN", "forum": "E68dgQUzrC", "replyto": "E68dgQUzrC", "signatures": ["ICLR.cc/2026/Conference/Submission8421/Reviewer_fyiJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8421/Reviewer_fyiJ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8421/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761482351645, "cdate": 1761482351645, "tmdate": 1762920319488, "mdate": 1762920319488, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a Gaussian-based SLAM framework that integrates open-vocabulary semantic features derived from pretrained visual-language models. It introduces an updating mechanism for semantic features across frames, aiming to improve temporal consistency and robustness in semantic mapping. The method is evaluated on multiple RGB-D datasets, showing improvements in both geometric accuracy and semantic segmentation performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Leveraging pretrained models for enhancing scene-level semantic awareness is meaningful and practically relevant for scalable 3D mapping.\n\n- The integration of semantic information into a Gaussian-based SLAM framework is valuable and timely, addressing the growing need for open-vocabulary 3D understanding on real-time systems.\n\n- The experimental section covers multiple datasets and tasks， typically three in-the-wild scenes captured by everyday devices are interesting.\n\n- The visualization in the paper is clear and informative, effectively illustrating the semantic reconstruction results and helping understand the pipeline of the proposed method."}, "weaknesses": {"value": "- The quantitative comparison in Table 1 lacks several recent SOTA RGB-D SLAM baselines such as MonoGS, Gaussian-SLAM, RTG-SLAM, and SplatSLAM. It is highly recommended to include these baselines to ensure a fair, comprehensive, and up-to-date evaluation of the proposed module's performance.\n\n- The organization of the paper needs substantial improvement. Essential information about how semantic features are extracted, processed, and integrated into the pipeline is relegated to Appendix A.1, while the main body spends excessive space on general preliminaries and related work (Eq. 1–5, 10–11). As a result, readers struggle to understand the core contribution without repeatedly consulting the supplementary material. The authors should move the key descriptions of the semantic feature pipeline, backbone choice, 2D-to-3D mapping, update rules, and training losses into the main Method section, and condense redundant preliminary equations.\n\n- The use of pretrained semantic features from CLIP and DINOv2 is no longer novel, as several recent works, such as SemGauss-SLAM and OVO-SLAM, have already demonstrated open-vocabulary mapping with similar embeddings. The only distinctive component here is the recurrent update mechanism applied to explicit per-map semantic features. However, the motivation for updating explicit feature representations across frames is not clearly justified. Updating/Memorization is intuitive for latent representations that capture temporal dependencies, but less so for fixed explicit map representations, as per pixel level, their cross-frame correspondence is not recurrently updated but shifted from adjacent pixels in a continuous trajectory."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XcaoJObGd7", "forum": "E68dgQUzrC", "replyto": "E68dgQUzrC", "signatures": ["ICLR.cc/2026/Conference/Submission8421/Reviewer_r2wC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8421/Reviewer_r2wC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8421/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761884490282, "cdate": 1761884490282, "tmdate": 1762920318965, "mdate": 1762920318965, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an open-set semantic SLAM system based on 3D Gaussian Splatting. The key innovation is the introduction of an expandable semantic feature pool, which decouples high-level semantics from individual Gaussians. This design significantly reduces memory usage and allows for dynamic integration of new semantic concepts during SLAM operation. To address the inconsistency issue from 2D foundation models, the authors also propose a consistency-aware optimization strategy and a semantic stability guidance mechanism. Extensive experiments on both synthetic and real-world datasets demonstrate the system's advantages in rendering quality, tracking accuracy, and open-set semantic understanding tasks, such as 3D localization and scene editing."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The core idea of a learnable and expandable semantic feature pool is novel and clever. It effectively separates the scene-level semantics from the geometric representation, enabling efficient and scalable open-set learning.  \n\nThe paper is structured logically, and the framework is explained step by step, making it understandable.   \n\nThis work pushes the boundary of semantic SLAM from closed-set to open-set, which is a crucial step towards general-purpose 3D scene understanding. The ability to run on commodity hardware and support applications like 3D editing greatly enhances its practical value."}, "weaknesses": {"value": "While the comparison with existing SLAM methods is comprehensive, I feel the comparison with state-of-the-art open-set 3D understanding methods (e.g., OpenMask3D, OpenScene) in terms of pure semantic segmentation accuracy is somewhat lacking.   \n\nThe runtime analysis in the supplement shows a non-negligible overhead. Although the authors attribute this to the baseline, a more in-depth discussion on how to optimize the efficiency of the semantic module itself would be helpful for practical deployment.  \n\nThe threshold parameters for the pool expansion (e.g., the similarity thresholds in Algorithm 1) seem crucial but their selection process is not deeply analyzed."}, "questions": {"value": "1. The expansion factor n and the threshold for determining \"empty slots\" seem to be empirical. Could you discuss the sensitivity of the model's performance to these hyperparameters? Is there a risk of the pool expanding too aggressively in very large-scale scenes?\n﻿\n2. In the semantic stability guidance, how is the \"object that appears for the first time\" specifically identified? Is this based purely on the lack of correspondence in previous frames?\n﻿\n3. The paper demonstrates excellent results on in-the-wild data. Could you comment on the system's performance in highly dynamic environments where objects move frequently? Does the semantic pool and consistency mechanism handle such cases robustly?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LQXMz3wumJ", "forum": "E68dgQUzrC", "replyto": "E68dgQUzrC", "signatures": ["ICLR.cc/2026/Conference/Submission8421/Reviewer_zwtS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8421/Reviewer_zwtS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8421/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761899202973, "cdate": 1761899202973, "tmdate": 1762920318493, "mdate": 1762920318493, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces an open-set semantic 3D Gaussian Splatting (3DGS) framework designed to enhance scene reconstruction and semantic segmentation under open-set and real-time conditions. The proposed method integrates semantic understanding into the Gaussian Splatting pipeline by associating per-Gaussian semantic embeddings and enabling online label adaptation. The system claims to handle unknown categories and domain shifts, and to improve both reconstruction quality and scene-level segmentation.\n\nExperiments are conducted mainly on the Replica dataset, showing improved reconstruction quality and semantic accuracy compared to several baseline methods. The results demonstrate promising performance in synthetic indoor environments, suggesting potential for robust open-world mapping."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Good presentation and writing quality.\nThe paper is clearly structured, logically consistent, and easy to follow. Figures are visually clean and the methodology is well explained.\n\n2. Strong results on benchmark datasets.\nThe proposed approach achieves good reconstruction and segmentation results on Replica and other small-scale datasets, showing the method’s effectiveness in controlled settings.\n\n3. Direct and effective idea.\nThe proposed framework is conceptually straightforward yet functional. It extends 3D Gaussian Splatting toward semantic understanding and contributes a practical perspective to open-set semantic reconstruction."}, "weaknesses": {"value": "1. Overreliance on synthetic data.\nUsing Replica as the main evaluation dataset is limiting. Since Replica is synthetic and lacks real-world sensor noise, it is less meaningful for evaluating SLAM or localization robustness. The paper would be stronger with experiments on real-world semantic datasets such as ScanNet++, SemanticKITTI.\n\n2. Missing comparisons with recent baselines.\nSeveral recent 3DGS-based SLAM and semantic mapping methods (e.g., MonoGS, S3PO-GS, SEGS-SLAM) are not included in comparisons. Without these baselines, it is difficult to gauge the real advancement of the proposed approach relative to the current state of the art.\n\n3. Limited improvement from semantics to pose estimation.\nWhile the paper introduces semantic components, the pose estimation accuracy remains very close to previous methods, suggesting that semantics may not significantly contribute to the geometric optimization process."}, "questions": {"value": "The questions are the same as weakness. This paper presents a solid and well-written approach that meaningfully extends semantic understanding into 3D Gaussian Splatting. However, the experimental evaluation is too narrow and overly dependent on synthetic data, which weakens claims of real-world robustness and open-set generalization. Including stronger baselines and more diverse datasets would substantially improve the paper’s credibility.\nTypos:\n1. In Figure 2, the label “Ground Truth RGB Frame” appears misplaced — please verify and correct this annotation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics review needed."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HOSk5KuQas", "forum": "E68dgQUzrC", "replyto": "E68dgQUzrC", "signatures": ["ICLR.cc/2026/Conference/Submission8421/Reviewer_21bL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8421/Reviewer_21bL"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8421/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761901818674, "cdate": 1761901818674, "tmdate": 1762920318137, "mdate": 1762920318137, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}