{"id": "3AnplD4Q54", "number": 18090, "cdate": 1758283722016, "mdate": 1759897134066, "content": {"title": "Efficient Conformal Prediction via Conformalized Meta-Learning from Noisy Labels", "abstract": "As a distribution-free uncertainty quantification method for machine learning models, conformal prediction constructs prediction sets with statistical coverage guarantees. However, in real deep-learning systems, the deep learners could be affected by training label noise, which leads to inefficiently large prediction sets. In this work, focusing on the classification task, we study and address such a robust learning issue within conformal prediction. We first empirically and theoretically analyze this problem. Then, to alleviate this issue, we propose an efficiency-aware conformalized meta-learning-based method, which directly minimizes the empirical size of prediction sets on meta data, aiming at rectifying the training loss. Experiments on datasets with both synthetic and real-world noise demonstrate that the proposed method can effectively enhance the efficiency of the prediction sets against training label noise.", "tldr": "We analyze the impact of training label noise on the efficiency of the prediction sets and propose a new method to address it based on meta-learning.", "keywords": ["conformal prediction", "training label noise", "meta-learning"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5521c5d70a3598ff23965e2e80312d3484b09de1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The submission studies the impact of a model pre-trained with noisy labels on the performance of split CP. This is done by introducing some theoretical analysis of the average set size, as well as by proposing a meta-learning strategy in which clean-label data is used to enhance the efficiency of CP."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Understanding how the quality of a predictor affects the efficiency of CP is a valuable goal, and noisy labels offer a valid setting to model inaccuracies in the pre-trained predictor. \n\nThe submission builds on existing art to attempt an analysis of the role of noisy labels. Furthermore, the proposed meta-learning approach is sensible and it appears to be effective in practice."}, "weaknesses": {"value": "The analysis builds directly on prior art, and it does not appear to add new substantial insights about the role of noisy labels. In particular, the only new result, Proposition 4.2 is formulated under strong, and not clearly expressed, assumptions, and it only provides an approximated result, namely (4). It is not clear what the approximate inequality (4) means in mathematical terms, and it is not clear what type of insights can be obtained from (4).\n\nThe proposed meta-learning strategy is quite straightforward. Furthermore, as also mentioned by the authors, there are many other approaches that could be attempted to operate on noisy-label data when reference clean-label data is present.\n\nThe experimental results are limited in scope, considering very few reference strategies."}, "questions": {"value": "1) What is the significance of the assumptions underlying Proposition 4.2?\n\n2) What does the approximation (4) mean at a mathematical level?\n\n3) What type of insights can be obtained from (4)?\n\n4) Which other methods could be considered that leverage clean-label data in addition to noisy-label data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "uc3Plgm9K0", "forum": "3AnplD4Q54", "replyto": "3AnplD4Q54", "signatures": ["ICLR.cc/2026/Conference/Submission18090/Reviewer_pU7Y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18090/Reviewer_pU7Y"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18090/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760519682031, "cdate": 1760519682031, "tmdate": 1762927865617, "mdate": 1762927865617, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a method that combines meta-learning with conformal training to enhance the efficiency of conformal classifiers trained on data with label noise. The approach jointly optimizes a classifier and a weight function in a bi-level optimization framework: the classifier minimizes cross-entropy loss, while the weight function minimizes prediction set size using a relaxed, differentiable conformal prediction procedure applied to a clean subset of samples. The proposed method demonstrates positive empirical results and is supported by theoretical analysis."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed method is conceptually simple yet empirically effective, as demonstrated by the reported results. This balance of simplicity and performance suggests that the approach could serve as a practical and valuable addition to the literature on conformal training, particularly in scenarios involving label noise.\n- The paper is generally well-structured and easy to follow, even though it includes some uncommon terminology such as “deep learners” and minor typographical errors (e.g., “uncertainty qualification” instead of “uncertainty quantification”).\n- The empirical evaluation is extensive and well documented in the appendix."}, "weaknesses": {"value": "The primary weakness of the paper is that its contributions do not appear to offer substantial novelty or impact. The proposed approach combines existing techniques, namely meta-learning and conformal training, to improve conformal prediction under label noise. While the empirical results are encouraging, it remains unclear whether this combination represents a meaningful advancement beyond prior work.\n\nFor example, in Section 4, the empirical observation is not particularly surprising. It is well established that optimal (most efficient) prediction sets are obtained under the true distribution $P(Y|X)$ [1], and introducing label noise during training naturally pushes the model away from this distribution, resulting in larger prediction sets. Furthermore, the theoretical component does not clearly differentiate itself from previous results by Dhillon et al. (2024) and Zecchin et al. (2024). I recommend that the authors clarify these distinctions in the main text.\n\nRegarding the meta-learning aspect, the contribution seems limited to leveraging a set of clean samples (without label noise) to learn a weight-function like proposed by Shu et al. (2019) by minimizing a relaxed conformal training loss like in Stutz et al. (2022). This appears to be a minor extension, and I invite the authors to clarify whether there is a deeper contribution that I may have overlooked. On the theoretical side, again, it is not evident how the main result advances beyond prior work.\n\nThere are a few minor presentation issues worth noting. In Theorem 4.1, it would improve readability to state the assumptions directly within the theorem rather than referring readers to the appendix. In Section 5, the parameters $\\mathbf{w}$ and $\\Theta$ should be introduced more clearly; I had to consult Shu et al. (2019) to fully understand their meaning.\n\n### References\n\n[1] Vovk, Vladimir, et al. \"Criteria of efficiency for conformal prediction.\" Symposium on conformal and probabilistic prediction with applications. Cham: Springer International Publishing, 2016."}, "questions": {"value": "Would it be possible to disentangle the effect of meta learning vs the conformal loss? From the experiments in Tables 1 and 2, it seems the conformal loss only marginally improves the results (making it worse in some cases), while meta learning is doing most of the heavy lifting. Meta learning improves coverage even in the absence of noise, which is interesting. Any intuition on why that could be? For instance, for CIFAR-100 with no label noise, meta learning improves coverage without improving accuracy, which suggests it improves the model calibration somehow."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8C8oHjgojA", "forum": "3AnplD4Q54", "replyto": "3AnplD4Q54", "signatures": ["ICLR.cc/2026/Conference/Submission18090/Reviewer_xkzW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18090/Reviewer_xkzW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18090/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761777761773, "cdate": 1761777761773, "tmdate": 1762927864983, "mdate": 1762927864983, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the impact of label noise in training data on the efficiency (i.e., size) of prediction sets in conformal prediction for classification tasks. It provides empirical evidence and theoretical analysis demonstrating that noisy training labels lead to larger prediction sets while maintaining coverage guarantees, assuming a clean calibration set. To mitigate this, the authors propose Conf-MWN, an efficiency-aware meta-learning method that uses a small clean meta dataset to directly minimize the empirical prediction set size via sample re-weighting during classifier training. Experiments on synthetic and real noisy datasets show improved efficiency without sacrificing coverage."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper deals with a practical problem: the degradation of conformal prediction efficiency due to training label noise, distinct from prior focus on calibration noise. Theoretical analysis seems solid."}, "weaknesses": {"value": "The novelty of the proposed method is somewhat limited as it is based of a combination of existing approaches for meta-learning and conformal training. \nIn addition, Propositions 4.1,4.2 rely on 0-1 score which is a bit non standard, and it is unclear how this score can be computed for the test set, where the true label is unknown."}, "questions": {"value": "1.⁠ ⁠Inefficiency improvement over CE-MVN seems marginal for real datasets. Could this be justified?\n\n2.⁠ ⁠Comparison to CE-MVN is missing in Tables 5-8. Consider adding this comparison to reassure the benefit of the proposed method.\n\n3.⁠ ⁠Minor issues:\n* ⁠Eq. (5) it seems that w is not explicitly defined.\n* Line 161 - \"can largely deviate\" should be \"deviate\""}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DXKxTQ07C4", "forum": "3AnplD4Q54", "replyto": "3AnplD4Q54", "signatures": ["ICLR.cc/2026/Conference/Submission18090/Reviewer_aXem"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18090/Reviewer_aXem"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18090/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761826519624, "cdate": 1761826519624, "tmdate": 1762927864155, "mdate": 1762927864155, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of prediction set inefficiency in conformal prediction (CP) when the base classifier is trained on noisy labels. The authors empirically show that label noise can significantly enlarge prediction sets while preserving coverage. To mitigate this, they propose an efficiency-aware Conformalized Meta-Weight-Net (Conf-MWN), which uses a small clean meta-dataset to reweight noisy training examples. The meta-objective directly minimizes the empirical prediction set size through a differentiable relaxation of the conformal quantile. Experiments show notable reductions in set size under both synthetic and real-world noise."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Addresses an underexplored yet practically relevant problem: label noise–induced inefficiency in conformal prediction.\n2. The proposed Conf-MWN method is conceptually simple, computationally feasible, and empirically effective.\n3. Experimental validation is broad and convincing, covering synthetic and real noisy datasets, multiple α-levels, and combinations with NACP.\n4. Clarity and presentation quality are high; figures and tables are easy to follow."}, "weaknesses": {"value": "1. Proofs apply only to trivial 0–1 nonconformity scores and do not support the HPS/APS-based experiments.\n2. The method operates at the training stage while the inefficiency arises in calibration; no theoretical link is established between reweighting and quantile correction.\n3. Assumption of a small clean meta-set is unrealistic for most high-noise domains; robustness to imperfect meta data is untested.\n4. Replacing the CE meta-loss in MWN with a differentiable set-size surrogate is a moderate extension, not a conceptual leap.\n5. Efficiency gains may simply result from accuracy improvements, not genuine uncertainty calibration."}, "questions": {"value": "1. How sensitive is the method to the size and quality of the meta-dataset?\n2. Can the authors provide accuracy-controlled comparisons or ablations to isolate the effect on inefficiency?\n3. What happens if the meta-dataset also contains label noise?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "McWpFph1bT", "forum": "3AnplD4Q54", "replyto": "3AnplD4Q54", "signatures": ["ICLR.cc/2026/Conference/Submission18090/Reviewer_o2TS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18090/Reviewer_o2TS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18090/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761937200985, "cdate": 1761937200985, "tmdate": 1762927863506, "mdate": 1762927863506, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}