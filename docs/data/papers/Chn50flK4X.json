{"id": "Chn50flK4X", "number": 21199, "cdate": 1758314826663, "mdate": 1759896935653, "content": {"title": "Rethinking Predictive LLM Routing: When Simple KNN Beats Complex Learned Routers", "abstract": "As large language models (LLMs) grow in scale and specialization, routing—selecting the best model for a given input—has become essential for efficient and effective deployment. While recent methods rely on increasingly complex learned routing strategies, their dependence on disparate training data and evaluation setups makes comparison and generalization difficult. In this work, we fundamentally rethink LLM routing by questioning whether such complexity is necessary. We show that a well-tuned k-Nearest Neighbors (kNN) approach not only matches but often outperforms state-of-the-art learned routers while being significantly more efficient. To support systematic evaluation, we introduce a suite of standardized routing benchmarks spanning instruction-following, question-answering, and reasoning tasks, as well as the first multi-modal routing dataset involving visual inputs. Our theoretical analysis reveals that the strong locality properties of model performance in embedding space enable simple non-parametric methods to achieve superior routing decisions with lower sample complexity than parametric approaches. These findings challenge the prevailing trend toward sophisticated architectures and demonstrate that simple, interpretable approaches can be surprisingly effective for LLM routing.", "tldr": "", "keywords": ["LLM Routing"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/09a1cf8eea342f695327cb4308918d85676c6637.pdf", "supplementary_material": "/attachment/adf43ee825c55910aeb5b0c4e987a2dcba526805.zip"}, "replies": [{"content": {"summary": {"value": "This paper challenges the assumption that complex architectures are needed for effective LLM routing. The authors show that a simple k-Nearest Neighbors approach can match or surpass more complex learned routers across text and multi-modal benchmarks while being faster and more robust to distribution shifts. They also introduce multiple standard routing benchmark datasets for evaluation, and provide a theoretical result to support the claim."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper is well written and easy to follow. All the used datasets and methods are illustrated in detail.\n2. The ablation studies look comprehensive to me. \n3. Some theoretical analysis is provided to support the analysis further.\n4. I think LLM routing is a very interesting problem with great potentials. This paper focuses on this practical issue."}, "weaknesses": {"value": "1. It looks a bit surprising that linear regression is more promising than other regression models such as MLP and attention-based methods, and I feel tha happens when we do not have enough or comprehensive training datasets and hence those more complex models fail to converge. Ideally, if we have great training datasets, I feel those training models could surpass the performance of kNN-based method. However, as authors highlight that it is very difficult to obtain a decent training data, and hence kNN might be the decent option without high-quality training data.\n\n2. It is better to have a paragraph summarizing the existing work on training state-of-the-art routers such as linear regression, MLP, attention-based NN, etc, and I can only see [Ong et al.] explicitly mentioned in Section 5.\n\n3. I am not very familiar with existing routing work and did some literature view, and I feel this paper does not compare with some existing works such as CARROT, which might weaken the empirical results. Another recent work (arxiv 2509.09782) also explores an attention-based training network and compares it with kNN, which might be quite similar in spirit. But I agree it is a very new and parallel work.\n\n4. kNN also suffers from curse of dimensionality due to the distance concentration problem (a possible reason why k=100 works better than k=10), so I feel it might be better to consider low-dimensional embedding model for kNN. Otherwise, it is widely known that kNN is not very robust in practice. \n\nSince I am not very familiar with LLM routing, I will refer to author's response and other reviewers' opinions to adjust my rating accordingly."}, "questions": {"value": "1. What will happen if we choose k between 10 and 100, or even chose a larger value of k over 100? It seems that the model performs better with larger value of k.\n\n2. How is the model's selection with different values of lambda? I think the author can try to plot the model performance under various values of lambda, which might give readers some insights on the selection of lambda in practice."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HlJMX4RWDH", "forum": "Chn50flK4X", "replyto": "Chn50flK4X", "signatures": ["ICLR.cc/2026/Conference/Submission21199/Reviewer_ESEH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21199/Reviewer_ESEH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21199/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760596407736, "cdate": 1760596407736, "tmdate": 1762941608486, "mdate": 1762941608486, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "LLM routing aims to learn a model (router) to select an appropriate LLM to use for each given input query. This problem has received attention in recent years. The present paper puts forward a thesis stating that using a well-tuned kNN model as the router can perform well. The paper supports this claim empirically on public benchmarks and theoretically (Theorem 1). The paper further introduces a new benchmark dataset for evaluating routing models. Notably, this is claimed to be the first multi-modal (vision and text) routing dataset."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "The paper is clearly written and easy to read. kNN as a routing model was proposed in past works. The significance of this work is from 1) showing that kNN can perform well as a routing model, as an alternative to recently developed techniques which tend to be overly complicated; 2) introduction of a new dataset. These contributions are not without limitations though (detailed in Weaknesses). In the literature on model routing, there are not many analysis papers that seek to understand an existing technique (kNN) like this paper does. This research direction is valuable."}, "weaknesses": {"value": "While kNN is demonstrated to perform well empirically on a number of datasets, as someone familiar with the literature on model routing, I do not find this surprising. This observation can be found in [A], [B], [C] and possibly other existing works. Still, it is useful to analyze why kNN performs well, and publish the findings to a wider audience. *I find this analysis insufficient in the present work.* The presented results largely focus on empirical evidence that kNN performs well, and barely touch upon the *reason* for why it works well. I acknowledge the theoretical analysis in Theorem 1, which I find useful as a starting point. However, *actionable insights* that one can gain from the theorem are not sufficiently articulated. I also acknowledge the contribution of a new multi-modal routing benchmark dataset. However, more discussion is needed to explain why it is a good benchmark dataset, and why it differs from existing datasets.\n\n[A] CARROT: A Cost Aware Rate Optimal Router. https://arxiv.org/abs/2502.03261\n\n[B] Universal Model Routing for Efficient LLM Inference. https://arxiv.org/abs/2502.08773\n\n[C] Large Language Model Routing with Benchmark Datasets. Shnitzer et al., 2023."}, "questions": {"value": "**Comments and suggestions:**\n\nC1: Missing relevant citations [A] and [B] (see Weaknesses). [A] also proposes a new dataset. It is unclear how the proposed dataset differs from that in [A] (beyond the fact that [A] does not propose a multi-modal dataset).\n\nC2: I do not think all existing routing works rely on Eq 1. As far as I know, in the context of LLM routing,  RouterBench (Hu et al., 2024) proposed it (minor difference in parameterization), and Jitkrittum et al., 2025 ([B] in Weaknesses section) provided a theoretical justification for it. More justification and citations should be added.\n\nC3: Just a suggestion. In Sec 4.3, the discussion on the AUC may be hard to grasp for non-specialist readers. One needs to understand the cost-quality trade-off curve first. The paper does not present such a curve at all except in the appendix. [This is not a question. I am familiar with it.]\n\nC4: L239, sec 4.3. Remind the reader that “selection-based” refers to models that directly predict LLM indices.\n\n**Questions:**\n\nQ1: Why is the proposed new dataset a good benchmark dataset for LLM routing? What characteristics does the dataset have? For instance, is it good for testing distribution shifts? Does it contain realistic queries? What is the difference to the dataset proposed in CARROT [A]? Without these clarifications, the significance of the new dataset is unclear. The paper does mention that this is the first vision-language routing benchmark. From Sec B.2, I think the dataset lacks diversity in terms of model families. There are only two model families (GPT, and Claude). \n\nQ2: How does one translate Theorem 1 to practice? This result appears to say that if the closeness in the query embedding space implies similar utility (i.e., the $\\\\delta$-locality property), then kNN is good. In practice, how does one know which query embedding model has $\\\\delta$-locality property? \n\nQ3: Related:  kNN clearly depends on the query embedding model.  Has there been an empirical investigation across several embedding models? I think it is better to investigate more beyond BERT and SFR. Performance is expected to vary, depending on the embedding model. Can Theorem 1 explain this? This will help strengthen the paper.\n\nQ4: I do not think the paper made it clear how $k$ should be selected. The abstract states “well-tuned k-Nearest Neighbors (kNN) approach not only matches but often outperforms state-of-the-art learned routers”. How does one tune $k$?\n\nQ5: In Sec 4.2, \"Selection-Based Evaluation\", it is stated that\n\n> We evaluate these routers at three distinct cost-performance preferences: low-cost (λ = 1.0/cmax ), balanced (λ = 0.5/cmax ), and high-performance (λ = 0.1/cmax )\n\nHow did you come up with these three operating points? For the same $\\lambda$, I understand that different routing models will yield different average quality and average cost. Please correct me if I am wrong. If so, for say $\\\\lambda=1.0/\\\\mathrm{c_max}$, router 1 may excessively call large and accurate models, whereas router 2 may end up sending all queries to small models. Router 1 would yield a routing system that is accurate and expensive, and router 2 would yield one that is less accurate but cheap. How do you then compare these two systems in a fair manner?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PZ1Uj0FOJ1", "forum": "Chn50flK4X", "replyto": "Chn50flK4X", "signatures": ["ICLR.cc/2026/Conference/Submission21199/Reviewer_DY2s"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21199/Reviewer_DY2s"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21199/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761617069590, "cdate": 1761617069590, "tmdate": 1762941607915, "mdate": 1762941607915, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper challenges the current dominant trend of building complicated LLM routers. Through building a standardized suite of routing benchmark and re-implementing a spectrum of routing approaches, the authors find that a well-tuned KNN router often matches or outperforms more complex route, is significantly faster on RouterBench, and more robust under distribution shift.\n\nMoreover, the authors provide a theoretical understanding of why KNN router perform well: as embedding distance between queries grows, the agreement of model rankings decays sharply, and this condition allow non-parametric methods like KNN to shine."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Solid comparison established on diverse benchmarks: many existing routing work perform benchmarking on different sources, the authors create a suite of benchmarks that is comprehensive for unified evaluation. Moreover with same embedding being used, the comparison becomes clean, attributing gains to the routing method and controlling the quality of representation.\n\n2. Multiple angles of attack: Besides measuring accuracies, the authors also take routing time into consideration. Moreover, a theoretical analysis shows why KNN-style method works well."}, "weaknesses": {"value": "1. Scalability: Work like Zhuang et al. (2024) suggests that matrix factorization methods seems to scale better under a large pool of candidate model and queries. KNN is training-free but it suffers from maintaining inference time support set. Is there a cost comparison that we can see that takes the index building result into account (memory and latency wise)?\n\n2. Reliance on quality of embedding/representation: It is nice that a fixed embedding model is used for apple-to-apple comparison, however there are also methods like Zhang et al. (2025) that achieve better routing through constructing better representation of the question/model quality. In this regime it is hard for KNN to be used for comparison.\n\nReferences:\n[1] Zhuang, Richard, et al. “EmbedLLM: Learning Compact Representations of Large Language Models.” arXiv, 2024, arxiv.org/abs/2410.02223.\n[2] Zhang, Haozhen, et al. “Router-R1: Teaching LLMs Multi-Round Routing and Aggregation via Reinforcement Learning.” arXiv, 2025, arxiv.org/abs/2506.09033."}, "questions": {"value": "1. Following on the theoretical analysis, I wonder if there is any diagnostic that one can run on their data to say something like \"KNN is safe here?\"\n2. For routing settings where the cost is flat (e.g. all self-hosted), do we still see KNN dominate?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "llW0lTa4Lp", "forum": "Chn50flK4X", "replyto": "Chn50flK4X", "signatures": ["ICLR.cc/2026/Conference/Submission21199/Reviewer_oidj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21199/Reviewer_oidj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21199/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761862120817, "cdate": 1761862120817, "tmdate": 1762941607072, "mdate": 1762941607072, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper contributes two benchmarks and validate the effectiveness of non-parametric KNN rather than complex networks in LLM routing."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. useful to community: introduce language and multimodal benchmark\n2. findings are significant: efficient and simple kNN works very well"}, "weaknesses": {"value": "1. no explicit comparison between support set and no support set methods. Need a pre-defined support set can be a problem of KNN. And whether it is dense enough for real-world various queries maybe a bottleneck."}, "questions": {"value": "1. Can you provide the dense version of Figure 1? That is, replace distance bin with continuous distance value and scatter many points and then compute r2."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lzBMbf2S00", "forum": "Chn50flK4X", "replyto": "Chn50flK4X", "signatures": ["ICLR.cc/2026/Conference/Submission21199/Reviewer_xABe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21199/Reviewer_xABe"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21199/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976962676, "cdate": 1761976962676, "tmdate": 1762941606618, "mdate": 1762941606618, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}