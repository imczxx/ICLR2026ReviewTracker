{"id": "4vfEo07rmv", "number": 16331, "cdate": 1758263270332, "mdate": 1759897247128, "content": {"title": "Enhancing LLMs for Knowledge Base Question Answering by Chain-of-Decomposition", "abstract": "Large language models (LLMs) have demonstrated remarkable success across diverse domains through in-context learning or fine-tuning. However, adapting LLMs to Knowledge Base Question Answering (KBQA) remains challenging, as KBQA necessitates multi-step reasoning over large-scale structured knowledge bases. Directly prompting LLMs with entire knowledge bases incurs prohibitive computational costs, while existing methods provide limited guidance on effectively fine-tuning LLMs for such complex reasoning tasks. In this work, we propose Chain-of-Decomposition (\\texttt{CoD}), a novel framework that decomposes KBQA into three modular steps: (1) an LLM-free retrieval module to extract query-relevant subgraphs from the knowledge base, (2) a parameter-free reformulation step that transforms retrieved contexts into structured reasoning paths, and (3) a lightweight LLM-based reasoning module trained to evaluate the logical validity of each path. By isolating computation-heavy retrieval and rule-based reformulation from LLM reasoning, \\texttt{CoD} reduces task complexity and enables efficient fine-tuning focused solely on the final verification step. Comprehensive experiments demonstrate that Llama-2 7B, fine-tuned with the proposed \\texttt{CoD} surpasses strong baselines, including GPT-4 augmented with retrieved knowledge, achieving state-of-the-art performance on WebQSP and MetaQA benchmarks.", "tldr": "", "keywords": ["LLMs; LoRA; KBQA"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e514a53b4ca2dd589f4e1c242e39dec9af0e2b83.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper demonstrates the theoretical equivalence between two paradigms in knowledge base question answering (KBQA): directly generating the answer versus generating a logical form and then executing it. Based on this observation, the authors propose CoD, a \"Retrieve-Construct-Answer\" KBQA framework. By decomposing the KBQA task into distinct stages, CoD reduces the input burden of large-scale knowledge graphs on LLMs and improves reasoning and answering performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The motivation of the paper is clearly presented. The authors rigorously derive the mathematical formulation of both KBQA paradigms and prove that they share the same optimization objective for the first two steps. This theoretical insight provides a solid foundation for the introduction of CoD and establishes a clear correspondence between the two approaches."}, "weaknesses": {"value": "1. The overall presentation and figure design could be improved. First, Figure 1 is somewhat confusing: the answer to the question \"Which country is Elon Musk from?\" should be South Africa, corresponding to Path 4 in the figure. It is unclear why an incorrect reasoning path is shown in the framework's overview figure. Second, the captions of Tables 2 and 3 are aligned to the left side of the table content, which appears awkward.\n\n2. Although CoD involves fine-tuning a language model, the paper does not disclose details of the training process.\n\n3. The paper lacks further analysis of the experimental results. For instance, identifying bottlenecks of CoD through ablation or diagnostic studies (though this may require additional experimental conditions) would provide valuable insights.\n\n4. There are a number of typographical and grammatical issues throughout the paper:\n\n    (1) In Figure 1, the prompt contains \"it no,\" which should be corrected to \"if no,\" and the quote marks around \"return no\" are incorrect.\n\n    (2) The acronyms ToG and RoG are inconsistently capitalized as TOG and ROG in several instances.\n\n    (3) In Appendix E, line 5, \"STOA\" should be \"SOTA\".\n\n    (4) The phrase \"reason paths\" appears multiple times and should be corrected to \"reasoning paths\"."}, "questions": {"value": "1. The appendix mentions that CoD is a generalization of RoG, yet the experimental results do not reflect a substantial performance difference to support this claim. Furthermore, in Table 1, the RoG row under the same backbone LLM (LLaMA-2-7B) shows consistently lower numbers compared to those reported in the original RoG paper. Have the authors analyzed the reasons for this discrepancy?\n\n2. The model is fine-tuned using WebQuestionsSP and ComplexWebQuestions datasets. How well does this generalize to other benchmarks? Specifically, how does CoD—and particularly its comparison to RoG—perform on GrailQA, GraphQ, or other datasets (e.g., those used in KBQA-o1)?\n\n3. The experiments provided may not fully demonstrate the advantages of CoD:\n\n    (1) In Appendix D, the results indicate a clear performance gain when using LLaMA-3 8B over LLaMA-2 7B on CWQ. Would newer open-source models such as LLaMA-4 17B, Qwen3 8B, or Qwen3-30A3B offer further improvements, especially given their resolution of known issues in earlier models?\n\n    (2) One widely adopted and competitive solution for KBQA is GraphRAG. Could the authors articulate CoD's advantages over GraphRAG-style systems (e.g., HippoRAG)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Tta3xh4R4G", "forum": "4vfEo07rmv", "replyto": "4vfEo07rmv", "signatures": ["ICLR.cc/2026/Conference/Submission16331/Reviewer_viyW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16331/Reviewer_viyW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761542900643, "cdate": 1761542900643, "tmdate": 1762926466688, "mdate": 1762926466688, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a KG-RAG (called KBQA by authors) method based on reasoning paths generated through a deterministic algorithm, with answers subsequently produced by LLMs. However, the paper’s writing is quite poor and difficult to follow. For example, there is a lack of explanation of the logical form introduced in Figure 1 and Section 2.2, weak motivation in Section 3.1, and an unclear description of the graph simplification process in Section 3.4."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "-Claims improved performance on two widely used benchmark datasets."}, "weaknesses": {"value": "1. The overall writing quality needs substantial improvement. The meanings of the notations $f_\\theta$, $g_\\theta$, and $P$ are not clearly explained and are used inconsistently throughout the paper (see Questions 1–3).  \n   In particular, the extraction process—where the reduced graph is directly input into an LLM—is poorly explained and unconvincing (see Questions 6–7 below).\n \n2. The paper lacks discussion and comparison with recent representative works, such as ToG [1].\n\n  **Reference:**  \n   [1] *Think-on-Graph: Deep and Responsible Reasoning of Large Language Models with Knowledge Graphs.* ICLR 2024."}, "questions": {"value": "1. In Equation (1), is $P(A|Q,Z)$ means the ground-truth distribution?  \n   Why use a probabilistic formulation instead of the ground-truth answer directly?\n \n2. In lines 177–214, do the authors mean the decomposition of $f_\\theta$ instead of $P$?  \n \n3. In Section 3.2, the output of $f_\\theta$ is ambiguous—it seems to represent classification in Equation (9) but generation in the equation (11). This should be clarified to avoid confusion.  \n   For example, do the authors mean $g_\\theta$ in Equation (11)? Furthermore, the $f_\\theta$ defined in Section 3.2 seems not consistent with the one in Section 2.2.\n \n4. In Section 3.3, the complexity and necessity of reasoning paths are not discussed. If the extracted triples form a dense structure, the number of possible paths could grow exponentially. Conversely, when the extracted triples are few or sparse, path construction might be unnecessary—one could simply input all triples into the language model.\n \n5. The benefits compared to other methods that also use paths, such as RoG and ToG, should be explained more clearly. The current comparison with RoG in Section 3.5 is confusing:  Why should we assume that “the generation of answer A to question Q is independent of the question-relevant context C”? This assumption completely contradicts the purpose of KG-RAG. The same concern applies to the second assumption in line 310.\n \n6. In Section 3.4, the process for simplifying the input graph is entirely unclear:  \n   - (1) The graph-shrinking procedure is not well defined or justified, and there is no guarantee for how well it preserves relevant-information to the query.  \n   - (2) The simplification step that merges relations into two classes is confusing, as the answer-related relation should not be known for the input data.\n \n7. Since the extraction process in Section 3.4 directly feeds the graph into an LLM, why not train the LLM to generate the answer directly instead of producing intermediate outputs?\n \n8. In Table 1, the last column suggests that the F1 score of **HGNet** should be the highest. Can you clarify this inconsistency?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "LnBcYyIROi", "forum": "4vfEo07rmv", "replyto": "4vfEo07rmv", "signatures": ["ICLR.cc/2026/Conference/Submission16331/Reviewer_HJHf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16331/Reviewer_HJHf"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761729664224, "cdate": 1761729664224, "tmdate": 1762926466185, "mdate": 1762926466185, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Chain-of-Decomposition (CoD), a framework for Knowledge Base Question Answering (KBQA) that decomposes KBQA into three modular steps: 1) Retrieval: an LLM-free module (using T5) that extracts relevant subgraphs from a knowledge base; 2) Reformulation: a rule-based transformation that converts subgraphs into reasoning paths; and 3) Reasoning: a lightweight LLM-based verifier that determines whether a reasoning path is logically valid. The authors proposes a causal graph (Figure 2) that formalizes the generative process of answers, allowing the authors to express the conditional probability $P(A | Q,G)$ as a sum over retrieval, reformulation, and reasoning components. Empiricially, CoD outperforms GPT-4 and prior fine-tuning frameworks such as ROG, FiDeLis, and DeCAF on two benchmarks: WebQSPand ComplexWebQuestions, achieving new SOTA performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "[S1] Simple-but-effective decomposition of the workflow. I think there is a lot of value in finding simple yet competitive approaches as proposed herein as regularizers for future methodologies. The idea of isolating retrieval and rule-based steps from reasoning reduces computational burden and is shown through emprical evidences to be effective. The graph formulation and factorization (Fig 2, Eq. 5, 7) also sets a clear stage for understanding the problem map out. \n\n[S2] Potential efficiency benefits: Two of three stages are LLM-free, and the actual reasoning component is relatively small. This will reduce training as well as inferencing cost, potentially beneficial in real-world scenarios. \n\n[S3] Strong empirical results: The method is shown to induce significant improvements over finetuned baselines as well as GPT-4 + KG on two benchmarks."}, "weaknesses": {"value": "[W1] Evaluation scope: Only WebQSP and CWQ are used; inclusion of more diverse KBQA datasets (e.g., GrailQA/GrailQA++, GraphQ) would strengthen generalizability. One related comment is: the authors mentioned MetaQA in their Abstract, yet MetaQA results are not reported in the main content. While this might be a typo, I was curious what would happen if the proposed method is applied on MetaQA. \n\n[W2] The presentation can be improved. E.g., The bottom-right portion of Figure 1 is underspecified, the symbols in the logic forms appear out of context, making them a bit hard to interpret; The causal interpretation may be overstated, the method is more of a probabilistic modularization than genuine causal analysis/reasoning, and the assumption 2 (independence between Z and G) seems a bit not straightforward. I would recommend revising the presentation narrative of the logical relationship between the RVs. \n\n[W3] Language and structure: Some grammatical and stylistic issues (e.g., \"dramatically outperform\" should be \"drastically outperforms\"; \"lead to a simple binary task problem1\" the footnote seems a bit unnecessary. I would recommend a round of thorough reading to eliminate such artifacts."}, "questions": {"value": "[Q1] I had some difficulty understanding the integration of logical form and binary \"yes/no\" prediction. How does the LLM-based reasoning module integrates logical form generation and binary \"yes/no\" prediction, are both outputs produced jointly or alternately?\n\n[Q2] What are some potential challenges and risks to transfer CoD to larger LLMs and more complex KBs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gX03RyGRcR", "forum": "4vfEo07rmv", "replyto": "4vfEo07rmv", "signatures": ["ICLR.cc/2026/Conference/Submission16331/Reviewer_FkYc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16331/Reviewer_FkYc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761891202622, "cdate": 1761891202622, "tmdate": 1762926465767, "mdate": 1762926465767, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Chain-of-Decomposition (CoD), a novel framework that enhances large language models (LLMs) for Knowledge Base Question Answering (KBQA) by decomposing the reasoning process into three modular components: (1) an LLM-free retrieval module that extracts query-relevant subgraphs, (2) a parameter-free reformulation step that converts retrieved contexts into structured reasoning paths, and (3) a lightweight LLM-based reasoning module to validate logical consistency. Grounded in a causal factorization of the answer-generation process, CoD isolates computationally intensive retrieval and rule-based reasoning from LLM fine-tuning, substantially improving efficiency and interpretability. Experiments on WebQSP and ComplexWebQuestions show that Llama-2 7B + CoD achieves state-of-the-art performance, surpassing GPT-4 with retrieved knowledge and previous methods like RoG and FiDeLis."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. CoD innovatively formalizes KBQA through a causal graph–based factorization, offering a principled decomposition of retrieval, reformulation, and reasoning.\n2. By decoupling heavy retrieval from LLM reasoning, CoD reduces computational cost and enables lightweight fine-tuning focused on logical verification.\n3. CoD significantly outperforms GPT-4 + retrieval and previous SOTA frameworks (e.g., RoG, FiDeLis) on WebQSP and CWQ, showing broad robustness.\n4. The authors provide clear mathematical formulation, implementation details, and reproducibility statements, enhancing credibility and clarity."}, "weaknesses": {"value": "1. The independence assumptions in the causal graph (e.g., P(A|Q,Z) being independent of C) are difficult to satisfy in real-world knowledge graph reasoning, which may undermine the theoretical rigor of the framework.\n2. The retrieval, reformulation, and reasoning modules are trained separately without a unified loss function or gradient propagation, potentially leading to suboptimal global optimization.\n3. Although the paper emphasizes logical path validation, it lacks visualizations or path-level case analyses; the ablation studies mainly focus on hyperparameters rather than validating the effectiveness of the causal decomposition."}, "questions": {"value": "See the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "FoOQ5XgPso", "forum": "4vfEo07rmv", "replyto": "4vfEo07rmv", "signatures": ["ICLR.cc/2026/Conference/Submission16331/Reviewer_Ebcb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16331/Reviewer_Ebcb"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16331/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976901763, "cdate": 1761976901763, "tmdate": 1762926465253, "mdate": 1762926465253, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}