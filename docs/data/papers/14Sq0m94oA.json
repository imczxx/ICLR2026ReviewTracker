{"id": "14Sq0m94oA", "number": 10558, "cdate": 1758175520054, "mdate": 1763727046833, "content": {"title": "Dynamic Orthogonal Continual Fine-tuning for Mitigating Catastrophic Forgetting of LLMs", "abstract": "Catastrophic forgetting remains a critical challenge in continual learning for large language models (LLMs), where models struggle to retain performance on historical tasks when fine-tuning on new sequential data without access to past datasets. In this paper, we first reveal that the drift of functional directions during the fine-tuning process is a key reason why existing regularization-based methods fail in long-term LLM continual learning. To address this, we propose Dynamic Orthogonal Continual (DOC) fine-tuning, a novel approach that tracks the drift of these functional directions and dynamically updates them during the fine-tuning process. Furthermore, by adjusting the gradients of new task parameters to be orthogonal to the tracked historical function directions, our method mitigates interference between new and old tasks. Extensive experiments on various LLM continual learning benchmarks demonstrate that this approach outperforms prior methods, effectively reducing catastrophic forgetting and providing a robust tool for continuous LLM fine-tuning.", "tldr": "", "keywords": ["(Large) Language Models", "Continual Learning", "Catastrophic Forgetting", "Principal component analysis(PCA)", "Functional Direction"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c0ad59538f8930d1f96b80b0fa85c98185bf920d.pdf", "supplementary_material": "/attachment/b5ec3f266e101f8a4900a5e6675aad7c6803d9b5.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces Dynamic Orthogonal Continual (DOC) fine-tuning for LLM continual learning. The authors identify drift of functional directions during fine-tuning as a key reason regularization-based methods fail. They then propose tracking this drift with a modified Online Principal Component Analysis (PCA) and orthogonally cutting new gradients with respect to the tracked historical functional directions. Experiments show that the method mitigates catastrophic forgetting and outperforms prior methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper clearly identifies drift in functional directions during fine-tuning as the \nkey issue for regularization-based approaches, and proposes an intuitive method that \ntracks and updates these directions using gradients and LoRA increments, then applies \nan orthogonal cut. \n2. By using modified online PCA, the method updates principal components from the most recent \ndata without storing historical data. The authors justify adopting Candid Covariance-free \nIncremental PCA because it allows components to be added freely and has lower \ncomputational overhead, demonstrating efficient tracking with a modified online PCA.  \n3. On LLaMA-7B and LLaMA-13B and on T5-Large, the paper reports Average Accuracy, \nBackward Transfer, and Forward Transfer on standard continual learning benchmarks and \non long task chains, and includes DOC ablations to highlight the impact of tracking."}, "weaknesses": {"value": "1. The rationale for choosing online PCA is largely descriptive, and there is no comparative study among alternative online PCA methods. Although the paper lists approaches such as incremental PCA and stochastic approximation methods and gives reasons for preferring CCIPCA, it does not provide head-to-head comparisons under the same continual learning setup, including tracking quality, compute, and memory.\n2. Comparisons center on EWC, LwF, and O-LoRA; other-based methods are excluded as not comparable due to additional settings, and oracle methods are only upper bounds. This narrow and dated selection suggests that more recent baselines are missing, making the coverage of related work and empirical comparisons limited.\n3. Motivation leans too heavily on Figure 2, which reports cosine similarity for a particular datapoint x, y and an average over randomly chosen datapoints with standard deviation. It stops short of generalizing the drift analysis beyond that setup."}, "questions": {"value": "1. Please include comparative experiments within the same continual learning setup that evaluate the multiple online PCA approaches described in the paper against the modified CCIPCA, reporting tracking quality, Average Accuracy, Backward Transfer, Forward Transfer, and computational costs.\n2. Beyond a single datapoint and the average over randomly chosen datapoints in Figure 2, please present drift analyses under more diverse conditions directly in the motivation.\n3. Please provide additional experiments on the tracking hyperparameters, including the amnesic factor, the tracking factor, and the residual threshold, and present residual rate and coverage trends in greater detail.\n4. In addition to the setting that freezes updates of the principal components, please evaluate how varying the tracking strength affects Average Accuracy, Backward Transfer, and Forward Transfer."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gWucWt5tBy", "forum": "14Sq0m94oA", "replyto": "14Sq0m94oA", "signatures": ["ICLR.cc/2026/Conference/Submission10558/Reviewer_3uqt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10558/Reviewer_3uqt"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10558/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761719911144, "cdate": 1761719911144, "tmdate": 1762921832884, "mdate": 1762921832884, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work addresses the continual fine-tuning of large language models (LLMs). The authors first identified the drift of functional directions as the main cause of the failure in regularization-based CL for LLMs. Based on this observation, they proposed Dynamic Orthogonal Continual (DOC) to address this issue. DOC consists of two components. First, the authors track the increment of LoRA as the effective functional direction. An online PCA is applied to dynamically update the stored functional directions in sequential learning. Second, the authors applied an orthogonal projection to avoid knowledge interference. Extensive experiments have demonstrated the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well motivated\n\nThe proposed method is derived from an observation and has successfully alleviated the issue.\n\n2. The presentation is good\n\nMany illustrative figures and texts are useful to help understand the phenomenon and the context\n\n3. The proposed method is effective"}, "weaknesses": {"value": "1. Some details of the method are not clear enough\n\n2. Presentation of Figure.1 can be improved\n\n3. Applicability to other parameter-efficient-tuning CL methods\n\nPlease see the details below in the Question section."}, "questions": {"value": "I would love to have a bit more details about the implementation details\n\n1. Is the LoRA shared across CL tasks or different LoRA adapters are used for each task?\n\nIt is not clearly stated in the paper.\n\n2. How to initialize the set of h to calculate PCA? \n\nIs the initial set of h calculated by the end of task?\n\n3. How to compute cosine similarity if the vectors do not match?\n\nAccording to line 179 and lines 251-259, it seems the coordinate vector is dependant on the principle components. It is likely the coord(h1) and coord(h5) do not have the same number of principle components. If this is the case, how to compare these two vectors to calculate the cosine similarity?\n\n4. Presentation of Figure.1 can be improved\n\nThe two sub-figures here are hard to understand.\n\n5. Applicability to other parameter-efficient-tuning CL methods\n\nI am wondering if the proposed method is compatible with CL methods based on other parameter-effecient tuning techniques, such as prompt tuning."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No concern."}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vyKYsYKCly", "forum": "14Sq0m94oA", "replyto": "14Sq0m94oA", "signatures": ["ICLR.cc/2026/Conference/Submission10558/Reviewer_rKEH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10558/Reviewer_rKEH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10558/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761951519437, "cdate": 1761951519437, "tmdate": 1762921832465, "mdate": 1762921832465, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses catastrophic forgetting in continual learning for large language models (LLMs). The authors identify the drift of functional directions during fine-tuning as a key factor behind the failure of existing regularization-based methods in long-term continual learning. To mitigate this issue, they propose Dynamic Orthogonal Continual (DOC) fine-tuning, which dynamically tracks and updates these functional directions while enforcing gradient orthogonality to reduce interference between tasks. Experiments on multiple LLM continual learning benchmarks show that the proposed method effectively alleviates forgetting and outperforms regularization-based approaches."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea is clear and intuitive. This paper considers tracking the drift of ffunctional directions that regularization-based method ignored and dynamically updates them during the fine-tuning process.\n2. This paper is well-written and easy to follow."}, "weaknesses": {"value": "1. The statement “We reveal the drift of function directions in the fine-tuning process, which explains why regularization-based approaches fail in long-term LLM continual learning” is somewhat overstated. The described phenomenon of drifting functional directions appears more as an empirical observation rather than a definitive causal explanation. From a theoretical standpoint, one fundamental reason for forgetting in neural networks is the non-convex nature of their optimization landscape. When the model is fine-tuned on new data distributions, the optimizer converges to a different local minimum, shifting the basin of attraction and consequently degrading previously learned representations. \n2. Since the paper’s core claim is that dynamically updated regularization mitigates forgetting, the experiments should explicitly probe (1) task-order sensitivity (change task orders) and (2) sequence-length robustness (Vary the number of tasks ).These ablations would substantiate that the proposed dynamic regularization is not brittle to ordering effects and remains effective over long horizons."}, "questions": {"value": "see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "aSPj5BYmV2", "forum": "14Sq0m94oA", "replyto": "14Sq0m94oA", "signatures": ["ICLR.cc/2026/Conference/Submission10558/Reviewer_K2j5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10558/Reviewer_K2j5"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10558/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968402231, "cdate": 1761968402231, "tmdate": 1762921832000, "mdate": 1762921832000, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to improve a currently existing technique (LoRA) that is used for fine tuning LLMs. The existing technique forces the updates to the weights to be low rank, the proposed method ensures that the updates for new tasks are also orthogonal to previous updates."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "I think the main idea of the paper is very natural: the weights are in a high dimensional space and the updates are low rank, so there is quite bit of space to force the updates to be orthogonal to each other."}, "weaknesses": {"value": "My main concern is that paper's presentation of main idea is unnecessarily complicated. For example, it uses online PCA even when it is not really using the principal components, from equation 13, it seems that a simple gram-schmidt process would do. In other words, maintaining any orthonormal basis for the gradient updates would suffice, it doesn't have to be principal components. \n\nThe writing could be improved. For example, I find the  introduction of LoRA in section 2.2 quite abrupt and more motivation/context there would be helpful. \nIt would be helpful in equation 4 to first introduce the gradient notation. The references need to be fixed as well, many of them are currently just urls."}, "questions": {"value": "Is PCA actually necessary here?\nIt seems to me that these techniques would also apply to general neural networks, is there a reason that the focus is on LLMs?\n\nIn equation 10, to force the sum of the two terms to be orthogonal to $\\tilde{v}^k$, you set each to be orthogonal. That would be sufficient, but not necessary, could you justify it more?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "riKtg6Jjnh", "forum": "14Sq0m94oA", "replyto": "14Sq0m94oA", "signatures": ["ICLR.cc/2026/Conference/Submission10558/Reviewer_Lsnj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10558/Reviewer_Lsnj"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10558/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984841121, "cdate": 1761984841121, "tmdate": 1762921831462, "mdate": 1762921831462, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}