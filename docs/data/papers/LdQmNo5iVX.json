{"id": "LdQmNo5iVX", "number": 17151, "cdate": 1758272805928, "mdate": 1759897193645, "content": {"title": "Agent2World: A Unified LLM-based Multi-Agent Framework for Symbolic World-Model Generation", "abstract": "Symbolic world models, which formally represent environment dynamics and constraints, are essential for model-based planning. While leveraging large language models (LLMs) to automatically generate these models from natural language has shown promise, existing approaches predominantly rely on scripted workflows that follow predetermined execution paths regardless of intermediate outcomes, often leading to inefficient computations and suboptimal solutions. In this paper, we propose Agent2World, a novel paradigm that employs autonomous tool-augmented LLM-based agents to generate symbolic world models adaptively.  We further introduce Agent2World$_{\\\\text{Multi}}$, a unified multi-agent framework with specialized agents: (i) a Deep Researcher agent performs knowledge synthesis by web searching to address specification gaps; (ii) a Model Developer implements executable world models; and (iii) a specialized Testing Team conducts evaluation-driven refinement via systematic unit testing and simulation-based validation. Agent2World demonstrates superior performance across three benchmarks spanning both Planning Domain Definition Language(PDDL) and executable code representations, achieving consistent state-of-the-art results through a single unified framework. By enabling proactive, knowledge-grounded world-model generation, this work opens new possibilities for AI systems that can reliably understand and formalize complex environments.", "tldr": "", "keywords": ["Large Languge Model; LLM-based Agents; World Model"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/54a4007ed436257ba7586eaaa14db1732b56adfc.pdf", "supplementary_material": "/attachment/007c40bc84b783d33053acab9024dfd156818961.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces a novel curated multi-agent pipeline comprising LLM agents for symbolic world model code synthesis. This complex, compulsory pipeline consists of: (1) a Deep Researcher for web search, (2) a Model Developer for code synthesis, and (3) a Unit Test Generator coupled with Simulation Evaluators. The pipeline is evaluated on the Text2World, CWMB, and ByteSized32 benchmarks. Notably, it operates as a fully test-time scaling approach, with no training involved.\nFrom a theoretical perspective, related concepts appear in ReAct [1] and have been extensively explored in multi-agent tool-use frameworks (e.g., Agent2World_multi) since 2023 [2][3][4]. Thus, the paper's primary contribution lies in adapting tool-augmented LLM agent pipelines to the domain of generating symbolic world models.\n\nReAct:\n[1] https://arxiv.org/pdf/2210.03629\nAn architecture of LLM agent w\\o mentioning world model: \n[2] https://lilianweng.github.io/posts/2023-06-23-agent/\nSimulator \n[3] https://arxiv.org/pdf/2507.23773\n[4] World coder\n[5] Language models, agent models, and world models: The law for\nmachine reasoning and planning\nand many more..."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "I think the comparison experiment is thorough, and it seems like the compulsory pipeline is stronger than the baselines."}, "weaknesses": {"value": "As I mentioned in the previous sections of the review, the paper demonstrates impressive performance of the multi-agent pipeline in PDDL code synthesis. However, the construction of such a composite pipeline is hardly novel in 2025. Indeed, the contribution cannot lie in the pipeline itself: tool-augmented pipelines were first introduced in Toolformer [1]; Lilian Weng outlined a general architecture for tool-using LLMs in her blog [2]; CAMEL open-sourced a comprehensive framework for LLM reasoning [3]; self-refinement emerged in ReAct and Reflection [4,5]; the concept of LLMs as world simulators was advanced in [6,7]; and LLM-guided reasoning with unit tests appeared in [8], and many more. Thus, none of the individual modules in Agent2World are originally proposed here. The primary contribution instead resides in the effective composition of these existing modules and their targeted application to PDDL code synthesis. \n\nThat said, my concerns lie in the following aspects:\n\n1. **Potential contamination in the deep researcher procedure**: I am worried that ground-truth answers could be retrieved from the web. And how to prevent the situation is not mentioned in the paper.\n\n2. **Token efficiency**: The Agent2World pipeline should consume significantly more tokens, yet Figure 7 shows substantial performance gains with only modest token increases in the multi-agent method. It remains unclear how tokens are computed for both methods. Given the three-stage design, the multi-agent approach should reveal far more information and thus consume far more tokens; the minimal token increase is surprising and unexplained.\n\n3. **Unclear experimental settings**: It is not specified which LLM is used in each comparison experiment or in each stage of Agent2World. Even if the code-generation LLM is held constant, could stronger LLMs in the deep researcher or unit-test modules (e.g., better at PDDL understanding) be driving the gains due to unbalanced LLM usage?\n\n4. **Limited comparison methods**: For example, in Text2World, the authors compare only with direct search, a single-agent baseline, and the original Text2World method. Many more test-time scaling techniques (e.g., MCTS, World Coder, advanced prompt engineering) should be included.\n\n5. **Beyond zero-shot inference**: Although the paper is not about learning, could training-based methods enhance WM synthesis? I ask this because some LLMs may have seen PDDL data from GitHub during pretraining, giving them an inherent advantage.\n\nAccording to the above reasons, I think a score of 4 is the maximum score I can give to this paper, considering some of the concerns would be addressed by the authors in the rebuttal sections. \n\n[1] https://arxiv.org/pdf/2302.04761\n\n[2] https://lilianweng.github.io/posts/2023-06-23-agent/\n\n[3] https://github.com/camel-ai/camel\n\n[4] https://arxiv.org/pdf/2210.03629\n\n[5] https://arxiv.org/abs/2303.11366\n\n[6] https://arxiv.org/pdf/2305.14992 \n\n[7] Language models, agent models, and world models: The law for machine reasoning and planning\n\n[8] https://arxiv.org/html/2508.00408v1"}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mUUF8nWu6j", "forum": "LdQmNo5iVX", "replyto": "LdQmNo5iVX", "signatures": ["ICLR.cc/2026/Conference/Submission17151/Reviewer_J92f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17151/Reviewer_J92f"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17151/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761654316277, "cdate": 1761654316277, "tmdate": 1762927138777, "mdate": 1762927138777, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes Agent2World, a novel paradigm that uses tool-augmented LLM agents to generate symbolic world models. It has 3 components, a Deep Researcher which uses the internet to collect information and specifications, a Model Developer which creates and implements the world model, and a Testing Team, which uses systematic unit testing and simulations to validate and refine the world model. This work evaluates this paradigm on 3 benchmarks spanning PDDL and executable code representations and achieves good performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Method is simple and easy to understand and well presented. Figures of Agent2World clearly show how the system works as well as how this method differs from prior methods. Authors conduct experiments on 3 diverse benchmarks and compare against multiple baselines to show on-par or superior performance. Ablation studies run by the author ablate each of the 3 components of Agent2World while also analyzing how the feedback affects the performance as well as how the multi-agent architecture affects it."}, "weaknesses": {"value": "The novelty of the method may be overstated. As stated in Section 4.1 Baselines, two prior work: WorldCoder and GIF-MCTS both have an LLM that creates a worlds model and another LLM which refines the world model using code and/or unit testing. In the introduction, in the second paragraph as well as in Figure 1, the authors claim that existing methods use \"scripted workflows\" which couple generation with verification and repair. However, it seems like WorldCoder and GIF-MCTS are very similar to Agent2World, except that they do not have the searcher agent to do RAG/Research on the internet, and that they are \"Adaptive Agents\" instead of \"Static Workflows\" (Table 5).\n\nLooking closer at Table 2 and Table 8, it looks like WorldCoder performs around the same as Agent2World with no deep researcher, which seems to indicate that the main contribution to performance is mostly the deep researcher compared to prior work. It is unclear whether this claim that prior work have \"Passive and rigid execution\" affects performance significantly. Furthermore, it seems like this is solely a cost saving metric: \"leading to unnecessary computations when simpler solutions exist or inadequate exploration when complex problems require adaptive strategies\" (lines 50-51) rather than for performance. \n\nIn addition, since these are public benchmarks, the fact that they allow the model to search the internet seems to be a potential point of test-set leakage. The paper only states that they have \"blocked some websites\" (lines 231-232, line 269), but it is unclear if any other websites or results may have leaked the test set."}, "questions": {"value": "Can the authors show that adding a Deep Research agent to do research online to these baselines like WorldCoder or GIF-MCTS, or just a Deep Research Agent + some \"static workflows\" performs worse than Agent2World? This would be great to show that being an \"adaptive agent\" is important for performance.\n\nWhat is the cost associated with running these experiments, in terms of token counts and also latency? One of the stated improvements of the model is efficiency, but it does not seem to be any results related to this.\n\nIt is unclear how Agent2World uses a \"unified cross-representation framework\" (line 081-082), and how this differs from prior work.\n\nI am very concerned about leakage of the test set on the internet, can the authors do some kind of analysis on the links/results that the deep research agent went to to make sure that there was no egregious leakage here?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SnzheoQ7qb", "forum": "LdQmNo5iVX", "replyto": "LdQmNo5iVX", "signatures": ["ICLR.cc/2026/Conference/Submission17151/Reviewer_m6C3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17151/Reviewer_m6C3"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17151/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761899491043, "cdate": 1761899491043, "tmdate": 1762927138293, "mdate": 1762927138293, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents agent2world, a LLM-based framework for automatically generating symbolic world models (in both PDDL and executable code forms) from natural language descriptions. To address the limitations of prior approaches, the proposed framework has three components:\n\n1. A web searcher that retrieves missing or external knowledge via web search;\n2. A model developer that generates executable world models (e.g., python code);\n3. A testing team, which generates feedback by simulation and unit tests to refine the model's outputs. \n\nEvaluation is done on three benchmarks â€” Text2World, CWMB, and ByteSized32. The proposed framework achieves good results, and ablation and error analyses further show the complementary benefits of knowledge synthesis and iterative refinement."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear modular design: The three-stage architecture (knowledge synthesis, model generation, evaluation-driven refinement) is conceptually clean and practically effective.\n2. Strong performance and comprehensive evaluation: The proposed framework demonstrated better results across three datasets. The authors also provided a deep analysis, including an ablation study, distribution of errors, case study, etc."}, "weaknesses": {"value": "1. Limited novelty in methodology: While the framework design is reasonable and overcomes previous limitations, each component, e.g., web search, sandbox testing, builds on commonly used agentic LLM paradigms. The contribution is incremental and more like engineering integration. \n2. Scalability and cost: The approach relies heavily on multiple LLM calls and web queries; runtime and token cost are not deeply analyzed, raising questions about scalability to large domains.\n3. Limited base models: The paper only experimented with one base LLM -- GPT 4.1 mini, which is one of the state-of-the-art LLMs. It's unclear whether the complicated framework can also improve less capable LLMs."}, "questions": {"value": "Figure 6 presents the error distribution of the proposed framework. What are the error distributions of baseline approaches? What kind of errors does the proposed framework reduce or increase? This fine-grained comparsion can reveal the strenghs and weaknesses of the proposed method but is missing."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Xx9OGLFrBg", "forum": "LdQmNo5iVX", "replyto": "LdQmNo5iVX", "signatures": ["ICLR.cc/2026/Conference/Submission17151/Reviewer_aueF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17151/Reviewer_aueF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17151/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761916565677, "cdate": 1761916565677, "tmdate": 1762927137948, "mdate": 1762927137948, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents AGENT2WORLD, a system that tackles the challenge of automatically creating symbolic world models (like environment rules for a planner) just from natural language. Instead of using a fixed, step-by-step script, it uses a flexible team of AI agents. This team includes a deep researcher that browses the web to find missing details, a model developer that actually writes the code for the world model in PDDL or Python, and a Testing Team that runs unit tests and simulations to find bugs. The authors show that this approach works well, setting new state-of-the-art results on three different benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- The multi-agent framework is well-designed, with clear specialization for each agent (research, development, and testing), which is validated by ablation studies showing each component's contribution.\n- Strong empirical results are demonstrated, establishing new state-of-the-art performance across three different benchmarks, which cover both PDDL and executable code representations."}, "weaknesses": {"value": "- Experiments rely exclusively on OpenAI's GPT-4.1-mini as the backbone LLM. It is unclear how dependent the framework's success is on this specific model. Have the authors tested other models to assess the generalizability of the agentic framework, or does the performance heavily rely on the capabilities of GPT-4.1?\n- The novelty seems to stem from the composition of existing techniques (ReAct-style agents, RAG via web search, iterative refinement) into a multi-agent pipeline. Is the primary contribution this specific system design, or are there fundamental algorithmic contributions beyond this integration?\n- The paper does not include a quantitative comparison against several other recent LLM-based agent or world-modeling frameworks, with the results being compared primarily to task-specific baselines or ablated versions of the system itself."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GKBXTnmNEo", "forum": "LdQmNo5iVX", "replyto": "LdQmNo5iVX", "signatures": ["ICLR.cc/2026/Conference/Submission17151/Reviewer_XwvJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17151/Reviewer_XwvJ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17151/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761946689680, "cdate": 1761946689680, "tmdate": 1762927137202, "mdate": 1762927137202, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}