{"id": "1Q85tfZaOa", "number": 23329, "cdate": 1758342228997, "mdate": 1759896820735, "content": {"title": "Practical estimation of the optimal classification error with soft labels and calibration", "abstract": "While the performance of machine learning systems has experienced significant improvement in recent years, relatively little attention has been paid to the fundamental question: to what extent can we improve our models? This paper provides a means of answering this question in the setting of binary classification, which is practical and theoretically supported. We extend a previous work that utilizes soft labels for estimating the Bayes error, the optimal error rate, in two important ways. First, we theoretically investigate the properties of the bias of the hard-label-based estimator discussed in the original work. We reveal that the decay rate of the bias is adaptive to how well the two class-conditional distributions are separated, and it can decay significantly faster than the previous result suggested as the number of hard labels per instance grows. Second, we tackle a more challenging problem setting: estimation with _corrupted_ soft labels. One might be tempted to use calibrated soft labels instead of clean ones. However, we reveal that _calibration guarantee is not enough_, that is, even perfectly calibrated soft labels can result in a substantially inaccurate estimate. Then, we show that isotonic calibration can provide a statistically consistent estimator under an assumption weaker than that of the previous work. Our method is _instance-free_, i.e., we do not assume access to any input instances. This feature allows it to be adopted in practical scenarios where the instances are not available due to privacy issues. Experiments with synthetic and real-world datasets show the validity of our methods and theory.", "tldr": "We propose a practical and theoretically grounded method for estimating the best achievable error rate in binary classification from (potentially corrupted) soft labels.", "keywords": ["Bayes error", "irreducible error", "uncertainty quantification", "soft labels", "calibration", "evaluation"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/baa716de1745a5682d4cc85d0cb1487dfaeae11e.pdf", "supplementary_material": "/attachment/ec1cd3cd16978f2e484581d6cd121d10107b608b.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes extensions to the instance-free Bayes error estimation framework based on soft labels introduced by Ishida et al. (2023). Firstly, the authors provide a deepened theoretical analysis of the bias of the hard-label-based estimator $\\widehat{Err^*}(\\widehat{\\eta}_{1:n})$ by showing that the bias decay rate is adaptive to class separation and can achieve a faster rate $O(1/m)$ than the previously established $O(1/\\sqrt{m})$. This analysis results in a substantially tighter upper bound on the bias from Corollary 2. Secondly,  the authors proposed a method for estimation from corrupted soft labels $\\tilde{\\eta}_i$. The authors demonstrate that naive calibration is insufficient and subsequently propose using isotonic calibration. They prove that this method yields a statistically consistent estimator given the critical assumption that the corruption function $f$ maintains the order of the clean soft labels (i.e., $\\tilde{\\eta}_i = f(\\eta_i)$, where $f$ is increasing). Experiments validate these methods on synthetic and real-world datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The new bounds on the hard-label-based estimator Theorem 1, Corollary 2 are substantially tighter and also address the unnatural dependency on $n$ found in the previous work. This refined analysis provides much stronger confidence in the hard-label estimator when $m$ is small, which is common in practice.\n\n2. The paper successfully reveals that the bias decay rate is adaptive and achieves the desired $O(1/m)$ rate when classes are well-separated. This offers important theoretical insight into the fundamental limits of this estimation method.\n\n3. The manuscript correctly identifies and formalizes the practical challenge of using corrupted soft labels obtained from sources like LLMs or subjective human confidence. The counterexample demonstrating the failure of even perfectly calibrated soft labels in Example 2 is insightful."}, "weaknesses": {"value": "1. The core theoretical breakthrough in Section 3 relies on the assumption that corruption is monotonic ($\\tilde{\\eta}_i = f(\\eta_i)$). This assumption seems like a major weakness. Any real-world corruption that inverts the relative uncertainty of two close points (e.g., some $\\eta_a$ and $\\eta_b$) would violate this and destroy the theoretical guarantee. This severely undermines the claim of tackling a \"more challenging problem setting\".\n\n2. Using isotonic regression (a classical, non-parametric calibration method) as the primary solution for the corrupted label problem seems incremental, especially since the consistency proof requires such a strong functional assumption.\n\n3. The empirical results (such as Fig. 4, Fig. 10) show that isotonic calibration works well. However, they also show that simple histogram binning often performs comparably, suggesting the specific choice of isotonic calibration might not be essential (or that the synthetic corruption used is too simple). \n\n4. Appendix D.2 highlights that the parametric beta calibration performs poorly, sometimes getting worse as $m$ increases when the assumption $f' \\geq c$ is violated. While this suggests isotonic calibration is robust, it seems unusual that a well-specified parametric model (where the corruption $f$ is related to the inverse beta calibration map) would perform worse than non-parametric alternatives. This demands a deeper theoretical explanation beyond merely noting the violation of Theorem 3's assumption."}, "questions": {"value": "1.  The result in Theorem 2 relies on the strict assumption of monotonic corruption $\\tilde{\\eta}_i=f(\\eta_i)$. Given that the paper addresses complex real-world corruptions like subjective annotator bias and distribution shift, can you provide a stronger justification or analysis regarding the prevalence of monotonic corruption in these settings? If the monotonicity assumption is violated e.g., if $\\tilde{\\eta}$ does not preserve the order of $\\eta$, how rapidly does the estimator degrade in performance?\n\n2.  The improved bias bounds rely on the class separation. For the binarized CIFAR-10H, the classes are noted to be very well-separated in Fig. 6, which leads to fast decay approaching $O(1/m)$. If the underlying distribution separation is minimal (i.e., $\\eta(x) \\approx 0.5$ for many instances), the bounds revert to $O(1/\\sqrt{m})$. For truly challenging, high-Bayes-error tasks where separation is weak, is the improvement offered by Theorem 1 essentially negligible, forcing practitioners back to the weak bounds? Please clarify the practical significance of this adaptive rate in high-uncertainty scenarios."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "IHpYf36Zcy", "forum": "1Q85tfZaOa", "replyto": "1Q85tfZaOa", "signatures": ["ICLR.cc/2026/Conference/Submission23329/Reviewer_A2T4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23329/Reviewer_A2T4"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23329/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761955777887, "cdate": 1761955777887, "tmdate": 1762942607659, "mdate": 1762942607659, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors study Bayes error estimation problem under soft label settings. They first provide a deepen theoretical understanding of the existing Bayes error estimator in statistical viewpoint. The second contribution is about the corrupted soft labels, and the main idea of using corrupted one is calibration that places the corrupted soft labels to clean version of soft labels. In particular, isotonic calibration is studied, and the authors provide theoretical understanding of it as well as some experimental results."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This work studies the Bayes error estimation problem that is very important in theory and practice. In theoretical view, the paper provides a better understanding of the existing estimator under soft label. In addition to the soft label case, the authors study how to estimate Bayes error using corrupted soft labels by leveraging calibration. Overall, I think this work is important for ML society, especially for classification problems, in terms of theory."}, "weaknesses": {"value": "Although I enjoyed reading the paper, I feel this work is too limited in practice. Especially, for the first part of the contribution, we could understand more about the existing estimator, this is still limited to be apply more general setting. Second, I think experiments are not enough to convince the work. The synthetic and those simple benchmark dataset is limited to show the proposed estimators performance in modern ML tasks."}, "questions": {"value": "1. Can the author provide experiment result in more larger datasets?\n2. In figure 4, why hist25 has different behavior?\n3. Could the author provide more intuitive explanation of corollary 2? I do not fully understand it as there is a parameter $E$. $E$ already provide Bayes error, but why do we need bias? In other word, how to estimate $B(E,m)$ without knowing $E$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6LPSdYBLw3", "forum": "1Q85tfZaOa", "replyto": "1Q85tfZaOa", "signatures": ["ICLR.cc/2026/Conference/Submission23329/Reviewer_THRQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23329/Reviewer_THRQ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23329/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761975007338, "cdate": 1761975007338, "tmdate": 1762942607353, "mdate": 1762942607353, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the estimation of the Bayes error. It improves the existing estimates from hard labels and proposes an approach to compute it using corrupted soft labels."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Originality:\nThe originality arises from applying isotonic regression to the problem of Bayes error estimation to remove the limitation of the need for uncorrupted soft labels.\n\nQuality:\nThe submission seems to be technically correct. It is experimentally rigorous and reproducible.\n\nClarity:\nThe submission is generally clear.\n\nSignificance:\nThe submission presents theoretical novel findings in the form of improved Bayes error estimates."}, "weaknesses": {"value": "There are not major weaknesses to note so I am leaning towards acceptance.\n\nHowever, it is important to note that the challenges in achieving the results are not glaringly obvious. The novelty may not be as significant as it appears."}, "questions": {"value": "Questions:\n\nWhat was the primary challenge involved in obtaining your results (i.e., improvements to Bayes error estimation)? Does the result naturally follow with mainly the application of isotonic regression?\n\n\nSuggestions:\n\nFocus more on the correct type of calibration (i.e., isotonic) and what is different about it for your goals.\n\n\nMinor comments:\n\nPage 5 Line 247: heading typo."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8nYIKxbH5t", "forum": "1Q85tfZaOa", "replyto": "1Q85tfZaOa", "signatures": ["ICLR.cc/2026/Conference/Submission23329/Reviewer_pGnM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23329/Reviewer_pGnM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23329/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761985542090, "cdate": 1761985542090, "tmdate": 1762942607074, "mdate": 1762942607074, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the fundamental question regarding how to measure bayes error theoretically and practically. Building directly on Ishida et al. (2023)'s instance-free soft-label estimator  \\widehat{\\text{Err}}^*(\\eta_{1:n}) = \\frac{1}{n} \\sum_{i=1}^n \\min\\{\\eta_i, 1 - \\eta_i\\}  (where   \\eta_i = P(y=1 \\mid x_i)  ), the authors make two major advances.\n\nFirst, replacing the prior loose   \\mathcal{O}(1/\\sqrt{m})   bound (with n-dependence), they derive a tighter, adaptive bound (Theorem 1) where bias decay depends on class separability:   \\mathcal{O}(1/m)   for well-separated points  and   \\mathcal{O}(1/\\sqrt{m})   near the boundary.\n\nSecond, they address the underexplored setting of corrupted soft labels   \\tilde{\\eta}_i   which is more practical. The solution: Apply isotonic calibration (Zadrozny & Elkan, 2002) to   \\tilde{\\eta}_i   using one true hard label y_i per instance, yielding   \\widehat{\\text{Err}}^*(\\hat{\\eta}^A_{1:n})  . Theorem 2 proves statistical consistency under the weak order-preservation assumption (  \\tilde{\\eta}_i = f(\\eta_i)   for increasing f), with a new sharp oracle inequality for binary isotonic regression (Proposition 2). Experiments on synthetic data and real benchmarks (CIFAR-10H, Fashion-MNIST-H) validate robustness, outperforming baselines like beta/histogram calibration.\n\nThis instance-free, privacy-preserving framework enables reliable checks on model limits, overfitting, and resource allocation in noisy-label settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Theoretical Innovation: Tighter bounds and new isotonic oracle inequality.\n\nPracticality: Instance-free, corruption-robust method for real noise case\n\nImpact: Privacy-preserving for medicine/social data; signals diminishing returns, curbing wasteful scaling."}, "weaknesses": {"value": "Ordering Assumption Sensitivity: Consistency hinges on monotonic f. More broad assumption would be better.\n\nData Diversity\n\nCalibration Benchmarks: test against other calibration method such as Plat scaling.\n\nBinary Label Scope"}, "questions": {"value": "How would the paper's results (e.g., bias decay rates or consistency bounds) differ if Tsybakov's margin assumption were applied instead of the paper's separability condition, and where in the paper would this fit?\n\nJean-Yves Audibert and Alexandre B. Tsybakov. Fast learning rates for plug-in classifiers. Ann.\nStatist., 35(2):608–633, 04 2007."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "pDUKPUnWkN", "forum": "1Q85tfZaOa", "replyto": "1Q85tfZaOa", "signatures": ["ICLR.cc/2026/Conference/Submission23329/Reviewer_yVpp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23329/Reviewer_yVpp"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23329/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762154684093, "cdate": 1762154684093, "tmdate": 1762942606715, "mdate": 1762942606715, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}