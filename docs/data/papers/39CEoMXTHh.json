{"id": "39CEoMXTHh", "number": 22200, "cdate": 1758327703139, "mdate": 1759896880776, "content": {"title": "$\\texttt{LLINBO}$: Trustworthy LLM-in-the-Loop Bayesian Optimization", "abstract": "Bayesian optimization (BO) is a sequential decision-making tool widely used for optimizing expensive black-box functions. Recently, Large Language Models (LLMs) have shown remarkable adaptability in low-data regimes, making them promising tools for black-box optimization by leveraging contextual knowledge to propose high-quality query points. However, relying solely on LLMs as optimization agents introduces risks due to their lack of explicit surrogate modeling and calibrated uncertainty, as well as their inherently opaque internal mechanisms. This structural opacity makes it difficult to characterize or control the exploration–exploitation trade-off, ultimately undermining theoretical tractability and reliability. To address this, we propose $\\texttt{LLINBO}$: LLM-in-the-Loop BO, a hybrid framework for BO that combines LLMs with statistical surrogate experts (e.g., Gaussian Processes ($\\mathcal{GP}$)). The core philosophy is to leverage contextual reasoning strengths of LLMs for early exploration, while relying on principled statistical models to guide efficient exploitation. Specifically, we introduce three mechanisms that enable this collaboration and establish their theoretical guarantees. We end the paper with a real-life proof-of-concept in the context of 3D printing.", "tldr": "", "keywords": ["Bayesian Optimization", "Large Language Models", "Collaborative Learning"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/44d6aaf0df88d849f3b949748d899c539b728477.pdf", "supplementary_material": "/attachment/5551f8c160e69c0a1eb5b1bbaf96ca6fb2862330.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents three different approaches on how to provide acquisition functions for Bayesian Optimisation with the use of an LLM together with a Gaussian process surrogate model. The motivation for this approach in the paper is the notion that the LLM will somehow contain \"contextual\" information. The first approach uses a linear combination of the LLM acquisition and the GP acquisition, the second uses a rejection criteria based on the GP surrogates acquisition function while the third uses the LLM proposal to create a constrained surrogate.\n\nThe paper ends with a set of experiments comparing the proposed method to several different baselines. The experiments are on classic BO tasks and the more interesting on a 3d printing task."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper is somewhat original given that the field of including LLMs into BO loops has not extensively been explored in academia. There is a substantial amount of work in this sector that is never published as a lot of the work is done in an industrial setting. While the authors are clearly open that this is by no means the \"finished article\" it is easy to motivate why there should be a bigger focus in this area."}, "weaknesses": {"value": "The paper is not very clearly written and its not obvious to actually decipher what the authors propose. There is a lot of intuitive arguments and while this sadly comes with the territory when working with black-box LLMs this could have been done better. The main part which is really unclear to me is how the interaction with the LLM actually works. In the paper it is referred to as \"we assume that the client can query the LLM\". In the case of saying the Ackley function, what is even contextual information, what is it that the LLM actually provides and how and what does the client query?\n\nFurthermore, in the experimental evaluation, what would have been interesting to see is how often the LLMs choices are used. Especially in the \"justify\" setting this is something that could be quantified.\n\nThe experimental setting is somewhat lacklustre, the basic BO examples are not really too interesting and as can be seen from the results a basic BO loop does well on these experiments. What is not clear from the paper is what the actual BO loop is, what is the surrogate model, what is the acquisition etc."}, "questions": {"value": "- 211 :: am I correct that you use a linear combination of the LLM and the GP proposed locations? Can you explain what motivates this?\n- Please provide information about how the LLM is actually queried what is the structure of this and how is the agent, and what is the agent that does this?\n- Clearly describe the experimental set-up for the baselines, what is the BO loop?\n- What do you mean by contextual information, can you describe what this in the example of optimising the Brain-2D or Ackley-6D? To me it is very unclear what this is making it hard to dechiper what you are proposing."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8UNS41uWHA", "forum": "39CEoMXTHh", "replyto": "39CEoMXTHh", "signatures": ["ICLR.cc/2026/Conference/Submission22200/Reviewer_m9hu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22200/Reviewer_m9hu"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22200/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761772139366, "cdate": 1761772139366, "tmdate": 1762942112054, "mdate": 1762942112054, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces LLINBO, a hybrid framework that integrates LLMs with statistical surrogate models like Gaussian Processes (GPs) to enhance trustworthiness in black-box optimization (BBO). LLMs excel in low-data regimes by leveraging contextual knowledge for early exploration, but they lack explicit surrogate modeling, calibrated uncertainty, and transparency, leading to risks in exploration-exploitation balance and theoretical reliability. LLINBO addresses this by using LLMs for initial design proposals while progressively relying on GPs for principled exploitation as data grows. Three specific mechanisms are proposed: LLINBO-Transient (transient LLM influence that fades over iterations), LLINBO-Justify (LLM justifies proposals, GP verifies feasibility), and LLINBO-Constrained (LLM proposals constrained within GP uncertainty bounds). These draw inspiration from federated learning and come with regret-based theoretical guarantees ensuring asymptotic optimality similar to standard BO. The framework is evaluated through simulations and a real-world proof-of-concept in 3D printing, demonstrating improved efficiency and robustness."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Pioneers a hybrid LLM-GP approach for BO, explicitly modeling LLM degradation over time and hedging with statistical surrogates. The three variants offer flexible integration, addressing opacity and uncertainty issues in pure LLM-assisted BO.\n2. Provides rigorous regret guarantees for each mechanism by extending classical BO results to the hybrid setting. \n3. Balances LLM's contextual strengths (e.g., few-shot learning from prompts) with GP's uncertainty quantification. The 3D printing application shows real-world potential in costly evaluation scenarios like drug discovery or hyperparameter tuning."}, "weaknesses": {"value": "1. Relies on GP surrogates; no discussion of alternatives like neural networks. LLM prompting (e.g., for justifications) may be sensitive, with no ablation studies mentioned. Theoretical guarantees assume smooth functions and high-probability bounds, potentially limiting generality.\n2. Combining LLMs and GPs could increase computational cost (e.g., LLM queries per iteration), but no analysis of scalability or comparisons to baselines in terms of runtime.\n3. Proof-of-concept in 3D printing is promising, but without full results, it's unclear how it compares to pure GP-BO or LLM-only methods across diverse benchmarks."}, "questions": {"value": "Please see the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "D8SYeJQkSx", "forum": "39CEoMXTHh", "replyto": "39CEoMXTHh", "signatures": ["ICLR.cc/2026/Conference/Submission22200/Reviewer_1aud"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22200/Reviewer_1aud"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22200/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761790850960, "cdate": 1761790850960, "tmdate": 1762942111800, "mdate": 1762942111800, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes LLINBO, a trustworthy hybrid Bayesian optimization framework that integrates LLMs with GP surrogates. LLMs are used during early exploration to propose contextually informed designs, while GPs gradually take over to ensure reliable uncertainty quantification and convergence guarantees. Theoretically, it derives regret bounds under RKHS assumptions. Empirically it validates the framework on synthetic benchmarks, hyperparameter tuning, and a 3D printing experiment, showing that LLINBO achieves strong early performance and near-zero stringing in real-world tests."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe paper clearly motivates the need for a trustworthy hybrid. LLM assisted BO lacks explicit uncertainty and its performance degrades as data accumulate, so combining LLMs with calibrated surrogates like GPs can retain early contextual benefits and ensuring rigorous exploration–exploitation tradeoffs. The work appears to be the first to explicitly integrate LLM suggestions with GP surrogates and to analyze this interaction theoretically.\n2.\tThree mechanisms to coordinate LLMs and GPs during BO, including Transient (LLM exploring and shift to GP), Justify (evaluate LLM proposal against GP), and Constrained (treat LLM’s proposal as a soft constraint).\n3.\tThe framework emphasizes trustworthy optimization. By design, LLINBO mitigates the opaque and unbounded nature of LLM suggestions, and each mechanism has a built-in safety check.\n4.\tEach of the three methods is accompanied by a theoretical analysis, with regret bounds developed."}, "weaknesses": {"value": "1. The theoretical analysis treats LLM suggestions generically (e.g., by gradually ignoring them or rejecting them if the GP’s acquisition is much higher) without modeling how good the LLM’s proposals actually are. Regret bounds rely on predetermined schedules for $p_t$, $\\psi_t$, or $S_t$ rather than any adaptive assessment of LLM quality. Consequently, the bounds mirror standard GP-based BO and do not show that LLM proposals improve asymptotic performance.\n\n2. Benchmarks involve low dimensional synthetic functions and relatively small budgets (10×dimension for BBO and 5×dimension for HPT) and the real world study tests only LLINBO Transient on one 3D printing setup. It remains unclear how the approaches scale to higher dimensional or discrete design spaces, whether the constrained method is computationally feasible when many samples are needed, and how robust the results are to different LLMs or prompts. \n\n3. LLINBO-Constrained assumes that the LLM’s suggestion $f(x_{\\mathrm{LLM},t})$ is better than the current mean maximum. If this assumption is violated, the algorithm may discard the LLM proposal entirely, and the CGP sampling procedure can be computationally expensive. The practical benefit of this mechanism relative to the simpler transient or justify variants is unclear, especially since it is not tested in the real-world experiment.\n\n4. The paper compares against a few baselines (GP-UCB, LLAMBO, and the authors’ LLAMBO-light). Given the nascent state of LLM-assisted BO, this is reasonable. One small concern is that the original LLAMBO method was modified (for practicality) – the full LLAMBO might generate multiple candidates and evaluate them with a surrogate, which could potentially yield better results than the one-shot “light” version used. Also, there are additional LLM enhanced BO methods should be compared and discussed: BioDiscoveryAgent [1], FunBO [2], LLaMEA-BO [3], and SLLMBO [4] etc. These are important works in this line of research.\n---\n[1] Roohani, Yusuf, et al. \"Biodiscoveryagent: An ai agent for designing genetic perturbation experiments.\" arXiv preprint arXiv:2405.17631 (2024).\n\n[2] Aglietti, Virginia, et al. \"Funbo: Discovering acquisition functions for bayesian optimization with funsearch.\" arXiv preprint arXiv:2406.04824 (2024).\n\n[3] Li, Wenhu, et al. \"LLaMEA-BO: A Large Language Model Evolutionary Algorithm for Automatically Generating Bayesian Optimization Algorithms.\" arXiv preprint arXiv:2505.21034 (2025).\n\n[4] Mahammadli, Kanan, and Seyda Ertekin. \"Sequential large language model-based hyper-parameter optimization.\" arXiv preprint arXiv:2410.20302 (2024)."}, "questions": {"value": "1. In LLINBO-Constrained, the authors assume $f(x_{\\mathrm{LLM},t}) > \\kappa_{t-1}$. How robust is the method when this assumption is wrong? Is it possible to use a probabilistic belief about the LLM’s suggestion quality rather than a hard constraint?\n\n2. Beyond a single candidate per iteration, have you experimented with eliciting richer information from the LLM?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1eQ4Fdhrwa", "forum": "39CEoMXTHh", "replyto": "39CEoMXTHh", "signatures": ["ICLR.cc/2026/Conference/Submission22200/Reviewer_w5nX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22200/Reviewer_w5nX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22200/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976859286, "cdate": 1761976859286, "tmdate": 1762942111568, "mdate": 1762942111568, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "LLM in the Loop BO (LLINBO) is a hybrid framework for Bayesian optimization that combines large language models with statistical surrogate experts, with Gaussian processes as the focus in this paper. The goal is to tap the contextual reasoning strengths of LLMs while relying on principled uncertainty from statistical surrogates to enable more trustworthy optimization. The work advances the growing line of research that uses the few shot capabilities of LLMs for black box optimization, while addressing inherent limitations such as the lack of calibrated uncertainty and the opaque behavior of LLMs that makes them hard to interpret. To leverage LLMs without inheriting these risks, the authors propose a framework in which the LLM accelerates early exploration and the surrogate model increasingly guides and exploits as data accumulates.\n\nAt a high level, each BO round maintains a GP posterior, queries the LLM for a candidate $x_{LLM,t}$, evaluates that suggestion with the GP to accept, refine, or reject it (according to one of three mechanisms), and then evaluates the chosen design point. The GP “check and balance” is instantiated in three variants. LLINBO-TRANSIENT uses a Bernoulli schedule that prioritizes LLM suggestions early and shifts toward GP driven selection later. LLINBO-JUSTIFY uses the GP posterior to judge $x_{LLM,t}$, accepting it only if it lies within a specified suboptimality region; otherwise it retains the GP chosen point $x_{GP,t}$. LLINBO Constrained treats $x_{LLM,t}$ as a promising design choice and builds a constrained GP by conditioning on the event that this chosen design outperforms the current posterior mean maximizer, then acquires using a Monte Carlo approximation under the constrained posterior. Unlike the first two methods, the constrained approach avoids additional tuning parameters. All three mechanisms use GP-UCB variants s the acquisition function and come with upper bounds that ensure no regret as $T \\to \\infty$. The paper presents a range of empirical results to demonstrate early gains from LLM guidance and competitive or improved performance as the GP takes over for several problems."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well motivated and tackles a growing area of research in the BO community. \n\n2. The authors present a clear, coherent narrative of their proposed methods. \n\n3. The paper provides solid theoretical results that establish the no regret behavior of the mechanisms.\n\n4. The work includes a practical demonstration that shows how LLINBO performs in a real setting.\n\n5. The experimental section is extensive, with clearly documented details that support reproducibility."}, "weaknesses": {"value": "1. The novelty is quite moderate. Although the third variant (LLINBO Constrained) presents a meaningful new idea, its scalability and the compute trade offs are not clearly justified with profiling or ablations.\n\n2. Related to the above, the paper claims LLINBO is the first hybrid framework that integrates LLMs and GPs for BO. This does not seem entirely correct: for example, Kristiadi et al. (ICML 2024), “A Sober Look at LLMs for Materials Discovery,” used an LLM as a feature extractor into a GP surrogate for BO in materials discovery. The authors should clarify the novelty relative to such setups.\n\n3. Several controlling parameters are required across the three mechanisms. Although recommended values are provided, there is no elegant or reliable procedure for selecting them across domains.\n\n4. The synthetic functions for the black-box optimization (BBO) task do not mimic the higher dimensional settings common in BO papers as the chosen functions range from 2D to 6D. Also for the BBO tasks, LLINBO variants and standard BO are not clearly differentiated in final performance, aside from early stage gains that do not always change the end result. The authors, however, do demonstrate stronger performance on real world tasks and hyperparameter tuning settings."}, "questions": {"value": "1. Can the authors clarify the distinction from Kristiadi et al. paper as noted earlier, and whether the claim of being the first hybrid framework combining GPs and LLMs for BO is accurate? Fundamentally, the methods are different, but the “first” claim may not be entirely correct. A clarification would be greatly welcomed. \n\n2. Can the authors comment on the restriction of the synthetic functions to just 2 to 6 dimensions and, if possible, report performance on higher dimensional synthetic problems as typically done in BO papers (for example, 2D to 16D for low to moderate dimensional settings)? If this is not feasible, a brief justification would be helpful.\n\n3. Can the authors discuss the cost implications across the three methods, beyond the interpretability argument that motivated the choice of LLINBO-TRANSIENT for the 3D-printing problem?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lt1CtFcvmw", "forum": "39CEoMXTHh", "replyto": "39CEoMXTHh", "signatures": ["ICLR.cc/2026/Conference/Submission22200/Reviewer_nvHk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22200/Reviewer_nvHk"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22200/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978370104, "cdate": 1761978370104, "tmdate": 1762942111341, "mdate": 1762942111341, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}