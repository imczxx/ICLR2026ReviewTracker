{"id": "vHaBLrq7OE", "number": 14015, "cdate": 1758226990537, "mdate": 1763663584815, "content": {"title": "Dual Optimistic Ascent (PI Control) is the Augmented Lagrangian Method in Disguise", "abstract": "Constrained optimization is a powerful framework for enforcing requirements on neural networks. These constrained deep learning problems are typically solved using first-order methods on their min-max Lagrangian formulation, but such approaches often suffer from oscillations and can fail to find all local solutions. While the Augmented Lagrangian method (ALM) addresses these issues, practitioners often favor dual optimistic ascent schemes (PI control) on the standard Lagrangian, which perform well empirically but lack formal guarantees. In this paper, we establish a previously unknown equivalence between these approaches: dual optimistic ascent on the Lagrangian is equivalent to gradient descent-ascent on the Augmented Lagrangian. This finding allows us to transfer the robust theoretical guarantees of the ALM to the dual optimistic setting, proving it converges linearly to all local solutions. Furthermore, the equivalence provides principled guidance for tuning the optimism hyper-parameter. Our work closes a critical gap between the empirical success of dual optimistic methods and their theoretical foundation.", "tldr": "We show that dual optimistic ascent on the Lagrangian is equivalent to gradient descent–ascent on the Augmented Lagrangian", "keywords": ["Constrained Optimization", "Min-max Optimization", "Augmented Lagrangian Method", "Optimistic Gradient Method"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/90c53f12448efaf23dc610d6cf1334ef6c9dd7bb.pdf", "supplementary_material": "/attachment/594fce2e40e7011e1a85554bb7686a62d39acd2f.pdf"}, "replies": [{"content": {"summary": {"value": "The paper studies dual-only optimistic ascent applied to the standard Lagrangian. The central result establishes a precise equivalence between this method and gradient descent–ascent on the Augmented Lagrangian (ALM) when the optimism and penalty parameters are aligned. This equivalence holds at the iterate level for equality-constrained problems (under specific initialization) and, for inequality constraints, extends to locally stable stationary points, transferring local linear convergence and damping properties. The work thus generalizes the theoretical foundation of ALM-based gradient methods to the dual-only optimistic ascent framework, explains the empirically observed stabilization effect of dual optimism, and offers practical guidance on parameter tuning (e.g., matching optimism and penalty parameters) through the ALM perspective."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper reduces dual-only optimistic ascent to the Augmented Lagrangian Method (ALM), establishing a theoretical foundation for its practical use in constrained deep-learning pipelines. The theoretical derivation seems sound."}, "weaknesses": {"value": "The generality of the results appears limited, as the analysis focuses on the specific setting of dual-only optimism with single-step first-order primal updates. Since the reviewer is not deeply familiar with the literature on constrained optimization via dual optimistic ascent, it is somewhat difficult to assess the broader significance of the contribution, especially given that the problem formulation seems rather specialized."}, "questions": {"value": "Could the authors provide further justification or point the reviewer to references explaining why existing theoretical analyses of general min–max optimization are insufficient for this setting? It would also be helpful to clarify what specific advantages the proposed analysis offers over prior frameworks."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "sau7q1UOwG", "forum": "vHaBLrq7OE", "replyto": "vHaBLrq7OE", "signatures": ["ICLR.cc/2026/Conference/Submission14015/Reviewer_2hch"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14015/Reviewer_2hch"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14015/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761845644791, "cdate": 1761845644791, "tmdate": 1762924509453, "mdate": 1762924509453, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Response to all Reviewers"}, "comment": {"value": "We thank all three reviewers for their valuable feedback. We are encouraged that the reviewers described our contribution as “novel and elegant”, “interesting”, and as providing a “sound theoretical foundation” for a practical method.\n\nWe address here two concerns shared by **Reviewers Wayq** and **GKqh**.\n\n### Lack of Empirical Results\n\nWe thank the reviewers for this crucial feedback. **Reviewer GKqh** suggested including an empirical verification to corroborate our theory, while **Reviewer Wayq** suggested substantiating our claim that the equivalence provides practical, algorithmic benefits (e.g., reusing ALM tuning schemes for dual optimistic ascent).\n\nWe have addressed both points. For the sake of the discussion period, we have added a supplementary PDF with new experiments. **We invite the reviewers to view this file, which is attached under “Supplementary Material” above.**\n\nThese new experiments demonstrate:\n1. The exact primal-iterate equivalence predicted by Theorem 1.\n2. The practical utility of our connection, showing that an ALM-style adaptive scheduler can be directly applied to the $\\omega$ parameter in dual optimistic ascent to improve convergence.\n\nWe believe these additions make the paper significantly stronger. Should the paper be accepted, we will polish these experiments and integrate them into the camera-ready version.\n\n\n### Differences between ALM and dual optimistic ascent for inequality constraints\n\nHere, we characterize the differences between the two methods for inequality constraints. Crucially, **the effective multipliers of both methods coincide for a significant portion of the optimization trajectory.**\n\nRecall the updates for both methods:\n$$\n\\lambda_{t+1}^{\\text{OGA}} = [\\lambda_{t}^{\\text{OGA}} + \\eta g(x_{t}) + c (g(x_{t}) - g(x_{t-1})) ]\\_+\n$$\nand\n$$\n\\lambda_{t+1}^{\\text{ALM}} = \\left(1 - \\frac{\\eta}{c} \\right)\\lambda_{t}^{\\text{ALM}} + \\frac{\\eta}{c} [\\lambda_{t}^{\\text{ALM}} + c g(x_{t+1})]_+\n$$\n\n**1. The Common Regime (Active Constraints)**.\nConsider the common case where the constraint is violated ($g(x_t) > 0$) for a sustained period and multipliers become large. Here, the projection arguments remain strictly positive, so the operator $[\\cdot]\\_+$ acts as the identity.\nConsequently, the updates simplify to:\n$$\n\\lambda_{t+1}^{\\text{OGA}} = \\lambda_{t}^{\\text{OGA}} + \\eta g(x_{t}) + c (g(x_{t}) - g(x_{t-1}))\n$$\nand\n$$\n\\lambda_{t+1}^{\\text{ALM}} = \\lambda_{t}^{\\text{ALM}} + \\eta g(x_{t+1})\n$$\nThese recover the exact dynamics of the equality-constrained setting, where—under the initialization of Theorem 1—we know the primal iterates match exactly. This scenario is fairly common in practice, particularly during phases where the constraint is consistently violated.\n\n**2. When Discrepancies Occur**.\nThe projection logic is triggered differently in the two methods whenever the **difference term** $c(g(x_{t}) - g(x_{t-1}))$ in OGA contradicts the current feasibility measurement, leading to two scenarios:\n* **Premature Drop:** $g(x_{t-1}) \\gg g(x_t) > 0$ (violation), but decreasing so fast that the negative trend dominates. OGA projects to zero (\"anticipating\" feasibility), while the ALM multiplier stays active.\n* **Pre-activation:** $g(x_{t-1}) \\ll g(x_t) \\le 0$ (feasible), but increasing so fast that the positive trend dominates. OGA activates (\"anticipating\" violation), while ALM stays inactive.\n\nMathematically, for this disagreement to occur, the single-step change must dominate the current constraint magnitude:\n$$\n|g(x_t) - g(x_{t-1})| \\gtrsim |g(x_t)|\n$$\nThis condition is rare in smooth optimization with small step sizes, occurring primarily during rapid changes across the boundary.\n\nWe highlight that, near the boundary ($g(x_t) \\approx 0$), the differences between both methods become **negligible**. By continuity, the multipliers here are small; thus, even if the methods disagree (one clamps to zero, the other retains a small value), the resulting primal gradient contribution $\\lambda \\nabla g(x)$ is still very small. For trajectories far from the boundary (such as the active case above, or a significantly inactive constraint), the projection logic is typically stable and identical.\n\n\nIn summary, OGA is slightly more **anticipatory** (reacting to trends), while ALM is more **robust** (reacting to states). In any case, we re-iterate the most important practical implication of our work: regardless of these transient differences, **both methods share the same set of locally stable stationary points.** Locally, both algorithms target the same solutions in a principled way."}}, "id": "cHmleJ0dvs", "forum": "vHaBLrq7OE", "replyto": "vHaBLrq7OE", "signatures": ["ICLR.cc/2026/Conference/Submission14015/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14015/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14015/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763669844186, "cdate": 1763669844186, "tmdate": 1763669844186, "mdate": 1763669844186, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper establishes a theoretical equivalence between dual optimistic ascent (PI control) and the Augmented Lagrangian Method (ALM). Specifically, it shows that for equality-constrained problems, dual optimistic ascent on the Lagrangian is identical (in primal iterates) to gradient descent–ascent on the Augmented Lagrangian when the optimism coefficient ω equals the penalty parameter c. For general inequality constraints, the two methods share the same locally stable stationary points (LSSPs), implying the same convergence targets. This equivalence allows transferring ALM’s robust theoretical guarantees—especially linear convergence—to the dual optimistic framework, previously known mainly for empirical success. The paper further analyzes implications for convergence, stability, oscillation damping, and hyperparameter tuning."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This submission has novel and elegant theoretical contribution. The main equivalence result is new and insightful: it unifies two popular but seemingly different optimization paradigms. The insight that “dual optimism ≈ augmented regularization” is elegant and of clear theoretical and practical significance. This bridge justifies the strong empirical performance of PI-control methods used in deep RL and constrained deep learning.\n\nThis submission is mathematically sound and grounded in classical references. The local stability analysis via Jacobians is carefully argued and well contextualized. Theorems systematically extend the equivalence to convergence, oscillation damping, and conditioning, providing a unified picture.\n\nThe practical implications for tuning the optimism coefficient ω using ALM’s penalty intuition are particularly valuable. The discussion connects to recent empirical work in reinforcement learning and fairness-constrained training. This paper has some practical use in deep learning and LLM."}, "weaknesses": {"value": "The most significant weakness of this submission is that this paper lacks empirical verification from numerical experiments. Although the theory neatly explains prior empirical results, no new experiments are provided. The reviewer suggest adding a simple numerical example (e.g., a 2D quadratic constraint problem or other simple constrained optimization problem ) showing the equivalence in iterates and the damping of oscillations. With the numerical experiments results, this can significantly improve the quality of this submission.\n\nOther minor weaknesses include limited scope for inequality constraints. The equivalence for inequalities is only local, and the intuition behind the “two projections vs. one” distinction could be expanded with geometric visualization or numerical illustration. \n\nAlso the assumptions (strict complementarity, LICQ, SOSC) are standard but a little strong. The paper could benefit from discussing whether relaxed conditions (e.g., weak constraint qualification) still preserve equivalence.\n\nThis submission didn't have discussion on Multi-step or Second-order ALM Variants The authors explicitly limit equivalence to single-step first-order methods. It is suggest that adding brief discussion about how multi-step variants (as used in practical ALM solvers) might diverge, or outline what breaks in the proof."}, "questions": {"value": "There are no other questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bEVDmrkMPL", "forum": "vHaBLrq7OE", "replyto": "vHaBLrq7OE", "signatures": ["ICLR.cc/2026/Conference/Submission14015/Reviewer_GKqh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14015/Reviewer_GKqh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14015/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966092797, "cdate": 1761966092797, "tmdate": 1762924508723, "mdate": 1762924508723, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper considers constrained optimization problems with both equality and inequality constraints. After describing three primal-dual approaches for solving the problem (Lagrangian, augmented Lagrangian, and dual optimistic ascent), the paper then establishes theoretical equivalence results between the augmented Lagrangian method and the dual optimistic ascent approach, hence allowing the desirable properties of augmented Lagrangian to be transferred to dual optimistic ascent (also known as PI control). Discussions are also provided on the practical implications of this equivalence, including the choice of the optimism hyperparameter in dual optimistic ascent."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is very well written and provides adequate background for an audience who may not be readily working in constrained optimization/learning.\n- The provided equivalence results are interesting and could lead to significant follow-up theoretical and empirical research in constrained optimization, especially in the context of modern deep learning problems."}, "weaknesses": {"value": "- There was no mention of how the results connect to the *parameterized* setting, where the primal variables are the parameters of a non-convex deep neural network architecture. Do you anticipate the results to have parameterized analogs under assumptions (such as near-universality of the parameterization)?\n- The results are limited to a single primal step per iteration (although this is, I believe, what is mainly used in practice).\n- The exact equivalence of primal iterates is limited to problems with only equality constraints.\n- No empirical results are provided to corroborate/complement the theoretical findings."}, "questions": {"value": "- What is the downside of augmented Lagrangian (and dual optimistic ascent) compared to regular Lagrangian? If convergence properties are more desirable, why is the regular Lagrangian the most commonly used approach in practice?\n- Could you please clarify the statement on lines 224-225 on the replacement of the first dual update in (Lag-GD-OA) in practice? Is there a way to get around evaluations of $g$ and $h$ at $x_{t-1}$?\n- Is there a way to better formalize the Jacobian \"becoming real\" in Corollary 5 (e.g., via characterizing the rate of decline of the imaginary eigenvalues)?\n- I understand that this paper's contribution is primarily on the theoretical side. However, I believe some simple experiments on the differences between augmented Lagrangian and dual optimistic ascent in problems with inequality constraints, as well as dynamic tuning of the optimism hyperparameter by mirroring augmented Lagrangian penalty scheduling methods (as mentioned in lines 460-461), would be interesting and helpful additions to the paper.\n- I would suggest swapping the discussion on OGDA and ALA in Section 2 (i.e., discussing OGDA first and then ALA) for a better flow."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "eqrmBWqcTd", "forum": "vHaBLrq7OE", "replyto": "vHaBLrq7OE", "signatures": ["ICLR.cc/2026/Conference/Submission14015/Reviewer_Wayq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14015/Reviewer_Wayq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14015/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762199336284, "cdate": 1762199336284, "tmdate": 1762924508281, "mdate": 1762924508281, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}