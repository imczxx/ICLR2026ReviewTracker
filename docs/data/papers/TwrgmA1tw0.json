{"id": "TwrgmA1tw0", "number": 10752, "cdate": 1758181051568, "mdate": 1759897631684, "content": {"title": "Rating Quality of Diverse Time Series Data by Meta-learning from LLM Judgment", "abstract": "High-quality time series (TS) data are essential for ensuring TS model performance, rendering research on rating TS data quality indispensable. Existing methods have shown promising rating accuracy within individual domains, primarily by extending data quality rating techniques such as influence functions and Shapley values to account for temporal characteristics. However, they neglect the fact that real-world TS data can span vastly different domains and exhibit distinct properties, hampering the accurate and efficient rating of diverse TS data. \n\nIn this paper, we propose TSRating, a novel and unified framework for rating the quality of time series data crawled from diverse domains. TSRating leverages LLMs' inherent ample knowledge, acquired during their extensive pretraining, to comprehend and discern quality differences in diverse TS data. We verify this by devising a series of prompts to elicit quality comparisons from LLMs for pairs of TS samples. We then fit a dedicated rating model, termed TSRater, to convert the LLMs' judgments into efficient quality predictions by inferring future TS samples through TSRater's inference. To ensure cross-domain adaptability, we develop a meta-learning scheme to train TSRater on quality comparisons collected from nine distinct domains. To improve training efficiency, we employ signSGD for inner-loop updates, thus circumventing the demanding computation of hypergradients. Extensive experimental results on eleven benchmark datasets across three time series tasks, each using both conventional TS models and TS foundation models, demonstrate that TSRating outperforms baselines in terms of estimation accuracy, efficiency, and domain adaptability.", "tldr": "", "keywords": ["Data quality assessment", "Data selection", "Time series data", "Large language models"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2973ec112e6917a876ed9be69bc82b05a12b8ab9.pdf", "supplementary_material": "/attachment/9262ad8a86b30662a09456fc5e48230c284b0be0.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes TSRating, a novel framework for evaluating the quality of diverse time series data, addressing limitations in existing methods regarding cross domain generalization and efficiency. The core idea involves using LLMs guided by specific prompts based on TS characteristics:trend, frequency, amplitude, pattern, to make pairwise quality judgments on TS blocks. These judgments are then converted into scalar scores using the Bradley-Terry model and used to train an efficient scoring model TSRater composed of a TSFM encoder and an MLP head. Crucially, TSRater is trained using a meta learning approach across multiple domains, enabling few shot adaptation to new, unseen TS data types. The paper demonstrates TSRating's effectiveness through extensive experiments on downstream tasks, showing improved performance when selecting data based on its scores compared to baseline methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1 The paper exhibits strong originality through its synthesis of multiple concepts: applying the LLM-as-a-judge paradigm cross-modally to raw time series signals, formulating a unique knowledge distillation pipeline to train an efficient scoring model from LLM preferences; and being the first to apply meta-learning for learning a cross-domain data quality scoring function. This architectural combination is novel.\n\n2 The TSRating framework is well-designed. The use of pairwise comparisons, Bradley-Terry modeling, a TSFM encoder, and MAML with SignSGD represents a thoughtful integration of techniques. Experimental validation is extensive across 11 datasets and 3 tasks, providing strong support for the claims.\n\n3 The paper is clearly written and organized. Problem, methodology, and results are presented logically. Prompt design rationale and LLM validation enhance clarity.\n\n4 This work addresses an important gap in time series analysis – scalable and adaptable data quality assessment. As datasets grow in size and diversity, such a tool is valuable. The framework offers a practical approach to automated data curation, potentially improving TSFM training robustness and efficiency."}, "weaknesses": {"value": "1 The framework relies on LLM judgments, which may have inherent biases or sensitivity to prompts. While stability measures were taken , potential systematic biases require further discussion.\n\n2 Justification for selecting the four specific criteria:\" trend, frequency, amplitude, pattern\" could be stronger. Their sufficiency for all TS tasks (e.g., anomaly detection) is unclear, and potential subjectivity exists.\n\n3 Collecting numerous LLM judgments across multiple domains for meta-learning might be costly and time-consuming, potentially limiting practical scalability.\n\n4 Performance relies on MOMENT's representations. Sensitivity to this choice and effectiveness with other encoders should be discussed.\n\n5 Simple averaging is used for channels and criteria. Exploring adaptive aggregation might improve performance."}, "questions": {"value": "1 Can you elaborate on potential biases in LLM judgments (e.g., pattern preference, positional bias) and mitigation strategies? Did you consider using ensemble judgments from different LLMs?\n\n2 What is the theoretical or empirical basis for selecting these four specific criteria? Are they sufficient for all types of time series tasks (e.g., anomaly detection)? Do you plan to explore more dynamic or task-adaptive criteria?\n\n3 What are the costs and time involved in collecting the LLM judgments for meta-learning? How scalable do you see this approach in practice, especially for covering many more domains or larger datasets?\n\n4 How much does TSRater's performance rely on the MOMENT encoder? What performance changes might be expected if using other TSFM encoders (e.g., Chronos, TimeGPT)?\n\n5 Did you experiment with aggregation methods beyond simple averaging (e.g., weighted average, attention) for fusing scores across channels or criteria?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vTuQo50wak", "forum": "TwrgmA1tw0", "replyto": "TwrgmA1tw0", "signatures": ["ICLR.cc/2026/Conference/Submission10752/Reviewer_pUfp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10752/Reviewer_pUfp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10752/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761473075223, "cdate": 1761473075223, "tmdate": 1762921973399, "mdate": 1762921973399, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces TSRating, a framework designed to evaluate the quality of time series data using meta-learning guided by large language models (LLMs). TSRating identifies quality based on four criteria: trend, frequency, amplitude, and pattern. It leverages LLMs to compare pairs of time series and convert these judgments into quality predictions via the TSRater model, which adapts across multiple domains. The framework employs meta learning for efficient training and demonstrates superior performance over traditional methods in experiments. TSRating is shown to be effective in identifying high-quality time series samples, enhancing model performance in various forecasting and classification tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. Proposes an innovative method for time series quality evaluation by employing LLMs as general “pattern evaluators”, moving beyond traditional statistical or contribution-based metrics.\n2. Uses meta-learning to effectively address domain heterogeneity, resulting in strong cross-domain generalization and applicability.\n3. Clearly defines the evaluation criteria and provides transparent methodology.\n4. Demonstrates significant practical relevance through measurable improvements in downstream tasks."}, "weaknesses": {"value": "1. Heavy reliance on LLM judgments may introduce biases or inaccuracies in understanding intrinsic time series patterns, risking propagation of these biases into TSRater.\n2. The definition of “quality” along four fixed dimensions implicitly equates high quality with signal clarity or prominence, which may not be optimal for all downstream tasks (e.g., classification vs. forecasting), potentially leading to suboptimal data selection."}, "questions": {"value": "1. Given that real-world time series data may contain rare or complex patterns that score poorly yet are crucial for future events, how does TSRating avoid discarding “anomalous but important” sequences?\n2. Could TSRater exhibit a preference for common or simple patterns, thus reducing diversity in the selected training set and harming generalization? For example, in Figure 4(a) indices 1531 and 1552, and in Figure 4(c) indices 860 and 883, there are long overlapping segments.\n3. How does the choice of data segmentation strategy (e.g., different sequence lengths or block sizes) affect TSRater’s evaluation performance?\n4. Regarding the integration of multiple criteria (trend, frequency, amplitude, pattern), what is the specific fusion method used? Can a fixed fusion strategy generalize well to all types of downstream tasks?\n\nIf the authors are able to address the questions raised, I would be inclined to increase my evaluation score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5GYl391K3U", "forum": "TwrgmA1tw0", "replyto": "TwrgmA1tw0", "signatures": ["ICLR.cc/2026/Conference/Submission10752/Reviewer_kv5d"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10752/Reviewer_kv5d"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10752/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761880807211, "cdate": 1761880807211, "tmdate": 1762921972953, "mdate": 1762921972953, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes TSRating, which uses LLM pairwise judgments on four TS criteria including trend, frequency, amplitude and pattern, to score fixed-length blocks via a Bradley–Terry model, then trains a meta-learned TSRater to predict quality efficiently on new datasets. Meta-training relies on MAML with signSGD over 9 domains; in downstream selection, the top-50 percent “high-quality” samples train forecasting/classification models. The authors report improved performance and favorable amortized runtime vs. Shapley/Influence baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**S1.** This paper is well-organized and easy to follow.\n\n**S2.** The task of time series datasets quality evaluation is important in deep time series model training.\n\n**S3.** Meta-learning across 9 domains/22 subsets and reuse on unseen datasets is a sensible design for diverse time series."}, "weaknesses": {"value": "**W1.** The most critical weakness lies in the evaluation strategy of TSRating. The framework implicitly assumes that time series with strong trends, seasonality, and regular patterns (Figure 4 in the Appendix) represent high-quality data because they are more predictable and easier to learn. Conversely, series with irregular or unpredictable fluctuations (e.g., the red block in the right part of Figure 1) are treated as “bad samples.” However, in real-world applications, data often exhibit irregular noise and unpredictable variations rather than such idealized patterns. Therefore, the evaluation strategy based on these four criteria is limited in its applicability to real-world scenarios.\n\n**W2.** The LLM judgement is limited, inlcluding:\n\n* Based on LLM pairwise labels yet provides only small-scale synthetic checks and a single-dataset tri-LLM comparison.\n\n* There is no inter-LLM agreement, prompt-order/wording sensitivity, or human/expert adjudication beyond illustrative plots.\n\n* The Bradley–Terry likelihood carries no uncertainty calibration and no analysis of label noise propagation into TSRater. \n\n**W3.** There is no ablation replacing MOMENT with other (TSFM) encoders or fine-tuning MOMENT, so the gains might stem from encoder pretraining/domain coverage rather than the rating scheme. This also risks domain-shift leakage if MOMENT has seen similar sources during pretraining\n\n**W4.** Selecting the top-50 percent across all methods may advantage rank-based raters..\n\n**W5.** Runtime Table 2 aggregates “LLM judgments” but does not report token counts, pairwise comparison budget per dataset, or prompting policy vs. quality.\n\n**W6.** Line 246, synthetic set with obvious hand-crafted time series characteristics labeled as high-quality blocks is not make sense (refer to W1)."}, "questions": {"value": "Please see Weaknesses.\n\nAdditional questions:\n\n**Q1.** How consistent are the LLM pairwise judgments across prompts, random seeds, and different LLMs?\n\n**Q2.** Does TSRater still perform well if the MOMENT encoder is fine-tuned or replaced with another TSFM backbone?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "nBQdDsrZ1I", "forum": "TwrgmA1tw0", "replyto": "TwrgmA1tw0", "signatures": ["ICLR.cc/2026/Conference/Submission10752/Reviewer_nhuS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10752/Reviewer_nhuS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10752/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761906641509, "cdate": 1761906641509, "tmdate": 1762921972636, "mdate": 1762921972636, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}