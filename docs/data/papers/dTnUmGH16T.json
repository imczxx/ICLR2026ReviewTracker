{"id": "dTnUmGH16T", "number": 2493, "cdate": 1757124341732, "mdate": 1759898144770, "content": {"title": "SPREAD-GS: Scale-Progressive Representation Extraction and Detailing for 3D Gaussian Splatting", "abstract": "3D Gaussian Splatting (3DGS) has recently shown remarkable capability for high-fidelity scene reconstruction. However, its potential for object recognition remains under-explored. Existing approaches often extract 2D features from multi-view images and embed them into 3DGS, which limits the joint use of 3DGS geometric and appearance information.\nTo fully exploit both the structural and fine-grained details encoded in 3DGS, we propose Scale-Progressive Representation Extraction And Detailing for 3D Gaussian Splatting (SPREAD-GS), a framework for object classification that combines scale-aware sampling with detail-preserving feature propagation. \nSPREAD-GS has two key modules: Scale-Progressive Sampling (SPS), generating multi-scale subsets by progressively narrowing the visible region, and SpreadNet, encoding these subsets and propagating details across scales through noise-augmented feature upsampling. On the texture-rich MACGS dataset, SPREAD-GS achieves 93.92% overall accuracy, surpassing the best prior method by 2.01%. On the geometry-centric ModelNet40GS, it reaches 91.67%, a 0.51% improvement.\nThese results demonstrate the effectiveness of scale-progressive sampling and detail-preserving feature propagation for 3DGS recognition. Our code is available at https://anonymous.4open.science/r/noname-64BE.", "tldr": "SPREAD-GS leverages scale-progressive sampling and hierarchical detail propagation to improve texture- and geometry-aware 3D object classification.", "keywords": ["3D Gaussian Splatting", "multi-scale representation", "feature propagation", "3D object classification"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d78325db865368b8ba8457e3e15c570a9f79cff4.pdf", "supplementary_material": "/attachment/e4ff4471b4f5f23b9aafb4b541c666e125fbfd03.zip"}, "replies": [{"content": {"summary": {"value": "In this paper, the authors propose a framework for object classification, named SPREAD-GS. Its key module SPS generate multi-scale subsets and by progressively narrowing the camera FoV, and then SpreadNet encodes these subsets and propagating details across scales through noise-augmented feature upsampling. The experiments show that SPREAD-GS achieves the best results on the MACGS and ModelNet40GS datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The authors propose leveraging Gaussian attributes as additional information to enhance the object classification capability, which I consider effective and innovative.\n2. The experiments demonstrate that SPREAD-GS achieves superior performance on the MACGS and ModelNet40 datasets."}, "weaknesses": {"value": "1. Incorporating more Gaussian attributes increases the input storage size compared to other methods that use point cloud representations. It would be valuable if the authors could provide additional experiments to validate the model’s performance under conditions where the input storage size is comparable across different methods. This would help clarify whether the performance improvement of SPREAD-GS stems from the richer Gaussian attributes or merely the larger input size.\n2. As the authors claim that Gaussian attributes enhance the object classification capability. To better support this claim, it is recommended that the authors present comparative experiments to demonstrate the impact of combined Gaussian attributes—such as scale, rotation, opacity, and color—versus using only position information. \n3. The design of SPS focuses on single object. However, multi-object interactive scenes are more common in practical Gaussian Splatting applications(e.g., autonomous driving). It would be better if the authors could provide more examples or experiments on multi-object scenes to evaluate SPREAD-GS’s performance in handling object interactions."}, "questions": {"value": "The definition of the camera pose during SPS remains unclear, which causes confusion. As an object’s appearance varies with the observation direction, the distance and angle between the camera and the object can significantly affect the sampling results. Additionally, the robustness of SPS to different camera poses also raises confusion."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3PIkULAY1x", "forum": "dTnUmGH16T", "replyto": "dTnUmGH16T", "signatures": ["ICLR.cc/2026/Conference/Submission2493/Reviewer_uFqF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2493/Reviewer_uFqF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2493/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760696729972, "cdate": 1760696729972, "tmdate": 1762916254471, "mdate": 1762916254471, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SPREAD-GS, a new framework that aims to enhance 3D object classification using 3D Gaussian Splatting (3DGS) representations. The authors argue that existing approaches either rely on 2D features embedded into 3DGS, which fail to exploit native 3D information, or treat Gaussians as point cloud, which discards fine-grained per-primitive details. To address this, SPREAD-GS proposes two key components: (1) Scale-Progressive Sampling (SPS): A multi-scale sampling mechanism that progressively narrows the FoV to create hierarchical subsets of Gaussians. It captures both global geometric structure and localized appearance details. (2) SpreadNet: A hierarchical network that processes these subsets and propagates fine-scale features across scales via a Detail Propagation (DP) module. The network leverages EdgeConv layers for local structure encoding and fuses features progressively to build robust object-level representations. Experiments on MACGS and ModelNet40GS benchmarks show that SPREAD-GS outperforms state-of-the-art point cloud and Gaussian-based baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Good writing and organization.\n\n2. Effective idea with clear motivation.\n\n3. The proposed scale-progressive sampling and SpreadNet are novel and with solid engineering."}, "weaknesses": {"value": "1. Lack of efficiency report. While SPREAD-GS is presented as efficient, the paper does not report detailed runtime, memory usage, or FLOPs. Given the multiple hierarchical scales and EdgeConv-based architecture, quantitative efficiency comparisons with baselines (e.g., DGCNN, PointMLP) would strengthen the claim of practical implementation and scalability.\n\n2. According to Figure 3, although SPREAD-GS adopts random offsets to alleviate the central bias, during the Scale-Progressive Sampling process, each time it extracts Gaussians from a smaller region, it still focuses only on a localized area instead of sampling a large number of local features across multiple smaller regions. This may lead to a significant bias in local feature extraction.\n\n3. The component ablation of SpreadNet is not sufficiently fine-grained. Although the paper performs ablations on hierarchical feature aggregation and propagation, it does not conduct step-by-step ablations on its five major modules, including EdgeConv, Encoder, Detail Propagation, Center Sample, and Feature FPS, to verify the necessity and contribution of each component."}, "questions": {"value": "See the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "3Wz2zbmwp2", "forum": "dTnUmGH16T", "replyto": "dTnUmGH16T", "signatures": ["ICLR.cc/2026/Conference/Submission2493/Reviewer_fxNS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2493/Reviewer_fxNS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2493/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761914531377, "cdate": 1761914531377, "tmdate": 1762916254265, "mdate": 1762916254265, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SPREAD-GS, a method for classifying 3D Gaussians. It leverages SPS to sample 3DGS at multiple scales, feeding each scale into the proposed SpreadNet to extract corresponding features. The final global feature representation is then used for classification."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.Demonstrates strong classification performance on datasets such as MACGS and ModelNet40GS, validating the method’s effectiveness.\n\n2.Proposes SpreadNet with novel encoder and block designs, showing clear architectural innovation.\n\n3.Integrates multi-scale 3DGS features, enhancing attention to local details and improving their contribution to classification accuracy."}, "weaknesses": {"value": "1.The method is primarily focused on 3D Gaussian classification. Although Section 4 suggests potential application to semantic segmentation, no experiments are provided, leaving its effectiveness on segmentation tasks uncertain. This may limit its broader applicability.\n\n2.The ablation study lacks evaluation of the impact of varying the number of detail scales and the use of Feature FPS on classification performance.\n\n3.While the paper references \"Mitigating Ambiguities in 3D Classification with Gaussian Splatting (CVPR 2025)\" and uses its datasets, no direct comparisons with that method are reported."}, "questions": {"value": "The visual results are quite limited, only one lego case is provided. Should provide more visual results of used benchmarks."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "O38t24mHQk", "forum": "dTnUmGH16T", "replyto": "dTnUmGH16T", "signatures": ["ICLR.cc/2026/Conference/Submission2493/Reviewer_hkUC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2493/Reviewer_hkUC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2493/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926622156, "cdate": 1761926622156, "tmdate": 1762916254053, "mdate": 1762916254053, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SPREAD-GS, a novel framework for 3D object classification using native 3D Gaussian Splatting (3DGS) representations, introducing Scale-Progressive Sampling (SPS) to generate multi-scale Gaussian subsets and SpreadNet, a hierarchical network with Detail Propagation (DP) to fuse local details and global structure across scales. \nEvaluated on MACGS (texture-rich) and ModelNet40GS (geometry-only), SPREAD-GS achieves 93.92% (+2.01% over SOTA) and 91.67%, respectively, with comprehensive ablations validating the efficacy of SPS, DP, and encoder design."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper presents a well-motivated and timely approach to 3D object classification using native 3D Gaussian Splatting representations, a largely underexplored direction. \nIts originality lies in the thoughtful combination of multi-scale sampling (SPS) and cross-scale detail propagation (DP), which creatively adapts hierarchical reasoning to the unique structure of 3DGS beyond treating it as a plain point cloud. The technical quality is high, with comprehensive experiments on two distinct benchmarks (MACGS and ModelNet40GS) and thorough ablations validating each component. The clarity of presentation is strong, with clear figures and logical flow, and the significance is notable—by demonstrating that 3DGS contains rich semantic cues in its native attributes, the work opens new pathways for 3D understanding tasks beyond reconstruction."}, "weaknesses": {"value": "1 Questionable task motivation: 3D Gaussian Splatting (3DGS) is primarily a reconstruction output rather than a standard input modality, and it is rarely the starting point for classification in real-world pipelines, making the practical relevance of this task unclear.\n\n2 Unfair comparison: The comparison with Gaussian-MAE is conducted without using its intended pretraining setup—the paper explicitly trains it from scratch, which undermines the fairness and validity of the comparison."}, "questions": {"value": "Fairness of comparison with Gaussian-MAE: Gaussian-MAE is designed as a large-scale self-supervised pretraining framework for 3DGS, where downstream tasks like classification and segmentation are used to evaluate the quality of its pretrained features—not as standalone task-specific models. Training Gaussian-MAE from scratch (without pretraining) for classification, as done in this work, does not reflect its intended use and undermines the comparison. \nSince the proposed SPREAD-GS is trained from scratch and tailored specifically for classification, comparing it against a general-purpose pretrained backbone under a non-standard (scratch) setting is neither fair nor meaningful."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "r0FwiZVQ0S", "forum": "dTnUmGH16T", "replyto": "dTnUmGH16T", "signatures": ["ICLR.cc/2026/Conference/Submission2493/Reviewer_JS8v"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2493/Reviewer_JS8v"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2493/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761929388948, "cdate": 1761929388948, "tmdate": 1762916253708, "mdate": 1762916253708, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}