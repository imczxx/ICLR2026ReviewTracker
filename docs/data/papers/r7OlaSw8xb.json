{"id": "r7OlaSw8xb", "number": 25559, "cdate": 1758369092224, "mdate": 1759896715654, "content": {"title": "MCCE: A Framework for Multi-LLM Collaborative Co-Evolution", "abstract": "Multi-objective discrete optimization problems, such as molecular design, pose significant challenges due to their vast and unstructured combinatorial spaces. Traditional evolutionary algorithms often get trapped in local optima, while expert knowledge can provide crucial guidance for accelerating convergence. Large language models (LLMs) offer powerful priors and reasoning ability, making them natural optimizers when expert knowledge matters. However, closed-source LLMs, though strong in exploration, cannot update their parameters and thus cannot internalize experience. Conversely, smaller open models can be continually fine-tuned but lack broad knowledge and reasoning strength. We introduce Multi-LLM Collaborative Co-evolution (MCCE), a hybrid framework that unites a frozen closed-source LLM with a lightweight trainable model. The system maintains a trajectory memory of past search processes; the small model is progressively refined via reinforcement learning, with the two models jointly supporting and complementing each other in global exploration. Unlike model distillation, this process enhances the capabilities of both models through mutual inspiration. Experiments on multi-objective drug design benchmarks show that MCCE achieves state-of-the-art Pareto front quality and consistently outperforms baselines. These results highlight a new paradigm for enabling continual evolution in hybrid LLM systems, combining knowledge-driven exploration with experience-driven learning.", "tldr": "MCCE is a framework for collaboration of large and small language models, combining knowledge-driven exploration with experience-driven learning", "keywords": ["reinforcement learning", "large language models", "model collaboration", "evolutionary algorithms"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0521c6df0acbd41d9c7c79c8855881f06af7d9fb.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes MCCE, a framework that unites a frozen, closed-source LLM (for global exploration) with a smaller, trainable open-source LLM (for local adaptation) in a collaborative co-evolution setup. The two models alternate between generating and refining candidate solutions, with the small model updated using DPO based on “breakthrough” trajectories. The system aims to combine reasoning strength and adaptability, achieving improved performance on multi-objective molecular design tasks such as drug discovery."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This paper addresses an emerging direction in hybrid LLM collaboration by demonstrating the strengths of large frozen models and fine-tunable smaller models.\n\nStrong results on multi-objective optimization benchmarks with quantitative evidence (e.g., hypervolume and diversity metrics)."}, "weaknesses": {"value": "1. Key elements such as the feedback exchange protocol, update frequency, and data flow between models are only briefly described. Without algorithmic pseudocode or concrete update rules, reproduction is difficult.\n\n2. Evaluation is limited to a single domain (molecular design). Either broader multi-domain testing (e.g., combinatorial optimization or symbolic reasoning) or re-framing the title and introduction to emphasize domain specificity would make the contribution more accurate and credible.\n\n3. Claims that MCCE constitutes a “general framework for collaborative reasoning” are not substantiated by the experiments, which focus solely on molecular tasks. The paper would benefit from tempering these claims or providing stronger cross-domain evidence.\n\n4. There is no detailed analysis isolating the contributions of each design component—e.g., DPO fine-tuning, trajectory selection, or mutual feedback.\n\n5. The paper does not discuss computational cost, scalability, or stability of the co-evolution loop, which are critical for practical adoption.\n\n6. Missing references on multi-agent collaboration:\n\n[1] Collabllm: From passive responders to active collaborators.\n\n[2] From LLM-anation to LLM-orchestrator: Coordinating Small Models for Data Labeling \n\n[3] Collab-RAG: Boosting Retrieval-Augmented Generation for Complex Question Answering via White-Box and Black-Box LLM Collaboration\n\n[4] Many Heads Are Better Than One: Improved Scientific Idea Generation by A LLM-Based Multi-Agent System"}, "questions": {"value": "1. Could you elaborate on the exact information exchange mechanism between the large and small models—does the frozen model adapt its generation strategy based on feedback, or is the communication one-way?\n\n2. What is the update schedule between the large and small models? Are updates synchronous after each generation cycle or asynchronously buffered?\n\n3. Have you tested MCCE in non-molecular domains (e.g., code synthesis, symbolic reasoning, or text generation) to assess generalizability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rxcOv1NhbZ", "forum": "r7OlaSw8xb", "replyto": "r7OlaSw8xb", "signatures": ["ICLR.cc/2026/Conference/Submission25559/Reviewer_T7G1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25559/Reviewer_T7G1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25559/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761814541555, "cdate": 1761814541555, "tmdate": 1762943475478, "mdate": 1762943475478, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MCCE, a framework that unites a frozen, closed-source LLM (for global exploration) with a smaller, trainable open-source LLM (for local adaptation) in a collaborative co-evolution setup. The two models alternate between generating and refining candidate solutions, with the small model updated using DPO based on “breakthrough” trajectories. The system aims to combine reasoning strength and adaptability, achieving improved performance on multi-objective molecular design tasks such as drug discovery.\n\n**Disclaimer: \nI am surprised to find that my review was labeled as \"fully llm-generated\" in https://iclr.pangram.com/. Here I would like to clarify that  I have read this paper during the review period and all the points I wrote here are my own judgments. I used GPT to make the review more fluent.**"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This paper addresses an emerging direction in hybrid LLM collaboration by demonstrating the strengths of large frozen models and fine-tunable smaller models.\n\nStrong results on multi-objective optimization benchmarks with quantitative evidence (e.g., hypervolume and diversity metrics)."}, "weaknesses": {"value": "1. Key elements such as the feedback exchange protocol, update frequency, and data flow between models are only briefly described. Without algorithmic pseudocode or concrete update rules, reproduction is difficult.\n\n2. Evaluation is limited to a single domain (molecular design). Either broader multi-domain testing (e.g., combinatorial optimization or symbolic reasoning) or re-framing the title and introduction to emphasize domain specificity would make the contribution more accurate and credible.\n\n3. Claims that MCCE constitutes a “general framework for collaborative reasoning” are not substantiated by the experiments, which focus solely on molecular tasks. The paper would benefit from tempering these claims or providing stronger cross-domain evidence.\n\n4. There is no detailed analysis isolating the contributions of each design component—e.g., DPO fine-tuning, trajectory selection, or mutual feedback.\n\n5. The paper does not discuss computational cost, scalability, or stability of the co-evolution loop, which are critical for practical adoption.\n\n6. Missing references on multi-agent collaboration:\n\n[1] Collabllm: From passive responders to active collaborators.\n\n[2] From LLM-anation to LLM-orchestrator: Coordinating Small Models for Data Labeling \n\n[3] Collab-RAG: Boosting Retrieval-Augmented Generation for Complex Question Answering via White-Box and Black-Box LLM Collaboration\n\n[4] Many Heads Are Better Than One: Improved Scientific Idea Generation by A LLM-Based Multi-Agent System"}, "questions": {"value": "1. Could you elaborate on the exact information exchange mechanism between the large and small models—does the frozen model adapt its generation strategy based on feedback, or is the communication one-way?\n\n2. What is the update schedule between the large and small models? Are updates synchronous after each generation cycle or asynchronously buffered?\n\n3. Have you tested MCCE in non-molecular domains (e.g., code synthesis, symbolic reasoning, or text generation) to assess generalizability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rxcOv1NhbZ", "forum": "r7OlaSw8xb", "replyto": "r7OlaSw8xb", "signatures": ["ICLR.cc/2026/Conference/Submission25559/Reviewer_T7G1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25559/Reviewer_T7G1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25559/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761814541555, "cdate": 1761814541555, "tmdate": 1763342205265, "mdate": 1763342205265, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes MCCE, a hybrid optimization framework that couples a frozen, closed‑source LLM (for global exploration) with a lightweight, trainable local LLM (for experience‑driven exploitation). The system keeps a trajectory memory and periodically fine‑tunes the local model using a Direct Preference Optimization (DPO) scheme. A key design is a similarity‑based data synthesis procedure that forms stable preference pairs for DPO by filtering generated molecules using global similarity statistics and score quantiles. Core contributions claimed: (i) a collaborative co‑evolution framework that lets a frozen API LLM and a trainable local LLM “mutually inspire” each other; (ii) an experience‑driven learning paradigm via DPO with similarity‑aware triplet construction; (iii) empirical gains on a five‑objective drug design benchmark, extending prior three‑objective setups."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Timely hybrid design that leverages a frozen API LLM for wide exploration and a trainable local LLM for learned exploitation.  \n\n2. Similarity‑aware triplet construction with global statistics and progressive windows"}, "weaknesses": {"value": "1. sim(c,q) between a molecule and a prompt is not formally defined; the text proposes fingerprint‑based metrics but those are molecule‑to‑molecule.  \n\n2. Lack of detail about the multi‑objective selection operator undermines interpretability of diversity and HV results. \n\n3. Add GFlowNet numbers and standard EA baselines under identical objectives; include recent LLM‑EA baselines (e.g., MoLLEO/ExLLM reproductions with your five‑objective setup).\n\n4. Report API token counts, calls per generation, and cost vs. HV curves. Consider a budgeted setting where total API calls are capped; show MCCE’s advantage under realistic constraints."}, "questions": {"value": "see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yh9dUOkwtk", "forum": "r7OlaSw8xb", "replyto": "r7OlaSw8xb", "signatures": ["ICLR.cc/2026/Conference/Submission25559/Reviewer_PG1o"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25559/Reviewer_PG1o"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25559/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762011403241, "cdate": 1762011403241, "tmdate": 1762943473685, "mdate": 1762943473685, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Multi-LLM Collaborative Co-evolution (MCCE), a hybrid framework for multi-objective discrete optimization. The core idea is to combine a powerful, but frozen, closed-source LLM (e.g., GPT-4) with a smaller, trainable, open-source LLM. The frozen LLM acts as a global explorer, while the local model is progressively fine-tuned on \"breakthrough\" search trajectories to internalize experience and perform more targeted, experience-driven learning. Furthermore, a more stable, similarity based version of DPO is presented for RL based training."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "● Paper is well written and easy to understand - great use of diagrams and figures ● SOTA results on the multi-objective showing the benefit of co-evolving LLMs vs closed-source LLMs alone \n● Similarity based DPO is a well thought out method for avoiding training instability and ensuring training on structural meaningful pairs"}, "weaknesses": {"value": "● Limited comparison to prior work. the benchmarking is done against the closed source LLM and the trainable model, however, the method is not compared against methods such as MoLLEO. \n● The paper restricts its experiments to molecular design and fails to show the benefit of co-evolving LLMs in other discrete optimization domains. \n● Hyperparameters could be ablated to study the effect of values such as alpha or the intervals for similarity."}, "questions": {"value": "● The paper states the operator alternates between the frozen and local LLMs. Is this split 50/50? Is it fixed or adaptable? \n● How crucial is the Tanimoto similarity metric for similarity based DPO? Have you explored alternative, simpler, or non-domain-specific similarity functions (e.g., embedding-based similarity)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1hO1S0FO0W", "forum": "r7OlaSw8xb", "replyto": "r7OlaSw8xb", "signatures": ["ICLR.cc/2026/Conference/Submission25559/Reviewer_gNx8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25559/Reviewer_gNx8"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25559/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762190216102, "cdate": 1762190216102, "tmdate": 1762943473401, "mdate": 1762943473401, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies multi-objective molecular optimization with LLMs. Classic evolutionary algorithms often converge prematurely and lose diversity; single-LLM optimizers can stagnate and, if frozen, cannot absorb experience. The proposed MCCE framework pairs a powerful frozen closed-source LLM (broad exploration) with a trainable lightweight local LLM (experience-driven adaptation). The two alternate as generators in an evolutionary loop; “breakthrough” trajectories are logged and used to continually refine the local model so the pair co-evolves rather than simply distilling one into the other. For training the local model, the authors compare SFT and RL, finding SFT induces catastrophic forgetting (hurting uniqueness) and RL is unstable with scalar rewards. They instead adopt DPO with a similarity-based preference construction that forms (prompt, preferred vs. rejected) pairs from structurally comparable molecules, improving stability and data efficiency. Empirically, MCCE achieves state-of-the-art hypervolume and consistently outperforms single-model and co-evolution baselines using SFT or RL. DPO-based parameter training is key for long-horizon gains; both the local and frozen components benefit (fitness/diversity and exploration), and score distributions shift upward after co-evolution."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Combining a frozen, high-capacity API model for exploration with a trainable local model for exploitation/learning is well-motivated and practically appealing.\n\n2. The DPO + similarity-based pair construction is a neat way to stabilize preference learning without expensive curated labels."}, "weaknesses": {"value": "1. The paper claims they have provide the code however, I do not find the link to the code. \n\n2. How is the synthesizability metric?\n\n3. What is the training cost?"}, "questions": {"value": "Please see the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "W4r5Qz0yVr", "forum": "r7OlaSw8xb", "replyto": "r7OlaSw8xb", "signatures": ["ICLR.cc/2026/Conference/Submission25559/Reviewer_sWYB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25559/Reviewer_sWYB"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25559/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762380408796, "cdate": 1762380408796, "tmdate": 1762943473084, "mdate": 1762943473084, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}