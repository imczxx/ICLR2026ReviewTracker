{"id": "9235Gzvgiq", "number": 25141, "cdate": 1758364609490, "mdate": 1763661856135, "content": {"title": "Bridging Gaps with Dynamic Knowledge Probes: Robust LLM–KG Collaborative Reasoning", "abstract": "Large Language Models (LLMs) exhibit exceptional capabilities in various natural language tasks but are constrained by static knowledge, potential hallucinations, and opaque reasoning processes. Integrating external Knowledge Graphs (KGs) has emerged as a promising solution. While agent-based paradigms enhance knowledge exploration by iteratively retrieving grounded facts from KGs, they often adopt a conservative KG-centric strategy that deliberately avoids using the LLM's internal knowledge—rendering them vulnerable to failures whenever missing links occur, a common challenge even in largely complete KGs.\nWe propose a KG–LLM collaborative framework that repositions the LLM’s knowledge as dynamic knowledge probes, generated via our Guidance Graph of Thought (GGoT) reasoning backbone from partially specified triples. These probes guide KG exploration, highlight potential incompleteness, and trigger trust-aware bridging with existence and necessity checks before integrating LLM-derived entities. Cross-triple constraint-based disambiguation then ensures consistency, using KG structure for credible nodes and LLM validation for low-confidence ones.\nExtensive experiments across multiple benchmarks show that our framework consistently achieves superior performance over existing approaches, with ablation studies verifying the contribution and necessity of each component in our design.", "tldr": "", "keywords": ["LLM", "knowledge graph", "question answering", "internal knowledge"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3eece6f002a954758cb753983d7d97c299da199a.pdf", "supplementary_material": "/attachment/46aaec055774082c467ca2a876042c1c847074d5.zip"}, "replies": [{"content": {"summary": {"value": "Large Language Models (LLMs) excel at language tasks but face limits from static knowledge, hallucinations, and opaque reasoning. Existing agent methods over-rely on Knowledge Graphs (KGs) and ignore LLM priors, failing when links are missing. They propose a KG–LLM collaborative framework that treats the LLM’s knowledge as dynamic probes—produced by a Guidance Graph of Thought (GGoT) from partial triples—to steer KG search, detect gaps, and perform trust-aware bridging with existence/necessity checks, followed by cross-triple constraint disambiguation. Experiments on multiple benchmarks show consistent gains over prior methods, with ablations confirming each component’s contribution."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Dynamic KG–LLM Collaboration – They combine Knowledge Graph verification with LLM reasoning, maintaining robustness even under KG incompleteness.\n\n2. Guidance Graph of Thought (GGoT) – They introduce a modular reasoning backbone that enables transparent, multi-step reasoning and seamless KG integration.\n\n3. Trust-Aware Knowledge Bridging – They ensure reliability by verifying the existence and necessity of LLM-derived entities before integration, preventing hallucination propagation."}, "weaknesses": {"value": "1. The paper presentation is lacking. First of all, there are too many line breaks. In the abstract, line breaks are generally not used, and in particular, Section 5.2 feels cluttered with unnecessary line breaks.\n\n2. The motivation and methodology of this study do not seem to be fully aligned. Early in the paper, it is stated that the use of a KG alongside an LLM aims to mitigate issues such as static knowledge, potential hallucinations, and opaque reasoning processes in LLMs. However, the method describes filling the incomplete parts of the KG with LLM-generated information, which does not sound logically consistent. It would be better to revise the motivation so that it resonates more clearly with readers.\n\n3. The datasets used in the experiments seem to be favorable to this framework. Rather than relying only on WebQSP and CWQ, testing in settings where LLM hallucinations are more likely to occur would be more effective in demonstrating the generalizability of the proposed framework."}, "questions": {"value": "The points I wrote under Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Rh5rKT8fib", "forum": "9235Gzvgiq", "replyto": "9235Gzvgiq", "signatures": ["ICLR.cc/2026/Conference/Submission25141/Reviewer_i9nf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25141/Reviewer_i9nf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25141/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760819694659, "cdate": 1760819694659, "tmdate": 1762943343001, "mdate": 1762943343001, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Case Study"}, "comment": {"value": "We greatly appreciate the time and thoughtful feedback from all reviewers. To better illustrate the behavior and effectiveness of our method, we provide two additional case studies below.\n\n## Case Study 1\n| Steps | Content |\n| :--- | :--- |\n| **Question** | What country bordering France contains an airport that serves Nijmegen? |\n| **Guidance Graph Construction** | **Guidance Graph:** `(country, borders, France)`, `(country, contains, airport)`, `(airport, serves, Nijmegen)`**Specific entities:** France; Nijmegen **Note:** France is retrievable in the KG and is used as the starting point. |\n| **First Round** | **Baseline Method:** Retrieves all relations associated with France (498 in total), randomly selects a subset, and uses an LLM for pruning. **Our Method:** **Triplet to parse:** `(country, borders, France)` **Probe generation:** `[Germany, Spain, Italy, Belgium, Switzerland]` **KG verification & connectivity check:** France is connected to the probes via the path `location.location.adjoin_s → location.adjoining_relationship.adjoins`. **Candidate acquisition:** All nodes connected by the same relation path are collected as country candidates: `['Germany', 'United Kingdom', 'Italy', ..., 'Bay of Biscay', 'Dover']` (19 nodes in total). |\n| **Second Round** | **Baseline Method:** Retrieves relations associated with the previous round's nodes, randomly selects a subset, and uses an LLM for pruning. **Our Method:** **Triplet to parse:** `(country, contains, airport)` **Probe generation:** `[Heathrow Airport, Charles de Gaulle Airport, Frankfurt Airport, Schiphol Airport, Munich Airport]` **KG verification & connectivity check:** The nodes from the previous round are connected to the probes via `location.location.contains`. **Candidate acquisition:** 15,184 nodes connected by the same relation path are collected as airport candidates. |\n| **Third Round** | **Baseline Method:** Retrieves relations associated with the previous round's nodes and uses an LLM for pruning. **Our Method:** **Triplet to parse:** `(airport, serves, Nijmegen)` **Credible Knowledge Disambiguation:** Triggered because Nijmegen is a specific entity. **Disambiguation process:** Among the 15,184 candidate nodes from the previous round, only Weeze Airport is connected to Nijmegen via `aviation.airport.serves`. All other unconnected nodes are discarded. |\n| **Knowledge Path** | `('France', 'location.location.adjoin_s→location.adjoining_relationship.adjoins', 'Germany')``('Germany', 'location.location.contains', 'Weeze Airport')``('Weeze Airport', 'aviation.airport.serves', 'Nijmegen')` |\n| **Answer** | Germany |\n\nIn this case, the underlying subgraph is extremely dense and noisy. The first reasoning step involves 498 distinct relations from *France*—making full pruning computationally prohibitive, while random sampling (as used by baselines) risks missing the correct relation entirely.\n\nOur method circumvents this by leveraging the LLM’s internal knowledge to generate targeted probes (e.g., neighboring countries like *Germany*, *Belgium*), which rapidly identify the unique relevant relation path (`location.location.adjoin_s → ...`) without exhaustive search. Since only one valid relation emerges, semantic consistency filtering is unnecessary.\n\nSimilarly, in the second round, probe-based retrieval efficiently isolates the correct relation linking candidate countries to airports. Finally, our **Credible Knowledge Disambiguation** mechanism exploits KG connectivity to filter 15,184 airport candidates down to a single node—*Weeze Airport*—that actually serves *Nijmegen*. Among all country candidates from Round 1, only *Germany* connects to *Weeze Airport*, yielding the correct answer."}}, "id": "sGwmRjc6QC", "forum": "9235Gzvgiq", "replyto": "9235Gzvgiq", "signatures": ["ICLR.cc/2026/Conference/Submission25141/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25141/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25141/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763659530003, "cdate": 1763659530003, "tmdate": 1763659530003, "mdate": 1763659530003, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Dynamic Knowledge Probes (DKP), a novel framework for robust collaboration between Large Language Models (LLMs) and Knowledge Graphs (KGs) under conditions of graph incompleteness. Unlike conventional KG-authoritative methods, which strictly rely on the KG as the sole source of truth, DKP repositions the LLM as an active knowledge probe generator. DKP bridges the gap between question complexity and knowledge incompleteness by: (1) Guided KG Exploration via LLM Probes: Using lightweight, LLM-generated entities to steer KG traversal toward semantically relevant subgraphs. (2) Trust-Aware Bridging: Performing existence and necessity checks to safely integrate LLM-inferred entities when KGs are incomplete. (3) Constraint-Based Disambiguation: Enforcing cross-triple consistency via KG structure for credible nodes and LLM validation for low-confidence ones. Experiments on WebQSP and CWQ show that DKP achieves state-of-the-art accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The paper proposes a clear paradigm shift: instead of treating the LLM as a passive query generator, it becomes an active collaborator capable of proposing missing links under verifiable control. This insight directly addresses a long-standing bottleneck of KG incompleteness. The proposed Guidance Graph of Thought (GGoT) is a coherent, interpretable framework. It cleanly separates reasoning stages (triplet resolution, probing, bridging), allowing transparent integration of KG and LLM modules."}, "weaknesses": {"value": "1. Missing highly relevant literature. The paper identifies one key bottleneck in LLM reasoning, that the internal static knowledge and external knowledge base can be both sparse, which is discussed in [1]. The proposed retrieval method that focuses on semantically similar subgraphs and use LLM internal knowledge to bridge the knowledge gap also overlaps with [1]. \n\n2. Too much white space in the body of the paper.\n\n3. See Questions for other technical weakness. \n\n[1] GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation"}, "questions": {"value": "1. Could the authors provide a detailed comparison with [1]? In terms of methodology and empirical results? \n\n2. How sensitive the proposed method is to different sparsities of KG? It is necessary to evaluate the performance of the proposed method on KGs with different sparcities (edge ratio), to prove its effectiveness in \"BRIDGING GAPS\" between question complexity and knowledge incompleteness.\n\n3. Does the proposed method generalize to different domains? As the proposed method relies highly on LLM-generated probe, its beneficial to test its generalizability to corner domains (scientific for example) where the  model's internal knowledge is even more limited, especially considering the fact that \"switching from LLaMA3-8B to DeepSeek-V3 improves partial matching by 20%\nand more than doubles complete matching on WebQSP\". \n\n4. The experiment setup is not consistent with the main claim about bridging gaps between incomplete KG and complex QA. It does not make sense to compare partial or complete gold answer retrieval. Instead, comparison should be focused on how the competing baselines deal with incomplete KG and conduct correct reasoning to answer the question that the gold context is not accessible.\n\n\n[1] GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "YPFC7fCMdA", "forum": "9235Gzvgiq", "replyto": "9235Gzvgiq", "signatures": ["ICLR.cc/2026/Conference/Submission25141/Reviewer_v2w7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25141/Reviewer_v2w7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25141/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761952822016, "cdate": 1761952822016, "tmdate": 1762943342744, "mdate": 1762943342744, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents **Dynamic Knowledge Probes over a Guidance Graph-of-Thought (GGoT)** for **LLM–KG collaborative reasoning**. Starting from a structured “guidance graph” built from the question, the method iteratively converts **generic** entities to **specific** ones (Type II→Type I triples) using the LLM’s parametric knowledge, while interleaving **KG verification**. The key contributions are: (i) **knowledge probes**—LLM-suggested candidate entities that guide local KG exploration; (ii) **trust-aware bridging**—existence and necessity checks that temporarily insert LLM-derived entities/edges when the KG appears incomplete, with later pruning if they fail to connect; and (iii) **constraint-based disambiguation** across triples to enforce consistency (preferring KG structural checks and reserving LLM only for low-confidence “bridge” nodes). Experiments on **WebQSP** and **CWQ** (Freebase) show improvements over ToG/PoG/FiSKE/StructGPT and GG-explore in both partial and complete match; efficiency is comparable to or better than prior agents on WebQSP and slightly higher on CWQ; ablations highlight the benefit of trust-aware bridging and probes."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "* **Well-motivated robustness target.** Clearly identifies brittleness of KG-authoritative agents under incompleteness and proposes a principled collaboration scheme. \n* **Clean, extensible backbone.** GGoT’s fact-level interfaces decouple steps and make KG insertion points natural. \n* **Trust-aware bridging is explicit.** Existence/necessity checks and later pruning provide a defensible safety valve against hallucination. \n* **Empirical gains + ablations.** SOTA-level results on WebQSP/CWQ (esp. with DeepSeek-V3); efficiency roughly on par with strong agents; ablations on bridging/probes and “trusted subset” analysis."}, "weaknesses": {"value": "1. **Risk of evaluation conflation.** Temporary **edge insertion** effectively augments the KG with LLM knowledge; without strict auditing, improvements may partly reflect parametric recall rather than better KG reasoning. Authors should report **rates, locations, and impact** of bridging (how often temporary edges persist vs. get pruned; effect size per category). \n2. **LLM-dependent validators.** Semantic consistency filtering and low-confidence node validation rely on prompts (A5), which can be brittle and model-biased. A **KG-executability** or **type-constraint** signal would be a stronger arbiter than LLM scoring alone.  \n3. **Limited statistics.** Main tables omit **CIs/multi-seed**; given stochastic components, uncertainty should accompany all metrics and efficiency numbers. \n4. **Scope and generality.** Only Freebase (WebQSP/CWQ). No results on **Wikidata/DBpedia** or **text+KG** regimes, where aliasing and schema variance are larger. \n5. **Entity-linking details.** Starting-point discovery iterates EL and GGoT, but matching rules/ambiguity handling are under-specified; errors here could cascade. \n6. **Ablation interpretation.** Table 4 shows non-monotone cost/accuracy tradeoffs when removing single modules; more granular diagnostics (e.g., which question types benefit) would clarify interactions."}, "questions": {"value": "1. **Bridging audit.** Please report: fraction of questions where bridging is triggered; proportion of **temporary nodes/edges** that survive pruning; and accuracy deltas **with vs. without** those edges on the same items. \n2. **Validator alternatives.** Can you replace/augment LLM-based semantic filtering with **schema/type constraints**, **range/domain checks**, or **executed path validation**? Any accuracy drop if you remove LLM scoring in A5?  \n3. **Generality.** Any results or qualitative studies on **Wikidata** or **Freebase+Wikipedia** (text+KG) to assess robustness to aliasing and missing edges?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ENsAbCQDRM", "forum": "9235Gzvgiq", "replyto": "9235Gzvgiq", "signatures": ["ICLR.cc/2026/Conference/Submission25141/Reviewer_e5Aj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25141/Reviewer_e5Aj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25141/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762187367798, "cdate": 1762187367798, "tmdate": 1762943342557, "mdate": 1762943342557, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Dynamic Guidance Graph of Thought (D-GGoT), a framework that enables collaboration between LLMs and knowledge graphs (KGs) for multi-hop reasoning under graph incompleteness. Instead of letting the LLM generate full answers or relying solely on KG structure, D-GGoT decomposes the query into triple-level reasoning steps, allowing the LLM to suggest candidate entities/relations and verify them through trust-aware bridging and constraint-based disambiguation. The system dynamically discovers starting points when entity linking fails and iteratively refines generic triples into more specific ones. Experiments on WebQSP and ComplexWebQuestions (CWQ) show that D-GGoT achieves superior accuracy, particularly on multi-hop queries, while maintaining reasonable efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper clearly diagnoses the brittleness of KG-authoritative agents: one missing KG link can collapse the whole reasoning chain. This motivates letting LLMs “assist” rather than being fully suppressed. The Guidance Graph of Thought (GGoT) turns queries into triples with three specificity types and iteratively converts generic→specific, exposing a fact-level interface that interleaves KG verification without entangling prior textual rationales. This is a neat, extensible backbone. Three concrete collaboration mechanisms. (1) Guided KG exploration via LLM knowledge probes; (2) trust-aware bridging with existence/necessity checks; (3) cross-triple, constraint-based disambiguation that prefers KG structure for credible nodes. Together they operationalize “LLM assists KG” instead of replacing it."}, "weaknesses": {"value": "While the paper presents an interesting and well-motivated framework for integrating LLMs with knowledge graphs, several concerns remain regarding evaluation scope and methodological transparency:\n\n1. The experiments are primarily conducted on Freebase-based datasets (WebQSP, CWQ). To better demonstrate generality, the authors should include results or analyses on more widely used KGs such as Wikidata or DBpedia ideally with noisy or imperfect entity linking to assess robustness.\n\n2. The comparison table involves multiple base LLMs (e.g., GPT-3.5, DeepSeek, LLaMA3-8B). It would be clearer to group or standardize results by model family or size for consistent comparison.\n\n3. Several internal procedures—such as semantic consistency filtering, triple pruning, and relation validation—depend heavily on LLM responses. This reliance may introduce hallucination or alignment drift, potentially leading to incorrect triple acceptance. An empirical analysis or mitigation strategy for such hallucination errors would strengthen the paper.\n\n4. The paper does not report time, token, or computational cost compared to other baselines. Given that the proposed method includes multiple iterative calls and reasoning stages, an efficiency comparison is essential for assessing practical utility."}, "questions": {"value": "See weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "3gf6deCHgW", "forum": "9235Gzvgiq", "replyto": "9235Gzvgiq", "signatures": ["ICLR.cc/2026/Conference/Submission25141/Reviewer_9oaZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25141/Reviewer_9oaZ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25141/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762219253344, "cdate": 1762219253344, "tmdate": 1762943342254, "mdate": 1762943342254, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}