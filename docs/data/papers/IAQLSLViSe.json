{"id": "IAQLSLViSe", "number": 17915, "cdate": 1758281983229, "mdate": 1763731503641, "content": {"title": "Quan-dorcet: Tournament-Based One-vs-One Quantum Classification for Robust Single-Shot Inference", "abstract": "Quantum machine learning (QML) promises powerful classification capabilities, but suffers from fragile output encodings and high sampling demandsâ€”especially in multiclass settings. Traditional schemes such as one-hot and binary encoding either produce interpretable outputs too rarely or require many shots to achieve reliable predictions. We propose a decision aggregation framework for quantum multiclass classification based on round-robin tournament scoring. Each output qubit represents a binary comparison between class pairs, and the final prediction is determined by majority winsâ€”yielding a Condorcet-style winner when one exists. This structure improves both the resolvability and accuracy of single-shot predictions, outperforming standard encodings under few-shot conditions. Our method retains global entanglement while localizing decision tasks, enabling interpretable inference that remains reliable under intrinsic quantum randomness, without sacrificing expressivity. Empirical results show that this approach achieves high accuracy and interpretability with significantly fewer measurements, suggesting a promising direction for future quantum classifiers.", "tldr": "Using round-robin tournaments as an output encoding increases the likelihood of a single-shot from a QML model being accurate.", "keywords": ["quantum", "classification", "tournaments", "qml", "encoding"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/da46c9b0b664fd9aaf9e54d1fb9a148502d7dea9.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces a novel output encoding technique for QML in multi-class classification tasks. Specifically, the authors propose a decision aggregation framework based on round-robin tournament scoring, offering an alternative to traditional encoding schemes such as Gray and binary encoding. A key feature of the proposed approach is its reliance on one-shot encoding, where a single measurement is used to determine the class label, rather than computing expectations over multiple shots. This design aligns well with practical constraints in QML, contributing to more efficient inference.\nIn addition to the theoretical framework, the paper presents empirical evaluations across multiple datasets, demonstrating that the proposed method consistently outperforms existing encoding strategies."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Reducing the sample complexity or shot complexity of QML for multiclass problems is an interesting and important problem that this paper addresses. The numerical experiments clearly demonstrate that the proposed method outperforms existing approaches for output encoding. Overall, the paper is relatively well written and easy to follow"}, "weaknesses": {"value": "The paper focuses on a single-shot approach, which is nice. But I wonder if a comparison with a few-shot measurements would make sense and give improvements. Essentially, a comprehensive discussion on the number of measurement shots for output encoding seems lacking in this paper."}, "questions": {"value": "Can you provide any theoretical justification comparing the single shot with the fixed multi-shot approach?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0Y08y2CLjF", "forum": "IAQLSLViSe", "replyto": "IAQLSLViSe", "signatures": ["ICLR.cc/2026/Conference/Submission17915/Reviewer_AhDi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17915/Reviewer_AhDi"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762186902522, "cdate": 1762186902522, "tmdate": 1762927732932, "mdate": 1762927732932, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a new decision aggregation framework, QUAN-DORCET to address the critical sampling bottleneck and fragile output encodings in multiclass quantum machine learning under limited measurement budgets, especially for single-shot inference. The main contribution is the replacement of traditional global output schemes with a round-robin tournament structure where each output qubit performs a binary comparison between a pair of classes. The final prediction is a Condorcet-style winner determined by majority wins across all pairwise comparisons which theoretically converges to full resolvability as the number of classes increases. The authors also develop a unique, differentiable training method that embeds the pairwise comparisons into a continuous simplex using a symmetric cross-entropy loss and empirically demonstrate that this approach significantly improves both shot resolvability and accuracy compared to baselines in few-shot regimes."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper introducing a novel output encoding for VQC based on external political/tournament theory (Condorcet's criterion) to solve the intrinsic quantum problem of low single-shot resolvability. The core innovation is leveraging the statistical robustness of the tournament structure, which, unlike one-hot encoding does not suffer from exponentially vanishing resolvability and, unlike binary encoding is less susceptible to single-bit noise causing large semantic misclassifications. The quality of the work is substantiated by the comprehensive theoretical analysis (Section 3.2) and the technical development of a non-trivial, end-to-end differentiable training procedure that successfully maps the $K(K-1)/2$ binary outputs to a continuous simplex for gradient-based optimization. The writing is clear and provides sound motivation explicitly highlighting the trade-offs of all incumbent encoding methods in Table 1."}, "weaknesses": {"value": "The most significant weakness is the fundamental issue of quadratic scaling in the required number of qubits as $K$ classes require $K(K-1)/2$ output qubits meaning the approach is constrained to small class counts (e.g., $K\\le6$ in the experiments) and cannot scale to large classification problems on near-term hardware. While the method aims for robustness on real-world devices, all model training and performance evaluations are conducted exclusively under noiseless simulation. Also, a critical and missing piece of the empirical quality is a systematic study of how the Condorcet-style aggregation handles realistic hardware noise (e.g., bit-flip or depolarizing channels) in comparison to the binary/Gray codes it claims to outperform in terms of noise robustness. Overall, the paper should address the potential for Condorcet cycles (tournament paradox) in the measured results as the existence and frequency of these cycles would determine the fundamental practical limit of the method's resolvability under non-ideal (noisy) conditions."}, "questions": {"value": "A key question for the authors concerns the empirical analysis of the Condorcet paradox,\n\na) Could the authors provide data on the frequency of non-unique winners (cycles or ties) in the tournament aggregation? As this is a vital component of the non-resolvable shots and have they considered using a tie-breaking rule or a ranking method (like the Schulze method) to maximize the practical resolvability? \n\nb) Given that the robustness to bit-level noise is a central claim against binary encodings, the authors should perform an actionable study by including results for all encodings under a simulated hardware noise model (e.g., $1\\%$ depolarizing noise on the output measurement qubits) to confirm the robustness advantage in the setting where it is most needed. As a suggestion to overcome the $\\mathcal{O}(K^2)$ qubit requirement, have the authors explored an alternative sparse tournament structure, such as a hierarchical elimination or a Tournament-of-Champions (ToC) scheme, and can they provide an analysis on the trade-off between the decreased resource cost and the expected decrease in single-shot resolvability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MYdUBEbFt0", "forum": "IAQLSLViSe", "replyto": "IAQLSLViSe", "signatures": ["ICLR.cc/2026/Conference/Submission17915/Reviewer_BZ68"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17915/Reviewer_BZ68"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762258859436, "cdate": 1762258859436, "tmdate": 1762927732479, "mdate": 1762927732479, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Statement"}, "comment": {"value": "**Scope Clarification**\nOur work does not claim a breakthrough for NISQ hardware. All results assume best-case conditions under noiseless simulation, applied equally to all methods. This isolates algorithmic behavior from hardware-specific noise and focuses on the theoretical scaling properties of output encodings.\nWe explicitly assume a future outlook where quantum computers continue to grow in qubit countâ€”similar to historical trendsâ€”and where noise either remains constant or decreases through error correction or hardware improvements. These assumptions are standard in theoretical QML research and are clearly stated in the paper. We have discovered and corrected several statements in the manuscript that may have given the wrong impression in this regard. We offer to provide our notes about these changes upon request to keep this response concise, noting that OpenReview provides an even more thorough pdf-diff. \n\n**Noise and Hardware Robustness**\nWe distinguish between two notions of noise in quantum computing: (i) intrinsic quantum randomness, which arises from the probabilistic nature of measurement and motivates our focus on single-shot inference and resolvability, and (ii) hardware-level noise, such as decoherence, thermal fluctuations, and cross-talk, which stem from the physical limitations of current devices. Our contributions address (i) under idealized conditions while (ii) remains an open challenge and is outside the scope of this work. We clarify this as best as possible in the revised manuscript.\n\nWe acknowledge that robustness to hardware noise is an open challenge. While Appendix A.1.2 includes inference under IBM Qiskit noise models, a full systematic study of noise resilience is beyond the scope of this work. Importantly, our claims about tournament encoding hold under worst-case tournament conditions and do not rely on noise assumptions.\nRegarding Condorcet cycles: theory guarantees that the probability of a unique winner converges to unity as $K \\to \\infty$ (Malinovsky \\& Moon, 2024). We view deeper exploration of tournament theoryâ€”such as tie-breaking strategies and cycle analysisâ€”as an exciting extension for future work. Given the breadth of this field, a comprehensive treatment is beyond the scope of a single paper, but we will highlight these directions explicitly in the revision.\n\n**Quadratic vs Exponential Scaling**\nWe freely acknowledge that tournament encoding requires $O(K^2)$ qubits, which is a limitation for large $K$. However, this polynomial growth is fundamentally different from the exponential shot requirements inherent to one-hot encoding and the irreducible sampling overhead of expectation-based methods.\nOur contribution introduces a complexity trade-off: quadratic resource scaling (potentially reducible via sparse tournaments or hierarchical schemes, etc.) for tournament inference versus exponential sampling cost growth for the alternatives (irreducible). No one in the field can make definitive claims about whether qubit count or shot requirements will dominate in the future, but we argue that reducible > irreducible and quadratic < exponential, making this a worthwhile research direction.\nWe will add a resource scaling analysis and explicitly frame this trade-off in the revision.\n\n**Hardware Experiments**\nWe respect the request for real-device experiments but note that training thousands of PQCs on NISQ hardware is computationally expensive and ethically questionable given the resource cost (e.g., helium lossage) for toy datasets. Our primary contributionâ€”the theoretical link between tournament winners and shot resolvabilityâ€”would be obscured by hardware noise, which affects all methods equally.\nWe will clarify this rationale and emphasize that hardware validation is future work.\n\n**Realism, Imbalance, and Overlap**\n\n_Class Imbalance \\& Semantic Overlap:_ We agree that imbalance and overlapping class boundaries can influence tournament aggregation. These effects are not unique to quantum classifiersâ€”they also affect classical one-vs-one frameworks. Our current study assumes balanced datasets to evaluate encoding strategies under controlled conditions. We will explicitly state this assumption and note that extending the framework to handle imbalance (e.g., weighted voting, tie-breaking rules) and ambiguous boundaries is an important direction for future work.\n\n_Real-World Scaling:_ We do not claim applicability to large-scale real-world datasets or NISQ hardware at this stage. All experiments use standard benchmark subsets (MNIST Digits and FashionMNIST) to isolate algorithmic behavior without conflating results with hardware limitations or dataset-specific complexities. Applying this method to high-dimensional, large-class datasets or real hardware requires addressing quadratic resource scaling and noise resilienceâ€”both acknowledged limitations in Section 5. We will highlight these constraints more prominently and frame them as future research directions."}}, "id": "62RzfDmcBJ", "forum": "IAQLSLViSe", "replyto": "IAQLSLViSe", "signatures": ["ICLR.cc/2026/Conference/Submission17915/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17915/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17915/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763730663045, "cdate": 1763730663045, "tmdate": 1763730663045, "mdate": 1763730663045, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The papr introduces \"Quan-dorcet\" a round-robin tournament aggregation technique for multiclass quantum classification. Quan-dorcet targets the fragility of existing output encodings in QML, specifically under single.few-shot measurement constraints. In the following I provide the strengths and weaknesses of the paper."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. **Addressing an important bottleneck:** Authors address an important bottleneck in current QML architectures which is poor reliability and the requirement of high shot.\n\n2. **The encoding** The tournament is well motivated. Going beyond ad hoc output mappings and leveraging robust statistical voting mechanisms.\n\n3. **Comparison** Empirical comparisons against standard output encodings (one-hot, binary, Gray) on quantum circuits for MNIST digits/fashion datasets are extensive, covering multiple circuit types and parameter regimes.\n\n4. **Code availability** The authors have publicly released their code, demonstrating a commitment to open-source practices and enabling reproducibility."}, "weaknesses": {"value": "## **Quadratic resource scaling:** \nThe method requires a number of quantum wires/qubits that scales quadratically with the number of classes: for K classes ~K(K-1)/2, pairwise comparisons are encoded. This makes the approach impractical for even moderate sized output spaces and restricts applicability to small problems. The text neither addresses this limitation nor empirical studies on the maximal class count achievable on actual hardware.\n\n## **Lacking QPU execution:** \nAll the main experiments are performed under noiseless simulation; only limited inference ablations are reported using noise models from IBM Qiskit. There is no demonstration of end-to-end training or inference on real quantum processors. The authors should provide a detail characterization of the Quan-dorce's robustness under device noise and decoherence effects.\n\n## **Scalability:** \nThe computational cost is high around \"100 kCPU-hours\". As stated by the authors, the approach necessitated \"unforeseen compute limitations\" that prevented reporting results for all circuit blocks and larger K in time for the submission. I believe this demonstrates not only scalability barriers for NISQ devices but also for classical simulation pipelines.\n\n## **Lacking analysis of class imbalance and semantic overlap:** \nThe framework does not explore: \n- Class imbalance, where some classes are much less represented than others, can severely impair prediction accuracy because minority classes may rarely win pairwise matchup. I believe this can lead to majority-win bias and poor generalization. \n- Semantic overlap, where different classes share similar characteristics, can lead to  ambiguous or non-separable boundaries.\n\n## **Clarity:** \nThe manuscript is technically sound but sometimes impenetrable to non-specialists.  Some claims about tournament theory and Condorcet aggregation would benefit from clearer intuitive explanations and more concrete worked examples. \n\n## **Lack of references** \nIn introduction: \n- The second sentence does not provide any reference. Such as the claim that PQC used for encoding input data. \n- The term \"tunable gate operations\" is vague. \n- The sentence `practical implementations face a significant challenge in the form of a sampling bottleneck` neither provide any justification why this bottleneck appears nor it provide any relevant information. \n- The claim `the proportion of resolvable outputs.. vanishes exponentially with the number of classes, making inference increasingly unreliable` is made without any references or explanation. I encourage the author should provide more references and explanations in the introduction."}, "questions": {"value": "As noted in the weaknesses above, I would like to pose the following questions and suggestions to the authors:\n\n## **Resource Scaling:**  \n   - Can you propose, analyze, or empirically test methods to reduce the quadratic scaling of qubit requirements? \n- For example, could some pairwise decisions be encoded or aggregated classically, or can hybrid output encodings balance accuracy with qubit economy? \n- What is the largest class count (K) for which the method remains practical on current or near-term hardware?\n\n## **Quantum hardware execution:**  \n   - Do you have plans to implement the tournament method on real quantum processors, and if so, what are the expected resource bottlenecks and noise impacts? \n- Could you provide results, or at least simulated characterizations, for your method under realistic device noise and decoherence, especially regarding accuracy and resolvability?\n\n## **Scalability:**  \n   - Can you clarify the extent of computational resources required across architectures, and suggest optimizations to the classical simulation pipeline? \n- What are the directions for scaling up your method on either quantum or classical backends?\n\n## **Class Imbalance and semantic overlap:**  \n   - How does your framework handle class imbalance, where some classes are underrepresented and risk being overlooked in majority voting? \n- Could you design experiments with imbalanced or overlapping class distributions, and report rates of ties and ambiguous predictions (such as `Condorcet cycles`)?\n\n## **Clarity:**  \n   Can you expand the descriptions of tournament theory and Condorcet mechanisms with visual example (e.g., for a small 3-class case)?\n\n## **References:**  \n   Can you add more references to support the foundational claims in the introduction, especially regarding PQC input encoding, sampling bottlenecks, and exponential validity decay with the number of classes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NDJQs8ka9C", "forum": "IAQLSLViSe", "replyto": "IAQLSLViSe", "signatures": ["ICLR.cc/2026/Conference/Submission17915/Reviewer_JMzA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17915/Reviewer_JMzA"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762337565172, "cdate": 1762337565172, "tmdate": 1762927732172, "mdate": 1762927732172, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel output encoding framework, \"Quan-Dorcet,\" for quantum multiclass classification. The method is based on pairwise round-robin tournament comparisons, aiming to improve the accuracy and \"resolvability\" of single-shot and few-shot inference. The authors introduce \"shot resolvability\" as a key metric and demonstrate through simulation that their method outperforms one-hot and binary encodings for a small number of classes (Kâ‰¤6)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses the challenge of multiclass classification in quantum machine learning (QML), particularly the issues of fragile output encodings and high sampling demands under few-shot or single-shot inference. The authors propose a tournament-based one-vs-one encoding scheme wherein each qubit corresponds to a binary comparison between a pair of classes; class prediction is obtained via a round-robin vote (Condorcet winner) across all pairwise outcomes. This decouples the multiclass output into many simpler binary decisions embedded within a shared entangled quantum state, which the authors argue improves â€œshot resolvabilityâ€ (probability a single measurement yields a valid class) and accuracy under measurement-limited settings. Empirical results demonstrate that the scheme outperforms standard one-hot or binary encoding architectures in few-shot/single-shot regimes, suggesting this paradigm as a robust path for quantum classifiers with fewer measurements."}, "weaknesses": {"value": "Scalability Problem: This is the most critical issue. As the authors admit in Section 5 (\"Limitations\"), the required number of qubits (wires) $W$ scales quadratically with the number of classes $K$ ($W = \\binom{K}{2} = K(K-1)/2$).\n\nImpact on Practicality: This makes the method practically infeasible. While binary encoding requires only $\\lceil \\log_2 K \\rceil$ qubits, the proposed method requires 45 qubits for $K=10$ and nearly 5,000 qubits for $K=100$. This is unattainable on near-term (or even mid-term) quantum hardware.\n\nPoor Trade-off: The paper claims to solve the \"sampling bottleneck\" but introduces a far more severe \"qubit resource bottleneck.\" This trade-off (exchanging sampling efficiency for an exponentially increasing qubit requirement) is unacceptable in practice.\n\nIncomplete Experiments: As noted in the footnotes of Table 2 and Table 3, the authors admit that \"Due to unforeseen compute limitations,\" the results for $K=6$ are incomplete, tested on only one circuit, and that the rest \"will be ready by rebuttal period.\" This indicates the submission is incomplete work."}, "questions": {"value": "While this contribution is creative and potentially impactful, several limitations and open concerns remain:\n\n1. Limited demonstration of practical quantum advantage\n\nThe experiments, while promising, appear to be simulation-based (no demonstrated real quantum hardware results). Thus, real-world factors (noise, decoherence, measurement error, circuit overhead) are not fully addressed.\n\nThe improvement in â€œshot resolvabilityâ€ is compelling, but it remains unclear how that metric translates into end-to-end system performance, especially when scaling to larger class sets or higher dimensional inputs.\n\n2. Scalability issues not thoroughly addressed\n\nFor  ð¾ classes, one-vs-one induces  K*(K-1)/2 binary comparisons/qubits (or circuits). The paper should more clearly analyse the resource scaling (qubits, gates, measurement overhead) for large ð¾, and whether the tournament cost outweighs encoding benefits.\n\nThe assumption that a unique Condorcet winner will emerge reliably may break down in practice under noisy or ambiguous class boundaries; the authors should discuss scenarios where majority voting may fail or require tie-break strategies.\n\n3. Baseline comparisons and alternative encodings\n\nAlthough one-hot and binary encodings are compared, more recent and sophisticated quantum multiclass classifier encoding schemes (e.g., amplitude encoding, mixedâ€state discriminators) are not deeply benchmarked. Without comparison to strong state-of-the-art quantum multiclass methods, the improvement claim is less convincing.\n\nMoreover, many classical multiclass frameworks (ensemble binary classifiers, one-vs-one classical SVMs) employ similar architectural breakdowns; a comparison of quantum vs classical one-vs-one paradigms would strengthen significance.\n\n4. Theoretical justification of single-shot improvements\n\nThe notion of â€œshot resolvabilityâ€ is interesting but currently heuristic. A deeper theoretical analysis of how measuring fewer shots yields reliable class output (given quantum measurement statistics, error rates) would improve confidence.\n\nAlso, the impact of entanglement and shared statewide encoding on error propagation among the binary comparators is not fully addressed.\n\n5. Application and realism of datasets/inputs\n\nThe datasets used, while unspecified here in detail, likely involve small-scale toy problems under simulation. It remains unclear how the method performs on large-input real-world classification tasks (e.g., image datasets with many classes and high dimensionality).\n\nThe authors should discuss how measurement budget, class imbalance, noise, and decoherence would influence performance in near-term quantum devices.\n\n**Relevant References for Inclusion**\n\nTo strengthen the literature context and demonstrate awareness of related work, the authors should consider citing the following:\n\nDu, Y., Yang, Y., Hsieh, M.-H., & Tao, D. (2023). Problem-Dependent Power of Quantum Neural Networks on Multi-Class Classification. Phys. Rev. Lett. 131, 140601. \n\nBokhan, D., Mastiukova, A. S., Boev, A. S., Trubnikov, D. N., & Fedorov, A. K. (2022). Multiclass classification using quantum convolutional neural networks with hybrid quantum-classical learning. arXiv:2203.15368. \n\nUseche, D. H., Quiroga-Sandoval, S., Molina, S. L., Vargas-CalderÃ³n, V., Ardila-GarcÃ­a, J. E., & GonzÃ¡lez, F. A. (2025). Quantum generative classification with mixed states. arXiv:2502.19970. \n\nDelilbasic, A., Le Saux, B., Riedel, M., Michielsen, K., & Cavallaro, G. (2023). A Single-Step Multiclass SVM based on Quantum Annealing for Remote Sensing Data Classification. arXiv:2303.11705. \n\nCruzeiro, E. Z., De Mol, C., Massar, S., & Pironio, S. (2023). Quantum-inspired classification based on quantum state discrimination. arXiv:2303.15353. \n\nRiaz, F., Abdulla, S., Suzuki, H., Ganguly, S., Deo, R. C., & Hopkins, S. (2023). Accurate Image Multi-Class Classification Neural Network Approaches including quantum variations. Sensors, 23(5):2753."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dDSWd7puly", "forum": "IAQLSLViSe", "replyto": "IAQLSLViSe", "signatures": ["ICLR.cc/2026/Conference/Submission17915/Reviewer_XFm6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17915/Reviewer_XFm6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17915/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762467368346, "cdate": 1762467368346, "tmdate": 1762927731726, "mdate": 1762927731726, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}