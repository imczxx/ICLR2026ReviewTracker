{"id": "4VW9HVCRw0", "number": 8295, "cdate": 1758077779876, "mdate": 1759897793735, "content": {"title": "TOUCH: Text-guided Controllable Generation of Free-Form Hand-Object Interactions", "abstract": "Hand-object interaction (HOI) is fundamental for humans to express intent. Existing HOI generation research is predominantly confined to fixed grasping patterns, where control is tied to physical priors such as force closure or generic intent instructions, even when expressed through elaborate language. Such an overly general conditioning imposes a strong inductive bias for stable grasps, thus failing to capture the diversity of daily HOI. To address these limitations, we introduce $\\textbf{Free-Form HOI Generation}$, which aims to generate controllable, diverse, and physically plausible HOI conditioned on fine-grained intent, extending HOI from grasping to free-form interactions, like pushing, poking, and rotating. To support this task, we construct $\\textbf{WildO2}$, an in-the-wild diverse 3D HOI dataset, which includes diverse HOI derived from internet videos. Specifically, it contains 4.4k unique interactions across 92 intents and 403 object categories, each with detailed semantic annotations. Building on this dataset, we propose $\\textbf{TOUCH}$, a three-stage framework centered on a multi-level diffusion model that facilitates fine-grained semantic control to generate versatile hand poses beyond grasping priors. This process leverages explicit contact modeling for conditioning and is subsequently refined with contact consistency and physical constraints to ensure realism. Comprehensive experiments demonstrate our method's ability to generate controllable, diverse, and physically plausible hand interactions representative of daily activities.", "tldr": "We extend hand-object interaction generation beyond simple grasping to a diverse range of controllable manners, such as pushing, poking, twisting, and rolling.", "keywords": ["hand-object interaction", "3D generation"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e69b5f726059ea85572c54baee684de755845a8b.pdf", "supplementary_material": "/attachment/2a659796a248decbc83b6f0530ad09b12fd31c52.zip"}, "replies": [{"content": {"summary": {"value": "This paper tackles free-form HOI generation, pushing the field beyond the standard grasp-centric paradigm. The authors introduce two main contributions: WildO2, a novel 3D HOI dataset reconstructed from in-the-wild videos, and TOUCH, a three-stage diffusion framework designed to synthesize these diverse interactions from fine-grained text prompts. The work is solid, and the results are impressive."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1.\tThe formulation of the \"Free-Form HOI\" task is a forward-looking contribution. It moves the community beyond the well-trodden \"grasping\" paradigm toward more realistic and diverse interactions.\n2.\tThe proposed data pipeline for reconstructing 3D HOIs from monocular videos is effective. Creating an in-the-wild 3D dataset like WildO2 is a valuable asset for the community.\n3.\tThe TOUCH framework is technically sound. Its three-stage approach is a logical decomposition of the problem, and the coarse-to-fine conditioning is an effective strategy for fine-grained text control."}, "weaknesses": {"value": "1.\tThe dataset pipeline's quality is naturally capped by its upstream components (e.g., image-to-3D models, SAM2). Existing 3D generation methods are less used for in-the-wild, low-resolution generation, and a discussion on how to improve the accuracy of the dataset synthesis method in the future would be beneficial.\n2.\tWildO2 excels in interaction diversity. However, its absolute scale is understandably smaller than that of massive lab datasets (e.g., Gigahands). \n3.\tThe method's generalizability needs more validation. Adding experiments on other datasets/domains would strengthen the paper's claims, e.g., qualitative results on OakInk and tests on open-set object or CAD models from sources like Objaverse.\n4.\tThe 4/4 layer split for coarse-to-fine conditioning appears empirical. An ablation study is needed to justify this specific architectural choice against other alternatives (e.g., 2/6)."}, "questions": {"value": "1.\tThe reconstruction failure analysis for the dataset is great. Could you also show some typical generation failures of the TOUCH model itself w.r.t. certain objects or text prompts?\n2.\tWhat is the inference speed of the full pipeline? How much overhead does the TTA add, and is it critical for performance?\n3.\tThere is an incomplete citation for Ye et al. (L698) and a missing space in 'WildO2that' (L99)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "FtQR73100l", "forum": "4VW9HVCRw0", "replyto": "4VW9HVCRw0", "signatures": ["ICLR.cc/2026/Conference/Submission8295/Reviewer_yAMZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8295/Reviewer_yAMZ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8295/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761835143346, "cdate": 1761835143346, "tmdate": 1762920225462, "mdate": 1762920225462, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses a critical data bottleneck in the hand–object interaction (HOI) domain — the lack of high-quality 3D datasets capturing free-form, non-grasping interactions. While existing datasets focus almost exclusively on structured grasping scenarios collected in laboratory settings, this work proposes WildO2, an in-the-wild 3D HOI dataset that covers diverse everyday manipulations such as pushing, poking, turning, and rotating. WildO2 is automatically constructed from internet videos using an object-only to interaction (O2HOI) frame pairing pipeline, followed by multi-stage 3D reconstruction, contact optimization, and text-based semantic annotation via vision–language models.\n\nBuilding on this dataset, the authors introduce TOUCH, a three-stage text-guided framework for controllable HOI generation. TOUCH integrates (1) explicit contact map prediction, (2) a multi-level conditioned diffusion model that fuses coarse-to-fine text and geometric cues, and (3) a physical refinement module ensuring realistic contact and alignment. Experiments show that TOUCH generates diverse, semantically aligned, and physically plausible free-form interactions, outperforming prior baselines (e.g., ContactGen, Text2HOI) in contact accuracy, plausibility, and diversity metrics."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper’s WildO2 dataset is a major technical contribution, featuring an well-designed and automated data generation pipeline. This pipeline successfully integrate multi-stage object–hand reconstruction, camera alignment, and physical contact refinement, resulting in high-quality 3D annotations and realistic HOI samples. The inclusion of Descriptive Synthetic Captions (DSCs), generated and verified through vision–language models, is particularly valuable for enabling text-guided interaction synthesis tasks. \n\nThe dataset specifically targets free-form, non-grasping hand–object interactions—a type of everyday manipulation that is pervasive in the real world but consistently overlooked in prior HOI datasets, which mostly emphasize stable grasping or object holding.  the work fills a clear research gap and opens new possibilities for studying intent-driven, semantically controllable HOI generation in both computer vision and embodied AI \n\nthe proposed TOUCH framework (contact → pose → refinement) follows a fairly typical architecture within current interaction synthesis pipelines, it is well-implemented and well-validated through both quantitative and qualitative experiments. Its role here effectively complements the dataset."}, "weaknesses": {"value": "The WildO2 dataset primarily focuses on rigid objects, while articulated or deformable objects (e.g., clothes, plastic bags, napkins) are absent. These categories are often the most likely to trigger free-form and dynamic hand–object interactions in everyday activities. Although using rigid objects is acceptable for building an initial benchmark, this omission limits the dataset’s ability to fully capture the spectrum of natural, unconstrained human–object interactions.\n\nDespite the paper’s aim to model free-form interactions, the proposed TOUCH framework largely inherits design principles from grasp-based synthesis—treating contact as a quasi-static grasping state. While this formulation is reasonable for static contact modeling, free-form interactions are inherently motion-centric, and thus would benefit from a dynamic or sequence-level synthesis perspective rather than purely static pose generation.\n\nThe use of the term data generation sec 3.2 may be somewhat misleading, as the proposed pipeline mainly performs 3D reconstruction and alignment rather than generative modeling. Although the inclusion of LLM-generated Descriptive Synthetic Captions (DSCs) introduces a generative component, the overall process is better described as a data reconstruction or annotation pipeline to avoid misleading ."}, "questions": {"value": "What is the average processing time per frame in the data generation pipeline for WildO2? It would be helpful to know the computational cost and scalability of the proposed reconstruction and alignment procedure.\n\n In the WildO2 dataset, how were the object categories and action types selected? Do the defined free-form action labels correspond to common patterns of real-world human activity, or were they primarily derived from the source video dataset?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6TrcBxtL2p", "forum": "4VW9HVCRw0", "replyto": "4VW9HVCRw0", "signatures": ["ICLR.cc/2026/Conference/Submission8295/Reviewer_TWqj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8295/Reviewer_TWqj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8295/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972928405, "cdate": 1761972928405, "tmdate": 1762920224911, "mdate": 1762920224911, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Free-Form HOI Generation, emphasizing controllable and semantically rich interaction synthesis beyond grasping. In addition, the paper proposes TOUCH, a three-stage framework for text-guided, controllable generation of free-form hand-object interactions (HOI). The multi-level diffusion framework is conditioned on fine-grained text and contact maps, integrating global and local semantic cues for physically plausible synthesis. Finally, the paper introduces WildO2, a large in-the-wild 3D HOI dataset (4.4k interactions, 92 intents, 403 objects) from internet videos via an automated O2HOI reconstruction pipeline. Experiments show the advantage of TOUCH over baselines (ContactGen, Text2HOI) in contact accuracy, plausibility, and semantic alignment."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper addresses free-form HOI generation with fine-grained textual control. The three-stage design effectively combines semantics, geometry, and physics.\n\n2. Comprehensive dataset: WildO2 offers unprecedented diversity, with detailed contact annotations and high-quality reconstructions from in-the-wild videos.\n\n3. Strong quantitative and qualitative performance: improvements over state-of-the-art HOI generation baselines across multiple metrics.\n\n4. Clear ablations and insightful analyses: The impact of contact maps, coarse/fine text, and physical consistency is systematically evaluated."}, "weaknesses": {"value": "1. Static generation limitation: TOUCH focuses on single-frame poses; temporal dynamics (motion continuity, causality) are left for future work.\n\n2. Dataset scale and noise: Although diverse, WildO2 (4.4k samples) remains smaller, and in-the-wild reconstruction errors (≈45% failure rate) suggest potential biases.\n\n3. Comparisons could be expanded: While ContactGen and Text2HOI are solid baselines, comparisons with other text-conditioned 3D diffusion or affordance models (e.g., DiffH2O, Nl2Contact) would strengthen positioning.\n\n4. Ablations on language encoder: The Qwen-7B module shows gains, but results for alternative encoders (e.g., CLIP, BERT) are only briefly summarized. An analysis of semantic faithfulness could be better.\n\n5. Limited discussion on cross-domain generalization: It is unclear how the model generalizes to unseen object categories or out-of-distribution verbs beyond the 92 labeled intents."}, "questions": {"value": "1. How does TOUCH handle ambiguous or conflicting textual intents (e.g., “loosely hold” vs. “grasp tightly”)?\n\n2. What about the generalization to unseen object categories or verbs in WildO2?\n\n3. Could the refinement module be extended to temporal HOI (e.g., multi-frame optimization)?\n\n4. For dataset details, will WildO2 include the intermediate 2D-3D alignment pipeline and failure cases?\n\n5. How does the model behave when the text omits contact information (e.g., only “push the cup”)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TS27beVHEB", "forum": "4VW9HVCRw0", "replyto": "4VW9HVCRw0", "signatures": ["ICLR.cc/2026/Conference/Submission8295/Reviewer_8tRM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8295/Reviewer_8tRM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8295/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761983021759, "cdate": 1761983021759, "tmdate": 1762920224279, "mdate": 1762920224279, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper reframes HOI generation from grasp-centric scenarios to free-form interactions and introduces WildO2, an in-the-wild 3D HOI dataset constructed via an O2HOI pairing-and-reconstruction pipeline. It proposes TOUCH, a three-stage framework: (i) text- and geometry-conditioned CVAEs that predict hand/object contact maps; (ii) a multi-stage conditional diffusion model that injects global cues with coarse SSC text early and local geometry with fine DSC text late; and (iii) a lightweight physics-constrained refiner with cycle-consistent contact to correct global pose and sharpen local contacts. The system aims to produce controllable, diverse, and physically plausible interactions beyond grasping."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper contributes a relatively comprehensive dataset to the community and provides useful dataset statistics and analyses in the supp.\n2. The method’s explicit prediction of contact regions, coupled with a coarse-to-fine conditioning schedule, is conceptually sound and well aligned with the goal of improving both global plausibility and local contact fidelity."}, "weaknesses": {"value": "1. The approach (and the dataset pipeline) relies on one-image-to-3D reconstructions, especially during TTA. Inaccurate object reconstruction can propagate to and bias the estimated hand pose. The paper should analyze or mitigate this dependency—for example, via robustness studies under controlled reconstruction noise, uncertainty-aware weighting, or comparisons with stronger/alternative reconstruction backbones.\n2. While modeling dorsal-side contact is interesting, the paper does not clearly articulate advantages over prior grasp-generation methods such as SemGrasp, which also specifies finger contacts and applies TTA for post-processing. A direct comparison—quantitative and qualitative—under matched prompts and settings would better substantiate the claimed benefits."}, "questions": {"value": "The following questions are based on the weaknesses discussed above; please refer to that section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "92XwXGDpk5", "forum": "4VW9HVCRw0", "replyto": "4VW9HVCRw0", "signatures": ["ICLR.cc/2026/Conference/Submission8295/Reviewer_JuZb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8295/Reviewer_JuZb"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8295/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762000696981, "cdate": 1762000696981, "tmdate": 1762920223738, "mdate": 1762920223738, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}