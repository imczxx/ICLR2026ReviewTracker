{"id": "kthID5C61V", "number": 11625, "cdate": 1758202614445, "mdate": 1763115493554, "content": {"title": "Region-Aware Instance Consistency Learning for Apex-free Micro-Expression Recognition", "abstract": "Micro-expression Recognition (MER) is challenging due to the subtle motion. Existing methods heavily rely on the onset/apex pair to capture the most discriminative motion clues. This paradigm struggles with labor-intensive apex annotation and effective utilization of data. In this paper, we propose a novel apex-free paradigm for MER that eliminates the need for expensive apex annotations while effectively capturing subtle motion dynamics. Our key insight is that multiple frames near the sequence midpoint exhibit spatially consistent and intensity varied motion cues relative to the onset frame. Motivated by this, our method treats each sequence as a set of multiple onset/near-median motion instances. To fully exploit weaker motion information conveyed by these diverse instances, our framework introduces an Instance Region Consistency (IRC) module that enforces visual attention consistency on similar facial activation regions across different instances within the same set. Furthermore, we present a Multi-Region Discovery (MRD) module with self-supervised learning to expand attention on more subtle activation regions which are typically neglected. Extensive experiments on four public micro-expression datasets demonstrate that our proposed approach surpasses state-of-the-art methods without any apex frame annotations.", "tldr": "", "keywords": ["Micro-expression Recognition", "Affective Computing"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/1a870c52969f1d6d1dadbdc9996889d0f8530b3c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes an apex-free paradigm for micro-expression recognition (MER), replacing the conventional onset–apex pair with Multiple Instances Representation (MIR) built from onset/near-median frame pairs. Two modules exploit these weaker but diverse motion cues: Instance Region Consistency (IRC), which enforces CAM-level attention consistency between instance pairs via a BYOL-style Siamese setup, and Multi-Region Discovery (MRD), which uses learnable facial queries and a transformer decoder to discover additional subtle regions with a self-supervised alignment/clustering loss. Experiments on several benchmarks report SOTA performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Removing apex dependence addresses both annotation cost and data under-utilization. This motivation is clear.\n\n2. Ra-ICL tops prior methods on the composite set and each constituent dataset."}, "weaknesses": {"value": "1. Although the paper emphasizes the proposed middle-region sampling as the core novelty, the actual gain from this strategy appears marginal. The approach essentially samples N consecutive frames around the middle portion of the video and computes optical flow between the onset frame and each selected frame. Compared with conventional strategies such as Random, Uniform, or Full sampling, the only difference lies in the temporal location of selected frames rather than a new sampling mechanism.\n\n2. As shown in Table 3, the performance differences between the proposed method (M6) and other sampling variants (M7–M9, which do not require apex) are quite small and not statistically significant. This indicates that the sampling strategy itself contributes little to the overall improvement. The substantial performance gain of the full model seems to come mainly from the complex feature learning pipeline, including CAM-based attention consistency, Transformer-decoder region discovery, and multiple self-supervised/supervised losses, rather than from the proposed sampling policy. \n\n3. In other words, the framework integrates several existing components (e.g., CAM, BYOL-style Siamese training, Transformer decoder) and stacks them in a heavy architecture. The reported accuracy improvements could largely be attributed to this increased model complexity and computational cost, rather than to the claimed novelty of the sampling design. Therefore, the paper’s main claimed contribution is not convincingly supported by the ablation evidence.\n\n4. The paper claims efficiency by avoiding apex annotation, yet the overall framework seems computationally heavy."}, "questions": {"value": "1. Why should the middle region better capture subtle micro-expressions than the entire sequence or randomly sampled regions? As shown in Table 3, both random and full sampling can also achieve a similar performance.\n\n2. How much improvement comes solely from the sampling strategy, independent of the feature-learning modules and multi-loss design? The authors could replace the original sampling strategies in other baseline models with the proposed middle sampling and observe the corresponding performance changes.\n\n3. What is the additional computational cost (training/inference time, FLOPs, or preprocessing) introduced by the complex modules and multiple loss terms compared with standard apex-based methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jGpMFnifiH", "forum": "kthID5C61V", "replyto": "kthID5C61V", "signatures": ["ICLR.cc/2026/Conference/Submission11625/Reviewer_47ad"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11625/Reviewer_47ad"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11625/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761567719458, "cdate": 1761567719458, "tmdate": 1762922697864, "mdate": 1762922697864, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "uZDFC8H0lq", "forum": "kthID5C61V", "replyto": "kthID5C61V", "signatures": ["ICLR.cc/2026/Conference/Submission11625/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11625/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763115492811, "cdate": 1763115492811, "tmdate": 1763115492811, "mdate": 1763115492811, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenges of Micro-Expression Recognition (MER), which traditionally relies on labor-intensive apex frame annotations and struggles with limited data utilization. The authors propose a novel apex-free framework called Region-aware Instance Consistency Learning (Ra-ICL) to eliminate the need for apex annotations while effectively capturing subtle motion dynamics. Ra-ICL consists of three core components: (1) Multiple Instances Representation (MIR), which models a ME sequence as a set of onset/near-median motion instances instead of a single onset/apex pair; (2) Instance Region Consistency (IRC) module, which enforces visual attention consistency across different instances in the same set via a Siamese network and attention heatmaps; (3) Multi-Region Discovery (MRD) module, a self-supervised component that uses learnable facial queries to identify subtle, often neglected facial activation regions. Extensive experiments on four public ME datasets (CASME II, SAMM, SMIC-HS, and CAS(ME)³) under the Composite Database Evaluation (CDE) setting and Leave-one-subject-out (LOSO) cross-validation show that Ra-ICL outperforms state-of-the-art (SOTA) methods in terms of Unweighted F1-score (UF1) and Unweighted Average Recall (UAR), even without using any apex annotations. Ablation studies further validate the contribution of each component to the framework’s performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Originality：Introduces a novel apex-free MER paradigm, replacing reliance on apex annotations with a multi-instance representation (MIR) of onset/near-median frames. The combination of IRC (for attention consistency) and MRD (for self-supervised region discovery) presents a fresh integration of supervised and self-supervised learning to capture weak motion cues.\nQuality：Rigorous design: MIR sampling is well-justified, IRC uses Siamese+EMA for robust attention consistency, and MRD integrates Transformer decoders with clustering loss. Comprehensive experiments on four datasets with solid ablations validate the framework's effectiveness.\nClarity：Well-structured and readable. Key components (MIR, IRC, MRD) are clearly explained, supported by intuitive figures and formulas. Experimental settings and results are thoroughly documented for easy replication.\nSignificance：Practically reduces annotation cost, enhancing MER's applicability in real-world scenarios. Theoretically challenges the necessity of apex frames and demonstrates effective learning from limited data without external pre-training."}, "weaknesses": {"value": "Limited Motion Diversity Analysis: The ablation study compares sampling methods but fails to investigate how the variation in motion duration between frames affects performance. It's unclear which types of motion instances are most informative.\nInsufficient Apex-Free Comparisons: As an apex-free method, the paper lacks explicit comparisons to other recent works that also avoid apex annotations. A direct comparison to an adapted FRL-DGT would better validate Ra-ICL's claimed superiority.\nNo Computational Cost Analysis: The computational overhead of Ra-ICL's two-branch Siamese network and Transformer is not quantified. Metrics like training time and memory usage are needed to assess practical efficiency."}, "questions": {"value": "1. The paper sets N=16 for MIR based on frame rate priors, but how does the temporal distribution of near-median frames (e.g., frames closer to the onset vs. closer to the offset) affect the model’s ability to capture subtle motion? For example, do instances with larger temporal gaps from the onset (i.e., closer to the offset) provide more complementary information than those with smaller gaps? Could a dynamic sampling strategy (e.g., weighting instances by motion intensity) further improve performance?\n\n2. Are there any existing MER methods that explicitly avoid apex annotations (even if not framed as “apex-free”)? If yes, how does Ra-ICL’s architecture (e.g., MIR, IRC, MRD) differ from these methods, and why does it outperform them? If no, can the authors clarify why prior work has not explored apex-free MER, and how Ra-ICL overcomes technical barriers that may have prevented this?\n\n3. Can the authors provide quantitative data on Ra-ICL’s computational cost (e.g., training time per epoch on a NVIDIA 3090 Ti, inference time per sample, GPU memory usage) and compare it to SOTA methods (e.g., MFDAN, HTNet)? For applications requiring real-time processing, would Ra-ICL’s computational overhead be prohibitive, and are there potential optimizations (e.g., smaller backbones, simplified MRD) to reduce cost without sacrificing performance?\n\n4. For ME sequences with extremely low motion intensity (e.g., subtle eye movements), does MIR’s middle sampling still capture sufficient motion cues? Are there cases where even multiple onset/near-median instances fail to provide discriminative information, and if so, how could Ra-ICL be adapted to handle such cases (e.g., integrating RGB texture features with optical flow)?\n\n5. The MRD module uses 8 learnable facial queries, justified by hyper-parameter analysis. However, do these queries learn to map to specific facial regions (e.g., eyes, mouth, eyebrows) consistently across datasets, or are they dataset-specific? Can the authors visualize the regions targeted by individual queries to confirm that they correspond to meaningful facial activation areas (rather than noise)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "yUtdnt26CA", "forum": "kthID5C61V", "replyto": "kthID5C61V", "signatures": ["ICLR.cc/2026/Conference/Submission11625/Reviewer_cKyk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11625/Reviewer_cKyk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11625/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761828064915, "cdate": 1761828064915, "tmdate": 1762922697306, "mdate": 1762922697306, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel apex-free micro-expression recognition (MER) framework called Region-aware Instance Consistency Learning (Ra-ICL). This method aims to address the bottleneck caused by existing MER methods' heavy reliance on costly apex frame annotations. The authors' key insight is that a micro-expression sequence can be represented as a set of motion instances composed of 'onset/near-mid' frame pairs, which are consistent in spatial activation regions but differ in intensity. Based on this, the paper introduces two key modules: the Instance Region Consistency (IRC) module, which captures subtle motion dynamics by enforcing visual attention consistency across different instance pairs of the same sample; and the Multi-Region Discovery (MRD) module, which uses self-supervised learning to discover additional overlooked subtle activation regions. Extensive experiments on four public datasets demonstrate that this method outperforms existing state-of-the-art approaches without any apex frame annotations."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper accurately points out the high cost of vertex labeling in current 'start-end' pair-based MER methods and proposes a new 'vertex-free' paradigm. This motivation is very reasonable and practical.\n2. Experiments were conducted on four mainstream micro-expression datasets (CASME II, SAMM, SMIC-E, CAS(ME)²), and the results fully demonstrate the effectiveness and generalization ability of the method.\n3. Ablation experiments thoroughly validated the effectiveness of each module and analyzed the impact of different sampling strategies. Through visualization methods such as attention heatmaps and confusion matrices, the model's focus areas and classification performance are intuitively displayed."}, "weaknesses": {"value": "This paper contains a promising idea and strong experimental results, but the experimental comparisons are insufficient and the methodology is not clearly described."}, "questions": {"value": "1. Although experiments show that intermediate sampling yields the best results, in some ME sequences, the key frame may be at either end of the sequence. Is there a mechanism to handle this situation?\n2. How does the model perform in terms of generalization across datasets (such as from CASME II to SAMM)? Are there any cross-dataset experiments?\n3. The relationship between IRC and MRD is unclear: Are these two modules executed sequentially, in parallel, or nested? Figure 2 is too simplistic and fails to clearly show the data flow and interactions between modules. Readers have to repeatedly switch between the main text and the formulas just to barely understand it.\n4. The formulas (7) to (14) in the MRD section are overloaded with symbols, but the core idea (discovering different regions through self-supervised clustering) is drowned out by the mathematical notation. It feels more like the content of the appendix has been moved into the main text, making it very hard to read.\n5. The paper mentions the use of 'onset/near-median frame pairs,' but does not explain in detail how 'near-median' is defined and selected. Is it the midpoint frame of the sequence, or a dynamically chosen frame? How does this selection affect the quality of the instance and the final performance?\n6. The paper identifies 'dependency on vertex frames' as a key point of criticism and uses this as the main motivation for its own method. However, this methodological limitation is widely recognized within the community, and there are already several works aimed at reducing or eliminating reliance on vertex frames (such as FRL-DGT, which is cited in the paper). The authors fail to clearly explain the fundamental differences between their method and these existing 'vertex-free' or 'weakly supervised' approaches.\n7. The sentences are lengthy, and the terminology and symbols are inconsistent throughout the text, which undermines professionalism and readability. The quality of the charts needs improvement."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZeT6O4JPQR", "forum": "kthID5C61V", "replyto": "kthID5C61V", "signatures": ["ICLR.cc/2026/Conference/Submission11625/Reviewer_zbPm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11625/Reviewer_zbPm"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11625/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761901014568, "cdate": 1761901014568, "tmdate": 1762922696766, "mdate": 1762922696766, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an apex-free paradigm for micro-expression recognition (MER) that reduces the cost of apex annotations. The key component is Region-aware Instance Consistency Learning (Ra-ICL), which treats each sequence as a set of multiple onset vs near-median frame pairs (instances) to broadly exploit weak yet valid motion cues."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- An apex-free method for MER is proposed. In general, precise apex frame annotation imposes a heavy burden on annotators; the proposed approach can reduce annotation costs.\n- Instance Region Consistency (IRC) module is proposed. IRC learns consistency of attention over facial activation regions across instances with different intensities. A BYOL-style Siamese network (online/target with EMA updates) encourages CAM consistency, including horizontal flip consistency.                                                    \n- Multi-Region Discovery (MRD) module is proposed. MRD, via self-supervision, expands attention to subtler multiple activation regions that are often overlooked. In combination with IRC, it strengthens the extraction of information from weak motion."}, "weaknesses": {"value": "- From Section 3.3, the mathematical expression of tensor operations is insufficient. Notation such as $Q_e[m, :]$ and $F^{dense}_e[, u, v]$ appears to follow Python-style array indexing, but it is not standard mathematical notation and is not clearly defined in the paper. In particular, the distinction between $:$ and $*$ is unclear. Moreover, the relationship to earlier notation such as $M_j(x, y)$ used before Section 3.2 is not well specified. \n- It would be helpful to provide a more detailed qualitative analysis of how the proposed mechanism operates. Although Figure 5 visualizes attention heatmaps, analyses comparing them with the true apex, e.g., demonstrating that the learned representations sufficiently cover apex-level information, would strengthen the paper.           \n- There should be a direct comparison with a straightforward two-stage pipeline that chains existing micro-expression spotting and recognition. \n- In addition to micro-expressions, accuracy for macro-expression recognition should also be reported. These can be handled under a similar framework, and many papers report both."}, "questions": {"value": "As mentioned above, please provide a mathematically correct explanation of the notation for tensor operations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VCku162vmj", "forum": "kthID5C61V", "replyto": "kthID5C61V", "signatures": ["ICLR.cc/2026/Conference/Submission11625/Reviewer_UVoD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11625/Reviewer_UVoD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11625/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977388816, "cdate": 1761977388816, "tmdate": 1762922696263, "mdate": 1762922696263, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}