{"id": "TbEyl6krsY", "number": 5249, "cdate": 1757876687586, "mdate": 1759897985605, "content": {"title": "Learning Correlated Reward Models: Statistical Barriers and Opportunities", "abstract": "Random Utility Models (RUMs) are a classical framework for modeling user preferences and play a key role in reward modeling for Reinforcement Learning from Human Feedback (RLHF). However, a crucial shortcoming of many of these techniques is the Independence of Irrelevant Alternatives (IIA) assumption, which collapses \\emph{all} human preferences to a universal underlying utility function, yielding a coarse approximation of the range of human preferences. On the other hand, statistical and computational guarantees for models avoiding this assumption are scarce. In this paper, we investigate the statistical and computational challenges of learning a \\emph{correlated} probit model, a fundamental RUM that avoids the IIA assumption. First, we establish that the classical data collection paradigm of pairwise preference data is \\emph{fundamentally insufficient} to learn correlational information, explaining the lack of statistical and computational guarantees in this setting. Next, we demonstrate that \\emph{best-of-three} preference data provably overcomes these shortcomings, and devise a statistically and computationally efficient estimator with near-optimal performance. These results highlight the benefits of higher-order preference data in learning correlated utilities, allowing for more fine-grained modeling of human preferences. Finally, we validate these theoretical guarantees on several real-world datasets, demonstrating improved personalization of human preferences.", "tldr": "We show how to learn correlated probits.", "keywords": ["reward model", "RLHF", "choice model", "random utility model"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/82874d3b681f6f510b62f0fa8316b5b9c9a59a85.pdf", "supplementary_material": "/attachment/8d452620de906367e860621edd64796f8887eb53.zip"}, "replies": [{"content": {"summary": {"value": "The paper demonstrates that pairwise preference data is insufficient to learn correlated utility models in Random Utility Models (RUMs), specifically the correlated probit model. It proves that best-of-three comparisons are both necessary and sufficient for identifiability, proposes a near-optimal estimator, and empirically validates its advantages over traditional models in capturing human preference correlations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is clearly written and logically organized, presenting formal identifiability theorems that rigorously establish the necessity and sufficiency of triplet comparisons for learning correlated probit models.\n\n2. The paper delivers a persuasive critique of the Independence of Irrelevant Alternatives (IIA) assumption commonly used in RLHF, and introduces a well-justified alternative that enables more nuanced and personalized preference modeling.\n\n3. The experimental results, though modest in some cases, effectively demonstrate the advantages of triplet-based modeling on real-world datasets (e.g., Netflix, MovieLens, Sushi)."}, "weaknesses": {"value": "While I am not a domain expert, I would like to offer a few comments based on my understanding of the paper. One notable limitation is the absence of experiments conducted in an actual RLHF setting (whether in reinforcement learning tasks or fine-tuning large language models). Although the theoretical and empirical results (i.e., the correlations) on general preference datasets are compelling, they may not fully demonstrate the practical value of the proposed approach. Without experiments in the RLHF context, it remains unclear how well the method performs in the scenarios it is ultimately intended to support."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "sZR5b0KH8G", "forum": "TbEyl6krsY", "replyto": "TbEyl6krsY", "signatures": ["ICLR.cc/2026/Conference/Submission5249/Reviewer_taUP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5249/Reviewer_taUP"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5249/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761636231401, "cdate": 1761636231401, "tmdate": 1762917971556, "mdate": 1762917971556, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focusses on learning correlated utility models—parameterized as a correlated probit model——to avoid the IIA assumptions required by RUMs. The paper first proves that pairwise comparison data is insufficient to identify the data generating model. The paper then proves that best-of-three observations are both sufficient and necessary to learn the data generating probit model, and provides finite sample guarantees. Finally, the paper presents a series of experiments evaluating the use of best-of-three observations to learn the parameters of a probit model for 3 real-world datasets and 1 synthetic dataset."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This paper explores an interesting question and provides substantive theoretical analysis to support their conclusion: pairwise comparisons are not sufficient to recover the parameters of a correlated choice model, but best-of-three comparisons are. This conclusion is interesting and, to the best of my knowledge, addresses an important gap in existing literature."}, "weaknesses": {"value": "My main concerns are with the experiments in Section 6. Across all datasets, the proposed best-of-three-probit model matches or underperforms the direct matrix completion method. The authors claim that the direct matrix completion method is unrealistic in some scenarios—particularly when the set of alternatives and users is large—-but do not evaluate their method on those scenarios. Therefore, as far as I can tell, how their method also performs with larger alternatives/user sets remains an open question. Given the experimental evidence the authors do provide, there is no clear empirical benefit to using the best-of-three-probit model. I will raise my score if the authors can provide empirical evidence indicating where their best-of-three-probit model outperforms all other baselines. \n\nAlso, regarding Figure 3: the authors call this a “welfare maximizing experiment” but then note that the quantity they evaluate by “does not directly correlate with welfare as welfare is sensitive to the magnitude of utility change whereas this plot is not”. The authors should therefore change the name and how they discuss this experiment to avoid confusion."}, "questions": {"value": "When does the best-of-three-probit model outperform the direct matrix completion method?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "m1AiAIuwqq", "forum": "TbEyl6krsY", "replyto": "TbEyl6krsY", "signatures": ["ICLR.cc/2026/Conference/Submission5249/Reviewer_GvjC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5249/Reviewer_GvjC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5249/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761773281072, "cdate": 1761773281072, "tmdate": 1762917971338, "mdate": 1762917971338, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies RUMs and explores the statistical and computational challenges of learning a correlated probit model that avoids the IIA assumption.\nThe authors first prove that pairwise preference data is fundamentally insufficient to capture correlation among utilities.\nThey then show that best-of-three preference data is both identifiable and sufficient, and propose a statistically and computationally efficient estimator that achieves near-optimal performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "I think that the contribution of this paper is significant, particularly Theorem 3.2, which rigorously proves that the classical pairwise comparison paradigm is fundamentally insufficient for recovering the parameters of a correlated probit model.\nThis finding challenges long-standing assumptions in choice modeling and clearly explains why existing methods fail to capture correlations in human preferences.\nMoreover, the paper provides both theoretical and practical advances by establishing the first identifiability and finite-sample guarantees for correlated Random Utility Models.\nOverall, the work offers a novel perspective on preference learning to the community."}, "weaknesses": {"value": "Despite its strong theoretical contributions, the paper also has a few weaknesses and open questions.\n\n- In Theorem 5.2, the sample complexity depends on $\\gamma^{-24}$. Since $\\gamma$ can be extremely small in practical settings, this dependence may lead to an unrealistic sample requirement. It would be important to discuss whether this exponent can be tightened or whether a refined analysis could yield a more favorable dependence on $\\gamma$.\n\n- While the paper motivates its setting through RLHF, it treats each item as a single (prompt, response) pair. In RLHF, however, the prompt space is effectively infinite and highly structured. It remains unclear how the proposed framework could be extended to handle such a large or continuous prompt and action space. \n\n- I think this work is also highly related to general preference modeling frameworks, such as [1] and [2].\nCould the authors compare their proposed framework with these prior approaches and clarify the key similarities and differences?\n\n---\n[1] Ye, Chenlu, et al. \"Online iterative reinforcement learning from human feedback with general preference model.\" NeurIPS, 2024.\n[2] Zhang, Yuheng, et al. \"Iterative Nash Policy Optimization: Aligning LLMs with General Preferences via No-Regret Learning.\", ICLR 2025."}, "questions": {"value": "- How strong is Assumption 3.1? Could the authors elaborate on its necessity and implications?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CscsWVkGZ6", "forum": "TbEyl6krsY", "replyto": "TbEyl6krsY", "signatures": ["ICLR.cc/2026/Conference/Submission5249/Reviewer_ZMzz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5249/Reviewer_ZMzz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5249/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761821533087, "cdate": 1761821533087, "tmdate": 1762917971096, "mdate": 1762917971096, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper considers a correlated probit model of preferences that avoids the Independence of Irrelevant alternatives (IIA) assumption; for this model, the paper shows that pairwise preference data isn't sufficient for provably learning the correlations, and suggests the use of three way preference data to provably solve for the parameters of this model."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. A very clearly written paper, a concrete model / setup and clear theoretical results.\n2. Interesting observations, and a particularly relevant problem in the current scheme of RLHF based pipelines for training foundation models."}, "weaknesses": {"value": "1. In principle, this is a fairly stylized model and its applicability to realistic setups, particularly in RLHF is questionable in the sense of how useful it can be compared to optimizing the standard pairwise loss.\n2. This specific connection to training improved reward models (in RLHF) is not explored as part of the empirical evaluations which could've helped bolster the results offered by this paper."}, "questions": {"value": "One question that I am interested in thinking about (and getting the authors to weigh in on) is what does this imply for policy learning in RLHF setups -- in particular, I am thinking about situations involving intransitive preferences."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ha9Z4dyEpL", "forum": "TbEyl6krsY", "replyto": "TbEyl6krsY", "signatures": ["ICLR.cc/2026/Conference/Submission5249/Reviewer_AY4G"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5249/Reviewer_AY4G"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5249/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761848326970, "cdate": 1761848326970, "tmdate": 1762917970843, "mdate": 1762917970843, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}