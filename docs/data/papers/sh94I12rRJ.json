{"id": "sh94I12rRJ", "number": 19644, "cdate": 1758297933037, "mdate": 1759897028521, "content": {"title": "Searching Meta Reasoning Skeleton to Guide LLM Reasoning", "abstract": "Meta reasoning behaviors work as a skeleton to guide large language model (LLM) reasoning, thus help to improve reasoning performance.\nHowever, prior researches implement meta reasoning skeleton with manually designed structure, limiting ability to adapt to query-specific requirement and capture intricate logical dependency among reasoning steps.\nTo deal with the challenges, we represent meta reasoning skeleton with directed acyclic graph (DAG) to unify skeletons proposed in prior works and model intricate logical dependency.\nThen we propose AutoMR, a framework that searches for query-aware meta reasoning skeleton automatically inspired by automated machine learning (AutoML).\nSpecifically, we construct search space based on DAG representation of skeleton and then formulate the search problem.\nWe design a dynamic skeleton sampling algorithm by expanding meta reasoning skeleton along with reasoning context at inference time.\nThis algorithm can derive any meta reasoning skeleton in search space efficiently and adapt skeleton to evolving base reasoning context, thus enable efficient query-aware skeleton search.\nWe conduct experiments on extensive benchmark datasets. Experimental results show that AutoMR achieves better reasoning performance than previous works broadly.", "tldr": "", "keywords": ["LLM Reasoning", "Neural Architecture Search", "Meta Reasoning"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cdfd062b6ebad497681d7ccb1da3a877c3df6c11.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "AutoMR reframes “meta reasoning” for LLMs as searching a query-aware **reasoning skeleton** represented by a single-source, edge-heterogeneous DAG that can encode sequential, parallel, tree, and more intricate dependencies among steps. It defines a strategy set (e.g., Next, Reflect, Explore, Decompose, Summarize, Recall, Answer) and introduces a **dynamic skeleton sampling** algorithm that interleaves with inference: for each step it selects incoming strategy-typed edges conditioned on the evolving reasoning context, generating content only when needed. A lightweight MLP guides edge selection, and a policy over skeletons is optimized with REINFORCE; this adds minimal overhead compared to vanilla reasoning while adapting structure per query. Across math QA (GSM8K, MATH-500, AMC, Olympiad) and general multiple-choice (MMLU-Pro) with LLaMA-3B and Qwen-3B backbones under the same token budgets, AutoMR consistently outperforms CoT, MRP, Meta-Reasoner, rStar, and an agent-workflow NAS baseline, and scales compute more efficiently, highlighting the advantage of DAG-based, instance-specific meta-reasoning."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The authors’ motivation is well founded, where for different problems, the meta-reasoning framework should be dynamic rather than static.\n2. The proposed method is highly effective, achieving substantial performance gains across settings compared with prior approaches.\n3. While improving accuracy, the method also demonstrates better efficiency than previous work."}, "weaknesses": {"value": "1. Experiments are limited to short-CoT and small-scale models, which constrains the validation of the approach. Evaluating on long-CoT models (e.g., DeepSeek-R1-Distilled, Qwen3) and larger models (e.g., 8B, 14B) would more convincingly substantiate the method’s effectiveness.\n2. Although many prior works also rely on training for meta reasoning, in many practical scenarios it is difficult to obtain sufficient training data and compute. Even when such resources are available, one could instead train a LoRA to boost performance, which makes the niche for this work somewhat awkward.\n3. The method bears similarities to Graph-of-Thought [1]. Although the granularity differs, both enhance performance by structuring the reasoning process as a graph.\n4. The writing is somewhat disorganized: for example, Figure 1 is not placed at the top, and Figure 5 appears to be a Table.\n\n[1] Graph of Thoughts: Solving Elaborate Problems with Large Language Models. Besta et al., AAAI 2024."}, "questions": {"value": "1. How did you determine the set of strategies used in Table 2? Why not include more or fewer strategies?\n2. What are the MLP hyperparameters in your experiments?\n3. Why does Figure 4 report results only on MATH-500 rather than an average across all datasets?\n4. It is surprising that on MMLU-Pro such significant gains are achieved with only 70 training examples. Did you attempt to train the MLP on MATH-500 with fewer than 100 training samples as well?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Rzq7DXtrT6", "forum": "sh94I12rRJ", "replyto": "sh94I12rRJ", "signatures": ["ICLR.cc/2026/Conference/Submission19644/Reviewer_CbsY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19644/Reviewer_CbsY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19644/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760461450133, "cdate": 1760461450133, "tmdate": 1762931498477, "mdate": 1762931498477, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes AutoMR, a framework designed to search for meta-reasoning skeletons more effectively and efficiently. Experiments conducted across a wide range of tasks demonstrate the framework’s strong performance and provide a comprehensive analysis of its effectiveness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The presentation and writing are clear and generally easy to follow.\n\n- The core idea and motivation are interesting and relevant.\n\n- The proposed method appears highly effective.\n\n- The experiments and analyses are comprehensive and well-executed."}, "weaknesses": {"value": "- Design Motivation: The paper would benefit from a deeper explanation of the design motivation behind AutoMR. Many parts of the explanation are highly technical and provide limited intuition for understanding why the framework works. While the inclusion of formulas is appreciated, the methodology—especially Section 3.2.1—would be easier to follow if accompanied by more intuitive explanations or illustrative examples.\n\n- Baselines: The paper should include comparisons with more recent and relevant reasoning models to strengthen its empirical claims.\n\n- Analysis Depth: Additional analysis could enhance the interpretability and transparency of the framework, helping readers gain a deeper understanding of its internal mechanisms and behavior. (e.g., error analysis to understand the limitations)\n\nI would be willing to raise my score if the authors can adequately address these weaknesses."}, "questions": {"value": "The meta-reasoning behaviors summarized in the paper are derived from existing studies on LLM reasoning. Are these behaviors comprehensive enough? Have the authors considered incorporating other types of reasoning behaviors, perhaps inspired by cognitive or psychological perspectives?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Z3G78j832k", "forum": "sh94I12rRJ", "replyto": "sh94I12rRJ", "signatures": ["ICLR.cc/2026/Conference/Submission19644/Reviewer_SgMk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19644/Reviewer_SgMk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19644/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760834154187, "cdate": 1760834154187, "tmdate": 1762931497999, "mdate": 1762931497999, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper purposes AutoMR, a meta-reasoning framework that treats the reasoning skeleton as a single-source, edge-heterogeneous DAG. The search space uses a strategy set plus a zero edge, enabling rich inter-step dependencies that prior fixed skeletons miss. Trained via policy-gradient over the sampler, AutoMR consistently outperforms CoT, Meta-Reasoner, rStar, etc. across math QA and MMLU-Pro subsets and exhibits superior token-scaling efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper reframes meta-reasoning as a creative, NAS-style control layer interleaved with the LLM’s ongoing reasoning rather than fixed upfront.\n2. The unified DAG view plus inference-time search offers a general recipe for meta-control that can envelop many existing meta-reasoning templates.\n3. The paper cleanly motivates the limitations of fixed skeletons, then walks through the search space and dynamic sampler with a concrete algorithmic presentation, which makes it easy to follow."}, "weaknesses": {"value": "Results are on 3B instruction models (Qwen2.5-3B-Inst, LLaMA-3.2-3B-Inst) with a 1024-token budget for all methods. It remains unclear if AutoMR’s gains persist with stronger models or longer budgets typical in practice."}, "questions": {"value": "1. When a node has multiple incoming edges with possibly different strategies, it is unclear how instructions are composed into one prompt for generating $c_i$​. (line 249-250)\n2. Why not use Graph of thoughts as a baseline?\n3. Some typos e.g. “dose” (line 161) “AutoTTS” (Table 1)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "wzZl7LXATN", "forum": "sh94I12rRJ", "replyto": "sh94I12rRJ", "signatures": ["ICLR.cc/2026/Conference/Submission19644/Reviewer_SpuB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19644/Reviewer_SpuB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19644/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762183928048, "cdate": 1762183928048, "tmdate": 1762931497527, "mdate": 1762931497527, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces AutoMR, a framework that improves large language model (LLM) reasoning performance by automatically searching for query-aware meta-reasoning skeletons. It represents these skeletons as directed acyclic graphs (DAGs) and employs a dynamic sampling algorithm. Experiments demonstrate that AutoMR improves reasoning performance and efficiency compared to existing methods that rely on manually designed skeletons."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper introduces a new method that eliminate the need for traditional manual design. \n2. The dynamic skeleton sampling algorithm enables the generated meta-reasoning skeletons to possess strong query-awareness and adaptability."}, "weaknesses": {"value": "I have the following concerns. *If the authors could address my concerns during the rebuttal stage, I will consider raising my score.*\n1. Despite the authors stating that 3B models were used for fair comparison, I am still curious about the potential performance gains when applying AutoMR to larger LLMs, especially given the method's reported low training cost and inference efficiency.\n2. The performance improvement on knowledge-intensive tasks is notably more limited compared to thinking-intensive tasks, and the method's performance on knowledge-intensive tasks seems insufficient to demonstrate the method's advantages fully.\n3. As the paper only evaluates the method on math Q&A and general multiple-choice tasks across different disciplines and difficulties, I am worried about the method's scalability and broad effectiveness across a wider range of diverse tasks. I look forward to the authors providing performance results on complex reasoning datasets, including, but not limited to, Game of 24 [1], BIG-Bench Hard (BBH) [2], and Python Programming Puzzles [3].\n4. Buffer of Thoughts (BoT) [4] is a great thought-augmented reasoning approach, which utilizes a meta-buffer to store and retrieve high-level thought-templates distilled from various problem-solving processes. I'm very curious about the performance difference between this work and BoT.\n5. There are several spelling errors in the paper, for instance, \"an\" in the Table 1 caption, \"subet\" on page 7, and \"to to enhance\" on page 8.\n\n[1] Tree of thoughts: Deliberate problem solving with large language models. NeurIPS 2024.\n\n[2] Challenging big-bench tasks and whether chain-of-thought can solve them. ACL 2023 Findings.\n\n[3] Programming puzzles, in Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track, \n2021.\n\n[4] Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models. NeurIPS 2024."}, "questions": {"value": "Please see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ItSt1u8tjp", "forum": "sh94I12rRJ", "replyto": "sh94I12rRJ", "signatures": ["ICLR.cc/2026/Conference/Submission19644/Reviewer_iKDH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19644/Reviewer_iKDH"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19644/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762220846689, "cdate": 1762220846689, "tmdate": 1762931496981, "mdate": 1762931496981, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}