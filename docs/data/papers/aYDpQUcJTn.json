{"id": "aYDpQUcJTn", "number": 14131, "cdate": 1758228946002, "mdate": 1763621206046, "content": {"title": "Single Index Bandits: Generalized Linear Contextual Bandits with Unknown Reward Functions", "abstract": "Generalized linear bandits have been extensively studied due to their broad applicability in real-world online decision-making problems. However, these methods typically assume that the expected reward function is known to the users, an assumption that is often unrealistic in practice. Misspecification of this link function can lead to the failure of all existing algorithms. In this work, we address this critical limitation by introducing a new problem of generalized linear bandits with unknown reward functions, also known as single index bandits. We first consider the case where the unknown reward function is monotonically increasing, and propose two novel and efficient algorithms, STOR and ESTOR, that achieve decent regrets under standard assumptions. Notably, our ESTOR can obtain the nearly optimal regret bound $\\tilde{O}_T(\\sqrt{T})$ in terms of the time horizon $T$. We then extend our methods to the high-dimensional sparse setting and show that the same regret rate can be attained with the sparsity index. Next, we introduce GSTOR, an algorithm that is agnostic to general reward functions, and establish regret bounds under a Gaussian design assumption. Finally, we validate the efficiency and effectiveness of our algorithms through experiments on both synthetic and real-world datasets.", "tldr": "We study a new problem of generalized linear bandits where reward functions are unknown to the users, also known as single index bandits.", "keywords": ["contextual bandit", "online learning"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cd867d29e801d2959c9d17c6d67802ff34997b36.pdf", "supplementary_material": "/attachment/f2aedad11c66b391f08af0a0b9b140b3872372db.zip"}, "replies": [{"content": {"summary": {"value": "The paper studies generalized linear bandits (GLBs) with unknown reward functions, referred to as single index bandits (SIBs). This setting is analogous to single index models which generalize generalized linear models by allowing an unknown link function. The presence of an unknown reward function poses substantial theoretical challenges. The authors proposed a family of algorithms for the single index bandits, based on the Stein’s method: STOR and ESTOR for the case where the unknown reward function is monotonically increasing, and GSTOR for the case of general reward functions. The paper provides regret bounds for all proposed algorithms within this new problem setting."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper makes a clear and original contribution by being the first to extend generalized linear bandits to the setting where the reward function is unknown. The authors carefully discuss the theoretical challenges that arise in this new formulation and emphasize that most of the popular GLB algorithms such as UCB-based methods cannot be directly applied.  To tackle with the challenges, the authors introduce new algorithms based on Stein’s method, which jointly estimate both the underlying parameter and the unknown link function. Notably, Among these, ESTOR achieves a near-optimal regret bound (optimal up to logarithmic factors) under the assumption of a monotone reward function. The paper further extends this approach to the sparse high-dimensional regime and to the general reward function setting. For the latter, the authors propose GSTOR, and prove regret guarantees under a Gaussian design assumption."}, "weaknesses": {"value": "The presentation of the paper could be improved for clarity and intuition. Theorem 3.1 plays a central role across all three proposed algorithms, as the joint learning of both the parameter and the unknown link function is the core challenge of the new problem setup. However, little intuition is given for the minimization problem. It is hard to see how the bound in Theorem 3.1 contributes to the regret analysis that follows. It would be helpful if the authors highlighted where and how the unknown function is estimated within the algorithmic framework. Including a brief proof sketch for Theorem 3.1 and Theorem 3.5 would also improve understanding, especially regarding why the regret bound improves substantially in Theorem 3.5 through epoch scheduling.\n\nIn contrast, the sections on STOR and the sparse high-dimensional extension could be presented more concisely, as they are relatively straightforward once ESTOR is clear. The last section on arbitrary reward function is an exciting direction to expand on, but it is presented shortly. The regret bound for the general case is relatively weak, given it is formulated under Gaussian assumptions - It would strengthen the paper to elaborate on the notion of “fundamental unattainability” and to explain more clearly the need/necessity behind the double Etc strategy."}, "questions": {"value": "1.What is the fundamental difficulty in the arbitrary reward function setting that prevents the exponential epoch scheduling technique (used in ESTOR) from being effective?  \n2.Does the presented upper bound match any known lower bound in this setting? And what about the dependency on K?   \n3.Could the authors also include the performance of GSTOR in Figure 1 for a more complete empirical comparison across all proposed algorithms?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QnVIIy0HiY", "forum": "aYDpQUcJTn", "replyto": "aYDpQUcJTn", "signatures": ["ICLR.cc/2026/Conference/Submission14131/Reviewer_pAj9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14131/Reviewer_pAj9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14131/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761540103226, "cdate": 1761540103226, "tmdate": 1762924598691, "mdate": 1762924598691, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces and addresses the Single Index Bandit problem, a generalization of the Generalized Linear Bandit (GLB) framework. In a SIB, the expected reward is an unknown, potentially non-linear function $f$ of a linear predictor $x^\\top \\theta_*$, in contrast to GLBs which assume $f$ is known.  The authors propose a family of efficient algorithms based on a novel estimator derived from Stein's method, which avoids the need for complex optimization or a known link function."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The work directly addresses a critical and often unrealistic limitation (known link function) in the extensive GLB literature, making bandit algorithms significantly more robust to model misspecification.\n2. The paper is generally well-written and structured. The motivation is compelling, and the challenges of the problem are clearly explained, especially in contrasting with existing GLB and general contextual bandit approaches."}, "weaknesses": {"value": "1. The analysis crucially relies on the assumption that the context vectors (arms) are i.i.d. from a fixed distribution. This is a significant limitation, as a large body of bandit literature deals with adversarially chosen arm sets. Why this assumption is needed?\n2. The worst-case regret bound of ESTOR exhibits a $K^{3/2}$ dependence on the number of arms, a limitation not present in prior work on heavy-tailed GLBs. Why this term exists? Is there any lower bound?\n3. This paper assumes $||\\theta_*||=1$, which is less common in contextual linear bandits. Why the norm bound on the parameter is needed?"}, "questions": {"value": "see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lpBARjPKWC", "forum": "aYDpQUcJTn", "replyto": "aYDpQUcJTn", "signatures": ["ICLR.cc/2026/Conference/Submission14131/Reviewer_vpkp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14131/Reviewer_vpkp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14131/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761752902062, "cdate": 1761752902062, "tmdate": 1762924598027, "mdate": 1762924598027, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Single Index Bandits (SIB), extending generalized linear bandits (GLBs) to settings where the reward function $f$ is unknown. Note that GLBs require the link function, and misspecification in the link function can lead to linear regret. To address this, the authors propose a novel Stein's method-based estimator that achieves minimax-optimal error rates $O\\sqrt{d/n}$ without knowing $f$,  requiring only $O(nd)$ time complexity. For monotonically increasing $f$, they develop STOR (explore-then-commit), achieving $O(T^{2/3})$ regret and ESTOR (epoch-based), achieving near-optimal $O(\\sqrt{T})$ regret. The framework extends to sparse high-dimensional settings, replacing $d$ with sparsity $s$ in regret bounds. For general non-monotonic $f$, GSTOR employs kernel regression under Gaussian design, achieving $O(T^{3/4})$ regret. The Stein's estimator cleverly exploits $E[f(X^\\intercal \\theta^{\\star})S(X)] = E[f'(X^\\intercal \\theta^{\\star})]\\theta^{\\star}$ through integration by parts, using truncation to control variance. Experiments on synthetic and real datasets (Forest Cover, Yahoo News) demonstrate substantial improvements over GLB methods, with ESTOR/STOR running 100-1000x faster than UCB-GLM/GLM-TSL."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper tackles a fundamental limitation of GLBs - the known reward function (link function) assumption. By using an the Stein's method approach, they address this issue. The resulting estimator is both theoretically optimal (achieving minimax rates) and computationally efficient (closed-form solution requiring no optimization).\n2. The paper provides two algorithms, STOR, a simpler variant with uniform exploration, and ESTOR which is an epoch-based algorithm that balances exploration-exploitation. Finally, GSTOR, stated in the Appendix for non-monotonic functions, is the algorithm that tackles non-monotonic reward functions.\n3. Synthetic experimentation shows good performance against baselines."}, "weaknesses": {"value": "1. To me, one of the main weaknesses of the paper is that it tries to pack too much stuff into the paper without going deep into one section.\n2. Following the previous comment, none of the theorems, technical novelty has been explained in detail.\n3. The sparse high-dimensional experiments only test linear rewards (not truly testing the unknown f capability), GSTOR evaluation is limited."}, "questions": {"value": "1. The technical novelty is not clear to me. I actually went over the proof of Theorem 3.1 in the appendix. It uses the standard Holder's and Cauchy-Schwarz inequality. Relies on Lemma C.3, which follows directly from Steim's inequality and Bernstein's inequality. Where is the key technical challenge in this?\n2. One thing I am slightly confused about is that, to get rid of the knowledge of the link function, the authors mainly rely on the estimator and the quadratic loss function in eq (1), and that data is sampled from a fixed distribution D. Is this enough? Or are there some hidden assumptions I am missing?\n3. While theoretically sound, the STOR algorithm (which is an Explore-then-Commit algorithm) is quite impractical. Observe that, combined with Theorem 3.1, the first stage requires $O(dT^{2/3}$ samples. which is very large. Basically, to build the estimator itself, it takes two-thirds of the samples. Now, if you look into a stochastic bandit setting with no structure, the ETC algorithm takes $O\\sqrt{T}$ samples. Check Chapter 6 of https://tor-lattimore.com/downloads/book/book.pdf.\n4. The sparse high-dimensional setting only tests linear rewards; as such, testing against a synthetic complex f will enhance the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XzBkS6RLhd", "forum": "aYDpQUcJTn", "replyto": "aYDpQUcJTn", "signatures": ["ICLR.cc/2026/Conference/Submission14131/Reviewer_Fk6c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14131/Reviewer_Fk6c"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14131/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761911059222, "cdate": 1761911059222, "tmdate": 1762924597622, "mdate": 1762924597622, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates generalized linear bandits with unknown reward functions. The authors propose three algorithms that progressively handle increasingly general link functions. STOR addresses monotone functions using an ETC strategy, ESTOR achieves near-optimal regret through an epoch-based framework, and GSTOR extends the approach to arbitrary functions under Gaussian design. The paper explores sparse high-dimensional settings and leverages Stein’s identity to estimate model parameters without prior knowledge of the reward function. Extensive experiments validate the effectiveness of the proposed methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1) This paper tackles a challenging and relatively unexplored generalized linear bandit setting in which the link function is unknown. \n2) It offers a hierarchical perspective on assumptions and algorithms, distinguishing between monotone and general link functions, to illustrate the trade-off between assumptions and regret. \n3) The proposed Stein’s estimator is new and conceptually clear, enabling efficient estimation of the underlying parameter without explicitly modeling the link function."}, "weaknesses": {"value": "1) The monotonicity assumption is key to achieving near-optimal regret but remains restrictive. It would be helpful to discuss whether weaker conditions, e.g., local monotonicity or Lipschitz continuity, could still lead to meaningful results.\n2) The non-monotone case achieves $O(T^{3/4})$ rate is suboptimal. The dependence on the number of arms $K$ might be suboptimal.\n3) The analysis of sparsity is good but assumes knowledge of the true sparsity level."}, "questions": {"value": "1) How critical is the Gaussian design assumption in GSTOR? Could the analysis extend to sub-Gaussian or other distributions, or does it rely on properties unique to the Gaussian setting?\n2) Are the dependencies on $T, d, K$ optimal?\n3) Can the sparse variants adapt to unknown sparsity levels? How sensitive are the algorithms to misspecification of the sparsity parameter?\n4) Are there specific settings where realizability-based contextual bandits can outperform the single-index bandits?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "531RNQwa07", "forum": "aYDpQUcJTn", "replyto": "aYDpQUcJTn", "signatures": ["ICLR.cc/2026/Conference/Submission14131/Reviewer_2RuZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14131/Reviewer_2RuZ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14131/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762538012250, "cdate": 1762538012250, "tmdate": 1762924597213, "mdate": 1762924597213, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}