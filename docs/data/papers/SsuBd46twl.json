{"id": "SsuBd46twl", "number": 4079, "cdate": 1757597569068, "mdate": 1759898054096, "content": {"title": "Eliciting Numerical Predictive Distributions of LLMs Without Auto-Regression", "abstract": "Large Language Models (LLMs) have recently been successfully applied to regression tasks---such as time series forecasting and tabular prediction---by leveraging their in-context learning abilities. However, their autoregressive decoding process may be ill-suited to continuous-valued outputs, where obtaining predictive distributions over numerical targets requires repeated sampling, leading to high computational cost and inference time. In this work, we investigate whether distributional properties of LLM predictions can be recovered _without_ explicit autoregressive generation. To this end, we study a set of regression probes trained to predict statistical functionals (e.g., mean, median, quantiles) of the LLM’s numerical output distribution directly from its internal representations. Our results suggest that LLM embeddings carry informative signals about summary statistics of their predictive distributions, including the numerical uncertainty. This investigation opens up new questions about how LLMs internally encode uncertainty in numerical tasks, and about the feasibility of lightweight alternatives to sampling-based approaches for uncertainty-aware numerical predictions.", "tldr": "We demonstrate that LLMs' hidden states contain information about their own numerical predictive distribution, that can be elicited without the need of auto-regressive decoding.", "keywords": ["mechanistic interpretability", "uncertainty estimation", "LLMs", "time series", "probing"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5fbed7649e6bf94be79be30c57c505ebaf07aec9.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "In an empirical paper, authors target numerical prediction in LLMs by decomposing prediction into magnitude classification and scaled value regression. The key contribution is learning the magnitude and a normalized value separately, and using the predictions before LLM token generation. \n\nWhile it is hinted that the idea enables uncertainty-aware numerical \nprediction without repeated sampling, evaluation is limited to maximum Pinball loss and IQR prediction in generated data.\n\nWhile the methods empirically work well, we gain no insight regarding the LLM representation behind.\n\nThe paper is well written and source code is provided anonymously.\n\nWhile the paper presents convincing empirical results for the applicability of the decomposed numerical prediction learning in LLMs, I miss theoretical or architectural explanations. Also, the uncertainty considerations are shomewhat limited."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "+ New contribution towards improved numeric prediction capabilities of LLMs\n+ Very well written paper\n+ Source code is available"}, "weaknesses": {"value": "- No theoretical and/or architectural explanation of how the LLMs represent the numeric range and scaled value\n- The uncertainty part could be strengthened\n- Comparison with methods that learn the distribution of regression problems (e.g. Bayesian NN, Mixture Density Networks), while not absolutely necessary, could make the contribution more valuable"}, "questions": {"value": "The discussion of Table 1 could be more elaborate. Do I understand well that the LLM raw output is much worse than the mean or median of several of its outputs? I see no explanation, not even in the Appendix.\n\n3.1 pinball loss: why the maximum over quantiles? Why not the integral, as in CRPS [Alexander Jordan, Fabian Kruger, and Sebastian Lerch. Evaluating probabilistic forecasts with scoringrules. Journal of Statistical Software, 90(12):1–37, 2019, Diane Bouchacourt, Pawan K Mudigonda, and Sebastian Nowozin. Disco nets: Dissimilarity coefficients networks, Neurips'16]?\n\nIn the training procedure of eqs (6-7), how can you handle if a multimodal distribution has modes of different order of magnitude? Isn't eq (6) too restrictive?\n\nWhile the main goal is certainly not to provide the best model for distribution learnting, could you compare other methods that learn the distribution, e.g. [Shengyang Sun, Changyou Chen, and Lawrence Carin. Learning Structured Weight Uncertainty in Bayesian Neural Networks. AISTATS'17]. \n\nFig. 6 only shows MAE, it would be interesting to see e.g. Pinball Loss, compared to non-LLM models for learning distributions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yDgigdPRwr", "forum": "SsuBd46twl", "replyto": "SsuBd46twl", "signatures": ["ICLR.cc/2026/Conference/Submission4079/Reviewer_8jM1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4079/Reviewer_8jM1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4079/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761306192244, "cdate": 1761306192244, "tmdate": 1762917167958, "mdate": 1762917167958, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors explore the ability to extract the predictions of an LLM dependent on its hidden states of its final layers using a variety of methods. For their main experiment, they adopt a mantissa+exponent floating point style method of calculating the regression model, with the mantissa trained as a regression problem and the exponent trained as a classification problem. Only the exponent is trained first, then the mantissa is used to fine-tune the results. They then compare this against the point estimates of the greedy, median, and greedy methods of the LLM. They additionally train a quantile-regression probe using pinball loss to quantify uncertainty."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Strengths\nThis is an interesting dive into whether both 1. point estimates and 2. uncertainty can be recovered from the LLM's hidden state.\n\nThey show advantages against standard LLM sample-based prediction in Figure 4, along with improved results over GP in the tables for the time-series regression task.\n\nThey also demonstrate some generalization properties, which can be instrumental when dealing with distribution shift."}, "weaknesses": {"value": "Though the author's main goal seems to be moving towards sidestepping autoregressive generation, they only explore one-step prediction in the current results. Additionally, for some of the main other results, they calculate statistics and last step predictions, it may be worth it to show average MSE across time rather than MSE against the average in time.\n\nCurrently, the experiments seem to be all done on synthetic datasets. While this is useful for the uncertainty metrics, having some error-based analysis on some standard real-world time series datasets could strengthen the paper."}, "questions": {"value": "If LLMs generate results autoregressively and the model does not work as well for the greedy approach, does this mean that it would still be hard to capture the results of the LLMs purely from the hidden states?\n\nHow much contribution does the floating-point formulation actually bring for the probe, compared to just predicting the value directly? If it is significant, then how would this method compare to using it against a standard regressor (without LLM) with the same floating-point formulation?\n\nWhy is the LLM sample error so high in the beginning for Figure 4?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "5Ifx1Lnjve", "forum": "SsuBd46twl", "replyto": "SsuBd46twl", "signatures": ["ICLR.cc/2026/Conference/Submission4079/Reviewer_hDqn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4079/Reviewer_hDqn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4079/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761680135567, "cdate": 1761680135567, "tmdate": 1762917167759, "mdate": 1762917167759, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a set of regression probes to predict the distributional properties of LLM-based time-series forecasters. By training the probes on synthetic data, the probes can predict quantities such as the greedy prediction, mean, and median with good accuracy without autoregressive decoding in both ID time-series and, to a less extent, OOD time-series."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- I appreciate the careful design going into designing the parameterization and loss functions of the probes, which is important for handling values with large ranges.\n- The empirical result shows good agreement between the probe predictions and actual values obtained from decoding.\n- The computational efficiency of the probe over decoding / sampling is appealing.\n- Overall good presentation."}, "weaknesses": {"value": "- A main finding of the paper is that LLM’s predictive distribution is encoded in its internal activations. This statement seems trivially true. The predictive distribution (jointly over all future tokens) is fully determined given the hidden states of the LLM (KV cache) as a direct consequence of the model architecture.\n- The probes only make predictions about a single next value, rather than a future sequence. In practice, time-series forecasters are used to make extended, variable-length predictions over a non-trivial horizon, where this approach does not trivially generalize over to. In other words, the probe only shortcuts autoregression over the digits, but not time steps.\n- I'm not convinced that the probes provide significant computational speedup over directly decoding from the LLM. In both approaches, most of the computation is in running the LLM forward pass on the input sequence. Decoding from the LLM is much cheaper, especially for predicting only the very next value. Thus, the savings from the probes can be negligible relative to the overall cost."}, "questions": {"value": "- Can the proposed approach be generalized to predict distributional properties of a future sequence, rather than a single value?\n- How much total runtime or compute saving do the probes provide over decoding from the LLM across the experiments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DrvxuQuTB7", "forum": "SsuBd46twl", "replyto": "SsuBd46twl", "signatures": ["ICLR.cc/2026/Conference/Submission4079/Reviewer_x9bF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4079/Reviewer_x9bF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4079/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978676897, "cdate": 1761978676897, "tmdate": 1762917167481, "mdate": 1762917167481, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the question of whether LLM's hidden representations encode distributional information about their numerical predictions rather than relying on autoregressive decoding when it comes to utilizing LLMs for time-series forecasting regression tasks. They Introduce a probing model that separately predict the order of magnitude ( treated as classification ) and the multiplicative residual to predict the mean, median and the greedy predictions from the LLM internal representations. They further extend their results to predicting multiple quantiles of the underlying distribution utilizing quantile regressors. They lastly validate generalization capabilities of the underlying predictors."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. the paper is very well written. All experiments all well-motivated, clearly explained, and results are well presented. \n\n2. The idea of eliciting numerical predictions and uncertainties from hidden states is timely, and can possible be extended to tasks beyond time series forecasting. \n\n3. The experiments are sound, and different aspects such as different kind of generalizations are well considered, thus are comprehensive. I found the calibration analysis interesting extension of the experiments and that it strengthens the credibility of the results. \n\nLastly, and to summarize, the paper is well written, and the findings are interesting, informative, and of interest to a broader community. The evidence that distributional information about LLM predictions are recoverable from hidden states is enlightening followed by sound experimental evidence."}, "weaknesses": {"value": "Most of the weaknesses are well acknowledged in the paper. These include (i) accessing hidden states may decrease the practicality of the method, (ii) relying on extensive autoregressive sampling for training the probes. \n\n1. While the paper positions itself only within the context of regression and time-series forecasting, it does not sufficiently discuss prior work that also show hidden states encode future outputs and uncertainty in other modalities and tasks. There is a growing literature that shows similar behaviors that probe internal states in the context of analyzing sentiment, factuality, intent, jailbreaking, chain-of-thought reasoning and etc. The related works would benefit from addressing these works as well for better positioning the contribution within a larger context.\n\n2. The experiments in section 2.2 focus on [-1,1] range but its not very clear how the method behaves for larger value ranges. although the authors mention testing other ranges, the results don't show how performance and calibration changes with scale, and it would be interesting to see how performance metric across different ranges change; whether larger numeric ranges introduce instability, or if normalization essentially removes that issue."}, "questions": {"value": "1. How sensitive are the probe's predictions to the choice of layers used ? It would be interesting to analyze which layers contribute the most to recovering the numerical predictions, and whether the same choice of \"best\" layers is consistent across tasks and different settings studied in the paper under \"generalization\". \n\n2. One form of generalization that is not studied in the experiments is whether a probe trained on llama2 for example generalizes ( or not ) to different models from the same family ( for example llama3 ). Results discussing this would be interesting."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "K4qL8MMvIt", "forum": "SsuBd46twl", "replyto": "SsuBd46twl", "signatures": ["ICLR.cc/2026/Conference/Submission4079/Reviewer_Mkh9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4079/Reviewer_Mkh9"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4079/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762394508518, "cdate": 1762394508518, "tmdate": 1762917167036, "mdate": 1762917167036, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}