{"id": "wMtS3brldm", "number": 9137, "cdate": 1758112556790, "mdate": 1759897741435, "content": {"title": "Dynamically Scaled Activation Steering", "abstract": "Activation steering has emerged as a powerful method for guiding the behavior of generative models towards desired outcomes such as toxicity mitigation. However, most existing methods apply interventions uniformly across all inputs, degrading model performance when steering is unnecessary. We introduce Dynamically Scaled Activation Steering (DSAS), a method-agnostic steering framework that decouples when to steer from how to steer. DSAS adaptively modulates the strength of existing steering transformations across layers and inputs, intervening strongly only when undesired behavior is detected. At generation time, DSAS computes context-dependent scaling factors that selectively adjust the strength of any steering method. We also show how DSAS can be jointly optimized end-to-end together with the steering function. When combined with existing steering methods, DSAS consistently improves the Pareto front with respect to steering alone, achieving a better trade-off between toxicity mitigation and utility preservation. We further demonstrate DSAS’s generality by applying it to a text-to-image diffusion model, showing how adaptive steering allows the modulation of specific concepts. Finally, DSAS introduces minimal computational overhead while improving interpretability, pinpointing which tokens require steering and by how much.", "tldr": "We propose DSAS, a steering-agnostic method that adaptively scales activation steering to reduce undesired behavior only when needed, improving safety and utility in generative models.", "keywords": ["Activation Steering", "Conditional Activation Steering", "Representation Editing"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0b5df46c46b4e0792608083fd09dac1e6fbff205.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces Dynamically Scaled Activation Steering (DSAS), a new conditional activation steering method which uses a logistic regression to determine the relevance of the concept at each sequence position and applies scaled steering accordingly. Training of the logistic regression is done using a labelled dataset of average activations: activations belonging to a source set (containing the concept) and activations belonging to a control set (free of the concept). The logistic regression learns to separate these two sets of actions and thus determine when the concept is present. The paper also introduces an end-to-end version of this following the LINEAS method with an additional new learning objective to encourage the consistency of the control set activations. Both methods perform well compared to existing conditional and unconditional steering methods. Results are mainly reported for the toxicity-reduction task, with a small example with diffusion models too."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The method is principled, simple, and outperforms the existing baselines on a key task of interest (toxicity reduction). The details behind this experiment are clear, and the results are strong. A particularly strong point is the efforts taken to carefully implement existing methods.\n- In general, this paper is well-written and easy to follow. \n- The addition of the Zou et al. (2024) circuit-breaking objective to maintain activations on the control set is nice and makes sense in this context.\n- The analysis is comprehensive in the sense that it considers two models and many ablations. It would have been good to see performance in another task aside from toxicity to solidify the claim that this method outperforms existing methods."}, "weaknesses": {"value": "- The presentation DSAS vs E2E-DSAS could be clearer. It is not immediately obvious that the claim \"DSAS trained end-to-end matches or outperforms the vanilla version\" is universally true. In Table 1, LINEAS+DSAS appears to outperform the E2E methods for Qwen 2.5. Similarly, the Pareto frontier plots in the appendix don't show one of the E2E methods consistently matching or outperforming the standard DSAS method. In Qwen, it seems a tie between DSAS and the ReLU variant of the E2E method, and with Gemma, it seems the Sigmoid variant is best. Perhaps this claim could be reworded.\n- The banana case study feels somewhat out of place and it would be more interesting to see examples from the actual task of interest. I understand there are challenges in reporting toxic statements in papers, but generally studies find ways to mitigate this, e.g. reporting text with asktrix. It would be helpful to see the actual learnt behaviour in this case. For example, where is the strongest steering applied? \n- Add some limitations, e.g. are there any cases in the toxicity case where the logistic regression coefficient seems wrong? The main empirical results are clearly strong, so I feel the authors can afford to spend more time addressing some limitations. For example, given the method relies on the strength of the linear classifier, are there other concepts which might be harder to get to work, e.g. where the concept isn't as obvious."}, "questions": {"value": "1. Did you consider a method to remove the reliance on the accuracy threshold? Clearly this is important given a layer with no signal is going to get ~0.5 coefficients, but could this be baked into the method? e.g. the strength of the steering is multiplied by some transformation of the accuracy, so that steering tends to 0 as accuracy tends to 0.5. Choosing a threshold of 0.75 is fine, but it feels a bit arbitrary. \n\n2. What is your theory of change for activation steering? The paper mentions standard alignment concerns in the introduction, but could you more clearly outline how improved steering directly addresses these. Especially in the presence of other strong alignment methods like standard finetuning pipelines. The results are strong, but clearly demonstrating the importance would help the impact of the paper, in my view."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Hzhc8MAmKm", "forum": "wMtS3brldm", "replyto": "wMtS3brldm", "signatures": ["ICLR.cc/2026/Conference/Submission9137/Reviewer_ancN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9137/Reviewer_ancN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9137/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761604153679, "cdate": 1761604153679, "tmdate": 1762920827619, "mdate": 1762920827619, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduced Dynamically Scaled Activation Steering (DSAS), a method-agnostic steering framework that decouples when to steer from how to steer. DSAS adaptively modulates the strength of existing steering transformations per layer, per input, and per token. DSAS intervenes strongly only when undesired behavior is detected in the input, improving the Pareto front with respect to steering alone on toxicity mitigation. The paper further demonstrated DSAS’s generality by applying it to a text-to-image diffusion model, enabling targeted concept modulation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper clearly identified pain points in existing conditional steering methods and addressd this gap with a universal conditioning mechanism that adapts steering strength per input (e.g., per token or spatial feature) and shows consistent improvements over prior conditional steering baselines.\n\nThe framework extended DSAS to end-to-end training with joint optimization, and demonstrated cross-modal generality by successfully applying it to text-to-image diffusion models.\n\nThe diffusion results are particularly interesting: where CAA affects concept- and non-concept-related images similarly, CAA+DSAS selectively blurs concept-related content while better preserving non-concept regions. \n\nThe paper is well written."}, "weaknesses": {"value": "While DSAS shows promising results on toxicity mitigation, validating its generalisability beyond this single behavior would strengthen the work, e.g. extending experiments to other safety-related behaviors such as bias mitigation and factuality changes. Similarly, experiments are limited to 1B–2B parameter models; evaluating DSAS on larger-scale LLMs would help confirm scalability across sizes.\n\nThe banana case study in the text-to-image diffusion experiments is interesting, but appears too narrow as a demonstration. Did you observe consistent concept-selective behaviours across other concepts? How many additional experiments you have conducted apart from steering away from 'bananas'? \n\nSection 3.2 could benefit from adding a bit more subheadings to guide readers."}, "questions": {"value": "DSAS adaptively adjusts steering strength per input and token. How sensitive is this scaling mechanism to the quality of the underlying detection signal (i.e., how “undesired behavior” is recognized)? Would DSAS still perform well if the classifier or detection metric is noisy or imperfect?\n\nThe paper describes DSAS as method-agnostic. Could the authors clarify whether DSAS could also apply to non-linear or generative steering methods, e.g., those using learned vectors or latent-space edits beyond linear activation additions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "dAes8yqPzO", "forum": "wMtS3brldm", "replyto": "wMtS3brldm", "signatures": ["ICLR.cc/2026/Conference/Submission9137/Reviewer_tbgj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9137/Reviewer_tbgj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9137/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923093624, "cdate": 1761923093624, "tmdate": 1762920827227, "mdate": 1762920827227, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present a method for adaptively controlling steering strength when steering activations away from undesired qualities. They study the tradeoff between language modeling / MMLU performance and toxicity reduction for their method as well as for vanilla steering methods. They then demonstrate their steering method using a case study with a placeholder concept. Finally, they apply their method to text-to-image diffusion."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "The paper is well-written and plots are clear and well-designed. The results in Figure 2 are strong at showing that they improve the Pareto frontier and Table 1 convincingly shows improvement over existing methods. The authors also show that their method extends beyond LLMs to diffusion models as well."}, "weaknesses": {"value": "Some results give concerns about the sample quality for samples generated after steering and it is unclear how diffusion model performance is affected by steering. Figure 2 should be clarified to ensure that the comparison is 1-1."}, "questions": {"value": "In Figure 2, it appears that fewer global strength values are considered for the vanilla version of each versus the version with DSAS. Why is that?\n\nIn Figure 2, why do you not show performance with E2E-DSAS as well?\n\nWhy does DSAS require a global strength at all? It seems like you could just learn the optimal strength value to balance the two objectives without reference to a preset strength\n\nHow does performance change on datasets beyond MMLU? I would be interested in seeing results for more difficult QA tasks, e.g. GPQA, and math or coding datasets as well to be sure there's no performance degradation\n\nHow similar does the control set need to be to the source set? Does the variation between them need to solely or mainly be the undesired quality? If not, how dissimilar can they be to still be effective and how did you choose your source, control, and target sets in practice?\n\nHow much variation do you observe between the strengths at each layer in practice?\n\nIn Table 1, why does E2E-DSAS perform worse than regular DSAS at toxicity reduction for Qwen but better for Gemma? \n\nIn Table 2, the samples post intervention seem to veer off and become incoherent. Is that something you observe in general, that when steering away from an undesired quality your output is significantly worse than the vanilla version? If not, why is that the case here?\n\nDoes DSAS hurt the general performance of text-to-image diffusion models when applied? Can you produce a similar plot as Figure 2 but measuring the quality of text-to-image diffusion rather than language modeling perplexity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1m00icIezh", "forum": "wMtS3brldm", "replyto": "wMtS3brldm", "signatures": ["ICLR.cc/2026/Conference/Submission9137/Reviewer_6Gqr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9137/Reviewer_6Gqr"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9137/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761954000253, "cdate": 1761954000253, "tmdate": 1762920826852, "mdate": 1762920826852, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Dynamically Scaled Activation Steering, a controller that decides when and how strongly to apply an activation-steering transform to model’s internal states, per-token (or spatial feature). DSAS trains a light logistic regressor per layer (with PCA for regularization) to distinguish source (undesired) from control (neutral) activations. Its probability output scales the base steering map so that strong interventions occur only when needed, decoupling when from how to steer. The authors also give an end-to-end variant E2E-DSAS trained jointly with LINEAS using a Wasserstein loss on source. With Qwen-2.5-1.5B and Gemma-2-2B, DSAS shows improvement on the Pareto front compared to unconditional steering and conditional methods. They also apply DSAS to text-to-image diffusion to blur images only when a target concept is present."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The controller is method-agnostic and composes with CAA, ITI, and LINEAS. The paper shows drop-in gains across three families on two LLMs. \n\n2. Pareto-front reporting instead of single operating points is good practice for safety-utility trade-offs. End-to-end variant with a principled control-set regularizer improves or matches vanilla DSAS when trained with LINEAS shows joint optimization is viable. \n\n3. Low overhead with simple linear classifiers and small FLOP cost per token provides practical inference footprint."}, "weaknesses": {"value": "1. Relatively small training sets for toxicity risk overfitting and unstable layer classifiers, and results may not hold with broader distributions. Using only 32 examples per split should be justified, with variance analyses beyond 4 seeds. \n\n2. The paper seems to train classifier on average embeddings and then applying per-token, and this mismatch may blunt localization. Per-token supervision would better support token-wise scaling. \n\n3. Given scaling phenomena in steering, showing results on larger model parameters would strengthen claims of generality. (The line of work this paper compares to does evaluate larger sizes.) \n\n4. Toxicity is measured with a single RoBERTa-style classifier, which could introduce metric biases. Include an ensemble of detectors to ensure DSAS doesn’t induce evasive paraphrasing would be beneficial. \n\n5. Layer selection and PCA dimension are under-motivated. While Appendix mentioned, main-text justifications for why five PCs suffice and how sensitive performance is to accuracy threshold and r are needed. More ablation details would be beneficial."}, "questions": {"value": "Could the paper condition DSAS on cross-attention maps or segmentation masks to localize interventions to object regions (rather than diffuse blurring)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SHRl9IChq4", "forum": "wMtS3brldm", "replyto": "wMtS3brldm", "signatures": ["ICLR.cc/2026/Conference/Submission9137/Reviewer_V18V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9137/Reviewer_V18V"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9137/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962980537, "cdate": 1761962980537, "tmdate": 1762920826525, "mdate": 1762920826525, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}