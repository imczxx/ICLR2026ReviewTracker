{"id": "5YRmf6GbNs", "number": 7767, "cdate": 1758035356865, "mdate": 1759897833652, "content": {"title": "S$^2$MAM: Semi-supervised Meta Additive Model for Robust Estimation and Variable Selection", "abstract": "Semi-supervised learning with manifold regularization is a classical family for learning from both labeled and unlabeled data jointly, where the key requirement is that the support of the unknown marginal distribution possesses the geometric structure of a Riemannian manifold. Typically, the Laplace-Beltrami operator-based manifold regularization can be approximated empirically by the Laplacian regularization associated with the entire training data and its corresponding graph Laplacian matrix. However, the graph Laplacian matrix depends heavily on the pre-specifying similarity metric and may result in inappropriate penalties when facing redundant and noisy input variables. \nTo address the above issues, this paper proposes a new Semi-Supervised Meta Additive Model (S$^2$MAM) based on a bilevel optimization scheme, which automatically identifies informative variables, updates the similarity matrix, and achieves interpretable predictions simultaneously. Theoretical guarantees are provided for S$^2$MAM, including the computing convergence and the statistical generalization bound. Experimental assessments on synthetic and real-world datasets validate the robustness and interpretability of the proposed approach.", "tldr": "", "keywords": ["sparse additive model", "manifold regularization", "bilevel optimization", "robustness", "learning theory"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5606a2c3bd76c021e7cb382f5e9c89e350b31506.pdf", "supplementary_material": "/attachment/cc55cc06ec7984cceec0071f3c07aac703a2f7bf.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces a SSL method, that performs robust feature selection combined with manifold regularization. This makes the method also interpetable (because we can see which features are used). Feature selection is achieved through l2,1 regularization; but also a bi-level optimization routine is used on top, to update the masks of features and update the regularization terms. The bi-level optimization is relaxed into a probabilistic bilevel problem, which can be solved efficiently. Several proofs are given showing the algorithm converges and enjoys good generalization bounds. An extensive empirical evaluation is compared, showing the method obrtains state-of-the-art performance, especially when uninformative and noisy variables are included."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Extensive empirical evaluation\n- The proofs are a nice addition, but I did not check them carefully\n- I like how the work is presented, and the comparison with the SOTA with the table makes the contribution very clear"}, "weaknesses": {"value": "- I found it hard to understand the bilevel optimization; I think there might be a few notational errors (see questions below), but maybe a figure may also help. \n\n- I find it hard to evaluate whether the proposed method improves on state-of-the-art due its technical innovations, or whether it simply can remove improperly scaled features? Are features scaled prior to fitting models (also for competetitors)? See also questions.\n\n- I think reflections on the weaknesses and future work would be better suited to the main body."}, "questions": {"value": "1. Are the features scaled in the experiments? How? If not, why not? For me, the features that are normally distributed with a mean of 100 and std of 100, are clearly going to mess with algorithms that are not scaling features. In this case, your algorithm may just be favored because it will ignore unscaled features; meanwhile, I think your claim is that your algorithm is robust for other reasons. So it would be good to include an experiment where features are properly scaled (for all baselines). \n\n2. I think in line 242 it should be alpha^*? For me, the bilevel optimization was not clear. Is it true that alpha^* is the result of an optimization? I am not sure what is the difference with alpha hat in line 251. \n\n3. \"It is usually intractable to solve the bilevel problem.\" This is a bit vague. Can you make this more concrete? (if possible). Furthermore, can you clarify why this is difficult? \n\n4. I did not understand how C was set (remark 6). Can you explain in more detail? E.g. I don't understand over which data quantiles are taken, and why multiple models are trained. I checked the Appendix but I still was a bit lost. \n\nSome other minor issues:\n\n5. Why logistic loss for S^2 MAM? In principle we can plug in any loss, right? \n\n6. Line 254; I think it would be good to more clearly indicate that L depends on m, e.g. write L(m)\n\n7. Its unclear why D_{meta} was introduced and why its called D_{meta}. Isn't it simply the case that this is the labeled data? How it is written now, it comes accross as if D_{meta} could be instantiated in different ways. \n\n8. Why is Tau needed? It is introduced, but Appendix B.2.3 states you always set all Tau equal to 1? \n\n9. \"As in Table 2 with ...\"; do you mean \"As can be seen in Table 2\" ? \n\n10. Line 295; are you now saying here that m^t is a sample from p(s|m) ? I found it a bit strange that this is a single sample; but I can imagine that if you iterate long enough it will still converge? E.g. you could also update L^t with multiple samples from m. Is this something you considered?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uNhmyKjQQT", "forum": "5YRmf6GbNs", "replyto": "5YRmf6GbNs", "signatures": ["ICLR.cc/2026/Conference/Submission7767/Reviewer_rNn1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7767/Reviewer_rNn1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7767/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761768182581, "cdate": 1761768182581, "tmdate": 1762919811321, "mdate": 1762919811321, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes $S\\^2MAM$ , a bilevel optimization framework that couples feature-level masking with manifold regularization to improve robustness and interpretability in semi-supervised learning. Experiments on synthetic data, UCI-style regressions, ADNI cognitive scores , and COIL-20 classification show improved robustness under injected redundant/noisy features versus, and several deep SSL baselines. For scalability the authors use CNN embeddings for images and RFF to reduce kernel cost from $O((\\ell+u)^2)$ to $O((\\ell+u)D)$."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Variable masks simultaneously reduce noise impact on the Laplacian and yield clear feature importance.\n2. Policy-gradient updates with projection have a stated $O(1/\\sqrt{T})$ convergence; a generalization bound is provided for the base model.\n3. Synthetic, UCI, ADNI regression, and COIL-20 classification; robustness under injected noisy/redundant features is consistently strong.\n4. CNN embeddings for images and RFF for kernel approximation; simple to integrate in non-deep settings.\n5. Identifies how fixed similarity metrics are distorted by irrelevant variables and addresses it directly."}, "weaknesses": {"value": "1. The current statistical bound omits the combined stochastic mask + adaptive graph procedure. This leaves a gap between the analyzed surrogate and the implemented algorithm.\n\n2. The paper does not report whether baseline/control-variate techniques are used, how many mask samples are drawn per iteration, or temperature settings / comparisons to Gumbel-Softmax. Without these, it is hard to assess variance, convergence behavior, and accuracy. \n\n3. Graph construction and updates are not evaluated against practical alternatives (e.g., kNN graphs, ANN search, sparsification, mini-batch graph updates) nor against the full $O(n^2)$ similarities baseline.\n\n4.  The comparison set focuses on manifold methods and omits competitive consistency/augmentation SSL baselines. \n\n5. The paper does not report sensitivity to key hyperparameters ($C,\\mu,D$), learning rates, or projection radius; nor does it examine mask stability across random seeds or its link to downstream interpretability (e.g., ADNI feature groups). \n\n6. The “Unlabeled” column is not precisely defined, and for COIL-20 with CNN features the semantics of variables and how mask importance maps back to image attributes are unclear."}, "questions": {"value": "Please see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Xs9BPk0AoP", "forum": "5YRmf6GbNs", "replyto": "5YRmf6GbNs", "signatures": ["ICLR.cc/2026/Conference/Submission7767/Reviewer_YaK4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7767/Reviewer_YaK4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7767/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761787399864, "cdate": 1761787399864, "tmdate": 1762919810935, "mdate": 1762919810935, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new Semi-Supervised Meta Additive Model(S2MAM) based on a bilevel optimization scheme to automatically identifies informative variables, updates the similarity matrix, and achieves interpretable predictions simultaneously. The authors provide theoretical guarantees regarding the computing convergence and the statistical generalization bound. Experiments on synthetic and real-world datasets demonstrate promising improvements over previous methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper proposes a meta-learning method for manifold-regularized additive model with a bilevel optimization scheme to select informative features.\n2. The paper provides theoretical guarantees for the proposed model.\n3. The paper provides extensive experiments on both synthetic and real-world datasets to show that the proposed method outperforms other methods."}, "weaknesses": {"value": "1. The manuscript **lacks clarity and organization**. Key information, such as **undefined notation** ($\\alpha$, $\\tau$), **unexplained terms** (\"Unlabeled\"), **unclear experimental setups** (noise in Table 4), and **inconsistencies** (Table 5 reference, absent visualizations), needs thorough correction. A **comprehensive proofreading** is recommended.\n2. The **motivation seems weak**. A more detailed analysis of the **specific significance and benefits of manifold regularization** over other SSL approaches would strengthen the paper. Furthermore, the comparison **could be broadened** by including other SSL methods (e.g., pseudo-labeling). The contribution seems to be incremental.\n3. The **validity of the independent feature assumption** (Remark 2) seems like a strong assumption that **warrants further discussion**. Given that many real-world features are naturally correlated, an analysis of the model's **robustness** to this assumption would be helpful.\n4. The **distinction between \"uninformative features\" ($N(0, 1)$) and \"noisy features\" ($N(100, 100)$) is unclear** and needs explanation. The **reasoning behind this inconsistent application** of these feature types across different datasets should be explained.\n5. **Core Size $C$ is highly influential**. The **computational cost of optimizing $C$ seems to be excluded** from the reported training time comparisons (L 1447). Additionally, the claim (L 1447) about determining $C$ early on **needs a more detailed explanation**.\n6. For the image experiments: The choice to use the **first FCN for feature extraction needs explanation. An explanation for the **32-dimensional feature space** is also needed. Finally, the noise experiments are limited to **block noise**; experiments on more common **random noise** are missing."}, "questions": {"value": "1. The authors introduce multiple additive hypothesis spaces (L 192), but why was the **Reproducing Kernel Hilbert Space (RKHS)** specifically chosen? What are the implications or effects of choosing an alternative hypothesis space?\n2. The authors employ a **sampling strategy based on Bernoulli distributions** to select informative features. Why was this distribution chosen over others? Furthermore, does this specific sampling strategy inadvertently allow the selected features to **contain noisy features**?\n3. The authors state that the experiments were repeated 100 times, yet the **standard deviations in Table 2 remain quite large**. What is the reason for this high variability? Have the authors conducted an in-depth analysis to understand the underlying cause?\n4. In Table 9, the standard deviation for the **R2 Score is reported to be greater than 1**. As the R2 Score is generally defined as being less than or equal to 1, this result is unusual. Could the authors please provide an explanation for this phenomenon?\n5. There appears to be a **discrepancy in the experimental results** between Table 4 and Table 13. Could the authors clarify the reason for this difference?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Qnib932v0P", "forum": "5YRmf6GbNs", "replyto": "5YRmf6GbNs", "signatures": ["ICLR.cc/2026/Conference/Submission7767/Reviewer_7hG3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7767/Reviewer_7hG3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7767/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762066378497, "cdate": 1762066378497, "tmdate": 1762919809914, "mdate": 1762919809914, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes one Semi-Supervised Meta Additive Model method based on a bilevel optimization scheme, which automatically identifies informative variables, updates the similarity matrix, and achieves interpretable predictions simultaneously. The proposed semi-supervised meta additive model (MAM) unifies three key objectives: robust estimation under noisy/redundant variables, automatic variable selection, and interpretable predictions."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Unlike existing SSL methods (e.g., LapSVM) that rely on pre-specified similarity matrices and fail to handle variable noise, or supervised additive models (e.g., SpAM) that cannot leverage unlabeled data, the proposed MAM method introduces a bilevel optimization framework to jointly learn variable masks, additive component functions and adaptive similarity matrices.\n\n2. The paper provides comprehensive theoretical support for MAM, addressing both optimization convergence and statistical generalization."}, "weaknesses": {"value": "1. While this paper mentions using for mask probability initialization in Section 2.4, it provides insufficient guidance on choosing the core variable size. And it is a critical hyperparameter that directly impacts variable selection performance.\n\n2. This paper analyzes the theoretical complexity of MAM. However, it lacks empirical quantification of the bilevel framework’s overhead compared to single-level SSL methods.\n\n3. The authors compare the proposed MAM method to traditional SSL methods (e.g., LapSVM) and a few deep SSL models (e.g., SSNP) but fail to include state-of-the-art deep SSL methods designed for noisy/variable selection tasks, such as FixMatch (Sohn et al., 2020), FlexMatch (Zhang et al., 2021) and Semi-Supervised Variable Selection Networks (e.g., SSVS-Net, Li et al., 2023).\n\n4. The theoretical analysis as in Section 3 and most experiments focus on convex objectives (e.g., logistic regression, squared loss for regression). However, the authors claim the proposed MAM method is applicable to non-convex tasks (e.g., neural networks). \n\n5. No theoretical guarantees are provided for non-convex additive components (e.g., neural additive layers, Agarwal et al., 2021).\n\n6. Empirical validation is limited to convex tasks—there is no experiment on non-convex objectives (e.g., training a shallow neural network on MNIST with semi-supervised labels and noisy pixels)."}, "questions": {"value": "1. While this paper mentions using for mask probability initialization in Section 2.4, it provides insufficient guidance on choosing the core variable size. And it is a critical hyperparameter that directly impacts variable selection performance.\n\n2. This paper analyzes the theoretical complexity of MAM. However, it lacks empirical quantification of the bilevel framework’s overhead compared to single-level SSL methods.\n\n3. The authors compare the proposed MAM method to traditional SSL methods (e.g., LapSVM) and a few deep SSL models (e.g., SSNP) but fail to include state-of-the-art deep SSL methods designed for noisy/variable selection tasks, such as FixMatch (Sohn et al., 2020), FlexMatch (Zhang et al., 2021) and Semi-Supervised Variable Selection Networks (e.g., SSVS-Net, Li et al., 2023).\n\n4. The theoretical analysis as in Section 3 and most experiments focus on convex objectives (e.g., logistic regression, squared loss for regression). However, the authors claim the proposed MAM method is applicable to non-convex tasks (e.g., neural networks). \n\n5. No theoretical guarantees are provided for non-convex additive components (e.g., neural additive layers, Agarwal et al., 2021).\n\n6. Empirical validation is limited to convex tasks—there is no experiment on non-convex objectives (e.g., training a shallow neural network on MNIST with semi-supervised labels and noisy pixels)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "POsxbtYmVq", "forum": "5YRmf6GbNs", "replyto": "5YRmf6GbNs", "signatures": ["ICLR.cc/2026/Conference/Submission7767/Reviewer_S5mP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7767/Reviewer_S5mP"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7767/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762249944436, "cdate": 1762249944436, "tmdate": 1762919809386, "mdate": 1762919809386, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}