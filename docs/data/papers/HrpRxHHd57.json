{"id": "HrpRxHHd57", "number": 11277, "cdate": 1758194967018, "mdate": 1759897596664, "content": {"title": "TrigReason: Trigger-Based Collaboration between Small and Large Reasoning Models", "abstract": "Large Reasoning Models (LRMs) achieve strong performance on complex tasks through extended chains of thought but suffer from high inference latency due to autoregressive reasoning. Recent work explores using Small Reasoning Models (SRMs) to accelerate LRM inference, yet existing frameworks such as SpecReason adopt a polling-based design that repeatedly invokes the LRM for verification at every step. This approach is inefficient, as frequent LRM calls introduce a high computational overhead, and is unreliable, since the LRM as a judge is prone to errors. In this paper, we systematically characterize the capability boundaries of SRMs and identify three common types of reasoning risks: (1) path divergence, where SRMs lack the strategic ability to construct an initial plan, causing reasoning to deviate from the most probable path; (2) cognitive overload, where SRMs fail to solve particularly difficult steps; and (3) recovery inability, where SRMs lack robust self-reflection and error correction mechanisms. To address these challenges, we propose TrigReason, a trigger-based collaborative reasoning framework that replaces continuous polling with selective intervention. TrigReason delegates most reasoning to the SRM and activates LRM intervention only when necessary—during initial strategic planning (strategic priming trigger), upon detecting extraordinary overconfidence (cognitive offload trigger), or when reasoning falls into unproductive loops (intervention request trigger). We show that TrigReason enables more reliable and efficient collaboration between small and large reasoning models, with broad practical application. Under edge–cloud conditions, TrigReason reduces latency by 43.9\\% and API cost by 73.3\\% compared to SpecReason.", "tldr": "", "keywords": ["Large Reasoning Models", "Collaborative Reasoning", "Efficient Thinking"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/58d2fa78a8984ea1019248c1027c8eaa20ada701.pdf", "supplementary_material": "/attachment/fbbf14a3bfc470b071690aef052a1c27a3d7345c.zip"}, "replies": [{"content": {"summary": {"value": "LRMs suffer from high inference latency due to autoregressive token generation. Current acceleration methods using SRMs, such as SpecReason, rely on an inefficient polling-based design that invokes the LRM for verification at every step. This paper proposes TrigReason, a trigger-based collaborative framework that replaces continuous polling with selective intervention. TrigReason delegates most reasoning to the SRM and activates the LRM only when necessary: for initial strategic planning (Strategic Priming), upon detecting SRM overconfidence on difficult steps (Cognitive Offload), or when the SRM gets stuck (Intervention Request). This maintains LRM-level accuracy while significantly reducing latency and API costs in edge-cloud setups compared to SpecReason."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper provides a clear characterization of the limitations in prior work, specifically the polling-based SpecReason framework. It highlights the inefficiency of constant verification and presents experiments questioning the reliability of the LRM-as-a-Judge mechanism, noting that LRMs frequently reject their own reasoning steps.\nThe paper attempts to categorize the common failure modes of SRMs. It identifies three risk patterns: path divergence , cognitive overload , and recovery inability, which are then used to motivate the design of the proposed heuristic triggers.\n\nThe TrigReason framework is evaluated in an edge-cloud deployment scenario, a relevant setting for this type of collaborative inference. In this setting, the method is reported to reduce latency by 43.9% and API cost by 73.3% compared to the SpecReason baseline, addressing the overheads identified in the polling-based approach."}, "weaknesses": {"value": "1. **Obvious writing error in the paper:** In Section 4.1 “Models”, the definitions of SRM and LRM are completely reversed. For example, the paper defines the 32B QwQ model as the SRM and the 1.5B DeepSeek model as the LRM. This directly contradicts other parts of the paper (e.g., Fig. 1 and Fig. 4) and represents a serious typographical mistake.\n\n2. **Too many hyperparameters and manual configurations, questionable robustness:**\n   The proposed method introduces several new hyperparameters, such as the *cognitive overload threshold*, *bootstrapping steps*, and *refinement steps*. The ablation study (Fig. 6a) shows that the optimal overload threshold varies across different model pairs. This suggests that the method may require careful hyperparameter tuning when applied to new SRM–LRM combinations, increasing the deployment cost and raising concerns about generalization and elegance.\n\n   * **“Cognitive offloading” trigger (the trickiest part):** This trigger relies on a counterintuitive empirical assumption that when the SRM (the small model) experiences cognitive overload, it paradoxically becomes overconfident (i.e., exhibits unusually low perplexity). This is a very tricky observation rather than a general confidence estimation; it captures an abnormal behavior pattern specific to SRM’s failure mode. Moreover, the activation of this trigger depends on two finely tuned hyperparameters: the coverage threshold and perplexity threshold.\n   * **“Intervention request” trigger:** This trigger essentially functions as a keyword-matching system. It scans for “hesitation words” such as *wait*, *hmm*, or *alternatively* in the text to determine whether the SRM is stuck. This is a clear heuristic rule that relies heavily on the predefined vocabulary (see Appendix D), thus lacking sufficient generalization capability.\n   * **“Strategic initialization” trigger:** This is a hard-coded rule that forces LRM to take charge of the first n steps. Although the ablation study shows its effectiveness, this “forced start” design appears straightforward and lacks adaptivity.\n\n3. **Dependence on heuristic rules:**\n   The *intervention request trigger* depends on a predefined lexicon of hesitation words. Such word-based heuristic rules are not robust. If the SRM becomes logically stuck without using these specific words, the trigger may fail to activate. Overall, the mechanism appears overly *tricky* and insufficiently generalizable."}, "questions": {"value": "Same as the weeknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qMGIDjtQd1", "forum": "HrpRxHHd57", "replyto": "HrpRxHHd57", "signatures": ["ICLR.cc/2026/Conference/Submission11277/Reviewer_1WNG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11277/Reviewer_1WNG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11277/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761531880616, "cdate": 1761531880616, "tmdate": 1762922429589, "mdate": 1762922429589, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces TrigReason, a trigger-based collaborative reasoning framework designed to improve the efficiency of speculative reasoning between Small Reasoning Models (SRMs) and Large Reasoning Models (LRMs). Current approaches rely on a polling-based mechanism where the LRM verifies each reasoning step generated by the SRM. This frequent verification is computationally expensive and unreliable because LRMs often make subjective or inconsistent judgments about intermediate reasoning steps. To overcome this, TrigReason replaces continuous polling with selective, event-triggered intervention. It identifies and addresses three key reasoning failure modes of SRMs, including (1) Path Divergence, (2) Cognitive Overload, and (3) Recovery Inability, and introduces corresponding triggers. Empirical results across three benchmarks show that TrigReason maintains or slightly surpasses LRM-level accuracy while reducing latency and API cost under edge–cloud settings, compared to SpecReason."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper identifies a concrete bottleneck, i.e., polling inefficiency in speculative reasoning, and provides convincing empirical evidence that LRM judgments are inconsistent and unreliable, even when judging their own reasoning trajectories.\n2. The paper proposes an event-driven approach grounded in behavioral analysis of SRM reasoning failures. The introduction of token-level perplexity monitoring and linguistic hesitation detection represents a good diagnostic approach for hybrid reasoning systems.\n3. Extensive experiments across multiple reasoning datasets and SRM–LRM pairs, together with edge–cloud deployment studies, demonstrate both generality and practical efficiency."}, "weaknesses": {"value": "1. While empirically well-supported, the triggers lack a formal theoretical foundation. The thresholds (e.g., perplexity < 1.05) and trigger rules are heuristic, raising questions about generalizability to unseen models or tasks.\n2. The detection mechanisms (e.g., fixed hesitation word list, perplexity thresholds) depend on manually designed signals rather than learned or adaptive ones, which might limit scalability to broader reasoning domains beyond math and logic.\n3. The benchmarks focus heavily on symbolic/mathematical reasoning (AIME, GPQA). It remains unclear how well TrigReason extends to open-ended reasoning, commonsense tasks.\n4. There are many presentation issues in the paper, such as incomplete sentence in Line 189, the direct reference to the figures in Appendix (this is potentially violating the page limit policy)."}, "questions": {"value": "1. How sensitive are the trigger parameters across different model pairs or domains? Is it possible to set them more automatically?\n2. Have you tested TrigReason on tasks involving non-symbolic reasoning (e.g., commonsense QA)?\n3. How do the triggers behave when SRM outputs are noisy or contain linguistic variations (e.g., “hmm...” vs “let’s rethink this”)? \n4. In edge–cloud setups, how does TrigReason handle asynchronous LRM availability or network delays? Could trigger latency itself introduce new bottlenecks?"}, "flag_for_ethics_review": {"value": ["Yes, Other reasons (please specify below)"]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}, "details_of_ethics_concerns": {"value": "In the main body of the submission, the authors directly refer to the figures in the Appendix, instead of the sections in the Appendix. This potentially violates the page limit policy (9 pages at most). In other venues, such unprofessional presentations will result in desk rejection."}}, "id": "brkqmFq957", "forum": "HrpRxHHd57", "replyto": "HrpRxHHd57", "signatures": ["ICLR.cc/2026/Conference/Submission11277/Reviewer_xCXr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11277/Reviewer_xCXr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11277/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761547942441, "cdate": 1761547942441, "tmdate": 1762922428672, "mdate": 1762922428672, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces TrigReason, a framework aiming to enhance the efficiency of collaborative reasoning between a Small Reasoning Model (SRM) and a Large Reasoning Model (LRM). It critiques the polling-based approach of prior work like SpecReason, where the LRM verifies every SRM step, citing inefficiency and unreliability of LRM judgments. TrigReason identifies three common SRM reasoning risks: path divergence (poor initial strategy), cognitive overload (failure on complex steps, often signaled by overconfidence/low perplexity), and recovery inability (getting stuck, signaled by hesitation markers) . Instead of continuous polling, TrigReason uses selective LRM intervention triggered by specific events: (1) Strategic Priming (LRM provides initial steps), (2) Cognitive Offload (LRM intervenes on overconfident SRM steps), and (3) Intervention Request (LRM intervenes upon detecting SRM hesitation loops). Experiments on math (AIME24/25) and QA (GPQA) benchmarks show TrigReason maintains accuracy comparable to LRM-only and SpecReason, while significantly improving efficiency: increasing SRM token utilization (1.7x-4.8x vs SpecReason), and reducing latency (by 43.9%) and API cost (by 73.3%) in simulated edge-cloud settings. Ablations support the trigger designs, and a theoretical reliability characterization is included."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**Well-Motivated Problem:** Addresses the important practical challenge of reducing LRM inference latency and cost for complex reasoning tasks while maintaining accuracy.\n\n**Principled Approach:** The trigger-based design is grounded in a systematic analysis of SRM failure modes, making the interventions targeted and interpretable. \n\n**Significant Efficiency Gains:** The empirical results convincingly demonstrate substantial improvements in latency, cost, and SRM utilization compared to the SpecReason baseline, without compromising accuracy.\n\n**Thorough Evaluation:** The framework is validated across multiple difficult benchmarks (AIME, GPQA) , various SRM-LRM pairs , including a practical edge-cloud simulation , and supported by ablation studies.\n\n\n**Clear Improvement over Baseline:** Directly tackles and demonstrably overcomes key weaknesses (inefficiency, unreliability) identified in the prior state-of-the-art (SpecReason)."}, "weaknesses": {"value": "**Hyperparameter Tuning:** The framework introduces several hyperparameters (priming steps $n$, perplexity threshold $\\tau$, coverage threshold $\\rho$, hesitation count $k$, rectification steps $m$). While ablations show sensitivity, the optimal values appear model/task-dependent. Guidance on tuning these efficiently for new setups is limited.\n\n**Domain Generality:** The evaluation is primarily focused on mathematical reasoning and QA tasks. While these are important domains, the universality of the identified failure modes and the effectiveness of the triggers in other reasoning domains (e.g., planning, creative generation, coding) remains to be demonstrated.\n\n**Reliability of Trigger Signals:** The paper demonstrates correlations, but the causal link and robustness need consideration. Can SRMs fail without showing high confidence or hesitation? Can these signals appear spuriously? The reliance on a fixed list of hesitation words (Appendix D) might also be brittle."}, "questions": {"value": "1. How robust are the optimal hyperparameter settings found in the ablations (e.g., $\\rho=0.85$ or $0.75$) across different SRM-LRM pairs, model sizes, or reasoning domains beyond math/QA? What is the recommended procedure for tuning these parameters in practice?\n\n2. Regarding the Cognitive Offload trigger: How sensitive is performance to the perplexity threshold $\\tau$? Are there failure cases where SRMs err without exhibiting abnormally low perplexity, or vice-versa? Were alternative confidence metrics considered?\n\n3. Regarding the Intervention Request trigger: How was the list of hesitation words (Appendix D) derived? How well does this trigger generalize across different model families or languages? Could models enter unproductive loops without using these specific phrases?\n\n4. How are discrete \"reasoning steps\" defined for calculating the perplexity ratio $r_s$ and tracking consecutive hesitations? Is segmentation based on punctuation, newlines, or another method, and how might this affect trigger activation?\n\n5. Appendix F suggests TrigReason might lag behind LRM-only performance at very high token budgets (32K). Can you quantify this gap and explain why trigger-based collaboration might become suboptimal in resource-abundant settings?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MfYOmgMNjz", "forum": "HrpRxHHd57", "replyto": "HrpRxHHd57", "signatures": ["ICLR.cc/2026/Conference/Submission11277/Reviewer_EARS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11277/Reviewer_EARS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11277/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761721527517, "cdate": 1761721527517, "tmdate": 1762922428045, "mdate": 1762922428045, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces TrigReason, a trigger-based collaborative reasoning framework that coordinates Small Reasoning Models (SRMs) and Large Reasoning Models (LRMs). Unlike the polling-based paradigm used in SpecReason, which continuously queries the LRM for verification at each reasoning step, TrigReason employs event-driven triggers (strategic priming, cognitive offload, and intervention request) to selectively involve the LRM only when necessary. Empirical evaluations on AIME24, AIME25, and GPQA Diamond demonstrate that TrigReason reduces latency and API cost while maintaining comparable accuracy to full-LRM reasoning. The authors claim that this selective intervention mechanism effectively balances efficiency and reliability in collaborative reasoning."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear Problem Formulation – The paper provides a well-articulated motivation by analyzing inefficiencies in the existing polling-based speculative reasoning frameworks (e.g., SpecReason).\n2. Systematic Characterization – The identification of three SRM failure modes (path divergence, cognitive overload, recovery inability) adds structure to the reasoning failure analysis.\n3. Empirical Breadth – The experiments cover multiple datasets (AIME24/25, GPQA Diamond) and SRM–LRM pairs, showing generality in observed trends."}, "weaknesses": {"value": "1. While the trigger-based scheme is presented as novel, its underlying principle (adaptive invocation of a stronger model based on simple heuristic signals) is an incremental modification over existing selective collaboration paradigms. The work lacks deeper theoretical or algorithmic contribution beyond heuristic event detection.\n2. The triggers (confidence, hesitation words, initial planning) appear manually designed and dataset-specific. There is little discussion on how robust or general these heuristics are across reasoning domains (e.g., multi-modal reasoning, logic proofs, planning tasks).\n3. Lack of Statistical Validation: The claimed efficiency improvements are presented mainly in relative percentages, without statistical significance testing or variance analysis. There is no examination of whether results are stable across random seeds or reasoning temperatures.\n4. Incomplete Comparative Baseline: The experiments compare mainly with SpecReason and full LRM inference, but omit several recent acceleration or mixture frameworks (e.g., ReaLM, ThinkFlow, or self-adaptive CoT controllers). This makes it difficult to judge whether TrigReason truly advances the state of the art.\n5. The paper excludes latency from the main results, citing hardware variability, yet latency is central to the efficiency motivation. This omission weakens the empirical foundation of the efficiency claims.\n6. While three risk types are defined, their quantitative prevalence and interaction are not thoroughly analyzed. For example, it is unclear how often each trigger actually fires, and whether those interventions consistently lead to correct outcomes."}, "questions": {"value": "1. Please report the frequency and distribution of each trigger’s activation (strategic priming, cognitive offload, intervention request). How do these correlate with actual accuracy gains or failures?\n2. Have you tested whether the same thresholds (e.g., perplexity < 1.05, ρ = 0.85) transfer to unseen reasoning domains or models? Adding results on a dataset outside math reasoning (e.g., scientific QA, commonsense reasoning) would strengthen claims of generality.\n3. Include comparisons with ReaLM (2025), ThinkFlow (2024), or Adaptive-CoT controllers, which also perform selective reasoning delegation. Without these, the novelty and empirical advantage are hard to assess.\n4. Even if hardware-sensitive, please provide approximate latency distributions (mean, std) under identical conditions for fairness. Otherwise, efficiency claims remain qualitative.\n5. What happens if hesitation-based triggers are replaced by learned detectors or simplified confidence thresholds? This would clarify whether the improvements stem from general mechanisms or specific handcrafted choices."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "n7lDe5IOxb", "forum": "HrpRxHHd57", "replyto": "HrpRxHHd57", "signatures": ["ICLR.cc/2026/Conference/Submission11277/Reviewer_zBA1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11277/Reviewer_zBA1"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11277/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761877527205, "cdate": 1761877527205, "tmdate": 1762922427562, "mdate": 1762922427562, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}