{"id": "jITPFROpWN", "number": 20675, "cdate": 1758308886634, "mdate": 1759896964622, "content": {"title": "Learning Koopman Representations with Controllability Guarantees", "abstract": "Learning nonlinear dynamical models from data is central to control. Two fundamental challenges exist: (1) how to learn accurate models from limited data, and (2) how to ensure the learned models are suitable for control design of the nominal system. We address both by enforcing a critical \\emph{a priori} property of the nominal system during learning: \\emph{controllability}. Controllability guarantees the existence of control policies that can drive the learned model from any initial state to any desired state. From a modeling perspective, it captures key structural features of the nominal system, thereby improving data efficiency. For downstream control, it enables the use of modern techniques such as model predictive control (MPC). Our approach is based on controllability-preserving Koopman representation learning. Rather than learning dynamics directly in the nominal state space, we learn in a latent space where the system admits a linear representation. We prove that controllability of the learned latent model implies controllability in the nominal state space. To enforce this property, we introduce a novel canonical parameterization of the latent dynamics matrices. We further incorporate Gramian-based regularization to shape the degree of controllability, yielding well-conditioned models for control. Implemented as an end-to-end Neural ODE framework, our method learns models that are both predictive and controllable from limited data. Experiments on nonlinear benchmarks demonstrate accurate long-horizon prediction, reliable MPC performance, and substantially improved data efficiency.", "tldr": "Learning koopman representations of nonlinear dynamical systems with controllability guarantees", "keywords": ["Dynamical System", "Koopman Operator", "Control", "Controllability", "Nonlinear System"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/265834114a074e1fcab79adbf16a823d08504212.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a framework for learning Koopman representations of nonlinear control systems that are guaranteed to be controllable. The authors derive conditions linking output-to-output controllability (OOC) and standard state-output controllability (SOC), and introduce a canonical parameterization of the latent linear dynamics matrices A_\\theta, B_\\theta that ensures controllability by construction. Additionally, a controllability Gramian regularizer is used to improve the conditioning (“well-controllable” property). The learned model can be used directly in model predictive control (MPC). Experiments on benchmark systems demonstrate improved sample efficiency and control performance compared to standard Deep Koopman (DKO) and MLP-based models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1. Embedding controllability directly into the Koopman parameterization is novel. Prior deep Koopman and neural ODE models treat controllability as an afterthought or soft constraint. The proposed canonical form and similarity transform provide an elegant, principled way to enforce this property.\n\nS2. The proofs linking OOC↔SOC and the use of the finite-time output controllability Gramian are mathematically well-grounded and consistent with classical control theory. This makes the paper attractive to both ML and control communities.\n\nS3. The ability to plug the learned model directly into linear MPC is a significant engineering advantage. The demonstration that the approach maintains performance under limited data conditions is also persuasive."}, "weaknesses": {"value": "W1. There is limited novelty relative to the existing Koopman literature. While embedding controllability guarantees is new, the core architecture—learning a linear operator in latent space via encoder + linear dynamics + decoder—is largely inherited from standard deep Koopman frameworks. The contribution thus appears incremental in form but conceptual in framing. The authors should clarify in what sense their controllability parameterization extends beyond “structured Koopman learning” or prior work on “control-aware embeddings.”\n\nW2. Controllability parameterization may constrain expressive power. The use of a canonical controllable form plus similarity transform P_\\theta guarantees controllability but may significantly restrict the learned dynamics manifold. It is unclear whether the proposed structure can approximate arbitrary Koopman operators as the dimension of z increases, or whether expressiveness is traded off for structural rigidity. \n\nW3. There seems to be no stability guarantees. The method ensures controllability but says little about the stability of the learned system -  an equally critical property for control deployment. Without constraints on the eigenvalues of A_\\theta, the learned linear system may be unstable, making MPC optimization difficult or ill-posed.\n\nW4. All benchmarks are relatively small and well-known toy systems (Pendulum, CartPole, etc.). While these are standard, they do not convincingly demonstrate the method’s scalability or robustness to real-world noise and unmodelled dynamics. \n\nW5. Computational cost and training stability are unclear. The paper lacks analysis of training complexity, numerical conditioning, or the computational overhead introduced by the Gramian regularizer (which involves integrating matrix exponentials).\n\nW6. The connection to Koopman theory is not fully justified. Although the paper uses the Koopman terminology, the approach essentially learns a linear latent-space model via a neural encoder. There is limited evidence that this latent space truly captures Koopman-invariant subspaces or observables."}, "questions": {"value": "Q1. The paper constrains A_\\theta, B_\\theta through a controllable canonical form plus similarity transform P_\\theta. Does this restriction reduce the expressive power of the learned Koopman operator? Please clarify whether your parameterization still provides a universal approximation property for arbitrary nonlinear dynamics in the lifted space, or discuss the trade-off between controllability enforcement and representational flexibility.\n\nQ2. The current method enforces controllability but not stability. Have you observed instability in the learned latent dynamics (e.g., exploding eigenvalues of A_\\theta)? It would be useful to regularize eigenvalues of A_\\theta or provide evidence that the MPC formulation mitigates instability during rollout.\n\t\nQ3. The Gramian term involves computing W_T^y. How is this computed efficiently during training, and how does it scale with the latent dimension N? It would be helpful to include complexity analysis or ablation to show that the regularizer does not dominate training time.\n\t\nQ4. The framework is called “Koopman,” but it remains unclear whether the learned observables correspond to Koopman-invariant subspaces or simply linear latent embeddings. Can you empirically or theoretically justify that \\varphi_\\theta(x) approximates Koopman eigenfunctions or invariant coordinates? Spectral or mode analysis (e.g., eigenvalue comparison with known systems) would strengthen the Koopman interpretation.\n\t\nQ5. Can your framework scale to higher-dimensional or partially observed systems (e.g., PDEs, power network, or soft-robot system)? Discuss computational limits and whether encoder-decoder architectures can handle such cases without losing controllability guarantees.\n\t\nQ6. The paper does not compare against recent Koopman or geometric control approaches (e.g., KEEC) that emphasize structural invariance. What are the pros and cons of controllability-based representations and equivariance-based representations?\n\nQ7. Parameters like the Gramian regularization weight and time horizon T may strongly affect results. How sensitive is performance to these settings? Suggest including an ablation or at least a qualitative discussion on how these hyperparameters influence both controllability conditioning and prediction accuracy.\n\nQ8. The paper claims the learned model can be “directly integrated” with MPC. Was this tested in a closed-loop simulation with constraints? Suggest presenting control performance metrics (tracking error, energy use, robustness) under realistic MPC settings to demonstrate deployability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0WTNyK1498", "forum": "jITPFROpWN", "replyto": "jITPFROpWN", "signatures": ["ICLR.cc/2026/Conference/Submission20675/Reviewer_dLx9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20675/Reviewer_dLx9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20675/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761941748788, "cdate": 1761941748788, "tmdate": 1762934060496, "mdate": 1762934060496, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a dynamics learning method that enforces controllability as a structural prior in order to improve the quality and usability of the learned dynamics. In particular, this paper:\n* Introduces a Koopman-based framework for learning linear surrogate models using Neural ODEs.\n* Enforces controllability of the learned model by design, by proposing a particular parameterization of the to-be-learned Koopman operator. This parameterization is based on the observation that enforcing state-to-output controllability in the lifted space (easy) is equivalent to enforcing output-to-output controllability in the original space (hard).\n* Provides experiments on four control settings (mountain car, pendulum, cartpole, gene regulatory network), showing improved quality of the learned dynamics and improved controllability of those dynamics compared to SOTA baselines."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "* The idea of the paper is clear, simple, and well-grounded: Encode controllability as a structural prior enforced by design within neural ODE learning. The method and motivation are very clearly explained, and the clear notation facilitates understanding of how the Koopman operator is integrated into the neural ODE framework.\n* The proposed parameterization is backed by theoretical proofs, proving controllability.\n* The proposed loss regularization is a nice idea to ensure not just the binary notion of \"controllable,\" but also improve the degree of controllability.\n* The experimental results on mountain car, pendulum, and cartpole compare against SOTA baselines, and clearly show improved quality of dynamics learning in low-data regimes (comparable quality in higher-data regimes), as well as improve controllability of the learned dynamics when used within MPC."}, "weaknesses": {"value": "* The experimental settings are all quite small, with the largest setting (GRN = gene regulatory network) including 6 dimensions and 3 control inputs, and with the best results on the smaller single-input settings (GRN is the only multi-input setting, and results are more more marginal). It would be nice to see additional and more convincing validations on larger systems.\n* For large systems, the eigenvalue computation needed for the Gramian regularization term might be expensive to compute. In general, it would be nice to see relative training cost between the different methods reported."}, "questions": {"value": "* What do results look like on larger experimental systems?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FhDtVI4fVx", "forum": "jITPFROpWN", "replyto": "jITPFROpWN", "signatures": ["ICLR.cc/2026/Conference/Submission20675/Reviewer_vF1q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20675/Reviewer_vF1q"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20675/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762129066896, "cdate": 1762129066896, "tmdate": 1762934059668, "mdate": 1762934059668, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper consider the problem of modeling and control of nonlinear systems via Koopman operator theory (KOT). Particularly, the paper ensures controllability by using a certain canonical parameterization and also are able to tune the degree of controllability to ensure better control performance. In addition they use Neural ODE to learn a KOT based model Simulation results present the efficacy of their approach"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The main strengths are as follows:\n1) The efficacy of their approach over other methods is clearly show.\n2) The literature review in the introduction is extensive.\n3) The use of Neural ODE is a smart choice over MLPs; one main reason being free from what discretization issues while converting the continuous to discrete systems."}, "weaknesses": {"value": "I have worked on Koopman operators for a while now. I believe these are the following weakness:\n\n1) The KOT for control literature is quite rich today. For instance works that consider controllability for KOT based models, use Neural ODE or similar techniques exist in literature. \n2) The motivation for this work is not clear to me.\n3) The approximation error between the KOT and real system is not considered. This is particularly important because Koopman operator is an infinite dimensional linear operator and to make it of practical value, a finite approximation of the Koopman operator via EDMD is usually made.\n4) Missing real world examples of more sophisticated nonlinear systems such as quadruped or humanoid is missing. There are already hundreds of paper that consider standard and simple nonlinear systems."}, "questions": {"value": "I have the following questions:\n\n1) Since the Koopman model is just a surrogate model, there is an approximation error between actual and approximated model. This is not considered in the paper. In addition, there exists works that consider this approximation rigorously (see [1]).\n2) There are also papers that consider the controllability of the KOT surrogate model. It is not clear to me on how your work is significantly different from [2].\n3) It is not always possible to make a nonlinear system controllable by ensuring controllability in the KOT model.\n4) There has been lots of work that convert unknown dynamics into Koopman based models and use the surrogate model for control design purposes (see [3,4,5] ). It is not clear how your work is different from them. Yes, you mention that you also ensure controllability of the KOT model, but [2] does this as well\n5) In simulation results, although you have compared your approach with some prior methods, the nonlinear systems considered are too simple. I would like examples of more complex robotic systems such as quadruped and humanoid where efficiency of KOT models is yet to shown. \n6) Showing that the proposed approach works on more complex nonlinear dynamics such as quadruped or humanoid needs to shown. In addition, they must be well motivated to show their efficacy compared to RL based control policies\n7) Ensuring controllability as one of your main contributions would not add significant contribution to the paper given the fact that there exists some work that do it\n\n\n\n[1] Mamakoukas, G., Di Cairano, S. and Vinod, A.P., 2022, June. Robust model predictive control with data-driven Koopman operators. In 2022 American Control Conference (ACC) (pp. 3885-3892). IEEE.\n\n[2] Choi, Joonwon, Minhyun Cho, Hyunsang Park, Vishnu Vijay, and Inseok Hwang. \"On The Controllability Preservation of Koopman Bilinear Surrogate Model.\" In 2024 IEEE 63rd Conference on Decision and Control (CDC), pp. 3457-3462. IEEE, 2024.\n\n[3] Korda, M. and Mezić, I., 2018. Linear predictors for nonlinear dynamical systems: Koopman operator meets model predictive control. Automatica, 93, pp.149-160.\n\n[4] Zinage, V. and Bakolas, E., 2023. Neural koopman lyapunov control. Neurocomputing, 527, pp.174-183.\n\n[5] Salzmann, T., Kaufmann, E., Arrizabalaga, J., Pavone, M., Scaramuzza, D. and Ryll, M., 2023. Real-time neural mpc: Deep learning model predictive control for quadrotors and agile robotic platforms. IEEE Robotics and Automation Letters, 8(4), pp.2397-2404."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "mwHB1VZqlt", "forum": "jITPFROpWN", "replyto": "jITPFROpWN", "signatures": ["ICLR.cc/2026/Conference/Submission20675/Reviewer_x559"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20675/Reviewer_x559"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20675/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762379543653, "cdate": 1762379543653, "tmdate": 1762934058486, "mdate": 1762934058486, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a Koopman-based representation learning framework, implemented as an end-to-end Neural ODE, that learns nonlinear dynamical models from limited data while ensuring the learned models remain suitable for control.  It enforces controllability by construction via a new canonical parameterization of the latent linear dynamics (A, B), and shows that controllability of the learned latent model implies controllability of the original (nominal) system.  The method also shapes the degree of controllability by adding a finite-horizon output-Gramian regularizer that enlarges the smallest eigenvalue and controls the condition number to promote well-conditioned models for control. For downstream control, the learned linear surrogate enables a convex quadratic-program MPC in the lifted space with receding-horizon execution.  Empirically, on standard nonlinear benchmarks (pendulum, mountain car, cartpole), the approach achieves more accurate long-horizon prediction and better MPC performance with improved data efficiency compared to Deep Koopman Operator and MLP baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. Learning the Koopman operator is an interesting and important classical control system problem."}, "weaknesses": {"value": "1.\tThis paper has marginal algorithmic or theoretical contributions. See the details below.\n2.\tThe main contribution is a method to learn the Koopman operator. However, the proposed methods are quite standard, typical in any Koopman operator learning approach. While the paper prominently states the connection with Neural ODE, it is not really clear why that is relevant or interesting. Lifting the state x to a high-dimensional variable z and modeling the non-linear system as a linear system at this lifted space is indeed the standard approach of Koopman theory. So, the reason for presenting neural ODE as new approach is not clear. \n3.\tThe theoretical results presented are standard results from linear systems theory. In particular, Theorem 1 about controllability and Theorem 2 about reparameterization to a suitable form are standard results. So, it is not clear why these are presented as novel results, and how they contribute to the Koopman operator theory. \n4.\tOnce the Koopman operator is learned, LQR or MPC are the standard ways to design a control policy. There is no novelty in that part.\n5.\tThe experiments are done on three very simple tasks: mountain car, pendulum, cartpole. It is not clear if the proposed methods can scale to even a slightly more difficult settings, say, mujoco environments."}, "questions": {"value": "1. Aren't Theorems 1 and 2 about any linear systems? Any specific connection to Koopman operators?\n2. Will the proposed approach work even in slightly highly dimensional non-linear systems, such as simple MuJoCo environments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0gNRK5IDbt", "forum": "jITPFROpWN", "replyto": "jITPFROpWN", "signatures": ["ICLR.cc/2026/Conference/Submission20675/Reviewer_ybHH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20675/Reviewer_ybHH"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20675/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762645659068, "cdate": 1762645659068, "tmdate": 1762934058094, "mdate": 1762934058094, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}