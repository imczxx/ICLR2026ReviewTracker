{"id": "466gVY2sBQ", "number": 4354, "cdate": 1757665889170, "mdate": 1759898037716, "content": {"title": "Token Dynamics on Spheres in Mamba Models", "abstract": "The dynamical properties of tokens in internal representations, or token dynamics, of a deep learning model has recently attracted considerable attention in deep learning theory. While transformer dynamics have been extensively studied, the analysis of token dynamics in selective state space (Mamba) models remains largely unexplored. Existing studies on Mamba models impose restrictive assumptions, such as relying solely on state space layers and limiting token embeddings to one dimension. However, practical implementations of Mamba incorporate layer normalization and operate in high dimensions, implying that token dynamics evolve on a high-dimensional unit sphere. In this work, we address this gap by formulating deep Mamba models as flow maps on high-dimensional unit spheres and providing a comprehensive theoretical analysis of their token dynamics. We characterize all possible token limit points and establish explicit exponential convergence rates toward these points. Our analysis reveals that the first token’s limit point exerts an attracting effect on other tokens, leading to clustering phenomena. Furthermore, we extend our theoretical analysis of the attracting effect to a broader class of autoregressive sequence models, including state space models, causal Transformers, and classical time-series models. Leveraging this insight, we propose two applications: (i) randomly reordering tokens during training to diversify clustering on a small subset of limit points, thereby improving model performance, and (ii) explaining the attention sink effect in Mamba models through the attraction of the first token. Experimental results confirm our theoretical findings and demonstrate the practical benefits of these refinements, offering new perspectives on enhancing the effectiveness of Mamba models.", "tldr": "We investigate the dynamical properties of tokens in deep Mamba models, extend our analysis to autoregressive sequence models, and propose principled strategies for enhancing model performance.", "keywords": ["selective state space model", "token dynamics", "continuous-time limit", "dynamical system"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6136c6684979bcb84369e3b306040392eae6e16b.pdf", "supplementary_material": "/attachment/5c0dee2ca260eaf41ae54973505ae3f589c1234b.zip"}, "replies": [{"content": {"summary": {"value": "This paper investigates the token dynamics of autoregressive sequence models (mainly on Mamba) by treating the layers’ index as a continuous variable. Following the framework of [Karagodin et al., 2024], the authors model the token dynamics of Mamba as the solution to an ordinary differential equation, where the continuous layer index is interpreted as time $t$. They analyze the limit as $t \\to \\infty$ and, under certain assumptions, prove that (1) the first token converges to a vector with specific properties, (2) all subsequent tokens are attracted to the first token, and (3) this convergence is exponential. Based on these results, they conclude that tokens form a small number of clusters and present two applications derived from this finding."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper provides a theoretical analysis of token dynamics based on the existing framework (Eq. 6, 7), and these findings are also verified empirically through simulations. \n2. The study demonstrates exponential convergence in token dynamics, which clearly distinguishes this paper from prior research."}, "weaknesses": {"value": "1. The theoretical assumptions are strong, and there is no empirical justification for them. The paper proceeds to theoretically justify the observations shown in Figure 1. However, the figure’s results are (1) qualitative rather than quantitative, (2) based on small-scale settings, and (3) constrained by random parameter choices.\n2. The range of applications is limited. The insights into token dynamics are applied only to (1) understanding the attention sink phenomenon and (2) improving performance via token permutation during training. Regarding (2), as noted in (Weakness 4), the justification is insufficient.\n3. In Section 4.1, the paper claims to provide a theoretical explanation of the attention sink (line 374), yet it never explicitly explains how the attraction of later tokens to the first token causes the attention sink phenomenon.\n4. The rationale behind the method proposed in Section 4.2 is weak. The fact that tokens form a small number of clusters does not directly imply that randomly permuting token order during training will improve performance. Moreover, the experiment is small-scale, and the final accuracy hardly changes with or without the proposed technique (Figure 4). Since no error bars are reported, the generality of this result remains unclear.\n5. The normalization used in the paper deviates from RMSNorm, yet the authors do not investigate how this deviation affects their conclusions. Although the paper emphasizes as a contribution that it includes the effect of layer normalization (lines 58 and 73), the analysis presented here is insufficient to support that claim.\n6. Assuming that parameters do not depend on $t$ ignores the differences between layers. It is unclear what practical implications or benefits such an observation offers for real-world implementations."}, "questions": {"value": "1. The paper extends the theoretical results developed for Mamba to a broader class of autoregressive sequence models. What are the statements that can be proved for Mamba but not for this broader class?\n2. Can the results of this study be used to explain differences in token dynamics across models?\n3. Why does Figure 1 not include the results for the case where the parameter $a$ depends on time?\n4. As noted in Remark 3.4, the result of Theorem 3.2 is consistent with experiments, while Theorem 3.3 is not. Why does this inconsistency arise only in the two-dimensional case?\n5. Theorem 3.5 and Proposition 3.6 state that, as $t \\to \\infty$, all tokens converge to the first token. However, Figure 1 and Remark 3.7 demonstrate that “tokens in a deep Mamba model tend to form a small number of clusters.” Could the authors explain this apparent discrepancy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "D9JrcR0oU7", "forum": "466gVY2sBQ", "replyto": "466gVY2sBQ", "signatures": ["ICLR.cc/2026/Conference/Submission4354/Reviewer_ZK7P"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4354/Reviewer_ZK7P"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4354/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761222780888, "cdate": 1761222780888, "tmdate": 1762917312516, "mdate": 1762917312516, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper examines Mamba models through the lens of dynamical systems. The authors primarily aim to demonstrate that the first token functions as an attractor for the subsequent tokens."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper seeks to analyze the token dynamics of Mamba models and explore the concept of sinks within them.\n\n2. It also aims to identify practical applications or benefits that arise from the theoretical framework it develops."}, "weaknesses": {"value": "1. The paper makes several assumptions that seem insufficiently supported (see questions for details).\n\n2. A few figures in the paper are difficult to interpret (see questions).\n\n3. The usefulness of Section 4.2 is unclear to me (see questions).\n\n4. Some of the claims in the paper appear somewhat overstated (see questions)."}, "questions": {"value": "1. The abstract highlights the role of layer normalization; however, most of the proofs appear to rely on the L2 norm. It may be helpful to reference prior works such as [A] and [B], which discuss constructions that modify layer normalization to effectively reduce to an L2 norm. The authors might also consider clarifying where exactly layer normalization is applied within the SSM layer and how it interacts with the overall model dynamics.\n\n2.  The reasoning underlying Proposition 1 could benefit from further explanation. Since the system does not necessarily reach equilibrium, it would be helpful for the authors to clarify the intuition and potential implications of the result in cases where equilibrium is not achieved.\n\n3. It would strengthen the paper to discuss whether some of the stated assumptions could be empirically validated. For example, do these assumptions hold in trained SSMs or when SSMs are trained from scratch? Clarifying which assumptions align with observed behavior in practical settings would make the theoretical contributions more compelling and relevant to real-world machine learning models.\n\n4. The motivation for focusing on asymptotic analysis as T -> $\\infty$ could be elaborated upon. Since most networks are of finite depth (often fewer than 100 layers), it might be helpful to comment on whether finite-time behavior or convergence rates also play a meaningful role in the theoretical conclusions. (I understand that there are other works that have used similar analysis techniques but I'm trying to question the analysis technique as a whole). \n\n5. The purpose and practical relevance of Section 4.2 could be clarified. The reported improvements appear modest and potentially within the range of standard deviation, and it is not immediately clear how the random perturbation setup extends to language modeling. Providing additional context or justification for this section would enhance its contribution to the overall narrative.\n\t\n6. The explanation of Figure 1 could be made clearer. It would be useful to specify what is meant by “most trajectories converge”,  for example, whether this refers to a percentage, threshold, or specific criterion. Detailing the initialization scheme and other experimental settings used to produce the figure would also improve interpretability.\n\n7. The paper could benefit from extending Figure 2 to additional channels and layers. It would also be valuable to describe the experimental setup more thoroughly, including dataset details, model configuration, training protocol, and hyperparameters, to facilitate reproducibility and interpretation.\n\n8. Equations 1619-1620 may contain a typographical error. The authors are kindly requested to verify and, if necessary, correct this in the final version.\n\n---\n**Minor Typos**\n\nLine 284: far more challenge -> far more challenging\n\n---\n\n**References**\n\n[A] Rajaraman, N., Bondaschi, M., Makkuva, A. V., Ramchandran, K., & Gastpar, M. (2024). Transformers on markov data: Constant depth suffices. Advances in Neural Information Processing Systems, 37, 137521-137556.\n\n[B] Ekbote, C., Makkuva, A. V., Bondaschi, M., Rajaraman, N., Gastpar, M., Lee, J. D., & Liang, P. P. (2025). What one cannot, two can: Two-layer transformers provably represent induction heads on any-order Markov chains. In Proceedings of the 39th Annual Conference on Neural Information Processing Systems (NeurIPS 2025)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sOeMa5MqWB", "forum": "466gVY2sBQ", "replyto": "466gVY2sBQ", "signatures": ["ICLR.cc/2026/Conference/Submission4354/Reviewer_FDLD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4354/Reviewer_FDLD"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4354/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762058755319, "cdate": 1762058755319, "tmdate": 1762917312302, "mdate": 1762917312302, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper examines Mamba models through the lens of dynamical systems. The authors primarily aim to demonstrate that the first token functions as an attractor for the subsequent tokens."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper seeks to analyze the token dynamics of Mamba models and explore the concept of sinks within them.\n\n2. It also aims to identify practical applications or benefits that arise from the theoretical framework it develops."}, "weaknesses": {"value": "1. The paper makes several assumptions that seem insufficiently supported (see questions for details).\n\n2. A few figures in the paper are difficult to interpret (see questions).\n\n3. The usefulness of Section 4.2 is unclear to me (see questions).\n\n4. Some of the claims in the paper appear somewhat overstated (see questions)."}, "questions": {"value": "1. The abstract highlights the role of layer normalization; however, most of the proofs appear to rely on the L2 norm. It may be helpful to reference prior works such as [A] and [B], which discuss constructions that modify layer normalization to effectively reduce to an L2 norm. The authors might also consider clarifying where exactly layer normalization is applied within the SSM layer and how it interacts with the overall model dynamics.\n\n2.  The reasoning underlying Proposition 1 could benefit from further explanation. Since the system does not necessarily reach equilibrium, it would be helpful for the authors to clarify the intuition and potential implications of the result in cases where equilibrium is not achieved.\n\n3. It would strengthen the paper to discuss whether some of the stated assumptions could be empirically validated. For example, do these assumptions hold in trained SSMs or when SSMs are trained from scratch? Clarifying which assumptions align with observed behavior in practical settings would make the theoretical contributions more compelling and relevant to real-world machine learning models.\n\n4. The motivation for focusing on asymptotic analysis as T -> $\\infty$ could be elaborated upon. Since most networks are of finite depth (often fewer than 100 layers), it might be helpful to comment on whether finite-time behavior or convergence rates also play a meaningful role in the theoretical conclusions. (I understand that there are other works that have used similar analysis techniques but I'm trying to question the analysis technique as a whole). \n\n5. The purpose and practical relevance of Section 4.2 could be clarified. The reported improvements appear modest and potentially within the range of standard deviation, and it is not immediately clear how the random perturbation setup extends to language modeling. Providing additional context or justification for this section would enhance its contribution to the overall narrative.\n\t\n6. The explanation of Figure 1 could be made clearer. It would be useful to specify what is meant by “most trajectories converge”,  for example, whether this refers to a percentage, threshold, or specific criterion. Detailing the initialization scheme and other experimental settings used to produce the figure would also improve interpretability.\n\n7. The paper could benefit from extending Figure 2 to additional channels and layers. It would also be valuable to describe the experimental setup more thoroughly, including dataset details, model configuration, training protocol, and hyperparameters, to facilitate reproducibility and interpretation.\n\n8. Equations in lines 1619-1620 may contain a typographical error. The authors are kindly requested to verify and, if necessary, correct this in the final version.\n\n---\n**Minor Typos**\n\nLine 284: far more challenge -> far more challenging\n\n---\n\n**References**\n\n[A] Rajaraman, N., Bondaschi, M., Makkuva, A. V., Ramchandran, K., & Gastpar, M. (2024). Transformers on markov data: Constant depth suffices. Advances in Neural Information Processing Systems, 37, 137521-137556.\n\n[B] Ekbote, C., Makkuva, A. V., Bondaschi, M., Rajaraman, N., Gastpar, M., Lee, J. D., & Liang, P. P. (2025). What one cannot, two can: Two-layer transformers provably represent induction heads on any-order Markov chains. In Proceedings of the 39th Annual Conference on Neural Information Processing Systems (NeurIPS 2025)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sOeMa5MqWB", "forum": "466gVY2sBQ", "replyto": "466gVY2sBQ", "signatures": ["ICLR.cc/2026/Conference/Submission4354/Reviewer_FDLD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4354/Reviewer_FDLD"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4354/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762058755319, "cdate": 1762058755319, "tmdate": 1763040561753, "mdate": 1763040561753, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper at hand extends the analysis of Karagodin et al. (2024) to Mamba-based Language models. The authors effectively start from equations (6, 7, 8), defining a dynamical system, and then study the dynamics of the first token, comparing it to those of the subsequent tokens in a causal model. After characterizing the sink effect, the authors propose a reordering strategy that improves performance on Vision Mamba models slightly."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "0) The paper is easy to read and had good notation.\n\n1) The paper is easily accessible yet not boring or trivial for researchers familiar with the topic.\n\n2) The theoretical results well align with the experimental results."}, "weaknesses": {"value": "I think this paper could use an additional round of polishing and could benefit from looking at the bigger picture:\n\n0) For readers that are familiar with Karagodin et al. 2024, this paper looks a bit incremental: basically, what changes here is the structure of the attention matrix -- yet the formalism and the main idea for this analysis is not novel.\n\n1) Looking only at Mamba is a bit limiting at this stage -- one is left wondering what happens to other linear attention mechanisms, and specifically about the relation with the discussion in https://arxiv.org/pdf/2410.10781 (section 7.4) about how attention mechanisms affect the sink effect differently. To summarize, the scope here is very limited, and there is no precise comparison to previous works.\n\n2) The reordering strategy proposed by the authors is effective to some extent, yet it is in some way not really satisfying in the context of this paper. I believe a much better way to wrap up the work is indeed (as above written) to compare different types of attention operations and the role those have on token dynamics.\n\n3) This is a critique that would also apply to Karagodin et al.: I believe the setup is really a bit simplistic. In particular, Mamba can have a few normalization layers (pre and post), has skip connections, convolutions and gates. None of this is present in the analysis."}, "questions": {"value": "0) What challenge or interesting technical aspect does your analysis have that would justify publishing your work? \n\n1) What differs in the analysis, precisely, compared to the attention case?\n\n2) Why is the result surprising? Does this also apply to architectures such as Gated DeltaNet?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "z5e6dzu72U", "forum": "466gVY2sBQ", "replyto": "466gVY2sBQ", "signatures": ["ICLR.cc/2026/Conference/Submission4354/Reviewer_2BGT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4354/Reviewer_2BGT"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4354/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762215830041, "cdate": 1762215830041, "tmdate": 1762917311957, "mdate": 1762917311957, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}