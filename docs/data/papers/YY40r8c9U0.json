{"id": "YY40r8c9U0", "number": 3679, "cdate": 1757496054098, "mdate": 1759898075487, "content": {"title": "A Constellation-Aware Transformer for Nonlinear Channel Equalization", "abstract": "Decoding signals over unknown channels with minimal pilot overhead is a critical challenge in communications. Existing deep learning approaches struggle to model long-range temporal dependencies. Conversely, off-the-shelf Transformers, while powerful sequence models, are domain-agnostic and inefficiently learn the channel's physical properties from scarce data. We introduce the *Constellation-Aware Transformer* (CAT), a novel architecture that integrates fundamental communication principles into the Transformer model. CAT is composed of a stack of custom *TransFIRmer* blocks, which redesign the standard Transformer to be constellation-aware. Each block facilitates deep interaction between the received signals and the ideal constellation geometry via a specialized attention mechanism. Furthermore, it replaces the standard feed-forward network with a two-stream architecture: a bidirectional Finite Impulse Response (FIR)-inspired filter processes the signal representations for robust deconvolution, while a parallel MLP refines the constellation representations. In the challenging semi-supervised setting, CAT achieves superior performance across multiple noisy channels, significantly outperforming other baselines, with using fewer pilot signals.", "tldr": "We introduce Constellation-Aware Transformer (CAT), a new transformer-based model for decoding communication signals over unknown, noisy channels, especially when very few known \"pilot\" signals are available.", "keywords": ["Channel Equalization", "Transformer", "Physical Layer Communications", "Signal Processing"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a7d95a1a71c9d2972e43ba849614f51bd99615d6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The manuscript describes a new transformer based neural architecture for non-linear channel equalisation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "In theoretical point of view, the study is interesting. Formulation seems sound and their extension of architecture seems sound  and results are also ok."}, "weaknesses": {"value": "The thing which puzzles me quite a lot and is that what is actually the intended use case for the approach they consider? Based on description in section 2.3, a neural network is trained based on pilots and payload data in semi-supervised manner. If I interpret this correctly, this would mean that a transformed needs to be trained or fine-tuned every time when channel conditions change. If you consider common wireless communication frameworks, such as 5G or WiFi, this happens all the time especially if mobile device or terminal is moving. In those system, you would need to process a large numbers of symbols in milliseconds and the complexity to train continuously a transformer model would be out of limits of any practical implementation with several orders of magnitude. This comment of course also applies Burstein & Bery's work, which is the basis of this work, but authors could comment this also here for the audience of ICLR. \n\nMinor specific comments:\n- PAs can also have memory effects (e.g GaN RF amplifiers suffers from it)\n- Figure 1 font size could be increased."}, "questions": {"value": "- As mentioned above, authors could clarify possible use cases for their methods, \n- Continuing from that, would there be a way to separate sources of nonlinear effects such as PA and the wireless channel (which is usually linear) in a way that transformed would be just trained one for each transmitter with a nonlinear PA?  This would perhaps make more sense in practical point of view."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "WfIaQaabsV", "forum": "YY40r8c9U0", "replyto": "YY40r8c9U0", "signatures": ["ICLR.cc/2026/Conference/Submission3679/Reviewer_vShY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3679/Reviewer_vShY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3679/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761218112790, "cdate": 1761218112790, "tmdate": 1762916914597, "mdate": 1762916914597, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a modification to the transformer architecture to incorporate domain knowledge regarding the constellation structure and channel effects into the design choices."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Using cross-attention between the received vector and the constellation early on to provide more context to the decoder is a clever and interesting approach. \n\n2. The FIR-inspired design approach is interesting. Replacing the FFN block with a convolutional filter-like block is appropriate for the problem under consideration. \n\n3. Empirical results are convincing and tested well on both memoryless and ISI channels. \n\n4. The ablation studies reasonably back up the claims presented."}, "weaknesses": {"value": "1. Relatively simple idea with overall contributions more suitable for a communication venue. Particularly because of the empirical validation on experiments, which are very specific to wireless communication.\n\n2. Given the broad adoption and availability of realistic channel simulators such as Sionna, experimenting with such channel simulators instead of limiting to synthetic channels would be more convincing. \n\n3. Interesting and well-executed, but the work lacks sufficient core ML innovation to meet a machine-learning venueâ€™s bar."}, "questions": {"value": "1. Can you perform some experiments with a more realistic channel, such as TDL/CDL channels with mobility, in Sionna? Given the problem of poor equalization in OFDM systems during mobility, and a well-established line of work on \"neural receivers\" and \"neural precoding\", discussion and differentiation with these works would be appreciated. \n\n2. Instead of considering the uncoded transmission, can the BER/BLER be measured in the presence of channel coding? Quantification of gains on coded transmission is more relevant and might give a better picture of the contribution of each component, given that the current performance of the model for different variants is very similar."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XhjEl3ELak", "forum": "YY40r8c9U0", "replyto": "YY40r8c9U0", "signatures": ["ICLR.cc/2026/Conference/Submission3679/Reviewer_kxLq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3679/Reviewer_kxLq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3679/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761284062763, "cdate": 1761284062763, "tmdate": 1762916914278, "mdate": 1762916914278, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the Constellation-Aware Transformer (CAT). Each TransFIRmer module is an independent processing unit that redesigns the standard Transformer encoder by integrating two key innovations, both derived from the following principles:1. Constellation-Aware Attention (CAT) 2. Feedforward networks inspired by finite impulse response. Experiments demonstrate that it achieves state-of-the-art performance in channel decoding."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper is well-written, with a clear and logical structure. The comparisons presented in the experimental section are also very clear, and the appendix provides a substantial amount of background information."}, "weaknesses": {"value": "The greatest contribution of this paper lies in the innovative design of the network, but I believe that the novelty of the proposed design is insufficient, and the explanation for why such a design was chosen is also inadequate. Firstly, the Signal-Constellation Attention Mechanism seems to demonstrate through experiments that full attention is better than causal attention. However, the use of uncertain wording like \"likely because\" suggests that it might be due to the ability of full attention to capture global information. Whether there is any correlation between information across different channels, or whether local designs (e.g., Swin Transformer) might be better than global designs, is not addressed in this paper. Secondly, in the FFN, the authors simulate Finite Impulse Response filters using 1D convolution. This does not bring any prior knowledge. In my opinion, the improved performance gain is due to the combination of convolutional and linear layers, which has already been proven feasible in other transformer design papers.\n\nThe comparison methods used in the experimental phase are also insufficient. In the related work section, the paper claims that current transformers used in the wireless field are all traditional transformers with little design innovation. However, this is not the case. For example, the paper \"Joint Channel Estimation and Feedback with Masked Token Transformers in Massive MIMO Systems\" employs a channel selection method. Another paper, \"Transformer-Empowered CSI Feedback for Massive MIMO Systems,\" also uses transformers for channel estimation. In the experimental phase, this paper only compares against ordinary transformers, indicating that the experiments are very preliminary."}, "questions": {"value": "see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "kVPRTG8ZEw", "forum": "YY40r8c9U0", "replyto": "YY40r8c9U0", "signatures": ["ICLR.cc/2026/Conference/Submission3679/Reviewer_bxnZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3679/Reviewer_bxnZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3679/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761624451061, "cdate": 1761624451061, "tmdate": 1762916914010, "mdate": 1762916914010, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- The paper introduces a novel transformer-based architecture designed for channel equalization.\n- The contribution is twofold: 1) The receiver employs a transformer network that utilizes signal constellation properties to enhance decoding performance. 2) The paper proposes a novel, FIR-inspired feed-forward network within the transformer layers to mimic channel deconvolution."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The core concepts presented are both interesting and novel.\n- The inclusion of experiments on channels with memory is a valuable addition to the evaluation."}, "weaknesses": {"value": "- The experimental results are limited to high SNR values (17, 18, 20, and 22 dB). The lack of experiments across a wider SNR range makes it difficult to assess performance under varied channel conditions.\n- The evaluation on channels with memory is restricted to only three specific channel models.\n- There is no comparison or normalization based on computational complexity or parameter count. It is unclear if the proposed CAT transformer outperforms the VAE-CNN baseline due to architectural superiority or simply having more parameters.\n- For both memoryless and memory channels, the CAT model appears to be trained and tested on the same channel realization. This approach raises concerns about the system's generalizability, as real-world channel conditions are dynamic rather than static."}, "questions": {"value": "- The selection of specific channels with memory is attributed to Bushtein & Bery. Is there any specific reasoning behind choosing these particular channels for experimentation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0J1aP3iPAG", "forum": "YY40r8c9U0", "replyto": "YY40r8c9U0", "signatures": ["ICLR.cc/2026/Conference/Submission3679/Reviewer_vF6C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3679/Reviewer_vF6C"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3679/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762451039082, "cdate": 1762451039082, "tmdate": 1762916913689, "mdate": 1762916913689, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}