{"id": "mdvLeMd8T7", "number": 7423, "cdate": 1758021142081, "mdate": 1759897853662, "content": {"title": "The Best of Both Worlds: Amortized Variational Diffusion Posterior Sampling", "abstract": "Diffusion models pre-trained on large datasets are powerful priors for inverse problems such as super-resolution and inpainting. Zero-shot variational diffusion posterior sampling achieves state-of-the-art reconstructions without task-specific training but is slow due to costly test-time optimization. Supervised diffusion for inverse problems offers fast inference, yet demands large datasets and often fails under unseen degradations. We introduce a best-of-two-worlds strategy that jointly leverages upstream training and test-time likelihood guidance. An amortized inference model, trained on a small paired dataset, predicts a good initialization for a variational approximation problem involved in variational diffusion posterior sampling, while retaining the explicit use of the degradation operator to guide inference. This combination removes several gradient updates at inference, reducing inference time by up to 32 \\% compared to zero-shot posterior sampling. Importantly, it remains robust against out-of-distribution degradation operators and training settings with limited data (e.g., 1 \\% of the pre-training data), outperforming the supervised diffusion baselines in these scenarios. Our results show that coupling modest training with test-time operator knowledge can unlock fast, flexible, and high-quality diffusion reconstructions.", "tldr": "Amortized optimization for variational diffusion posterior sampling", "keywords": ["diffusion models", "inverse problems", "amortized optimization"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/93c60c99cfe5b06f244b69eb7b76b0dc93673e66.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper approaches the problem of inverse problem inference using diffusion priors for image reconstruction tasks. The authors base their approach on the recent paper: A mixture-based framework for guiding diffusion models, which introduces the MGDM approach. This approach involves optimizing a variational approximation to the posterior of a sample given a higher noise-level sample and a partial observation, as part of a larger Gibbs-sampling approach to sampling at a given time conditioned on a partial observation. The authors propose training an amortization network to initialize this optimization, potentially saving significant computation over the more naive initialization used in the original work. The authors validate their approach with a number of experiments on the FFHQ dataset."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**Method**\n\n- The authors provide a clear motivation for the approach, and it seems reasonable that the computational expense of the MGDM approach  would necessitate improvements such as this.\n- While the novelty of this approach is somewhat limited, it seems like a reasonable approach that I would expect might have the claimed benefits.\nThe design of the amortization network appears to be thoughtful and sound\n\n**Writing**\n- The paper is clearly written and provides a good introduction to diffusion models for images and Bayesian inverse problems, as well as the quite complex MGDM approach"}, "weaknesses": {"value": "**Evaluation setup**\n\nEvaluation is not up to contemporary standards for the following reasons:\n\n- Only a single dataset is considered: FFHQ. FFHQ has significantly less image diversity than natural image datasets such as imagenet, widely used in the literature.\n- Only models at a 64x64 resolution are considered, which is well below the 256x256 or higher benchmarks present in other papers.\n- The base model used is non-standard, it is not from the original HDiT paper, nor is it a commonly used foundation model such as Guided diffusion, LDMs or stable diffusion.\n- Comparison is only against MGDM for running time and Palette for supervised diffusion. A larger set of comparisons would be needed.\n\nAll of these issues make it largely impossible to determine the real-world practically of this method and whether the claimed results would scale to larger, more modern diffusion models.\n\n**Performance**\n\nThe primary benefit seems to be speeding up inference compared to the Zero-Shot MGDM approach, which could be useful. However, I have significant concerns about the usefulness of this method in general:\n\n- Runtime is only compared to the MGDM and not to other methods. While there is an improvement, >10s still seems like a long time for inference on a 64x64 image and there are no other benchmarks to put this into perspective.\n- This method does require significant training for the amortization network, making it only useful over the true zero-shot approach if many similar reconstructions need to be performed. \n- The experiments showing OOD performance are unconvincing. While it does appear to outperform InvFussion as predicted, the performance and runtime appears equivalent to the zero-shot MGDM approach, still performing poorly with no gradient updates. \n\n**Novelty**\n\nThe novelty is somewhat limited as it does not introduce a fundamentally new approach to inverse problem inference, rather applies amortization to speed up an existing approach."}, "questions": {"value": "My understanding is that even with amortization the approach still requires potentially multiple steps of gradient descent for each of R Gibbs sampling steps within each step of denoising. How does this compare in practice to other methods for zero-shot inference?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xACiyZJc4Y", "forum": "mdvLeMd8T7", "replyto": "mdvLeMd8T7", "signatures": ["ICLR.cc/2026/Conference/Submission7423/Reviewer_WWNq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7423/Reviewer_WWNq"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7423/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761602486423, "cdate": 1761602486423, "tmdate": 1762919544259, "mdate": 1762919544259, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles an important gap between two existing paradigms for diffusion‐based inverse problems: (i) zero‑shot variational diffusion posterior sampling (VDPS), which is robust but slow; and (ii) supervised diffusion models, which are fast but require large paired datasets and often fail under unseen degradations. The proposed amortized variational diffusion posterior sampling (Amortized MGDM) trains an inference model on a small set of paired data to predict a good initialization for the variational approximation in VDPS. By retaining explicit likelihood guidance during test time, the method aims to combine the adaptability of VDPS with the speed of supervised models. This is a creative application of amortized optimization to diffusion posterior sampling."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- Clarity: The paper provides a clear derivation of the approach. It describes how the inference network takes the current noisy sample, the clean reference, the timesteps, the degraded observation and operator as input and outputs residual mean and variance to initialize the variational optimization. The use of residual prediction relative to the unconditional bridge transition and architecture modifications (concatenating x_0 and x_t, summing timestep embeddings, doubling channels) are explained. The method maintains explicit likelihood guidance via subsequent gradient steps, ensuring the final reconstruction remains consistent with the degradation operator.\n\n- Significance: Accelerating variational diffusion posterior sampling while retaining robustness has practical value for inverse problems. Demonstrating that modest training (1 % of data) plus explicit likelihood guidance can outperform fully supervised diffusion models at data-poor scenarios highlights a compelling alternative for certain scenarios."}, "weaknesses": {"value": "- Inaccurate baseline discussion and limited comparison: The paper’s discussion of prior amortized variational inference methods is inaccurate. The authors argue that previous amortized inference approaches with diffusion priors (e.g., [1], [2]) require paired degraded–clean datasets, which is not the case. These methods can learn implicit priors using only degraded data without access to ground-truth clean samples. This misunderstanding should be properly addressed, as it leads to an unfair dismissal of related methods. Moreover, the paper’s experimental comparison is incomplete: it only contrasts Amortized MGDM with zero-shot MGDM, Palette, and InvFussion, omitting several recent works that also aim to accelerate posterior sampling. For instance, [1] adopts amortized variational posterior sampling and can solve inverse problems in a single step, directly targeting the same problem setup. It also demonstrates strong OOD performance. A careful quantitative and conceptual comparison with such approaches is necessary to situate the contribution accurately within the existing literature.\n\n- Limited speed‑up: Although the authors report speed gains of roughly 10–32 % over zero‑shot MGDM, the improvements are modest compared to supervised diffusion models that require only a single network pass. Amortized MGDM still involves training an inference network and then performing gradient steps during inference; for OOD operators the paper notes that around 30 additional steps were necessary to match zero‑shot performance. Thus the method does not eliminate the test‑time optimization burden and may remain slower than purely supervised approaches. Moreover, Table 2 compares reconstruction quality between Amortized MGDM and a supervised baseline but does not report inference time, limiting a fair assessment of the trade‑offs. Without discussing the cost of the total inference time and performance vs. supervised methods, it is difficult to gauge practical advantages.\n\n- Data requirements and generality: The method requires data to train the inference model. While the authors successfully use only 600 images (1 % of pre‑training data) for FFHQ64, it is unclear how much data would be needed for higher‑resolution tasks (e.g., ImageNet) or more complex modalities. The evaluation is restricted to 64×64 images from FFHQ; there are no experiments on higher resolutions, other datasets, or other modalities (e.g., medical imaging), so the generality of the approach remains uncertain.\n\n- Dependence on hyperparameters: The inference network is derived from a specific HDiT denoiser architecture. Adapting the approach to other diffusion backbones like UNet or DiT may require non‑trivial modifications. Performance depends on the number of gradient steps and hyperparameter tuning for both zero‑shot and amortized MGDM. Sensitivity analyses for the warm‑start network capacity, data size, and number of gradient steps are absent, leaving it unclear how robust the method is to these choices.\n\n---\n[1] Diffusion Prior-Based Amortized Variational Inference for Noisy Inverse Problems, ECCV 2024 \\\n[2] AMORTIZED POSTERIOR SAMPLING WITHDIFFUSION PRIOR DISTILLATION, ICLR 2025 workshop"}, "questions": {"value": "- Have the authors compared Amortized MGDM against recent amortized inference approaches with diffusion priors? These methods often learn implicit priors and can perform single-step inference (e.g., DAVI). A direct comparison and breakdown of performance versus the inference cost would clarify the methodological and empirical differences between Amortized MGDM and prior amortized diffusion inference models.\n\n- Missing FID evaluation: Have the authors tried to compare the FID performance of Amortized MGDM agains existing baselines?\n\n- Gradient step sensitivity: How does reconstruction quality and inference time vary with the number of gradient steps following the amortized warm-start? Is there a clear trade-off between speed and quality, and is there a principled or data-dependent way to select the optimal number of steps?\n\n- Have you tested Amortized MGDM on higher-resolution datasets such as ImageNet-256 × 256 or other domains (e.g., natural images, medical data)? Demonstrating generalization across resolutions and domains is crucial for establishing the scalability and robustness of the amortized zero-shot sampling algorithm.\n\n- While the method performs well with only 1 % of the training data, how does performance evolve as the amount of paired data increases? Is there a clear threshold below which amortization fails to yield reliable speed-ups or reconstruction quality? An analysis of performance versus data scale would strengthen the claim that small subsets suffice.\n\n- What is the computational cost of pre-training the amortized initialization model, and how does this compare to the cost of the zero-shot approach? Is the pre-training complexity included in Table 1 or Figure 1 when comparing total efficiency? A breakdown of training versus inference costs would clarify the overall benefit.\n\n- Could you provide an ablation comparing the trade-off between reconstruction performance and inference time on (i) zero‑shot MGDM, (ii) warm‑start with no subsequent gradient steps, and (iii) warm‑start with varying numbers of steps? This would clarify how much each component contributes."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "zP9bx8m8xa", "forum": "mdvLeMd8T7", "replyto": "mdvLeMd8T7", "signatures": ["ICLR.cc/2026/Conference/Submission7423/Reviewer_WbUn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7423/Reviewer_WbUn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7423/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761948104855, "cdate": 1761948104855, "tmdate": 1762919543794, "mdate": 1762919543794, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Amortized Variational Diffusion Posterior Sampling (Amortized MGDM), an approach to accelerate variational diffusion posterior sampling by training an inference network that predicts a good initialization for the variational optimization step. This shifts part of the expensive test-time optimization into an offline amortized model trained on a small paired dataset. The method reportedly reduces inference time by up to 32% while maintaining reconstruction quality and improving data efficiency, with preliminary evidence suggesting some robustness to variations in the degradation operator."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-written and well-organized, with detailed reporting of experimental methodology and implementation.\n2. The neural network initialization reduces the number of gradient updates required, providing faster inference compared to full iterative optimization.\n3. The paper provides a practical engineering contribution that improves the efficiency of an established method during test time."}, "weaknesses": {"value": "1. The reported “up to 32%” inference speedup is measured under specific hyperparameter settings and remains modest considering the additional cost of training the amortized inference network. Moreover, this training step makes the approach no longer zero-shot. Unlike MGDM, which can be applied to arbitrary degradations without retraining, the proposed amortized model must be trained for each degradation operator and dataset. This is a major weakness for the paper.\n2. The motivation for the “data-scarce” scenario is unconvincing. In typical image restoration settings, large pretrained diffusion priors (e.g., Palette or Stable Diffusion) already eliminate the need for paired data, making the data-limited justification for amortization weak. If the intended motivation is specialized domains with scarce training data (e.g., medical imaging), this should be demonstrated in such contexts rather than on 64×64 FFHQ. Moreover, in genuinely data-limited applications, a 20–30% slower zero-shot MGDM inference would likely be an acceptable trade-off compared to retraining an amortized model tied to a specific degradation.\n3. The paper claims robustness to out-of-distribution (OOD) operators, but both the training and testing setups involve inpainting with different mask patterns. This does not represent a truly OOD scenario, as the degradation type remains the same. Demonstrating genuine robustness would require evaluating across different degradations (e.g., training on inpainting and testing on super-resolution) or different datasets (e.g., training on FFHQ and testing it on ImageNet).\n4. The title and framing suggest a conceptual unification of zero-shot and supervised diffusion paradigms, but in reality the method remains a variant of posterior sampling with a learned warm start. Also, since MGDM already includes explicit likelihood guidance, it is expected to be robust to OOD operators, so the novelty is relatively limited.\n5. All experiments are restricted to 64×64 FFHQ. There are no results on standard higher-resolution benchmarks (CelebA-HQ 256, FFHQ 256, ImageNet 256, etc.), making it difficult to assess whether the claimed performance generalizes beyond the toy-scale setting.\n\n**Minor Comments:**\n- Vectors and matrices should be written in boldface to clearly distinguish them from scalar quantities.\n- The choice of measurement noise $\\sigma_y$=0.01 is acceptable but notably lower than the conventional setting of $\\sigma_y$=0.05. This difference should be acknowledged."}, "questions": {"value": "1. *Regarding weakness 1:* Can the authors report total training and inference wall-clock times (including amortization training) to clarify the end-to-end efficiency trade-off compared to zero-shot MGDM?\n2. *Regarding weakness 2:* If the “data-scarce” motivation targets real low-data domains, have the authors considered testing on medical or scientific imaging datasets where this assumption holds? Why was FFHQ chosen instead?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "p1tO6DjJwW", "forum": "mdvLeMd8T7", "replyto": "mdvLeMd8T7", "signatures": ["ICLR.cc/2026/Conference/Submission7423/Reviewer_CLP9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7423/Reviewer_CLP9"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7423/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761956165169, "cdate": 1761956165169, "tmdate": 1762919542731, "mdate": 1762919542731, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work concerns inverse problems such as inpainting, where a model is trained over paired data to warm-start the inference time variational approximation as opposed to zero-shot variational posterior sampling and supervised diffusion for inference. The authors claim up to 32% inference time savings and data scarce training possibilities, in addition to robustness to OOD operators."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The work evaluates comprehensively using PSNR/SSIM. It also reports LPIPS, CMMD, shows qualitative samples, and evaluates (i) speed/quality tradeoff, (ii) low-data regime, and (iii) OOD degradations (new masks), covering decent breadth of evaluations.\n2. The method is a simple addendum to existing approaches and demonstrates promising results under the chosen evaluation regime."}, "weaknesses": {"value": "1. OOD robustness only works upon adding back the additional gradient steps, thus falling back on the behavior on MGDM.\n2. Data scarce regime comparisons are only made to Palette which may not be suited for the 1% setting. Additional methods that target scarcity in data could be incorporated to enhance one of the work's core claim of data scarcity robustness. The bulk of the benefits appear to arise from the pre-training in the existing conditional denoisers and the MGDM's framework, which Palette doesn't have.\n3. All experiments are limited to 64x64 image sizes in facial domain.\n4. The authors could provide some insights into why the proposed amortization must preserve correctness and its limitations."}, "questions": {"value": "1. Could the authors provide insights into which steps lead to the time saving that is being observed?\n2. How far is the amortized network's prediction from the optimal setup with full optimization?\n3. Does the method generalize to larger images where MGDM struggles?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "d0UzdGPi0C", "forum": "mdvLeMd8T7", "replyto": "mdvLeMd8T7", "signatures": ["ICLR.cc/2026/Conference/Submission7423/Reviewer_bgvG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7423/Reviewer_bgvG"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7423/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762134848395, "cdate": 1762134848395, "tmdate": 1762919542361, "mdate": 1762919542361, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}