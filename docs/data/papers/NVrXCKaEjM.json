{"id": "NVrXCKaEjM", "number": 17207, "cdate": 1758273422030, "mdate": 1759897190975, "content": {"title": "Token-Efficient Long-Term Interest Sketching and Internalized Reasoning for LLM-based Recommendation", "abstract": "Large language models (LLMs) can solve complex real-world tasks when prompted to generate chain-of-thought (CoT) reasoning, motivating their use for preference reasoning in recommender systems. However, applying LLM reasoning on recommendation faces  two practical challenges. First, LLMs struggle to reason over long, noisy user histories that often span hundreds of items while truncation discards signals needed to capture long-term interests. Second, in decoder-only architectures, CoT requires generating rationale tokens autoregressively, leading to prohibitive inference latency for real-world deployment. To address the challenges, we propose SIREN, a framework that enables effective LLM-based rating prediction via long-term interest sketching and internalized reasoning. First, instead of prompting raw histories, we build a compact, token-bounded interest sketch that preserves persistent preferences and suppresses noise. Specifically, we encode and cluster item descriptions to discover semantic topics, then compress each user’s history into a short list of liked and disliked topics, facilitating LLM reasoning. \nSecond, we develop an internalized reasoning strategy for efficient inference. We adopt a two-stage training paradigm: (i) train the LLM to reason explicitly for rating prediction with rule-based reinforcement learning, since ground-truth CoTs are unavailable in recommendation; and (ii) learn to internalize CoT into model parameters through hidden alignment. At inference, the LLM directly generates the rating with near-CoT quality.\nExtensive experiments show that SIREN reduces average input tokens by $48.7\\%$ compared to raw-history prompting, outperforms existing methods while delivering over $100\\times$ lower inference latency than CoT-based LLM recommenders. Code and data are available at https://anonymous.4open.science/r/LLM4Rec-C7CF.", "tldr": "We propose an LLM4Rec framework that effectively handles long user histories while enabling efficient inference.", "keywords": ["LLM-based Recommendation", "Rating Prediction", "Efficient Reasoning"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2b75a71ae5b00762d16e7c04969a1578637b6ddb.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes SIREN, a framework to improve rating prediction with large language models (LLMs). It targets two deployment challenges: (1) long and noisy user histories that harm reasoning, and (2) high inference latency due to explicit CoT generation."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Clear practical motivation: identifies real deployment issues of long user histories and expensive CoT reasoning.\n2. Elegant design: the “interest sketch + hidden-alignment” combination is conceptually simple yet effective.\n3. Significant efficiency gains: achieves near-CoT accuracy with minimal latency."}, "weaknesses": {"value": "1. Limited dataset diversity. Experiments are conducted only on two domains (Books and Movies) from the Amazon Reviews dataset. The generalizability to ranking, Top-N recommendation, multimodal, or more complex scenarios remains unclear.\n2. Dependence on textual descriptions. The robustness of the encoding and clustering components should be further validated under conditions where item descriptions are scarce, noisy, or cross-lingual.\n3. Cross-model generalization. The evaluation is limited to Qwen3-4B. It would strengthen the paper to include experiments on models with different architectures and scales (e.g., Llama, Gemma).\n4. Insufficient discussion of related work. Several relevant studies are not discussed or cited, such as [1–2] on long-term user profiling and [3] on latent reasoning. \n\n\n[1] Temporal User Profiling with LLMs: Balancing Short‑Term and Long‑Term Preferences\n\n[2] HyMiRec: A Hybrid Multi‑interest Learning Framework for Long‑Term Multi‑interest Sequential Recommendation\n\n[3] Reinforced Latent Reasoning for LLM‑based Recommendation"}, "questions": {"value": "See comments in Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "c10dz6FsnA", "forum": "NVrXCKaEjM", "replyto": "NVrXCKaEjM", "signatures": ["ICLR.cc/2026/Conference/Submission17207/Reviewer_NNTh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17207/Reviewer_NNTh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17207/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761146534283, "cdate": 1761146534283, "tmdate": 1762927174998, "mdate": 1762927174998, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper identifies two main limitations of LLM-based recommender systems: their difficulty in reasoning over long and noisy user histories, and their high inference latency. To address these challenges, the authors propose a method called SIREN, which employs long-term interest sketching to effectively process user histories and internalized reasoning to enhance inference efficiency. Experimental results demonstrate that the proposed method performs well."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-motivated, and the two main limitations of LLM-based recommender systems it identifies are highly worth addressing.\n2. Experimental results show that the proposed method effectively mitigates these limitations, demonstrating solid empirical performance.\n3. The hidden state alignment component is particularly insightful."}, "weaknesses": {"value": "1. In lines 254–256, the paper states that *“the final rating prediction under both answer-only (Fig. 1(c)) and CoT (Fig. 1(d)) decoding depends on the hidden state at the <answer> token.”* Could you provide additional evidence to support this claim?\n2. What does the “Rank” column mean in Table 2?\n3. Could you compare the training costs of these LLM-based recommender systems?\n4. I think Table 2 is missing an important baseline — one where the **first stage** extends the recent history with additional past interactions until reaching the token budget (*More history*), and the **second stage** uses **GRPO-CoT**."}, "questions": {"value": "see weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0hmdjEZftQ", "forum": "NVrXCKaEjM", "replyto": "NVrXCKaEjM", "signatures": ["ICLR.cc/2026/Conference/Submission17207/Reviewer_5SEj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17207/Reviewer_5SEj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17207/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761891520664, "cdate": 1761891520664, "tmdate": 1762927174606, "mdate": 1762927174606, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a post-training method for LLM-based recommendation systems that can reduce input length by aggregating and clustering long histories. Through a two-stage training algorithm, it first provide the LLM with accurate recommendation capabilities, then uses hidden state supervision alignment to reduce the CoT part to zero, thereby achieving fast and accurate score computation. The work's motivation and experiments are relatively comprehensive, and the writing is fairly well-structured. However, the overall innovation is notably insufficient. In particular, the results of the ablation study (RQ4) actually demonstrate that the proposed method's optimizations for the input and output components show minimal improvement in effectiveness."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper proposes a two-stage post-training method based on reinforcement learning that first elicits the model's reasoning capability through RL to achieve accurate score estimation, then shortens the CoT length through an aligned \"internalized reasoning\" stage, thereby accomplishing the objective of being \"both fast and accurate.\"\n\n2. The motivation is clear and highly valuable, addressing a problem that current LLM-based systems are actively working to solve. The paper provides comprehensive experimental results demonstrating the superiority of the proposed method over other related approaches, and is also well-written."}, "weaknesses": {"value": "1. The paper suffers from a notable lack of innovation, applying mature techniques from the existing community to recommendation systems. However, neither Stage 1 nor Stage 2 represents a novel idea. Moreover, the ablation study results (Figure 4) indicate that these modifications show almost no difference from direct SFT (CE in the Figure 4), with only marginal improvements (considering the test set and randomness, my personal view is that these improvements are extremely minimal).\n\n2. As for the experimental results. Particularly in Figure 4, where simple CE achieves results very close to the original SIREN, I am unclear why your reproduced Exp3RT performs significantly worse (I noticed in the appendix that you used the same base model for training, but still have doubts about the results). Additionally, it should be noted that I did not find SFT results directly using ratings as labels in the paper, so I can only refer to your SFT results based on the Stage 1 model as the base (i.e., CE in Figure 4).\n\n3. There are also some minor writing issues, such as subscripts that should be in roman type but were overlooked (e.g., Eq. 12), \"Appendix ??\" on line 491, and non-standard citation formatting (e.g., the title of Kim 2025's paper is incorrect)"}, "questions": {"value": "In addition to the issues mentioned in the Weaknesses section, I would also like to ask the authors: \n1. The instability and randomness of RL are widely acknowledged in the community. Have the authors encountered similar issues, and were the experimental results averaged over multiple training runs as is common practice in the RL community? \n2. When selecting the reward function, was an ablation study conducted (especially for s_{rate}) to try different forms of reward functions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9u3fSpWf9U", "forum": "NVrXCKaEjM", "replyto": "NVrXCKaEjM", "signatures": ["ICLR.cc/2026/Conference/Submission17207/Reviewer_Zz5G"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17207/Reviewer_Zz5G"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17207/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761903517205, "cdate": 1761903517205, "tmdate": 1762927174167, "mdate": 1762927174167, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}