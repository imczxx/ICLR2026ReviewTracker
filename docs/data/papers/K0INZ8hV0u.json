{"id": "K0INZ8hV0u", "number": 14059, "cdate": 1758227730498, "mdate": 1759897392882, "content": {"title": "LEMMA-RCA: A Large Multi-modal Multi-domain Dataset for Root Cause Analysis", "abstract": "Root cause analysis (RCA) is crucial for enhancing the reliability and performance of complex systems. However, progress in this field has been hindered by the lack of large-scale, open-source datasets tailored for RCA. To bridge this gap, we introduce LEMMA-RCA, a large dataset designed for diverse RCA tasks across multiple domains and modalities. LEMMA-RCA features various real-world fault scenarios from Information Technology (IT) and Operational Technology (OT) systems, encompassing microservices, water distribution, and water treatment systems, with hundreds of system entities involved. We evaluate the performance of six baseline methods on LEMMA-RCA across various settings, including offline and online modes, as well as single and multi-modal configurations. Our study demonstrates the utility of LEMMA-RCA in facilitating fair evaluation and promoting the development of more robust RCA techniques. The dataset and code are publicly available at https://www.lemmarca.info.", "tldr": "", "keywords": ["root cause analysis", "multi-modal learning", "microservice systems", "benchmark data"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c35027eb9945f9abd0a498241b6bb2d2788ed25e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "he paper introduces LEMMA-RCA, a large, multi-domain, multi-modal benchmark for root cause analysis. It aggregates real faults from IT microservices and OT water systems, with per-fault timestamps, entity-level metrics, and logs. The dataset supports offline and online evaluation and single or multi-modal inputs. Six baselines are evaluated."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper makes a strong case that RCA lacks large, open, realistic datasets across domains and modalities, then directly addresses this gap with IT and OT data at second-level granularity and millions of log events.\n\n2. The dataset enables metric only, log only, and multi-modal settings, and provides a concrete online protocol with streaming snapshots. This is timely because most RCA works are offline and single-modal.\n\n3. Six public baselines are run with fixed hyperparameters. Results show consistent gains from multi-modality and expose sharp drops online, which motivates future methods. Tables are clear."}, "weaknesses": {"value": "1. Many IT scenarios are induced on in-house platforms. OT segments are standardized to two-hour windows and may concatenate normal data around attacks. These choices aid benchmarking but can shift distributions and simplify temporal context, which could bias methods tuned to the benchmark\n\n2. Root cause labels are described at entity level, but the paper does not deeply detail labeling procedures, annotator reliability, or ambiguity handling when multiple entities co-cause failures.\n\n3. Using default hyperparameters improves fairness but may understate some methods. No per-dataset tuning, no ablations on window sizes, log features, or OT KPI construction. Results might change with modest tuning.\n\nMinor: Is a pure dataset paper appropriate for ICLR?"}, "questions": {"value": "1. How are ambiguous multi-cause incidents labeled and scored. Are partial credits or grouped causes considered.\n\n2. How sensitive are results to the log feature pipeline choices, especially template frequency and golden-signal keywords. Any robustness checks.\n\n3. What licensing and redaction steps ensure reproducibility for logs while protecting sensitive info. The dataset is CC BY-ND, but are raw logs fully available or partially sanitized."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "W8YE1AdLJe", "forum": "K0INZ8hV0u", "replyto": "K0INZ8hV0u", "signatures": ["ICLR.cc/2026/Conference/Submission14059/Reviewer_vZS5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14059/Reviewer_vZS5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14059/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761867446223, "cdate": 1761867446223, "tmdate": 1762924543477, "mdate": 1762924543477, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces LEMMA-RCA, a multimodal dataset for root cause analysis that includes multiple domains. The proposed dataset aims to address the scarcity of publicly available RCA datasets that contain diverse and realistic fault scenarios. LEMMA-RCA includes metrics and log data collected from IT and OT systems. The authors evaluate 6 RCA methods across offline and online, single- and multi-modal settings. Experimental results show the dataset’s utility for benchmarking different RCA approaches."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The paper constructs a multimodal RCA dataset, which is meaningful given the data scarcity in this field.\n- The proposed dataset is collected from multiple systems (IT + OT) and supports both offline and online RCA evaluation.\n- The experimental section compares multiple baselines in both online and offline settings"}, "weaknesses": {"value": "- The microservice failures are injected, while the paper states that the dataset contains \"real faults\". In Appendix D, the authors describe in detail the steps used to generate failures in microservices systems. If my understanding is correct, this indicates that the faults in the microservices are artificially injected rather than collected from real-world cases. However, in Table 1, the authors state that their dataset contains real faults. These two statements appear contradictory to me. The authors need to clarify whether the faults are injected and define what is meant by real faults.\n\n- The paper’s statements about existing RCA methods are inaccurate. The paper conflates offline RCA with supervised data-driven methods, which is conceptually inaccurate. Many RCA algorithms (e.g., CIRCA, TraceRCA, BARO, and many LLM-based methods, which are cited in this paper) are unsupervised methods that do not require any training or retraining when new faults occur. However, the paper states that “most RCA methods are designed for offline use, requiring extensive data collection and full retraining for new faults,” which clearly does not reflect the current state of research. Furthermore, the authors’ definition of \"data-driven RCA\" is unclear and misleading. In RCA, “data-driven” refers to inferring causal relationships directly from observed data, not to methods that perform better with more data. The current words ignore the dominant unsupervised approaches in both single-modal and multi-modal RCA.\n\n- The number of failure cases in each dataset is not explicitly given. It appears that the Product Preview and Cloud Computing sub-datasets each contain only four failure cases. This is insufficient for a comprehensive evaluation of RCA. I suggest that the authors clearly state the number of failure cases in the paper.\n\n- The advantages of Lemma-RCA over other datasets are not discussed in detail. As mentioned by the authors in the paper, there are already many open-source RCA datasets, including multimodal datasets and datasets obtained through failure injection. However, the authors only provide a vague comparison of different datasets in Table 1. This is not sufficient to demonstrate the advantages of the LEMMA-RCA dataset over others. The authors should present more cases to illustrate the advantages of LEMMA-RCA in terms of quality, quantity, and other aspects compared with similar datasets.\n\n- Figures 3 and 5 only provide a simple presentation of monitoring metrics without sufficient explanation, which makes them confusing. Moreover, they do not clearly show the fault propagation relationships among the metrics. I suggest that the authors provide more detailed explanations.\n\n- Section 3.1 includes many technical details that are not directly related to data collection. The authors should move the details in this section to the appendix and provide a more detailed description of the characteristics and advantages of the dataset itself.\n\n- In Section 3.2, the authors mention that logs from some system entities were excluded. However, the paper does not describe the specific filtering criteria."}, "questions": {"value": "1. What's the definition of \"real faults\"? Are the microservices failures in LEMMA-RCA injected?\n2. What's the difference between data-driven and non-data-driven RCA methods? Why do the offline methods need per-case retraining?\n3. What's the number of failure cases in each sub-dataset?\n4. What are the advantages of LEMMA-RCA compared with the other RCA datasets?\n5. What's the criteria for filtering the logs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GbJ4ImACNg", "forum": "K0INZ8hV0u", "replyto": "K0INZ8hV0u", "signatures": ["ICLR.cc/2026/Conference/Submission14059/Reviewer_JtiH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14059/Reviewer_JtiH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14059/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761910048041, "cdate": 1761910048041, "tmdate": 1762924543038, "mdate": 1762924543038, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces LEMMA-RCA, a new large-scale, multi-modal, and multi-domain dataset designed to facilitate research in RCA. The authors argue that progress in data-driven RCA has been hampered by a lack of suitable public benchmarks, with existing datasets often being small, proprietary, synthetic, or limited to a single domain/modality.\n\nLEMMA-RCA addresses this gap by providing a comprehensive collection of data from real-world systems, including IT operations (microservices) and Operational Technology (water treatment/distribution systems). The dataset features diverse and realistic system faults, involves hundreds of system entities, and contains multiple data modalities, primarily time-series metrics and textual logs. The authors provide a detailed description of the data collection process, preprocessing steps, and fault scenarios. To demonstrate the dataset's utility, they evaluate 6 baseline RCA methods in both offline and online settings, highlighting the performance differences across modalities and settings. The dataset is made publicly available to encourage fair comparisons and advance the field."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper successfully identifies and fills a major gap in the RCA research landscape by providing a large-scale, public benchmark.\n2. The dataset contains real system faults (or realistic induced faults) across different domains (IT and OT), which is a major step up from datasets with purely synthetic or simplistic faults.\n3. The inclusion of both time-series metrics and textual logs allows for the development and evaluation of multi-modal RCA methods. The data is structured to support both offline and online evaluation settings.\n4. The paper provides clear and detailed descriptions of the data sources, preprocessing, fault scenarios, and ground truth labeling process, which is essential for a dataset paper."}, "weaknesses": {"value": "1. The evaluated baselines are primarily traditional causal discovery or statistical methods. Given the recent surge of interest in using LLMs for diagnostics and RCA, the absence of any LLM-based baseline is a notable omission. Including even a simple zero-shot LLM baseline would have provided a valuable modern reference point.\n2. The feature extraction pipeline for logs is quite specific and multi-faceted (combining template frequency, keyword signals, and TF-IDF). This introduces a potential dependency, as future work might achieve different results based on their own feature engineering. It would be helpful if the authors clarified whether these preprocessed features are part of the release.\n3. The adaptation of offline methods for online evaluation uses a simple stopping criterion (\"similar results appear three times\"). This is heuristic and lacks the rigor of more standard online evaluation protocols like prequential evaluation. While it demonstrates the challenge, the protocol itself could be stronger.\n4. The paper focuses on single root causes tied to induced faults. Real-world incidents often involve multiple interacting root causes or complex cascading failures. It's unclear if the dataset captures this complexity or how such scenarios are labeled and evaluated."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FsNlw2RULu", "forum": "K0INZ8hV0u", "replyto": "K0INZ8hV0u", "signatures": ["ICLR.cc/2026/Conference/Submission14059/Reviewer_BL7y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14059/Reviewer_BL7y"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14059/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986838845, "cdate": 1761986838845, "tmdate": 1762924542664, "mdate": 1762924542664, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper describes a dataset that the authors are releasing on root cause analysis (RCA) spanning 4+ different domains and including both time-series of various metrics and textual logs.  The datasets are marked with root causes, that are real, and not simulated. The paper evaluates various existing RCA methods in both online and offline mode."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.  Releases a useful data resource for the community on root-cause analysis.which is distinguished from existing datasets by being multi-modal (textual logs and time-series), and real.\n\n2.  Evaluates six existing methods on the released datasets."}, "weaknesses": {"value": "1.  It is difficut to justify an ICLR paper just on the basis of releasing a dataset.  There are conferences with special tracks on datasets and benchmarking.  The paper is best submitted to such tracks.\n\n2.  Most of the methods evaluated are not mainstream to the AI/ML/DL community, so relevance to ICLR is of question.  Here are some papers that are missed:\n\n    2a:  Root cause analysis of outliers with missing structural knowledge  N Okati, SHG Mejia, WR Orchard, P Blöbaum… -NeurIPS 2025\n     \n     2b. Budhathoki, Kailash, et al. \"Causal structure-based root cause analysis of outliers.\" International conference on machine learning. PMLR, 2022.\n\n    2c.  Nagalapatti, Lokesh, et al. \"Robust Root Cause Diagnosis using In-Distribution Interventions.\" ICLR 2025.\n\n3.  Presentation issues:\n\n     3a: The sentence in line 183 claiming that \"fault ran the microservice\" is confusing.  How can a fault run a service?\n     \n      3b. The term multi-modal may be a bit mis-leading in current AI/ML community.  \n\n       2c.  Citations are sloppy.  For example, Li 2022 is repeated.  Citation Yu 2023 does not mention venue."}, "questions": {"value": "Q1: The description of the type of data and attach for the SWaT and WADI datasets misses important details like the type of the attack, and what are the recorded metrics, and logs.\n\nQ2.  Around line 278, the method of discretizing data into continuous values is not well-justified.  Isn't it better to directly do the RCA on the discrete data?\n\nQ3: The description of baselines is quite poor quality.  A paper like this, should ideally first define a common framework, and describe each method with common termilogy.  Currently, it comprises disconnected snippets which may have been lifted directly from individual papers without much attempt to actually explain and contrast each baseline.\n\n."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cnObUh1Z7w", "forum": "K0INZ8hV0u", "replyto": "K0INZ8hV0u", "signatures": ["ICLR.cc/2026/Conference/Submission14059/Reviewer_GReh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14059/Reviewer_GReh"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14059/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762071270817, "cdate": 1762071270817, "tmdate": 1762924542358, "mdate": 1762924542358, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}