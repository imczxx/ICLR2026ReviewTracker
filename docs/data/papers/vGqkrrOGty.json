{"id": "vGqkrrOGty", "number": 25195, "cdate": 1758365181247, "mdate": 1763135701537, "content": {"title": "Towards Real-world Debiasing: Rethinking Evaluation, Challenge, and Solution", "abstract": "Spurious correlations in training data significantly hinder the generalization capability of machine learning models when faced with distribution shifts, leading to the proposition of numberous debiasing methods. However, it remains to be asked: Do existing benchmarks for debiasing really represent biases in the real world? Recent works attempt to address such concerns by sampling from real-world data (instead of synthesizing) according to some predefined biased distributions to ensure the realism of individual samples. However, the realism of the biased distribution is more critical yet challenging and underexplored due to the complexity of real-world bias distributions. To tackle the problem, we propose a fine-grained framework for analyzing biased distributions, based on which we empirically and theoretically identify key characteristics of biased distributions in the real world that are poorly represented by existing benchmarks. Towards applicable debiasing in the real world, we further introduce two novel real-world-inspired biases to bridge this gap and build a systematic evaluation framework for real-world debiasing, RDBench. Furthermore, focusing on the practical setting of debiasing w/o bias label, we find real-world biases pose a novel Sparse bias capturing challenge to the existing paradigm. We propose a simple yet effective approach named Debias in Destruction (DiD), to address the challenge, whose effectiveness is validated with extensive experiments on 8 datasets of various biased distributions.", "tldr": "In this work, we revisit the task of debiasing under real-world scenarios, proposing systematic evaluation framework, challenges, and solutions for real-world debiasing.", "keywords": ["spurious correlation", "dataset bias", "debias"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/733614fecaad155ea957639ee81c9f41ac3b8403.pdf", "supplementary_material": "/attachment/e6065ec709c132da2b77743a4b0eec090236f788.zip"}, "replies": [{"content": {"summary": {"value": "The paper scrutinises whether current debiasing benchmarks faithfully reflect the complexity of real-world biases. The authors (i) present a fine-grained analytic framework that decomposes bias into “magnitude” and “prevalence”, (ii) empirically and theoretically demonstrate that real-world data sets often exhibit low-magnitude and low-prevalence biases—properties missing from popular benchmarks, (iii) introduce two new bias types and assemble them (plus existing data sets) into a systematic evaluation suite called RDBench, and (iv) identify a “sparse-bias-capturing” challenge when debiasing without bias labels. To tackle this they propose a simple method, Debias-in-Destruction (DiD), which first “destroys” dominant features and then reconstructs, leading to gains on eight data sets across several bias settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1. Important problem – The work challenges a widespread, implicit assumption (high-prevalence biases) and argues convincingly that it is misaligned with reality.\nS2. Novel analytical perspective – The magnitude / prevalence decomposition offers a clear, quantitative lens through which to study bias distributions.\nS3. New benchmark – RDBench fills a gap by providing real-world-inspired biases and multi-bias scenarios; releasing code/data will benefit the community.\nS4. Practical focus – Concentrating on “debiasing without bias labels” increases the paper’s relevance for industry deployment where bias attributes are rarely annotated.\nS5. Methodological contribution – DiD is conceptually simple, easy to integrate into existing pipelines, yet yields consistent improvements.\nS6. Thorough experiments – Eight data sets, multiple baselines, ablations, and both empirical and theoretical analyses lend credibility to the claims."}, "weaknesses": {"value": "W1. Scope limited to image classification – All studied tasks are visual. It is unclear whether the magnitude/prevalence findings (and DiD) generalise to NLP or multimodal settings.\nW2. “Real-world inspired” still partly synthetic – The two proposed biases are constructed heuristically; evidence that they mirror true large-scale natural distributions (e.g., via quantitative fitting or user studies) is thin.\nW3. Cost to “clean” accuracy – Results mainly highlight robustness under bias; corresponding drops on i.i.d. test sets are not fully reported. Practical users need to understand this trade-off.\nW4. Hyper-parameter robustness – DiD introduces new knobs (destruction ratio, masking schedule). Limited analysis is given on sensitivity and tuning without bias labels.\nW5. Reproducibility details – Key implementation aspects (random seeds, data split scripts, destruction operator specifics) are relegated to the supplement; including them in main paper would strengthen reproducibility."}, "questions": {"value": "Q1. How exactly were the two new bias distributions designed? Do you have quantitative evidence showing their closeness to real-world statistics?\nQ2. Can the magnitude/prevalence metrics be automatically computed on arbitrary data sets? If yes, will you release a toolkit?\nQ3. How does DiD perform when combined with other strong debiasing methods (e.g., GroupDRO, JTT) on RDBench? Are the gains additive?\nQ4. What is the computational overhead (training time, memory) introduced by DiD compared with vanilla ERM?\nQ5. Have you analysed failure cases where DiD hurts both biased and unbiased accuracy? Understanding such cases would be useful for practitioners."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qVHtxXkVCR", "forum": "vGqkrrOGty", "replyto": "vGqkrrOGty", "signatures": ["ICLR.cc/2026/Conference/Submission25195/Reviewer_k3gy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25195/Reviewer_k3gy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25195/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761632818678, "cdate": 1761632818678, "tmdate": 1762943358731, "mdate": 1762943358731, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper argues that existing debiasing benchmarks fail to reflect the true nature of biases found in real-world data. The authors introduce a fine-grained framework to analyse bias magnitude and prevalence, revealing that real-world biases are typically low and sparse, unlike the strong correlations assumed in synthetic datasets. They further propose RDBench, a systematic evaluation framework, and Debias-in-Destruction (DiD), a simple yet effective method that enhances bias capture under sparse, low-prevalence settings."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "(1) Presents a comprehensive empirical and theoretical analysis of real-world bias distributions, introducing the RDBench framework that provides a systematic and realistic benchmark for evaluating debiasing methods.\n\n(2) Proposes a simple yet effective Debias-in-Destruction (DiD) approach that generalizes well across multiple datasets and modalities, demonstrating strong improvements over existing debiasing methods."}, "weaknesses": {"value": "(1) The clarity of theoretical exposition could be improved, especially regarding assumptions and proofs.\n\n(2) Evaluation on large-scale, high-dimensional real-world data (e.g., complex vision-language models) remains limited.\n\n(3) The DiD method’s simplicity, while appealing, may lack interpretability and deeper theoretical grounding.\n\n(4) Some parts of the framework (e.g., threshold selection for bias magnitude/prevalence) rely on heuristics rather than principled estimation."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5aSMMdm3zD", "forum": "vGqkrrOGty", "replyto": "vGqkrrOGty", "signatures": ["ICLR.cc/2026/Conference/Submission25195/Reviewer_o4es"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25195/Reviewer_o4es"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25195/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761687570089, "cdate": 1761687570089, "tmdate": 1762943358407, "mdate": 1762943358407, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the gap between existing debiasing benchmarks and real-world biased distributions. The authors propose a fine-grained framework for bias analysis that distinguishes between bias magnitude and bias prevalence. Based on empirical and theoretical insights from real-world datasets, the authors introduce RDBench, a new benchmark for realistic bias evaluation, and a simple yet effective debiasing method called Debias in Destruction (DiD). DiD is designed to handle “sparse bias” scenarios, especially under the practical setting of debiasing without bias labels."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Novel problem framing and fine-grained bias analysis\nThe paper raises an important question about whether current benchmarks truly represent real-world biases. By distinguishing bias magnitude (how strong the spurious correlation is) and bias prevalence (how common it is in the dataset), the authors provide a meaningful and interpretable framework for bias characterization. This fine-grained view can serve as a strong foundation for future benchmark design. \n\n- Realistic motivation for bias-agnostic debiasing\nThe authors focus on debiasing without explicit bias labels, a practically relevant and challenging setting in real-world applications (e.g., MS COCO, COMPAS). The discussion on the limitations of existing auxiliary-model-based approaches (e.g., Nam et al., 2020; Lee et al., 2021) is insightful. \n\n- Simplicity and generality of the proposed DiD method\nDiD is conceptually simple, can be easily integrated into existing methods, and empirically improves performance across several benchmark tasks (LfF, DisEnt, BEL, BED, etc.). The consistent improvements across multiple bias setups demonstrate its general applicability.\n\n- Comprehensive literature grounding\nThe authors provide an extensive review of existing bias-agnostic debiasing methods, clearly situating their contribution within the field."}, "weaknesses": {"value": "- Lack of validation on real-world datasets (MS COCO, COMPAS)\nAlthough the introduction emphasizes real-world bias distributions and repeatedly mentions datasets such as MS COCO (for vision) and COMPAS (for fairness in tabular domains), the actual experiments are limited to synthetic or semi-synthetic settings such as Colored MNIST or Corrupted CIFAR-10 (referred to as HMLP BC). The absence of evaluation on these real datasets undermines the claim that DiD or RDBench effectively handles real-world biases.\n\n- Dependence on prior bias knowledge for bias magnitude estimation\nSimilar to many previous debiasing works, the computation of bias magnitude (Equation 1) assumes that the spurious attribute (or biased feature) is known a priori. This contradicts the fully unsupervised debiasing objective and limits the applicability in settings where such bias attributes are unknown or latent.\n\n- Limited empirical diversity and scalability\nThe reported experiments (e.g., HMLP BC) are confined to small-scale benchmarks with controlled bias patterns. It remains unclear whether DiD can scale to multimodal or large-scale datasets such as MS COCO or social datasets like COMPAS, which involve complex, overlapping biases.\n\n- Missing discussion on recent relevant works\nThe paper omits several closely related and contemporaneous studies, such as “Debiasing Classifiers by Amplifying Bias with Latent Diffusion and Large Language Models” (2025), which similarly address real-world bias modeling using diffusion-based augmentation. Including comparisons or conceptual distinctions from these methods would strengthen the paper’s positioning.\n\n- Ambiguity in benchmark naming and description (e.g., HMLP BC)\nSome terms such as HMLP BC are not clearly defined or are introduced without detailed explanation of their dataset composition, making reproducibility difficult."}, "questions": {"value": "ms coco, is there a reason COMPAS wasn't included in the main results or additional experiments?\nCan you provide a complexity analysis of the proposed method when implemented in practice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fhCMq3Oc8e", "forum": "vGqkrrOGty", "replyto": "vGqkrrOGty", "signatures": ["ICLR.cc/2026/Conference/Submission25195/Reviewer_SKNU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25195/Reviewer_SKNU"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25195/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761789062846, "cdate": 1761789062846, "tmdate": 1762943358177, "mdate": 1762943358177, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the assumption that training datasets exhibit severe biases affecting nearly all samples (over than 95%). Analysis of MSCOCO and COMPAS datasets reveals real-world biases are sparse (about 8~15% prevalence) with scattered patterns, contrasting with the diagonal patterns of existing benchmarks. \n\nKey proposals include the followings:\n\n(1) Fine-grained Metrics: Bias Magnitude (KL Divergence) and Bias Prevalence (proportion of biased samples).\n\n(2) Bias Neutral Category: Expands the Bias aligned/Bias Conflict dichotomy for samples lacking biased features.\n\n(3) Theoretical validation: Propositions 1~2 demonstrate high prevalence distributions require unrealistic matched and uniform marginals, unsupported in reality.\n\n(4) DiD Method: Destroys target features during bias model training, ensuring low loss for bias aligned and high loss for bias neutral and bias conflict by capturing only spurious correlations.\n\nSom this paper mainly claim that existing methods falter on low prevalence real-world data due to misweighting abundant bias neutral samples, a problem addressed by the proposed method DiD."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Strengths are summarized as follows:\n\n(1) Clear problem framing: Figure 1 contrasts diagonal benchmark patterns with scattered real-world biases.\n\n(2) Rigorous theory: Propositions 1 and 2 justify the sparsity of real-world biases mathematically.\n\n(3) Comprehensive experiments: Covers 8 datasets (vision + NLP benchmarks), 9 baselines (e.g., LfF, DisEnt, BEL), multiple bias types."}, "weaknesses": {"value": "** Critical Weaknesses\n\n(1) Limited real-world evidence: Detailed analysis only for COCO and COMPAS datasets.  CelebA, MultiNLI, and CCW are minimally discussed, appearing mainly in Figure 2 and Appendix. CelebA is real-world, but coverage is limited; medical and social media domains are only motivationally mentioned. Core experiments likely rely on synthetic datasets (Colored MNIST and Corrupted CIFAR-10)\n\n(2) Experimental design flaw: LMLP with threshold 0 result in 0% BN samples, which contradicts the focus on BN prevalence. Only HMLP are LMLP examine the hypothesis.\n\n(3) Unexplained Performance Variation: Table 1 shows improvement from -0.8 to 32.6 across datasets with the proposed algorithm DiD. The paper lacks a predictive model, quantitative feature complexity metric, or failure analysis.\n\n(4) Theory practice gap: Propositions assume binary attributes, while experiments use 10-class problems without a multi-class extension.\n\n(5) Incomplete coverage of related work: Although the paper discusses many relevant studies, several important papers and comparison baselines are missing - for example, PGD [1]\n\n[1] Mitigating dataset bias by using per-sample gradient, ICLR 2023"}, "questions": {"value": "Please refer to the Weaknesses section, which includes my main questions and concerns about the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "NtsPv1dGRH", "forum": "vGqkrrOGty", "replyto": "vGqkrrOGty", "signatures": ["ICLR.cc/2026/Conference/Submission25195/Reviewer_RjaM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25195/Reviewer_RjaM"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25195/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977635766, "cdate": 1761977635766, "tmdate": 1762943357903, "mdate": 1762943357903, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}