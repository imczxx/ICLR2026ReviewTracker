{"id": "jOTc6bolV5", "number": 12806, "cdate": 1758210449455, "mdate": 1763644159337, "content": {"title": "ContraLog: Log File Anomaly Detection with Contrastive Learning and Masked Language Modeling", "abstract": "Log files record computational events that reflect system state and behavior, making them a primary source of operational insights in modern computer systems. Automated anomaly detection on logs is therefore critical, yet most established methods rely on log parsers that collapse messages into discrete templates. This discretization discards valuable information. Variable log values are ignored, semantic variation is lost. We propose ContraLog, a parser-free and self-supervised method that reframes log anomaly detection as predicting continuous message embeddings rather than discrete template IDs. ContraLog combines a message encoder that produces rich embeddings for individual log messages with a sequence encoder to model temporal dependencies across sequences. ContraLog is trained with a combination of masked language modeling and contrastive learning to predict masked message embeddings based on the surrounding context. Experiments on the HDFS, BGL, and Thunderbird benchmark datasets empirically demonstrate ContraLogs effectiveness on complex datasets with diverse log messages. Additionally, we find that message embeddings generated by ContraLog carry meaningful information and are predictive of anomalies even without sequence context. These results highlight embedding-level prediction as an approach for log anomaly detection, with potential applicability to other event sequences such as IoT telemetry and audit trails.", "tldr": "A self-supervised framework that predicts log message embeddings based on context using contrastive learning and masked language modeling.", "keywords": ["Anomaly detection", "Contrastive learning", "Masked language modeling", "Log file processing"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a98da2c9a0e0d1488f0e2069619c1071fb2a8b9c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces ContraLog, a novel, self-supervised method for log anomaly detection that operates directly on raw log messages, eliminating the need for a separate log parsing step. The core idea is to reframe the problem from predicting discrete log template IDs to predicting continuous message embeddings.The paper's key contributions include :A parser-free and self-supervised framework for log anomaly detection; A two-pronged inference strategy that combines a contextual anomaly score (based on the discrepancy between predicted and actual message embeddings) and a point anomaly score (based on the deviation of a message's embedding from a set of normal embeddings)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1, The work is highly original. While the use of transformers and masked language modeling exists in prior log analysis works (e.g., LogBERT, LogFit), the core innovation lies in predicting continuous embeddings rather than discrete tokens. This elegantly circumvents the information loss inherent to log parsers. The creative combination of contrastive learning with masked language modeling for this specific task is novel and well-motivated. \n\n2, The methodology is sound and well-explained, from the custom BPE tokenizer to the symmetric contrastive loss and the robust z-score aggregation for inference. \n\n3, The paper is generally well-written and clear. The problem is effectively motivated, the architecture is illustrated (Figure 1), and the training and inference procedures are described in sufficient detail."}, "weaknesses": {"value": "1, A significant weakness that must be addressed is the substantially lower performance reported for LogBERT and DeepLog compared to their original publications. While the authors provide a plausible justification (fitting the parser only on the training set and chronological splitting), the magnitude of the performance drop (e.g., LogBERT F1 of 55.51 vs. originally reported ~99+ on HDFS) is dramatic. This raises questions about the fairness of the comparison. A more rigorous experimental setup, such as reporting results with both the original parsing method and the proposed stricter method, is needed to conclusively demonstrate that ContraLog's gains are due to its architecture and not the experimental conditions.\n\n2,The self-supervised approach crucially depends on the training data consisting purely of normal sequences. The paper correctly identifies this as a limitation, but could do more to quantify the method's sensitivity to contamination. An experiment injecting small, realistic rates of anomalous sequences into the training set would provide crucial insights into its robustness in noisy, real-world scenarios.\n\n3,Although an ablation study is present, it is purely empirical (showing which score combinations work best). A more mechanistic ablation, such as training a version of ContraLog that predicts discrete template IDs (using the same architecture but a cross-entropy loss on parsed templates), would directly isolate the benefit of continuous embedding prediction versus the discrete approach. Furthermore, the excellent performance of point anomaly detection on BGL/Thunderbird, while explained, warrants a deeper investigation into why the contextual signal is less critical there."}, "questions": {"value": "The results for LogBERT and DeepLog are far lower than those typically reported in the literature. Could you please provide a more detailed analysis to rule out implementation or experimental setup artifacts? For instance, have you attempted to replicate the original papers' parsing strategy (on the full dataset) to establish a performance upper-bound for these baselines under your evaluation split? A clear demonstration that the performance gap persists even when parsing is done \"optimally\" would significantly strengthen the claim that ContraLog's advantages are fundamental."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "eyZf2tyHFc", "forum": "jOTc6bolV5", "replyto": "jOTc6bolV5", "signatures": ["ICLR.cc/2026/Conference/Submission12806/Reviewer_Z3KG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12806/Reviewer_Z3KG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761884042935, "cdate": 1761884042935, "tmdate": 1762923614429, "mdate": 1762923614429, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a self-supervised log file anomaly detection method called ContraLog. It uses a message encoder to encode individual log messages and a sequence encoder to model log sequences. ContraLog categorizes anomalies into two types: point anomalies and contextual anomalies. During inference, each message in a sequence is masked sequentially, producing two corresponding anomaly scores for every message. Experiments on three datasets show that the F1 score of the proposed method is higher than the baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "W1. The core idea of shifting from discrete template prediction to continuous embedding prediction is a significant strength. This directly addresses the well-known limitations of parser-based methods, namely the loss of information from variable parameters and the inability to capture semantic similarity between different templates.\nW2. Comparing actual and predicted values is a common approach in time-series anomaly detection. This work innovatively applies this method to anomaly detection in textual logs, representing a valuable contribution.\nW3. The proposed method ContraLog has a higher F1 score than other methods."}, "weaknesses": {"value": "S1. In Table 2, the F1-score calculations for the ContraLog model across the three datasets appear to be incorrect. For example, on the HDFS dataset, the precision is 85.52 and the recall is 83.58, yielding an F1-score of 84.54, whereas Table 2 reports 83.35. Similar discrepancies are found for the BGL and Thunderbird datasets. The authors should provide an explanation for these differences.\nS2. The Introduction section states, “Parsing Errors: Parsers require dataset-specific rules and frequent updates as log schemas evolve.” However, the ContraLog method also relies heavily on the training dataset and therefore does not appear to address this issue."}, "questions": {"value": "1. Please explain the discrepancies in the F1-score values reported in Table 2.\n2. Can the ContraLog method be transferred to log datasets that differ from the training dataset, for example by fine-tuning with a small amount of data or using a few-shot approach?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lIyTmWtRUr", "forum": "jOTc6bolV5", "replyto": "jOTc6bolV5", "signatures": ["ICLR.cc/2026/Conference/Submission12806/Reviewer_fatz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12806/Reviewer_fatz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761887314210, "cdate": 1761887314210, "tmdate": 1762923614085, "mdate": 1762923614085, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents ContraLog, a method for log file anomaly detection that operates directly on raw log messages, avoiding the use of traditional log parsers. The core idea is to reframe the problem from predicting discrete log templates to predicting continuous message embeddings in a self-supervised manner. The model uses a hierarchical transformer architecture to learn embeddings for both individual messages and sequences of messages. Anomaly detection is based on a two-part scoring system: a contextual score, which measures how well a message embedding can be predicted from its surrounding context, and a point score, which measures the similarity of a message embedding to those seen in normal training data. The method's effectiveness is demonstrated on the HDFS, BGL, and Thunderbird benchmark datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The central concept of predicting continuous embeddings instead of discrete log keys is a strong contribution. This directly addresses the information loss problem inherent in parser-based methods, which often discard important details contained in variable parameters.\n2. The dual-pronged anomaly scoring mechanism is a practical and well-thought-out design. The point anomaly score provides a safety net for cases where contextual information is weak or misleading, such as a sequence of identical abnormal messages. The analysis in the appendix effectively shows how the importance of each score type varies by dataset, validating this design choice.\n3. The evaluation is quite thorough. Beyond reporting standard metrics, the paper includes a qualitative analysis of the learned embedding space, which gives confidence that the model is learning semantically meaningful representations. This analysis shows the model can group related messages and distinguish between different parameter values for the same log template, supporting the main claims."}, "weaknesses": {"value": "1. The \"parser-free\" claim feels a bit overstated. The method uses a custom Byte-Pair Encoding (BPE) tokenizer trained on each specific dataset. This is still a data-dependent preprocessing step that learns the statistical patterns of the log text, which is conceptually not so different from what a parser aims to achieve, albeit at a different level of granularity. \"Template-free\" might be a more accurate descriptor.\n2. The training process seems to require a fair amount of dataset-specific tuning. As shown in Table 5, key hyperparameters like tokenizer vocabulary size, embedding dimension, and even learning rate were set differently for each dataset. The paper notes an extensive search was not conducted, but this raises questions about how to apply ContraLog to a new system. It's not clear how a practitioner would set these parameters without a labeled dataset for tuning.\n3. The handling of long-range dependencies is a potential issue. The model's maximum sequence length was limited to 256 messages, and the authors acknowledge the quadratic complexity of transformers as a limitation. For anomalies that unfold over thousands of log messages, this architecture might not be suitable, and it's not clear how performance or computational costs would scale."}, "questions": {"value": "1. Regarding the Point Anomaly Score: This score is calculated as the distance to the single closest embedding from a random subset of the training data (Section 3.3). This seems potentially sensitive to the choice of that subset. Were other, perhaps more robust, methods considered, such as using a k-NN distance or the distance to a cluster centroid of normal embeddings? Also, how was the size of this subset of normal training sequences determined?\n2. On the HDFS Results: In Table 2, the statistical methods outperform ContraLog on the HDFS dataset. The paper suggests this is because sequential information is less important for HDFS anomalies (lines 425-428). However, the ablation study in Table 4 shows that using only the contextual scores (Cmax and Cmean) gives the best F1-score for HDFS. This seems to suggest that context is, in fact, the most important signal for this dataset. Could the authors clarify this apparent contradiction?\n3. On the Practicality of the Threshold: The detection threshold is set at the 95th percentile of scores from a normal calibration set (line 330). In a production environment, this would imply a static 5% false positive rate on normal data, which could be too high. It would be helpful to see a Precision-Recall curve or similar analysis to understand the trade-off between flagging true anomalies and raising false alarms at different threshold settings.\n4. Inference Latency: The paper mentions that caching embeddings for repeated messages can significantly reduce redundant computations (lines 342-346), noting an 89.1% reduction in embedding steps for Thunderbird. This is a great practical optimization. Could the authors provide some concrete numbers on the wall-clock inference time (e.g., latency per sequence) with and without this caching enabled? This would offer a clearer picture of the model's real-world performance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pcu7LP1WDY", "forum": "jOTc6bolV5", "replyto": "jOTc6bolV5", "signatures": ["ICLR.cc/2026/Conference/Submission12806/Reviewer_4dZc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12806/Reviewer_4dZc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762124918649, "cdate": 1762124918649, "tmdate": 1762923613658, "mdate": 1762923613658, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel  parser-free and self-supervised method for log file anomaly detection named ContraLog, which reframes log anomaly detection as predicting continuous message embeddings rather than widely-used discrete template IDs. ContraLog combines a message encoder that produces rich embeddings for individual log messages with a sequence encoder to model temporal dependencies across sequences. Masked language modeling and contrastive learning are adopted in the training process to predict masked message embeddings based on the surrounding context. Experiments on three benchmark datasets empirically demonstrate the effectiveness of ContraLogs on complex datasets with diverse log messages.\n\nThe major contribution of the paper is concluded as following:\n1. ContraLog is a novel framework that combines self-supervised contrastive learning and masked language modeling for log anomaly detection, eliminating the need for a log parser by working directly on raw log messages. It also does not rely on a large amount of manually labeled log messages.\n\n2. ContraLog includes a novel anomaly scoring mechanism that consists of a contextual anomaly score and a point anomaly score. \nThe contextual anomaly score measures the model's ability to predict an embedding based on its context, while the point anomaly score measures how much a single message's embedding deviates from those seen in the training set.\n\n3. Empirical validation on three public log datasets demonstrates that ContraLog outperforms existing methods like LogBERT and DeepLog, showing robust performance in complex logging scenarios. Additional experimental results are reported in the appendix."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The novelty of the proposed method is good. The core idea of this research is reframing log anomaly detection from predicting discrete tokens to predicting continuous embeddings of raw messages, which distinguishes ContraLog from existing approaches. The combination of masked language modeling and contrastive learning is also novel and effective.\n\n2. The paper is clearly written and well structured. The research motivation is well explained in the introduction and related work section. The description of the models, training objective, and inference process is well expained and easy to follow. Figure 1 is a concise and well illustrated summarization of the proposed method.\n\n3. The experimental results of ContraLog has a significant advantage in terms of F1-score,. Specifically, the F1-scores on BGL and Thunderbird have reached >96%."}, "weaknesses": {"value": "1. The contents about the masked language modeling part is not very clear. Please see the questions below. The sequence encoder part in section 3.1 seems that it takes all the message representations as input, but only the masked messages are used for computing the contrastive loss.\n\n2. The experiment section in the formal contents is very short, and only contains a single group of results. I think an ablation study about the essential parts of the proposed method like message masking and contrastive learning should be  conducted to validated the effectiveness of these components.\n\n3. As listed in the limitation section of the appendix, the proposed method relies on a large amount of normal log messages. If the training set contains many abnormal messages, the performance would deteriorate. The proposed method does not make fully use of labeled abnormal messages, which may be expensive to obtain and contain rich information."}, "questions": {"value": "I have not fully understood the masked language modeling part of ContraLog, so I raise the following questions: \n\n1. How is masked messages generated? I thought that a number of randomly selected log messages in a sequence is masked.\n\n2. Is the contrastive loss only computed with the masked input messages? If it is, why don't we mask the messages before inputting them into the message encoder?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "n01mTRV6FM", "forum": "jOTc6bolV5", "replyto": "jOTc6bolV5", "signatures": ["ICLR.cc/2026/Conference/Submission12806/Reviewer_QeV3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12806/Reviewer_QeV3"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762234023366, "cdate": 1762234023366, "tmdate": 1762923613234, "mdate": 1762923613234, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}