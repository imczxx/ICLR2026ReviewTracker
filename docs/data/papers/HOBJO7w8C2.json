{"id": "HOBJO7w8C2", "number": 7636, "cdate": 1758030038589, "mdate": 1763651188774, "content": {"title": "SurvDiff: A Diffusion Model for Generating Synthetic Data in Survival Analysis", "abstract": "Survival analysis is a cornerstone of clinical research by modeling time-to-event outcomes such as metastasis, disease relapse, or patient death. Unlike standard tabular data, survival data often come with incomplete event information due to dropout, or loss to follow-up. This poses unique challenges for synthetic data generation, where it is crucial for clinical research to faithfully reproduce both the event-time distribution and the censoring mechanism. In this paper, we propose SurvDiff, an end-to-end diffusion model specifically designed for generating synthetic data in survival analysis. SurvDiff is tailored to capture the data-generating mechanism by jointly generating mixed-type covariates, event times, and right-censoring, guided by a survival-tailored loss function. The loss encodes the time-to-event structure and directly optimizes for downstream survival tasks, which ensures that SurvDiff (i) reproduces realistic event-time distributions and (ii) preserves the censoring mechanism. Across multiple datasets, we show that SurvDiff consistently outperforms state-of-the-art generative baselines in both distributional fidelity and downstream evaluation metrics across multiple medical datasets. To the best of our knowledge, SurvDiff is the first diffusion model explicitly designed for generating synthetic survival data.", "tldr": "", "keywords": ["synthetic data generation", "right censoring", "diffusion models", "generative modeling", "survival analysis"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/099a77377c4bcc3dbc90f40d9741d63e62d9cb7e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper aims to build a generative model that is specifically tailored for survival analysis data generation, which is a known application problem. The paper introduced SurDiff model to address the problem, which is an end-to-end diffusion model that can generate both continuous and discrete variables at the same time. During training, the model is guided by a survival loss function to match the true survival event distribution across samples. Experiments show that SurvDiff can reproduce realistic event-time distribution and is potentially useful for downstream application. The authors claim that existing methods are not able to reproduce realistic event-time distributions and preserve censoring mechanisms, while SurvDiff can success in these two aspects with the help of survival loss."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Survival analysis is one of the critical problems in the medical area. The proposed method SurvDiff contains a survival loss that is specifically tailored for addressing the problem, making original contribution to the area.\n2. SurvDiff is the first diffusion-based survival data generation model with survival task-specific design. Compared with SurvivalGAN, it is an end-to-end method that tends to avoid error propagation and is able to be trained stably.\n3. The presentation is clear and well-structured, making the paper easy to follow. The choices of evaluation metrics, baseline methods and datasets are comprehensive."}, "weaknesses": {"value": "1. Covariate distribution experiments: Missing implementation details, e.g. the number of samples used to compute these metrics, how is each covariate vector normalized for dimension reduction computation, how many bins are used to estimate probability density, how anomaly values are addressed.\n2. Numerical results mismatch between JS distance and Wasserstein distance metrics. More explanations on this phenomenon are expected to help understand the true performance of the proposed method.\n3. Downsampled dataset settings are not sufficiently justified. Does this setting mean that the dataset used to trained SurvDiff and all baselines are downsampled? What is the downsampling ratio and how will the performance change with varying downsampling ratio (including the full-dataset scenario)? From my perspective, it is still meaningful testing on full dataset to show the performance of SurvDiff. \n4. Survival metrics are weak, which raises concerns on the effectiveness of the survival specific loss. TabDiff turns out to be the best baseline, which should just be equivalent to remove the survival loss from SurvDiff. Since the survival loss stands for the core contribution of this paper, these results make the contribution of this paper questionable. \n5. Missing ablation studies and parameter sensitivity analysis. The effectiveness of survival loss, sparsity-aware weighting, and the loss weight parameters in SurvDiff are not fully explored. For downstream tasks, it is also critical to evaluate the downstream model performance without using any synthetic data generation methods to demonstrate benefits.\n\nThe major problem of this submission is that the claimed contribution is not sufficiently justified by the experiments. In fact, some experiments are showing opposite results: survival loss doesn’t really help survival task, while the naive TabDiff can perform notably better than SurvDiff. Without proper justifications, I believe this paper is not ready for publication yet, and major revisions are needed on both the methodology and experiment."}, "questions": {"value": "I have some questions on parts where I didn’t fully understand: In eq.(10-11), the weights are not normalized. When trying to balance two loss components with eq.(13), how will the number of samples $n$ (for calculating eq.(10)) influence the optimal target fraction $\\alpha_{\\text{surv}}$? How is this $n$ selected? What is the definition of $\\tau$? Is this $\\mathcal{L}_{\\text{surv}}$ calculated across the batch size dimension?\n\nI have another minor suggestion for the authors: The two colors in Figure 3-8 are too similar to visually show the discrepancy between distributions of real and synthetic data. It would be better to opt for more contrasting colors."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GEuIK5911h", "forum": "HOBJO7w8C2", "replyto": "HOBJO7w8C2", "signatures": ["ICLR.cc/2026/Conference/Submission7636/Reviewer_ctHa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7636/Reviewer_ctHa"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7636/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761908190423, "cdate": 1761908190423, "tmdate": 1762919712980, "mdate": 1762919712980, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "We thank all reviewers for the thoughtful and constructive comments. We are glad to hear that you found the contribution innovative and important. We followed your feedback closely and have carefully revised our paper as a result (see **updated PDF**). We further highlighted all key changes in **blue color**.\n\nIn particular, our **key improvements** are the following:\n\n1. **New baseline**: We added new experiments with a new baseline. However, our proposed Survdiff performs best by a clear margin (see our **new results** in **Tables 2 and 3**).  \n2. **New empirical evaluations**: We added temporal event and censoring distribution plots, as well as normalized marginal covariate histograms to assess alignment between real and synthetic data, specifically real and synthetic time and event data. Across these diagnostics, our SurvDiff matches the real data most closely (see our **new Figures 4, 7-9** and our **new Appendix E**).  \n3. **New survival-specific fidelity metric**: We added the Event-Time Divergence to quantify survival-specific fidelity and to evaluate how well our model reproduces event-time distributions. SurvDiff achieves the best scores (see our **new Appendix C**).  \n4. **New Shape metric reporting**: We now also report the Shape metric to quantify overall distribution alignment. We added the Shape metric to quantify fidelity that includes survival-specific event-time. Our SurvDiff remains the strongest method on this metric (see our **new results** in **Table 2**).  \n5. **New ablation and parameter sensitivity studies**: We added an ablation study and a focused parameter sensitivity study to show how the key design choices influence performance. Overall, the studies confirm our design choice (see our **new Appendix J**).   \n6. **New privacy proof-of-concept and experiments**: We extended our method with a differentially private training variant that provides formal privacy guarantees. We also added a comparison to DP-GAN baseline and found that our differentially private variant achieves higher performance under the same privacy budget (see our **new Appendix I**).  \n7. **Clarifications of technical details**: We expanded implementation and evaluation details and added clarifications on definitions.\n\nWe believe these additions fully address the reviewers’ comments and strengthen both the empirical and methodological presentation. Thank you again, we sincerely appreciate your time and effort in reviewing our work and believe that the revised paper will be a strong fit for ICLR 2026."}}, "id": "TgUeSLsK9Q", "forum": "HOBJO7w8C2", "replyto": "HOBJO7w8C2", "signatures": ["ICLR.cc/2026/Conference/Submission7636/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7636/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7636/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763651867021, "cdate": 1763651867021, "tmdate": 1763651867021, "mdate": 1763651867021, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents SurvDiff, an end-to-end diffusion model specifically designed for generating synthetic survival data. The key contribution is jointly modeling covariates, event times, and censoring mechanisms through a survival-tailored loss function."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Well-motivated problem: The paper addresses a need in medical research where survival data with censoring mechanisms presents unique challenges for synthetic data generation and downstream applications.\n2. Comprehensive experiments: The evaluation across AIDS, GBSG2, and METABRIC datasets is thorough, showing consistent improvements over baselines in both covariate fidelity and downstream performance.\n3. Clear presentation: The paper is generally well-written with good visualizations (t-SNE plots, KM curves) that effectively demonstrate the method's performance."}, "weaknesses": {"value": "*Limited Novelty* \n1. The core diffusion framework closely follows TabDiff (Shi et al., 2024b) for mixed-type data\n2. The main novel contribution is adding a weighted Cox loss (Equation 10) with exponential decay weighting (Equation 11)\n.The combination of existing techniques (masked diffusion for discrete, Gaussian for continuous) is straightforward\n\n*Lack of Theoretical Guarantees*\n1. No theoretical justification for why the proposed loss preserves censoring mechanisms\n2. Missing bounds on the quality of generated distributions\n\n*Missing Privacy Analysis* The paper lack privacy analysis, such as membership inference attack evaluation. No discussion of potential patient re-identification risks"}, "questions": {"value": "Only compares against SurvivalGAN as a survival-specific method. Could benefit from comparisons with other recent tabular generative models."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xWRXalvmcN", "forum": "HOBJO7w8C2", "replyto": "HOBJO7w8C2", "signatures": ["ICLR.cc/2026/Conference/Submission7636/Reviewer_Tnii"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7636/Reviewer_Tnii"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7636/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971379232, "cdate": 1761971379232, "tmdate": 1762919712686, "mdate": 1762919712686, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a diffusion model for generating synthetic data for survival analysis. It achieves this by introducing a survival analysis specific loss function. The resulting architecture is evaluated across multiple datasets, focusing on 1) covariate distribution similarity, 2) downstream task performance, 3) survival outcome reproduction and 4) robustness in low-data regimes. The model shows strong performance on 1, 2 and 4 while showing comparable performance on 3."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "- Strong performance on both covariate distribution fidelity and downstream tasks.\n- Addresses an important problem, synthetic data for healthcare applications."}, "weaknesses": {"value": "1. Weak connection between the drawbacks of existing works and the chosen evaluation. The introduction states that existing general-purpose methods for generating tabular data fail to: 1) reproduce realistic event-time distributions and 2) preserve censoring mechanics. The evaluation is based on comparing covariate distributions, not event-time distributions, as well as downstream tasks. It is unclear whether the downstream tasks evaluate both event-time distribution realism and censoring mechanics preservation. \n2. The clarity of the paper could benefit from additional intuition when introducing key concepts. While these might be common in the domain of survival analysis, they might not be familiar to the general ICLR audience. \n\t1. (Right-)Censoring: First used in introduction, definition and intuition given in 3.1\n\t2. Time-to-event: First used in introduction, definition and intuition given in 3.1\n\t3. Risk sets: Defined in 4.3, no intuition given\n3. The notation in section 4.3 was challenging and difficult to follow. \n4. No discussion around memorization, there is always a risk of the model learning to reproduce individuals from the training data, which could raise privacy concerns."}, "questions": {"value": "1. Are the event indicator and event time variables part of the covariate distribution fidelity study? \n2. How are the different evaluations related to the stated goals of the paper?\n\t1. reproduce realistic event-time distributions\n\t2. preserve censoring mechanics.\n3. Could you elaborate on how $\\mathcal{L}\\_\\text{surv}$ is calculated? The survival head $f_\\theta$ takes the continuous covariates and the discrete covariate probabilities, both denoised by the reverse diffusion process, and predicts a scalar risk score $r_i$ for a specific individual $i$. This $i$ refers to a synthetic sample. In equation 10, it is then compared to other individuals using the risk set in the denominator. Are these individuals also synthetic or are they drawn from the training data? \n4. Questions to clarify the notation in section 4.3:\n\t1. In equation 10, is the denominator supposed to be $\\exp(r_j)$ rather than $\\exp(r_i)$?\n\t2. In equation 11, what are the definitions of $\\tau$ and $T_i$? How are they related to $T$ and $t_i$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "anng42S1NO", "forum": "HOBJO7w8C2", "replyto": "HOBJO7w8C2", "signatures": ["ICLR.cc/2026/Conference/Submission7636/Reviewer_biW2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7636/Reviewer_biW2"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7636/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990511533, "cdate": 1761990511533, "tmdate": 1762919712374, "mdate": 1762919712374, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose DiffSurv, an end-to-end diffusion model for generating synthetic survival data. Unlike existing approaches, it jointly generates covariates, event times and censoring indicators. They present experimental results demonstrating the superiority of their approach relative to SurvivalGAN."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The proposed objective is the most innovative aspect of the proposed model. Specifically, they take a standard partial likelihood loss and add weights to mitigate the effects caused by the shrinking risk set as t goes to infinity."}, "weaknesses": {"value": "The authors argue that there is only one method (SurvivalGAN) to generate synthetic survival data, however, there is [1], which was more recently presented at MLHC [2]. In fact in [2], they also consider a diffusion model (TabDDPM) as their backbone and as an unconditional sampler (X, T and E are sampled jointly), thus the presented approach is not even the first to use diffusion models.\n\nThe experimental results in Tables 2 and 3 indicate that the proposed model is comparable or better than SurvivalGAN, however, they do not seem better than those in [2].\n\n[1] Ashhad M, Henao R. Conditioning on time is all you need for synthetic survival data generation. arXiv preprint arXiv:2405.17333. 2024 May 27.\n[2] Ashhad M, Henao R. Generating Accurate Synthetic Survival Data by Conditioning on Outcomes. InMachine Learning for Healthcare Conference 2025 Oct 7. PMLR."}, "questions": {"value": "- Consider acknowledging TabDDPM [3] in the related work.\n- Is TabDiff as implemented in the experiments equivalent to optimizing (12) with lambda=0? if, not an ablation study will be important to illustrate the benefit of the proposed objective.\n- An ablation study with w=1 vs. (11) is necessary to demonstrate the impact of the proposed weighting scheme on performance.\n\n[3] Kotelnikov A, Baranchuk D, Rubachev I, Babenko A. Tabddpm: Modelling tabular data with diffusion models. InInternational conference on machine learning 2023 Jul 3 (pp. 17564-17579). PMLR."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TBlEb1Ct37", "forum": "HOBJO7w8C2", "replyto": "HOBJO7w8C2", "signatures": ["ICLR.cc/2026/Conference/Submission7636/Reviewer_Ser3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7636/Reviewer_Ser3"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7636/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995161568, "cdate": 1761995161568, "tmdate": 1762919712003, "mdate": 1762919712003, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}