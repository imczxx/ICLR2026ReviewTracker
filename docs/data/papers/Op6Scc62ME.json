{"id": "Op6Scc62ME", "number": 4630, "cdate": 1757730073229, "mdate": 1759898022614, "content": {"title": "Learning Robust Diffusion Models from Imprecise Supervision", "abstract": "Conditional diffusion models have achieved remarkable success in various generative tasks recently, but their training typically relies on large-scale datasets that inevitably contain imprecise information in conditional inputs. Such supervision, often stemming from noisy, ambiguous, or incomplete labels, will cause condition mismatch and degrade generation quality. To address this challenge, we propose $\\textbf{DMIS}$, a unified framework for training robust Diffusion Models from Imprecise Supervision, which is the first systematic study within diffusion models. Our framework is derived from likelihood maximization and decomposes the objective into generative and classification components: the generative component models imprecise-label distributions, while the classification component leverages a diffusion classifier to infer class-posterior probabilities, with its efficiency further improved by an optimized timestep sampling strategy.\nExtensive experiments on diverse forms of imprecise supervision, covering tasks of image generation, weakly supervised learning, and noisy dataset condensation demonstrate that $\\textbf{DMIS}$ consistently produces high-quality and class-discriminative samples. The code package is available at https://anonymous.4open.science/r/ICLR26_DMIS-3452/.", "tldr": "", "keywords": ["Diffusion Model; Weakly Supervised Learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8bc76605bc653c4c840b495db0def80b00dce6dd.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces DMIS (Diffusion Models from Imprecise Supervision) — a unified framework designed to train conditional diffusion models (CDMs) robustly when the supervision data is noisy, ambiguous, or incomplete.\n\nIn real-world datasets, conditional inputs such as labels or text prompts often contain imprecise information (e.g., mislabeled, missing, or uncertain data). This leads to condition mismatch and reduces generation quality. To address this, DMIS formulates the training process as a likelihood maximization problem, treating the true label as a latent variable and decomposing the objective into:\n\n- a generative component, which models the distribution of imprecise labels, and\n\n- a classification component, which uses a diffusion-based classifier to estimate posterior class probabilities efficiently.\n\nTo further improve computational efficiency, the method introduces an optimized timestep sampling strategy, allowing accurate ELBO estimation without redundant computation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper effectively uses a diffusion model to handle generative, discriminative, and condensation tasks under various weak-supervision settings, and presents the framework with clear and consistent notation."}, "weaknesses": {"value": "- **Originality**: The paper covers many tasks, but most of them have already been addressed using diffusion models before. Is there real value in simply combining them into one unified paper? Moreover, Theorem 1 appears to be identical to Theorem 1 in [1], and Proposition 1 seems equivalent to Theorem 3 in [1].\n\n- **No baseline**: There is no baseline shown in Table 1. Why didn’t you compare your method with [1]? Is your method identical to [1]?\n\n- **Limited experimental scope**: Recently, zero-shot tasks using text-conditional diffusion models have shown greater potential and received more attention than those based on class-conditional models. It would be more important to address such tasks using text-to-image (T2I) diffusion models. \n\n[1] (ICLR 24) Label-Noise Robust Diffusion Model."}, "questions": {"value": "What is the distinction between your Theorem 1 and Proposition 1 compared to [1]?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2P73QXdJXq", "forum": "Op6Scc62ME", "replyto": "Op6Scc62ME", "signatures": ["ICLR.cc/2026/Conference/Submission4630/Reviewer_9nKU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4630/Reviewer_9nKU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4630/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761811356976, "cdate": 1761811356976, "tmdate": 1762917478225, "mdate": 1762917478225, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the robustness of diffusion model training under imprecise supervision. Unlike prior works that focus on specific forms of imprecise supervision, they propose a unified framework for robust diffusion learning in such settings. The approach decomposes the likelihood maximization objective into generative and classification components. The generative component trains the diffusion model, while the classification component handles imprecise label classification. The framework is instantiated from three types of imprecise supervision: partial labels, supplementary-unlabeled data, and noisy labels, and evaluated across three benchmark datasets on image generation, weakly supervised classification, and dataset condensation tasks."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* Addressing how to train diffusion models in the presence of incomplete data is an important and meaningful problem.\n\n* Unlike prior works that focus on specific types of imprecise supervision, the paper's proposal of a unified framework represents a valuable contribution."}, "weaknesses": {"value": "* In Section 3.1, Eq. (6) suggests maximizing the joint distribution $p_{\\theta} (X,Z)$. It is unclear why the objective is formulated this way rather than maximizing the marginal distribution $p_{\\theta} (X)$, or the marginal/conditional distributions involving $Y$, such as $p_{\\theta} (X,Y)$ or $p_{\\theta}(X|Y)$. I want to know that the reason that the likelihood of imprecise supervision also be increased. I think that it might be more natural to consider maximizing the conditional likelihood over $Y$.\n\n* In Eq. (7), the objective is decomposed into generative and classification components, where the generative objective appears to correspond to $\\log p_{\\theta} (X|Z)$, as indicated by the subtitle of Section 3.2. However, instead of maximizing this term directly (as in Eq. (8)), the paper proceeds to Eq. (10), which maximizes the conditional likelihood over $Y$. The reasoning behind this transition is unclear. As mentioned above, directly maximizing the conditional likelihood over $Y$ might be conceptually more coherent, so clarification of this logical flow is needed.\n\n* In Section 3.2, Proposition 1 describes the optimal point of the learned score function under the objective in Eq. (10). However, the overall training objective includes an additional classification term, as shown in Eq. (7). Then, it is beneficial to discuss the optimal point of the final objective. A discussion on this one would strengthen the theoretical grounding.\n\n* The methodology in Section 3.2 appears highly similar to that in Na et al. (2024), both in structure and explanation. The mathematical derivations seem almost identical, with only variable substitutions (e.g., replacing $\\tilde{Y}$ with $Z$), and the sequence of Remark, Theorem, and Proposition mirrors that paper closely. Several parts of the text also appear to be paraphrased. Proper attribution and a clear explanation of what is newly contributed beyond that paper are necessary.\n\n* In Eq. (13), it is unclear why $f_{\\theta}$ is not normalized. Also, the explanation for normalized probability provided below the equation is insufficient. The paper only states that it lies on a simplex, but a concrete description of the normalization process is required.\n\n* The notation for $\\tilde{f}_{\\phi}$ in Eqs. (13) and (14) appears to refer to different quantities, yet the same symbol is used, which could cause confusion. Distinguishing them more clearly would improve readability.\n\n* The proposed method requires evaluating the diffusion model for each class during every objective computation, which may significantly increase computational complexity. Section 4 discusses efficiency improvements in the classification evaluation stage by reducing the timesteps. Since timesteps are still sampled during training, a discussion on how to mitigate the per-class computational cost during training is needed.\n\n* The experiments are conducted on three benchmark image datasets, each with 10 classes. It would be helpful to analyze whether the proposed method scales to datasets with larger number of classes (or even infinite classes, i.e., continuous labels). This issue is closely related to the aforementioned computational complexity.\n\n* Experimental comparisons with prior diffusion-based methods specifically designed for different types of imprecise supervision are missing. Including such comparisons, both methodological and empirical, would help clarify the novelty and significance of the proposed framework."}, "questions": {"value": "Please discuss the points in the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cyFBz2oCKF", "forum": "Op6Scc62ME", "replyto": "Op6Scc62ME", "signatures": ["ICLR.cc/2026/Conference/Submission4630/Reviewer_aCun"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4630/Reviewer_aCun"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4630/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761891349708, "cdate": 1761891349708, "tmdate": 1762917477891, "mdate": 1762917477891, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes to **disentangle the generative and discriminative aspects of diffusion models** (through implicit classifiers). The authors claim that doing this helps the network to **better learn under label noise conditions**. The authors also introduce the task of **noise-robust dataset condensation**."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. **Problem Relevance:** As highlighted by the authors, **real data is necessarily noisy**. Being **agnostic to the noise level of the data is key** to making the most out of available datasets.\n\n2. **No Prior Knowledge:** The fact that this method **doesn't require prior knowledge on the data's noise structure** is a significant advantage for real-world application."}, "weaknesses": {"value": "1. **Missing Related Work:** The paper is **missing at least two key works** on training with noisy datasets:\n\n   * \\[1\\] \"Don't drop your samples! Coherence-aware training benefits Conditional diffusion\" (Dufour et al., CVPR 2024)\n\n   * \\[2\\] \"Ambient Diffusion Omni: Training Good Models with Bad Data\" (Daras et al., 2025)\n     The **authors should compare to these methods**. While those methods use prior information (which might give them an advantage), a comparison is necessary, especially since both use reasonable and easy-to-obtain priors.\n\n2. **Numerical Results Not Convincing:** The **quantitative results are not convincing**. Some reported numbers show **almost no improvement over the baseline** (e.g., in Table 1, a FID of 3.33 vs. 3.47 for noisy label supervision). Without **confidence intervals**, these small differences are not meaningful. The method only seems to demonstrate clear benefits in the **partial label supervision setup**.\n\n3. **Only Tested on Synthetic Tasks and Small Datasets:** A major issue is that the paper **claims targeting large scale datasets but only tests on small datasets like CIFAR**. For a class-conditional model, one would **at least expect results on ImageNet 256px**. These small datasets are **prone to overfitting**, making them a poor evaluation setup for claims about robustness and scalability.\n\n4. **Problem Formulation:** **Noisy labels are usually not a significant issue for standard class-conditional generation**. This is perhaps reflected in the authors' decision to **work only on synthetic noise structures**. I could see benefits if the authors where to find real noisy datasets, but it's not the case here\n\n\n5. **Limited Scope (Class-Conditional Only):** The method appears **limited to class-conditional generation**. Currently, **text-conditioned generation is a more prevalent task where noisy labels are a major problem**. The paper **doesn't showcase any real-world use cases** for this, whereas both missing citations \\[1\\] and \\[2\\] demonstrate results for T2I, proving it is feasible. I think if the authors want to have the impact they claim in the abstract they should aim for their method to work in this kind of setup"}, "questions": {"value": "I advise the authors to try and make their method work where uncertain labels are a reality. A simple setup could be semantic segmentation like in [1] since segmentation masks are much more prone to segmentation errors.\nEven finding a real dataset that actually suffers from class conditional noise issues would prove the usefulness of this method. (Maybe very finegrained datasets where images are really similar? It's however not the case of all the datasets in the paper that are \"easy\" to discriminate"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GTzbkMvFPP", "forum": "Op6Scc62ME", "replyto": "Op6Scc62ME", "signatures": ["ICLR.cc/2026/Conference/Submission4630/Reviewer_CtmX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4630/Reviewer_CtmX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4630/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761951180508, "cdate": 1761951180508, "tmdate": 1762917477599, "mdate": 1762917477599, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses training diffusion models under noisy supervision by decomposing the likelihood objective into (1) a generative term modeling data confidence and (2) a classification term estimating clean labels. During sampling, the noisy condition is expressed as a linear combination of the clean label and its posterior, which also improves sampling efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Clear separation between generative modeling and clean-label estimation.\n- Theoretical framing is well motivated.\n- Sampling process is made more efficient via posterior-guided conditioning."}, "weaknesses": {"value": "- Missing comparisons with existing diffusion or image synthesis works; FID scores remain far from SOTA, making it difficult to assess the benefit.\n- Related work is not in the main paper\n- For Task 2 appears to require multiple forward passes slower inference.\n- Experiments rely mainly on synthetic noisy labels rather than real-world imprecise supervision (e.g., text prompts)."}, "questions": {"value": "- The assumption from Bo Han et al. (2021) about overfitting under noise may not hold without explicit regularization is this verified empirically?\n- “Noisy dataset condensation” is introduced but undefined; a clear explanation or reference is needed.\n- The paper mentions ImageNette but seems to use ImageNet"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zL0tKBoGDw", "forum": "Op6Scc62ME", "replyto": "Op6Scc62ME", "signatures": ["ICLR.cc/2026/Conference/Submission4630/Reviewer_MjZ5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4630/Reviewer_MjZ5"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4630/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990713541, "cdate": 1761990713541, "tmdate": 1762917477040, "mdate": 1762917477040, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}