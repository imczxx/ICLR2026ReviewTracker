{"id": "d0QYDET81b", "number": 13585, "cdate": 1758219455090, "mdate": 1759897426430, "content": {"title": "Reasoning on auto-verifiable, scalable, multi-step synthetic tasks", "abstract": "Complex reasoning---central to intelligent behavior---demands capabilities beyond pretrained knowledge in large language models (LLMs). Prevailing efforts to improve LLM reasoning often bootstrap from predefined question--answer pairs, selecting high-quality traces to guide self-improvement, which does not scale due to the need for curated problems and solutions. We address this limitation by introducing VAST: Reasoning on Auto-verifiable, Scalable, multi-step synthetic Tasks. VAST enables scalable improvement through structured task that grow in difficulty and allow algorithmic verification of both final answers and intermediate steps, substantially minimizing costly human annotation. We present two complementary methods that leverage VAST: (1) $\\nu$GRPO, an online approach that constructs rewards from solver outputs and shows generalization to out-of-distribution tasks; and (2) $\\nu$MCTS, a Monte Carlo Tree Search method that derives intermediate rewards from rollout-based solution discovery, thereby enabling self-improvement without human annotation. Together, VAST and these methods provide a practical path to robust, scalable, and verifiable multi-step reasoning in modern LLMs.", "tldr": "", "keywords": ["reasoning", "synthetic tasks", "heuristics solvers", "MCTS", "GRPO"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/196c161335e57c3a610239e017bdf1f87648ebf0.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work studies LLM reasoning on VAST, i.e., Auto-verifiable, Scalable, Multi-step Synthetic Tasks. Through vGRPO and vMCTS, the model could generalize to out-of-domain tasks and self-improve."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "Studies on LLM reasoning from an optimization aspect are less explored."}, "weaknesses": {"value": "1. The writing is hard to follow; providing examples when appropriate would help, e.g., when introducing VAST, what kinds of tasks can be categorized as a VAST. Also, the bullet-style introduction breaks the flow constantly. In Figure 1’s caption, VAST is a framework, but in many other places, VAST refers to auto-verifiable, scalable, multi-step synthetic tasks. Is VAST a method or a task? \n2. Also, figure 1 is very distant from the content; it is rarely mentioned, and it is not self-explanatory.\n3. While many RLVR tasks need human-annotated labels, those tasks are applicable in assisting humans, such as code generation. Synthesizing data or weak supervision is also possible to reduce such costs. VAST could be a nice test-bed for certain tasks, but the argument that “predefined question–answer pairs does not scale due to the need for curated problems and solutions” is weak.\n4.  The math notation is unnecessarily overcomplicated, making the main point even harder to understand. For example, in the definition of an auto-verifiable task, verification efficiency comes from nowhere, and it is also hard to see the necessity of introducing the polynomials p_chk, p_eval. It might be connected to the next “Scalable” part, but it is poorly connected in my opinion.\n5. The novelty is limited, which the main framework builds on GRPO and MCTS — both of them are well studied under the context of LLM reasoning.\n6. In the intro, the authors mentioned the task is programmed with a parameter alpha controlling the task complexity. However, there is no discussion on how this is controlling the task difficulty, nor how the performance changes w.r.t to this alpha.\n7. The authors claim that VAST is scalable, but experiments on scaling such data are missing.\n8. Recent work like Reasoning Gym [1] also explores auto-verifiable tasks with controllable task difficulty, and that covers around 100 tasks. What is the main distinction and novelty?\n\n[1] https://arxiv.org/abs/2505.24760"}, "questions": {"value": "1. In line 178, after “what fits VAST”,  could briefly mention several classic examples instead of leaving all of them in the appendix.\n2. Is there a reason why the related work is placed in Section 4 before the experiment? That also breaks the flow in my opinion.\n3. What is the methodological innovation of this work? Both GRPO and MCTS are well explored in the reasoning community, so I wonder what the main novelty is besides using these methods on VAST.\n4. How are VAST samples generated?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "ajNxrOHcGM", "forum": "d0QYDET81b", "replyto": "d0QYDET81b", "signatures": ["ICLR.cc/2026/Conference/Submission13585/Reviewer_sVMJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13585/Reviewer_sVMJ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13585/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761338035493, "cdate": 1761338035493, "tmdate": 1762924176600, "mdate": 1762924176600, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents VAST: a set of auto-verifiable reasoning-oriented synthetic tasks with symbolic solvers available to assess correctness of the reasoning and intermediate steps. The authors also show that these tasks can be used with online and offline RL methods like GRPO and MCTS. Lastly, the authors show that this training boosts performance other reasoning tasks of interest that require math abilities or 2D spatial reasoning."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The paper shows generalization from synthetic tasks to mathematical reasoning and 2D spatial reasoning.\n- For the most part, the writing is easy to follow and the method is easy to understand"}, "weaknesses": {"value": "- The paper does not meaningfully compare to other relevant papers. Apart from the transfer from synthetic planning tasks to math and 2D spatial reasoning, improving the ability of language models at these planning or search oriented tasks is well studied, including past iterations of ICLR, see few examples below and does a poor job of acknowledging these :\n     - https://arxiv.org/abs/2404.03683\n     - https://arxiv.org/abs/2407.14414\n     - https://arxiv.org/abs/2402.14083\n     - https://arxiv.org/abs/2402.01817, etc.\n- If authors believe that process rewarding is a significant contribution to their method or work (which is possible for other planning tasks too), then they do not engage in prior works suggesting that process rewards are not much more useful than outcome rewards (https://arxiv.org/abs/2402.10963, https://arxiv.org/abs/2403.04642), it also does not ablate training on some other tasks and if they yield more transfer to other reasoning tasks. Furthermore, the authors could use other RL methods like PPO which rely more on process rewards than GRPO."}, "questions": {"value": "In addition to previous points raised, I would personally get rid the paragraph title in the introduction and expand on the related work."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "N84c4V3m8T", "forum": "d0QYDET81b", "replyto": "d0QYDET81b", "signatures": ["ICLR.cc/2026/Conference/Submission13585/Reviewer_U7vw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13585/Reviewer_U7vw"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13585/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762118153852, "cdate": 1762118153852, "tmdate": 1762924176337, "mdate": 1762924176337, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces VAST, a framework for generating synthetic tasks that are Auto-verifiable, Scalable, and Multi-step，providing tasks with algorithmic verifiers (checkers and evaluators), decoupling solving difficulty from verification cost. The paper proposes two complementary methods, $\\nu$GRPO and $\\nu$MCTS, to train LLMs using these tasks."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "VAST introduces a novel optimization perspective by formalizing a task generator where the solving complexity (e.g., exponential search space) is **decoupled** from the low, polynomial verification cost (via $p\\_{chk}$ and $p\\_{eval}$). This represents a valuable direction for scaling LLM reasoning without expensive human annotation."}, "weaknesses": {"value": "1.\tThe paper is hard to follow. To make the VAST method more accessible, the authors should consider providing concrete VAST task examples and potentially VAST framework pseudocode in the main body. Furthermore, the discussion of the VAST framework in Figure 1 is vague and misleading, incorrectly emphasizing $\\nu$GRPO and $\\nu$MCTS over the framework itself.\n2.\tThe experiments fail to demonstrate the specific value of VAST. They show that $\\nu$MCTS (self-training) works better than a base model, but not that training on VAST is superior to training on existing synthetic benchmarks using the same algorithms. The value of generating VAST data is not empirically proven.\n3.\tThe paper's core motivation is to address the scalability bottleneck inherent in reasoning training methods that rely on costly, human-curated problem-solution pairs (referring to lines 12-15).However, the paper fails to contextualize this claim by discussing or comparing its $\\nu$MCTS self-improvement pipeline (e.g., $\\nu$MCTS on VAST) against established unsupervised self-training methods (e.g., PFPO [1], EMPO [2], TTRL [3]) that also do not require human-annotated (question, answer) pairs and thus address the same supervision bottleneck. This lack of comparison prevents a clear assessment of VAST's methodological necessity or superiority.\n4.\tThe central claim of Scalability relies on the theoretical parameter $\\alpha$ and the \"decoupling\" concept (lines 51-53). A major deficiency is the paper's failure to explicitly define the relationship between this theoretical scaling parameter $\\alpha$ and the discrete experimental difficulty settings, denoted as \"Level 1-4,\" in the main text.\n\n[1] Jiao F, Guo G, Zhang X, et al. Preference optimization for reasoning with pseudo feedback[J]. arXiv preprint arXiv:2411.16345, 2024.\n\n[2] Zhang Q, Wu H, Zhang C, et al. Right question is already half the answer: Fully unsupervised llm reasoning incentivization[J]. arXiv preprint arXiv:2504.05812, 2025.\n\n[3] Zuo Y, Zhang K, Sheng L, et al. Ttrl: Test-time reinforcement learning[J]. arXiv preprint arXiv:2504.16084, 2025."}, "questions": {"value": "Please see the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Lr1d8PLdeG", "forum": "d0QYDET81b", "replyto": "d0QYDET81b", "signatures": ["ICLR.cc/2026/Conference/Submission13585/Reviewer_RD9h"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13585/Reviewer_RD9h"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13585/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762156974706, "cdate": 1762156974706, "tmdate": 1762924175884, "mdate": 1762924175884, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose VAST, a framework for reasoning on auto-verifiable, scalable, multi-step synthetic tasks. Using this framework, they programmatically generate synthetic tasks that consist of a feasibility checker and an outcome evaluator. The authors then train on these tasks using either an online method -- specifically a GRPO variant or an offline algorithm that does rejection fine-tuning on searched trajectories with MCTS. Most of the experiments are limited to these synthetic tasks with some attempts to transfer to real math benchmarks that lead to rather weak results."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "* VAST is a framework for synthetic reasoning data generation and training that aims to mitigate the reliance on human-annotated reasoning benchmarks."}, "weaknesses": {"value": "* The experimental section of the paper is extremely weak. The only noteworthy experiments seem to be those in Table 2 in which the authors test their model for generalization to real math tasks. Even then, the presentation of these experiments and the results themselves are quite weak. First, Qwen-2.5-7B shows a 7% drop in performance. Second, it is unclear why this main table reports pass@8 instead of pass@1 and while there is a pointer to appendix, I am not sure which table to look at and what conclusions to draw from it (more on the readability of the paper below). Third, AIME benchmarks are rather small and the authors should clearly specify how many seeds they used. Fourth and most importantly, it does not tell much about the usefulness of the framework -- experiments are with older qwen-2.5 models on only 3 benchmarks, only pertaining to math.\n\n* I had a hard time reading the paper. Things that in my opinion should be central to understanding the paper like describing the synthetic tasks are all moved to appendix. The main text does not even talk about what a typical task looks like. The main paper also lacks sufficient details of the experimental setup and how this work compares to past works on synthetic data. The related work is a small paragraph that does not comment on the contributions of this work beyond what is already present. Instead most of the paper is spent on formalizing notations (some being quite obvious). This is distracting, especially given the weak nature of the experiments. I sincerely hope the authors improve the readability of the paper."}, "questions": {"value": "Please refer to my weakness above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Jpd9RIUZSg", "forum": "d0QYDET81b", "replyto": "d0QYDET81b", "signatures": ["ICLR.cc/2026/Conference/Submission13585/Reviewer_nHKh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13585/Reviewer_nHKh"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13585/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762767352686, "cdate": 1762767352686, "tmdate": 1762924175566, "mdate": 1762924175566, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}