{"id": "vqBatdoexa", "number": 10015, "cdate": 1758156397901, "mdate": 1759897680745, "content": {"title": "Finding the Cracks: Improving LLMs Reasoning with Paraphrastic Probing and Consistency Verification", "abstract": "Large language models (LLMs) have demonstrated impressive performance across a variety of reasoning tasks in domains such as mathematics, coding, and planning, particularly when guided by chain-of-thought prompting to elicit intermediate reasoning steps. However, their problem-solving ability often declines on more complex tasks due to hallucinations and the accumulation of errors within these intermediate steps. Recent work has introduced the notion of critical tokens—tokens in the reasoning process that exert significant influence on subsequent steps. Prior empirical studies suggest that replacing critical tokens can refine reasoning trajectories and lead to correct answers. Nonetheless, reliably identifying and exploiting critical tokens to enhance LLM reasoning remains challenging. To address this, we propose the Paraphrastic Probing and Consistency Verification (PPCV) framework, which leverages critical tokens to improve reasoning performance. PPCV operates in two stages. In the first stage, we roll out an initial reasoning path from the original question and then concatenate paraphrased versions of the question with this reasoning path. Feeding these inputs into the LLM yields token-level logits, from which we identify critical tokens based on mismatches between the predicted top-1 token and the expected token in the reasoning path. A criterion is employed to confirm the final critical token. In the second stage, we substitute critical tokens with candidate alternatives and roll out new reasoning paths for both the original and paraphrased questions. The final answer is determined by checking the consistency of outputs across these parallel reasoning processes. We evaluate PPCV on mainstream LLMs, including Llama-3.1-8B-Instruct, Mistral-7B-Instruct-v0.2 and Qwen3-32B, across multiple benchmarks covering mathematics and logical reasoning. Extensive experiments demonstrate that PPCV substantially enhances the reasoning performance of LLMs compared to baseline methods.", "tldr": "", "keywords": ["large language model", "reasoning", "critical token"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/334a260c545f6bd8cd5aa38cbc24f35981cf49f9.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a new inference time optimization method: paraphrastic probing and consistency verification. The main idea is (1) identify the critical tokens (tokens that may trigger very different reasoning paths) by running inference on paraphrased inputs + original response; (2) generate new rollouts by replacing the critical tokens in the original response and finally do a majority vote on all responses.\nThe empirical results show that the proposed method outperforms previous inference-time scaling methods such as self-consistency, across reasoning-intensive tasks such as Math and ARC-challenge."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is well-written. The method is clearly explained and easy to follow.\n- The experimental results and ablation supports most of the paper claims, and shows the importance of both the critical tokens and the paraphrased consistency."}, "weaknesses": {"value": "- One important baseline is still missing: simply perform majority voting but on the paraphrased questions (be sure to keep the total number instances the same as the PPCV method) => this will show that whether the rollout based on critical tokens really helps. Although the authors provide the comparison with random tokens, it does not make sense, since replacing random tokens may artificially shift the model's distribution too much and hurt it's original performance.\n- The computational analysis is too brief and lacks important details: I am suspicious about the correctness of the inference time figure: in most datasets, PPCV uses only about 2x the inference time than simple CoT, this does not seem to be possible. Becuase the computation overhead of PPCV comes from (1) N forward pass on q1...qN with the orignal question; (2) K * N generation sequences for each critical token and each question variant. Particularly, suppose the critical token is on average in the middle of the response, the stage (2) should add approximately 0.5 * K * N times of the original CoT generation time (regardless of the prefilling time)."}, "questions": {"value": "- The fonts in most figures are too small, e.g., Figure 3,4,5; would be good to enlarge"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "k1TDdLFhqf", "forum": "vqBatdoexa", "replyto": "vqBatdoexa", "signatures": ["ICLR.cc/2026/Conference/Submission10015/Reviewer_s9UP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10015/Reviewer_s9UP"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10015/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761190276353, "cdate": 1761190276353, "tmdate": 1762921431097, "mdate": 1762921431097, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to improve the reasoning performance of LLMs by proposing a Paraphrastic Probing and Consistency Verification (PPCV) framework. Specifically, PPCV consists of two stages: 1) roll out the initial reasoning path from the original question, then concatenate paraphrased questions with the reasoning path, which is fed into the LLM to identify the critical tokens; 2) leverage the extracted critical tokens to refine the initial reasoning path via a self-consistency mechanism. Experiments on multiple mathematics and logical reasoning benchmarks show that PPCV outperforms the vanilla CoT and some baseline decoding methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "-\tThe paper is overall well-written and easy to follow.\n-\tThe idea of locating the critical tokens makes sense, and does not rely on external models.\n-\tExperimental results show that PPCV outperforms the other counterparts by a clear margin."}, "weaknesses": {"value": "-\tMy main concern is the efficiency of the proposed framework. If I understand correctly, PPCV requires multiple passes of LLMs, e.g., paraphrasing the question, obtaining the initial reasoning paths, obtaining the critical tokens by feeding into multiple paraphrased questions, and generating a group of new trajectories. The total framework is complex and would lead to much inference latency. The comparison of the inference time in Figure 7 is also confusing. For example, in the case of the SVAMP test set, PPCV only brings a slight inference latency against the vanilla CoT method, which is obviously counterintuitive. The authors should provide more explanation.\n-\tThe technical contribution is limited. In my opinion, PPCV does not propose new technologies, but uses existing methods and ideas to solve a relatively new problem.\n-\tIn the ablation study, the authors do not analyze the influence of paraphrased questions. For example, remove the paraphrase processes in PPCV and explore the performance changes.\n-\tAlgorithm 1 is a little hard to paraphrase. It will be better to improve the presentation carefully."}, "questions": {"value": "See the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DhCtxDgr9d", "forum": "vqBatdoexa", "replyto": "vqBatdoexa", "signatures": ["ICLR.cc/2026/Conference/Submission10015/Reviewer_9jC6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10015/Reviewer_9jC6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10015/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761467335159, "cdate": 1761467335159, "tmdate": 1762921430731, "mdate": 1762921430731, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduced PPCV, a framework that leverages critical tokens to improve reasoning performance. First, the framework roll out an initial reasoning path from the original question and then concatenate paraphrased versions of the question with this reasoning path. Everything is passed to the LLM to get token-level logits to identify critical tokens based on mismatches between the predicted top-1 token and the expected token in the reasoning path. In the second stage, critical tokens are substituted with candidate alternatives and the framework rolls out new reasoning paths for both the original and paraphrased questions. The final answer is determined by checking the consistency of outputs across these parallel reasoning processes.\n\nFirst, the authors conduct an empirical analysis of the effectiveness of critical tokens: identify the one critical token, replace it. Compare performance with self-consistency. Indeed, critical token replacements is more beneficial.\n\nIn terms of methodology, an LLM is first prompted to paraphrase a problem multiple times while keeping all numerical values etc the same. Then a reasoning path is computed with the original question. The reasoning path is concatenated to each paraphrased version. Then the top-1 log-probs are computed for each token. The first one that does not match the the top-1 on the original problem is considered critical.\nTo refine the original reasoning path with alternative tokens, an LLM is prompted from the beginning until the critical token. A consistency score is computed on all alternatives.\n\nRegarding the experiments, Llama 8B, Mistral 7B, and Qwen 3 32b are used on multiple reasoning datasets. Baseline consists of CoT, ToT, guided decoding, predictive decoding and phi-decoding. Each dataset is paraphrased 3-5 times. PPVC seems to lead to the highest performance on 7B thinking models and Qwen3 32B. I would encourage the authors to compare higher reasoning models and use pass@k. The ablations are well done. Finally, I'm a bit disappointed by the computational cost analysis with Figure 7. There is no confidence interval, variation, and it is hard to weight the trade-off between performance and efficiency. Could you provide a Pareto plot with performance vs throughput and include confidence interval?"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Interesting idea.\n- Good ablation analysis."}, "weaknesses": {"value": "- No analysis with larger reasoning models.\n- No use of pass@k.\n- Computational cost analysis is insufficient."}, "questions": {"value": "- Could you compare performance on larger reasoning models?\n- Could you report pass@k for Table1 and Table2 (k>= 4)?\n- In Table 3&ç, please add the original performance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ndH2hEckaF", "forum": "vqBatdoexa", "replyto": "vqBatdoexa", "signatures": ["ICLR.cc/2026/Conference/Submission10015/Reviewer_MkiR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10015/Reviewer_MkiR"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10015/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762012269149, "cdate": 1762012269149, "tmdate": 1762921430261, "mdate": 1762921430261, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes PPCV (Paraphrastic Probing and Consistency Verification), a two-stage framework for improving LLM reasoning by identifying and leveraging \"critical tokens\" - tokens that significantly influence subsequent reasoning steps. The method first uses paraphrased versions of questions to identify critical tokens where the model's predictions diverge, then substitutes these tokens with alternatives and uses consistency to select the final answer."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Novel approaches. The method of identifying critical tokens is sound and interesting. The method does not require heavy token-level annotation to get token-level classification.\n* Results are promising. Improvements are observed consistently across 5 different datasets and 2 models."}, "weaknesses": {"value": "My main concern is that the methods do not seem generalizable.\n\n* First, it is hard to control the quality of the paraphrased questions. Although authors design careful instructions to ensure numbers are not changed, we do not have an evaluation metric to control.\n\n* Second, the methods can only be applied to greedy decoding; otherwise, the current method will tend to select non-top-1 tokens as the critical token.\n\n* Third, the current methods work well for one critical token but is hard to generalize to multiple critical tokens."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AcFGmdnDkt", "forum": "vqBatdoexa", "replyto": "vqBatdoexa", "signatures": ["ICLR.cc/2026/Conference/Submission10015/Reviewer_bEsz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10015/Reviewer_bEsz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10015/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762154803129, "cdate": 1762154803129, "tmdate": 1762921429546, "mdate": 1762921429546, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}