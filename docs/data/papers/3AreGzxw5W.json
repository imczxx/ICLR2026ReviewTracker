{"id": "3AreGzxw5W", "number": 8544, "cdate": 1758090441533, "mdate": 1763360086350, "content": {"title": "Ctrl-Z Sampling: Diffusion Sampling with Controlled Random Zigzag Explorations", "abstract": "Diffusion models have shown strong performance in conditional generation by progressively denoising Gaussian samples toward a target data distribution. This denoising process can be interpreted as a form of hill climbing in a learned representation space, where the model iteratively refines a sample toward regions of lower noise and higher quality.. However, this learned climbing often converges to local optima with plausible but suboptimal generations due to latent space complexity and suboptimal initialization. While prior efforts often strengthen guidance signals or introduce fixed exploration strategies to address this, they exhibit limited capacity to escape steep local maxima. In contrast, we propose Controlled Random Zigzag Sampling (Ctrl-Z Sampling), a novel sampling strategy that adaptively detects and escapes such traps through controlled exploration. In each diffusion step, we monitor the trajectory of quality-scores of predictions over denoising steps, given a reward model that serves as a surrogate for the underlying sample quality, and identify plateaus as local optima along this trajectory. Upon such detection, we inject noise and revert to a previous, noisier state to escape the current plateau. The reward model then evaluates candidate trajectories, accepting only those that offer improvement, otherwise scheming progressively deeper explorations when nearby alternatives fail. This controlled zigzag process allows dynamic alternation between forward refinement and backward exploration, enhancing both alignment and visual quality in the generated outputs. The proposed method is model-agnostic and also compatible with existing diffusion frameworks. Experimental results show that Ctrl-Z Sampling consistently improves generation quality across different NFE budgets compared to the original sampler.", "tldr": "", "keywords": ["Diffusion Models", "Sampling Strategies", "Inference-Time Technique"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5c01996e64a82aaf92d6b81d3e7f408165b1703d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a technique called \"Control Z Sampling,\" which reframes the sampling process in conditional diffusion models as a form of hill climbing in a reward space. When the sampling process stagnates at a local optimum according to a reward model (e.g., ImageReward), the algorithm injects controlled noise and reverts to a noisier latent state to explore alternative trajectories. This process creates a backward-forward or \"zigzag\" exploration path intended to escape local optima. The method is presented as a model-agnostic plugin compatible with existing diffusion frameworks, requiring no retraining. Experiments show modest improvements in evaluation metrics compared to baselines. However, these gains come at a significant computational cost, requiring approximately 7.72 times the neural function evaluations (NFEs) on average while also requiring evaluation of a second reward model."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The paper is well-written and mostly clear in its presentation.\n\n* The idea of conceptualizing conditional diffusion sampling as a hill-climbing problem is interesting.\n\n* The process of combining simulated annealing-like adaptive noise re-injection with a best-first search-like method to explore alternative trajectories is a reasonable blend of explore and exploit techniques.\n\n* The quantitative and qualitative results clearly show that the method is having an effect, with moderate gains in performance metrics."}, "weaknesses": {"value": "* The most significant weakness is the substantial computational cost, which averages roughly 7.72 times the neural function evaluations (NFEs) of the original process. In my opinion, this massive increase in energy and clock time makes the method practically unusable for what are only modest gains in output quality. Other hyperparameter choices for the algorithm would make this NFE multiplier even greater.\n\n* Following up on the above point, the technique currently feels like a brute-force example or the first step in a research process, where one demonstrates how a search-based method *could* work but is then expected to introduce an efficient implementation to contrast with it. The paper has its heart in the right place but is essentially missing the efficient algorithm that would make the core concept viable.\n\n* The fundamental re-framing of diffusion sampling as \"search\" or \"hill climbing\" is interesting but debatable, as diffusion models are fundamentally about sampling from a distribution, not necessarily about moving toward a single global optimum. A method that is too effective at achieving a global maximum could actually cause mode collapse by severely reducing output diversity.\n\n* Related to the above point, the authors seem to be performing search in \"reward space,\" but the structure of the diffusion sampling problem can easily lead a reader to think that the search is being performed in *probability* space. This distinction is not as clear as it could be in the text or Figure 1. Indeed, one comes away with opposite impressions from reading the abstract (\"a form of hill climbing ... where the model iteratively refines a sample toward regions of higher **probability**\") versus Section 4 (\"as a hill-climbing process ... where each denoising step moves the sample toward regions of higher **reward**\") [emphasis mine].\n\n* The method primarily uses the ImageReward model, which is trained on clean images, to evaluate states at intermediate steps of the denoising process. This likely places the reward model's input out-of-distribution, which may impact the reliability of the guidance signal.\n\n* The evaluation seems limited to latent space sampling and does not include testing in pixel space for computational reasons. This further limits the practical applicability of the work, as the field is increasingly moving back toward pixel-space diffusion.\n\n* Some relevant work (e.g. Direct Noise Optimization [1], Diffusion Tree Sampling [2]) should be discussed in the context of the authors' method and ideally compared to if possible.\n\n[1] Tang, et al (2024). Inference-Time Alignment of Diffusion Models with Direct Noise Optimization. \n\n[2] Jain, et al. (2025). Diffusion Tree Sampling: Scalable inference-time alignment of diffusion models."}, "questions": {"value": "1. The authors use a deterministic sampling process. Given that a significant amount of the benefits (exploring alternative paths, breaking out of local optima) could be inherently achieved more cheaply via stochastic sampling methods (Langevin Monte Carlo, DDPM), why was a comparison to or an evaluation on an established stochastic sampling process not included?\n\n2. I would like to see the authors respond to the issues raised in the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No concerns."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PQmXs9UXt6", "forum": "3AreGzxw5W", "replyto": "3AreGzxw5W", "signatures": ["ICLR.cc/2026/Conference/Submission8544/Reviewer_rfRj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8544/Reviewer_rfRj"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8544/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761398293368, "cdate": 1761398293368, "tmdate": 1762920400594, "mdate": 1762920400594, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Official Comment: Ctrl-Z Sampling as a scalable inference-time method"}, "comment": {"value": "We thank all reviewers for their careful reading and constructive feedback. We would like to clarify a central aspect of the contribution that may not have been sufficiently emphasized in the current draft.\n\n\nSeveral critiques focus on the *absolute* improvement achieved at around $7\\text{–}8\\times$ the NFEs of standard DDIM, interpreting our method primarily as a fixed-cost sampler with limited gains. Our intention, however, is to position Ctrl-Z Sampling as a low-cost **inference-time scaling mechanism** for diffusion models, rather than optimizing a single fixed-cost sampler. Inference-time scaling, which spends more test-time compute to systematically improve performance, has become a key paradigm in NLP and LLMs, where deeper decoding, reranking, and test-time optimization reliably trade extra compute for better outputs. In contrast, diffusion models have seen far fewer principled approaches in this direction; most prior efforts focus on architecture or training-scale changes to improve diffusion model, or more efficient sampling strategies during inference, rather than exposing controllable test-time scaling side of diffusion, aside from increasing sampling steps (which is of limited effectiveness).\n\nCtrl-Z sampling exposes explicit controls over exploration depth $d_{\\max}$, width $N$, and the exploration window $\\lambda$, allowing users to trade off additional test-time compute for more performance gains, in line with recent work on inference/test-time scaling in diffusion and language models (Ma et al., 2025; Singhal et al., 2025; He et al., 2025; Zhang et al., 2025). However, these works primarily characterize scaling laws under extremely large NFE budgets (e.g., $10^{2}$–$10^{5}$), whereas our contribution is a scalable sampler that remains effective under moderate, practical test-time compute.\n\nIn the main tables we chose a mid-range configuration (≈$7\\text{–}9\\times$ NFEs) so that Ctrl-Z can be fairly compared to SOP under similar compute budgets. However, the method is not tied to this single operating point. As shown in our ablations (Fig. 2 and Table 6), increasing exploration depth and/or the number of candidates yields consistent improvements across alignment metrics (HPSv2, PickScore, ImageReward), with AES being naturally less sensitive because it does not directly assess conditioning alignment. In other words, Ctrl-Z defines a *family* of samplers along a compute–quality curve, rather than a single fixed sampler. \n\nBy contrast, the baseline “self-refinement” methods we compare against (Resampling and Z-Sampling) offer only shallow, fixed-strength perturbations. In our experiments, simply stacking more resampling or zigzag iterations does not scale their performance with NFEs and can even degrade quality. SOP is the most direct inference-time scaling baseline; under comparable NFE budgets, Ctrl-Z matches or outperforms SOP on human-aligned metrics while using fewer or similar NFEs, and additionally benefits from *depth* as an extra scaling axis rather than relying solely on wider local search.\n\nTo avoid this misunderstanding, we revise the title to explicitly frame Ctrl-Z Sampling as an scalable inference-time method and to make the compute–quality trade-off and scaling behavior more prominent in the exposition. We also provide how Ctrl-Z and SOP sampling method performs with lower inference budget similar to Resampling and Z-Sampling.\n\n\n\n\n### **References**\nNanye Ma, Shangyuan Tong, Haolin Jia, Hexiang Hu, Yu-Chuan Su, Mingda Zhang, Xuan Yang, Yandong Li, Tommi Jaakkola, Xuhui Jia, et al. Inference-time scaling for diffusion models beyond scaling denoising steps. arXiv preprint arXiv:2501.09732, 2025.\n\n\nRaghav Singhal, Zachary Horvitz, Ryan Teehan, Mengye Ren, Zhou Yu, Kathleen McKeown, and Rajesh Ranganath. A general framework for inference-time scaling and steering of diffusion models. In International Conference on Machine Learning (ICML), 2025.\n\n\nHaoran He, Jiajun Liang, Xintao Wang, Pengfei Wan, Di Zhang, Kun Gai, and Ling Pan. Scaling image and video generation via test-time evolutionary search. arXiv preprint arXiv:2505.17618, 2025.\n\n\nXiangcheng Zhang, Haowei Lin, Haotian Ye, James Zou, Jianzhu Ma, Yitao Liang, and Yilun Du. Inference-time scaling of diffusion models through classical search. arXiv preprint arXiv:2505.23614, 2025."}}, "id": "Sy3Qem7Vjk", "forum": "3AreGzxw5W", "replyto": "3AreGzxw5W", "signatures": ["ICLR.cc/2026/Conference/Submission8544/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8544/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8544/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763358822223, "cdate": 1763358822223, "tmdate": 1763363837145, "mdate": 1763363837145, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Ctrl-Z, a novel inference strategy for diffusion models to address semantic misalignment caused by convergence to local optima during conditional generation. The method leverages a reward-guided, controlled zigzag exploration process, dynamically alternating between forward refinement and backward steps with adaptive noise injection to escape optimization plateaus. Some experiments are provided to validate the effectiveness of the method."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "* The approach is model-agnostic and substantially improves semantic alignment on text-to-image benchmarks, demonstrating a practical and efficient balance between exploration and computational cost.\n* The writing and results are clear to the readers.\n* Thorough ablation studies are conducted to show the robustness of the method."}, "weaknesses": {"value": "* In the abstract, the authors state that denoising is analogous to climbing a probability hill, and that the process may get stuck at some local maxima. Why do you consider these local maxima suboptimal for generation? Could you visualize the hill and illustrate the imperfect samples corresponding to these local optima? My understanding is that if the score function has learned a distribution with local optimal points, then generating samples around these points is reasonable, since they belong to the true distribution. In that case, I do not quite understand the motivation for manually pushing the denoising process away from these local maxima.\n* In Lines 43–46, you state that semantic misalignment and global inconsistency stem from local optima. Could you provide some evidence to support this claim?\n* The computational cost increases to 7.72 times that of the original diffusion generation process, imposing a significant computational burden in industrial or commercial settings.\n* You use ImageReward as the reward model during inference and also as the evaluation metric. This result is not convincing, since the evaluation metric is exactly what your method optimizes during generation. It is therefore expected that your method performs well on this metric. However, does this optimization degrade performance on other metrics? In addition, you do not report the FID score, which is the most commonly used metric in image generation. Although FID has some known limitations, I did not see any justification from the authors for omitting it."}, "questions": {"value": "Please refer to Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5xT5Nt4v8h", "forum": "3AreGzxw5W", "replyto": "3AreGzxw5W", "signatures": ["ICLR.cc/2026/Conference/Submission8544/Reviewer_J3qN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8544/Reviewer_J3qN"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8544/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927777893, "cdate": 1761927777893, "tmdate": 1762920400119, "mdate": 1762920400119, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose Ctrl-Z Sampling, a sampling strategy for diffusion models. The method targets a key limitation of standard denoising processes, which the authors liken to hill climbing: the tendency to become trapped in local optima. This can yield results that are semantically misaligned with the given condition or that lack global consistency. The core idea is an adaptive, reward-guided exploration mechanism. During sampling, a reward model monitors generation quality. If it detects optimization stagnation (suggesting a local trap), the method injects noise to roll back to a previous, noisier state. From that state, the reward model evaluates multiple candidate trajectories and selects a path that shows improvement. The rollback depth can be increased adaptively when shallow exploration fails. The authors report that this controlled “zigzag” exploration improves both generation quality and conditional alignment."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper provides a clear and intuitive characterization of the problem, framing diffusion sampling as \"latent space hill-climbing.\" This analogy effectively explains why samplers get stuck in local optima, leading to semantic mismatches or global inconsistencies. This narrative provides a unified motivational framework that helps readers grasp the necessity of the proposed strategy.\n- The primary innovation lies in its feedback-controlled mechanism that determines when to explore and how deep the exploration should be. Unlike methods with fixed perturbation frequencies or amplitudes, Ctrl-Z Sampling uses reward stagnation as a trigger for exploration. It then progressively deepens the rollback (via DDIM-based noise injection) until a superior candidate trajectory is identified. This creates a controlled \"forward-backward-forward\" zigzag path."}, "weaknesses": {"value": "- A core component of the method is the use of a reward model to detect stagnation (\"Local Maxima Detection\"). However, the paper does not propose a new reward model specifically designed or targeted for this task. Furthermore, the paper lacks discussion on several critical aspects of this component: 1) The stability and noise sensitivity of the chosen reward model. 2) The potential impact of reward misjudgments (false positives/negatives for stagnation) on the exploration path. 3) Any systematic biases in generation quality that might be introduced by the specific choice of reward model.\n- The paper relies heavily on the \"hill-climbing + rollback\" intuition but provides no theoretical analysis to support it. Key guarantees are missing, such as convergence analysis, proof of escape from local optima, or bounds on the expected improvement. For instance, the paper does not provide any theoretical analysis of the relationship between the probability of successfully escaping a local optimum and the method's hyperparameters (e.g., the depth budget, the threshold $\\delta$, the window $\\lambda$).\n- Although Ctrl-Z claims \"controlled\" exploration, its compute remains high: average NFEs are 7.72$\\times$ (SD-2.1) and 8.79$\\times$ (Hy-DiT) versus SOP’s 9.00$\\times$, while quality gains over SOP are modest/inconsistent."}, "questions": {"value": "Regarding the reward stagnation criterion, have you considered replacing the fixed threshold $\\delta$ with a more flexible approach such as a dynamic or schedule-based threshold, a relative improvement test, or an adaptive gate based on reward variance or uncertainty? In regions where the reward values plateau at high scores, a constant $\\delta$ might incorrectly interpret small but meaningful improvements as stagnation and trigger unnecessary rollbacks. How do you address this potential issue or prevent such misclassifications?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Fs7UqOmrmA", "forum": "3AreGzxw5W", "replyto": "3AreGzxw5W", "signatures": ["ICLR.cc/2026/Conference/Submission8544/Reviewer_1wxx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8544/Reviewer_1wxx"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8544/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761983533729, "cdate": 1761983533729, "tmdate": 1762920399642, "mdate": 1762920399642, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Ctrl-Z sampling, a sampling method for diffusion models designed to improve output quality by escaping local optima during the denoising process. The approach evaluates the generated state after each denoising step to determine whether it is a local optimum; if so, it injects an adaptive amount of noise to revert the process to a noisier state. This backward exploration mechanism is intended to leads to better text alignment and enhanced visual quality, while costing approximately 7.72× more function evaluations (NFEs) compared to standard diffusion sampling. The effectiveness of the proposed method is demonstrated through experiments on standard text-to-image benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* Interesting problem: The paper addresses an interesting and relevant issue in diffusion models — the tendency of sampling trajectories to stagnate or over-converge — which could be impactful. \n* Extensive empirical evaluation: The paper includes a comprehensive set of experiments across multiple text-to-image benchmarks, providing both quantitative metrics and qualitative visualizations.\n* Thoroughness and effort: The work is detailed and carefully executed, with significant experimental effort and a long appendix that documents settings, ablations, and implementation details."}, "weaknesses": {"value": "- The problem studied in this paper is not well explained or sufficiently justified. From the outset, in both the abstract and introduction, the authors describe how the denoising process converges to local optima. For example, lines 43–46 state:\n\n      “Despite their strong generative performance, diffusion models often exhibit semantic misalignment or global inconsistency in conditional generation. These issues arise when the denoising process converges to local optima that prioritize local visual plausibility over semantic relevance or structural coherence.”\n\n    The main concern is that it is unclear what the term *local optima* means in the context of diffusion models, as no explicit optimization occurs during inference. The authors could have more effectively explained and motivated this concept by framing it as follows: the denoising process is an iterative refinement procedure in which samples may occasionally collapse to suboptimal regions of the data manifold (for example, producing blurry or incomplete images). This underlying phenomenon of sampling stagnation or collapse could then be described as becoming stuck in a local optimum.\n\n\n- The procedure for detecting local optima during sampling is not well justified. The paper lacks an intuitive explanation or illustrative experiment demonstrating why the criterion defined in Equation (5) effectively identifies states corresponding to local optima.\n\n- The experimental results are not particularly convincing. The quantitative improvements over the baselines, especially on the SOP dataset, are marginal and do not clearly demonstrate a significant advantage. While the qualitative examples in Figure 3 more effectively illustrate the benefits of Ctrl-Z sampling, the additional qualitative results provided in the supplementary material appear less compelling and more comparable to benchmarks. \n\n- Considering the quality of the results, I am concerned that the approximately 7.72× increase in NFEs may not justify the relatively modest gains reported in the experiments."}, "questions": {"value": "1. The definition of $\\Phi$ provided in line 139 and equation 1 conflict as the output of $\\Phi$ is $x_0$.\n2. Line 153, it's better if \"clean image\" was replaced with \"clean sample\" as image was never used up to this point.\n3. Line 157: Why is the sample estimate $\\hat{x_0}$ a good proxy for the final clean sample $x_0$?\n4. Line 161: The concept of \"inversion\" is not a very popular concept. It would be useful to add an explicit description of inversion by something as short as \"...inversion (re-noising)...\".\n5. Line 181: \"forward denoising\" is probably incorrect, right? In the forward process, noise is added and in the backward, noise is removed.\n6. Is the \"Resampling\" method discussed in Figure 1 the same as the stochastic SDE sampler?\n7. Line 210: \"Zigzag Sampling takes a backward step along the direction of un-\nconditional generation, alternating between conditional and unconditional denoising to better inject\nconditioning signals.\" --> what does conditioning refer to here? condition on what exactly?\n8. Line 223: It would be beneficial to clarify what is meant by \"latent trajectory\" as it's not a standard term used in the diffusion community.\n9. Why does the criteria of equation 5 make sense?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LYAABiblor", "forum": "3AreGzxw5W", "replyto": "3AreGzxw5W", "signatures": ["ICLR.cc/2026/Conference/Submission8544/Reviewer_Lfgi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8544/Reviewer_Lfgi"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8544/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762191560570, "cdate": 1762191560570, "tmdate": 1762920398680, "mdate": 1762920398680, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}