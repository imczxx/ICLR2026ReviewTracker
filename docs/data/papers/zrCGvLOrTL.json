{"id": "zrCGvLOrTL", "number": 19913, "cdate": 1758300531637, "mdate": 1759897012465, "content": {"title": "Take Note: Your Molecular Dataset Is Probably Aligned", "abstract": "Massive training datasets are fueling the astounding progress in molecular machine learning. Since these datasets are typically generated with computational chemistry codes which do not randomize pose, the resulting geometries are usually not randomly oriented. While cheminformaticians are well aware of this fact, it can be a real pitfall for machine learners entering the burgeoning field of molecular machine learning. We demonstrate that molecular poses in the popular datasets QM9, QMugs and OMol25 are indeed biased. While the fact can easily be overseen by visual inspection alone, we show that a simple classifier can separate original data samples from randomly rotated ones with high accuracy. Second, we validate empirically that neural networks can and do exploit the orientedness in these datasets by successfully training a model on chemical property regression using the molecular orientation as _sole_ input. Third, we present visualizations of all molecular orientations and confirm that chemically similar molecules tend to have similar canonical poses. In summary, we recall and document orientational bias in the prevalent datasets that machine learners should be aware of.", "tldr": "", "keywords": ["molecular machine learning", "datasets", "orientation bias", "equivariance", "3D orientation"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3973d27da25c0a98a2b45fb56c2667eed8ae0431.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper describes the inherent bias present in the open-source molecular datasets (QM9, QMugs, and OMol25) in terms of molecular poses when applied to the task of predicting properties of these molecules."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The issue of dataset-induced bias in molecular ML is novel, especially as orientation-invariant architectures (e.g., SE(3)/E(3)-equivariant networks) are increasingly used.\n- The Mollweide projections and density analyses effectively highlight the non-uniformity of molecular orientations."}, "weaknesses": {"value": "- I find the paper’s argument about “pose bias” somewhat unclear. The 3D molecular geometries in datasets like QM9, QMugs, and OMol25 are generated using physics-based computational chemistry software, and therefore correspond to energetically stable conformers of each molecule. These conformations are naturally determined by the molecule’s 2D topology, atom types, and underlying energy landscape. From a physical standpoint, certain configurations or poses are expected to be more stable and thus more frequently observed — similar to how structures in the Protein Data Bank (PDB) reflect biologically preferred conformations. Given this, it seems there may be a misinterpretation between “pose bias” (a coordinate or orientation artifact) and physical realism (the fact that molecules adopt specific stable conformations). Could the authors clarify whether the observed “pose bias” truly represents an artifact of how datasets are stored and oriented, or whether it simply reflects physically meaningful conformational preferences inherent to molecular systems?\n\n- I understand that, when developing methods for downstream applications on these molecular datasets, it is important to account for how global molecular poses relate to their representation in Cartesian coordinates. However, most state-of-the-art molecular machine learning architectures are E(3)-equivariant or invariant, meaning they operate on geometric quantities such as interatomic distances, angles, and relative orientations, rather than on absolute Cartesian coordinates. Consequently, these models are inherently insensitive to global rotations and translations of the molecule. This raises the question of how practically relevant the reported orientation bias is, given that such equivariant models should, by design, be unaffected by the dataset’s global coordinate frame.\n\n- I think it would be more beneficial to check if this so-called \"pose bias\" is demonstrated in the models that have been trained on these datasets such as EGNNs, etc, to see if they are also susceptible to the variations wrt random rotations."}, "questions": {"value": "- Can the authors describe how the random rotation operation is being executed in Sec 3.3, as it's not fully clear how it is applied to the canonical molecular pose? Is it a global or local transformation applied to the canonical position?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jgOEJglweP", "forum": "zrCGvLOrTL", "replyto": "zrCGvLOrTL", "signatures": ["ICLR.cc/2026/Conference/Submission19913/Reviewer_F9xk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19913/Reviewer_F9xk"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19913/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760704191521, "cdate": 1760704191521, "tmdate": 1762932083197, "mdate": 1762932083197, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper provides clear evidence of subtle leakage in major molecular conformation datasets used for public comparisons of machine learning applications to drug discovery. Notably, the leakage arises because molecules with similar properties have similar geometric orientations in these datasets. The authors demonstrate this defect with increasing levels of rigor: from simple visualization, to discriminating rotated vs unrotated molecules with a simple classifier (even in the presence of substantial noise), to comparing the densities of orientational distributions.  Importantly, the paper shows that simply reading a molecule's orientation enables property prediction with a substantial reduction in variance compared to the test set mean. Finally, the paper includes equal-area Mollweide projections of the overall orientational distributions in small molecule datasets that show the relative degree of the lack of true randomness across datasets."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "This paper is original and significant because it analyzes a subtle effect that might prematurely and incorrectly influence the selection of models based on their observed performance. It is particularly timely, as limitations imposed from forced SE3 equivariance in existing architectures could be replaced by learned equivariance with faster/stronger architectures and larger datasets. Unfortunately, careful preprocessing of the standardized datasets is often avoided, but the magnitude of the effects shown in this paper clarify that such practice is unacceptable going forward. The quality of the work is high; as a subtle example: the authors apply single fixed rotations to un-randomized molecules when demonstrating their orientation-based property predictors to minimize any accidental deviation in their data pipelines. The flow of the presentation is clear and the message is strong. Duly Noted!"}, "weaknesses": {"value": "The main weakness is the lack of accompanying code for reproducibility, which should be resolved prior to publication. The lack of code would unfairly reduce the applicability of this work in future dataset preparations and benchmarks (although the implementations appear simple, rotations warrant care.)  A minor weakness is the hard-to-discern densities in some combined Mollweide plots.  While the lack of uniformity across datasets makes them memorable, comparing Fig 5 to 6 I wonder if the order of plotting the dots in Fig 6 is deterministic, rather than random, and hides information. A suggestion: perhaps also try a more distinct/color-blind friendly color palette (#0072B2 #E69F00 #CC79A7) and add a combined QM9 plot in the supplement for completeness."}, "questions": {"value": "Due to the possibility of reflection symmetries in small molecules (think small symmetric fragments), exact degeneracies can arise from their geometries. How do the authors handle degeneracies in the ranking of the principal components or the max function in Eq 3?\n\nFig 4 convincing and clear. I'd recommend that future datasets randomize orientations and include this analysis and the Mollweide equal-area plots.  Did the authors perhaps also try to use a simple summary metric of Fig 4, e.g. the distance between the actual vs intended CDE of the distributions?  Would the ranking of such a summary metric agree with the visual ranking in Fig 7?\n\nDoes this work imply issues in any specific prior publications that used symmetry-breaking, approximate-equivariant, or non-equivariant methods that relied on experimental evaluations? Highlighting any suspicious references (even in supplements or the openreview discussions) could benefit the community, though I understand that it's not the paper's main focus and nobody likes to be that guy."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 10}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "JUxLKGqLTp", "forum": "zrCGvLOrTL", "replyto": "zrCGvLOrTL", "signatures": ["ICLR.cc/2026/Conference/Submission19913/Reviewer_pzKZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19913/Reviewer_pzKZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19913/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761840026680, "cdate": 1761840026680, "tmdate": 1762932081178, "mdate": 1762932081178, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the prevalence of canonicalized poses in commonly used molecular datasets (QM9, QMugs, OMol25). The authors use a simple classification test to distinguish between molecules in their original orientation in the dataset and ones that are randomly rotated. They also present visualization of principal components of molecular orientations for each dataset and the distributions of relative rotation angles between molecules. Finally, they demonstrate that one can use the orientation alone to regress on molecular properties and that this achieves better performance than using randomly rotated features."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well written, organized, and easy to follow.The experiment with property regression from molecular orientation is quite interesting and illuminates that one should be cautious when using non-equivariant models (the model could memorize spurious information contained in the molecular orientation). The visualizations of correlations of molecular orientation with chemical properties (Figure 6) are also quite interesting. In general, the paper makes a good point that one should be cautious about data pre-processing and pre-existing canonicalizations in the data."}, "weaknesses": {"value": "A paper at the ICLR 2025 AI4Mat workshop (posted Mar 3, 2025) essentially presented the same idea [1] of a two-sample classifier test to detect whether a dataset is canonicalized or not, also applied to molecular datasets. [1] introduced the idea that these canonicalization biases may exist in molecular datasets. Furthermore, [1] showed that orientation of molecules in commonly used materials science benchmarking datasets is non-uniform (applied to QM9, MD17, OC20) and suggested that non-equivariant models may be strongly benefiting from canonicalization of the molecules’ orientations. This work seems to be quite similar, so I am not sure of the novelty ([1] also visualizes the distribution of principal moments of inertia for QM9 in the appendix). The framing and setup of [1] is very similar, but the authors of this work do not cite or mention this prior work. [1] also provided a more detailed treatment of the classifier test, showing how to compute p-values for a test of level $\\alpha$ and validation of classifier performance, which this paper does not discuss. The authors should clarify the novelty of their work relative to [1].\n\nAdditionally, in relation to section 3.1, two-sample classifier tests have already been presented in the literature, so I believe [2] should be cited. There also exists literature on non-parametric hypothesis tests for distributional group symmetry and statistical tests for invariance [3,4], so these works should be cited or discussed. \n\nWhile the visualization of molecular principal components are quite aesthetically pleasing, I am also not sure of their novelty. It is reasonable to expect that a machine learning practitioner would perform PCA on their data or visualize certain molecules prior to training a model, but much of the paper seems to rely on these visualizations. For example, take the observation that “chemically similar molecules tend to have similar canonical orientations.” For QM9, this most likely follows directly from the way conformers are generated (via CORINA from SMILES strings). Since CORINA uses deterministic geometry generation rules, this would be expected (the authors also state this). Therefore, I am not sure of the novelty of this finding/if it needs to be presented in the main part of the paper. For the other datasets (QMugs and OMol25) the authors should add further information as to why they think it has an orientational bias (L155). \n\nFrom my understanding, equivariant models generally perform best for molecular property regression on many of these datasets (outperforming non-equivariant models e.g. https://benchmarks.rowansci.com/). If there is useful information contained in the molecular orientations, shouldn’t we expect the non-invariant models to do better? There are no experiments comparing equivariant, non-invariant, or approximately equivariant models to support the claims such as “architectures that introduce symmetry breaking or are only approximately equivariant…might artificially inflate their performance by exploiting the extrinsic canonicalization” (L082). Thus, it is hard to draw meaningful conclusions. To strengthen the paper, it would be good to have more experiments comparing models on molecular property prediction.\n\nThe test in Section 3.3 is interesting, but the claim it is “empirical proof that canonical orientation alone holds information about a molecule’s properties” (L355-356) is misleading. Would it be possible for the model to effectively memorize the poses in association with properties, as the orientation correlates with the type of molecule? For example, $\\epsilon_{LUMO}$, ZVPE, and $c_V$ are all invariant properties, so the orientation physically should not hold information about the property. Rather, it should be made clear that this is a dataset level artifact. The model is essentially learning biases in the dataset’s conventions, rather than some physically meaningful relation between orientation and molecular property. I believe this may be what the authors meant but clarification would be helpful.\n\nI believe these weaknesses, particularly in terms of novelty, are somewhat substantial."}, "questions": {"value": "In Table 1, were any other QM9 properties explored? It would be interesting to see if the performance varies per property (although I expect it would not).\n\nFor Figure 6, it would be helpful to label each plot in a larger font with the chemical property being plotted.\n\nIn the conclusion L438, the authors state “it is essential to evaluate equivariant models on a randomly oriented test set as a sanity check for true equivariance.” Would it not be more robust to test the equivariance error of the model? E.g. for some sample $x$ and a rotation $R$\n$$\n\\epsilon(x, R) = \\frac{\\| f(R \\cdot x) - D(R) \\cdot f(x) \\|}{\\| f(x) \\|}\n$$\nand then average over multiple rotations/the data distribution.\n\nCould the authors elaborate on/connect their work to prior work on functional vs. distributional symmetry breaking? E.g. see [5]. Functional symmetry breaking is where the mapping between inputs and outputs is not fully equivariant. Approximately equivariant models have mostly been applied in this setting. The setting studied in this paper is distributional symmetry breaking, where a datapoint $x$ and its transform $Rx$ are not equally likely under the data distribution. This is also stated in [1]. Given that approximately equivariant models are built for the setting of functional symmetry breaking, it is not clear that they “might artificially inflate their performance by exploiting extrinsic canonicalization” (L082).\nIn general, I would like the authors to relate their work to the classifier test presented in [1] and explain the novelty of their work.\n\n[1] Lawrence et. al, Detecting Symmetry-Breaking in Molecular Data Distributions, https://openreview.net/forum?id=yEvdOXW5iY#discussion\n\n[2] David Lopez-Paz and Maxime Oquab. Revisiting classifier two-sample tests. In International Conference on Learning Representations, 2017. URL https://openreview.net/forum?\nid=SJkXfE5xx.\n\n[3] Kenny Chiu and Benjamin Bloem-Reddy. Non-parametric hypothesis tests for distributional group symmetry. In NeurIPS AI for Science Workshop, 2023.\n\n[4] Ashkan Soleymani, Behrooz Tahmasebi, Stefanie Jegelka, and Patrick Jaillet. A robust kernel\nstatistical test of invariance: Detecting subtle asymmetries. In Yingzhen Li, Stephan Mandt,\nShipra Agrawal, and Emtiyaz Khan (eds.), Proceedings of The 28th International Conference\non Artificial Intelligence and Statistics, volume 258 of Proceedings of Machine Learning Research, pp. 4816–4824. PMLR, 03–05 May 2025. URL https://proceedings.mlr.press/v258/\nsoleymani25a.html.\n\n[5] Rui Wang, Elyssa Hofgard, Robin Walters, and Tess Smidt. Discovering symmetry breaking in physical systems with relaxed group convolution. arXiv preprint arXiv:2310.02299, 2024c."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gU6N3BBdEr", "forum": "zrCGvLOrTL", "replyto": "zrCGvLOrTL", "signatures": ["ICLR.cc/2026/Conference/Submission19913/Reviewer_YdZo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19913/Reviewer_YdZo"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19913/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761878721431, "cdate": 1761878721431, "tmdate": 1762932072167, "mdate": 1762932072167, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper demonstrates that the molecules in the most commonly used molecular benchmark datasets are not in random orientations. Worse, the orientation implicitly encodes information about some of the properties that algorithms are supposed to be predicting."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper makes an important observation about the most popular molecular benchmarks and demonstrates it quite convincingly. It is important to convey this message to the community because it might be biasing our understanding of the relative strengths of different architectures. It is remarkable that this issue persists across multiple datasets."}, "weaknesses": {"value": "- The degree of deviation from uniformity of the orientations could be summarized in a single number, I don't see that in the paper.\n- It would be very interesting to see a putative explanation for why the way the datasets were generated lead to bias in orientation.\n- It is remarkable that a 3-layer message passing architecture is sufficient to decode the hidden signal in the orientations. I would be interested to see what the minimal architecture is that can do this. Relatedly, it would be interesting to see a how well this strategy works on all the target properties, not just the few cherry-picked ones reported in Table 1.\n- Section 3.2 suggests that to some extent the molecules are aligned by their principle components. A natural question then might be whether a very simple model trained on just the principle eigenvectors could do the same as the message passing network.\n- Of course it would be great to see how each of the models mentioned in the paper (both fully equivariant and non-equivariant) actually do on a randomly rotated version of these benchmarks, but I understand that running all the models is somewhat outside the scope of this paper."}, "questions": {"value": "see \"weaknesses\" for how the paper could be improved"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2cI9xAEEL2", "forum": "zrCGvLOrTL", "replyto": "zrCGvLOrTL", "signatures": ["ICLR.cc/2026/Conference/Submission19913/Reviewer_wjTX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19913/Reviewer_wjTX"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19913/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762023227090, "cdate": 1762023227090, "tmdate": 1762932069134, "mdate": 1762932069134, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}