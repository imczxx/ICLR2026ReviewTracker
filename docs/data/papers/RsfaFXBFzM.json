{"id": "RsfaFXBFzM", "number": 7556, "cdate": 1758027300770, "mdate": 1759897846461, "content": {"title": "Know When to Abstain: Optimal Selective Classification with Likelihood Ratios", "abstract": "Selective classification enhances the reliability of predictive models by allowing them to abstain from making uncertain predictions. In this work, we revisit the design of optimal selection functions through the lens of the Neyman–Pearson lemma, a classical result in statistics that characterizes the optimal rejection rule as a likelihood ratio test. We show that this perspective not only unifies the behavior of several post-hoc selection baselines, but also motivates new approaches to selective classification which we propose here. A central focus of our work is the setting of covariate shift, where the input distribution at test time differs from that at training. This realistic and challenging scenario remains relatively underexplored in the context of selective classification. We evaluate our proposed methods across a range of vision and language tasks, including both supervised learning and vision-language models. Our experiments demonstrate that our Neyman-Pearson-informed methods consistently outperform existing baselines, indicating that likelihood ratio-based selection offers a robust mechanism for improving selective classification under covariate shifts.", "tldr": "We propose likelihood ratio-based selective classification methods and evaluate them under vision and language covariate shifts tasks.", "keywords": ["selective classification"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/29cd00e94089b2756c2d449a15ad80d51874ce2d.pdf", "supplementary_material": "/attachment/8d943426757c53e894ebffa20eef104c4cac9593.zip"}, "replies": [{"content": {"summary": {"value": "The paper considers the problem of abstaining from making a classification decision. Abstaining can be useful when the classifier is likely to make a wrong prediction. The authors consider a formalism where abstaining decision is made by thresholding a confidence scoring function. Next, the authors review the Neyman–Pearson (NP) lemma on the optimal decision, and observe that some of the popular scoring functions can be viewed as approximations of the optimal rule. The authors then introduce two new scoring methods and describe conditions under which the methods are NP optimal. Effectiveness of the proposed scoring functions is supported by experiments on vision and language data."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The problem of abstaining rather than making incorrect predictions is an important practical problem\n2. The authors offer a framework to unify previous and newly proposed confidence scoring functions. Relevance to the NP lemma is an insightful observation\n3. The paper provides formal arguments (i.e., proofs) on optimality of different scores\n4. Evaluation on different datasets shows usefulness of the proposed scores\n5. The paper is clearly presented. There are minor issues, but overall the paper is easy to follow"}, "weaknesses": {"value": "1. On several occasions, justification of assumptions and theoretical constructs is not clear. First, it is not clear why p(y) should remain unchanged. It changes if relative frequencies of classes change. Also, it is not clear why exactly this assumption is required. Second, the practical implications of Lemma 2 are not clear. Third, Theorem 1 uses symbol \"<<\", which informally means \"much smaller\", but does not have any formal meaning\n2. The newly introduced scores are not fundamentally new, since MDS and KNN scores have already been considered\n3. On the practical side, it is not clear what amount of labelled data (e.g., relative to the amount of training data) is needed for the method to work reliably. This can be an issue, because modern classifiers can be constructed from pre-trained models with a minimum amount of training data (e.g., using few shot learning).\n4. In terms of presentation, it would be useful to define AURC within the paper. Also, I'm not sure how NP Lemma implies that \"thresholding this score yields the lowest possible selective risk for any given coverage level\"\n5. The experiments do not provide confidence intervals or p-values"}, "questions": {"value": "1. What amount of labelled data (e.g., relative to the amount of training data) is needed for the method to work reliably?\n2. What do assumptions of Theorem 2 mean in practice?\n3. What are the practical implications of Lemma 2?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bzHnBnsp0s", "forum": "RsfaFXBFzM", "replyto": "RsfaFXBFzM", "signatures": ["ICLR.cc/2026/Conference/Submission7556/Reviewer_55hp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7556/Reviewer_55hp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7556/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761609114573, "cdate": 1761609114573, "tmdate": 1762919651275, "mdate": 1762919651275, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the problem of selective classification, where one has to decide whether to predict or abstain. The authors leverage the Neyman-Pearson lemma which sets up the problem as a hypothesis test between H0 (the classifier makes a correct prediction) and H1 (the classifier makes an incorrect prediction). The authors can cast existing methods such as RLog, MDS, and KNN into the Neyman-Pearson framework to show optimality. In the end, the method takes a linear combination of classifier logit scores and distance, which produce strong results on image and text classification benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "This paper provides a unified framework based on the Neyman-Pearson lemma that captures existing methods (which are often treated as ad-hoc).\nThe paper is fairly well-written and uses proper mathematical notation.\nThe empirical results are strong."}, "weaknesses": {"value": "I think the optimality of Neyman-Pearson is a bit overstated, since optimality depends crucially on the distributional assumptions being valid."}, "questions": {"value": "Methods like MDS require estimating the covariance, which could be statistically expensive (require many samples) compared to RLog? The methodology in the experiments could be a bit more transparent: how many examples are required? In the end, the hybrid methods improve over existing methods, but I want to make sure I understand the resources / additional tuning that's required for each one?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Y7sgyPqq7a", "forum": "RsfaFXBFzM", "replyto": "RsfaFXBFzM", "signatures": ["ICLR.cc/2026/Conference/Submission7556/Reviewer_z5TG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7556/Reviewer_z5TG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7556/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762129338016, "cdate": 1762129338016, "tmdate": 1762919650331, "mdate": 1762919650331, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work studies the problem of selective classification where a classifier is allowed to abstain from making predictions if the model is not confident enough. This work proposed new approaches to selective classification  based on the Neyman-Pearson lemma and also unifies several existing approaches to this problem. They also provide experiments to support their theoretical results and show that their method outperforms various baselines under covariate shifts where the test input distribution is different form the train input distribution."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The authors using NP lemma to combine several existing baseline methods is simple and intuitive. \n- The authors proposed method - linear combination of distance based and logic based methods is simple and interesting."}, "weaknesses": {"value": "- Theorem 2 relies on strong assumptions that the covariance distribution conditioned on the prediction is a gaussian. Theorem 3 relies on  k tending to infinity which is not practical. \n- The authors do not provide intuitive understanding of in which cases, their proposed method should perform well compared to the baseline."}, "questions": {"value": "- The authors in lemma 2 assume that density for each distribution takes a tilted form. Could the authors please elaborate that?\n- The authors mention in line 305 that knn-distance based classifiers are ineffective on high dimensions. Why do they work for this work?\n- Are the values of lambda and k similar across datasets and classifiers? Or, they have to be tuned separately for each setting?\n- How is g^* computed in eqn 7?\n- The authors have not defined SIRC method which is used as comparison in the results."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "E8BQtv6lRj", "forum": "RsfaFXBFzM", "replyto": "RsfaFXBFzM", "signatures": ["ICLR.cc/2026/Conference/Submission7556/Reviewer_Vjb9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7556/Reviewer_Vjb9"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7556/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762137413919, "cdate": 1762137413919, "tmdate": 1762919649826, "mdate": 1762919649826, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}