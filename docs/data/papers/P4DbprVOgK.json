{"id": "P4DbprVOgK", "number": 21057, "cdate": 1758313287233, "mdate": 1759896944597, "content": {"title": "Contrastive Subgroups: Discovering Where Two Populations Differ, and Why", "abstract": "Given data from two distinct populations, a contrastive subgroup describes a subset of individuals from both groups who, despite sharing similar characteristics, exhibit significant differences in a target outcome. For example, we want to identify subsets of patients who respond differently to a treatment compared to a control group, or uncover disparities between protected and unprotected groups in fairness analysis. In this work, we formalize the notion of contrastive subgroups and propose a general optimization objective to discover them. To make these discovered subgroups actionable, we provide conditions under which the discovered subgroups allow to make causal inferences. We introduce Subcon, a gradient-based method to discover contrastive subgroups and evaluate it on both synthetic and real-world datasets. The results confirm that our method effectively identifies subgroups that expose significant, informative differences in \nreal-world datasets.", "tldr": "We introduce the concept of contrastive subgroups, describing a subset of indviduals who, despite sharing similar characteristics, exhibit significant differences in a target outcome based on group membership.", "keywords": ["Interpretability;Subgroups;"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7bc0670fba3ab84e5d5c1ac360e1fd24ef6bea3a.pdf", "supplementary_material": "/attachment/7838545d440032f4125b53b289aedcf9499dc117.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose a subgroup discovery method based on treatment effect estimation by employing the existing rule learner framework called SYFLOW. \n\nFor this goal, they have proposed formal notions called contrastive exceptionality and covariate dependence. However, these proposals are quite similar to the existing method for distributional treatment effect modifier discovery [Chikahara et al. UAI2022], which the authors do not even cite or mention."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- Problem setup is important: Many studies work on subgroup discovery based on treatment effect estimation, though the authors say “However, as of now, there does not exist a general definition or method to discover them in a principled way.” in Section 2.\n\n- The authors discuss the relation between the proposed notions and some example toy causal graphs."}, "weaknesses": {"value": "(A) No discussion on related work\n\nThe weakest point of this paper is the lack of related work discussion on subgroup discovery based on treatment effect estimation. \nA prominent line of work is to discover **treatment effect modifiers** [1] from covariates, the features that explain why the treatment effects are different. The authors cite none of the related work on this topic [2-3] and just say that “However, as of now, there does not exist a general definition or method to discover them in a principled way.” in Section 2.\n\nA serious issue is that the first contribution of this paper “(formalize the notion of contrastive subgroups)” is **NOT novel**, as **the proposed notion of contrastive exceptionality seems very close** (and the underlying idea is almost identical) *to the existing feature importance measure** based on conditional potential outcome distributions [3].  \n\nDue to the lack of related work discussion, I could not find the novelty, significance, and originality of this paper, thus I cannot recommend the acceptance to such a top conference as ICLR.\n\n> [1] Rothman, Kenneth J., Sander Greenland, and Timothy L. Lash. Modern epidemiology. Vol. 3. Philadelphia: Wolters Kluwer Health/Lippincott Williams & Wilkins, 2008.\n\n> [2] Zhao, Qingyuan, Dylan S. Small, and Ashkan Ertefaie. \"Selective inference for effect modification via the lasso.\" Journal of the Royal Statistical Society Series B: Statistical Methodology 84.2 (2022): 382-413.\n\n> [3] Yoichi Chikahara, Makoto Yamada, Hisashi Kashima. Feature Selection for Discovering Distributional Treatment Effect Modifiers. UAI, 2022.\n\n\n(B) Weakness of rule learning approach\n\nAnother weakness of this work is the lack of evaluating statistical significance of detected subgroups. Unlike the statistical-testing-based approaches [2-3], the authors learn interpretable, tree-based models. Although this approach is popular in existing work (e.g., [4]; though the authors do not mention or cite again), such approach cannot evaluate the statistical significance of the inferred results. \n\nHence, the learned subgroups are easily changeable due to the noise in empirical distribution, and the robustness is doubtful. Additional experiments for confirming the noise robustness will be necessary to claim the technical soundness.\n\n\n> [4] Falco J. Bargagli-Stoffi, Riccardo Cadei, Kwonsang Lee, Francesca Dominici. Causal Rule Ensemble: Interpretable Discovery and Inference of Heterogeneous Treatment Effects. arXiv\n \n\n(C) Inappropriate citations or related work reference on fairness\n\nThe description on algorithmic fairness (based on causality) seems inappropriate.\n\n- The proposal of [Dwork et al., 2012] is **NOT** demographic parity, but individual fairness definition. These notions are totally different. The citation is completely inappropriate. \n\n> These methods provide notions to quantify disparity between two populations, but they leave open where that disparity arises and why their distributions diverge.\n\n- The task of elucidating why the disparity arises is often called “discrimination discovery”, and there are several methods for this task. A pioneer work would be [5-6], which are **NOT** cited again in this paper.\n\n> [5] Lu Zhang, Yongkai Wu, and Xintao Wu. Situation Testing-Based Discrimination Discovery: A Causal Inference Approach. IJCAI, 2016.\n\n> [6] Zhang, Lu, Yongkai Wu, and Xintao Wu. \"Causal modeling-based discrimination discovery and removal: Criteria, bounds, and algorithms.\" IEEE Transactions on Knowledge and Data Engineering 31.11 (2018): 2035-2050."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3LRyuE7Cma", "forum": "P4DbprVOgK", "replyto": "P4DbprVOgK", "signatures": ["ICLR.cc/2026/Conference/Submission21057/Reviewer_ETqB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21057/Reviewer_ETqB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21057/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760847121143, "cdate": 1760847121143, "tmdate": 1762940629292, "mdate": 1762940629292, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SUBCON, a differentiable framework for contrastive subgroup discovery, a novel task that aims to identify subsets where the target distribution differs significantly between groups (e.g. treatment v.s. control).  The method is a combination of exceptionality, generality, and covariate independence. To make these discovered subgroups actionable, the authors provide conditions under which the discovered subgroups allow to make causal inferences. Experiments on simulated, IHDP, and COVID-19 datasets show that SUBCON reliably recovers meaningful contrastive subgroups, outperforming both traditional subgroup discovery and causal-effect baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Novelty: The paper introduces a new task, contrastive subgroup discovery, which is a largely unexplored research direction. Beyond defining this novel problem, it also proposes a concrete differentiable solution. The contribution is conceptually original, and the novelty is well established.\n2. Significance: The proposed task has potential implications for multiple downstream domains, such as fairness analysis. From my perspective, the formulation could be useful not only for real-world data mining applications but also for theoretical studies on causal and subgroup structures. \n3. Clarity: The paper is generally well written and easy to follow. Technical details are presented clearly and self-contained, and the figures (e.g. Figure 1 and 2) are intuitive and informative."}, "weaknesses": {"value": "1. The following statement could be improved:\n“By ensuring that the features do not locally influence the target variable, we can be more confident that the observed differences are not due to a shift in features caused by $A$, but instead directly driven by $A$ itself.”\nMinimizing the so-called “covariate dependence” seems to block both pathways $A$→$X$→$Y$ and $A$←$X$→$Y$, so it may not be rigorous to claim “features caused by $A$”.\n2. I would be interested in seeing more discussion or experimental illustrations of potential downstream applications, such as fairness analysis, to demonstrate the broader utility of SUBCON.\n3. While the proposed idea of contrastive subgroup discovery is interesting and well-motivated, much of the technical implementation (e.g. differentiable rule learner and optimization design) builds directly on prior work (e.g. Xu et al., SyFlow). Consequently, the main novelty lies in the problem framing rather than algorithmic innovation, and the paper explicitly focuses on the former."}, "questions": {"value": "1. Is it possible (though not strictly necessary) to provide some theoretical guarantees that the proposed learning procedure can indeed recover the (ground-truth) subgroup indicator? For example, a learning-theoretic bound or convergence analysis.\n2. As I understand, the same hyperparameter settings were used for both real-world and simulated datasets. Are these hyper-parameter selection rules generally suitable across different settings, or mainly for the small-graph cases in your simulations? It would be interesting to see experiments on larger and more complex datasets.\n3. I wonder how the performance of SUBCON scales with the dimensionality of $X$ and the number of subgroups involved. Have you evaluated the method’s robustness when varying the feature dimensionality? For instance, higher-dimensional $X$ may correspond to more complex subgroup structures and potentially harder optimization.\n4. For the real-world datasets, could you provide more scientific justification or evidence for the meaningfulness of the discovered subgroups? In other words, do the identified subgroups correspond to interpretable or actionable patterns in the underlying domain?\n\nThe paper introduces a novel and meaningful problem setting with an interesting formulation. While the current version still lacks clarity and sufficient empirical validation, I believe the work has value for the ICLR community. I lean towards a weak reject at this stage, but I acknowledge the potential impact of this work and remain open to increasing my score based on the authors’ rebuttal."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lQcl4rnSwZ", "forum": "P4DbprVOgK", "replyto": "P4DbprVOgK", "signatures": ["ICLR.cc/2026/Conference/Submission21057/Reviewer_b8UN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21057/Reviewer_b8UN"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21057/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761691439604, "cdate": 1761691439604, "tmdate": 1762940628832, "mdate": 1762940628832, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces contrastive subgroups—subsets of data where two populations with similar characteristics show significantly different outcomes. It formalizes this problem, provides causal conditions for valid interpretation, and proposes SUBCON, a gradient-based method to discover such subgroups. Experiments show SUBCON can reveal meaningful treatment heterogeneity and demographic disparities that standard subgroup discovery or causal models miss."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This paper’s main strength is that it identifies and formalizes an important but previously under-addressed problem: finding subgroups where two populations differ locally, rather than only measuring global disparities or blindly searching for exceptional patterns. The formulation is elegant and bridges subgroup discovery with causal inference in a principled way, making the results not just descriptive but potentially actionable.\n\n* Methodologically, the paper offers a well-constructed objective that balances statistical exceptionality, support, and confounding control, backed by clear causal interpretations. The SUBCON algorithm is thoughtfully engineered, combining differentiable rule learning with divergence-based objectives and regularization for causal validity.\n\n* The experimental evaluation is comprehensive, spanning controlled synthetic settings with known ground truth as well as semi-synthetic and real-world datasets. The results compellingly show that existing subgroup discovery and causal methods each miss key patterns that the proposed method identifies. The examples, especially in fairness and clinical-style settings, emphasize the practical relevance and interpretability of the discovered subgroups.\n\n* The paper is clearly written and motivates the problem well, using intuitive examples to illustrate why contrastive subgroup discovery matters. Overall, this is a strong and timely contribution that introduces a meaningful new problem and provides an effective and interpretable solution."}, "weaknesses": {"value": "While the paper makes a strong contribution, there are a few limitations. The method relies on accurate density and conditional distribution estimation, which may be challenging in higher-dimensional or noisy settings. The pipeline also has several components (e.g., temperature annealing, re-estimating densities), making it more complex to implement and tune compared to tree-based causal approaches. Finally, the method currently focuses on discovering one subgroup at a time, and extending it to systematically identify multiple subgroups would further increase its practical utility."}, "questions": {"value": "1. How sensitive is SUBCON to inaccuracies in density and conditional distribution estimation, particularly in higher-dimensional settings or smaller datasets?\n\n2. Could the authors provide more guidance or ablation results on tuning the key hyperparameters (e.g., temperature schedule, λ, γ)? Are there practical heuristics to simplify training?\n\n3. Do the authors envision a principled extension for discovering multiple contrastive subgroups simultaneously, rather than sequentially masking previously found groups?\n\n4. What is the computational scalability of SUBCON for large-scale tabular data (e.g., 100k+ samples or dozens of features)? Have the authors benchmarked runtime or memory overhead?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GrDz3tAQpZ", "forum": "P4DbprVOgK", "replyto": "P4DbprVOgK", "signatures": ["ICLR.cc/2026/Conference/Submission21057/Reviewer_1G57"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21057/Reviewer_1G57"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21057/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996863646, "cdate": 1761996863646, "tmdate": 1762940628422, "mdate": 1762940628422, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents an approach to finding \"contrastive subgroups\" - areas of the input space where two populations differ in outcomes according to a label Y. They present the criteria that these subgroups must hold, and connect some of these criteria to causal interpretations. Empirically, they demonstrate that this method is able to find contrastive subgroups in synthetic and semi-synthetic data and can also be used in some cases for causal effect estimation."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "- very interesting framing and question that hasn't seen that much work\n- connections to causality are nice and useful\n- experiments are convincing to me that the method is more successful at finding contrastive subgroups than existing alternatives"}, "weaknesses": {"value": "- I think the 3 criteria may miss a specific corner case: consider a subgroup S that consists of 2 disjoint subsets S1 and S0. S1 contains only A=1 and S2 contains only A=0. Then, generality is non-zero, and we can have both covariance independence and exceptionality by assigning Y=1 on S2 and Y=0 on S0 uniformly. This seems as though it does not satisfy the notion of contrastive subgroups that you want since there is 0 overlap between the two groups. In particular, this may be an issue for the approach as S is implemented in a more flexible way than the highly-parameterized approach used here. I think the contribution here is still useful but it does knock the utility of the theoretical contributions down for me - unless I'm missing something, in which case I would love to be corrected\n- additionally, this specific corner case may cause some of the causal reasoning, such as in Prop 1, to fail, since standard positivity notions are not satisfied\n- the generality metric is odd to me - it's not clear that once we get sufficiently far from 0, we necessarily want to bias towards larger subgroups\n- also on generality, in Eq 6 I don't see why it makes sense to multiply generality by exceptionality - more intuition here would be helpful! At the moment it seems arbitrary\n- Eq 16: a little unclear, is this supposed to  be JS divergence? what is Q(Y)?\n- missing some clarity on the PEHE experiments - they're interesting but I don't totally understand how the subgroup maps onto a causal effect estimate: is there some assumption made about what subgroup you're going to find? I understand the basic causal connections mentioned previously, but I'd imagine you could get very different causal effects by finding different subgroups"}, "questions": {"value": "- would like to see the corner case from the Weaknesses section addressed, or tell me why I'm wrong about it\n- two questions on generality: seems odd to maximize (rather than threshold above some number), and seems odd to multiply it with exceptionality as in Eq 6\n- more clarity on PEHE experiments \n\nHappy to increase my score if these two things are addressed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "u83F5uBVrL", "forum": "P4DbprVOgK", "replyto": "P4DbprVOgK", "signatures": ["ICLR.cc/2026/Conference/Submission21057/Reviewer_SWta"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21057/Reviewer_SWta"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21057/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762203826499, "cdate": 1762203826499, "tmdate": 1762940628130, "mdate": 1762940628130, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}