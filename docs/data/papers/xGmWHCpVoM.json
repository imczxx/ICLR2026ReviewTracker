{"id": "xGmWHCpVoM", "number": 16709, "cdate": 1758267901790, "mdate": 1763389301241, "content": {"title": "Semi-Supervised Speech Enhancement with Gradient-Guided Channel Attenuation", "abstract": "Recent methods for speech enhancement (SE) have generally adopted the supervised learning way and trained the models on synthetic noisy-clean paired speech data. However, when applying the supervised trained SE model to the recordings of real-world scenario, which we call unlabeled data, it will lead to the performance degradation. To improve the generalization performance of SE, we propose a semi-supervised monaural speech enhancement network, SS-SENet, which adopts the mean-teacher (MT) framework with domain adversarial (DA) learning to effectively exploit the unlabeled data. We also propose the Gradient-Guided Channel Attenuation (GGCA) module for suppressing the domain-specific features and enhance domain-invariant one, and Domain Shift-Aware Monitor (DSAM) strategy for dynamically adjusting the attenuation rate in GGCA. Comparing with seven SOTA methods exploiting the unlabeled data, our proposed SS-SENet achieves the best performances at all metrics both on synthetic Reverberant LibriCHiME-5 and LibriMix datasets, and at the critical metric, OVRL, on the real-world CHiME-5 dataset. The results verify that our proposed basic MT-based method is superior to the compared methods based on full supervised or self-supervised learning. It also verifies the effectiveness of our proposed GGCA module and DSAM strategy. The source code is available at \\url{https://anonymous.4open.science/r/SS-SENet}.", "tldr": "A semi-supervised speech enhancement network based on mean-teacher framework for speech enhancement.", "keywords": ["speech enhancement", "semi-supervised learning", "mean-teacher", "gradient-guide channel attenuation"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/517b76994b48b51bf5cf663e771257b73f996d2f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes SS-SENet, a semi-supervised monaural speech enhancement network that integrates a Mean Teacher (MT) framework with domain-adversarial (DA) learning to leverage unlabeled real-world audio. It introduces two modules: Gradient-Guided Channel Attenuation (GGCA), which suppresses domain-specific features, and Domain Shift-Aware Monitor (DSAM), which dynamically adjusts attenuation strength. Trained on LibriMix and CHiME-5 datasets, SS-SENet outperforms seven state-of-the-art baselines on synthetic and real-world benchmarks, demonstrating improved generalization and robustness."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. Comprehensive Experimental Evaluation: The paper presents extensive experimental results on both synthetic and real-world datasets (CHiME-5, LibriMix, and Reverberant LibriCHiME-5). The comparisons include seven competing baselines, covering both self-supervised and domain-adaptive approaches, which strengthens the empirical validation.\n\n2. Transparent Code Availability: The authors provide open-source code, which facilitates reproducibility and increases the paper’s practical value for future research in semi-supervised speech enhancement.\n\n3. Thorough Ablation Studies: The paper conducts systematic ablation analyses on each major component (DA, GGCA, and DSAM), clearly demonstrating their individual contributions to overall performance improvements."}, "weaknesses": {"value": "1. Limited Contribution and Novelty: The proposed framework primarily combines existing ideas such as Mean Teacher consistency learning and domain-adversarial training without introducing a fundamentally novel algorithmic or theoretical component. As a result, the methodological contribution feels incremental rather than innovative.\n\n2. Insufficient Discussion of Noise and Speech Types: The paper could benefit from a more detailed characterization of the noise types, speech conditions, and specific challenges encountered in the real-world CHiME-5 dataset. Such clarification would better contextualize the proposed method’s robustness and its potential limitations in practical deployment.\n\n3. Language and Presentation Issues: The manuscript contains several typographical and grammatical errors (e.g., “expoit”, “extratced”, “sturcture”, “banlanced”, “adpot”) throughout Section 3 and the ablation appendices. Although these do not hinder overall comprehension, they detract from the paper’s professionalism and polish.\n\n4. Lack of Statistical Significance Analysis: The reported improvements are not accompanied by statistical significance tests (e.g., Wilcoxon signed-rank test or paired t-test). This omission makes it difficult to assess whether the observed gains are consistent or potentially due to random variation.\n\n5. Absence of Efficiency Metrics: The paper does not provide any computational efficiency measurements, such as training speed, parameter count, GPU memory usage, or FLOPs. This omission limits the reader’s ability to assess the trade-off between performance gains and computational cost."}, "questions": {"value": "1. How consistent are the reported improvements across different random seeds or training runs? Have the authors performed any statistical tests to verify that the performance gains are significant?\n\n2. Given that the Mean Teacher framework doubles the number of model instances during training, what is the additional computational cost in terms of runtime, training speed, parameter count, GPU memory usage, and FLOPs compared to purely supervised baselines?\n\n3. Could the authors provide more detailed information on the types and distributions of noise in the real-world CHiME-5 dataset, and whether specific noise characteristics affect model performance?\n\n4. The study focuses primarily on SI-SDR, PESQ, and DNSMOS metrics. Have the authors considered perceptual or subjective listening tests to validate whether the improvements are perceptually meaningful?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mJLnxozTzK", "forum": "xGmWHCpVoM", "replyto": "xGmWHCpVoM", "signatures": ["ICLR.cc/2026/Conference/Submission16709/Reviewer_yN4M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16709/Reviewer_yN4M"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761058365002, "cdate": 1761058365002, "tmdate": 1762926761881, "mdate": 1762926761881, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "mlA3NZzHN7", "forum": "xGmWHCpVoM", "replyto": "xGmWHCpVoM", "signatures": ["ICLR.cc/2026/Conference/Submission16709/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16709/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763389300296, "cdate": 1763389300296, "tmdate": 1763389300296, "mdate": 1763389300296, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a semi-supervised monaural speech enhancement network, SSSENet, which adopts the Mean-Teacher (MT) framework with domain adversarial (DA) learning. It also introduces a Gradient-Guided Channel Attenuation (GGCA) module to suppress domain-specific features and enhance domain-invariant ones, along with a Domain Shift-Aware Monitor (DSAM) strategy to dynamically adjust the attenuation rate in GGCA, enabling more effective use of unlabeled data. However, there are some concerns regarding the experimental setup and the limited performance improvements observed (see the weakness below)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1)\tThe ideas of GGCA and DSAM are interesting, although they seem to serve the same purpose as domain adversarial (DA) learning.\n2)\tThe paper is well written and easy to follow."}, "weaknesses": {"value": "1)\tSince the domain discrimination loss has already been applied to remove domain-specific information, the necessity of the proposed Gradient-Guided Channel Attenuation (GGCA) and Domain Shift-Aware Monitor (DSAM) is unclear. In fact, as shown in Table 3, the improvements over domain adversarial (DA) training are quite limited and could be within the range of normal fluctuations due to different training iterations. I’m curious whether, if a learning curve plot similar to Figure 5 were shown, we could clearly observe any improvement from GGCA and DSAM.\n2)\tIn Table 6 (Appendix), the authors present ablation studies on hyperparameter tuning and report results on the test set. This approach may lead to overfitting and is not a fair evaluation, as test data should not be used for parameter tuning."}, "questions": {"value": "1)\tFor the seven baseline models presented in the experiments, were they all trained on the same dataset as your model?\n2)\tIn Figure 5, could you explain why RemixIT does not show improved scores?\n3)\tIn Table 2, why does Basic MT significantly outperform SuDoRM-RF (F) on the Reverb. LibriCHiME-5 dataset but not on CHiME-5? Since MT is semi-supervised on CHiME-5, I’m quite curious about the reason behind this discrepancy."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "dsA4nk7LZk", "forum": "xGmWHCpVoM", "replyto": "xGmWHCpVoM", "signatures": ["ICLR.cc/2026/Conference/Submission16709/Reviewer_3bsn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16709/Reviewer_3bsn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761188586082, "cdate": 1761188586082, "tmdate": 1762926761475, "mdate": 1762926761475, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a novel semi-supervised approach for speech enhancement that enables the incorporation of real-life data without requiring direct reference to clean samples in the training pipeline. The paper also introduces techniques to enhance the efficacy of semi-supervised training; in particular, it proposes attenuating domain-specific features to improve the model's generalisation to other domains and utilises a domain adversarial loss to make features less susceptible to domain changes."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper has the following strengths:\n\n1. The idea of using semi-supervised methods to incorporate real-world data without clean reference recordings has significant potential, as it allows models to be trained on a much more diverse set of recordings.\n\n2. The structure of the paper is good; it is well-structured and easy to read. Both the model architecture and the training pipeline are well-detailed, making it easy to comprehend the key components of the proposed algorithm."}, "weaknesses": {"value": "The paper has some minor weaknesses: \n\n1. The paper lacks comparisons with recent universal SE models trained on paired data. Since the paper claims that incorporating unlabelled data is beneficial, it would be interesting to see how the method compares to other recent models [1, 2, 3, 4, 5, 6] that use s traditional approach.  \n\n2. The DNSMOS results seem strange. They show that the model degrades the perceptual quality of the audio. I would recommend adding UTMOS [7]; moreover,  providing some reference audio recordings would be beneficial for a better understanding of the performance of the model."}, "questions": {"value": "1. Can the proposed semi-supervised method be used together with existing GAN-based or diffusion-based pipelines, which are widely adopted in a large body of work? \n\n#### **References** \n\n[1] Babaev et al., \"FINALLY: fast and universal speech enhancement with studio-like quality\".\n\n[2] Su et al., \"HiFi-GAN-2: studio-quality speech enhancement via generative\".\n\n[3] Lemercier et al., \"StoRM: a diffusion-based stochastic regeneration model for speech enhancement and dereverberation\".\n\n[4] Scheibler et al.,  \"Universal score-based speech enhancement with high content preservation\".\n\n[5] Jukíc et al., \"Schrödinger bridge for generative speech enhancement\".\n\n[6] Wang et al., \"Diffusion-based Speech Enhancement with Schrödinger Bridge and Symmetric Noise Schedule\".\n\n[7] Saeki et al., \"UTMOS: UTokyo-SaruLab system for VoiceMOS challenge 2022\""}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "F5fiuXmoxg", "forum": "xGmWHCpVoM", "replyto": "xGmWHCpVoM", "signatures": ["ICLR.cc/2026/Conference/Submission16709/Reviewer_VdMs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16709/Reviewer_VdMs"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761832363637, "cdate": 1761832363637, "tmdate": 1762926761090, "mdate": 1762926761090, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper considers the speech enhancement problem. The authors propose a semi-supervised monaural speech enhancement method based on the mean-teacher approach. A domain discriminator with gradient reversal layer is designed to narrow the synthetic-real gap. A gradient-guided channel attenuation module is emplyed to use discriminator gradients to rank channel-wise domain specificity and attenuate Top-k channels, while domain shift aware monitor is used to adapt the attenuation ratio via a batch-level labeled/unlabeled feature variance measure. Provided experiments on CHiME-5 and LibriMix/Reverberant LibriCHiME-5 show the proposed method outperforms recent methods across backbones."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper applies the mean teacher method to speech enhancement, and combines labeled synthetic data and unlabeled real-world data in a single-stage speech enhancement training pipeline, which is simpler than two-stage methods like RemixIT.  A gradient-guided channel attenuation (GGCA) module for for suppressing domain-specific features and enhancing domain-invariant features, and a domain shift aware monitor strategy for dynamically controlling the attenuation rate in GGCA have been proposed to further improve the performacne. Experimental results are reported across two backbone types, multiple datasets, seven baseline methods, which demonstrate the effectiveness of the proposed method."}, "weaknesses": {"value": "The contribution of this paper lies mainly in combining existing methods, mean teacher, domain adversarial learning, channel suppression, into a system for speech enhancement. The novelty is more in engineering integration of existing methods. It would be better to include downstream task results such as ASR word error rate, to validate practical usefulness of the proposed method."}, "questions": {"value": "Does mean teacher remain stable when unlabeled data dominates? How does it handle pseudo-label noise accumulation?\nIt would be better to include downstream task results such as ASR WER."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TUrhX1wMBR", "forum": "xGmWHCpVoM", "replyto": "xGmWHCpVoM", "signatures": ["ICLR.cc/2026/Conference/Submission16709/Reviewer_Lesi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16709/Reviewer_Lesi"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995356781, "cdate": 1761995356781, "tmdate": 1762926760610, "mdate": 1762926760610, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}