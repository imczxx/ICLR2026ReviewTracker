{"id": "5ystL0PeGx", "number": 20196, "cdate": 1758303570086, "mdate": 1763633567213, "content": {"title": "Private Federated Multiclass Post-hoc Calibration", "abstract": "Calibrating machine learning models so that predicted probabilities better reflect the true outcome frequencies is crucial for reliable decision-making across many applications. In Federated Learning (FL), the goal is to train a global model on data which is distributed across multiple clients and cannot be centralized due to privacy concerns. FL is applied in key areas such as healthcare and finance where calibration is strongly required, yet federated private calibration has been largely overlooked. This work introduces the integration of post-hoc model calibration techniques within FL. Specifically, we transfer traditional centralized calibration methods such as histogram binning and temperature scaling into federated environments and define new methods to operate them under strong client heterogeneity. We study (1) a federated setting and (2) a user-level Differential Privacy (DP) setting and demonstrate how both federation and DP impacts calibration accuracy. We propose strategies to mitigate degradation commonly observed under heterogeneity and our findings highlight that our federated temperature scaling works best for DP-FL whereas our weighted binning approach is best when DP is not required.", "tldr": "", "keywords": ["Classifier Calibration; Federated Learning; Differential Privacy;"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/84b2e231212f798237b9d2aa4aa7e86852c5e323.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper studies post-hoc calibration of multiclass classifiers in federated learning, with a focus on non-IID client data and user-level differential privacy. The authors adapt two common calibration strategies, histogram binning and temperature scaling, to the federated setting. For binning, they propose FedBBQ, which extends Bayesian Binning into Quantiles to FL and introduces a weighting scheme intended to handle client heterogeneity. For scaling, they propose a federated version of temperature scaling with an order-preserving training procedure that aims to avoid accuracy loss when clients are highly different. They also provide differentially private variants by clipping client updates and adding calibrated noise. The experiments span seven datasets. The results suggest that FedBBQ gives the best calibration in non-private FL with strong heterogeneity, while FedTemp is the most stable and effective approach when differential privacy is enforced."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper evaluates its methods on a range of datasets in both standard federated learning and differentially private federated learning settings.\n\n2. It proposes several calibration strategies that target different degrees of client heterogeneity and different privacy budgets, which makes the approach more practical and more adaptable to real deployment scenarios."}, "weaknesses": {"value": "1. The paper still lacks some key formal definitions in the main text. For example, the Bayesian binning (BBQ) procedure, the exact weighting scheme used by the server to stabilize FedBBQ under heterogeneity, and the “order-preserving” training used in scaling are only described at a high level or deferred to the appendix. Without these details in the core paper, it is hard for the reader to fully understand or reproduce the proposed methods. \n\n2. The motivation and analysis behind the main technical ideas could be stronger. The paper introduces weighted binning and order-preserving scaling as fixes for heterogeneity and accuracy drop, but it does not explain in a principled way why these fixes should work or under what assumptions they are guaranteed to help. As written, they read more like heuristics that happened to improve results, rather than methods whose behavior is theoretically understood.\n\n3. The motivation for doing post-hoc calibration in federated learning is not fully convincing. The method assumes each client can hold out a clean “calibration set” after training, and can revisit the model for an extra calibration phase. In realistic FL deployments, clients may not have enough leftover data or may not know in advance that calibration will happen. The paper does not clearly explain why calibration must be done post-hoc instead of training a calibrator jointly with the model during FL.\n\n4. The set of baselines is limited. Most comparisons are against FedCal and simple scaling variants, plus unweighted binning. There are other relevant directions in the related work, including prior FL calibration approaches, DP-aware calibration, and non-federated multiclass calibration methods that could be adapted. The argument that prior work does not consider cwECE or user-level DP is not fully sufficient, because cwECE can still be measured after the fact and DP-SGD style noise can in principle be applied to competing methods. A broader comparison in both non-private FL and DP-FL settings would make the empirical claims more convincing.\n\n5. There are some consistency and interpretability issues in the analysis. For example, the text claims that the proposed fixes prevent accuracy degradation under heterogeneity, but Table 2 still marks cases where FedBBQ causes more than 1% drop in test accuracy. The paper also argues that cwECE is the “right” metric for multiclass FL, mainly because it separates classes better than top-label ECE, but this is more a sensitivity argument than a justification that cwECE reflects real calibration quality for downstream decisions. These points should be clarified.\n\n6. The proposed FedBBQ method appears highly sensitive to hyperparameters such as the number of bins, the way multiple histograms are merged, the weighting factor αj, the clipping norms for DP, and the number of calibration rounds T. The paper does not provide clear guidance on how to choose these values, which makes it hard to know how robust the method is across new datasets\n\n7. The paper claims that the proposed approaches are lightweight in terms of computation and communication, but the main text does not quantify this cost. For example, the overhead of sending per-class histograms in FedBBQ, or repeatedly sending scaling parameters under DP noise, is not analyzed in detail. Since FL and DP-FL are often bottlenecked by communication and client resource limits, these costs should be made explicit in the main results rather than only mentioned qualitatively."}, "questions": {"value": "1. The paper introduces a weighting scheme (for binning) and an order-preserving training strategy (for scaling), and claims these help under client heterogeneity. Could you provide more intuition for how these components work? In particular, how exactly do they reduce the negative impact of heterogeneous client distributions, and why do they help avoid accuracy drop during calibration?\n\n2. FedTemp shows surprisingly strong performance under high heterogeneity and when differential privacy is applied. Can you explain why simple temperature scaling is so effective in that regime? Is there an intuitive reason that temperature scaling is more robust than the other approaches when data is both non-iid and noisy due to DP?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "rA3DaQrCm6", "forum": "5ystL0PeGx", "replyto": "5ystL0PeGx", "signatures": ["ICLR.cc/2026/Conference/Submission20196/Reviewer_6xAV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20196/Reviewer_6xAV"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20196/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761449580819, "cdate": 1761449580819, "tmdate": 1762933700337, "mdate": 1762933700337, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces two frameworks for federated post-hoc calibration in DP settings. The authors validate the effectivenss of the proposed methods on 7 datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper focues on an important issue, calibration in federated settings with user-level DP, which is highly relevant for real-world application in scenarios like healthcare. \n\n2. Generally, the paper is easy to follow."}, "weaknesses": {"value": "1. The technical contribution of the paper appears to be somewhat limited. The proposed method primarily integrates several well-established techniques. For example, federated binning largely follows (Cormode & Markov, 2023), scaling via FedAvg is straightforward application of existing methods. \n\n2. Some technical details aren’t well justified. For instance, in line 303, the weight $\\alpha_j$ doesn’t have a clear theoretical explanation. why was this specific form chosen? The paper briefly mentions an ablation on this weight, but the comparison isn’t really explored in depth. \n\n3. Only compares against FedCal (Peng et al., 2024) for scaling methods and missing comparisons with other recent federated calibration work."}, "questions": {"value": "1. How do your methods scale to $K >> 100$ clients with more extreme heterogeneity?\n\n2. The privacy analysis assumes fixed hyperparameters (M, C, etc.). In practice, how should practitioners account for the privacy cost of tuning these parameters on private data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yKOSQo3bFb", "forum": "5ystL0PeGx", "replyto": "5ystL0PeGx", "signatures": ["ICLR.cc/2026/Conference/Submission20196/Reviewer_aLWK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20196/Reviewer_aLWK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20196/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761807168391, "cdate": 1761807168391, "tmdate": 1762933700093, "mdate": 1762933700093, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the problem of probability calibration in FL. The motivation of the work is based on the observation that the porting centralized calibration methods to FL do not work; and local calibrations fit to local data distributions do not generalize well when aggregated reducing the accuracy of the model specially in the non-IID settings. The paper discusses two frameworks for calibration in FL - i) FedBinning which is a federated version of the histogram Binning method where clients share per class histograms and the server aggregates them; ii) FedScaling which is a federated version of the scaling method which are trained similarly to FedAvg . Both these methods can be used for multi-class settings using classwise expected calibration error (cwECE). The paper also discusses the privacy preserving versions of these two frameworks using DP."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The work tackles an important FL problem particularly so in real world deployment.\n2. The paper is well written and easy to follow.\n3. The proposed solution are easy to implement on top of existing methods and seem to have better calibration.\n4. Both private and non-private versions of the methods are discussed."}, "weaknesses": {"value": "1. The novelty in the solution stems from adapting the existing calibration methods for the FL settings with somewhat simpler changes.\n2. There is little formal analysis if why these mechanisms would work under heterogeneity."}, "questions": {"value": "1. How would the method perform under the different degrees of class imbalance across clients, for example when some classes are entirely missing from some clients?\n2. How would the method compare to train time calibration methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uWLJBsvfyG", "forum": "5ystL0PeGx", "replyto": "5ystL0PeGx", "signatures": ["ICLR.cc/2026/Conference/Submission20196/Reviewer_JRNY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20196/Reviewer_JRNY"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20196/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761939222977, "cdate": 1761939222977, "tmdate": 1762933699821, "mdate": 1762933699821, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles post-hoc calibration for FL using global cwECE, explicitly accounting for user-level DP noise. It explores two families: histogram binning via FedBBQ (server-side weighting and a “single big histogram → merged binners” trick) and federated logit scaling (temperature/vector/matrix) with an order-preserving variant to avoid accuracy loss. In results, FedBBQ provides the best cwECE without DP given sufficient rounds, whereas temperature scaling is the most stable and accuracy-preserving under DP."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Post-hoc calibration is widely deployed in practice, so adapting it to non-IID FL with user-level DP is genuinely useful.\n- The proposed FedBBQ and federated scaling methods are cleanly designed, easy to implement, and empirically effective.\n- The experiments span diverse datasets and baselines and surface actionable insights for research and deployment—for example, binning is sensitive to clipping/noise, while temperature scaling is noise-resilient but can overfit. \n- Ablations are thorough, and the code is released (though I didn’t audit it in detail)."}, "weaknesses": {"value": "- Lack of rigorous theory. The paper lacks statistical analysis for the federated + DP setting. For FedBBQ, there’s no treatment of bias/variance under user-level clipping + Gaussian noise and the merged-bin ensemble. For FedTemp / FedOPVector / FedOPMatrix, there are no envelope bounds or asymptotics showing when parameter averaging (under data heterogeneity and partial participation) approaches the centralized post-hoc optimum.\n\n- DP tuning is under-specified. Binning methods are clip-sensitive (and thus ε-sensitive) in the DP setting, but there’s no privacy-preserving tuning recipe for choosing $C, C^+$ or rounds $T$. \n\n- Systems reporting is thin. The paper would benefit from concrete bytes/round, client FLOPs, and wall-clock measurements to substantiate the “lightweight” claim and guide deployments."}, "questions": {"value": "- Can you provide statistical analysis for FedBBQ under user-level DP with merged bins (bias/variance, consistency), and a convergence/optimality note for FedTemp / FedOPVector / FedOPMatrix under heterogeneity? To me, averaging a single temperature calibration merely flatten the model's confidence, when does this parameter-averaging strategy work and when doesn't? \n- What privacy-preserving recipe do you recommend to tune this hyperparameter, especially for FedBBQ. \n- For scaling methods, each client learns its own parameters before aggregation—what do per-client calibration metrics look like pre- and post-federation? Any notable variance across clients?\n- Order-preserving guarantees protect top-1 accuracy; do you observe improvements (or regressions) in top-k calibration or ranking metrics (e.g., AUROC, AUPRC) after calibration? Any training strategy or Architecture can preserves top-k ordering? \n- Have you evaluated on larger, modern models/datasets (e.g., ViT/ResNet-50)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HaJhMujrxj", "forum": "5ystL0PeGx", "replyto": "5ystL0PeGx", "signatures": ["ICLR.cc/2026/Conference/Submission20196/Reviewer_AaLR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20196/Reviewer_AaLR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20196/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762243521650, "cdate": 1762243521650, "tmdate": 1762933699476, "mdate": 1762933699476, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Revised Paper"}, "comment": {"value": "Dear reviewers,\n\nThank you for your constructive comments. We have uploaded a new revised version of the paper with changes highlighted in red. We have made the following modifications using the allotted extra page to address feedback:\n* We have run a new set of experiments (Table 4) and added associated discussion to Section 5, comparing our approaches against 4 train-time methods adapted to the FL setting. We find that our post-hoc calibrators outperform train-time methods, and as observed in prior work, the best calibration occurs when combining train-time with post-hoc. This highlights the importance of studying post-hoc calibration in FL.\n* We have moved a version of our computation and communication overhead results to the main paper (Table 5) to highlight the client overheads for post-hoc calibration and added associated discussion to Section 5.\n* We have added two new tables to the Appendix (Tables 8 & 9) which display statistics about clients local data as heterogeneity is varied to answer some reviewer comments."}}, "id": "mP9ZSb3a69", "forum": "5ystL0PeGx", "replyto": "5ystL0PeGx", "signatures": ["ICLR.cc/2026/Conference/Submission20196/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20196/Authors"], "number": 9, "invitations": ["ICLR.cc/2026/Conference/Submission20196/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763635436751, "cdate": 1763635436751, "tmdate": 1763635436751, "mdate": 1763635436751, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}