{"id": "Ck1Gqb6ceb", "number": 486, "cdate": 1756742233336, "mdate": 1759898258143, "content": {"title": "Protocode: Prototype-Driven Interpretability for Code Generation in LLMs", "abstract": "Since the introduction of Large Language Models (LLMs), they have been widely adopted for various tasks such as text summarization, question answering, speech-to-text translation, and more. In recent times, the use of LLMs for code generation has gained significant attention, with tools such as Cursor and Windsurf demonstrating the ability to analyze massive code repositories and recommend relevant changes. Big tech companies have also acknowledged the growing reliance on LLMs for code generation within their codebases. Although these advances significantly improve developer productivity, increasing reliance on automated code generation can proportionally increase the risk of suboptimal solutions and insecure code. Our work focuses on automatically sampling In-Context Learning (ICL) demonstrations which can improve model performance and enhance the interpretability of the generated code. Using AST-based analysis on outputs from the MBPP test set, we identify regions of code most influenced by the chosen demonstrations. In our experiments, we show that high-quality ICL demonstrations not only make outputs easier to interpret but also yield a positive performance improvement on the pass@10 metric. Conversely, poorly chosen ICL demonstrations affected the LLM performance on the  pass@10 metric negatively compared to the base model. Overall, our approach highlights the importance of efficient sampling strategies for ICL, which can affect the performance of the model on any given task.", "tldr": "", "keywords": ["Code generation in LLMS", "Interpretability", "prototype", "In-context learning"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ab47d7bc57eb839c8e075ab7b01c89b22ae01236.pdf", "supplementary_material": "/attachment/b2456004c7adb98511564c7fb62c09b59c5329da.zip"}, "replies": [{"content": {"summary": {"value": "This paper explores automatic selection of in-context learning (ICL) examples for code generation.\nThe method analyzes AST structures to identify influential code regions, performs clustering based on these structural cues, and uses representative prototypes to construct ICL contexts."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- Addresses a practical and timely problem—automatically identifying effective ICL examples for code generation.\n\n- Leveraging abstract syntax trees provides a structured, semantics-aware notion of code similarity."}, "weaknesses": {"value": "- Methodological clarity: The procedure for prototype selection—an important step within the overall clustering framework—is described indirectly and spread across several sections (e.g., L145–147, L997–999).\nConsolidating these details into one cohesive subsection or including pseudo-code would make the approach clearer and easier to reproduce.\n\n- Evaluation scope:\nWhile prototypes are defined per programming language, experiments focus solely on Python.\nClarifying whether the clustering was performed cross-language or language-specific would help interpret generalizability.\n\n- Overall performance:\nThe reported Codellama-7B Pass@1 (≈ 2.4–3.0) is much lower than commonly reported results on MBPP / MBPP+ (≈ 47–57) [1].\nThis substantial gap suggests that the experimental setup or evaluation procedure may need to be revisited.\n\n- Static ICL selection:\nThe method appears to rely on a fixed set of in-context examples independent of the input query, which limits adaptivity and may understate performance.\n\n- Representation choice:\nDecoder-only hidden states are optimized for next-token prediction rather than holistic semantics, which can limit clustering or retrieval quality when reused as embeddings [2].\n\n[1] https://evalplus.github.io/leaderboard.html\n\n[2] Parishad BehnamGhader, Vaibhav Adlakha, Marius Mosbach, Dzmitry Bahdanau, Nicolas Chapados, & Siva Reddy (2024). LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders. In First Conference on Language Modeling."}, "questions": {"value": "- Please provide a concise diagram summarizing clustering and prototype retrieval steps.\n\n- Check the evaluation setup with standard MBPP / MBPP+ protocols.\n\n- Extend experiments (or discussion) to cross-language settings to validate broader applicability.\n\n- Compare static vs. query-adaptive selection to see how dynamic retrieval might help.\n\n- Motivate embedding choices and their implications for clustering quality.\n\n- Substantiate interpretability claims with qualitative or human-study examples illustrating AST-based influence."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vQG40fqqku", "forum": "Ck1Gqb6ceb", "replyto": "Ck1Gqb6ceb", "signatures": ["ICLR.cc/2026/Conference/Submission486/Reviewer_pk5F"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission486/Reviewer_pk5F"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission486/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761545231523, "cdate": 1761545231523, "tmdate": 1762915529241, "mdate": 1762915529241, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present ProtoCode a method for automatically sampling In-Context Learning demonstrations in order to improve the performance of coding models, as well as the interpretability of generations. A novel AST-based analysis identifies regions of code most influenced by the in context samples. The method combines piecewise-linear manifold learning with proxy-anchor metric learning to automatically sample high-quality ICL samples. This approach produces ICL samples that capture local data structures and are semantically meaningful. Additionally, for interpretability they map prototype-gradient attribution to ASTs, which avoids storing the full token probability distribution. In the experiments, the authors evaluate their approach on the MBPP dataset using 6 different LLMs, showing modest improvements in pass@10 metrics while enabling syntax-grounded explanations of which code regions are most influenced by the chosen demonstrations."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The related work and review of prior work is well written and clearly places the current methods within literature.\n- The evalaution setup spans 6 models, including both general-purpose and code-specific models. The experimental setup supports a reasonable generalizability of their approach. Likewise, the baselines include no ICL, similarity-based samples, diversity-based samples, MBPP provides samples which gives a good comparison. However, I would like to see these baseline methods introduced in the main section of the paper with, perhaps, more details on them left to Appendix.\n- The ablation study from the Figures in Section C demonstrate sensitivity analysis across 8 hyperparameters.\n- Experimental confounders (e.g., santization) and mentioning limitations, such as those discussed in `B.5`, are important to detail for reader and good to see.\n- The care take around reproducibility is great — the appendices include extensive implementation details."}, "weaknesses": {"value": "- The presentation could be improved, specifically a figure to help readers grasp the high-level approach and novelty of the method. \n- Additionally, it's difficult to grasp the core message from the current figures. Some additional context, especially in results figures like Figure 3 and Table 1 to clearly state what is being shown and why it is significant, and the axes must be labeled.\n- The performance gains seem modest (but consistent! Prototypes is best or 2nd best for all models), however it may just be that the gains are difficult to assess since none of the models perform super well on MBPP.\n- The experiments lack any statistical significance. Table 1 doesn't include confidence intervals, and Figure 3 lacks error bars and is difficult to compare the results. Given that the performances for all models are low, do the results mean very small differences in correctness (e.g., only a handful of samples as being correct/incorrect between the different models)?\n- For the Interpretability task it's difficult to assess the signficance without some level of human evaluation or major qualitative evaluation of the results (or how it might compare)."}, "questions": {"value": "1. Can you clarify why piecewise-linear manifold learning is necessary. Would simpler methods like PCA suffice?\n2. Do you have any intuitions for why similarity-based sampling outperforms your method for Llama3.2?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "f8553qyeEZ", "forum": "Ck1Gqb6ceb", "replyto": "Ck1Gqb6ceb", "signatures": ["ICLR.cc/2026/Conference/Submission486/Reviewer_5nLH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission486/Reviewer_5nLH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission486/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761857884007, "cdate": 1761857884007, "tmdate": 1762915529090, "mdate": 1762915529090, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Motivated by the lack of faithful interpretability in existing methods, the authors propose ProtoCode, which is a prototype-based in-context learning (ICL) sampling approach grounded in manifold learning and metric learning. Their method automatically selects representative demonstrations (“prototypes”) that are geometrically consistent and semantically discriminative. Using gradient-based attribution between prototype and token embeddings, the approach maps influence scores to Abstract Syntax Tree (AST) nodes, yielding syntax-grounded explanations at both local (node-level) and global (category-level) scales. Experiments across six models on MBPP and MBPP+ benchmarks show that prototype sampling consistently improves pass@10 accuracy compared to other baselines. The AST analysis further reveals consistent confidence alignment between prototype influence and key syntax categories (e.g., functions, scope, data structures). The study concludes that prototype-driven interpretability provides both efficiency and explanatory power for code generation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Unlike previous work focusing solely on accuracy, the proposed method is designed to improve both the interpretability of model behavior and the quality of code generation by selecting meaningful in-context examples.\n2. The paper integrates piecewise-linear manifold learning with proxy-anchor metric learning in a unified framework, allowing prototypes to capture both geometric structure and semantic distinctions within the data.\n3. The paper introduces a prototype–token gradient attribution mechanism that links each prototype to specific parts of the generated code. This allows the model to produce syntax-aware and transparent explanations of its behavior.\n4. The AST-based evaluation examines interpretability across syntax categories such as decisions, iterations, and exception handling. It gives a detailed view of how different components of a program are influenced by the model.\n5. The approach is grounded in the manifold hypothesis and metric learning theory. It provides a clear and mathematically supported explanation of how prototypes are formed and applied."}, "weaknesses": {"value": "1. The paper lists four baseline sampling strategies — base, diversity, similarity, and mbpp — in Tables 1 and 2, but provides no explanation of how these baselines are implemented or what criteria they use to select in-context examples.\n2. The baseline performance reported in the paper are much lower than the official performance numbers for the same models. This difference suggests possible issues in the evaluation setup. For example, the paper shows Qwen3-0.6B reaching only 1.1% pass@1 and 4.8% pass@10 on MBPP (Table 1) under the “base” setting. In contrast, the official Qwen-2.5 technical report (page 8, Table 8, https://arxiv.org/pdf/2505.09388) reports 36.6% for the Qwen3-0.6B model under a 3-shot MBPP setting. The same issue appears for CodeLlama-7B, which achieves only 2.1% pass@1 and 11.6% pass@10 under the “base” setting in this paper, while the CodeLlama report (page 6, Table 2, https://arxiv.org/pdf/2308.12950) shows 41.4% pass@1 and 61.7% pass@10. These large differences suggest that the evaluation in this paper does not align with standard MBPP protocols and may undervalue the true baseline capability of the models. \n3. While the paper notes that poor prototypes can degrade performance, it does not include qualitative examples showing when or why the prototype selection fails. This omission weakens understanding of the method’s limitations\n4. Although syntax categories are analyzed, the paper never discusses whether higher syntax confidence correlates with better code correctness, leaving the relationship between interpretability and performance unverified"}, "questions": {"value": "1. A major concern lies in the evaluation results presented in Section 4. Some implementation details appear missing, which makes it difficult to interpret the reported numbers. Could the authors clarify how the evaluation was conducted and how each baseline was implemented? How those number were calculated?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0XzDMk4OSz", "forum": "Ck1Gqb6ceb", "replyto": "Ck1Gqb6ceb", "signatures": ["ICLR.cc/2026/Conference/Submission486/Reviewer_PC6h"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission486/Reviewer_PC6h"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission486/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761880344156, "cdate": 1761880344156, "tmdate": 1762915528894, "mdate": 1762915528894, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces PROTOCODE, a prototype-driven framework that enhances interpretability in large language models (LLMs) for code generation. Specifically, the method can automatically sample in-context learning (ICL) demonstrations through a joint manifold–metric learning framework. Moreover, the method combines it with AST-grounded prototype attribution to identify syntactic regions of generated code most influenced by specific prototypes."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea is interesting, compared to previous works, which focused on either attribution or syntactic structure, this work connects them via prototype influence scores.\n2. The author provides extensive experiments, covering 6 LLMs and two datasets. Moreover, the AST-based interpretability analysis is detailed and interpretable, showing how models differ in their syntactic confidence across categories like functions, iteration, and exception handling"}, "weaknesses": {"value": "1. The evaluation metrics for the paper are not sufficient. While the author emphasizes the method's interpretability, the main evaluation focuses on syntactic confidence distributions rather than on whether the attributions faithfully reflect the model’s internal causal mechanisms. Specifically, the author didn't provide sufficient evidence to support the experiment's results. To provide stronger evidence of the methods' interpretability, the author should include additional ablation studies. For example, in section 5.2, the author shows that Qwen exhibits highly consistent confidence across all syntax categories, then the author should test if we remove these categories from the prototypes and regenerate the same code and see whether the results change a lot. \n2. It is better to provide more intuitive explanations to describe why the architecture is designed. For example, in section 3.4, the author provides only the loss function without explaining why it is designed this way. \n3. Some small weakness: the figure can be further improved, like figure 2, some words are out of the box. For Figure 3, I don't understand why the author split the 6 LLMs into 3 subfigures rather than drawing 1 figure that would help the reader better compare them."}, "questions": {"value": "If the author can provide more ablation studies to prove its $\\textbf{interpretability}$, I would like to raise my score. Current results cannot fully demonstrate the methods' contribution."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UcqLk8eOk4", "forum": "Ck1Gqb6ceb", "replyto": "Ck1Gqb6ceb", "signatures": ["ICLR.cc/2026/Conference/Submission486/Reviewer_i6KR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission486/Reviewer_i6KR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission486/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762048206438, "cdate": 1762048206438, "tmdate": 1762915528648, "mdate": 1762915528648, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}