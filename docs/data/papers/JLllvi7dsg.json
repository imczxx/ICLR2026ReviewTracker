{"id": "JLllvi7dsg", "number": 16429, "cdate": 1758264418689, "mdate": 1763456701041, "content": {"title": "Faster Parameter-Free Regret Matching Algorithms", "abstract": "Regret Matching (RM) and its variants are widely employed to learn a Nash equilibrium (NE) in large-scale games. However, most existing research only establishes a theoretical convergence rate of $O(1/\\sqrt{T})$ for these algorithms in learning an NE. Recent studies have shown that smooth RM$^+$ variants, the advanced variants of RM, can achieve an improved convergence rate of $O(1/T)$. Despite this improvement, smooth RM$^+$ variants lose the parameter-free property, i.e., no parameters that need to be tuned, a highly desirable feature in practical applications. In this paper, we propose a novel smooth RM$^+$ variant called Monotone Increasing Smooth Predictive Regret Matching$^+$ (MI-SPRM$^+$), which retains the parameter-free property while still achieving a theoretical convergence rate of $O(1/T)$. To achieve these properties, MI-SPRM$^+$ employs a technology called Adaptive Regret Domain (ARD), which ensures that the lower bound for the 1-norm of accumulated regrets increases monotonically by adjusting the decision space at each iteration. This design is motivated by the observation that the range of step-sizes supporting the $O(1/T)$ convergence rate in existing smooth RM$^+$ variants is contingent on the lower bound for the 1-norm of accumulated regrets. Experimental results confirm that MI-SPRM$^+$ empirically attains an $O(1/T)$ convergence rate.", "tldr": "We propose the first parameter-free Regret Matching algorithm achieving an  $O(1/T)$ convergence rate in learning Nash equilibra.", "keywords": ["Regret Matching", "Parameter-Free", "Nash Equilibrium"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3eed5fb5ea25069d833f7f377e7ebe0021bd492d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a smooth regret matching+ variant called Monotone Increasing Smooth Predictive Regret Matching+ (MI-SPRM+), which retains the O(1/T) convergence guarantee of current SOTA methods, while also being parameter-free. To achieve this, the authors introduce the Adaptive Regret Domain (ARD) method, which relies on the insight that the range of permissible stepsizes depends on the lower bound of the 1-norm of accumulated regrets. MI-SPRM+ dynamically adjusts the decision space after each iteration, ensuring that the lower bound monotonically increases and recovering the O(1/T) convergence property. Experiments show that MI-SPRM+ exhibits the theoretical convergence rate in standard benchmark games, and seems to outperform other existing methods in terms of duality gap."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is fairly well written, and the motivation of reducing the parameters required for tuning (especially for solving large games) is sound.\n- The technical contribution and insight behind the ARD method is strong, resulting in a main theoretical result that successfully obtains strong convergence rates while being parameter free.\n- The experimental results are surprisingly strong, particularly in EFGs, showing faster convergence than all prior approaches. Exploring this behavior is a crucial step for future work."}, "weaknesses": {"value": "- The algorithm description for MI-SPRM+ is very densely written, and some more intuition would greatly improve the readability of this work.\n- The paper presents a single convergence guarantee for NFGs, but it would be improved if a similar result can be shown for EFGs, even in the non-CFR variant (i.e. MI-SPRM+ directly applied to the sequence form representation of the EFG). If anything, the fact that MI-SPCFR+ seems to outperform SOTA methods makes it all the more compelling to see if there is some theoretical reasoning for this. \n- While the paper shows a comparison between the compute times of the main algorithms implemented, I believe more discussion or experiments could help clarify the relationship between 1) convergence rate in terms of duality gap and 2) compute time required. In particular, it seems that MI-SPRM+ achieves parameter freeness by incurring additional adaptive steps in the process. It is however not made clear to the reader what the computational cost of parameter tuning actually is (for instance in the case of SPRM+). It seems that the parameter tuning for SPRM+ amounted to stepsizes in $\\{0.01, 0.1, 1\\}$ but it is not clear to me if a grid search was performed, and if that would impact the compute times accordingly.\n- The sentence in Line  307: \"Unfortunately, to the best of my knowledge...\" is oddly phrased and could be restructured.\n- \"do\" in Line 48 should be \"are\"."}, "questions": {"value": "- The authors use the phrasing \"even faster than O(1/T) convergence\" several times in the paper, but this is a strong statement to make, given the lack of theoretical justification. Could the faster convergence be attributed to constant factors? I would suggest changing the wording to avoid confusing readers who might misconstrue the complexity of MI-SPRM+.\n- In Fig 7, we see that for some games, the value of $R^t$ seems to plateau then subsequently grow as the number of iterations increases. Is there some intuition for what this means? Would this imply that the algorithm shifts to a different NE, since the decision space changes after some period of stability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "OeyNxZXClP", "forum": "JLllvi7dsg", "replyto": "JLllvi7dsg", "signatures": ["ICLR.cc/2026/Conference/Submission16429/Reviewer_yD2A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16429/Reviewer_yD2A"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16429/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761326488049, "cdate": 1761326488049, "tmdate": 1762926548272, "mdate": 1762926548272, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes MI-SPRM$^+$, a smooth RM$^+$ variant that introduces an adaptive regret-domain floor so that the 1-norm of cumulative regrets grows to a level where the standard stability inequality holds. Once the floor is high enough, the scheme behaves like SPRM$^+$ without requiring tuned step sizes. The main theoretical claim is an $O(1/T)$ rate for a weighted average strategy with weights proportional to the domain floor sequence. Experiments include NFGs and EFGs in both two-player and multiplayer settings, and demonstrates favorable performance of the proposed method, when using uniform averaging for the algorithms compared to."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper studies an important problem of trying to design faster parameter-free regret-matching algorithms for equilibrium computation in games and recover parameter-free behavior while keeping the O(1/T) rate associated with smooth RM+ variants. A simple modification to SPRM+ is provided that achieves O(1/T) convergence for weighted average iterates.  \n\n2. The empirical section is broad. The method is tested in both NFGs and EFGs and compares against common RM-style and OCO baselines."}, "weaknesses": {"value": "1. Notation and presentation need work; there is a lot of inline math in the preliminaries section which makes it difficult to read, and the notation feel excessively verbose.\n2. The experiments only use uniform averaging, which is not particularly interesting from a practical perspective. It is well-established that linear or quadratic averaging should be used, or even the last iterate in some cases.\n3. The experiments do not use alternation. While it is good to test on the simultaneous case to verify the theory, numerical take-aways should most likely be concluded for the alternating variant.\n4. The proposed change does retain parameter-freeness, but it does not retain stepsize-invariance, another property cojectured to be important for RM-based algorithms."}, "questions": {"value": "1. The theoretical result is based on a weighted average of the iterates, which is not standard in decentralized learning settings. While this doesn’t take away from the result, it would be good to emphasize this in the abstract and intro.\n\n2. Why not include alternation and quadratic averaging for the CFR+/predictive CFR+ baselines, as is standard in the literature? These choices often improve empirical performance substantially on the EFGs you report.\n\n3. In Table 1, are the reported times for a fixed number of iterations (1e5?) or for reaching a fixed duality gap?\n\n4. Given that you run experiments for computing NE in multiplayer games (and use duality gap as the potential function), it might sense to not specify the notation/preliminaries section to use 2 players (even though the theoretical work is focused on the 2p0s setting) and let it be more general (some of the notation is already more general).\n\n5. Why is a proof for $O(1/T)$ of SPRM$^+$ given? Isn't that just restating results from Farina et al?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "T25yavClOp", "forum": "JLllvi7dsg", "replyto": "JLllvi7dsg", "signatures": ["ICLR.cc/2026/Conference/Submission16429/Reviewer_G2Xd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16429/Reviewer_G2Xd"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16429/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761847985543, "cdate": 1761847985543, "tmdate": 1762926547611, "mdate": 1762926547611, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new variant of regret matching, called Monotone Increasing Smooth Predictive Regret Matching+ (MI-SPRM+), that enjoys a parameter-free setting and achieves an O(1/T) convergence rate. It differs from SPRM+ by (1) eliminating the need of using \\eta, the step size of accumlating regret and (2) introduce an adaptaive scheduling of R^t, a lower bound of the regret values. The authrors also present relevant experimental results."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The technical contribution is sound."}, "weaknesses": {"value": "The experiments lack important baselines."}, "questions": {"value": "I think MI-SPRM+ is neat and achieving a provable O(1/T) convergence rate is great. My biggest concern is about the experiments on EFG: It would be great if baselines like CFR+ and DCFR is included."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "pWGfK6fl9r", "forum": "JLllvi7dsg", "replyto": "JLllvi7dsg", "signatures": ["ICLR.cc/2026/Conference/Submission16429/Reviewer_VUBu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16429/Reviewer_VUBu"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16429/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926294058, "cdate": 1761926294058, "tmdate": 1762926546686, "mdate": 1762926546686, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Monotone Increasing Smooth Predictive Regret Matching+ (MI-SPRM+), a novel variant of regret matching (RM) that simultaneously achieves two highly desirable but previously incompatible properties in the RM family:\n\nParameter-free: The algorithm requires no hyperparameter tuning (e.g., step size), making it robust and practical for real-world deployment.\nO(1/T) theoretical convergence rate to Nash equilibrium in two-player zero-sum normal-form games (NFGs).\nTo our knowledge, this is the first RM-based algorithm that attains both properties. Prior smooth RM+ methods (e.g., SPRM+, Farina et al., 2023) achieve O(1/T) convergence but lose parameter-freeness due to their dependence on a carefully tuned step size η. In contrast, classical RM+ and PRM+ are parameter-free but only guarantee O(1/√T) rates.\n\nThe key technical innovation is the Adaptive Regret Domain (ARD) mechanism, which dynamically expands the lower bound of the decision space (i.e., the 1-norm of accumulated regrets) to ensure the conditions for O(1/T) convergence are eventually satisfied—without any user-specified parameters. This approach is conceptually distinct from existing parameter-free methods like DS-OptMD, which adaptively shrink the step size and suffer from slow empirical convergence."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "A rigorous theoretical analysis proving the O(1/T) convergence of the weighted average strategy under MI-SPRM+.\nComprehensive experiments on NFGs and extensive-form games (EFGs), showing that MI-SPRM+ consistently outperforms state-of-the-art baselines—including SPRM+ with optimally tuned η—in both convergence speed and final solution quality.\nEmpirical validation that the algorithm achieves O(1/T) (or faster) rates in practice across diverse game settings.\nOverall, the work makes a clear and meaningful contribution to the regret minimization literature by resolving a concrete limitation in existing RM algorithms, with both theoretical depth and practical relevance."}, "weaknesses": {"value": "1) Larger-scale game benchmarks: The experiments are conducted on standard small to medium-sized games (e.g., Kuhn/ Leduc Poker, random NFGs). To better demonstrate the algorithm’s scalability and practical relevance, it would be valuable to include results on larger, more challenging domains—such as a heads-up no-limit Texas Hold’em (HUNL) subgame, which is commonly used in recent game-solving literature.\n2) Comparison with state-of-the-art CFR variants: The paper compares MI-SPRM+ against PRM+ and SPRM+, but does not include recently proposed advanced CFR algorithms like DDCFR[1] or PDCFR+[2]. Given that these methods also aim to accelerate convergence in EFGs, a direct comparison would help contextualize the empirical advantage of MI-SPRM+ more convincingly.\n\n[1] Xu Hang,et al. Dynamic discounted counterfactual regret minimization.  ICLR 2024.\n[2] Xu Hang,et al. Minimizing weighted counterfactual regret with optimistic online mirror descent. IJCAI 2024."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "V49Rr4arnN", "forum": "JLllvi7dsg", "replyto": "JLllvi7dsg", "signatures": ["ICLR.cc/2026/Conference/Submission16429/Reviewer_CnEQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16429/Reviewer_CnEQ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16429/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980356567, "cdate": 1761980356567, "tmdate": 1762926546029, "mdate": 1762926546029, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}