{"id": "6wLuhRh98p", "number": 5908, "cdate": 1757945287480, "mdate": 1762969108455, "content": {"title": "CARE: Causal Intervention and Adversarial Learning for Robust Multimodal Intent Recognition", "abstract": "Multimodal Intent Recognition (MIR) plays a key role in advancing human-computer interaction, yet its reliability is often challenged by spurious correlations and missing modalities in real-world data. Existing approaches, which mainly rely on complex fusion architectures or contrastive alignment, generally do not account for the underlying causal structures of multimodal signals, resulting in limited generalization and robustness. They typically treat missing modalities as a data issue addressed by passive imputation rather than an opportunity to learn deeper, causally-informed representations. To address these limitations, we propose the Counterfactual Adversarial Representation Enhancement (CARE) framework, which reframes MIR as a causal learning problem. CARE implements causal principles through two complementary modules: a counterfactual generation module that interprets modality completion as a causal intervention to capture shared, abstract concepts across modalities, and an adversarial de-confounding mechanism. The latter employs a Gradient Reversal Layer and a modality discriminator to remove the confounding effects of the modality combination, enforcing the learning of intervention-invariant representations. This dual approach ensures that the learned intent features are both robust to missing data and causally consistent. We evaluate CARE extensively on the MIntRec and the more challenging MIntRec2.0 datasets. Results show that CARE achieves state-of-the-art performance, surpassing the strongest baseline by up to 4.41% in WF1 and 12.03% in recall, while maintaining high robustness under various missing-modality scenarios. This work introduces a principled paradigm for building causally robust multimodal systems, providing a systematic way to mitigate confounding bias and improve generalization in complex, real-world interactive environments.", "tldr": "", "keywords": ["Multimodal Learning; Causal Inference; Adversarial Learning; Representation Learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/8767bc213aeeba2762e2ca36d0116861a60f61a0.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes CARE for multimodal intent recognition (MIR). CARE combines (1) a counterfactual generation module that synthesizes missing-modality features, (2) adversarial de-confounding via a gradient-reversal discriminator to remove dependence on the modality-availability indicator, and (3) a dynamic attention fusion block. Experiments on MIntRec and MIntRec 2.0 report gains (notably in recall on MIntRec 2.0), ablations for each component, and robustness to synthetic noise."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "+ Clear problem framing (robust MIR under missing modalities).\n+ Figures, algorithms, and training details are generally clear.\n+ Ablations indicate each component contributes to the final performance."}, "weaknesses": {"value": "- The evaluation is missing simpler baselines that would help justify the framework's complexity. While CARE is compared to strong MIR methods, it is unclear if the complex counterfactual generator is necessary. A simpler baseline, such as using modality dropout or a basic imputation method combined with the DAF and adversarial de-confounding, would be crucial for demonstrating the specific value of the generation module.\n- The generator seeds plus projection networks create plausible substitutes, but the paper does not verify whether generated features preserve label-conditional structure (e.g., calibration of class-conditional likelihoods, cycle-consistency, or causal faithfulness checks). This weakens the central claim that CARE captures “intervention-invariant” semantics.\n- Reported improvements (often ~1–2% on MIntRec; larger recall gains on MIntRec 2.0) lack variance estimates or statistical tests.\n- Very minor: The image source in Figure 1 is captioned as \"The Big Bang Theory\", but the character seems to be from the sitcom \"Friends.\""}, "questions": {"value": "(1) Does the counterfactual generator require complete, all-modality samples to learn its \"what-if\" synthesis? If so, how would the method be trained on datasets where certain modality combinations are entirely absent?\n\n(2) The adversarial de-confounding relies on a discriminator for 7 modality combinations. How is this approach expected to scale to scenarios with more than 3 modalities (e.g., 5 or 10), where the number of combinations ($2^N - 1$) would grow exponentially?\n\n(3) What specific design choices or assumptions make the generated features \"counterfactual\" (implying a causal what-if scenario) rather than simply \"imputational\" (a statistical best-guess for missing data)?\n\n(4) How sensitive are results to generator design (seed size, architecture) and GRL weight α/β across seeds?\n\n(5) The added components (generator, discriminator) seem likely to increase the model's size and inference time. Could you provide the inference-time cost (e.g., latency or GFLOPs) and total parameter count relative to the baselines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jFhbdRWi9Q", "forum": "6wLuhRh98p", "replyto": "6wLuhRh98p", "signatures": ["ICLR.cc/2026/Conference/Submission5908/Reviewer_xoYK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5908/Reviewer_xoYK"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5908/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761942006743, "cdate": 1761942006743, "tmdate": 1762918342454, "mdate": 1762918342454, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "6UR8mN6jed", "forum": "6wLuhRh98p", "replyto": "6wLuhRh98p", "signatures": ["ICLR.cc/2026/Conference/Submission5908/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5908/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762969107662, "cdate": 1762969107662, "tmdate": 1762969107662, "mdate": 1762969107662, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes CARE for Multimodal Intent Recognition (MIR) with missing modalities. CARE combines:\n- (i) a counterfactual generation module that synthesizes features for absent modalities using modality-specific projections plus a learnable seed tensor, and \n- (ii) adversarial de-confounding via a gradient reversal layer (GRL) to make the pooled representation invariant to the modality-combination indicator M. \n\nA Dynamic Attention Allocation Fusion (DAF) module integrates observed and generated features; the total loss adds task cross-entropy, adversarial loss, and a counterfactual consistency KL term computed by masking one modality on fully observed samples. Experiments on MIntRec and MIntRec2.0 report SOTA results."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **Clear causal framing and implementation**. The paper formalizes M (which marks which modalities are present or generated) as a confounder and enforces $Y \\perp M \\mid Z_{\\text{pooled}}$ via GRL—grounded in domain-adversarial training (DANN). The causal graph and the invariance objective are explicit, and the two-stage training (robustness pre-train then fine-tune) is well described.\n- **Simple yet effective counterfactual generator**. The generation module is lightweight but yields the largest gains in ablations.\n- **Stress tests and missing-modality matrix**. Cross-scenario results (all 7 modality configurations) and Gaussian-noise stress tests support the robustness claim; the per-component ablations are informative."}, "weaknesses": {"value": "- **Causal assumption on $M$ may be over-strong**. CARE treats $M$ as a confounder. I wonder if this holds true in every circumstance. E.g. in MIR, missingness can be informative (e.g., some intents surface mainly via audio/vision cues). Forcing invariance to $M$ may suppress predictive signals or induce negative transfer; the paper lacks diagnostics (e.g., mutual information $I(Z,M)$, or performance when $M$ is truly informative).\n- **Limited set of baselines for robustness**. Besides four MIR baselines, the study omits invariance methods (e.g., IRM, GroupDRO) and missing-modality adaptation approaches that could be competitive under incomplete inputs. Including one such baseline would strengthen claims of causal robustness (e.g. [1]).\n- **Scope of datasets**. Both benchmarks are from the same family (E.g. MIntRec, MIntRec2.0). This is somehow restrictive. Broader evaluation (e.g., other multimodal dialogue datasets) would better evidence generalization.\n- **Fairness/implementation details**. The Authors involve set of dedicated unimodal encoders -- E.g. text uses BERT-large fine-tuning, while video is a custom transformer, ... It’s unclear whether baselines were matched for encoder capacity and pretraining, leading to potential bias in selecting these as encoders.\n\n[1] Arjovsky, Martin, et al. \"Invariant risk minimization.\" arXiv preprint arXiv:1907.02893 (2019)."}, "questions": {"value": "Please refer to Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZS0b3vT8ci", "forum": "6wLuhRh98p", "replyto": "6wLuhRh98p", "signatures": ["ICLR.cc/2026/Conference/Submission5908/Reviewer_yNqJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5908/Reviewer_yNqJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5908/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761950596494, "cdate": 1761950596494, "tmdate": 1762918342014, "mdate": 1762918342014, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper attempt to do robust multimodal intent recognition by applying causal intervention. The basic causal model in the draft is that the modality availability variables causes the label $Y$ as well as the pooled feature $Z_{\\text{pool}}$, and consider the modality availability variable as a confounder. From causality's perspective, I highly doubt the proposed model. First of all, confounder should be a latent variable in the context of causality, while the modality availability variable, I guess, should be observable. Second, how can we justify that modality availability variable is a cause of true label Y? \n\nThere is a so-called counter-factual module in the overall model. Is that really counter-factual? How do you recover the latent variable and then do the intervention on the latent variable to achieve counter-factual? How do you ensure the consistency of the recovered latent variable against the true latent variable?"}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "I believe the causal model in the paper should be considered as ``not even wrong''."}, "weaknesses": {"value": "The basic model needs to be justified and it is highly likely to be wrong. Thus the paper is not really doing any intervention or counter-factual using a causal model.\n\nFor example, in Section 3.4, the authors claims that they are doing counterfactual, and they are generating features for missing modality. In the so-called ``causal`` graph, the authors thinks that modality will have effects on the $Z_{pool}$. Thus for the counterfactual, the authors should try to solve the problem of ''what if we have observed the modality, how would the feature $Z_{pool}$ and label $Y$ like''. Thus if the ``causal`` model in the draft is correct, then observing a modality or not would affect the ground truth label $Y$, and thus it should also affect all the observations in all other modality, otherwise how can the modality availability affect the ground truth label $Y$? The authors just use a generative model to generate features for the missing label, how do you ensure the generated feature align with other observed feature? How do the generated feature affect the ground truth label? \n\nI guess the $Y$ in the ``causal'' model is not the ground truth $Y$, instead it is the predicted $Y$ from the model, which represents the model’s internal belief or approximation of the outcome under the assumed causal mechanism rather than the true data-generating process. In this case, I can hardly view it as a causal model."}, "questions": {"value": "See above summary and weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FH6RzNQ27o", "forum": "6wLuhRh98p", "replyto": "6wLuhRh98p", "signatures": ["ICLR.cc/2026/Conference/Submission5908/Reviewer_577P"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5908/Reviewer_577P"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5908/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995313034, "cdate": 1761995313034, "tmdate": 1762918341058, "mdate": 1762918341058, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}