{"id": "AaC8Tau8NM", "number": 8808, "cdate": 1758098863738, "mdate": 1759897762694, "content": {"title": "ART-VITON: Measurement-Guided Latent Diffusion for Artifact-Free Virtual Try-On", "abstract": "Virtual try-on (VITON) aims to generate realistic images of a person wearing a target garment, requiring precise garment alignment in try-on regions and faithful preservation of identity and background in non-try-on regions. While latent diffusion models (LDMs) have advanced alignment and detail synthesis, preserving non-try-on regions remains challenging. A common post-hoc strategy directly replaces these regions with original content, but abrupt transitions often produce boundary artifacts. To overcome this, we reformulate VITON as a linear inverse problem and adopt trajectory-aligned solvers that progressively enforce measurement consistency, reducing abrupt changes in non-try-on regions. However, existing solvers still suffer from semantic drift during generation, leading to artifacts. We propose $\\textsf{ART-VITON}$, a measurement-guided diffusion framework that ensures measurement adherence while maintaining artifact-free synthesis. Our method integrates residual prior-based initialization to mitigate training-inference mismatch and artifact-free measurement-guided sampling that combines data consistency, frequency-level correction, and periodic standard denoising. Experiments on VITON-HD, DressCode, and SHHQ-1.0 demonstrate that $\\textsf{ART-VITON}$ effectively preserves identity and background, eliminates boundary artifacts, and consistently improves visual fidelity and robustness over state-of-the-art baselines.", "tldr": "A model-agnostic, measurement-guided diffusion framework that treats virtual try-on as a linear inverse problem, ensuring adherence to measurements while producing artifact-free synthesis.", "keywords": ["Image-to-Image Diffusion Model", "Virtual Try-On", "Linear Inverse Problems", "Image Generation"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d5afdc11fc264682e51cb994d96d8f2e832d3397.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes ART-VITON, a measurement-guided latent diffusion framework for artifact-free virtual try-on. The central idea is to recast virtual try-on as a linear inverse problem and introduce a latent diffusion-based inverse solver that incorporates measurement adherence progressively during the sampling process. ART-VITON combines residual prior-based initialization, artifact-free measurement-guided sampling utilizing data consistency and frequency-level correction, and periodic standard denoising."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. Clear Motivation: The paper addresses a well-recognized, often neglected issue in virtual try-on—preserving non-try-on regions and avoiding boundary artifacts between try-on and non-try-on areas. \n2 Sufficient Ablation Study: Ablation studies (Table 5 & 6, Figure 5) provide convincing evidence for their necessity and complementary effects."}, "weaknesses": {"value": "1. The baseline methods does not cover the latest approaches like IDM-VTON[1] or OOTDiffusion[2].\n[1] Improving diffusion models for authentic virtual try-on in the wild.\n[2] Ootdiffusion: Outfitting fusion based latent diffusion for controllable virtual try-on.\n\n2. Limited theoretical novelty in inverse solvers.  Although reducing abrupt changes innon-try-on regions is useful in Try-on, the core of the proposed high-frequency correction is to restrict the editing region with the mask, which is a common technique. It would be much better if the idea of partial editing in LDM is validated in more complex tasks.\n\n3. The overall quality is not good enough for ICLR."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "A7a3q7qKXe", "forum": "AaC8Tau8NM", "replyto": "AaC8Tau8NM", "signatures": ["ICLR.cc/2026/Conference/Submission8808/Reviewer_JK6a"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8808/Reviewer_JK6a"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8808/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761277450564, "cdate": 1761277450564, "tmdate": 1762920578132, "mdate": 1762920578132, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge in Virtual Try-On (VITON) of preserving non-try-on regions and eliminating boundary artifacts in latent diffusion models by reformulating the problem as a linear inverse problem. \n\nThe authors propose ART-VITON, a measurement-guided diffusion framework that ensures measurement adherence using residual prior-based initialization and an artifact-free sampling strategy. \n\nExperiments demonstrate that ART-VITON effectively preserves identity and background, eliminates boundary artifacts, and consistently improves visual fidelity and robustness over state-of-the-art baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Reformulates the virtual try-on task as a **linear inverse problem**, offering a principled approach to handle measurement consistency and reduce boundary artifacts.\n2. Introduces a **measurement-guided diffusion framework** with residual prior initialization and frequency-level correction to ensure artifact-free, identity-preserving synthesis.\n3. Demonstrates consistent performance gains and visual improvements across multiple benchmarks (VITON-HD, DressCode, SHHQ-1.0) compared to state-of-the-art methods."}, "weaknesses": {"value": "1. Several implementation details remain unclear. For instance, Line 64 mentions *“violates measurements (M)”*—it is not explained how **M** is defined or computed. The example showing *t = 835* also lacks justification for this choice, and results for other timesteps are not discussed. Moreover, training details and computational overhead compared to baselines are missing, making it difficult to assess reproducibility and efficiency.\n\n2. The claim of producing *“artifact-free”* results seems overstated. In Figure 1, minor artifacts are still visible, even if reduced compared to baselines. Similarly, Figures 4(b), 8, 9, and 10 show that improvements over baselines are sometimes marginal, suggesting the enhancement is not consistently substantial.\n\n3. The evaluation lacks comparisons with **recent diffusion transformer-based VITON methods**, such as ITA-MDT [1] and IMAGDressing-v1 [2], which would provide a fairer and more comprehensive validation of the proposed plug-and-play module.\n\n[1] *ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On*, CVPR 2025\n\n[2] *IMAGDressing-v1: Customizable Virtual Dressing*, arXiv:2407.12705"}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "dDL7RcywS8", "forum": "AaC8Tau8NM", "replyto": "AaC8Tau8NM", "signatures": ["ICLR.cc/2026/Conference/Submission8808/Reviewer_CHdC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8808/Reviewer_CHdC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8808/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761594601310, "cdate": 1761594601310, "tmdate": 1762920577448, "mdate": 1762920577448, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ART-VITON, a framework for virtual try-on aimed at resolving the boundary artifacts produced by existing methods when preserving non-try-on regions. The paper reformulates VITON as a linear inverse problem, seeking to reconstruct the full image conditioned on the given non-try-on regions (the \"measurement\"). The authors design an \"artifact-free measurement-guided sampling\" strategy that progressively guides the LDM's sampling trajectory during reverse diffusion to match these measurements."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The artifact-free measurement-guided solver combines multiple complementary techniques: (i) a residual prior-based initialization to mitigate the training-inference mismatch , (ii) data consistency to maintain semantic coherence , (iii) frequency-level correction to restore high-frequency details lost during VAE encoding , and (iv) periodic standard denoising to harmonize regions. Furthermore, the framework is model-agnostic, meaning it can be applied to various existing LDM-based VITON models without retraining, consistently improving their performance and demonstrating strong generalization on multiple datasets."}, "weaknesses": {"value": "My primary concern stems from the paper's comparison against post-hoc replacement. The authors motivate their complex measurement-guided sampling framework (ART-VITON) by highlighting the \"abrupt transitions\" and \"boundary artifacts\" produced by standard \"post-hoc replacement\". However, the \"post-hoc replacement\" method described appears to be a naive pixel-wise copy-paste. To my knowledge, methods like CAT-DM[1] have effectively utilized Poisson Blending as a \"post-hoc replacement\"to resolve these exact artifacts. The authors should therefore discuss blending techniques, especially Poisson Blending, to situate their contribution more accurately.\n\nFurthermore, the proposed sampling method seems extremely complex. Each sampling step involves: (1) a VAE decode and encode (Eq. 5), (2) a latent-space optimization (Eq. 6), and (3) both a Fourier Transform and an Inverse Fourier Transform (Eq. 7). This process is almost certainly much slower than standard DDIM sampling or even other solvers like TReg. The authors should include a discussion of the model's inference time and computational overhead.\n\n[1] Zeng J, Song D, Nie W, et al. Cat-dm: Controllable accelerated virtual try-on with diffusion model[C]//Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2024: 8372-8382.\n\n\nFinally, Figure 2, as the main flowchart for the method, is overly dense and difficult to understand."}, "questions": {"value": "Please address the issues raised in the weaknesses section. Including Poisson blending and inference time in the analysis would help address my concerns."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UNb0zfCMnG", "forum": "AaC8Tau8NM", "replyto": "AaC8Tau8NM", "signatures": ["ICLR.cc/2026/Conference/Submission8808/Reviewer_Jd4t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8808/Reviewer_Jd4t"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8808/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761901093289, "cdate": 1761901093289, "tmdate": 1762920577058, "mdate": 1762920577058, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper considers virtual try-on. The focus of this paper is on the improvement in generation of the non-garment regions that should be preserved. The proposed approach adapts the intermediate generated image so that the inpainted and existing regions are mode continuous. At regular intervals during the diffusion process, the predicted latent $\\hat{z}_0^{(t)}$ image is decoded and fused with the masked model image (the masked region comes from the decoded image, the non-masked region comes from the conditioning image). This image is again encoded into a latent $\\hat{z}_y$. To insure consistency, interpolation between $\\hat{z}_y$ and  $\\hat{z}_0^{(t)}$ is done and a further frequency correction is done to preserve detail. This process is interchangeably done with regular diffusion steps for a more stable diffusion process."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "[S1] The proposed approach is inference-time, and may therefore be used to improve existing VTON pipelines. \n\n[S2] Good quantitative and qualitative results."}, "weaknesses": {"value": "[W1] Missing ablations for important choices in the method (e.g. the strength of interpolation in equations 6 and 7, the number of steps for C).\n\n[W2] Prior-based initialization is not novel and I am not completely certain how it relates to reformulating VTON as inverse problem and equation 4.\n\n[W3] I thought that the paper is badly written and difficult to follow. See questions. I also thought some of the naming/symbol conventions made the paper more difficult to follow. For example, naming the masked area as a measurement. A measurement would imply some sort of injection of physical constraints into to model. Similarly, tradinally in VTOM paper M indicates the masked region that should be inpainted, but here it is reversed."}, "questions": {"value": "[Q1] What is being shown by the Figure 3? Is the determination of artefacts quantitative and measurable or just qualitative? How is failure/success determined?  \n\n[Q2] Some elements of the method are not completely clear, e.g. how is $\\hat{z}'_y$ obtained?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4cSuwvrUIx", "forum": "AaC8Tau8NM", "replyto": "AaC8Tau8NM", "signatures": ["ICLR.cc/2026/Conference/Submission8808/Reviewer_LxsW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8808/Reviewer_LxsW"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8808/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762258411817, "cdate": 1762258411817, "tmdate": 1762920576659, "mdate": 1762920576659, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}