{"id": "dTYbqgvZmc", "number": 14067, "cdate": 1758227920008, "mdate": 1759897392580, "content": {"title": "Product of Experts for Visual Generation", "abstract": "Modern neural models capture rich priors and have complementary knowledge over shared data domains, e.g., images and videos. Integrating diverse knowledge from multiple sources—including visual generative models, visual language models, and sources with human-crafted knowledge such as graphics engines and physics simulators remains under-explored. We propose a probabilistic framework that combines information from these heterogeneous models, where expert models jointly shape a product distribution over outputs. To sample from this product distribution for controllable image/video synthesis tasks, we introduce an annealed  MCMC sampler in combination with SMC-style resampling to enable efficient inference-time model composition. Our framework empirically yields better controllability than monolithic methods and additionally provides flexible user interfaces for specifying visual generation goals.", "tldr": "An inference-time sampling framework for image and video generation that compose knowledge from heterogeneous perceptual models.", "keywords": ["generative models", "image generation", "video generation"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1ad7fc3bff05f5bbc64feeb11f8ddab58c69c441.pdf", "supplementary_material": "/attachment/6315e54bc6734f58fa09865c6b27531f1dcf2b89.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces a training-free, probabilistic framework for controllable visual generation by combining heterogeneous pre-trained \"expert\" models (e.g., generative models, discriminative VLMs, and physics simulator software). The core of the method is a novel sampling algorithm that draws from the combined \"Product of Experts\" distribution by interleaving three techniques: Annealed Importance Sampling (AIS) to gradually refine samples from noise, MCMC to ensure fidelity to the generative experts, and Sequential Monte Carlo (SMC) to resample and filter particles. The method is instantiated and evaluated on complex tasks, including graphics-engine-instructed image editing, physics-instructed video generation, and layout-controlled text-to-image synthesis. The results demonstrate superior controllability over baselines, effectively adhering to precise object poses and physics-based motion trajectories while maintaining high visual quality."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper provides a classic and mathematically sound algorithm for combining heterogeneous pre-trained models, including both generative and discriminative experts. The method can generate images and videos with high controllability without extra training.\n\n- The paper demonstrates many instantiations of this framework across different tasks (image editing, video generation, layout control) and expert types (flow models, autoregressive models, VLMs, physics engines), and the proposed method consistently outperforms monolithic baseline approaches.\n\n- The main paper and the appendix provide extensive implementation details, qualitative results, and ablations, which support its claims and reproducibility."}, "weaknesses": {"value": "- The method is inherently slow due to its iterative nature, requiring $T$ annealing steps, $L$ parallel particles, and $K$ MCMC steps per particle. This makes it less practical for real-world GenAI applications, with image generation taking ~4 minutes and video generation taking 5-30 minutes. In my understanding, the proposed method is more like a proof of concept instead of a feasible path for future visual generation frameworks.\n\n- The use of the physics engine can be \"ad-hoc.\" For instance, the autoregressive video task requires the user to provide a full RGB rendering from the simulator. If a user must **manually** create complex 3D renderings or animations in professional software like Blender to serve as a control signal, the practical cost and effort may be prohibitively high."}, "questions": {"value": "Please see the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8LmBXDUG6K", "forum": "dTYbqgvZmc", "replyto": "dTYbqgvZmc", "signatures": ["ICLR.cc/2026/Conference/Submission14067/Reviewer_WhsG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14067/Reviewer_WhsG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14067/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761668841705, "cdate": 1761668841705, "tmdate": 1762924547206, "mdate": 1762924547206, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors proposed a sampling method from a joint of generative models with potential discriminators. Their idea is to apply AIS on the product of generative distributions, then interleave the AIS steps with an SMC reweighting using the discriminators when they are presented. The authors evaluated their method both qualitatively and quantitatively on various visual modalities."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-written and easy to follow.\n2. The proposed method is general and works well with different expert models across different modalities.\n3. The generated results can show better quality against the competing baseline, e.g., in Figure 2 the proposed method preserves the original image more faithfully."}, "weaknesses": {"value": "1. The proposed method is more heuristic than it appears to be. The main novelty is applying some tweaks to well-established sampling methods when discriminators are involved, which work well on the modern large expert models. At some point, this feels like a glorified classifier-based guidance with no theoretical guarantee provided. Maybe the authors can tone down a bit.\n2. The model performance is not always on the better side. This includes both the metrics across the tables and the visual examination such as Figure 5."}, "questions": {"value": "1. The ablation study is a bit limited. How would the vanilla classifier-free guidance and classifier-based guidance perform with all these expert models? This should serve as the baseline for justifying the necessity of the proposed sampling scheme."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wY73xaUWp1", "forum": "dTYbqgvZmc", "replyto": "dTYbqgvZmc", "signatures": ["ICLR.cc/2026/Conference/Submission14067/Reviewer_SGff"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14067/Reviewer_SGff"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14067/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976478056, "cdate": 1761976478056, "tmdate": 1762924546864, "mdate": 1762924546864, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Modern neural models possess complementary knowledge about data like images and videos, but combining this diverse expertise—from generative AI to structured simulators—is still challenging. The authors proposed a probabilistic framework that unifies these heterogeneous models into a single product distribution. For controllable image/video synthesis, the paper introduces an efficient inference-time sampler using annealed MCMC with SMC-style resampling. The proposed method provides superior controllability and more flexible user interfaces than monolithic approaches."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The proposed method achieves visually satisfactory generative results. The paper is well-structured and easy to follow."}, "weaknesses": {"value": "The performance improvements yielded by the proposed approach is kind of small, compared to the benchmarking algorithms, such as Depth2V for the setting of Object-Centric Simulation Input."}, "questions": {"value": "Please refer to weaknesses for my main concerns."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0Ss3SXCWkA", "forum": "dTYbqgvZmc", "replyto": "dTYbqgvZmc", "signatures": ["ICLR.cc/2026/Conference/Submission14067/Reviewer_jLD4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14067/Reviewer_jLD4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14067/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762004904092, "cdate": 1762004904092, "tmdate": 1762924546484, "mdate": 1762924546484, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to solve a critical challenge: given models with rich priors and knowledge over shared data domains, how to effectively integrate this diverse knowledge from multiple sources. The paper proposes an annealed MCMC sampler and SMC resampling for better model composition. The qualitative and visual results show success in both image and video generation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper is clearly presented, with sophisticated structure and logical flow.\n2. It addresses an interesting and significant problem: how to effectively utilize different experts for efficient and controllable visual generation.\n3. The paper presents detailed experimental results, showing improvement compared to baselines.\n4. It also demonstrates strong visual results with clear corresponding explanations."}, "weaknesses": {"value": "Method and motivation — Sections 3.1 and 3.2 emphasize that, to sample from the product of a set of generative experts, the paper uses Markov Chain Monte Carlo to iteratively refine samples based on their likelihood under the product distribution (3.1), and employs AIS and SMC to draw samples from the product-of-experts distribution. However, there still exists concern about the intrinsic sharpness of the product-of-experts energy landscape, even with intermediate tempered distributions and particle resampling weighted by discriminative likelihoods.\nThe overall energy surface can remain highly peaked. There is a chance that particles collapse into narrow regions of high probability, perhaps leading to a drop in effective sample size and poor mixing.\nCan the authors provide more evidence that the proposed framework overcomes the structural difficulty imposed by additive log-likelihoods in the PoE formulation?"}, "questions": {"value": "In Table 2, can the authors provide video quality metrics for analysis? It appears comparatively weak in Aesthetic compared with other baselines; a further explanation (visual or textual) would clarify the results.\nCan the authors also provide more failure cases where the framework does not perform well (in either image or video quality, efficiency, or controllability)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9mytWpNskT", "forum": "dTYbqgvZmc", "replyto": "dTYbqgvZmc", "signatures": ["ICLR.cc/2026/Conference/Submission14067/Reviewer_BVuA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14067/Reviewer_BVuA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14067/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762228375462, "cdate": 1762228375462, "tmdate": 1762924545926, "mdate": 1762924545926, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}