{"id": "DX9UX6rwlJ", "number": 10776, "cdate": 1758181649209, "mdate": 1759897629631, "content": {"title": "ATOM of Understanding: Information-Theoretic Decomposition for Interpretable 3D Question Answering", "abstract": "3D Question Answering remains largely opaque, with existing approaches functioning as black boxes that provide no insight into how different modalities contribute to spatial reasoning. This lack of interpretability limits trust and understanding in critical applications like robotics and autonomous systems. We present ATOM (\\textbf{A}daptive \\textbf{T}ask-aware m\\textbf{O}dular \\textbf{M}odel), the first information-theoretic framework that operationalizes Partial Information Decomposition (PID) to achieve fully interpretable 3D question answering. ATOM explicitly decomposes multimodal interactions into four theoretically-grounded information atoms: redundancy (shared cross-modal information), modality-specific uniqueness (point cloud and image-specific contributions), and synergy (emergent complementary information). Our framework provides transparent reasoning through a Query-driven View Aggregator for geometrically consistent visual features, a Contextual Grounding Module for description-guided visual grounding, a Question-aware PID module with theoretically-grounded regularization, and a Dynamic Atom Modulation mechanism that provides direct, quantifiable interpretability of each atom's contribution. Extensive experiments on ScanQA and SQA3D datasets demonstrate that ATOM achieves the performance comparable to prior work and, to the best of our knowledge, are the first to enable transparency in 3D reasoning. Our analysis reveals that different question types systematically rely on distinct information patterns that align with human spatial cognition.", "tldr": "", "keywords": ["3D Question Answering", "Partial Information Decomposition", "Multimodal Interpretability", "Information-theoretic Decomposition"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/690d01ed9e5cec75bc52e1dad37e374428b35c34.pdf", "supplementary_material": "/attachment/ae9d354c4f60740fae851b606a3e61e594ca2138.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces ATOM (Adaptive Task-aware mOdular Model), a framework for interpretable 3D Question Answering (3D QA) based on Partial Information Decomposition (PID) theory.\nThe authors aim to move beyond “black-box” fusion models by decomposing multimodal interactions into four interpretable information atoms: redundancy, uniqueness (for each modality), and synergy. ATOM integrates several modules:\n\n- Query-driven View Aggregator (QVA) for selecting geometrically relevant views,\n\n- Contextual Grounding Module (CGM) for injecting scene description context,\n\n- Question-aware PID (Q-PID) to decompose multimodal features, and\n\n- Dynamic Atom Modulation (DAM) for question-dependent weighting of these atoms.\n\nExperiments are conducted on ScanQA and SQA3D datasets, with comparisons against 3D QA baselines (e.g., DSPNet, 3DGraphQA, 3D-VisTA). Results show comparable or slightly lower performance than the strongest baselines, with claims of improved interpretability."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Conceptual novelty: The paper presents an interesting attempt to incorporate information-theoretic decomposition (PID) into multimodal QA, a direction that could enrich interpretability research in 3D reasoning.\n2. Clear motivation: The motivation for interpretability in 3D QA—addressing black-box fusion—is well framed and relevant to embodied AI. \n3. Theoretical grounding: The PID formulation (Equations 1–3, page 4) provides a rigorous theoretical foundation."}, "weaknesses": {"value": "1. Weak empirical justification of the proposed theory.\nThe ablation study (Table 3, page 8) shows minimal performance gains for most components. Removing the core PID module (“w/o Q-PID”) leads to only minor drops in ScanQA (22.5 → 23.5 EM@1) and SQA3D (48.76 → 49.71 EM@1). This 0.7–1 point difference is within noise for such datasets, suggesting the proposed information decomposition does not substantively improve task performance.\n\n2. Poor quantitative results compared to state-of-the-art.\n\n3. On SQA3D, ATOM achieves only 49.7 EM@1, below DSPNet’s 50.4.\n\n4. On ScanQA, ATOM’s EM@1 = 26.7 vs. DSPNet = 26.5, but CIDEr and BLEU-4 scores are lower (77.3 vs. 78.1, 15.0 vs. 15.4).\nThese marginal improvements or regressions do not justify the architectural complexity introduced.\n\n5. Ablation design does not convincingly isolate interpretability benefits.\nThe PID components (U1, U2, R, S) are claimed to provide “interpretable decomposition,” but the paper only shows weight histograms (Fig. 4) without human evaluation, visualization of PID contributions, or quantifiable interpretability metrics. The interpretability claims remain qualitative and anecdotal, not scientifically validated.\n\n6. Overly complex framework with minimal gain.\nThe model combines PointNet++, Swin Transformer, SBERT, QVA, CGM, Q-PID, and DAM, introducing a large number of modules, parameters, and hyperparameters. Despite this, the gains are statistically insignificant, raising concerns about over-engineering.\n\n7. Experimental setup not fully convincing.\nThe authors emphasize “no pre-training,” but this makes comparisons unfair since methods like 3D-VisTA and Multi-CLIP rely on pretraining. For a fair comparison, results should be grouped and analyzed under equivalent training regimes."}, "questions": {"value": "1. The claimed interpretability advantage is qualitative. Can the authors provide quantitative metrics or user studies showing that the decomposition indeed improves transparency or error diagnosis?\n\n2. The ablation results (Table 3) show very small gains from adding PID regularization. Can the authors explain how these minimal differences support their claim of “theoretically grounded interpretability”?\n\n3. Could you report statistical significance tests (e.g., confidence intervals or variance) on the EM@1 and EM@10 results to verify that improvements are meaningful?\n\n4. Given the heavy reliance on prior architectures (e.g., DSPNet backbone, MCGR), to what extent does the proposed contribution stand as an independent framework rather than an incremental modification?\n\n5. How does the method scale to open-ended QA or additional modalities (text + depth + point cloud), as briefly mentioned in Appendix B? Any early results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "bXjmabgEsz", "forum": "DX9UX6rwlJ", "replyto": "DX9UX6rwlJ", "signatures": ["ICLR.cc/2026/Conference/Submission10776/Reviewer_DBXe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10776/Reviewer_DBXe"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10776/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761361816486, "cdate": 1761361816486, "tmdate": 1762921987738, "mdate": 1762921987738, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ATOM, an end-to-end 3D question answering framework that incorporates Partial Information Decomposition. The proposed framework produces compatible performance with SOTA methods on ScanQA and SQA3D benchmarks, while providing different information atoms."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed information theoretic components indeed have several loss functions for regularization to make them more compatible with the theories."}, "weaknesses": {"value": "1. Lack of comprehensive analysis of the learned information atoms despite the claim that the proposed framework introduces interpretability.\n\n2. The baseline used for evaluation on SQA3D is not the current best model for this benchmark. For example, the author didn't compare against SID3D [1]\n\n3. Despite using image and point cloud together, the proposed method is not able to provide superior performance compared to single-modal models like 3D-VisTA.\n\n4. The notations in the paper are so much that the paper is hard to follow.\n\n\n[1] Man, Y., Gui, L.Y. and Wang, Y.X., 2024. Situational awareness matters in 3d vision language reasoning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 13678-13688)."}, "questions": {"value": "1. In Ln.19-21 and Ln. 59-61, the author claimed that there are four information atoms whereas in the following sentences and throughout the whole paper there's only three.\n\n2. For the loss term $L_{div}$, why does there exist case where atoms are not used inside a batch? What is the range for the importance weights $\\beta_k$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jTtQMlHpaq", "forum": "DX9UX6rwlJ", "replyto": "DX9UX6rwlJ", "signatures": ["ICLR.cc/2026/Conference/Submission10776/Reviewer_ifgS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10776/Reviewer_ifgS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10776/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761791687289, "cdate": 1761791687289, "tmdate": 1762921987333, "mdate": 1762921987333, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ATOM, an information-theoretic framework to integrate Partial Information Decomposition (PID) into an end-to-end 3D Question Answering (3D QA) model. ATOM emphasizes question-aware decomposition, which is essential for spatial reasoning. The framework comprises 4 key components: the Query-driven View Aggregator (QVA), the Contextual Grounding Module (CGM), the Question-aware PID (Q-PID) module, and the Dynamic Atom Modulation (DAM) mechanism. Validated on the ScanQA and SQA3D datasets, ATOM shows performance that is competitive with or marginally below the current SOTA, while achieving principled interpretability through information-theoretic decomposition."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. ATOM explicitly decomposes multimodal interactions into 4 theoretically-grounded information atoms (redundancy, uniqueness, and synergy) in a question-aware manner. This rigorous decomposition provides transparent reasoning pathways. Furthermore, the model achieves competitive results without requiring external pre-training, enhancing its practical utility.\n2. The experiments successfully validate that ATOM achieves performance comparable to prior work while providing unprecedented interpretability. This makes ATOM a valuable framework for bridging the gap between high-performing end-to-end 3D QA and the demands of explainable AI.\n3.  The framework is clearly explained through a concise overview figure (Fig. 3) and detailed descriptions in Section 3. The authors also commit to providing anonymous source code and comprehensive implementation details in the supplementary materials, enhancing reproducibility."}, "weaknesses": {"value": "1. The placement of figures is suboptimal, with Figure 1 appearing on page 3, one and a half pages after its initial textual mention in the Introduction, and following Figure 2. The manuscript layout could be more logically organized to align figures closer to their first mention.\n2. The incorporation of PID introduces 4 specific regularization losses in addition to the main task loss, making the final objective complex. The authors themselves admit that this explicit information decomposition requires careful hyperparameter tuning, which increases training complexity and engineering effort."}, "questions": {"value": "1. According to Figure 4 (Left), the mean DAM weight distributions for the ScanQA and SQA3D datasets exhibit notably different patterns. Could the authors elaborate on how they reconcile the general conclusions with the significantly different behavior observed between the two datasets, and why the final interpretation seems to align more closely with the SQA3D patterns?\n2. The ablation study in Table 4(b) systematically examines the individual and combined effects of the atoms, showing R, R+S, and the full ATOM. Given the emphasis on the modality-specific Uniqueness atoms U1 and U2 as crucial complementary signals that conventional methods overlook, why was the combined effect of uniqueness U1+U2 or U1/U2-only not included in the ablation study? Including this variant would be highly informative for direct comparison against the baseline w/o Q-PID, R, and R+S, thereby better isolating the contribution of different information atoms in 3D QA."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vzKyM7fff2", "forum": "DX9UX6rwlJ", "replyto": "DX9UX6rwlJ", "signatures": ["ICLR.cc/2026/Conference/Submission10776/Reviewer_woBS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10776/Reviewer_woBS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10776/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761871922259, "cdate": 1761871922259, "tmdate": 1762921986739, "mdate": 1762921986739, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "They attempted to apply Partial Information Decomposition (PID) theory to 3D-QA literature. Based on PID theory, the following information atoms are introduced: redundancy of the shared information between two sources; uniqueness of the evidence contributed by each source individually; and synergy of the complementary information emerging from combination. Their proposed ATOM works in three stages: stage 1 comprises Query-driven View Aggregator (QVA) and  Contextual Grounding Module (CGM),modules; stage 2 is Question-aware PID (Q-PID) that include redundancy, uniqueness and synergy modules; stage 3 is Dynamic Atom Modulation (DAM). Their training loss is the addition of task objective loss and the regularization losses of redundancy, uniqueness and synergy by PID-theory.\n\nIn experiments with ScanQA and SQA3D, their model performed on par with their previous models. They confirmed the effectiveness of each information atom (redundancy, uniqueness and synergy) with the ablation experiment.\n\nOverall, they proposed a model based on an interesting viewpoint of PID theory. Considering the final score, their final model doesn’t necessarily perform better than previous models. However, their approach can be worth further investigating."}, "soundness": {"value": 4}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- S1: Interesting approach to apply Partial Information Decomposition (PID) theory to 3D-QA literature\n- S2: CGM generates two different representations from different perspectives of images and 3D point clouds that are compared in the way of redundancy, uniqueness and synergy by PID-theory.\n- S3: Experimental results suggest the effectiveness of the proposed to some extent.\n- S4: It is interesting that authors provide the variations of architectures (ATOM-MoE and ATOM-Flat) in Table 5."}, "weaknesses": {"value": "- W1: The entire model becomes too complex and it is difficult to grasp how each module processes what kind of information and how it affects others at a glance. This can become an important limitation to further analyze and improve upon this model.\n- W2: The entire performance is mostly in the 2nd place or later in most of ScanQA and SQA3D datasets.\n- W3 (minor): Characters in some figures are too tiny and really difficult to read. (Especially for subscripts in Fig4)."}, "questions": {"value": "See weakness.\nL. 059: four information atoms: three?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zPWebsvwRl", "forum": "DX9UX6rwlJ", "replyto": "DX9UX6rwlJ", "signatures": ["ICLR.cc/2026/Conference/Submission10776/Reviewer_pRt9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10776/Reviewer_pRt9"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10776/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762012561790, "cdate": 1762012561790, "tmdate": 1762921986372, "mdate": 1762921986372, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}