{"id": "xnA1OpoAze", "number": 22479, "cdate": 1758331677058, "mdate": 1759896864012, "content": {"title": "The Mutual Information Uncertainty Range: A Non-Parametric Test for Dependent Censoring", "abstract": "Learning a survival prediction model can be viewed as regression with the added complication of censoring. Each subject $x_i$ has a true event time $E_i$ and a censoring time $C_i$, yet we only observe $T_i = \\min(E_i, C_i)$ and $\\delta_i = \\mathbf{1}(E_i \\leq C_i)$. Many standard survival methods implicitly assume the $E$ and $C$ are independent, conditioned on $X$:  $E \\perp C \\mid X$, which is not always true. To produce effective survival models, it would be useful to know this (in)dependency; however, this is difficult to determine as, for each subject, we observe either $E_i$ or $C_i$, but never both. To address this challenge, we  introduce, for each $t>0$, indicator variables $E_{i,t}\\ =\\ {\\bf 1}( E_i > t )\\ \\in\\ \\lbrace0,1,?\\rbrace$, where `$?$' represents unobserved values due to censoring;  with a similar definition for $C_{i,t}$. \nWe use this set of $\\lbrace E_{i,t}, C_{i,t} \\rbrace$ over the set of instance $i$ and various times $t$, to develop a nonparametric diagnostic for testing whether $E \\perp C \\mid X$,  based on the width of the Conditional Mutual Information (CMI) uncertainty range between $E_{i,t}$ and $C_{i,t}$ given $X_i$ over the unknown values ``$?$'', defined as $\\Delta I^t = I^t_{\\max} - I^t_{\\min}$. Under independence, $\\Delta I^t$ follows a characteristic null distribution from random data completions. Dependent censoring imposes structure, producing atypical $\\Delta I^t$ values. To make this computation feasible, we formulate the CMI bound computation as a decomposable integer program, which we solve exactly with a dynamic programming algorithm of polynomial complexity. Combined with a permutation test, this yields a scalable, assumption-free tool for detecting dependent censoring. To evaluate the performance of the proposed method, we conducted experiments on different types of synthetic data where both the presence and strength of dependence could be controlled.", "tldr": "", "keywords": ["Independent censoring", "Survival analysis", "Conditional mutual information"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5cc81fb4f8cc8816b9c13f15b0d7b2e0f219138d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a non-parametric diagnostic to test whether event and censoring times are conditionally independent given covariates (E \\perp C \\mid X). It discretizes time through binary indicators E_t = 1(E > t) and C_t = 1(C > t), and shows that continuous-time independence implies discrete-time independence for each t. Because censoring induces missing cells in the (E_t, C_t \\mid X) contingency tables, the authors bound the conditional mutual information over all valid imputations to obtain an uncertainty range. A stratified permutation test—using an RSF-based “impute-and-permute’’ null generation and Fisher’s method to aggregate results—yields a global p-value. Experiments on synthetic data show well-calibrated type-I error and sensitivity to dependence strength."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "•\tWell-posed reduction from continuous to discrete testing; Proposition 1 provides a usable contrapositive for rejection.\n\t•\tModel-free: no parametric assumptions on hazards or dependence; operates directly on counts and censoring patterns.\n\t•\tClear and transparent testing pipeline, with detailed algorithms for the ΔI statistic and Fisher aggregation.\n\t•\tSynthetic evaluation spans multiple dependence structures."}, "weaknesses": {"value": "• The work is fundamentally a statistical diagnostic, not a machine learning contribution — it introduces no learning algorithm, representation, or model.\n\t• The “RSF-based imputation” component uses a standard survival model purely as a simulation tool and does not constitute a methodological advance in ML.\n\t• All experiments are synthetic, with no real or large-scale data to demonstrate practical impact or relevance to modern ML pipelines.\n\t• The test outputs p-values rather than learned models or predictive improvements, limiting its applicability within the ICLR context."}, "questions": {"value": "1.\tHow could this diagnostic be integrated into modern machine learning survival pipelines (e.g., DeepSurv, RSF, or neural Cox models) to improve model selection or training?\n\t2.\tIs there a path toward making the proposed test differentiable or learnable, enabling its use as a regularizer or component within end-to-end ML models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "POOswdnWD9", "forum": "xnA1OpoAze", "replyto": "xnA1OpoAze", "signatures": ["ICLR.cc/2026/Conference/Submission22479/Reviewer_7e6M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22479/Reviewer_7e6M"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22479/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760968874272, "cdate": 1760968874272, "tmdate": 1762942234752, "mdate": 1762942234752, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This study develops a statistical test to assess the common assumption of non-informative, also called independent censoring. This assumption is deemed untestable, as the event time (E) and the censoring time (C) are never observed jointly for an individual. The authors propose to test for the underlying structure in the discretized missingness pattern. The authors provide experiments on simulated data with a variety of dependence patterns."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The authors address an interesting and underexplored problem. The proposed solution seems adequate and tractable, which is very appealing .The paper is overall clear and well written."}, "weaknesses": {"value": "This work has a number of weaknesses\n- The main weakness of this work is that it is mostly empirical, with no theory supporting the sensitivity or other properties of the test, \n- the experiences are very limited, with simulated datasets with only four covariates, either all binary, or all continuous, which is rather simplistic. \n- The claim that those simulated results \"demonstrat[e]  proper error control\" based on the fact that for the independent setting, the test returns a large p-value is a little strong compared to the level of evidence. \n- There is a double step of discretization (the time, and the covariates, without proper discussion, and empirical demonstration (for the time for example, what is the impact if there happens to be a big gap between the event times?"}, "questions": {"value": "- there is a strong need of more realistic, and more thoroug experimental setting, as the work is mostly empirical, with the use of real data, both with semi-simulation (to have a realistic covariate distribution, but the truth regarding the tested hypothesis), and real datasets, to see in practice how the test behaves: is the independent censoring assumption never true (according to the test)? It could also allow some evaluation about the practical usability in terms of dataset size, number of covariates, sensitivity of the results to the hyperparameter of the number of bins, the runtime of the algorithm depending on those data characteristics.\n- will the code with proper documentation will be made avaiable? it is absolutely key to the reproducibility of the results, and important for further use of the test"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WA7KzdwC1H", "forum": "xnA1OpoAze", "replyto": "xnA1OpoAze", "signatures": ["ICLR.cc/2026/Conference/Submission22479/Reviewer_WGY5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22479/Reviewer_WGY5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22479/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761555026684, "cdate": 1761555026684, "tmdate": 1762942234421, "mdate": 1762942234421, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a statistical test to evaluate the common assumption in survival analysis. The assumption states that the censoring time and the event time are conditionally independent given the covariates. However, this assumption is usually not tested (on synthetic datasets or on real-life datasets). Previous tests relied on additional assumptions (such as proportional hazards), and this work represents a novelty in overcoming that limitation."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper has several strengths:\n- The authors introduce a new statistical test to assess the common assumption E \\indep C | x in survival analysis. This test does not rely on additional assumptions (unlike previous statistical tests), which makes this work of high quality.\n- The theoretical aspect of the paper is well written, with clear proofs and a lot of intuitions.\n- The process for generating independent event and censoring times using RSF is very interesting."}, "weaknesses": {"value": "Major weaknesses:\n- In Section 4.1, the authors could provide more information about the CMI.\n- Although the authors mention that several existing tests are available, they did not compare their proposed test with these alternatives. It would be interesting to see how the other tests perform compared to theirs, and under which settings.\n- Some experiments could also have been conducted on real-life datasets, for instance those available in the python library pycox, to evaluate whether the proposed test passes in practical situations.\n- The experimental tables lack clarity. The authors could use colors or redesign the tables to better visualize independence (or dependence) through the p-values across different settings.\n\nMinor weaknesses:\n- The paper contains several typos, e.g. line 78: eahch -> each; line 159: xor -> or; line 247: missing parenthesis."}, "questions": {"value": "The questions I have are related to the weaknesses:\n\n- Could you explain a bit more about the creation of the synthetic data using RSF? Does the distribution of the generated datasets resemble that of other survival analysis datasets? And what is the distribution of $\\Delta I$ when the assumption holds?\n\n- Would it be possible for you to add the following three tests: the Cox-based test (Lee & Wolfe), the Rizopoulos test based on copulas, and the Sun & Lee test? This could really strengthen your paper.\n\n- Also, could you include the results for the real-life datasets (from the Python library pycox or scikit-survival) for both your test and the previous ones? It would help users understand how many tests have passed before using these datasets and methods that assume  E \\indep C | x"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4ybaNQnvPW", "forum": "xnA1OpoAze", "replyto": "xnA1OpoAze", "signatures": ["ICLR.cc/2026/Conference/Submission22479/Reviewer_RnfC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22479/Reviewer_RnfC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22479/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761820975924, "cdate": 1761820975924, "tmdate": 1762942233903, "mdate": 1762942233903, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to design a nonparametric test for diagnosing conditional independent censoring $(E \\perp C \\mid X)$ in survival data. Continuous time is discretized and binary event/censoring indicators with ``?'' for unobserved entries form partially observed contingency tables per stratum. The test statistic is the conditional mutual information (CMI) uncertainty range $\\Delta I_t$, defined as the gap between upper and lower CMI over all valid completions of the tables. These bounds are solved via a decomposable integer program with dynamic programming, and significance is assessed using a stratified permutation procedure. \n\nSynthetic experiments with Gaussian, Clayton, Gumbel, and Frank copulas, plus a frailty model, show Type-I error control near independence and increasing power as dependence strengthens."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Problem relevance: Targets the untestable yet ubiquitous independent-censoring assumption, which is very commonly used in survival analysis.\n\n2. Optimization setup: bounding CMI by integer variables per stratum is natural."}, "weaknesses": {"value": "1. “Assumption-free” is overstated: the null depends on RSF models and on discretization choices for continuous X. Sensitivity to bin counts and RSF hyperparameters is not studied.\n\n2. No stress tests with small strata, heavy censoring, ties, or time-dependent covariates.\n\n3. No power analysis beyond plots; no characterization of when bounds are tight."}, "questions": {"value": "1. How sensitive is Type-I control to RSF mis-specification, and would a conditional-randomization design reduce model dependence?\n\n2. Could you provide some stress tests with small strata, heavy censoring?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "GsDnTdjALw", "forum": "xnA1OpoAze", "replyto": "xnA1OpoAze", "signatures": ["ICLR.cc/2026/Conference/Submission22479/Reviewer_2WPk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22479/Reviewer_2WPk"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22479/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994995694, "cdate": 1761994995694, "tmdate": 1762942233660, "mdate": 1762942233660, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the problem of testing if dependent censoring exists in a dataset. The authors propose a statistical test based on *conditional mutual independence*, by comparing it against the null hypothesis; if the CMI is too large or small compared to the null hypothesis then the null hypothesis that there is independent censoring is rejected.\n\nThe overall method is based on the following contributions (i) showing that if independent censoring holds, then the same holds in the discrete case (hence allowing the authors to focus on discrete time settings thereafter for computational reasons), (ii) introducing CMI uncertainty range as a test statistic of sorts, (iii) proposing a more efficient method to compute CMI based on separability, and (iv) proposing a way to estimate the CMI under the null hypothesis.\n\nNote: this is outside my reviewing expertise. I have brought this up to the AC and defer to other reviewers."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is easy to understand and follow, even for someone outside the field. The contribution and motivation is clear"}, "weaknesses": {"value": "- I do not see any obvious big weaknesses, but the empirical evaluation does seem a little limited. The Clayton, Gumbel, and Frank copula are all Archimedean which are quite restrictive. I wonder if there are richer joint survival distributions that could be used to stress test the proposed method."}, "questions": {"value": "- Can the authors comment on whether imputation is an acceptable range of computing CMI? My intuition is that it may be that the difference between min and max would be so large that the test becomes too weak to be useful."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "gBZMGm1iIv", "forum": "xnA1OpoAze", "replyto": "xnA1OpoAze", "signatures": ["ICLR.cc/2026/Conference/Submission22479/Reviewer_fYPT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22479/Reviewer_fYPT"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission22479/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995733457, "cdate": 1761995733457, "tmdate": 1762942233464, "mdate": 1762942233464, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}