{"id": "WYfDoB44xy", "number": 1187, "cdate": 1756862029125, "mdate": 1763479977017, "content": {"title": "More Than What Was Chosen: LLM-based Explainable Recommendation Beyond Noisy User Preferences", "abstract": "Recommender systems traditionally rely on the principle of Revealed Preference (RP), which assumes that observed user behaviors faithfully reflect underlying interests.\nWhile effective at scale, this assumption is fragile in practice, as real-world choices are often noisy and inconsistent.\nThus, even LLM-based recommendation models (LLM-Rec) equipped with advanced reasoning capabilities may fail to capture genuine user preferences and often produce rationales of limited persuasiveness.\nTo address this issue, we introduce the concept of Coherent Preference (CP), which complements RP by favoring items that are logically and causally coherent with user interaction history.\nBuilding on this perspective, we propose Conflict-Aware Direct Preference Optimization (C-APO), an LLM-Rec framework that jointly optimizes RP and CP while adaptively reconciling their agreement and conflict, delivering robust recommendation performance and logically consistent rationales. \nWe construct a unified ordering approach that combines the RP signal, based on chosen versus unobserved items, with the CP signal, which ranks items by their logical consistency with past interaction history.\nIn this unified preference ordering, we dynamically adjust the influence of each signal depending on whether RP and CP agree or conflict, allowing the model to better capture user intent and generate more plausible recommendations.\nOn the Amazon Review dataset, our approach consistently outperforms approximately 20 state-of-the-art baseline models in both recommendation performance and rationale quality, achieving a 1.65$\\times$ relative improvement in click-through rate during deployment, thereby demonstrating its practical utility.\nThe code and dataset are available at https://anonymous.4open.science/r/C-APO.", "tldr": "We propose C-APO, an LLM-based recommender that balances Revealed Preferences and Coherent Preferences—logically consistent with user history—for robust recommendations and rationales.", "keywords": ["LLM-based Recommendation", "Rationale", "Revealed Preference", "Explainable Recommender"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/57d2d91d313ec85b5fd011eb2a1cb463f4499b77.pdf", "supplementary_material": "/attachment/6fc68d034aa3230a5f367a9a35e8cb5c4dfe20fd.pdf"}, "replies": [{"content": {"summary": {"value": "The author introduces C-APO, a large-language-model-based recommender framework that unifies Revealed Preference (RP)—the user’s actual selections—with a newly defined Coherent Preference (CP) that measures logical and causal consistency with past interactions."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper presents a very interesting and well-executed idea. I like that it goes beyond the traditional Revealed Preference view and tries to model Coherent Preference, which captures how consistent a user’s choice is with their history. That’s a fresh perspective, and it makes intuitive sense for real-world noisy data.\n\nThe paper doesn’t just show better HR or NDCG—it also includes online A/B testing and a rationale-quality evaluation, which makes the contribution more convincing."}, "weaknesses": {"value": "My main concern lies in how stable and reliable the LLM-generated coherence scores are. Since large language models are inherently stochastic, the same prompt could give slightly different scores on different runs or across model versions. The paper doesn’t discuss how this variability might affect training consistency or bias.\n\nRelatedly, because the same or similar LLMs are used both to generate the rationales and to train the model, there’s a risk of evaluation bias or circular reasoning. It’s not clear how independent the “LLM-as-a-Judge” step is from the model being optimized. Even though human validation is mentioned, the stability and generalizability of those coherence judgments still need stronger evidence.\n\nThe smaller concern is scalability. The process of generating and scoring rationales for triplets is expensive, and it’s not obvious how feasible it is to apply at industrial scale. Finally, while the authors describe Coherent Preference as “causal,” it’s more of a semantic or logical coherence measure rather than explicit causal reasoning. Clarifying this point would make the conceptual framing more accurate."}, "questions": {"value": "Since coherence scores are generated by an LLM, how do the authors ensure consistency across runs? LLM outputs can vary depending on temperature, prompt phrasing, or even random seeds. Were the scores averaged over multiple samples, or was the generation deterministic? Some empirical evidence of score stability would strengthen the paper.\n\nThe SBERT-based calibration step (Eq. 7) is interesting, but it’s not clear how much it actually changes or stabilizes the raw LLM scores.\n\nThe triplet-based data construction is computationally heavy. How practical is it to extend this method to millions of users or large catalogs? Is there any plan for lightweight CP scoring or distillation to make it more scalable?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nWtcZ6O8Js", "forum": "WYfDoB44xy", "replyto": "WYfDoB44xy", "signatures": ["ICLR.cc/2026/Conference/Submission1187/Reviewer_AZEL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1187/Reviewer_AZEL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1187/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760505179251, "cdate": 1760505179251, "tmdate": 1762915701431, "mdate": 1762915701431, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces the concept of coherent preference to complement the traditional principle of revealed preference. The paper proposed a LLM-Rec framework that jointly optimizes RP and CP by constructing an ordered preference data for optimization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The approach of inferring intrinsic preferences by reasoning over users’ choices with an LLM is well-motivated, and the mathematical derivation of the optimization is reasonably solid.\n\n2. The authors further propose dynamically adjusting the coherence score to accommodate scenarios with high data noise, where unselected items might actually reflect stronger user interest if available—an aspect often overlooked in existing methods.\n\n3. Extensive and convincing experiments."}, "weaknesses": {"value": "1. The deployment of the LLM appears to substantially increase computational cost, especially when the user interaction history is long. It is mentioned that the LLM is prompted to output a rationale for the user’s choice and a coherence score. This suggests that the overall computational cost could be quite high.\n\n2. Regarding the use of an LLM to generate the coherence score, how much previous interaction history is required? The paper should elaborate on how the length of this history affects the quality of the generated rationales and whether having too few interactions could negatively impact performance. This information would be useful for designing a filtering method to select high-quality training data.\n\n3. A readily foreseeable limitation of the work is the potential “echo chamber” effect, where noisy but exploratory user actions may be smoothed out by the model. The authors might consider discussing this issue further and suggesting possible ways to mitigate it."}, "questions": {"value": "Please see the previous section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Wxeg3rfLU9", "forum": "WYfDoB44xy", "replyto": "WYfDoB44xy", "signatures": ["ICLR.cc/2026/Conference/Submission1187/Reviewer_VjMo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1187/Reviewer_VjMo"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1187/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761502375680, "cdate": 1761502375680, "tmdate": 1762915700835, "mdate": 1762915700835, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper argues that RP (using observed choices) is often noisy and proposes CP: ranking items by their logical/causal consistency with a user’s history (measured via LLM-generated rationales and 7 “coherence” scores). It introduces C-APO, which extends a DPO objective to a triplet ordering (chosen, hard-rejected, asy-rejected) and reweights updates based on RP-CP agreement/conflict using a SBERT-based calibration module. Experiments on multiple Amazon domains show gains over a varietyo f baselines and an online A/B test reports significant CTR gains over a production ML model."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Clear motivation adn evidence of RP -CP conflict \n- Principled objective unifying triplet ordering with adaptive weightswith transparent gradient view.\n- Thorough empirical sweep across five domains with many baselines, reproducibility steps and code/data link.\n- Online A/B provides an initial real-world signal with latency considerations"}, "weaknesses": {"value": "- As acknoledged by the authors, human agreement with LLM coherence is positive but imperfect (ρ=0.71), and the paper itself treats LLM scores as noisy. CP also sometimes ranks a rejected item above the chosen one. This is significant as CP scores directly control learning pressure via weights. Residual mis-scoring can redirect gradients and produce brittle behavior in edge cases (e.g., sparse histories). This does not invalidate results but lowers confidence that gains generalize when the coherence signal weakens. More per-domain noise analyses might mitigate this concern. \n\n- The A/B study shows a large CTR lift with impressions/clicks and a z-test, yet lacks confidence intervals and downstream KPIs. The deployment is a pilot over a 2-month window. For claims of practical utility, reviewers need assurance that lifts are not artifacts of short-term novelty, catalog skew, or traffic allocation quirks, especially since the method changes not only ranking but rationales surfaced to users. Additional transparency would substantiate impact claims. Can you please report CTR CIs, per-user variance, and any downstream metrics (e.g., dwell, purchase, satisfaction proxy). Also clarify any holdout/novelty controls. \n\n- All offline datasets are Amazon text domains. The approach conceptually targets broad recommenders (video, image, music), but no multimodal or cold-start setting is shown. The coherence construct likely depends on modality. Showing at least one non-text domain would strengthen the generality claim.\n\n- The paper shows Base < SFT < DPO/PL < C-APO but does not include “C-APO (no SBERT calibration)” or “PL + calibration (no conflict-aware weighting)”. Without isolating the calibration block (Eq. 7), reviewers cannot attribute improvements to the central claimed idea (conflict-aware weighting) versus the auxiliary scoring stabilizer. This affects interpretability of the contribution and the portability of the method to settings where the calibration model might behave differently. Can you add an ablation for C-APO without the SBERT-gate and/or PL + calibration but no conflict-aware weighting? This would clarify which piece drives the gains."}, "questions": {"value": "- Please see the weaknesses section.\n- Were the annotation guidelines and instruction provided for the annotators disclosed? How many annotators were involved? Were they diverse in terms of demographics? What was their background in annotation? Additionally, what measures were taken to validate the quality and consistency of the annotations, and ensure the reliability of the labeled data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "40VUbyF2Z0", "forum": "WYfDoB44xy", "replyto": "WYfDoB44xy", "signatures": ["ICLR.cc/2026/Conference/Submission1187/Reviewer_EkyG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1187/Reviewer_EkyG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1187/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761847310807, "cdate": 1761847310807, "tmdate": 1762915700430, "mdate": 1762915700430, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Traditional recommender systems, including those using LLMs, rely on Revealed Preference (RP), assuming user actions reflect true interests. However, user behavior is often noisy and inconsistent, leading to flawed recommendations and unpersuasive rationales.\n\nThis paper introduces Coherent Preference (CP), a concept prioritizing items that are logically and causally consistent with a user's entire interaction history, not just isolated choices.\n\nBuilding on this, the authors propose Conflict-Aware Direct Preference Optimization (C-APO), an LLM-based framework that jointly optimizes for both RP and CP. C-APO uses a unified ranking system that combines signals from both preferences. Critically, it adaptively reconciles agreements and conflicts between RP and CP, allowing it to better capture genuine user intent.\n\nOn the Amazon Review dataset, C-APO outperformed approximately 20 state-of-the-art baselines in both recommendation performance and rationale quality. A real-world deployment confirmed its practical effectiveness."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The idea proposed in this paper is easy to understand, direct, and effective. However, the cost of dataset construction might need to be considered.\n\nThe paper provides some theoretical analysis and proofs.\n\nThe experiments are very thorough, for example, comparing against as many as 20 baselines and using datasets from multiple domains. The experimental results also demonstrate the effectiveness of the proposed model.\n\nThe code and dataset are publicly available."}, "weaknesses": {"value": "Figure 2 and the paragraph that references it (i.e., the paragraph starting around line 048) do not seem consistent. I could not fully understand what the authors were trying to illustrate with this paragraph and Figure 2.\n\nThe paper might be somewhat difficult for readers who are not very familiar with related work. For instance, some terms like \"rejected item\" lack an intuitive explanation when they first appear."}, "questions": {"value": "Regarding line 242, how is the conflict-aware reward weight w_{i,j} defined? Is it a function with g_i - g_j as input? Is it learned, or is it predefined as a constant?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2H6Xz9xrmR", "forum": "WYfDoB44xy", "replyto": "WYfDoB44xy", "signatures": ["ICLR.cc/2026/Conference/Submission1187/Reviewer_XFSC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1187/Reviewer_XFSC"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1187/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761921681521, "cdate": 1761921681521, "tmdate": 1762915700152, "mdate": 1762915700152, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Summary of the Revised Sections"}, "comment": {"value": "***Summary of the Revised Sections***\n> Please refer to the relevant sections in the revised manuscript. \n\n\n**§1. Introduction**\n> * (revised) Figure 2 and  line 48: Inconsistency between Figure 2 and the referencing paragraph (XFSC).\n> * (revised) line 76: added definition of rejected item (XFSC)\n\n**§3.2. Derivation of C-APO**\n> * (revised) line 250: conflict-aware adaptive weight → ***trainable*** conflict-aware adaptive weight (XFSC)\n\n**§4.5. Ablation Study**\n> * (new) Added new variants in the ablation study (C-APO w/o SBERT calibration) (EkyG, AZEL)\n> * (revised) Figure 5\n\n\n**§4.6 Online A/B Test**\n> * (new) Added the confidence intervals and downstream KPIs. (EkyG)\n> * (revised) Table 3\n\n\n**§6. Conclusion and Future Work**\n> * (new) Lightweight Scoring LLM (XFSC, AZEL)\n> * (new) Multi-modality (EkyG)\n\n**Appendix §D. Triplet Rationale Dataset Construction Recipe**\n> * (new) Added annotation protocol (EkyG)\n> * (new) Added the effect of history length on the rationales quality (VjMo)\n> * (revised) line 811: deterministic setup for LLM coherence scores (AZEL)\n\n**Appendix §H.1. Cold-Start and Zero-Shot Domain Transfer**\n> * (new) Added the cold-start scenario analysis (EkyG)\n\n\n**Appendix §H.2. Experiments on Non-Amazon Domains**\n> * (new) Added experiments on Non-Amazon Domains (EkyG)\n\n\n**Appendix §I. Serendipity Analysis**\n> * (new) Added the serendipity analysis (VjMo)"}}, "id": "qfCxR6HgbH", "forum": "WYfDoB44xy", "replyto": "WYfDoB44xy", "signatures": ["ICLR.cc/2026/Conference/Submission1187/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1187/Authors"], "number": 8, "invitations": ["ICLR.cc/2026/Conference/Submission1187/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763478290164, "cdate": 1763478290164, "tmdate": 1763478844101, "mdate": 1763478844101, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Summary of the Revised Sections"}, "comment": {"value": "***Summary of the Revised Sections***\n> Please refer to the relevant sections in the revised manuscript. \n\n\n**§1. Introduction**\n> * (revised) Figure 2 and  line 48: Inconsistency between Figure 2 and the referencing paragraph (XFSC).\n> * (revised) line 76: added definition of rejected item (XFSC)\n\n**§3.2. Derivation of C-APO**\n> * (revised) line 250: conflict-aware adaptive weight → ***trainable*** conflict-aware adaptive weight (XFSC)\n\n**§4.5. Ablation Study**\n> * (new) Added new variants in the ablation study (C-APO w/o SBERT calibration) (EkyG, AZEL)\n> * (revised) Figure 5\n\n\n**§4.6 Online A/B Test**\n> * (new) Added the confidence intervals and downstream KPIs. (EkyG)\n> * (revised) Table 3\n\n\n**§6. Conclusion and Future Work**\n> * (new) Lightweight Scoring LLM (XFSC, AZEL)\n> * (new) Multi-modality (EkyG)\n\n**Appendix §D. Triplet Rationale Dataset Construction Recipe**\n> * (new) Added annotation protocol (EkyG)\n> * (new) Added the effect of history length on the rationales quality (VjMo)\n> * (revised) line 811: deterministic setup for LLM coherence scores (AZEL)\n\n**Appendix §H.1. Cold-Start and Zero-Shot Domain Transfer**\n> * (new) Added the cold-start scenario analysis (EkyG)\n\n\n**Appendix §H.2. Experiments on Non-Amazon Domains**\n> * (new) Added experiments on Non-Amazon Domains (MovieLens; EkyG)\n\n\n**Appendix §I. Serendipity Analysis**\n> * (new) Added the serendipity analysis (VjMo)"}}, "id": "qfCxR6HgbH", "forum": "WYfDoB44xy", "replyto": "WYfDoB44xy", "signatures": ["ICLR.cc/2026/Conference/Submission1187/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1187/Authors"], "number": 8, "invitations": ["ICLR.cc/2026/Conference/Submission1187/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763478290164, "cdate": 1763478290164, "tmdate": 1763613793881, "mdate": 1763613793881, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}