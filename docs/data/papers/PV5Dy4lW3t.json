{"id": "PV5Dy4lW3t", "number": 21370, "cdate": 1758316799562, "mdate": 1763639298878, "content": {"title": "TSLM: Tree-Structured Language Modeling for Divergent Thinking", "abstract": "Language models generate reasoning sequentially, preventing them from decoupling irrelevant exploration paths during search. We introduce Tree-Structured Language Modeling (TSLM), which uses special tokens to encode branching structure, enabling models to generate and selectively expand multiple search paths within a single generation process. By training on complete search trees including both successful and failed attempts, TSLM learns to internalize systematic exploration without redundant recomputation of shared prefixes. TSLM achieves 100\\% accuracy on Game of 24 (vs. 17\\% sequential baseline), robust extrapolation to 20×20 grids (91.5\\% vs. 42.7\\% for Tree-of-Thought), and superior inference efficiency by avoiding the multiple independent forward passes required by external search methods. These results suggest a new paradigm of inference-time scaling for robust reasoning, demonstrating that supervised learning on complete tree-structured traces provides an efficient alternative for developing systematic exploration capabilities in language models.", "tldr": "", "keywords": ["language models", "reasoning", "planning", "Supervised Learning", "Inference-time scaling"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/56efd30affef4acd282f6274b82c38c1a32d14f2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes Tree-Structured Language Modeling (TSLM), a simple but distinctive way to let a standard transformer natively generate and traverse a search tree within a single sequence. The core idea is to serialize a tree into a linear token stream using special markers, so that teacher traces include both successful and failed branches. Training is standard LM loss on these serialized traces; inference reconstructs the tree and explores it until a solution or exhaustion. The paper reports results across Game of 24, Textualized Gridworld, ProntoQA, and GSM8K. On structured tasks, TSLM is very strong, shows rapid adaptation with few samples on ProntoQA, and claims parameter efficiency. For open-ended math (GSM8K), TSLM is competitive. Overall, TSLM is positioned as a purely supervised alternative to RL-style “reasoning” methods that require external search or test-time orchestration."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1: The token-based tree serialization for end-to-end supervised training of internal exploration is a neat, low-friction idea. It avoids extra modules (verifiers or value functions) and RL, and while LM-based search is well-studied, representing divergent branches natively within a single generation is an original framing with distinct trade-offs.\n\nS2: Strong performance on Game of 24 and Gridworld demonstrates the method’s core promise. The BFS vs. DFS analysis in Appendix G provides insight into how traversal strategies interact with learned preferences.\n\nS3. No architectural changes are required; the approach works with standard SFT and any base LM (e.g., Llama-3, Qwen). Training and inference procedures are clear, with many worked examples provided, supporting reproducibility."}, "weaknesses": {"value": "W1: ToT is configured minimally, and comparisons omit Self-Consistency and verifier-based selection, which are strong baselines on GSM8K, as well as natural tree-search comparators like TS-LLM, LATS, and RAP. Without these, it is difficult to judge when TSLM’s internalized tree search provides meaningful benefits.\n\n\nW2: TSLM trains over all tree nodes O(N⋅L)), and inference produces long serialized trees. Claims of efficiency are not quantitatively compared against ToT’s extra model calls or SC/self-consistency multi-sample decoding.\n\nW3: The tasks are well-suited to structured search-tree reasoning but do not represent open-ended domains such as large-scale software engineering, real-world system design, multi-agent planning, or long-horizon code generation. Claims that strong performance on structured tasks will generalize to these domains remain untested and speculative."}, "questions": {"value": "Q1. What were the exact ToT settings (beam width, evaluation heuristic, depth/budget) per task? Did you evaluate Self-Consistency (sample-and-vote) or GSM8K verifier selection? If so, how do they compare under equal token budgets?\n\nQ2: The reported scaling performance (“68% for 0.5B vs 19–26% for 7B baselines”) requires clarification: What is the exact metric and task (Gridworld 20×20 only?), and are these single-seed results? Please provide confidence intervals.\n\nQ3: The paper provides a qualitative example. Across a large set, how often does TSLM correctly abstain on unsolvable Game of 24 instances?\n\nQ4: How well does TSLM handle branches in open-ended problem domains, where the branching structure is unclear or multiple valid solution paths exist without a single “correct” branch?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HJYEfiahyA", "forum": "PV5Dy4lW3t", "replyto": "PV5Dy4lW3t", "signatures": ["ICLR.cc/2026/Conference/Submission21370/Reviewer_Aewk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21370/Reviewer_Aewk"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21370/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761631479986, "cdate": 1761631479986, "tmdate": 1762941727887, "mdate": 1762941727887, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Official Clarification on Tree-of-Thought (ToT) Baseline Configuration on GSM8K"}, "comment": {"value": "Thank you all for the thoughtful feedback!  We want to start by acknowledging and correcting a critical configuration issue from our September submission that may have caused confusion about our contributions. We revised the paper upon all your concerns, so feel free to check the new version!\n\n\n# ⚠️ The Core Misalignment: Pass@100(Tree-of-Thought) vs Pass@1(Others) ⚠️\n\n\n_TL;DR: We made a fundamental mistake in marking and explaining with ToT comparisons. ToT in our experiments is a pass@100 method, while all other methods (SC, PC, GRPO, TSLM) are pass@1. This is like comparing apples to oranges!_\n\n\n## 1. Tree-of-Thought(ToT) configuration (Missing in the original paper)\n\n\nOur ToT baseline uses the following configuration across all experiments:\n\n\n* Search algorithm: Breadth-First Search (BFS)\n\n\n* Base model for the rollout: model SFT-ed by the standard sequence format (SC in our paper)\n\n\n* Sample ordering: RAP (Hao et al., Prioritize searching higher process reward first)\n\n\n* Beam width: b=5\n\n\n* Temperature: 0.3\n\n\n* Evaluation: ToT@100 (we examine the first 100 terminal nodes and mark the instance as correct if any candidate reaches the correct answer)\n\n\n*We set ToT@k=100 in our setting, because k=100 already gave a good convergence point within the search tree.\n\n\nOne misconception among reviewers is that our method is not performing well compared to ToT. The truth is, however, ToT implementation in our paper is a test-time scaling method where we give multiple shots for the model to solve the same problem with parallel inference. Unlike other methods (including ours), they get instances right if at least one of 100 attempts is right.\n\n\nI am deeply sorry about the confusion and we should have made a more understandable figure for ToT in Table 1. \n\n\n## 2. Rebuttal Table 1 (Updated from original Table 1)\n\n\nWhat #1 means is that the original Table 1 should have looked more like this:\n\n\n| Tasks | SC | PC | GRPO | TSLM (ours) | | ToT@k (test time scaling from SC) |\n|---------:|:--------:|----------:|----------:|----------:|:--:|----------|\n| # candidates(&darr;) | 1 | 1 | 1 | 1 | ║ | 100 |\n|   Game of 24    |  17.0%  | 47.0%     | 15.0% | **100%**| ║ | 32.0% ; _changed from 17%_|\n|   Gridworld (10x10)    |  78.2%   | 99.7%     | 24.0% | **100%**| ║ | 95.0%|\n|   Gridworld (20x20); _we reevaluated with the same model_ |  33.0%   | 81.1%     | 6.0% | **91.5%**| ║ | 42.7%|\n|   ProntoQA    |  99.7%   | 97.5%     | 99.8%| **100%**| ║ | 100%|\n|   GSM8K    |  55.8%   | 55.9%     | 60.8%|**61.6%**| ║ | 62.3% ; _changed from 85%_|\n\n\n*For your recall, \n* SC (Sequence Cloning) is a standard CoT SFT method.\n* PC (Procedure Cloning) and GRPO (Group Relative Policy Optimization) are each SFT and RL methods to reproduce o1-like search tree in one model call.\n* TSLM (Tree-Structured Language Modeling) also reproduces o1-like search tree, but makes sure the model doesn’t attend to irrelevant subtree during inferencing each node\n* ToT@k (Tree-of-Thought) is a tree-like scaffold on top of SC to reproduce the search tree via multiple model calls.\n\n\n### So What Changed? \n\n\n* ToT score correction: We accidentally swapped some of the ToT results with other results by mistake. For Game of 24, it should be 32.0% instead of 17.0% (is a standard SFT result), and for GSM8K, it should be 62.3% instead of 85.0% (is a GRPO result for Qwen 2.5 7B, see #4).  Also we reported some of the Gridworld 20x20 performance with Qwen2.5 0.5B model, so we also changed it with our base llama 3 8B model performance (no big change in narration though)\n\n\n* I am sorry for the mistake, and it’s totally natural to doubt that we are manipulating on GSM8K results. However, if you see the increment in Figure 3  (Figure 4 of the original version), you would see that 85% doesn’t make any sense. The purple line (SC) has already converged to near 62% at $k=9$. ToT is a convergence point of the graph, and there’s no way it could be 85%.\n\n\n* The real comparison: Even in GSM8K, when you give ToT 100 chances to find the answer, it only barely beats TSLM's **single** attempt (62.3% vs 61.6%)."}}, "id": "UZfwVQ38Zt", "forum": "PV5Dy4lW3t", "replyto": "PV5Dy4lW3t", "signatures": ["ICLR.cc/2026/Conference/Submission21370/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21370/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21370/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763639783347, "cdate": 1763639783347, "tmdate": 1763639783347, "mdate": 1763639783347, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes TSLM, a training approach that teaches an LLM to internally construct and traverse a tree of reasoning within a single generation, rather than relying on external multi-pass search at inference time. The authors position TSLM as more efficient and easier to train and deploy than external search pipelines, and as a simpler alternative to RL approaches such as GRPO for improving multi-step reasoning and planning. Empirically the paper claims that TSLM improves extrapolation on structured reasoning tasks and helps smaller models approach the performance of larger ones, while also benefiting large models.\n\nThe paper situates itself against external search methods, and also cites multi-path generation like self-consistency and recent long-reasoning models. The narrative is consistent with the goal of moving reasoning structure into the model rather than the inference loop. However, there is a relevant gap regarding diversity-driven reasoning frameworks that target breadth before convergence and explicitly reduce redundant reflections with task-agnostic memory."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "TSLM aims at deployment simplicity. Eliminating external orchestration and multiple model calls is attractive for production where latency and engineering complexity matter. The authors take care to compare conceptually with ToT and with RL, explaining why a supervised approach can be more stable and economical. The stated effect that TSLM helps smaller models close the gap with larger ones is promising for cost-sensitive settings. \n\nThe conceptual boundary is easy to communicate. External search explores a tree outside the model, TSLM learns to write the tree inside the generation. That is a clean story, and it could generalize to code or games where branching structure is natural."}, "weaknesses": {"value": "Related work coverage is incomplete on diversity-first inference and redundancy reduction with memory, which is a very proximate thread to the authors’ efficiency and breadth claims. The current submission neither cites nor contrasts with these works (e.g., Lingam et al., ICLR 2025), which could mislead readers about the frontier on exploration efficiency. This needs correction. \n\nEvidence granularity is thin in the visible draft. The claims about improved extrapolation, small-to-large bridging, and efficiency would be more convincing with matched-budget comparisons against ToT, self-consistency, and diversity-driven methods, for example controlling node expansions or total tokens, plus wall-clock latency. The draft does not show whether TSLM outperforms a well tuned inference-time breadth strategy at the same compute."}, "questions": {"value": "(1) Under a fixed budget of model calls and total tokens, how does TSLM compare to ToT or self-consistency, and to a diversity-driven method with a task-agnostic memory bank such as DoT? \n\n(2) What happens if you linearize the tree to a CoT trace with the same token budget, or if you randomize branching order?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "The work is a modeling and training method, uses standard benchmarks, and does not involve sensitive data or human subjects."}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "o6TFf2fZEo", "forum": "PV5Dy4lW3t", "replyto": "PV5Dy4lW3t", "signatures": ["ICLR.cc/2026/Conference/Submission21370/Reviewer_BGCK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21370/Reviewer_BGCK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21370/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761681757825, "cdate": 1761681757825, "tmdate": 1762941727571, "mdate": 1762941727571, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "LLMs can generate sequential solutions but are unable to systematically explore multiple possibilities. The paper introduce a framework to serialize tree exploration into linear sequences for training to enable tree-structured reasoning. The method achieves better performance than baselines on most tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is generally clearly written.\n\nThe proposed tree-structured language modeling paradigm is interesting."}, "weaknesses": {"value": "The method is helpful on tasks where systematic exploration is needed, but I think more open-ended and real-world tasks are more important. As indicated in Table 1, the proposed method has no benefit in these scenarios. The bolded number in the GSM8k row should be the ToT one, by the way.\n\nThe experiment detailed configuration for the ToT baseline is not mentioned. Since the proposed method requires much higher inference-time compute, it is unclear how much the advantage will diminish\tif you let all methods use the same budget (say, the total tokens)."}, "questions": {"value": "Does the training data for the TSLM method include the 5 tasks that are also used for evaluation?\n\nCan you also try letting baseline methods train on the same training set, by extracting correct path from the tree. Basically, TSLM receives additional training signal and eliminating that factor will make the experiment results more solid."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "vCnEvjOm14", "forum": "PV5Dy4lW3t", "replyto": "PV5Dy4lW3t", "signatures": ["ICLR.cc/2026/Conference/Submission21370/Reviewer_fgNv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21370/Reviewer_fgNv"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21370/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984063101, "cdate": 1761984063101, "tmdate": 1762941727118, "mdate": 1762941727118, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Tree-Structured Language Modeling (TSLM), enabling language models to perform tree-structured reasoning natively within a single forward generation process.\nThe thought branching structures are shown into the token sequence through special markers.\nSerialized tree traces that capture both successful and failed reasoning paths are used to train standard transformers.\nExperiments are conducted on structured planning tasks and open-ended reasoning tasks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Tree structured reasoning is reflected into token sequences and only one model call is required. This is different from multiple independent model calls used by Tree-of-Thought.\n2. The token-based serialization approach is practical for achieving tree-structured generation using LLMs.\n3. The experiments span both structured and open-ended reasoning tasks."}, "weaknesses": {"value": "1. The time cost comparison with methods such as Tree-of-Thought is not presented.\n2. As shown in Table 1, the performance of TSLM is not as good as ToT in GSM8K.\n3. The token-based tree serialization relies on search trees gotten from other reasoning methods. As such, the performance is also limited by the other reasoning methods.\n4. There are some more advanced reasoning methods such as Graph-of-Thought and Everything of Thoughts."}, "questions": {"value": "What is the time cost of the proposed method?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "b0AlnmyloG", "forum": "PV5Dy4lW3t", "replyto": "PV5Dy4lW3t", "signatures": ["ICLR.cc/2026/Conference/Submission21370/Reviewer_cbMw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21370/Reviewer_cbMw"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21370/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762006091374, "cdate": 1762006091374, "tmdate": 1762941726618, "mdate": 1762941726618, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}