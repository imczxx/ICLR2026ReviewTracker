{"id": "ztIFs5nZJr", "number": 11154, "cdate": 1758191298220, "mdate": 1763726957329, "content": {"title": "Real-Aware Residual Model Merging for Deepfake Detection", "abstract": "Deepfake generators evolve quickly, making exhaustive data collection and repeated retraining impractical. We argue that model merging is a natural fit for deepfake detection: unlike generic multi-task settings with disjoint labels, deepfake specialists share the same binary decision and differ in generator-specific artifacts. Empirically, we show that simple weight averaging preserves Real representations while attenuating Fake-specific cues.\nBuilding upon these findings, we propose Real-aware Residual Model Merging (R$^2$M), a training-free parameter-space merging framework. R$^2$M estimates a shared Real component via a low-rank factorization of task vectors, decomposes each specialist into a Real-aligned part and a Fake residual, denoises residuals with layerwise rank truncation, and aggregates them with per-task norm matching to prevent any single generator from dominating.\nA concise rationale explains why a simple head suffices: the Real component induces a common separation direction in feature space, while truncated residuals contribute only minor off-axis variations. Across in-distribution, cross-dataset, and unseen-dataset, R$^2$M outperforms joint training and other merging baselines. Importantly, R$^2$M is also composable: when a new forgery family appears, we fine-tune one specialist and re-merge, eliminating the need for retraining.", "tldr": "", "keywords": ["Model merging", "Deepfake detection"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/80f73928a60572f75aea04b89429ebd5b8dddf99.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes the first method that introduces model merging to the deepfake detection task. It analyzed the real similarity and fake distinction among the DF40 dataset, and then proposed R2M with a theoretical explanation. The results show its effectiveness in balancing different types of forgery methods in comparison with the specialist."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe paper introduces model merging into deepfake detection for the first time.\n2.\tIt provides a reasonable analysis of real–fake similarity on the DF40 dataset.\n3.\tThe proposed R2M method shows balanced performance with theoretical support."}, "weaknesses": {"value": "1.\tSince DF40 is used, all real samples come from the same FF++ real, so it is unsurprising that they share the same distribution. However, this also limits the applicability of the conclusion. What if the training data contain reals from different distributions, e.g., FF++ and CDF?\n2.\tRegarding generalization: while it is understandable that model merging can improve in-domain performance, it remains unclear why merging would enhance cross-domain generalization. This point requires more explanation.\n3.\tIn Table 1: The experimental results appear unusual — the All-in-one model fails completely on EFS detection, and even reverses predictions. Why would changing the real distribution cause previously learned forgery types to invert their detection behavior? This phenomenon warrants deeper analysis, particularly to clarify how model merging could lead to label inversion.\n4.\tMore experiments on generalization are needed, for example, by evaluating on additional datasets (e.g., DFDCP, DFD) and comparing with more generalization-oriented methods (e.g., [1] and [2]).\n5.\tThe writing requires further proofreading. For instance, DF40 is incorrectly cited — it is not (Qian et al., 2024) but rather (Yan et al., 2024).\n6.\tWithin the same forgery category, the fake cases also require further analysis to validate the similarity findings in Fig. 2 — for example, within EFS. It would be helpful to train specialist models separately using DiT, SiT, and StyleGAN to support this analysis.\n\n[1] Effort: Efficient orthogonal modeling for generalizable ai-generated image detection //ICML’25\n\n[2] Can we leave deepfake data behind in training deepfake detector? //NIPS'24"}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2jb9eD95yR", "forum": "ztIFs5nZJr", "replyto": "ztIFs5nZJr", "signatures": ["ICLR.cc/2026/Conference/Submission11154/Reviewer_9CNL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11154/Reviewer_9CNL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11154/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761188203118, "cdate": 1761188203118, "tmdate": 1762922320326, "mdate": 1762922320326, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a training-free model merging approach that enhances the generalization ability of deepfake detectors by combining specialist parameters trained on different forgery types. Specifically, the authors argue that the “real” class direction can be well preserved during merging, while class-specific forgery artifacts are suppressed. To this end, they employ SVD decomposition to extract dominant directions and obtain a generalizable merged model.\n\nExtensive experiments on the DF40 dataset demonstrate that the proposed method largely retains each expert’s detection capability. The authors further claim that their method exhibits high scalability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper introduces a valuable setting: Merging detectors via a training-free approach to obtain generalized deepfake detectors at low cost.\n\n2.  The authors provide rich theoretical justifications supporting the effectiveness of their proposed method.\n\n3. The proposed approach is extensively evaluated under multiple protocols, showing competitive or superior AUC retention on seen tasks and improved generalization to unseen forgeries."}, "weaknesses": {"value": "1. Although the authors have discussed using a single averaged linear head after merging is enough to get the results, empirical validation is missing. The authors are encouraged to compare the following heads: i) Averaged linear head; ii) Specialist-specific linear heads; iii) Re-tuned linear head (after merging).\n\n2. Theoretical analysis relies on several assumptions: i) Local linearity; ii) Bounded remainder terms; and iii) Mild spectral gap. These assumptions may fail when specialist models differ substantially or when the networks exhibit high nonlinearity. Consequently, the validity of the core theoretical result (Proposition 1) hinges on whether such local properties still hold in large-scale models.\n\n3. The proposed approach shows scalability with six models. However, as the diversity of deepfake generation methods continues to grow, the current scale remains modest. It is unclear how the method performs when the number of experts increases dramatically (dozens or hundreds), especially when specialists have uneven capabilities or have been trained on partially overlapping domains. Since the proposed method depends on low-rank SVD, the dominance of a shared “real” direction may diminish as task vectors diversify.\n\n4. This paper argues for the asymmetry between shared “Real” and generator-specific “Fake” features. Nevertheless, it does not explore scenarios where the real data distribution changes or diversifies. For instance, when real samples come from new domains (e.g., different camera sensors or capture conditions). In such cases, the assumption of a single, stable “Real” direction may no longer hold.\n\n5. Merging parameters across different specialists could introduce vulnerabilities such as trojan signatures or model poisoning. The authors  are suggested to perform a security analysis to R2M robustness in this regard."}, "questions": {"value": "Please see Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sISbUSZmgn", "forum": "ztIFs5nZJr", "replyto": "ztIFs5nZJr", "signatures": ["ICLR.cc/2026/Conference/Submission11154/Reviewer_3mcr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11154/Reviewer_3mcr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11154/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761465403815, "cdate": 1761465403815, "tmdate": 1762922319431, "mdate": 1762922319431, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces **R²M**, a novel method for merging expert models in the domain of Deepfake detection. The core idea is to leverage SVD to decompose task vectors, treating shared \"Real\" features as a principal component and generator-specific \"Fake\" artifacts as residuals. This allows for a training-free and efficient merging process without a drop in performance. However, I have some concerns regarding the method's practical utility in real-world scenarios and its overall impact on advancing the field."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. **Well Motivation:** The paper's motivation is clear and reasonable. Figure 2 provides a compelling and intuitive illustration of the core hypothesis: different specialist models share a common understanding of \"Real\" data while diverging in their representation of \"Fake\" data.\n    \n2. **Efficient and Effective Method:** The proposed R²M method is elegant in its simplicity. Being training-free, it offers a highly efficient way to combine specialists, and the experiments show that it does so with negligible performance degradation on seen tasks."}, "weaknesses": {"value": "1. **Comparison of Similar SVD Technique Used for Detection is Missing:** Previous work like Effort (ICML'25) also proposed the similar  SVD-based approach for improved detection performance. More discussion and comparison for similar methods are needed.\n\n2. **Clarity of Visualizations:** The readability of several experimental figures is a concern. In Figure 3 (heatmaps) and Figure 5 (dumbbell plots), it is difficult to discern the precise numerical gains or losses.\n    \n3. **Marginal Performance Gains:** The improvement of R²M over prior model merging techniques, like CART, appears to be marginal. \n    \n4. **Concerns about Practical Utility and Scalability:** My primary concern lies with the practical application of the proposed merging strategy. The experiments partition domains based on broad forgery categories (e.g., FS, FR, EFS) rather than specific generator models (e.g., FSGAN, FaceSwapV2). This raises a crucial question: how should the framework handle the incremental addition of a new forgery method that belongs to an existing broad category? If a new FaceSwap variant emerges, would one retrain the entire FS specialist, or would a new, more granular merging strategy be required? The current setup does not seem to address this realistic scenario.\n\t\n5. **Strange Performance of Comparison Methods:** For instance, the performance of *Specialist-FR* on EFS samples is so low (AUC=0.099). Can the author explain?"}, "questions": {"value": "1. **Fine-tuning Details:** For reproducibility and clarity, it would be beneficial to specify which parameters of the backbone were fine-tuned for the specialist models. For instance, was it only the final linear layer, or were other parts of the network also updated?\n    \n2. **Lack of Pipeline Diagram:** It would be better to provide a high-level pipeline diagram. A clear visual representation of the R²M process—from task vectors to the final merged model—would significantly aid reader comprehension.\n    \n3. **Ambiguity of \"All-in-one\" Baseline:** The training setup for the \"All-in-one\" baseline is unclear. Was it trained as a single binary (Real vs. Fake) classifier on all forgery data? To further strengthen the experimental results, I would suggest including a baseline where the \"All-in-one\" model is trained on a multi-class Fake detection task (i.e., classifying each specific forgery type), with the logits for all fake classes then aggregated for binary evaluation. This would provide a more robust comparison.\n    \n4. **Limited Impact on the Deepfake Detection Field:** While the authors position the work as a contribution to model merging, its tangible impact on advancing the core challenges in Deepfake detection itself seems limited. The problem of generalizing to unseen forgery families, a critical issue in the field, is not substantially improved by this merging approach."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "N3a7je2zdt", "forum": "ztIFs5nZJr", "replyto": "ztIFs5nZJr", "signatures": ["ICLR.cc/2026/Conference/Submission11154/Reviewer_8SSQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11154/Reviewer_8SSQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11154/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761893698222, "cdate": 1761893698222, "tmdate": 1762922319022, "mdate": 1762922319022, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work analyzes the similarity between each specialist detector and the weight‑averaged model in deepfake detection, finding that real features are shared across detectors while fake features differ and can be complementary. Based on this observation, the paper proposes a Real‑aware Residual Model Merging strategy that enables rapid incorporation of new forgery families by preserving the shared real component and merging the residuals from different forgery specialists. Experiments across multiple datasets and protocols demonstrate the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.The proposed method is straightforward and compelling; the analysis of real and fake feature similarities between each specialist and the weight‑averaged model is particularly insightful.\n2.The R2M method is novel and effective: it updates models by retaining a shared real component while composing denoised, norm‑matched fake residuals to enable rapid adaptation to new forgeries."}, "weaknesses": {"value": "1.Figure 2’s analysis relies on features from older forgery datasets (e.g., DF40), where real and fake images are relatively easy to separate; how would the analysis and the proposed method perform when forgeries are highly realistic and real and fake feature distributions are not well separated?"}, "questions": {"value": "see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Yzzln52lSk", "forum": "ztIFs5nZJr", "replyto": "ztIFs5nZJr", "signatures": ["ICLR.cc/2026/Conference/Submission11154/Reviewer_2rrG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11154/Reviewer_2rrG"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11154/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762260974026, "cdate": 1762260974026, "tmdate": 1762922318467, "mdate": 1762922318467, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General response to all Reviewers"}, "comment": {"value": "We would like to sincerely thank all reviewers for their thoughtful feedback and constructive suggestions. The comments greatly helped us improve the clarity and overall quality of the manuscript. We are also encouraged that the reviewers highlighted several strengths of our work, including the principled formulation of real/fake decomposition (Reviewers 2rrG,  3mcr), the strong empirical performance across diverse forgery types and backbones (Reviewers  2rrG, 8SSQ,  3mcr), and the clear writing and well-motivated design of our real-aware residual merging procedure (Reviewers  8SSQ, 9CNL).\n\nWe are fully prepared to address all concerns raised and appreciate the opportunity to clarify any remaining questions. Below, we summarize the major revisions made in response to the reviewers’ suggestions, together with pointers to the corresponding sections in the revised manuscript:\n\n1. **Improved Clarity and Expanded Analyses**\n\n     We carefully revised the manuscript to improve clarity in several key sections. In particular, we enhanced the visual explanations in Figs. 2–5 and added accompanying tables in the appendix to ensure that all underlying AUC values are easy to interpret. We also included additional analyses—such as within-category behavior and merging under mixed Real distributions (FF + CDF)—to better illustrate the stability of the shared Real component and the variability of Fake residuals.\n\n2. **Strengthened Experimental Evidence and Robustness Evaluation**\n\n     Responding to the reviewers’ suggestions, we added new experiments covering incremental specialist integration (e.g., Uniface), six-specialist merging, and robustness to highly realistic or previously unseen generators. These results demonstrate that R²M consistently maintains or improves performance while degrading more gracefully than CART in challenging regimes. We also expanded ablations on encoder choices, linear heads, and All-in-one behavior to provide a more complete empirical picture.\n\n3. **Clarified Scope, Assumptions, and Relation to Prior Work**\n     \n     We revised the theoretical section to more clearly articulate the local assumptions behind Proposition 1 and specify the scenarios where they naturally hold. In the related-work section, we clarified the distinction between $R^{2}$M and training-time generalization methods such as Effort, emphasizing their complementary roles. To further aid understanding, we added a high-level pipeline diagram illustrating the full merging process.\n\nFor detailed, point-by-point clarifications, please refer to our individual responses to each reviewer. If any additional questions arise, we would be glad to provide further explanation during the discussion phase. We appreciate the opportunity to continue refining and improving the paper."}}, "id": "xLsDW9IVso", "forum": "ztIFs5nZJr", "replyto": "ztIFs5nZJr", "signatures": ["ICLR.cc/2026/Conference/Submission11154/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11154/Authors"], "number": 8, "invitations": ["ICLR.cc/2026/Conference/Submission11154/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763729228226, "cdate": 1763729228226, "tmdate": 1763729847672, "mdate": 1763729847672, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General response to all Reviewers"}, "comment": {"value": "We would like to sincerely thank all reviewers for their thoughtful feedback and constructive suggestions. The comments greatly helped us improve the clarity and overall quality of the manuscript. We are also encouraged that the reviewers highlighted several strengths of our work, including the principled formulation of real/fake decomposition (Reviewers 2rrG,  3mcr, 9CNL), the strong empirical performance across diverse forgery types and backbones (Reviewers  2rrG, 8SSQ,  3mcr), and the clear writing and well-motivated design of our real-aware residual merging procedure (Reviewers  8SSQ, 9CNL).\n\nWe are fully prepared to address all concerns raised and appreciate the opportunity to clarify any remaining questions. Below, we summarize the major revisions made in response to the reviewers’ suggestions, together with pointers to the corresponding sections in the revised manuscript:\n\n1. **Improved Clarity and Expanded Analyses**\n\n     We carefully revised the manuscript to improve clarity in several key sections. In particular, we enhanced the visual explanations in Figs. 2–5 and added accompanying tables in the appendix to ensure that all underlying AUC values are easy to interpret. We also included additional analyses—such as within-category behavior and merging under mixed Real distributions (FF + CDF)—to better illustrate the stability of the shared Real component and the variability of Fake residuals.\n\n2. **Strengthened Experimental Evidence and Robustness Evaluation**\n\n     Responding to the reviewers’ suggestions, we added new experiments covering incremental specialist integration (e.g., Uniface), six-specialist merging, and robustness to highly realistic or previously unseen generators. These results demonstrate that R²M consistently maintains or improves performance while degrading more gracefully than CART in challenging regimes. We also expanded ablations on encoder choices, linear heads, and All-in-one behavior to provide a more complete empirical picture.\n\n3. **Clarified Scope, Assumptions, and Relation to Prior Work**\n     \n     We revised the theoretical section to more clearly articulate the local assumptions behind Proposition 1 and specify the scenarios where they naturally hold. In the related-work section, we clarified the distinction between $R^{2}$M and training-time generalization methods such as Effort, emphasizing their complementary roles. To further aid understanding, we added a high-level pipeline diagram illustrating the full merging process.\n\nFor detailed, point-by-point clarifications, please refer to our individual responses to each reviewer. If any additional questions arise, we would be glad to provide further explanation during the discussion phase. We appreciate the opportunity to continue refining and improving the paper."}}, "id": "xLsDW9IVso", "forum": "ztIFs5nZJr", "replyto": "ztIFs5nZJr", "signatures": ["ICLR.cc/2026/Conference/Submission11154/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11154/Authors"], "number": 8, "invitations": ["ICLR.cc/2026/Conference/Submission11154/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763729228226, "cdate": 1763729228226, "tmdate": 1763730185520, "mdate": 1763730185520, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}