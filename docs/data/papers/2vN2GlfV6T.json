{"id": "2vN2GlfV6T", "number": 3877, "cdate": 1757559614131, "mdate": 1759898065084, "content": {"title": "Step-Aware Residual-Guided Diffusion for EEG Spatial Super-Resolution", "abstract": "For real-world BCI applications, lightweight Electroencephalography (EEG) systems offer the best cost–deployment balance. However, such spatial sparsity of EEG limits spatial fidelity, hurting learning and introducing bias. EEG spatial super-resolution methods aim to recover high-density EEG signals from sparse measurements, yet is often hindered by distribution shift and signal distortion and thus reducing fidelity and usability for EEG analysis and visualization. \nTo overcome these challenges, we introduce SRGDiff, a step-aware residual-guided diffusion model that formulates EEG spatial super-resolution as dynamic conditional generation.\nOur key idea is to learn a dynamic residual condition from the low-density input that predicts the step-wise temporal and spatial details to add and uses the evolving cue to steer the denoising process toward high density reconstructions.\nAt each denoising step, the proposed residual condition is additively fused with the previous denoiser feature maps, then a step-dependent affine modulation scales and shifts the activation to produce the current features. \nThis iterative procedure dynamically extracts step-wise temporal rhythms and spatial-topographic cues to steer high-density recovery and maintain a fidelity–consistency balance.\nWe adopt a comprehensive evaluation protocol spanning signal-, feature-, and downstream-level metrics across SEED, SEED-IV, and Localize-MI and multiple upsampling scales. \nSRGDiff achieves consistent gains of up to 40\\% over strong baselines, proving its superiority in the task of EEG spatial super-resolution. Moreover, topographic visualizations comparison and substantial EEG-FID gains jointly indicate that our SR EEG mitigates the spatial–spectral shift between low- and high-density recordings. Our code is available at https://anonymous.4open.science/r/DDPM-VAE-6F6B.", "tldr": "We introduce SRGDiff, a step-aware residual-guided diffusion model that formulates EEG spatial super-resolution as dynamic conditional generation.", "keywords": ["EEG spatial super-resolution; Conditional Diffusion Model; Multi-channel Time Series Generation"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/14cb0eea8f3114f4c2e7a20923ca7bc8f2c5233f.pdf", "supplementary_material": "/attachment/f6d725962dc870a98ac45c690756bb091dd363c5.pdf"}, "replies": [{"content": {"summary": {"value": "This paper tackles the problem of EEG spatial super-resolution (SR), which aims to reconstruct high-density (HD) EEG signals from sparse, low-density (LD) measurements. The authors argue that existing methods, including recent diffusion models, use a \"static guidance\" strategy (like concatenation) that leads to a trade-off between fidelity to the HD signal distribution and consistency with the LD input .\nTo solve this, they propose SRGDiff, a latent diffusion model that uses a novel \"dynamic conditional generation\" framework. The core idea is to learn a dynamic residual from the LD input, which acts as a step-aware directional correction during the reverse diffusion (denoising) process. This is implemented via two new modules: a Residual Direction Module (RDM) that predicts this step-wise residual and a Step-Aware Modulation Module (SMM) that applies step-dependent affine modulation to control the guidance strength. The authors evaluate their method on three datasets (SEED, SEED-IV, Localize-MI) using a comprehensive three-level protocol (signal, feature, and downstream) , demonstrating state-of-the-art results that significantly outperform strong baselines."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The core concept of \"dynamic residual guidance\" is a clever and novel departure from standard static conditioning in diffusion models.\nThe paper demonstrates massive, consistent performance gains over a suite of strong, recent baselines (e.g., ESTformer, STAD) across three datasets . A 50% NMSE reduction on SEED is a remarkable improvement.\nThe three-level evaluation protocol (signal-level NMSE/PCC, feature-level EEG-FID, and downstream classification accuracy) is a model of rigor and provides a holistic and convincing picture of the generated signals' quality and utility .\nDespite its architectural complexity, the authors provide evidence (Table 10) that their method is significantly faster than other diffusion-based approaches, making it more practical."}, "weaknesses": {"value": "The authors motivate their work by criticizing \"static guidance\"  but then fail to include a static guidance model (e.g., LDM with feature concatenation) in their ablation study (Figure 5). The comparison against a seemingly unconditional LDM baseline is a feeble argument. This omission makes it impossible to validate the paper's central claim: that the proposed dynamic RDM and SMM modules are superior to the standard, simpler conditioning method they are designed to replace."}, "questions": {"value": "In your ablation study (Figure 5), is the \"LDM\" baseline an unconditional model? If so, why did you not compare against the primary target of your criticism: a standard statically-guided LDM (e.g., using feature concatenation), which would serve as a proper baseline to evaluate the utility of your RDM and SMM modules?\n\nThe performance gains in your ablation (e.g., NMSE 0.86 for LDM vs. 0.34 for SRGDiff at 8x on SEED)  are far larger than the gains over the SOTA conditional model STAD (Table 2). This strongly suggests your LDM baseline is unconditional, making the ablation misleading. Can you provide a direct comparison between SRGDiff and an \"LDM + Static Concatenation\" baseline?\n\nYour runtime in Table 10 is impressively fast. Is this because the RDM and SMM are very lightweight? And does the static-guidance-by-concatenation baseline (which I am asking for) run even faster?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ynSUNM5IVT", "forum": "2vN2GlfV6T", "replyto": "2vN2GlfV6T", "signatures": ["ICLR.cc/2026/Conference/Submission3877/Reviewer_pkZv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3877/Reviewer_pkZv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3877/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760956697903, "cdate": 1760956697903, "tmdate": 1762917078646, "mdate": 1762917078646, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the emerging problem of EEG spatial super-resolution, a relatively new and challenging topic in the EEG community. While super-resolution has been extensively studied in computer vision, only a few works have recently explored this concept for EEG, primarily in IEEE journals rather than mainstream neuroscience venues. The authors adapt state-of-the-art deep learning tools, such as transformers and generative diffusion models, to reconstruct high-density EEG from low-density recordings. This effort bridges the methodological gap between biomedical signal processing and modern deep generative modeling, which is commendable. However, several conceptual and technical issues require deeper clarification and refinement to make the work truly convincing from both a signal processing and machine learning standpoint."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper introduces EEG spatial super-resolution to the broader ML community, addressing a domain problem that remains underexplored.\n\nThe use of deep generative modeling (transformer/diffusion) provides a fresh analytical perspective and helps re-interpret a traditionally biomedical task in a form understandable to the ICLR community.\n\nThe overall framework and evaluation pipeline are consistent with prior EEG SR baselines (e.g., ESTformer, STAD), allowing fair comparison and reproducibility."}, "weaknesses": {"value": "1. The authors continue using NMSE, PCC, and SNR as the main evaluation metrics. These are inherited from previous EEG works but lack a theoretical justification for super-resolution tasks in the ML setting. Given the ICLR context, this presents an opportunity to re-examine whether these metrics are conceptually valid critically. For instance, does high-density (HD) EEG necessarily yield higher SNR values than low-density EEG? If not, why do the reported gains occur?\n\n2. EEG signals vary significantly across sessions and subjects. Without explicitly addressing this factor, through normalization, adaptation, or domain alignment, the model’s reported performance might not generalize. The paper does not mention whether such variability was handled or controlled.\n\n3. When compared to recent baselines such as STAD and ESTformer, the proposed method shows similar results across several datasets and metrics. The manuscript lacks a clear and intuitive explanation of how the proposed architectural modifications lead to consistent improvements beyond fine-tuned engineering choices.\n\n4. Figure 4 appears to showcase selected examples. Quantitative evidence (e.g., statistical comparisons or full-dataset averages) should be provided to demonstrate consistent superiority."}, "questions": {"value": "1. Why did you decide to continue using NMSE, PCC, and SNR? Could you justify why these metrics are still meaningful for evaluating generative EEG models, especially when HD EEG may not inherently outperform LD EEG on such metrics?\n\n2. How do you handle session- and subject-level variability? Were normalization or adaptation techniques applied to ensure robustness?\n\n3. Can you provide a more intuitive explanation for the specific architectural innovations that differentiate this method from STAD or ESTformer?\n\n4. Could you include full quantitative comparisons corresponding to Figure 4 to rule out visual selection bias?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DbUciHqRI1", "forum": "2vN2GlfV6T", "replyto": "2vN2GlfV6T", "signatures": ["ICLR.cc/2026/Conference/Submission3877/Reviewer_cWrT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3877/Reviewer_cWrT"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3877/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761422744420, "cdate": 1761422744420, "tmdate": 1762917078360, "mdate": 1762917078360, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work proposes SRGDiff, a diffusion-based approach to solve the task of EEG spatial super-resolution (EEG-SR). SRGDifff proposes two modules, a residual direction module (RDM), predicting per-step residuals from LD EEG features as guidance, and a step-aware modulation module (SMM), providing time-dependent affine scaling and shifting of the latent features."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The work shows thorough experimentation by testing their approach across multiple datasets\n- The paper is well-writen and cleanly organized\n- The quantitative improvements over previous EEG SR methods are consistent and strong"}, "weaknesses": {"value": "Besides their meaningful application to an important domain, the proposed method largely combines existing diffusion-conditioning tricks (residual conditioning, affine modulation, step embeddings). There is little theoretical or conceptual innovation beyond standard conditional diffusion formulations. Overall, the method resembles ControlNet/T2I-Adapter-style modulation, rebranded for EEG. For the ICLR main track, this feels closer to an applied engineering paper than a new machine learning contribution."}, "questions": {"value": "- What is the conceptual difference between SRGDiff’s conditioning mechanism and standard conditional diffusion or ControlNet residual conditioning?\n- How does the \"residual direction\" differ from simply adding predicted corrections in the latent space (i.e., learned noise offsets)?\n- The reported FID improvements (Fig. 3) are inconsistent. SRGDiff does not always achieve the lowest FID, and in some settings, baseline methods perform comparably or better. Could the authors detail how the \"EEG-FID\" is computed, and why it is an appropriate metric for EEG fidelity (which seems primarily reference-based)?\n- Did the authors evaluate computational cost against simpler transformer-based SR models (e.g., ESTformer) under equal parameter budgets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "LcdIV30bfM", "forum": "2vN2GlfV6T", "replyto": "2vN2GlfV6T", "signatures": ["ICLR.cc/2026/Conference/Submission3877/Reviewer_sP2w"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3877/Reviewer_sP2w"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3877/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761548853482, "cdate": 1761548853482, "tmdate": 1762917078122, "mdate": 1762917078122, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents SRGDiff, a novel diffusion-based method for spatial super-resolution of EEG that addresses the consistency–fidelity trade-off by dynamically conditioning the reverse process on low-density EEG data using residual guidance. Specifically, the authors propose using the forward-noising residual from low-density channels as a per-step corrective direction in the denoising. To achieve this, a Residual Direction Module (RDM) predicts a path residual for directional correction, and a Step-Aware Modulation Module (SMM) predicts scale and bias for calibration of the residual update. \n\nExtensive experiments on three datasets (SEED, SEED-IV, and Localize-MI) demonstrate that SRGDiff outperforms strong baselines (e.g., ESTformer, STAD, DDPMEEG) across signal-, feature-, and downstream-level evaluations over multiple upsampling scales."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Originality. The idea of dynamically guiding each denoising step with a residual derived from the LD forward process is novel and conceptually distinct from prior approaches that rely on static conditioning.\n\nQuality. The method is comprehensively evaluated across three public datasets and multiple SR scales, covering signal-, feature-, and downstream-level tasks. Ablations demonstrate the importance of both RDM and SMM.\n\t\nSignificance. SRGDiff consistently achieves superior performance measured by NMSE, PCC, and SNR compared to strong baselines. The improvements are meaningful and practically relevant for EEG-based BCI applications.\n\nClarity. The paper is well-structured, concise, and coherent. Figures effectively illustrate the model components and results."}, "weaknesses": {"value": "- The authors claim that SRGDiff is transferable to general SR settings, while all experiments are restricted to EEG. This should at least be discussed in more detail but ideally be experimentally verified to support the claim.\n- The impact of $\\lambda_{res}$ and $\\lambda_{SMM}$ is not studied. Adding an experiment to the ablation section where $\\lambda_{res}$ and $\\lambda_{SMM}$ are varied would provide insight into the sensitivity and impact of hyperparameters.\n- In the abstract, the claim of “up to 40% gains” over baselines is vague. It would improve clarity to specify under which dataset, SR scale, and metric these gains occur.\n- When the authors or the publication are not included in the sentence, the citation should be in parenthesis using \\citep{}, as outlined in the formatting instructions. \n- Some abbreviations are not defined (e.g., BCI, PCC).\n  Figure 4 is not readable due to the text being too small.\n\nIf the authors address the weaknesses the reviewer would be willing to increase the rating."}, "questions": {"value": "- How was the form of the RDM and SMM chosen? Were other forms explored?\n- Is SRGDiff applicable to variable or irregular LD electrode layouts? For example, could a model trained on 16 electrodes generalize to 8-electrode inputs, or would retraining be required?\n- Have the authors experimented with SR tasks beyond EEG to support the claim of generality?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BnnnUprLm5", "forum": "2vN2GlfV6T", "replyto": "2vN2GlfV6T", "signatures": ["ICLR.cc/2026/Conference/Submission3877/Reviewer_7K5e"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3877/Reviewer_7K5e"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3877/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761918237129, "cdate": 1761918237129, "tmdate": 1762917077856, "mdate": 1762917077856, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}