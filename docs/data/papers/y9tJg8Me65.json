{"id": "y9tJg8Me65", "number": 14476, "cdate": 1758236768182, "mdate": 1759897367910, "content": {"title": "ODConNet: OD Pairs based Conditional Travel Time Inference Network", "abstract": "Estimating travel time in navigation systems enhances user decisions. Current path-based models face high computational costs due to their reliance on path-specific calculation. In this paper, we propose ODConNet(OD Pairs based Conditional Travel Time Inference Network), a model that leverages origin-destination pairs to reduce estimation time. ODConNet employs multi-scale cells to model traffic networks, learning common routes and travel times simultaneously. As a result, the model trained on M(suburb-scale) and S(intersection-scale) cells achieved an inference time of 0.2ms per trajectory, with MAE of 4.3minutes and MAPE of 20.9%. This approach enhances the memory efficiency of navigation systems and improves traffic-based search service.", "tldr": "", "keywords": ["Navigation", "Travel Time", "Origin-Destination Pair", "Cell Segmentation", "Conditional Network"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/49cf369311d55b368533d2c828d96fdbe44ef9a8.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a new framework for predicting Origin-Destination time. The framework consists of a Conditional Variational Autoencoder followed by a Transformer model."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The Dataste description covers almost all of the processes applied to the data, increasing the reproducibility of the paper. Improve the final phrase by adding the number of data points and any other relevant information. \n\nThe description of the training error function."}, "weaknesses": {"value": "The introduction can be improved. The problem is briefly described, and the approach shifts from a graph-based to an independent use of OD data. This creates confusion, and the final problem can not be completely understood until subsection 2.2. \n\nSeveral sentences can be improved by adding a reference. A sentence without a reference could be considered a claim, and in those cases, the paper should try to demonstrate that, for example, the sentence from lines 042-043. This problem is evident throughout the paper.\n\nThe related work must be improved. There are several papers on OD time travel prediction, but the current submission lists only four, being the newest from 2024.\n\nGeohash level must be described. \n\nThe paper's problem description is confusing. In subsection 2.1 the paper mentions that OD pair information was utilized. However, later in subsection 2.2, each trajectory is converted to a cell representation at the problem level, indicating that the entire trajectory is needed for the proposed framework. \n\nRegarding Figure 2, what are the ideas of the columns? I understand that these represent the embeddings for location, time, and dwell information, but no explanation is given. \n\nL_{pred} is not used in the paper. Use numbers for the equation and reference them in the text.\n\nThe description of the framework must be improved. The lack of information about the proposed framework reduces the reproducibility of the paper. For example, there is no description of the current architectures. As a simple idea, the paper can present the proposed framework in a figure rather than the architecture of the ODConNet.\n\nSeveral issues call my attention regarding the proposed framework. The transformer model starts with an embedding of the data. Why do you use another convolutional model to extract the information? Also, the original transformer model is for text, but in this case, the model's input is the original data's embeddings. Also, the original transformers use two types of inputs, and this is not explained in the paper (the decoder and encoder).\n\nIn general, it seems that the framework is using a vision transformer, and the actual data is the image generated by the cell transformation. If this is the case, then the paper must be rewritten to improve the explanation of this use.\n\nImprove the use of figures. While the figures are referenced in the text, most are basic examples rather than something useful for the paper. For example, Figure 3 shows the architecture of the ODConNet, but the text gives it almost no discussion or importance. Also, several figures have very low resolution or include information not described in the paper (see the scales in Figure 4).\n\nFigure 4 plots e and f seems to be completely different. As a suggestion, the paper should change the subjective results to something objective.\n\nThe paper must report the training, validation, and test results to check for overfitting. It should show the error over the number of epochs during training. Actually, the training process is not mentioned in the paper, reducing its reproducibility. \n\nThe paper does not use any other baselines to compare. Considering the large number of papers based on this type of data, the paper should compare against other baselines. \n\nSubsection 3.4 does not describe the experiment used to compare fairness.\n\nMinor comments:\n-”dong” it should be ``dong”"}, "questions": {"value": "What is the input and output of each model?\n\nHow does the paper adapt the transformer model for this data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "gHiMOdRDED", "forum": "y9tJg8Me65", "replyto": "y9tJg8Me65", "signatures": ["ICLR.cc/2026/Conference/Submission14476/Reviewer_Tuw2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14476/Reviewer_Tuw2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14476/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760792883579, "cdate": 1760792883579, "tmdate": 1762924877111, "mdate": 1762924877111, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a travel time estimation method for given OD pairs without using trajectory data. The road network is divided into multi-scale cells, and trajectory reconstruction is used to enhance estimation accuracy. However, the paper lacks clear motivation and fails to present any unique technical challenges. The proposed technique is straightforward and offers little innovation or adaptation difficulty for the ETA problem. Moreover, the paper does not include comparisons with baseline methods, making it unsuitable for publication at ICLR."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The paper applies the conditional VAE technique to address the OD travel time estimation problem."}, "weaknesses": {"value": "**W1:** The motivation is unclear. The authors are encouraged to review existing OD travel time estimation methods (e.g., [1], [2]), summarize their limitations, and clearly explain how the proposed approach addresses these shortcomings.\n\n**W2:** The paper does not specify the key challenges of the problem, making it unclear why the conditional VAE technique is necessary or appropriate.\n\n**W3:** The description of **ODConNet** lacks sufficient technical detail, and the use of the VAE technique appears straightforward, offering limited methodological novelty for solving the problem.\n\n**W4:** The experimental design is overly simple, with no comparison against baseline methods, making it difficult to evaluate the effectiveness or advantages of the proposed approach.\n\n**W5:** The presentation quality is poor; several figures are unclear and appear to have been plotted without vector (SVG) graphics, reducing readability.\n\n\n[1] Yaguang Li, Kun Fu, Zheng Wang, Cyrus Shahabi, Jieping Ye, and Yan Liu. *Multi-task Representation Learning for Travel Time Estimation.* SIGKDD, 2018.\n\n[2] Yan Lin, Huaiyu Wan, Jilin Hu, Shengnan Guo, Bin Yang, Youfang Lin, and Christian S. Jensen. *Origin-Destination Travel Time Oracle for Map-Based Services.* SIGMOD, 2023."}, "questions": {"value": "please see the weakness points"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "faS8IvyzvV", "forum": "y9tJg8Me65", "replyto": "y9tJg8Me65", "signatures": ["ICLR.cc/2026/Conference/Submission14476/Reviewer_iGRd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14476/Reviewer_iGRd"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14476/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761653354324, "cdate": 1761653354324, "tmdate": 1762924876633, "mdate": 1762924876633, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "While the paper presents a practical and efficient approach to travel time estimation using only origin–destination (OD) pairs, it falls short of the novelty, rigor, and generalizability expected for publication at ICLR. The work is more engineering-oriented than foundational, and several methodological and experimental limitations undermine its scientific contribution."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Strengths\n\nClear Motivation: The paper correctly identifies a real-world limitation of path-based travel time prediction, its dependency on full route sequences, and proposes a lightweight alternative that only requires OD pairs and departure time.\n\nImpressive Inference Speed: The reported inference time of 0.2 ms per query is compelling, especially compared to commercial systems. This could be valuable for real-time navigation services.\n\nMulti-Scale Grid Representation: The use of L/M/S spatial grids to capture traffic patterns at different granularities is sensible and empirically validated (MS combination performs best).\n\nCVAE Integration: The CVAE module effectively filters anomalous trajectories and reconstructs plausible routes, as shown in the case studies. Ablation results confirm its importance."}, "weaknesses": {"value": "The architecture combines standard components (CVAE + Transformer) without introducing new modeling ideas. Similar conditional generative frameworks have been widely used in trajectory modeling and time-series forecasting.\n\nExperiments are conducted exclusively on Seoul data over a two-week period, with no cross-city or cross-country validation. This raises serious concerns about generalizability to other urban structures, traffic regimes, or driving cultures.\n\nThe paper compares inference speed against commercial APIs but does not compare accuracy against state-of-the-art academic models like DeepETA, OD Oracle on the same dataset.\nWithout such comparisons, claims of “accuracy” (MAE = 4.26 min, MAPE = 20.9%) lack contex and are these numbers competitive?\n\nThe model ignores real-time traffic conditions, weather, road types, POI semantics, and historical congestion patterns—all standard inputs in modern ETA systems. While the authors acknowledge this, the omission significantly limits practical applicability.\n\nEven static road network features (e.g., speed limits, lane count) are absent, despite being publicly available and highly predictive.\n\nReproducibility Concerns:\nKey implementation details are missing: How are grid sequences fed into the Transformer? Is positional encoding used? How are M and S scales fused (concatenation, attention, etc.)?\nThe loss weighting scheme (1 for occupied cells, 0.1 for empty) is heuristic and not justified."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CWTBKf0CcN", "forum": "y9tJg8Me65", "replyto": "y9tJg8Me65", "signatures": ["ICLR.cc/2026/Conference/Submission14476/Reviewer_sCwr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14476/Reviewer_sCwr"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14476/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761738406866, "cdate": 1761738406866, "tmdate": 1762924875943, "mdate": 1762924875943, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces ODConNet, a deep learning model for travel time inference that operates using only origin-destination (OD) pairs and departure time, without requiring detailed route (path) sequences. The proposed approach combines a Conditional Variational Autoencoder (CVAE) to reconstruct routes between OD pairs, and a Transformer network to predict travel time conditioned on reconstructed trajectories.\nTo model spatial structure, the city is divided into multi-scale cells , Large (L), Medium (M), and Small (S, representing progressively finer geographic granularity. They performed experiments on a dataset of 3.56 million trajectories from the Seoul metropolitan area."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The topic is relevant to the transportation based research.\n2. The architecture is explained clearly with necessary loss functions.\n3. The hierarchical cell-based encoding is an elegant idea to capture both spatial dependencies without requiring explicit graph topology."}, "weaknesses": {"value": "1. No formal justification for why this combination is optimal for OD-based inference. Alongside, there is no comparison with existing baselines related to spatiotemporal CNNs or DeepETA [i].\n2. The results lack temporal and geographical diversity as it has been focussed on Seoul for a period of two-week under normal conditions.\n3. The paper assumes that route inference using OD suffices ETA prediction, but it ignores multimodality involved in real-time traffic like pedestrian detection, hazard stop etc.\n\n\n\n[i] Wu, F., & Wu, L. (2019). DeepETA: A Spatial-Temporal Sequential Neural Network Model for Estimating Time of Arrival in Package Delivery System. Proceedings of the AAAI Conference on Artificial Intelligence"}, "questions": {"value": "Same as weaknesses.\n\n1. What's the reason of such high difference between other navigation systems and the propsed model? How is it measured for the other systems -- is not at all clear."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "o3mODdaehf", "forum": "y9tJg8Me65", "replyto": "y9tJg8Me65", "signatures": ["ICLR.cc/2026/Conference/Submission14476/Reviewer_LfrR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14476/Reviewer_LfrR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14476/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762078389668, "cdate": 1762078389668, "tmdate": 1762924875122, "mdate": 1762924875122, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}