{"id": "I6lEri0e2K", "number": 17569, "cdate": 1758277677740, "mdate": 1763703924771, "content": {"title": "Graph-to-Sequence Generation Beyond Autoregressive Models: A Graph-Aware Diffusion Framework", "abstract": "Pre-trained language models (PLMs) remain unreliable for graph-to-sequence (G2S) generation, where two challenges are particularly acute: (i) factual grounding, ensuring all entities are faithfully realized, and (ii) edit sensitivity, ensuring small, local graph edits to propagate consistently in the output. We propose Diffusion Language Models for Graphs (DLM4G), a non-autoregressive framework for iterative refinement conditioned on the graph input. Central to DLM4G is a graph-aware adaptive noising strategy, where noise is applied to the output sequence aligned with the graph components (entities and relations) using a learnable component-wise schedule. We learn a component-wise schedule by linearly mapping between per-component denoising loss and noise schedule. This ensures entities are generated faithfully and keeps graph edits localized in the text. Through extensive experiments on three benchmark datasets, DLM4G outperforms state-of-the-art autoregressive baselines that are 12–127× larger, achieving 10–15\\% relative gains on standard surface-level metrics (BLEU, ChrF++, METEOR) and embedding-based metrics (BERTScore-F1, MAUVE). More importantly, DLM4G improves factual grounding (FGT, $\\uparrow$) by +$\\Delta_{\\text{FGT}}$ 4.7 \\% and edit sensitivity (EDR, $\\uparrow$) by +$\\Delta_{\\text{EDR}}$ 7.9 \\% on average compared to comparably sized autoregressive baselines. Finally, we evaluate on molecule captioning, where molecular graphs are verbalized into textual descriptions, demonstrating the applicability of DLM4G to biomedical G2S tasks.", "tldr": "Graph-to-Sequence generation with Graph-Aware Diffusion Framework", "keywords": ["Graph-to-Sequence", "Autoregressive models", "Non-autoregressive models", "Diffusion Models"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bd976521a9ec2f72c66768022e0e79d36a55b939.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors tackle the topic of Graph-to-sequence translation, offering a diffusion-based alternative to the autoregressive, left-to-right Large Language Models (LLMs). In doing so, they identify the structure-agnostic forward process of existing diffusion models as a key limitation to their application to graph data. They thus propose a component-based noise schedule to modify the forward process for the aligned tokens in the conditional sequence. The authors show that this approach leads to improved performance on the translation task, notably in factual grounding and edit sensitivity."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The problem statement is clearly defined and motivated\n- The method achieves empirical gains over existing baselines, using much fewer parameters\n- The experiments are thoroughly described and the code is made available to ensure reproducibility"}, "weaknesses": {"value": "**Graph-to-sequence is misleading** Since the authors model the graphs they condition on as sequences (see line 196), their model is essentially a sequence-to-sequence model. Graph modelling typically deals with topics like equivariance (e.g. to node permutation), but the current paper does not tackle any graph related topics beyond aligning elements in the conditional sequence with those of the generated one (see Questions below for a related discussion). I understand that the nomenclature might be conventional in the field, based on the citations you provided, but I believe a few sentences clarifying this point + a discussion of permutation equivariance or the lack thereof would be helpful to a broader audience.\n\n**The procedure behind the graph-aware noise has multiple steps and the justification for each is unclear** After the alignment set is obtained, the noise schedule is modified such that it matches a uniform decrease in learning difficulty for a specific token, as approximated by the reconstruction error. These are the elements I feel are missing justification:\n    - Linearization of the loss values: what advantage is there to having a uniform denoising difficulty over time? have you considred other types of difficulty progressions?\n    - Piecewise linear map to obtain noise levels: what about other formulas like a polynomial transformation or an exponential one?\n    - from my understanding, alignment with the graph is only used to identify the most important tokens for which the schedule is modified to match reconstruction errors. Why not apply this procedure to all the tokens in the sequence? I would imagine all tokens in the sequence could benefit from a noise schedule that decreases their reconstruction error over time.\n    - I don't understand the importance of interpolating between the original and modified schedules at inference. What happens if you only use the modified schedule for the aligned tokens as you did in training? \n\n**The main components of D4LMG are not ablated**\nI suggest the following ablations to better justify the components of the model:\n- Using different weights (w_{i,t}) to combine the original and modified schedules at inference.\n- Apply other transformation (or none) to the loss values of the breakpoints.\n- Applying other mappings between the loss values and the noise levels.\n\n**Maybe alignment alone is enouhg?** [2] is based on a similar observation/data domain as your work: it tackles specifically translating a molecular product graph (linearized in SMILES notation), into a sequence representing its chemical precursors (a set of molecules, which if combined, produces the target graph). The authors notice that preprocessing their data such that the source and target sequences are canonicalized in a way that minimizes their edit distance, using atom-mapping as an alignment tool, leads to dramatic improvements in the translation task (figure 1 in their paper illustrates this procedure). Would a similar procedure apply to graph-to-sequence translations in your case? I think it would be an interesting comparison to consider, in order to identify how much modifying the noise schedule helps compared to simply minimizing the edit distance between the conditional and generated sequences during training.\n\n**Missing mathematical details and derivations**\n- The authors mention in Section 3.3 that their framework adopts a \"further end-to-end reparametrization\" of [1]'s classic variational lower bound loss, but do not explain how they arrive at Equation 3 from Equation 2. \n- Appendix A mentions including 'the principal mathematical derivations', but these are not available in the current version of the appendix.\n\n**Presentation** \n- The methodology section is confusing as it stands. It is particularly difficult to identify this paper's contributions compared to established elements in diffusion (e.g. forward and reverse processes), and less relevant portions of the model (e.g. the denoiser architecture used). I recommend restructuring the text into a background section, a methodology section highlighting the authors' contributions (i.e. the noising schedule, the training and inference procedures), and an experiment setup subsection presenting less crucial elements (e.g. model architecture).\n- Some graphical elements, like additional figures and maybe an algorithm summarizing training, could help with the readibility of the paper. I recommend illustrating the alignment module and maybe inference pipeline.\n- Figure 1 could be improved for clarity and to provide more details. In subfigure (A), you could replace the description in the pink block with 'NER-based Alignment' instead of (G,S) Alignment. In other blocks, you could write DLM4G without the parentheses around it. Subfigure (B) is hard to follow. What does the rounding section show? and how does the second portion illustrate denoising and consistency? The checkered blocks (representing embeddings Z_T to Z_0) could be replaced by arrays representing vectors and show which distribution each vector is from. I am assuming the cold and fire symbols represent inference and training respectively, but this is not a common symbolism and it would be better to state this clearly in the caption or in a legend. Finally, the figure has a number of elements not defined until later in the paper (e.g. the alignment set A, the concepts of rounding and consistency). I think the figure should either be moved (and referred to) later in the text where it's most relevant, or replaced with high-level illustrations useful in its current context.\n- The motivation of the new noise schedule is only given at the end of Section 2.5 (line 254). It should be moved earlier to help motivate the choices made in the design of the new schedule. With the current presentation, the reader is left wondering why is the reconstruction error an important factor in diffusing the aligned components."}, "questions": {"value": "- Why corrupt in a continuous space instead of the data space?\n- How do you canonicalize the linear representation of the conditional graph (in Section 3.4., Graph representation)? A key property of graphs (in 2D) is their invariance to permutation (meaning reading the nodes in any order does not change the graph structure). So how do you decide in what order to write the phrases about the USA in the example you gave? And would your model be able to produce the same output for different permutations of the nodes in the graph?\n- Line 208: \"Recovering these facts mid-trajectory is harder, which weakens factual grounding and increases errors\": what is meant by mid-trajectory here? perhaps 'from a noisy sequence' is clearer, since what weakens the factual grounding is noise, and it is most prominent earlier in the sequence.\n- In the alignment pipeline, what do you mean by 'generating all possible names and aliases for each entity'? A small example could be beneficial here.\n- Can you explain what is a non-increasing isotonic projection over t (line 254)?\n- How large is the alignment set in your experiments? what effect does reducing its size have on your results?\n\n**Nitpicks and typos**\n- Edit Sensitivity Rate is given the acronym EDR, shouldn't it be ESR?\n\n## References\n\n[1] Denoising diffusion probabilistic models, Ho et al. 2020.\n[2] \"Root-aligned SMILES: a tight representation for chemical reaction prediction\", Zhong et al. 2022."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qwYP5TwVoZ", "forum": "I6lEri0e2K", "replyto": "I6lEri0e2K", "signatures": ["ICLR.cc/2026/Conference/Submission17569/Reviewer_LF55"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17569/Reviewer_LF55"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17569/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761830155303, "cdate": 1761830155303, "tmdate": 1762927429640, "mdate": 1762927429640, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "DLM4G presents a graph-conditioned diffusion language model which is able to generate a text sequence according a graph. The model is based on DDPM model with encoder–decoder Transformer as the architecture. A per-token noise schedule is learned from an offline entity–text alignment so that “fact” tokens are corrupted less aggressively than function words. The model is evaluated on three knowledge-graph corpora and one molecular captioning set with new metrics for factual grounding (FGT) and edit sensitivity (EDR). Results show equal or better surface/semantic scores compared with zero-shot 7–8 B LLMs and fine-tuned T5-Large, while using 1–2 orders of magnitude fewer parameters."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The topic of generating text sequences with KG is interesting and important.\n2. The paper proposes the first diffusion-based sequence generator that conditions on an explicit graph.\n3. Large-scale experiments cover three diverse KG-to-text datasets plus an out-of-domain molecular captioning benchmark."}, "weaknesses": {"value": "1. Minimal graph inductive bias: beyond linearising triples with special tokens, the architecture uses a vanilla Transformer; edge direction, multi-hop relations, or graph topology are not explicitly modelled.\n2. Unfair baseline comparison: the chief competitors are either zero-shot LLMs (no task fine-tuning) or off-the-shelf T5-Large; no results are given for fine-tuned GPT-2/LLaMA or graph-augmented PLMs, making the claimed “12–127× smaller” advantage less convincing.\n3. Inference efficiency: generation uses 2 000 full diffusion steps; latency, throughput, and memory are not reported, nor are faster samplers (DDIM, DPM-Solver) explored."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TaVeW6LUaX", "forum": "I6lEri0e2K", "replyto": "I6lEri0e2K", "signatures": ["ICLR.cc/2026/Conference/Submission17569/Reviewer_VSmM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17569/Reviewer_VSmM"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17569/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761836309027, "cdate": 1761836309027, "tmdate": 1762927429029, "mdate": 1762927429029, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a graph-aware, token-wise noise schedule for diffusion language models in Graph-to-Sequence (G2S) tasks, motivated by improving factual grounding and edit sensitivity. During training, tokens aligned to KG entities/relations receive per-token schedules derived by sorting per-token denoising losses and mapping them via a monotone piecewise-linear function; at inference, the model blends this anchor schedule with a baseline schedule using cross-attention weights to the serialized graph. The method is evaluated on three established G2S benchmarks and compared against 8B-parameter LLMs in zero-shot settings, BERT and T5 models with finetuning, and three G2S models trained from scratch. The authors report improvements across benchmarks on surface and embedding metrics, as well as on their proposed factual grounding (FGT) and edit sensitivity (EDR) metrics. Finally, they test transfer to molecule captioning, comparing against three strong molecular captioning methods and reporting gains across metrics."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Well-motivated objective (faithfulness + edit sensitivity). The paper targets two concrete failure modes of G2S (entity grounding and sensitivity to local graph edits) and aligns the method and evaluation directly to these goals.\n\nSimple, plausible mechanism for graph-aware diffusion. A token-wise, graph-aware adaptive noising schedule is constructed from per-token denoising loss and KG alignment, with monotone (isotonic) projection and clamping; this is easy to implement on top of standard diffusion LMs.\n\nInference-time adaptation without alignments. The attention-based blending of anchor/base schedules at inference is a practical way to recover graph awareness without relying on training-time alignments at test time.\n\nSolid architectural choices with minimal bells/whistles. Uses a standard encoder–decoder Transformer and linearized triples with a small set of control tokens, which keeps comparisons interpretable and lowers engineering overhead.\n\nConsistent empirical gains at small scale. The 50–63M parameter models are competitive with or better than much larger AR baselines (e.g., T5-Large) and zero-shot LLMs across three benchmarks, including embedding metrics (BERTScore, MAUVE).\n\nTask-grounded evaluation beyond surface overlap. Introduces FGT (entity grounding with hallucination penalty) and EDR (edit sensitivity) and demonstrates improvements on both, matching the stated problem.\n\nEdit robustness demonstrated with controlled perturbations. The edited-graph protocol (single-entity substitutions) provides a direct, reproducible way to test whether local KG changes propagate to text.\n\nGenerality beyond KGs. The same mechanism transfers to molecule captioning, suggesting the approach is not tied to a specific graph domain.\n\nParameter efficiency story. Results emphasize quality per parameter, which is relevant given the cost profile of diffusion decoding.\n\nReproducibility details. Training schedule (T=2000 steps, LR, warmup/decay), update cadence for adaptive schedules, datasets, and baselines are specified clearly enough to reimplement."}, "weaknesses": {"value": "Novelty is not that big relative to existing importance-aware diffusion schedules; no direct comparisons provided. \n\nMethod explanation is a bit underspecified. Especially in the derivations of the objective function and the attention derived weight terms for the inference blending.\n\nBaseline strength. Several G2S baselines are 4+ years old and potentially weak; the T5/BERT finetunes are the most convincing comparisons. Absent are modern diffusion s2s recipes and stronger PLM variants or retrieval-assisted KG verbalization baselines under a matched training regime.\n\nPotential leakage from 80/10/10 splits in molecular captioning; not fully clear whether molecular captioning baselines were retrained, finetuned or zero-shot evaluated.\n\nKey ablations isolating the schedule’s effect would have been very important to understand the its contribution against other model to baseline differences, like using diffuison models instead of autoregressive models, which could also explain a lot of the performance gain\n\nDecoding efficiency not sufficently reported. Using 2000 diffusion steps might be considerably more expensive even when having 10-100 times less parameters.\n\nThere is no real ReadMe that explains how the code is structured and how it is to be used. Took some time to find all the relevant functions."}, "questions": {"value": "How exactly are you deriving your training objective, especially the rounding term?\n\nFor the subset of the M3-20M dataset, did you check how dissimilar the SMILES-description pairs in the training split are compared to the vadidation and and test splits.\n\nAre MolT5, GitMol and GraphT5 also trained on the training set or are they pretrained on other data?\n\nCan you give more details on the derrived weight terms for the inference noise schedule blending. Which layer's attention weights and how is it normalized?\n\nHow good is the model with a normal quadratic noise schedule?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZUDPrKLqEH", "forum": "I6lEri0e2K", "replyto": "I6lEri0e2K", "signatures": ["ICLR.cc/2026/Conference/Submission17569/Reviewer_Dobo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17569/Reviewer_Dobo"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17569/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926885079, "cdate": 1761926885079, "tmdate": 1762927428678, "mdate": 1762927428678, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}