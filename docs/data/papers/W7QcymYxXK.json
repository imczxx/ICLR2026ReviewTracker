{"id": "W7QcymYxXK", "number": 19369, "cdate": 1758295725746, "mdate": 1759897042738, "content": {"title": "Bridging Unsupervised and Semi-Supervised Anomaly Detection: A Provable and Practical Framework with Synthetic Anomalies", "abstract": "Anomaly detection (AD) is a critical task across domains such as cybersecurity and healthcare. In the unsupervised setting, an effective and theoretically-grounded principle is to train classifiers to distinguish normal data from (synthetic) anomalies. We extend this principle to semi-supervised AD, where training data also include a limited labeled subset of anomalies possibly present in test time. We propose a theoretically-grounded and empirically effective framework for semi-supervised AD that combines known and synthetic anomalies during training. To analyze semi-supervised AD, we introduce the first mathematical formulation of semi-supervised AD, which generalizes unsupervised AD. Here, we show that synthetic anomalies enable (i) better anomaly modeling in low-density regions and (ii) optimal convergence guarantees for neural network classifiers — the first theoretical result for semi-supervised AD. We empirically validate our framework on five diverse benchmarks, observing consistent performance gains. These improvements also extend beyond our theoretical framework to other classification-based AD methods, validating the generalizability of the synthetic anomaly principle in AD.", "tldr": "We generalize unsupervised anomaly detection to the semi-supervised setting by showing that synthetic anomalies — previously used in unsupervised AD — remain provably and empirically beneficial with limited labeled anomalies.", "keywords": ["Statistical Learning Theory; Anomaly Detection; Supervised Learning; Classification; Synthetic Data"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/965d51a98e663af8cb10cad0ece815e5df12f3b2.pdf", "supplementary_material": "/attachment/d8ab4b83e3de28506794a4b0fbfb6ec6444931f3.zip"}, "replies": [{"content": {"summary": {"value": "This paper demonstrates that using synthetic anomalies improves the performance of semi-supervised anomaly detection. \nIt first formulates anomaly detection as a binary classification problem, \nthen shows why training a model using only normal data and known anomalies is difficult. \nThe proposed method theoretically resolves this issue by incorporating synthetic anomalies generated from a uniform distribution in addition to known anomalies. \nExperiments on tabular, image, and text data show that adding synthetic anomalies enhances the performance of semi-supervised anomaly detection."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- By defining a unified anomaly detection framework based on binary classification, this paper can handle both unsupervised and semi-supervised settings. Based on this, this paper also theoretically justify the use of synthetic anomalies.\n- The experimental results are very strong. Across a variety of methods and datasets, incorporating synthetic anomalies leads to improved performance."}, "weaknesses": {"value": "Please see the Questions section."}, "questions": {"value": "- In the proposed method, noise drawn from a uniform distribution is used as synthetic anomalies. However, since normal data also is a subset of a uniform distribution, would not the synthetic anomalies contain normal data as well? If so, I would expect the detection performance for normal data to drop. Why is the proposed method able to avoid this? (For example, DROCC also uses synthetic anomalies, but it includes mechanisms to avoid overlapping with normal data. That approach feels more natural to me; yet for images and text, adding uniform noise to DROCC actually improves performance.)\n- This paper uses autoencoders (AEs) in the experiments, but how about trying DeepSVDD? For tabular data, AEs may be better, but for image data I expect DeepSVDD to yield stronger results. I am interested in how the proposed method would perform within DeepSVDD-based variants such as DROCC, ABC, and DeepSAD."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gVNyvP6uaA", "forum": "W7QcymYxXK", "replyto": "W7QcymYxXK", "signatures": ["ICLR.cc/2026/Conference/Submission19369/Reviewer_DuyK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19369/Reviewer_DuyK"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19369/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761788100952, "cdate": 1761788100952, "tmdate": 1762931301877, "mdate": 1762931301877, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes to add synthetic anomalies to diversify the collected anomalies under the semi-supervised setting. Authors connect anomaly detection with binary classification and introduces synthetic anomalies to mitigate two issues in semi-supervised AD: false negative modeling and insufficient regularity of learning. Some theoretical analyses are provided to justify the effectiveness of incorporating synthetic anomalies. Experiments across tabular, image, and text datasets  demonstrate the applicability of the proposed framework."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1.  Some theoretical analyses are conducted on the effectiveness of introducing synthetic anomalies for semi-supervised anomaly detection.\n\n2. The experiments span diverse modalities (tabular, image, text) and multiple AD methods, showing general applicability of the “synthetic anomaly” principle."}, "weaknesses": {"value": "1. Formulating anomaly task as binary classification is fundamentally inappropriate. Since the type of anomaly is uncountable, anomaly detection is usually formulated as one-class classification to model the distribution of normal data or to learn the pattern of them. Using binary classifier may learn a unreliable decision boundary.\n \n2. The theoretical analysis of convergence is narrow to the network using ReLU as activation function. Extending the theoretical guarantees to broader architectures or activation functions would significantly strengthen the generality and impact of the results.\n\n3. The novelty of this paper is weak. While the theoretical framing is elegant, the core idea is adding synthetic anomalies, which is not new. The main contribution lies in extending this idea to a semi-supervised setting, which feels incremental and does not substantially push the frontier of anomaly detection research.\n\n4. Synthetic anomaly generation is overly simplistic. The use of uniformly random noise as synthetic anomalies is questionable, especially for complex or high-dimensional data. This weakens the practical significance of the framework and may not generalize to high-dimensional or structured data. There is no comparison with more informative or adaptive anomaly generation methods.\n\n5. The presented ablation resembles a sensitivity analysis rather than a comprehensive investigation.\n\n6. The writing of this work is terrible and should be significantly improvoed."}, "questions": {"value": "1. How sensitive is the framework to the way synthetic anomalies are generated? Would a more structured generator improve performance?\n2. It is possible to generalize the theoretical guarantees to broader architectures or activation functions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LC8eM1Vx8w", "forum": "W7QcymYxXK", "replyto": "W7QcymYxXK", "signatures": ["ICLR.cc/2026/Conference/Submission19369/Reviewer_SFnp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19369/Reviewer_SFnp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19369/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968850473, "cdate": 1761968850473, "tmdate": 1762931301458, "mdate": 1762931301458, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper deals with semi-supervised anomaly detection. It states that anomaly detection and semi-supervised anomaly detection can be approached as binary classification.\n\nIt proposes as algorithmical contribution in section 4.1 to sample from a uniform distribution background to create artificial anomaly samples.\n \nThey cite several theoretical results on excess risk convergence over a function class for binary classification. They prove certain special cases.\n\nThey perform experiments using relu networks."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Negligible in the light of the below weaknesses."}, "weaknesses": {"value": "The algorithmical proposal of this paper, sampling anomaly background ,  is long known (e.g. the paper by Sipple 2020, but it is known before), is trivial and has no novelty. There has been advantages over that, see eg SMOTE, Chawla et al from 2002 . \n\n- The claim that Semi-supervised anomaly detection can be treated as classification is not novel. Steinwart 2005 has established this formally for anomaly detection in general (Corollary 3 and theorem 4 in Steinwart 2005). \n\nWere it not for the old suggestion of sampling negatives and the many mistakes, this paper would feel like a recapitulation of Steinwart 2005, or one tries to confuse the readers over the simplicity of the algorithmical content by citing convergence bounds.\n\n- The paper has a number of severe theoretical mistakes:\n\n1. line 148-149 they state that if a non-negative lower bound converges to zero, then the term which it bounds from below must also converge to zero. Their statement is: $a >= b$, $b>=0$, $b \\rightarrow 0$ implies $a \\rightarrow 0$ \n\nfor evidence see  \"from [4], we see ...\"\n\n2. a similar wrong conclusion occurs in lines 240-244\n\n\"From Proposition 3.1 and Theorem 3.3, we can see that if the regression function is discontinuous, the approximation error is high (at least 1), which may lead to vacuous excess risk bounds (i.e., excess risk can be high and is not guaranteed to converge). Lacking theoretical guarantees, the Bayes classifier cannot be effectively learned.\"\n\nIf an upper bound diverges, it does not mean that the quantity bounded by it would have to diverge as well. Same kind of logical mistake as in 1., but now with an upper bound.\n\n3.Proposition 4.2 is obviously wrong. They claim continuitity, however if $h_-(X)$ is discontinuous, then $f_P(X)$ can be discontinuous, too.\nE.g. choose $s=0.5, \\tilde{s}=0.5, h_1 =c$, then \n$f_{P}(x) = \\frac{0.5c -0.25 h_-(X) -0.25}{0.5c + 0.25h_-(X) + 0.25}$ \n\n4. eq (4) is proven in Steinwart (2005) as an upper bound, see Theorem 10 in Steinwart (2005).\nProving the exact same result a lower bound would be very surprising.\nThey use exactly the same argument as Steinwart 2005 in the proof of theorem 10, but arrive at the opposite direction of inequality.\n\nIf this is corrected to the correct  direction of inequality, their extension is straightforward. Steinwart 2005 assumes for the anomaly density to be $\\mu$. They assume that it has density $h_2$ with respect to $\\mu$ . There is no technical effort in doing this change.\n\nbtw, line 1101 makes a lower bound (it should use 3/5 as constant but this is minor) . \n\n\n5. Proposition 3.1 is wrong because they do not ensure that $\\mu(X_1) >0$ and $\\mu(X_-) >0$ . One can choose closed sets such that  $\\mu(X_1) =0$ and $\\mu(X_-) =0$ Then one can get a zero $\\ell_{\\infty}$-norm to $f(x)=0$\n\nbut even if one would fix that, it would be of no consequence, see point 7 \n\n6. It could be that Theorem 4.5 has an unfavourable rate $O( (log n) ^4  / n ) ^{ (c+\\alpha) / (c+d) }$\n\nFor $c = \\alpha q$ is typically small compared to the input dimensionality $d$ if one wants smooth settings as they state it\n\nfor even moderate input dimensionalities d the bound is worse than the typical $O(n^{-1/2})$ results .\n\n7. the \"insufficient regularity of learning\" problem as they state it is no problem for training a classifier: \n\nassume $P[Y=1|X]$ makes a jump in direction orthogonal to the decision boundary, but the decision boundary is a standard hyperplane. This is trivially learnable with 1 layer. \n\n- Ironically, Tsybakovs noise condition, which is repeatedly cited by the submitters of this paper, requires a steepness of $\\eta(x) = P(Y=1|X=x )$ around 0.5 for faster convergence rates. They state that this steepness would a problem for learning. This is a direct contradiction to the results from Tsybakov and Steinwart. \n\n- Overall, the paper has very poor readability."}, "questions": {"value": "none"}, "flag_for_ethics_review": {"value": ["Yes, Research integrity issues (e.g., plagiarism, dual submission)"]}, "details_of_ethics_concerns": {"value": "Gaslighting / obfuscating style of writing:\na very trivial proposition (sampling from the uniform density for anomalies), covered up by lots of math formalisms being actually trivial extensions from Steinwart 2005. \n\nIt is very close to Steinwart 2005 for the theoretical results when one removes or corrects the errors.\n\nupdate: what I had in mind: if these authors submitted another paper, to check that they do not employ the same obfuscating style.\n\nThere is a striking contradiction between  the \"insufficient regularity of learning\" problem as they state it and the results from Tsybakov and Steinwart .\n\n- Ironically, Tsybakovs noise condition, which is repeatedly cited by the submitters of this paper, requires a steepness of $\\eta(x) = P(Y=1|X=x )$ for faster convergence rates. They state that this steepness is a problem for learning. This is a direct contradiction to the result from Tsybakov and Steinwart . \n\nHow can one dabble with the math of these papers and not get the semantic content of their conditions ? This is unexpected. If a human  is using the math, then the human should have some idea of what it is doing, no ?\n \nThis is a paper that makes one want to quit doing research."}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dViUTbPFYT", "forum": "W7QcymYxXK", "replyto": "W7QcymYxXK", "signatures": ["ICLR.cc/2026/Conference/Submission19369/Reviewer_n4YP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19369/Reviewer_n4YP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19369/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977000253, "cdate": 1761977000253, "tmdate": 1762931300828, "mdate": 1762931300828, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}