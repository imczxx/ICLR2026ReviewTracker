{"id": "KTjAeX6u2a", "number": 542, "cdate": 1756745302001, "mdate": 1759898254594, "content": {"title": "AURA: Structural and Semantic Calibration for Robust Federated Graph Learning", "abstract": "Training highly generalizable server model necessitates requires data from multiple sources in Federated Graph Learning. However, noisy labels are increasingly undermining federated system due to the propagation of erroneous information between nodes. Compounding this issue, significant variations in data distribution among clients make noise node detection more challenging. In our work, we propose an effective structural and semantic calibration framework for Robust Federated Graph Learning, AURA. We observe that spectral discrepancies across different clients adversely affect noise detection. To address this, we employs SVD for self-supervision, compelling the model to learn an intrinsic and consistent structural representation of the data, thereby effectively attenuating local high-frequency perturbations induced by noisy nodes. We introduce two metrics, namely \"Depth Influence\" and \"Breadth Influence\". Based on these metrics, the framework judiciously selects and aggregates the most consensual knowledge from the class prototypes uploaded by each client. Concurrently, clients perform knowledge distillation by minimizing the KL divergence between their local model's output distribution and that of the global model, which markedly enhances the model's generalization performance and convergence stability in heterogeneous data environments. AURA demonstrates remarkable robustness across multiple datasets, for instance, achieving a $7.6\\%$ $\\uparrow$ F1-macro score under a 20\\%-uniform noise on Cora. The code is available for anonymous access at \\url{https://anonymous.4open.science/r/AURA-F351/}.", "tldr": "", "keywords": ["Federated Learning", "Graph Learning", "Robustness", "Geometric Learning"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f6b9cf9f61199790456c2fa3f784385f781d1828.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses federated graph learning under the impact of label noise. The authors propose AURA, a protocol that filters out high-frequency components in the adjacency graph (noisy connections) and then leverages knowledge distillation based on prototype node representations. These prototypes are sourced from the different clients and represents nodes that are considered highly influential.\n\nThe results demonstrate that AURA outperforms several benchmarks on six different datasets under varying amounts of label noise."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- This paper considers the practically important problem within federated graph learning using noisy labels. \n- The paper is well structured in that it treats label noise and client heterogeneity separately and builds up to a streamlined federated protocol coined AURA. \n- AURA is compared to multiple benchmarks and is shown to outperform them all in all but a few scenarios."}, "weaknesses": {"value": "- To handle label noise, the authors propose each client to perform an SVD of the adjacency matrix in each round. This is a very costly operation ($\\mathcal{O}(n^3)$). Hence, I fail to see how this could possibly scale to larger graphs beyond the academic toy examples in the paper. \n\n- To focus on the low-frequency components is not novel, see e.g., GCN. Moreover, this translates into a homophily assumption of the underlying graph. AURA suffers from the same assumption. Indeed, to AURA, heterophilic connections are considered label noise.\n\n- The usage of eq 6 (the SFA loss) needs more motivation.\n\n- The random walk approach is not fully described. Supposedly there is a hyper parameter associated with this but it is introduced in Section 4.4 at first. \n\n- There are multiple inconsistencies in the writing, for example:\na) $\\epsilon$ is not defined in (2)\nb) All components in the problem formulation are not defined, e.g., $\\mathcal{X}_k$.\nc) By the end of Sec. 2, the authors state that the objective is to learn a generalizable global model but the loss in (1) is only concerned with the loss associated with a specific client.\nd) It is unclear what the results in Table 1 are based on; are they averages across clients on their corresponding labeled data?\ne) matrices are sometimes denoted by bold-face and sometimes without.\n\n- The authors talk about a prototype graph created at the server. However, the server only has access to average embeddings of \"semantic core nodes\" for each class and client. The server then aggregates a subset of clients' average embeddings for each class but it is unclear how a graph is created.\n\n- One of the main points of federated learning is to not share sensitive data between clients. Yet, AURA requires clients to share information associated with the most influential nodes in each client. This concern is not treated at all.\n\n- The paper proposes multiple hyperparameters (five) but do not address how to properly pick all of them. For example, the number of singular values, m, is simply chosen as 10 in the evaluations. These hyperparameter choices should be properly motivated. Moreover, there is a discrepency in what hyperparameters are used; in Sec. 4.1, the authors state $\\alpha=0.85$ and $\\beta=1$ while in Sec. 4.4., $\\alpha=0.5$ and $\\beta=0.25$.\n\n- The experimental results seem to be based on a single realization. The authors are encouraged to present the average and standard devation across multiple runs."}, "questions": {"value": "1) What is the complexity of AURA compared to other methods? Does it scale to larger graphs?\n2) Is AURA able to handle heterophilic graphs? \n3) Are the uniform noise and pair noise models realistic?\n4) What is the rational behind the Sinkhorn loss, i.e., why would one want to minimize the empirical node-representation distributions between the original and the low-pass filtered graph?\n5) How is the prototype graph at the server created?\n6) Clients sharing node prototypes with the server seem to violate privacy. \n7) How should the hyperparameters be chosen? For example, how should one think about $m$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lfA9IOy51T", "forum": "KTjAeX6u2a", "replyto": "KTjAeX6u2a", "signatures": ["ICLR.cc/2026/Conference/Submission542/Reviewer_1PKJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission542/Reviewer_1PKJ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission542/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761687530110, "cdate": 1761687530110, "tmdate": 1762915543355, "mdate": 1762915543355, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles the critical and challenging problem of label noise and data heterogeneity in FGL by proposing a novel and effective framework named AURA. The authors correctly identify two core challenges:  the message-passing mechanism of GNNs can propagate and even amplify noise across nodes, and heterogeneity among clients further complicates noise detection and leads to client drift and semantic aggregation conflicts. To address these issues, the framework introduces two well-designed components: SFA and SCD, demonstrating clear insight. I think the work is novel and solid."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.**Clear Motivation:** The paper's analysis of the noise problem in FGL is thorough. It accurately decomposes the problem into the inherent noise propagation issue of GNNs and the spectral and semantic  heterogeneity issues brought by FL , providing a clear motivation for the subsequent method design.\n\n2.**Novel and Technically Sound Method:** Its SFA component uses SVD for graph denoising and optimal transport for alignment, effectively addressing spectral heterogeneity and local noise. The SCD introduces a two-stage knowledge filtering mechanism: clients first select semantic core nodes via influence metrics to purify local prototypes, and the server then builds robust global anchors through consensus, outperforming naive averaging in resisting noise and client drift. Relational distillation further enhances robustness over hard feature alignment. \n\n3.**Sufficient experimentation**: Experiments against 15 baselines show AURA consistently achieves top results and even excels on clean data, proving it gains robustness without sacrificing generalization."}, "weaknesses": {"value": "1.In the methodology, the authors propose that clients select nodes with top-1/3 scores as the \"semantic core\" to compute local prototypes. Why is 1/3? This is a critical hyperparameter, but the paper seems to lack an empirical justification or sensitivity analysis for choosing this specific 1/3 ratio. For example, how would the model performance change if this ratio were set smaller or larger? \n\n2.Some descriptions are somewhat vague. The workflow description in Algorithm 1 could be further clarified. In the client-side update step for round $t$, the local knowledge alignment depends on the global prototype. Meanwhile, at the end of the same round, the server-side appears to use the newly uploaded information from that round to compute the for the next round. This seems to imply that the client in round $t$ is using the global prototype computed in round $t-1$. This is a reasonable and common \"one-round delay\" design in federated learning, but explicitly stating this in the main text would make the algorithmic flow clearer."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "6JEcN9OuJc", "forum": "KTjAeX6u2a", "replyto": "KTjAeX6u2a", "signatures": ["ICLR.cc/2026/Conference/Submission542/Reviewer_iurz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission542/Reviewer_iurz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission542/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761731775952, "cdate": 1761731775952, "tmdate": 1762915543194, "mdate": 1762915543194, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces AURA, a dual-perspective framework for robust federated graph learning under label noise and client heterogeneity. The two pillars are: (1) Structural-Aware Frequency Alignment (SFA), where client graphs are decomposed via SVD, enabling low-frequency backbone extraction to reduce both intra-client label noise and inter-client spectral drift, and (2) Semantic-Guided Consensus Distillation (SCD), which builds global class prototypes by weighting local client contributions using Breadth/Depth Influence metrics and enhancing knowledge transfer via relational knowledge distillation against a global anchor. Extensive experiments demonstrate the approach’s competitive robustness and performance compared to several baselines under different label noise scenarios."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- **Comprehensive empirical evaluation**. Extensive comparative experiments across multiple datasets (Cora, CiteSeer, PubMed, Physics, CS, Minesweeper) with varied noise conditions are provided, benchmarking against a diverse set of state-of-the-art methods. Notably, AURA delivers strong performance boosts in high noise regimes, as demonstrated by substantial margins in Table 1 and Table 5."}, "weaknesses": {"value": "-  **Notational Ambiguity**. The calculation and definition of marginals ($\\mathbf{r}$ and $\\mathbf{c}$) for optimal transport are not explicitly provided. It is unclear how node correspondence is enforced or relaxed during alignment, especially when original and backbone views may differ in size due to truncation in SVD. Clarification of this matching setup would ensure replicability.\n- **Issues on Table 1**. The results of the proposed method in PUBMED-pair setting were underlined as the second best one. However, there are another three results higher than 57.53 achieved by AURA.\n- **Inconsistent Experiment Settings**.  The number of smoothing factor α in Equation (8) is set 0.85. The number of the contribution score β in Equation (11) is set 1. However, the range of α in Sec. 4.4 is [0.15, 0.3]  and there is a similar issue with  β. The value range of the hyper-parameters is suggested to be consistent with the ones in the main experiments.\n- **Missing Experiment Details**. It's recommended to report the details of the partition of the graph across clients for better reproducibility. Besides, there were also no details about the model architecture.\n- **Complex Configurations**.Some configurations and their influences were not well jutisfied. For example, the server selects only the top-K local prototypes with the highest Global Cohesion Scores for aggregation, but the value of K was not reported in this paper. The sensitivity of the method to the number of the SVD parameter m was also not discussed. These complex configurations may lead to  vulnerability in practice."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1QikzJV76O", "forum": "KTjAeX6u2a", "replyto": "KTjAeX6u2a", "signatures": ["ICLR.cc/2026/Conference/Submission542/Reviewer_jSNf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission542/Reviewer_jSNf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission542/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998051327, "cdate": 1761998051327, "tmdate": 1762915543072, "mdate": 1762915543072, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes AURA, a framework for robust federated graph learning (FGL) under noisy labels and heterogeneous client data. The method introduces two core modules: Structural-aware frequency alignment (SFA) and semantic-guided consensus distillation (SCD). \nSFA leverages singular value decomposition (SVD) to filter out high-frequency noise and align graph structures across clients. \nSCD constructs a global prototype graph based on two new metrics, depth influence and breadth influence, to aggregate the most reliable semantic knowledge.\nClients then align with the global model through knowledge distillation, minimizing the divergence between local and global semantics.  The authors claim that this dual structural-semantic calibration improves both robustness and generalization in federated graph models. Experiments on six benchmark datasets show that AURA achieves up to 7.6% improvement in macro-F1 under noisy conditions compared to prior methods."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses a relevant and challenging problem, focusing on label noise in federated graph learning, which is both practically important and technically difficult due to data heterogeneity and privacy constraints. The proposed method achieves consistent improvements over baselines across multiple datasets and noise settings, suggesting that the structural-semantic calibration approach has potential."}, "weaknesses": {"value": "1. The approach relies on computationally expensive operations such as SVD, matrix inversion, and prototype similarity computations. For large-scale graphs, these operations are expensive and may not scale. The paper does not provide a complexity analysis, making it unclear whether the method can scale to realistic federated graph settings.\n\n2. Since AURA operates in a federated setting, sharing prototypes or global semantic representations could reveal sensitive information about local data. The paper does not discuss possible privacy leakage nor communication overhead.\n    \n3. Although the results are promising, the experiments do not fully support some of the paper’s claims regarding scalability and robustness. For example, no experiments are conducted on large graphs, and communication costs are not analyzed.\n\n4. Several design choices, such as SVD filtering, influence scores, and prototype selection, seem largely heuristic and are insufficiently motivated. The paper would benefit from a more rigorous explanation of how these components interact and contribute to the overall performance.  It feels like several techniques from prior work are combined without strong justification.\n\n5. Some relevant works, such as FedRGL: Robust Federated Graph Learning for Label Noise, are not discussed or compared. In addition, the related work section appears only in the appendix; it should be integrated into the main body of the paper.\n\n6. The writing and presentation of the paper can significantly be improved. The explanations are often unclear, and poorly structured, which makes it difficult to follow the main ideas and contributions. The paper would benefit greatly from\nclearer organization and concise language."}, "questions": {"value": "1. What is the computational complexity of the proposed method? Specifically, what is the cost of SVD and prototype similarity computations per round of FL? Can the approach handle graphs with millions of nodes?\n\n2. What is the privacy leakage  of AURA? What is the privacy implication of sharing prototypes with the server? What information about local data might be exposed?\n\n3. What is the total communication cost per round, and how does it compare with standard baselines such as FedAvg or FedProx?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ShKdWqB9jq", "forum": "KTjAeX6u2a", "replyto": "KTjAeX6u2a", "signatures": ["ICLR.cc/2026/Conference/Submission542/Reviewer_hrJw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission542/Reviewer_hrJw"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission542/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762003113351, "cdate": 1762003113351, "tmdate": 1762915542916, "mdate": 1762915542916, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}